{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d72d476f-0fed-431b-af11-2c2e57c871b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiplatform SDK version: 1.26.0\n"
     ]
    }
   ],
   "source": [
    "! python3 -c \"import google.cloud.aiplatform; print('aiplatform SDK version: {}'.format(google.cloud.aiplatform.__version__))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c15ec9b5-42d8-4f4d-9138-a98d5d65b126",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = 'mabv1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c228c41-c1fe-4972-ad95-ba536058b66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"mabv1\"\n",
      "VERSION                  = \"v1\"\n",
      "\n",
      "BUCKET_NAME              = \"mabv1-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://mabv1-hybrid-vertex-bucket/data\"\n",
      "BUCKET_URI               = \"gs://mabv1-hybrid-vertex-bucket\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_ID      = \"hybrid-vertex.movielens_dataset_mabv1\"\n",
      "BIGQUERY_TABLE_ID        = \"hybrid-vertex.movielens_dataset_mabv1.training_dataset\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f182545c-2dd5-4968-a7a3-d3096d352cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6812daea-da76-45dd-9ec4-c45eabdfe104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pickle as pkl\n",
    "\n",
    "import attr\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tf_agents.agents import TFAgent\n",
    "from tf_agents.bandits.agents import lin_ucb_agent\n",
    "from tf_agents.bandits.agents.examples.v2 import trainer\n",
    "from tf_agents.bandits.environments import (environment_utilities,\n",
    "                                            movielens_py_environment,\n",
    "                                            movielens_per_arm_py_environment)\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import TFEnvironment, tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.metrics.tf_metric import TFStepMetric\n",
    "from tf_agents.policies import policy_saver\n",
    "\n",
    "\n",
    "# from tf_agents.trajectories import time_step as ts\n",
    "# from tf_agents.specs import tensor_spec\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "# my project\n",
    "from src.per_arm_rl import data_utils\n",
    "from src.per_arm_rl import data_config\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1136c365-983c-4777-9c1f-2b5d9b30b3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88721fff-825f-42ef-8c9e-ecbbc6f92679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb730ba2-08cb-4433-9274-e754e11eee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a73c9b-5c6d-42c5-875e-39284f1cb3f2",
   "metadata": {},
   "source": [
    "# get train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8284886-9fc7-4b4f-9cbb-74821ea91943",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cde9c99b-0e7f-47b8-88fb-b6fb2257c1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://mabv1-hybrid-vertex-bucket/data/val/ml-ratings-100k-val.tfrecord']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/val'):\n",
    "# for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/train'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be3bc484-adec-47cb-b06d-25d56e39e7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([25.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[4]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'211'], dtype=object)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([874948475])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'346'], dtype=object)>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'other'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "train_dataset = train_dataset.map(data_utils.parse_tfrecord)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "83b5223c-bfc0-404a-ae1a-8474a1181532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER_RATING_DIM: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1.0: 0, 2.0: 1, 3.0: 2, 4.0: 3, 5.0: 4}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# USER_RATING_LOOKUP = data_utils.get_dictionary_lookup_by_tf_data_key(\n",
    "#     key = 'user_rating'\n",
    "#     , dataset= train_dataset\n",
    "# )\n",
    "\n",
    "# USER_RATING_DIM = len(USER_RATING_LOOKUP)\n",
    "# print(f\"USER_RATING_DIM: {USER_RATING_DIM}\")\n",
    "\n",
    "# USER_RATING_LOOKUP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea9e715-73ea-4880-a1f8-11a98116b8ca",
   "metadata": {},
   "source": [
    "# get vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a07e6550-b390-4dc4-83d7-acf5ca27c3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE_VOCABS: False\n"
     ]
    }
   ],
   "source": [
    "GENERATE_VOCABS = False\n",
    "print(f\"GENERATE_VOCABS: {GENERATE_VOCABS}\")\n",
    "\n",
    "VOCAB_SUBDIR   = \"vocabs\"\n",
    "VOCAB_FILENAME = \"vocab_dict.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9ae8cc3-fdd1-4c67-a9fc-0b87e9ec4a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab...\n",
      "Downloaded vocab from: gs://mabv1-hybrid-vertex-bucket/vocabs/vocab_dict.pkl\n",
      "\n",
      "'movie_id'\n",
      "'user_id'\n",
      "'user_occupation_text'\n",
      "'movie_genres'\n",
      "'bucketized_user_age'\n",
      "'max_timestamp'\n",
      "'min_timestamp'\n",
      "'timestamp_buckets'\n"
     ]
    }
   ],
   "source": [
    "if not GENERATE_VOCABS:\n",
    "\n",
    "    EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{VOCAB_SUBDIR}/{VOCAB_FILENAME}'\n",
    "    print(f\"Downloading vocab...\")\n",
    "    \n",
    "    os.system(f'gsutil -q cp {EXISTING_VOCAB_FILE} .')\n",
    "    print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "    filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "    vocab_dict = pkl.load(filehandler)\n",
    "    filehandler.close()\n",
    "    \n",
    "    for key in vocab_dict.keys():\n",
    "        pprint(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce58ca06-7de7-4d5f-ae60-01905bc146d0",
   "metadata": {},
   "source": [
    "# get preprocess layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaea6080-162e-4a85-8df0-fb74f6bacc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hparams_dict = {\n",
    "#     \"XXXXX\":XXXX\n",
    "# }\n",
    "\n",
    "# feature_emb_dict = {\n",
    "#     \"feature_key\":\"movie_id\"\n",
    "# }\n",
    "\n",
    "NUM_OOV_BUCKETS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "159e66f1-7771-44e3-b543-e09793dad236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _get_arm_feature_preprocess_layer(hparams, tf_transform_output):\n",
    "#     \"\"\"Returns arm feature preprocessing layer.\"\"\"\n",
    "#     inputs = []\n",
    "#     features = []\n",
    "#     embedding_configs = [\n",
    "#         _EmbeddingConfig('doc_id', tf.int64, hparams.docid_embedding_dim),\n",
    "#         _EmbeddingConfig('app_language_tag', tf.string, \n",
    "#                          hparams.app_language_embedding_dim),\n",
    "#         _EmbeddingConfig('app_region_tag', tf.string,\n",
    "#                          hparams.app_region_embedding_dim)\n",
    "#     ]\n",
    "#     for embedding_config in embedding_configs:\n",
    "#         input_feature = tf.keras.Input(\n",
    "#             name=embedding_config.feature_key,\n",
    "#             shape=(1,),\n",
    "#             dtype=embedding_config.dtype)\n",
    "#         vocab = tf_transform_output.vocabulary_file_by_name(\n",
    "#             embedding_config.feature_key)\n",
    "#         max_tokens = tf_transform_output.vocabulary_size_by_name(\n",
    "#             embedding_config.feature_key) + NUM_OOV_BUCKETS\n",
    "#         if embedding_config.dtype == tf.int64:\n",
    "#             lookup = tf.keras.layers.experimental.preprocessing.IntegerLookup(\n",
    "#                 vocabulary=vocab, num_oov_indices=NUM_OOV_BUCKETS, oov_value=0)\n",
    "#         else:\n",
    "#             lookup = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "#                 max_tokens=max_tokens,\n",
    "#                 num_oov_indices=NUM_OOV_BUCKETS,\n",
    "#                 mask_token=None,\n",
    "#                 vocabulary=vocab)\n",
    "#         ind_tensor = lookup(input_feature)\n",
    "#         embedding_input = tf.keras.layers.Embedding(\n",
    "#             input_dim=max_tokens, output_dim=embedding_config.embedding_dim)(ind_tensor)\n",
    "#         embedding_input = tf.reduce_sum(embedding_input, axis=-2)\n",
    "#         inputs.append(input_feature)\n",
    "#         features.append(embedding_input)\n",
    "#     outputs = tf.keras.layers.concatenate(features, axis=-1)\n",
    "#     return tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766a1c01-1507-43e6-82d9-38e2d903fafe",
   "metadata": {},
   "source": [
    "## user features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5abb10f7-528f-47c3-b715-5b95f57fdd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_inputs = []\n",
    "global_features = []\n",
    "\n",
    "USER_EMBEDDING_SIZE = 4 # 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "107a95d3-0699-4285-a25c-7e6cf70bd62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_input_layer = tf.keras.Input(\n",
    "    name=\"user_id\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.string\n",
    ")\n",
    "\n",
    "user_id_lookup = tf.keras.layers.StringLookup(\n",
    "    max_tokens=len(vocab_dict['user_id']) + NUM_OOV_BUCKETS,\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    mask_token=None,\n",
    "    vocabulary=vocab_dict['user_id'],\n",
    ")(user_id_input_layer)\n",
    "\n",
    "user_id_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['user_id']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=USER_EMBEDDING_SIZE\n",
    ")(user_id_lookup)\n",
    "\n",
    "user_id_embedding = tf.reduce_sum(user_id_embedding, axis=-2)\n",
    "\n",
    "global_inputs.append(user_id_input_layer)\n",
    "global_features.append(user_id_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fc35cb28-f07c-460d-80a1-cdc8a3b49890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 1) dtype=string (created by layer 'user_id')>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "124ba364-0668-44e3-aa44-c6234e38fbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 4) dtype=float32 (created by layer 'tf.math.reduce_sum_6')>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "89cba3b5-bca1-4208-9889-b5cf20c84485",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_age_input_layer = tf.keras.Input(\n",
    "    name=\"bucketized_user_age\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "user_age_lookup = tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=vocab_dict['bucketized_user_age'],\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    oov_value=0,\n",
    ")(user_age_input_layer)\n",
    "\n",
    "user_age_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['bucketized_user_age']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=USER_EMBEDDING_SIZE\n",
    ")(user_age_lookup)\n",
    "\n",
    "user_age_embedding = tf.reduce_sum(user_age_embedding, axis=-2)\n",
    "\n",
    "global_inputs.append(user_age_input_layer)\n",
    "global_features.append(user_age_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "595a6077-9592-4240-a439-8b79efba2698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 1) dtype=string (created by layer 'user_id')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'bucketized_user_age')>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1784b018-6c0e-48ba-904d-57bf31e4c523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 4) dtype=float32 (created by layer 'tf.math.reduce_sum_6')>,\n",
       " <KerasTensor: shape=(None, 4) dtype=float32 (created by layer 'tf.math.reduce_sum_7')>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9e0eb42b-cf39-4c4f-a783-52fbcbd4c34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_occ_input_layer = tf.keras.Input(\n",
    "    name=\"user_occupation_text\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.string\n",
    ")\n",
    "\n",
    "user_occ_lookup = tf.keras.layers.StringLookup(\n",
    "    max_tokens=len(vocab_dict['user_occupation_text']) + NUM_OOV_BUCKETS,\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    mask_token=None,\n",
    "    vocabulary=vocab_dict['user_occupation_text'],\n",
    ")(user_occ_input_layer)\n",
    "\n",
    "user_occ_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['user_occupation_text']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=USER_EMBEDDING_SIZE\n",
    ")(user_occ_lookup)\n",
    "\n",
    "user_occ_embedding = tf.reduce_sum(user_occ_embedding, axis=-2)\n",
    "\n",
    "global_inputs.append(user_occ_input_layer)\n",
    "global_features.append(user_occ_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "94de8185-6acd-403f-b71d-e2416e23461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ts_input_layer = tf.keras.Input(\n",
    "    name=\"timestamp\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.int64\n",
    ")\n",
    "\n",
    "user_ts_lookup = tf.keras.layers.Discretization(\n",
    "    vocab_dict['timestamp_buckets'].tolist()\n",
    ")(user_ts_input_layer)\n",
    "\n",
    "user_ts_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['timestamp_buckets'].tolist()) + NUM_OOV_BUCKETS,\n",
    "    output_dim=USER_EMBEDDING_SIZE\n",
    ")(user_ts_lookup)\n",
    "\n",
    "user_ts_embedding = tf.reduce_sum(user_ts_embedding, axis=-2)\n",
    "\n",
    "global_inputs.append(user_ts_input_layer)\n",
    "global_features.append(user_ts_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bcfb03-a091-48f6-a9d3-94626c518f06",
   "metadata": {},
   "source": [
    "### concat global (user) features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0fd60e48-80c4-4e83-95cc-4124cdcbc9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 16) dtype=float32 (created by layer 'concatenate_2')>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_outputs = tf.keras.layers.concatenate(global_features, axis=-1)\n",
    "global_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "15b87c0b-9dab-4ee7-a721-7254ec4a1839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.functional.Functional at 0x7fe29851fd60>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_preprocess_layers = tf.keras.Model(inputs=global_inputs, outputs=global_outputs)\n",
    "global_preprocess_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f85d0b-75e9-40fa-9637-25cec28cd87b",
   "metadata": {},
   "source": [
    "## arm features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4649477d-7fad-4e4c-9b58-1454bbe7658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MV_EMBEDDING_SIZE = 8 #32\n",
    "\n",
    "arm_inputs = []\n",
    "arm_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ca46d2e1-dcb3-4953-8b54-61d82915f096",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_id_input_layer = tf.keras.Input(\n",
    "    name=\"movie_id\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.string\n",
    ")\n",
    "\n",
    "mv_id_lookup = tf.keras.layers.StringLookup(\n",
    "    max_tokens=len(vocab_dict['movie_id']) + NUM_OOV_BUCKETS,\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    mask_token=None,\n",
    "    vocabulary=vocab_dict['movie_id'],\n",
    ")(mv_id_input_layer)\n",
    "\n",
    "mv_id_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['movie_id']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=USER_EMBEDDING_SIZE\n",
    ")(mv_id_lookup)\n",
    "\n",
    "mv_id_embedding = tf.reduce_sum(mv_id_embedding, axis=-2)\n",
    "\n",
    "arm_inputs.append(mv_id_input_layer)\n",
    "arm_features.append(mv_id_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cf92f9d5-bf49-4997-b02b-1aba7e05ec46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 1) dtype=string (created by layer 'movie_id')>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arm_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6a86ac77-b872-467b-a099-32227a2c61e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 4) dtype=float32 (created by layer 'tf.math.reduce_sum_10')>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arm_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a71b2aff-ffd4-42e1-b147-d3bb57a179b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_genre_input_layer = tf.keras.Input(\n",
    "    name=\"movie_genres\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "mv_genre_lookup = tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=vocab_dict['movie_genres'],\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    oov_value=0,\n",
    ")(mv_genre_input_layer)\n",
    "\n",
    "mv_genre_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['movie_genres']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=USER_EMBEDDING_SIZE\n",
    ")(mv_genre_lookup)\n",
    "\n",
    "mv_genre_embedding = tf.reduce_sum(mv_genre_embedding, axis=-2)\n",
    "\n",
    "arm_inputs.append(mv_genre_input_layer)\n",
    "arm_features.append(mv_genre_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b896f82e-3f37-43f0-b272-3502d976f685",
   "metadata": {},
   "source": [
    "### concat arm (movie) features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "463ed548-32ec-49f7-a98e-975cbe487a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 8) dtype=float32 (created by layer 'concatenate_3')>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arm_outputs = tf.keras.layers.concatenate(arm_features, axis=-1)\n",
    "arm_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "82394bb9-96e1-4d3d-9a1d-94b8d18ac7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.functional.Functional at 0x7fe2985472e0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arm_preprocess_layers = tf.keras.Model(inputs=arm_inputs, outputs=arm_outputs)\n",
    "arm_preprocess_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52232a1-9caa-4a9e-963d-60a26a4b97e8",
   "metadata": {},
   "source": [
    "# Create TF-Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f6428ab4-913f-4ab5-84d3-1b91a51f8fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL_DIM = XXX\n",
    "NUM_MVS_TO_RANK = 1\n",
    "NUM_USER_PER_STEP = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ea1d3ed0-9bc4-4b1d-a586-c348175aa490",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent\n",
    "from tf_agents.bandits.agents import neural_linucb_agent\n",
    "\n",
    "class NeuralEpsilonGreedyAgentNoFn(\n",
    "    neural_epsilon_greedy_agent.NeuralEpsilonGreedyAgent\n",
    "):\n",
    "    _enable_functions = False\n",
    "\n",
    "class NeuralLinUCBAgentNoFn(\n",
    "    neural_linucb_agent.NeuralLinUCBAgent\n",
    "):\n",
    "    _enable_functions = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8914b4-a059-49fa-8341-15a34bbd0fa4",
   "metadata": {},
   "source": [
    "## observation and action specs\n",
    "\n",
    "> The `observation_spec`` and the action_spec` methods return a nest of `(Bounded)ArraySpecs` that describe the `name`, `shape`, `datatype` and ranges of the observations and actions respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead035fc-4c85-4623-a912-0845cb0ee9c9",
   "metadata": {},
   "source": [
    "### observation spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d70e7b34-5a9b-4138-b1bd-cdb26ad4e697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': {'user_id': TensorSpec(shape=(1,), dtype=tf.string, name=None),\n",
       "  'bucketized_user_age': TensorSpec(shape=(1,), dtype=tf.float32, name=None),\n",
       "  'user_occupation_text': TensorSpec(shape=(1,), dtype=tf.string, name=None),\n",
       "  'timestamp': TensorSpec(shape=(1,), dtype=tf.int64, name=None)},\n",
       " 'per_arm': {'movie_id': TensorSpec(shape=(1,), dtype=tf.string, name=None),\n",
       "  'movie_genres': TensorSpec(shape=(1,), dtype=tf.int64, name=None)}}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.specs import tensor_spec\n",
    "\n",
    "obs_spec = {\n",
    "    bandit_spec_utils.GLOBAL_FEATURE_KEY: {\n",
    "        'user_id' : tensor_spec.TensorSpec(\n",
    "            shape=(NUM_USER_PER_STEP,), dtype=tf.string\n",
    "        ),\n",
    "        'bucketized_user_age' : tensor_spec.TensorSpec(\n",
    "            shape=(NUM_USER_PER_STEP,), dtype=tf.float32\n",
    "        ),\n",
    "        'user_occupation_text' : tensor_spec.TensorSpec(\n",
    "            shape=(NUM_USER_PER_STEP,), dtype=tf.string\n",
    "        ),\n",
    "        'timestamp' : tensor_spec.TensorSpec(\n",
    "            shape=(NUM_USER_PER_STEP,), dtype=tf.int64\n",
    "        ),\n",
    "    },\n",
    "    bandit_spec_utils.PER_ARM_FEATURE_KEY: {\n",
    "        'movie_id': tensor_spec.TensorSpec(\n",
    "            shape=(NUM_MVS_TO_RANK,), dtype=tf.string),\n",
    "        'movie_genres': tensor_spec.TensorSpec(\n",
    "              shape=(NUM_MVS_TO_RANK,), dtype=tf.int64),\n",
    "    }\n",
    "}\n",
    "\n",
    "obs_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8eadb2fe-0cfe-4e6b-8dc1-4a79f93434aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'global': {'bucketized_user_age': TensorSpec(shape=(1,), dtype=tf.float32, name=None),\n",
       "                            'timestamp': TensorSpec(shape=(1,), dtype=tf.int64, name=None),\n",
       "                            'user_id': TensorSpec(shape=(1,), dtype=tf.string, name=None),\n",
       "                            'user_occupation_text': TensorSpec(shape=(1,), dtype=tf.string, name=None)},\n",
       "                 'per_arm': {'movie_genres': TensorSpec(shape=(1,), dtype=tf.int64, name=None),\n",
       "                             'movie_id': TensorSpec(shape=(1,), dtype=tf.string, name=None)}},\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.trajectories import time_step\n",
    "\n",
    "time_step_spec = time_step.time_step_spec(obs_spec)\n",
    "time_step_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8cf9cf-c747-4f8b-9e90-1380fd87a477",
   "metadata": {},
   "source": [
    "### action spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fa7605b0-4134-4f08-8a0b-d24267398b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=(),\n",
    "    dtype=tf.int32,\n",
    "    minimum=0,\n",
    "    maximum=NUM_MVS_TO_RANK, # - 1,\n",
    "    name='action'\n",
    ")\n",
    "action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "888e03eb-0c5e-4254-84b1-08b5b0c68445",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.05\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8b1c46-f8c7-4eda-b8e7-f8e3dbb76259",
   "metadata": {},
   "source": [
    "## create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0968be3b-60bf-4a71-b137-70a1df839f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE = \"neural_ucb\"      # \"neural_ucb\" | \"neural_epsilon_greedy\"\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# layers\n",
    "GLOBAL_LAYERS = [16,4]\n",
    "ARM_LAYERS = [16,4]\n",
    "COMMON_LAYERS = [4]\n",
    "\n",
    "# encoding network\n",
    "ENCODING_DIM = 5\n",
    "# How many training steps to run for training the encoding network before\n",
    "# switching to LinUCB\n",
    "NETWORK_TRAIN_STEPS = 20\n",
    "\n",
    "# A float representing the probability of choosing a random action \n",
    "# instead of the greedy action\n",
    "EPSILON_GREEDY = 0.02\n",
    "\n",
    "# ==============================\n",
    "# HPARAMS for neural_ucb_model\n",
    "# ==============================\n",
    "\n",
    "# Exploration parameter that multiplies the confidence intervals\n",
    "EXPLORE_ALPHA = 0.1\n",
    "# A float forgetting factor in [0.0, 1.0]. When set to 1, the algorithm\n",
    "# doesn't forget.\n",
    "FORGETTING_FACTOR = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "71037c95-e4a8-4b15-b8c5-0a24724accc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.bandits.networks.global_and_arm_feature_network.GlobalAndArmCommonTowerNetwork at 0x7fe29857e800>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "\n",
    "if MODEL_TYPE == 'neural_epsilon_greedy':\n",
    "    network = global_and_arm_feature_network.create_feed_forward_common_tower_network(\n",
    "        observation_spec=obs_spec,\n",
    "        global_layers=GLOBAL_LAYERS,\n",
    "        arm_layers=ARM_LAYERS,\n",
    "        common_layers=COMMON_LAYERS,\n",
    "        global_preprocessing_combiner=global_preprocess_layers,\n",
    "        arm_preprocessing_combiner=arm_preprocess_layers,\n",
    "        output_dim=1\n",
    "    )\n",
    "elif MODEL_TYPE == 'neural_ucb':\n",
    "    network = global_and_arm_feature_network.create_feed_forward_common_tower_network(\n",
    "        observation_spec=obs_spec,\n",
    "        global_layers=GLOBAL_LAYERS,\n",
    "        arm_layers=ARM_LAYERS,\n",
    "        common_layers=COMMON_LAYERS,\n",
    "        global_preprocessing_combiner=global_preprocess_layers,\n",
    "        arm_preprocessing_combiner=arm_preprocess_layers,\n",
    "        output_dim=ENCODING_DIM\n",
    "    )\n",
    "    \n",
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "54d08c59-62a6-4ba2-b64d-33dae862ad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.bandits.policies import policy_utilities\n",
    "\n",
    "def _agent_fn(\n",
    "    time_step_spec, \n",
    "    action_spec, \n",
    "    network,\n",
    "    optimizer,\n",
    "    model_type\n",
    "):\n",
    "    if model_type == \"neural_epsilon_greedy\":\n",
    "        agent = NeuralEpsilonGreedyAgentNoFn(\n",
    "            time_step_spec=time_step_spec,\n",
    "            action_spec=action_spec,\n",
    "            reward_network=network,\n",
    "            optimizer=optimizer,\n",
    "            epsilon=EPSILON_GREEDY,\n",
    "            accepts_per_arm_features=True,\n",
    "            emit_policy_info=(policy_utilities.InfoFields.PREDICTED_REWARDS_MEAN),\n",
    "            error_loss_fn=tf.compat.v1.losses.mean_squared_error,\n",
    "            gradient_clipping=None,\n",
    "            debug_summaries=True,\n",
    "            summarize_grads_and_vars=True,\n",
    "            name='NeuralEpsilonGreedyAgent'\n",
    "        )\n",
    "    elif model_type == 'neural_ucb':\n",
    "        agent = NeuralLinUCBAgentNoFn(\n",
    "            time_step_spec=time_step_spec,\n",
    "            action_spec=action_spec,\n",
    "            encoding_network=network,\n",
    "            encoding_network_num_train_steps=NETWORK_TRAIN_STEPS,\n",
    "            encoding_dim=ENCODING_DIM,\n",
    "            optimizer=optimizer,\n",
    "            alpha=EXPLORE_ALPHA,\n",
    "            gamma=FORGETTING_FACTOR,\n",
    "            epsilon_greedy=EPSILON_GREEDY,\n",
    "            accepts_per_arm_features=True,\n",
    "            emit_policy_info=(\n",
    "                policy_utilities.InfoFields.PREDICTED_REWARDS_MEAN,\n",
    "                policy_utilities.InfoFields.PREDICTED_REWARDS_OPTIMISTIC\n",
    "            ),\n",
    "            error_loss_fn=tf.compat.v1.losses.mean_squared_error,\n",
    "            gradient_clipping=None,\n",
    "            debug_summaries=True,\n",
    "            summarize_grads_and_vars=True,\n",
    "            name='NeuralLinUCBAgent'\n",
    "        )\n",
    "        \n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ebc0b731-507a-4d96-b8cd-c4fdef3bb35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.NeuralLinUCBAgentNoFn at 0x7fe2985f0370>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_agent_fn(\n",
    "    time_step_spec=time_step_spec,\n",
    "    action_spec=action_spec, \n",
    "    network=network,\n",
    "    optimizer=optimizer,\n",
    "    model_type=MODEL_TYPE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e7b26c-146d-4a60-9ca8-50ad32f3a7ee",
   "metadata": {},
   "source": [
    "## get rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4e8f50c7-c54c-473c-9e9f-b548f8d49a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_rewards(element):\n",
    "    \"\"\"Calculates reward for the actions.\"\"\"\n",
    "\n",
    "    def _calc_reward(x):\n",
    "        \"\"\"Calculates reward for a single action.\"\"\"\n",
    "        r0 = lambda: tf.constant(0.0)\n",
    "        r1 = lambda: tf.constant(-10.0)\n",
    "        r2 = lambda: tf.constant(2.0)\n",
    "        r3 = lambda: tf.constant(3.0)\n",
    "        r4 = lambda: tf.constant(4.0)\n",
    "        r5 = lambda: tf.constant(10.0)\n",
    "        c1 = tf.equal(x, 1.0)\n",
    "        c2 = tf.equal(x, 2.0)\n",
    "        c3 = tf.equal(x, 3.0)\n",
    "        c4 = tf.equal(x, 4.0)\n",
    "        c5 = tf.equal(x, 5.0)\n",
    "        return tf.case([(c1, r1), (c2, r2), (c3, r3),(c4, r4),(c5, r5)], default=r0, exclusive=True)\n",
    "\n",
    "    return tf.map_fn(\n",
    "        fn=_calc_reward, \n",
    "        elems=element['user_rating'], \n",
    "        dtype=tf.float32\n",
    "    )\n",
    "\n",
    "def _add_outer_dimension(x):\n",
    "    \"\"\"Adds an extra outer dimension.\"\"\"\n",
    "    if isinstance(x, dict):\n",
    "        for key, value in x.items():\n",
    "            x[key] = tf.expand_dims(value, 1)\n",
    "        return x\n",
    "    return tf.expand_dims(x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0aa30407-4e10-4e95-98ab-589e047a1d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_global_feature_list(input_features):\n",
    "    \"\"\"Return list of global features.\"\"\"\n",
    "    global_feature_names = [\n",
    "        'user_id', 'bucketized_user_age', 'user_occupation_text', 'timestamp'\n",
    "    ]\n",
    "    \n",
    "    global_features = []\n",
    "    \n",
    "    for global_feature in global_feature_names:\n",
    "        if global_feature in input_features:\n",
    "            global_features.append(input_features[global_feature])\n",
    "\n",
    "    return global_features\n",
    "\n",
    "def _get_global_feature_dict(input_features):\n",
    "    \"\"\"Returns a dictionary mapping feature key to per arm features.\"\"\"\n",
    "    global_feature_names = [\n",
    "        'user_id', 'bucketized_user_age', 'user_occupation_text', 'timestamp'\n",
    "    ]\n",
    "    \n",
    "    global_features = {}\n",
    "    \n",
    "    for global_feature_name in global_feature_names:\n",
    "        if global_feature_name in input_features:\n",
    "            global_features[global_feature_name] = input_features[global_feature_name]\n",
    "    \n",
    "    return global_features\n",
    "\n",
    "def _get_per_arm_feature_dict(input_features):\n",
    "    \"\"\"Returns a dictionary mapping feature key to per arm features.\"\"\"\n",
    "    per_arm_feature_names = ['movie_id', 'movie_genres']\n",
    "    \n",
    "    arm_features = {}\n",
    "    \n",
    "    for per_arm_feature in per_arm_feature_names:\n",
    "        if per_arm_feature in input_features:\n",
    "            arm_features[per_arm_feature] = input_features[per_arm_feature]\n",
    "    \n",
    "    return arm_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ba249f11-684a-4105-a5e3-cddb0249ea9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id': <tf.Tensor: shape=(1, 1), dtype=string, numpy=array([[b'346']], dtype=object)>, 'bucketized_user_age': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[25.]], dtype=float32)>, 'user_occupation_text': <tf.Tensor: shape=(1, 1), dtype=string, numpy=array([[b'other']], dtype=object)>, 'timestamp': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[874948475]])>}\n",
      "{'movie_id': <tf.Tensor: shape=(1, 1), dtype=string, numpy=array([[b'211']], dtype=object)>, 'movie_genres': <tf.Tensor: shape=(1, 1, 1), dtype=int64, numpy=array([[[4]]])>}\n"
     ]
    }
   ],
   "source": [
    "# test \n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    global_features = _get_global_feature_dict(x)\n",
    "    arm_features = _get_per_arm_feature_dict(x)\n",
    "    \n",
    "    #\n",
    "    global_features = _add_outer_dimension(global_features)\n",
    "    arm_features = _add_outer_dimension(arm_features)\n",
    "    \n",
    "print(global_features)\n",
    "print(arm_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e0a5e76e-30c4-43e2-9e8c-a741875b942f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': <tf.Tensor: shape=(1, 1), dtype=string, numpy=array([[b'346']], dtype=object)>,\n",
       " 'bucketized_user_age': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[25.]], dtype=float32)>,\n",
       " 'user_occupation_text': <tf.Tensor: shape=(1, 1), dtype=string, numpy=array([[b'other']], dtype=object)>,\n",
       " 'timestamp': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[874948475]])>}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "234ea911-c224-4c16-ac10-97aa62218a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': <tf.Tensor: shape=(1, 1, 1), dtype=string, numpy=array([[[b'346']]], dtype=object)>,\n",
       " 'bucketized_user_age': <tf.Tensor: shape=(1, 1, 1), dtype=float32, numpy=array([[[25.]]], dtype=float32)>,\n",
       " 'user_occupation_text': <tf.Tensor: shape=(1, 1, 1), dtype=string, numpy=array([[[b'other']]], dtype=object)>,\n",
       " 'timestamp': <tf.Tensor: shape=(1, 1, 1), dtype=int64, numpy=array([[[874948475]]])>}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_add_outer_dimension(global_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f70c79af-50ac-41fd-b416-b3587d018fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie_id': <tf.Tensor: shape=(1, 1), dtype=string, numpy=array([[b'211']], dtype=object)>,\n",
       " 'movie_genres': <tf.Tensor: shape=(1, 1, 1), dtype=int64, numpy=array([[[4]]])>}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adds a time dimension.\n",
    "arm_features = _add_outer_dimension(arm_features)\n",
    "arm_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7e1cccc2-2aca-42fc-9572-62f490fd06b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _trajectory_fn(element):\n",
    "    \"\"\"\n",
    "    Converts a dataset element into a trajectory.\n",
    "    \"\"\"\n",
    "    # global_features = _get_global_feature_list(element)\n",
    "    global_features = _get_global_feature_dict(element)\n",
    "    arm_features = _get_per_arm_feature_dict(element)\n",
    "    # global_features = ['user_id', 'bucketized_user_age', 'user_occupation_text', 'timestamp']\n",
    "    # arm_features = {'movie_id':'movie_id', 'movie_genres':'movie_genres'}\n",
    "    \n",
    "    # tmp\n",
    "    print(f\"global_features: {global_features}\")\n",
    "    \n",
    "    # Adds a time dimension.\n",
    "    arm_features = _add_outer_dimension(arm_features)\n",
    "    # tmp\n",
    "    print(f\"arm_features: {arm_features}\")\n",
    "    \n",
    "    observation = {\n",
    "        bandit_spec_utils.GLOBAL_FEATURE_KEY:\n",
    "            _add_outer_dimension(tf.concat(global_features, axis=1))\n",
    "            # _add_outer_dimension(global_features, axis=1)\n",
    "    }\n",
    "    \n",
    "    reward = _add_outer_dimension(_get_rewards(element))\n",
    "    \n",
    "    # To emit the predicted rewards in policy_info, we need to create dummy\n",
    "    # rewards to match the definition in TensorSpec for the ones specified in\n",
    "    # emit_policy_info set.\n",
    "    dummy_rewards = tf.zeros([BATCH_SIZE, 1, NUM_MVS_TO_RANK])\n",
    "    \n",
    "    policy_info = policy_utilities.PerArmPolicyInfo(\n",
    "        chosen_arm_features=arm_features,\n",
    "        # Pass dummy mean rewards here to match the model_spec for emitting\n",
    "        # mean rewards in policy info\n",
    "        predicted_rewards_mean=dummy_rewards\n",
    "    )\n",
    "    if MODEL_TYPE == 'neural_ucb':\n",
    "        policy_info = policy_info._replace(\n",
    "            predicted_rewards_optimistic=dummy_rewards\n",
    "        )\n",
    "    return trajectory.single_step(\n",
    "        observation=observation,\n",
    "        action=tf.zeros_like(\n",
    "            reward, dtype=tf.int32\n",
    "        ),  # Arm features are copied from policy info, put dummy zeros here\n",
    "        policy_info=policy_info,\n",
    "        reward=reward,\n",
    "        discount=tf.zeros_like(reward)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "94079fcd-9fcf-489a-9b35-a43b376b3e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_features: {'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'346'], dtype=object)>, 'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([25.], dtype=float32)>, 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'other'], dtype=object)>, 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([874948475])>}\n",
      "arm_features: {'movie_id': <tf.Tensor: shape=(1, 1), dtype=string, numpy=array([[b'211']], dtype=object)>, 'movie_genres': <tf.Tensor: shape=(1, 1, 1), dtype=int64, numpy=array([[[4]]])>}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value ({'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'346'], dtype=object)>, 'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([25.], dtype=float32)>, 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'other'], dtype=object)>, 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([874948475])>}) with an unsupported type (<class 'dict'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[119], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m train_dataset\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43m_trajectory_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[118], line 21\u001b[0m, in \u001b[0;36m_trajectory_fn\u001b[0;34m(element)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# tmp\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marm_features: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marm_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m observation \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     20\u001b[0m     bandit_spec_utils\u001b[38;5;241m.\u001b[39mGLOBAL_FEATURE_KEY:\n\u001b[0;32m---> 21\u001b[0m         _add_outer_dimension(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mglobal_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;66;03m# _add_outer_dimension(global_features, axis=1)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m }\n\u001b[1;32m     25\u001b[0m reward \u001b[38;5;241m=\u001b[39m _add_outer_dimension(_get_rewards(element))\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# To emit the predicted rewards in policy_info, we need to create dummy\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# rewards to match the definition in TensorSpec for the ones specified in\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# emit_policy_info set.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:98\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m     97\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value ({'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'346'], dtype=object)>, 'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([25.], dtype=float32)>, 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'other'], dtype=object)>, 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([874948475])>}) with an unsupported type (<class 'dict'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(_trajectory_fn(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b58638-bd29-4d4a-a9e9-9d5424ef6b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.expand_dims(x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb91272-d9c3-4c7b-8730-ac5dd93f9e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _serving_input_fn(input_features):\n",
    "    \"\"\"\n",
    "    Converts input features into Timestep for serving.\n",
    "    \"\"\"\n",
    "    global_features = _get_global_feature_list(input_features)\n",
    "    arm_features = _get_per_arm_feature_dict(input_features)\n",
    "\n",
    "    observation = {\n",
    "        bandit_spec_utils.GLOBAL_FEATURE_KEY: tf.concat(global_features, axis=1),\n",
    "        # Adds an num_action dimension.\n",
    "        bandit_spec_utils.PER_ARM_FEATURE_KEY: _add_outer_dimension(arm_features)\n",
    "    }\n",
    "    batch_size = tf.reshape(\n",
    "        tf.shape(observation[bandit_spec_utils.GLOBAL_FEATURE_KEY])[0], [1])\n",
    "    \n",
    "    return time_step.restart(observation=observation, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "13b71808-90b7-4288-8b8c-a40fc4b2e242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bucketized_user_age': <tf.Tensor: shape=(), dtype=float32, numpy=25.0>,\n",
       " 'movie_genres': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([4])>,\n",
       " 'movie_id': <tf.Tensor: shape=(), dtype=string, numpy=b'211'>,\n",
       " 'timestamp': <tf.Tensor: shape=(), dtype=int64, numpy=874948475>,\n",
       " 'user_id': <tf.Tensor: shape=(), dtype=string, numpy=b'346'>,\n",
       " 'user_occupation_text': <tf.Tensor: shape=(), dtype=string, numpy=b'other'>,\n",
       " 'user_rating': <tf.Tensor: shape=(), dtype=float32, numpy=4.0>}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rb_iterator = iter(train_dataset)\n",
    "next(rb_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dc53b5-8f20-437a-aad3-83922f80b55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.train import learner\n",
    "from tf_agents.train.utils import strategy_utils\n",
    "from tf_agents.policies import policy_saver\n",
    "\n",
    "def create_run_fn(agent_fn, trajectory_fn, serving_input_fn, dataset, artifact_dir):\n",
    "    \"\"\"\n",
    "    Creates the run_fn passed to tensorflow_trainer.\n",
    "\n",
    "    Args:\n",
    "      agent_fn: Function to create a TF.Agent.\n",
    "      trajectory_fn: Function to convert input data into Trajectory.\n",
    "      serving_input_fn: Function to convert input data into Timestep.\n",
    "      model_hparams: An `HParams` object, holds hyperparameters to build and train\n",
    "        the model.\n",
    "\n",
    "    Returns:\n",
    "      A function that can be run by the tensorflow_trainer.\n",
    "    \"\"\"\n",
    "\n",
    "    def _run_fn(trainer_inputs):\n",
    "        \"\"\"Run_fn passed to the tensorflow_trainer.\n",
    "\n",
    "        Args:\n",
    "          trainer_inputs: A `TensorflowTrainerInputs` object.\n",
    "        \"\"\"\n",
    "        policy_save_interval = 5000\n",
    "        \n",
    "        tf_transform_output = trainer_util.TFTransformOutput(\n",
    "            trainer_inputs.transform_dir\n",
    "        )\n",
    "        # hparams = tf1.training.merge_hparam(model_hparams, trainer_inputs.hparams)\n",
    "\n",
    "        dist_strategy = strategy_utils.get_strategy(tpu=False, use_gpu=True)\n",
    "        with dist_strategy.scope():\n",
    "            summary_writer = tf.summary.create_file_writer(trainer_inputs.working_dir)\n",
    "            with summary_writer.as_default():\n",
    "                train_step = train_utils.create_train_step()\n",
    "                \n",
    "                model = agent_fn(\n",
    "                    time_step_spec=time_step_spec,\n",
    "                    action_spec=action_spec, \n",
    "                    network=network,\n",
    "                    optimizer=optimizer,\n",
    "                    model_type=MODEL_TYPE\n",
    "                )\n",
    "                # replay_buffer = dwrb.DatasetWrappingReplayBuffer(\n",
    "                #     data_spec=model.training_data_spec,\n",
    "                #     capacity=1,\n",
    "                #     buffer_mode=mode.SERVER_CLIENT,\n",
    "                #     dataset_fn=_create_dataset_fn(\n",
    "                #         trainer_inputs.examples_input, [TRAIN_EXAMPLE_SPLIT],\n",
    "                #         tf_transform_output,\n",
    "                #         functools.partial(trajectory_fn, hparams=hparams),\n",
    "                #         randomize_input=False\n",
    "                #     )\n",
    "                # )\n",
    "                # rb_iterator = iter(train_dataset)\n",
    "                # next(rb_iterator)\n",
    "                experience_dataset_fn = lambda: dataset\n",
    "                \n",
    "                # checkpointer = common.Checkpointer(\n",
    "                #     ckpt_dir=trainer_inputs.working_dir,\n",
    "                #     agent=model,\n",
    "                # )\n",
    "                \n",
    "#                 policy_learner = off_policy_learner.OffPolicyLearner(\n",
    "#                     agent=model,\n",
    "#                     replay_buffer=rb_iterator,\n",
    "#                     sample_batch_size=BATCH_SIZE,\n",
    "#                     strategy=dist_strategy,\n",
    "#                     summary_writers=[summary_writer],\n",
    "#                     train_checkpointer=checkpointer,\n",
    "#                     train_checkpoint_steps_frequency=CHECKPOINT_FREQUENCY,\n",
    "#                     policy_checkpointer=checkpointer,\n",
    "#                     policy_checkpoint_steps_frequency=CHECKPOINT_FREQUENCY,\n",
    "#                 )\n",
    "#                 policy_learner.launch(hparams.train_steps)\n",
    "\n",
    "                # Triggers to save the agent's policy checkpoints.\n",
    "    \n",
    "                saved_model_dir = f\"{artifact_dir}/saved_model\"\n",
    "                learning_triggers = [\n",
    "                    triggers.PolicySavedModelTrigger(\n",
    "                        saved_model_dir,\n",
    "                        model,\n",
    "                        train_step,\n",
    "                        interval=policy_save_interval),\n",
    "                    triggers.StepPerSecondLogTrigger(train_step, interval=1000),\n",
    "                ]\n",
    "                agent_learner = learner.Learner(\n",
    "                    root_dir = tempdir,\n",
    "                    train_step = train_step,\n",
    "                    agent=model,\n",
    "                    experience_dataset_fn = experience_dataset_fn,\n",
    "                    triggers=learning_triggers,\n",
    "                    strategy=dist_strategy\n",
    "                )\n",
    "    \n",
    "                # if trainer_inputs.tf_job.is_chief:\n",
    "                logging.info('Exporting trained policy.')\n",
    "                saver = policy_saver.PolicySaver(\n",
    "                    policy=model.policy,\n",
    "                    train_step=model.train_step_counter,\n",
    "                    # input_fn_and_spec=_create_serving_input_fn_and_spec(\n",
    "                    #     tf_transform_output, serving_input_fn, model)\n",
    "                )\n",
    "                # for key in trainer_inputs.export_dir_by_format.keys():\n",
    "                #     saver.save(trainer_inputs.export_dir_by_format[key])\n",
    "\n",
    "    return _run_fn\n",
    "\n",
    "Options = tensorflow_trainer_inputs.Options\n",
    "\n",
    "\n",
    "def run_tensorflow_trainer(\n",
    "    run_fn: Callable[\n",
    "        [tensorflow_trainer_inputs.TensorflowTrainerInputs], None],\n",
    "    options: Optional[Options] = None\n",
    ") -> None:\n",
    "    \n",
    "    options = options or Options()\n",
    "    _run_tensorflow_trainer_internal(run_fn, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caca760d-9a17-4526-94a0-88e7cd245f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "EXPERIMENT_NAME   = f'custom-neural-bandits-v3'\n",
    "\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "LOG_DIR           = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}/tb-logs\"\n",
    "ROOT_DIR          = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c595382-a236-4afc-9f6b-be47155c9455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_run_fn():\n",
    "    return trainer_common.create_run_fn(\n",
    "        agent_fn = _agent_fn, \n",
    "        trajectory_fn = _trajectory_fn, \n",
    "        serving_input_fn = _serving_input_fn,\n",
    "        dataset = train_datset,\n",
    "        artifact_dir = ARTIFACTS_DIR\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde15eb4-7a61-4093-a899-1b778c74eb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_run_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b575b035-2bba-425f-b9c8-2e5a2b1ddf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main(unused_argv):\n",
    "#   tensorflow_trainer.run_tensorflow_trainer(create_run_fn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35968c12-604c-45d4-9c3f-a81a260e93ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
