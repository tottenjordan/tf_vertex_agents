{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e4e2cbd-33b0-47e0-b1c0-596921415742",
   "metadata": {},
   "source": [
    "# Environment Setup for training TF-Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9497e0-2c91-4375-95af-95087d3021e2",
   "metadata": {},
   "source": [
    "## Install Packages\n",
    "Run `pip requirements.txt` in either (1) the notebook cell below or (2) in a notebook terminal window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4610a9-d160-47f5-a141-9aada673f2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e85584-fff1-4a46-931c-ee86faec08f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Vertex AI Workbench Notebook product has specific requirements\n",
    "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\")\n",
    "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
    "    \"/opt/deeplearning/metadata/env_version\"\n",
    ")\n",
    "\n",
    "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_WORKBENCH_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\"\n",
    "\n",
    "# !pip install --no-cache-dir -r ./requirements.txt --user -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92cae7b-f56a-46ce-ad60-4a1d4a59e090",
   "metadata": {},
   "source": [
    "## Set vars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3517a97d-7f98-442e-ae40-54f09a029302",
   "metadata": {},
   "source": [
    "#### CREATE_NEW_ASSETS\n",
    "\n",
    "* `True` creates new GCS buckets and BQ tables, etc.\n",
    "* `False` skips these steps (in case you need to re-run notebook to include new variables you create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248a7dfa-2a55-4483-bf9b-dbd6ee394228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new BQ datasets, tables, etc.?\n",
    "CREATE_NEW_ASSETS         = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23489b2a-cec0-4ce6-9e25-6aa3c5815bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# naming convention for all cloud resources\n",
    "VERSION        = \"v2\"              # TODO\n",
    "PREFIX         = f'rec-bandits-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX = {PREFIX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ffbf4b-e0f7-46b3-adc2-7eb6bf67dec3",
   "metadata": {},
   "source": [
    "### GCP project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feb8bda-6180-4464-8548-3c63cc6f66f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creds, PROJECT_ID = google.auth.default()\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "PROJECT_NUM              = !gcloud projects describe $PROJECT_ID --format=\"value(projectNumber)\"\n",
    "PROJECT_NUM              = PROJECT_NUM[0]\n",
    "\n",
    "VERTEX_SA                = f'{PROJECT_NUM}-compute@developer.gserviceaccount.com'\n",
    "\n",
    "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
    "\n",
    "# locations / regions for cloud resources\n",
    "LOCATION                 = 'us-central1'        \n",
    "REGION                   = LOCATION\n",
    "BQ_LOCATION              = 'US'\n",
    "\n",
    "print(f\"PROJECT_ID            = {PROJECT_ID}\")\n",
    "print(f\"PROJECT_NUM           = {PROJECT_NUM}\")\n",
    "print(f\"VPC_NETWORK_NAME      = {VPC_NETWORK_NAME}\")\n",
    "print(f\"LOCATION              = {LOCATION}\")\n",
    "print(f\"REGION                = {REGION}\")\n",
    "print(f\"BQ_LOCATION           = {BQ_LOCATION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb38e632-60d9-4d39-911b-545b0a84333f",
   "metadata": {},
   "source": [
    "### Define Cloud Resource Names and Args\n",
    "\n",
    "You shouldn't need to change the variable names below. We are going to save them to a config file we can call across different notebooks and environments; the goal is to ease tracking and managing these many variables across the repo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfce9f45-8e8e-4f06-8ea0-151aee009766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCS bucket and paths\n",
    "BUCKET_NAME                   = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI                    = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "BIGQUERY_DATASET_NAME         = f\"{BUCKET_NAME.lower().replace(PROJECT_ID,'').replace('bucket','').replace('-','_').replace('__','_')}\".rstrip(\"_\")\n",
    "\n",
    "print(f\"BUCKET_NAME           = {BUCKET_NAME}\")\n",
    "print(f\"BUCKET_URI            = {BUCKET_URI}\")\n",
    "print(f\"BIGQUERY_DATASET_NAME = {BIGQUERY_DATASET_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a4850f-ed86-4c07-8efa-a704b3a381ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location to write TF-Records for MovieLens 100K dataset\n",
    "DATA_GCS_PREFIX          = \"data\"\n",
    "DATA_PATH                = f\"{BUCKET_URI}/{DATA_GCS_PREFIX}\"\n",
    "VOCAB_SUBDIR             = \"vocabs\"\n",
    "VOCAB_FILENAME           = 'vocab_dict.pkl'\n",
    "DATA_PATH_KFP_DEMO       = f\"{DATA_PATH}/kfp_demo_data/u.data\"\n",
    "\n",
    "VPC_NETWORK_FULL         = f\"projects/{PROJECT_NUM}/global/networks/{VPC_NETWORK_NAME}\"\n",
    "\n",
    "# BigQuery parameters (used for the Generator, Ingester, Logger)\n",
    "BIGQUERY_DATASET_NAME      = f\"mvlens_{BIGQUERY_DATASET_NAME}\"\n",
    "BIGQUERY_TABLE_NAME        = f\"training_dataset\"\n",
    "\n",
    "# container registry\n",
    "REPOSITORY                = f'rl-movielens-{PREFIX}'\n",
    "\n",
    "# Custom Images - 01-baseline-perarm-bandit\n",
    "DOCKERNAME_01             = \"Dockerfile_train_my_perarm_env\"\n",
    "IMAGE_NAME_01             = f'train-my-perarm-env-{VERSION}'\n",
    "IMAGE_URI_01              = f'gcr.io/{PROJECT_ID}/{IMAGE_NAME_01}'\n",
    "\n",
    "# Custom Images - 02-perarm-features-bandit\n",
    "DOCKERNAME_02             = \"Dockerfile_perarm_feats\"\n",
    "IMAGE_NAME_02             = f'train-perarm-feats-{VERSION}'\n",
    "IMAGE_URI_02              = f'gcr.io/{PROJECT_ID}/{IMAGE_NAME_02}'\n",
    "\n",
    "# Custom Images - 03-ranking\n",
    "DOCKERNAME_03             = \"Dockerfile_ranking_bandit\"\n",
    "IMAGE_NAME_03             = f'train-rank-bandit-{VERSION}'\n",
    "IMAGE_URI_03              = f'gcr.io/{PROJECT_ID}/{IMAGE_NAME_03}'\n",
    "\n",
    "# Custom Images - 04-pipelines\n",
    "DOCKERNAME_04             = \"Dockerfile_train_mab_e2e\"\n",
    "IMAGE_NAME_04             = f'train-mab-e2e-{VERSION}'\n",
    "IMAGE_URI_04              = f'gcr.io/{PROJECT_ID}/{IMAGE_NAME_04}'\n",
    "\n",
    "DOCKERNAME_04_pred        = \"Dockerfile_pred_mab_e2e\"\n",
    "IMAGE_NAME_04_pred        = f'pred-mab-e2e-{VERSION}'\n",
    "IMAGE_URI_04_pred         = f'gcr.io/{PROJECT_ID}/{IMAGE_NAME_04_pred}'\n",
    "\n",
    "# docker (local build)\n",
    "REMOTE_IMAGE_NAME         = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/local_docker_tfa\"\n",
    "\n",
    "print(f\"DATA_GCS_PREFIX      : {DATA_GCS_PREFIX}\")\n",
    "print(f\"DATA_PATH            : {DATA_PATH}\")\n",
    "print(f\"VOCAB_SUBDIR         : {VOCAB_SUBDIR}\")\n",
    "print(f\"VOCAB_FILENAME       : {VOCAB_FILENAME}\")\n",
    "print(f\"DATA_PATH_KFP_DEMO   : {DATA_PATH_KFP_DEMO}\")\n",
    "\n",
    "print(f\"VPC_NETWORK_FULL     : {VPC_NETWORK_FULL}\")\n",
    "\n",
    "print(f\"BIGQUERY_DATASET_NAME: {BIGQUERY_DATASET_NAME}\")\n",
    "print(f\"BIGQUERY_TABLE_NAME  : {BIGQUERY_TABLE_NAME}\")\n",
    "\n",
    "print(f\"REPOSITORY           : {REPOSITORY}\")\n",
    "\n",
    "print(f\"DOCKERNAME_01        : {DOCKERNAME_01}\")\n",
    "print(f\"IMAGE_NAME_01        : {IMAGE_NAME_01}\")\n",
    "print(f\"IMAGE_URI_01         : {IMAGE_URI_01}\")\n",
    "\n",
    "print(f\"DOCKERNAME_02        : {DOCKERNAME_02}\")\n",
    "print(f\"IMAGE_NAME_02        : {IMAGE_NAME_02}\")\n",
    "print(f\"IMAGE_URI_02         : {IMAGE_URI_02}\")\n",
    "\n",
    "print(f\"DOCKERNAME_03        : {DOCKERNAME_03}\")\n",
    "print(f\"IMAGE_NAME_03        : {IMAGE_NAME_03}\")\n",
    "print(f\"IMAGE_URI_03         : {IMAGE_URI_03}\")\n",
    "\n",
    "print(f\"DOCKERNAME_04        : {DOCKERNAME_04}\")\n",
    "print(f\"IMAGE_NAME_04        : {IMAGE_NAME_04}\")\n",
    "print(f\"IMAGE_URI_04         : {IMAGE_URI_04}\")\n",
    "\n",
    "print(f\"DOCKERNAME_04_pred   : {DOCKERNAME_04_pred}\")\n",
    "print(f\"IMAGE_NAME_04_pred   : {IMAGE_NAME_04_pred}\")\n",
    "print(f\"IMAGE_URI_04_pred    : {IMAGE_URI_04_pred}\")\n",
    "\n",
    "print(f\"REMOTE_IMAGE_NAME    : {REMOTE_IMAGE_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e096698e-97e8-4881-b065-a9248de6e2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CREATE_NEW_ASSETS:\n",
    "    # create new bucket\n",
    "    ! gsutil mb -l $REGION $BUCKET_URI\n",
    "    \n",
    "    # give Service account IAM perms\n",
    "    ! gsutil iam ch serviceAccount:{VERTEX_SA}:roles/storage.objects.get $BUCKET_URI\n",
    "    ! gsutil iam ch serviceAccount:{VERTEX_SA}:roles/storage.objects.get $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05194be0-ca5c-4efa-9818-ef9de36ab042",
   "metadata": {},
   "source": [
    "## Repo structure\n",
    "\n",
    "* these variables are used to structure the repo\n",
    "* this means they are required for correctly building Dockerfile's, importing classes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cf09cf-4a01-4b89-aee7-a42b77283f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_DOCKER_PATH_PREFIX          = 'src'\n",
    "RL_SUB_DIR                       = 'per_arm_rl'\n",
    "\n",
    "print(f\"REPO_DOCKER_PATH_PREFIX  : {REPO_DOCKER_PATH_PREFIX}\")\n",
    "print(f\"RL_SUB_DIR               : {RL_SUB_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930d0e7c-4db6-445a-8bbc-af351b3e9782",
   "metadata": {},
   "source": [
    "## Save Notebook Configuration Data\n",
    "If you want to avoid having to re-enter these across notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed3d8bb-f4d2-493e-ae8c-66830ca12d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = f\"\"\"\n",
    "PROJECT_ID               = \\\"{PROJECT_ID}\\\"\n",
    "PROJECT_NUM              = \\\"{PROJECT_NUM}\\\"\n",
    "LOCATION                 = \\\"{LOCATION}\\\"\n",
    "\n",
    "REGION                   = \\\"{REGION}\\\"\n",
    "BQ_LOCATION              = \\\"{BQ_LOCATION}\\\"\n",
    "VPC_NETWORK_NAME         = \\\"{VPC_NETWORK_NAME}\\\"\n",
    "\n",
    "VERTEX_SA                = \\\"{VERTEX_SA}\\\"\n",
    "\n",
    "PREFIX                   = \\\"{PREFIX}\\\"\n",
    "VERSION                  = \\\"{VERSION}\\\"\n",
    "\n",
    "BUCKET_NAME              = \\\"{BUCKET_NAME}\\\"\n",
    "BUCKET_URI               = \\\"{BUCKET_URI}\\\"\n",
    "DATA_GCS_PREFIX          = \\\"{DATA_GCS_PREFIX}\\\"\n",
    "DATA_PATH                = \\\"{DATA_PATH}\\\"\n",
    "VOCAB_SUBDIR             = \\\"{VOCAB_SUBDIR}\\\"\n",
    "VOCAB_FILENAME           = \\\"{VOCAB_FILENAME}\\\"\n",
    "DATA_PATH_KFP_DEMO       = \\\"{DATA_PATH_KFP_DEMO}\\\"\n",
    "\n",
    "VPC_NETWORK_FULL         = \\\"{VPC_NETWORK_FULL}\\\"\n",
    "\n",
    "BIGQUERY_DATASET_NAME    = \\\"{BIGQUERY_DATASET_NAME}\\\"\n",
    "BIGQUERY_TABLE_NAME      = \\\"{BIGQUERY_TABLE_NAME}\\\"\n",
    "\n",
    "REPOSITORY               = \\\"{REPOSITORY}\\\"\n",
    "\n",
    "DOCKERNAME_01            = \\\"{DOCKERNAME_01}\\\"\n",
    "IMAGE_NAME_01            = \\\"{IMAGE_NAME_01}\\\"\n",
    "IMAGE_URI_01             = \\\"{IMAGE_URI_01}\\\"\n",
    "\n",
    "DOCKERNAME_02            = \\\"{DOCKERNAME_02}\\\"\n",
    "IMAGE_NAME_02            = \\\"{IMAGE_NAME_02}\\\"\n",
    "IMAGE_URI_02             = \\\"{IMAGE_URI_02}\\\"\n",
    "\n",
    "DOCKERNAME_03            = \\\"{DOCKERNAME_03}\\\"\n",
    "IMAGE_NAME_03            = \\\"{IMAGE_NAME_03}\\\"\n",
    "IMAGE_URI_03             = \\\"{IMAGE_URI_03}\\\"\n",
    "\n",
    "DOCKERNAME_04            = \\\"{DOCKERNAME_04}\\\"\n",
    "IMAGE_NAME_04            = \\\"{IMAGE_NAME_04}\\\"\n",
    "IMAGE_URI_04             = \\\"{IMAGE_URI_04}\\\"\n",
    "\n",
    "DOCKERNAME_04_pred       = \\\"{DOCKERNAME_04_pred}\\\"\n",
    "IMAGE_NAME_04_pred       = \\\"{IMAGE_NAME_04_pred}\\\"\n",
    "IMAGE_URI_04_pred        = \\\"{IMAGE_URI_04_pred}\\\"\n",
    "\n",
    "REMOTE_IMAGE_NAME        = \\\"{REMOTE_IMAGE_NAME}\\\"\n",
    "\n",
    "REPO_DOCKER_PATH_PREFIX  = \\\"{REPO_DOCKER_PATH_PREFIX}\\\"\n",
    "RL_SUB_DIR               = \\\"{RL_SUB_DIR}\\\"\n",
    "\"\"\"\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58b9443-c5cc-456b-bd92-1ac5543d7afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo '{config}' | gsutil cp - {BUCKET_URI}/config/notebook_env.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db73041c-291e-4839-912a-e24f0900ba7a",
   "metadata": {},
   "source": [
    "Copy your first dataset to your bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73b23b2-faaf-4ae8-b0a0-0492c81abedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE_URI = \"gs://cloud-samples-data/vertex-ai/community-content/tf_agents_bandits_movie_recommendation_with_kfp_and_vertex_sdk/u.data\"\n",
    "\n",
    "# ! gsutil cp $SOURCE_URI $DATA_PATH_KFP_DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb374e1-ec22-468b-82c1-cae19aba8031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil ls $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26c8d55-19ee-4cd4-b53f-b770603c7c49",
   "metadata": {},
   "source": [
    "# Create BigQuery dataset and tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1568f2d3-04f9-4c3d-9370-45f4c133c819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# bigquery client\n",
    "bqclient = bigquery.Client(\n",
    "    project=PROJECT_ID,\n",
    "    # location=LOCATION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d110225-93fb-4d61-a3c0-7df6de6057c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CREATE_NEW_ASSETS:\n",
    "    ds = bigquery.Dataset(f\"{PROJECT_ID}.{BIGQUERY_DATASET_NAME}\")\n",
    "    ds.location = BQ_LOCATION\n",
    "    ds = bqclient.create_dataset(dataset = ds, exists_ok = False)\n",
    "\n",
    "    print(ds.full_dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b510374-62d0-4dbd-9145-63ac2c36b4f9",
   "metadata": {},
   "source": [
    "# gitignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03219843-7ad8-4324-93e3-5b1c4f0844cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile .gitignore\n",
    "*.cpython-310.pyc\n",
    "*checkpoint*\n",
    "*.ipynb_checkpoints/*\n",
    "*WIP*\n",
    "*/archive/*\n",
    "# .gcloudignore\n",
    "# .git\n",
    "# .github\n",
    "# *__pycache__\n",
    "# *cpython-37.pyc\n",
    "# .gitignore\n",
    "# .DS_Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c613951-bd35-4075-a11d-849c38a83d17",
   "metadata": {},
   "source": [
    "# gcloudignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eafbfd4-8497-4a5f-884b-4fb4dbd652d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud config set gcloudignore/enabled true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e6503e-dd7e-491e-b3a8-0519d8ece23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile .gcloudignore\n",
    ".gcloudignore\n",
    "/WIP/\n",
    "# /img/\n",
    "*.pkl\n",
    "*.png\n",
    "*.ipynb\n",
    ".git\n",
    ".github\n",
    ".ipynb_checkpoints/*\n",
    "*/__pycache__/*\n",
    "*cpython-37.pyc\n",
    "**.cpython-310.pyc\n",
    "/hptuning/*\n",
    "/imgs/*\n",
    "README.md\n",
    ".gitignore\n",
    ".DS_Store\n",
    "*.tfrecord\n",
    "src/archive/*\n",
    "00-archived/*\n",
    "learning/*\n",
    ".ipynb_checkpoints/**\n",
    "*.md\n",
    "src_root/*\n",
    "*.h\n",
    "*.gsutil\n",
    ".local/include/python3.10/*\n",
    "*.local/lib/python3.10/site-packages/gslib/tests/*\n",
    "*.local/include/python3.10/*\n",
    ".local/lib/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5cd8e8-14cd-4904-9c29-5fcca701bac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check eligible files\n",
    "!gcloud meta list-files-for-upload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17431096-a82a-4571-9203-1e6a3d5e32f1",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
