{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f462e3ae-0544-4a09-8345-01fc822192f0",
   "metadata": {},
   "source": [
    "# Contextual Bandits for Ranking with TF-Agents\n",
    "\n",
    "> see [ranking tutorial](https://www.tensorflow.org/agents/tutorials/ranking_tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214b2409-ca72-4a2f-972b-32185fbf441c",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "* The contextual bandits approach is classified as an extension of multi-armed bandits\n",
    "* a contextual multi-armed banded problem is a simplified reinforcement learning algorithm where the agent takes an action from a set of possible actions \n",
    "\n",
    "> **TODO**\n",
    "\n",
    "The **Bandit Ranking** agent will be similar to the `NeuralEpsilonGreedy` agent. Main differences:\n",
    "\n",
    "* The item features are stored in the `per_arm` part of the observation, in the order of how they are recommended\n",
    "* Since this ordered list of items expresses what action was taken by the policy,\n",
    "the `action` value of the trajectory is not used by the agent.\n",
    "\n",
    "> Note: difference between the \"per-arm\" observation recieved by the policy vs the agent:\n",
    "\n",
    "While the agent receives the items in the recommendation slots, the policy receives the items that are available for recommendation. The user is responsible for converting the observation to the\n",
    "syntax required by the agent.\n",
    "\n",
    "\n",
    "The training observation contains the global features and the features of the items in the recommendation slots \n",
    "* The item features are stored in the `per_arm` part of the observation, in the order of how they are recommended\n",
    "* Note: since this ordered list of items expresses what action was taken by the policy, the action value of the trajectory is not used by the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce53b012-c8db-4874-90bc-e13ac83fae19",
   "metadata": {},
   "source": [
    "## Load notebook config\n",
    "\n",
    "* use the prefix defined in `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "056b54b6-79d5-4ed6-b94a-6a776fc7db36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "VERSION        = \"v2\"                       # TODO\n",
    "PREFIX         = f'rec-bandits-{VERSION}'   # TODO\n",
    "\n",
    "# PREFIX = 'mabv1'\n",
    "\n",
    "print(f\"PREFIX: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d3596a1-670b-4974-b643-2079a5db0afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"rec-bandits-v2\"\n",
      "VERSION                  = \"v2\"\n",
      "\n",
      "BUCKET_NAME              = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_ID      = \"hybrid_vertex.movielens_ds_rec_bandits_v2\"\n",
      "BIGQUERY_TABLE_ID        = \"hybrid_vertex.movielens_ds_rec_bandits_v2.training_dataset\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-rec-bandits-v2\"\n",
      "IMAGE_NAME               = \"train-perarm-feats-v2\"\n",
      "DOCKERNAME               = \"Dockerfile_perarm_feats\"\n",
      "\n",
      "IMAGE_URI_01             = \"gcr.io/hybrid-vertex/train-perarm-feats-v2-01\"\n",
      "IMAGE_URI_02             = \"gcr.io/hybrid-vertex/train-perarm-feats-v2-02\"\n",
      "\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/train-perarm-feats-v2\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940507dd-369b-4b93-a0c5-4b2d0e079269",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4fec363-3a69-4fc6-ab38-706230fba418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70e611f2-2d75-4b8d-9c9b-3b4421f8e04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/03-ranking\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93b706f8-8739-426b-b3c0-49c5ae2163f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from collections import defaultdict\n",
    "from typing import Callable, Dict, List, Optional, TypeVar, Iterable, Tuple\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "# from tf_agents.agents import TFAgent\n",
    "\n",
    "# from tf_agents.bandits.environments import stationary_stochastic_per_arm_py_environment as p_a_env\n",
    "from tf_agents.bandits.environments.ranking_environment import FeedbackModel\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "# from tf_agents.drivers import dynamic_step_driver\n",
    "# from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "# from tf_agents.bandits.agents import lin_ucb_agent\n",
    "# from tf_agents.bandits.agents import linear_thompson_sampling_agent as lin_ts_agent\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent\n",
    "from tf_agents.bandits.agents import neural_linucb_agent\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "from tf_agents.bandits.policies import policy_utilities\n",
    "\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.bandits.environments import ranking_environment\n",
    "from tf_agents.bandits.agents import ranking_agent\n",
    "\n",
    "from tf_agents.utils import nest_utils\n",
    "from tf_agents.specs import array_spec\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# this repo\n",
    "from src.per_arm_rl import data_utils\n",
    "from src.per_arm_rl import data_config\n",
    "from src.per_arm_rl import train_utils as train_utils\n",
    "\n",
    "from src.per_arm_rl import utils_config as utils_config\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5bc92e4-dac3-468e-a0f5-26d48ec63620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d4c0818-64e0-4629-a9d8-2fed58a7086f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28167f0d-5870-40bb-ba1e-b4a2cc4bd7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b249f6-2e74-4e2a-bf04-be4bfd0732bd",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c726bc2-ff41-41b0-9671-113a499e55d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de644e7f-8a6b-4c64-858f-1618fc76e373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT: listwise-3n-val\n"
     ]
    }
   ],
   "source": [
    "# 3 | 5\n",
    "NUM_EXAMPLES_PER_LIST = utils_config.NUM_EXAMPLES_PER_LIST\n",
    "\n",
    "# SPLIT = \"val\"\n",
    "# SPLIT = \"listwise-val\"\n",
    "SPLIT = f\"listwise-{NUM_EXAMPLES_PER_LIST}n-val\"\n",
    "\n",
    "print(f\"SPLIT: {SPLIT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56222181-f72a-4a9c-946e-5cd94ab40caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/listwise-3n-val/ml-100k-listwise-3n-val.tfrecord\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls $BUCKET_URI/$DATA_GCS_PREFIX/$SPLIT/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b22408a-fbfc-4b56-8f4b-b12462329fd3",
   "metadata": {},
   "source": [
    "### Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8afaa02e-5638-40a8-964e-e51b27d433d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_genres': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([3, 0, 0])>,\n",
      " 'movie_id': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'94', b'245', b'403'], dtype=object)>,\n",
      " 'user_id': <tf.Tensor: shape=(), dtype=string, numpy=b'346'>,\n",
      " 'user_rating': <tf.Tensor: shape=(3,), dtype=float32, numpy=array([3., 4., 3.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "# SPLIT = \"val\"\n",
    "# SPLIT = \"listwise-val\"\n",
    "SPLIT = f\"listwise-{NUM_EXAMPLES_PER_LIST}n-val\"\n",
    "\n",
    "val_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        val_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "val_dataset = tf.data.TFRecordDataset(val_files)\n",
    "val_dataset = val_dataset.map(data_utils.parse_lw_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "for example in val_dataset.take(1):\n",
    "    pprint(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46862c4-dcbb-4b2d-aa53-765204f79250",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e814c64-1c96-47fd-a0f4-4c56bb15e0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT = \"train\"\n",
    "# SPLIT = \"listwise-train\"\n",
    "# SPLIT = f\"listwise-{NUM_EXAMPLES_PER_LIST}n-train\"\n",
    "\n",
    "# train_files = []\n",
    "# for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "#     if '.tfrecord' in blob.name:\n",
    "#         train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "# train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "# train_dataset = train_dataset.map(data_utils.parse_lw_tfrecord)\n",
    "\n",
    "# for x in train_dataset.batch(1).take(1):\n",
    "#     pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6ca4675-7c73-49b5-8146-0e2966fd3cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9501973f-6c96-46ba-adaa-6d85450c1256",
   "metadata": {},
   "source": [
    "### Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4099e809-1152-4b27-b4aa-bc627652e45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE_VOCABS: False\n"
     ]
    }
   ],
   "source": [
    "GENERATE_VOCABS = False\n",
    "\n",
    "print(f\"GENERATE_VOCABS: {GENERATE_VOCABS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b136aa91-bc57-4acf-80f2-fff09b33acf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://mabv1-hybrid-vertex-bucket/vocabs/vocab_dict.pkl [Content-Type=application/octet-stream]...\n",
      "/ [1 files][142.9 KiB/142.9 KiB]                                                \n",
      "Operation completed over 1 objects/142.9 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{VOCAB_SUBDIR}/{VOCAB_FILENAME}'\n",
    "\n",
    "!gsutil cp gs://mabv1-hybrid-vertex-bucket/vocabs/vocab_dict.pkl $EXISTING_VOCAB_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2d881e8-b633-4c06-b8b0-c788e1806fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded storage object vocabs/vocab_dict.pkl from bucket rec-bandits-v2-hybrid-vertex-bucket to local file vocab_dict.pkl.\n",
      "'movie_id'\n",
      "'user_id'\n",
      "'user_occupation_text'\n",
      "'movie_genres'\n",
      "'bucketized_user_age'\n",
      "'max_timestamp'\n",
      "'min_timestamp'\n",
      "'timestamp_buckets'\n"
     ]
    }
   ],
   "source": [
    "data_utils.download_blob(\n",
    "    project_id = PROJECT_ID,\n",
    "    bucket_name = BUCKET_NAME, \n",
    "    source_blob_name = f\"{VOCAB_SUBDIR}/{VOCAB_FILENAME}\", \n",
    "    destination_file_name= VOCAB_FILENAME\n",
    ")\n",
    "\n",
    "filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "vocab_dict = pkl.load(filehandler)\n",
    "filehandler.close()\n",
    "\n",
    "for key in vocab_dict.keys():\n",
    "    pprint(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c58d83-52f1-4490-931b-3d65c157cc13",
   "metadata": {},
   "source": [
    "# Global & Per-Arm feature embedding models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5dc1c53-af82-400a-b841-32775855578d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_OOV_BUCKETS    : 2\n",
      "GLOBAL_EMB_SIZE    : 64\n",
      "MV_EMB_SIZE        : 32\n",
      "BATCH_SIZE         : 5\n",
      "EVAL_BATCH_SIZE    : 1\n",
      "NUM_ITEMS          : 3\n",
      "NUM_SLOTS          : 2\n",
      "DISTANCE_THRESHOLD : 0.5\n"
     ]
    }
   ],
   "source": [
    "NUM_OOV_BUCKETS       = 2\n",
    "GLOBAL_EMBEDDING_SIZE = 64 #64\n",
    "MV_EMBEDDING_SIZE     = 32 #32\n",
    "\n",
    "BATCH_SIZE            = 5 #128\n",
    "EVAL_BATCH_SIZE       = 1\n",
    "\n",
    "NUM_ITEMS             = NUM_EXAMPLES_PER_LIST # 3 | 5 \n",
    "NUM_SLOTS             = 2\n",
    "\n",
    "DISTANCE_THRESHOLD    = 0.5\n",
    "\n",
    "print(f\"NUM_OOV_BUCKETS    : {NUM_OOV_BUCKETS}\")\n",
    "print(f\"GLOBAL_EMB_SIZE    : {GLOBAL_EMBEDDING_SIZE}\")\n",
    "print(f\"MV_EMB_SIZE        : {MV_EMBEDDING_SIZE}\")\n",
    "print(f\"BATCH_SIZE         : {BATCH_SIZE}\")\n",
    "print(f\"EVAL_BATCH_SIZE    : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"NUM_ITEMS          : {NUM_ITEMS}\")\n",
    "print(f\"NUM_SLOTS          : {NUM_SLOTS}\")\n",
    "print(f\"DISTANCE_THRESHOLD : {DISTANCE_THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "833f62ac-e6bf-4892-a168-b5d075771fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie_genres': <tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n",
       " array([[3, 0, 0],\n",
       "        [7, 0, 0]])>,\n",
       " 'movie_id': <tf.Tensor: shape=(2, 3), dtype=string, numpy=\n",
       " array([[b'94', b'245', b'403'],\n",
       "        [b'678', b'127', b'343']], dtype=object)>,\n",
       " 'user_id': <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'346', b'602'], dtype=object)>,\n",
       " 'user_rating': <tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       " array([[3., 4., 3.],\n",
       "        [4., 5., 2.]], dtype=float32)>}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    \n",
    "    iterator = iter(train_dataset.batch(2))\n",
    "    data = next(iterator)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a281a7ae-be08-41c6-a648-caab55ad1235",
   "metadata": {},
   "source": [
    "## Embedding layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec8212d-0b97-4db8-8126-6693af06d55a",
   "metadata": {},
   "source": [
    "#### User ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcc2d6f1-4559-466d-8f0f-53fc5c3bd4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_input_layer = tf.keras.Input(\n",
    "    name=\"user_id\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.string\n",
    ")\n",
    "\n",
    "user_id_lookup = tf.keras.layers.StringLookup(\n",
    "    max_tokens=len(vocab_dict['user_id']) + NUM_OOV_BUCKETS,\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    mask_token=None,\n",
    "    vocabulary=vocab_dict['user_id'],\n",
    ")(user_id_input_layer)\n",
    "\n",
    "user_id_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['user_id']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=GLOBAL_EMBEDDING_SIZE\n",
    ")(user_id_lookup)\n",
    "\n",
    "user_id_embedding = tf.reduce_sum(user_id_embedding, axis=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c31717b-900e-44dd-8fa8-4692caa4dc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'346'], shape=(1,), dtype=string)\n",
      "tf.Tensor(\n",
      "[[ 0.02409824  0.00439677 -0.02838409  0.00959983 -0.0306898  -0.03096371\n",
      "   0.03607819  0.03301442  0.0189674   0.0472681   0.00874193 -0.01467835\n",
      "  -0.01625825  0.01820537  0.01343845 -0.02740647  0.01214357  0.0249221\n",
      "   0.0358796   0.03853519 -0.04556305 -0.04429594  0.002506    0.03192786\n",
      "   0.04803034 -0.00718015  0.0375897   0.03720978  0.03792012  0.02919904\n",
      "  -0.01979443  0.03208634 -0.04318004 -0.02038409 -0.02075547  0.02397003\n",
      "   0.02699273  0.02321482 -0.00417148 -0.02541105 -0.00859941 -0.00833646\n",
      "   0.00921681 -0.03157143 -0.01451939  0.01519987 -0.03876623  0.01135423\n",
      "  -0.03226405 -0.04044051  0.01555766  0.02248392 -0.01401436 -0.01019765\n",
      "  -0.03155918 -0.01233897  0.02556698  0.03375467 -0.03687272 -0.03991523\n",
      "   0.018152    0.00085736  0.04575268  0.04789146]], shape=(1, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_user_id_model = tf.keras.Model(inputs=user_id_input_layer, outputs=user_id_embedding)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(x[\"user_id\"])\n",
    "    print(test_user_id_model(x[\"user_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a114a3-1cdd-46c7-b68d-3f9f55e06280",
   "metadata": {},
   "source": [
    "#### Movie ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bcc5a95f-8298-4d68-92c0-7d3887b8364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(vocab_dict['movie_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7c494c2-5a71-4de4-a1a0-746653f805dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_id_input_layer = tf.keras.Input(\n",
    "    name=\"movie_id\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.string\n",
    ")\n",
    "\n",
    "mv_id_lookup = tf.keras.layers.StringLookup(\n",
    "    max_tokens=len(vocab_dict['movie_id']) + NUM_OOV_BUCKETS,\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    mask_token=None,\n",
    "    vocabulary=vocab_dict['movie_id'],\n",
    ")(mv_id_input_layer)\n",
    "\n",
    "mv_id_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['movie_id']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=MV_EMBEDDING_SIZE\n",
    ")(mv_id_lookup)\n",
    "\n",
    "# mv_id_embedding = tf.reduce_sum(mv_id_embedding, axis=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c448c58-fbc8-42b1-aa3e-d69f113ee093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[b'94' b'245' b'403']], shape=(1, 3), dtype=string)\n",
      "tf.Tensor(\n",
      "[[[-0.01020818  0.0203963   0.03782905  0.04259365  0.03883089\n",
      "    0.01513633 -0.04341742  0.04280907 -0.01687434 -0.03803598\n",
      "   -0.03476577 -0.0257284   0.00540622  0.04206529  0.01691098\n",
      "    0.02106353  0.03780023  0.01914278  0.01268687 -0.02212795\n",
      "    0.0497325   0.01239011 -0.02221676 -0.01827216  0.04054283\n",
      "    0.04269342 -0.04910258  0.04734648 -0.04832636  0.04406605\n",
      "   -0.00252738  0.00890038]\n",
      "  [-0.03763245 -0.03134408 -0.03013839 -0.02073256 -0.02715528\n",
      "    0.03340855  0.03647807 -0.00189767  0.04697769  0.00709448\n",
      "   -0.03711182  0.00252603 -0.0352978  -0.01233221 -0.00518265\n",
      "    0.01322826 -0.02511042 -0.04917243 -0.0058673   0.01373788\n",
      "   -0.04607867 -0.04854529  0.01649073 -0.02633615  0.03487164\n",
      "   -0.02753892 -0.01247466 -0.04335777  0.01681933  0.01664496\n",
      "    0.00685073 -0.00219759]\n",
      "  [-0.02652711  0.0211661   0.04925023  0.03580297 -0.00516739\n",
      "   -0.02294213 -0.02553456 -0.02815533  0.00389897  0.0094597\n",
      "    0.01998141  0.00514273 -0.01407725  0.04353826 -0.02247404\n",
      "   -0.00192098 -0.01411468 -0.02801365  0.0231174  -0.01308309\n",
      "   -0.00178425  0.01755995  0.02105849 -0.0014056   0.03602577\n",
      "   -0.02243553 -0.03371791  0.02354913  0.03962437  0.03154316\n",
      "    0.01872876  0.04181418]]], shape=(1, 3, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_mv_id_model = tf.keras.Model(inputs=mv_id_input_layer, outputs=mv_id_embedding)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(x[\"movie_id\"])\n",
    "    list_length = x[\"movie_id\"].shape[1]\n",
    "    print(test_mv_id_model(x[\"movie_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9da6dc0-a871-4b73-b975-87871e571cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e66ac33f-6def-4529-9a2d-f17482471757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in train_dataset.batch(1).take(1):\n",
    "#     print(x[\"movie_id\"])\n",
    "#     single_sample = x[\"movie_id\"][0]\n",
    "#     item_1 = tf.gather(x[\"movie_id\"][0], 0)\n",
    "#     print(item_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e894e0c-b080-4e3c-ad2c-7fc460a2b97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_sample[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5886b2a-011b-4648-9834-b8a1e2d343f2",
   "metadata": {},
   "source": [
    "#### Movie Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dee33311-d565-4003-8d28-0d3dfc0ca68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(vocab_dict['movie_genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "052db904-0935-44db-bbba-548aa7b01c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_genre_input_layer = tf.keras.Input(\n",
    "    name=\"movie_genres\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "mv_genre_lookup = tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=vocab_dict['movie_genres'],\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    oov_value=0,\n",
    ")(mv_genre_input_layer)\n",
    "\n",
    "mv_genre_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['movie_genres']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=MV_EMBEDDING_SIZE\n",
    ")(mv_genre_lookup)\n",
    "\n",
    "# mv_genre_embedding = tf.reduce_sum(mv_genre_embedding, axis=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0cd72900-c9bc-4349-8984-8c0218c08efe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[3 0 0]\n",
      " [7 0 0]], shape=(2, 3), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-0.01172165  0.04488413  0.04784555 -0.04033741 -0.02281132\n",
      "    0.02662319 -0.03772918 -0.0362082  -0.01156131 -0.02120118\n",
      "    0.01844202  0.02179832 -0.01430397  0.03169998 -0.01258159\n",
      "   -0.02852133  0.00277523  0.04502774 -0.0332548   0.04514119\n",
      "   -0.0104882   0.01668752 -0.00065576 -0.02984524  0.01878712\n",
      "    0.04776387 -0.01532439  0.04177114 -0.0025756  -0.02670593\n",
      "   -0.03738177  0.04541738]\n",
      "  [-0.03107576 -0.01460776 -0.03411764 -0.01686355 -0.03049396\n",
      "    0.0227044   0.01983554 -0.02619834  0.0258412   0.0134943\n",
      "    0.0032429  -0.00345822 -0.00692091  0.04543713 -0.01839808\n",
      "    0.01852553 -0.00302775 -0.03992827 -0.03634677  0.00243723\n",
      "   -0.03530606  0.03298659 -0.00171708 -0.03774018 -0.01813754\n",
      "    0.03456208  0.02867026 -0.04483645 -0.00297464  0.01042732\n",
      "    0.00702989 -0.04469549]\n",
      "  [-0.03107576 -0.01460776 -0.03411764 -0.01686355 -0.03049396\n",
      "    0.0227044   0.01983554 -0.02619834  0.0258412   0.0134943\n",
      "    0.0032429  -0.00345822 -0.00692091  0.04543713 -0.01839808\n",
      "    0.01852553 -0.00302775 -0.03992827 -0.03634677  0.00243723\n",
      "   -0.03530606  0.03298659 -0.00171708 -0.03774018 -0.01813754\n",
      "    0.03456208  0.02867026 -0.04483645 -0.00297464  0.01042732\n",
      "    0.00702989 -0.04469549]]\n",
      "\n",
      " [[ 0.01816568 -0.00061094 -0.04824369 -0.04828063 -0.00194399\n",
      "   -0.03037736  0.01328603 -0.03463365 -0.00266731  0.028347\n",
      "   -0.03446684 -0.01833577  0.03419787 -0.02768232 -0.00292246\n",
      "    0.02893326  0.02061426 -0.01907414  0.04460824  0.02107116\n",
      "    0.02729681 -0.00997581 -0.04440759  0.02640006  0.00248321\n",
      "    0.01139009  0.03134146 -0.02829974  0.00262358 -0.04676609\n",
      "    0.02710042  0.02590528]\n",
      "  [-0.03107576 -0.01460776 -0.03411764 -0.01686355 -0.03049396\n",
      "    0.0227044   0.01983554 -0.02619834  0.0258412   0.0134943\n",
      "    0.0032429  -0.00345822 -0.00692091  0.04543713 -0.01839808\n",
      "    0.01852553 -0.00302775 -0.03992827 -0.03634677  0.00243723\n",
      "   -0.03530606  0.03298659 -0.00171708 -0.03774018 -0.01813754\n",
      "    0.03456208  0.02867026 -0.04483645 -0.00297464  0.01042732\n",
      "    0.00702989 -0.04469549]\n",
      "  [-0.03107576 -0.01460776 -0.03411764 -0.01686355 -0.03049396\n",
      "    0.0227044   0.01983554 -0.02619834  0.0258412   0.0134943\n",
      "    0.0032429  -0.00345822 -0.00692091  0.04543713 -0.01839808\n",
      "    0.01852553 -0.00302775 -0.03992827 -0.03634677  0.00243723\n",
      "   -0.03530606  0.03298659 -0.00171708 -0.03774018 -0.01813754\n",
      "    0.03456208  0.02867026 -0.04483645 -0.00297464  0.01042732\n",
      "    0.00702989 -0.04469549]]], shape=(2, 3, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_mv_gen_model = tf.keras.Model(inputs=mv_genre_input_layer, outputs=mv_genre_embedding)\n",
    "\n",
    "for x in train_dataset.batch(2).take(1):\n",
    "    print(x[\"movie_genres\"])\n",
    "    print(test_mv_gen_model(x[\"movie_genres\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4799ad0c-abc8-4e56-88d0-93111bba6d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in train_dataset.batch(1).take(1):\n",
    "#     print(x[\"movie_genres\"])\n",
    "#     mv_gen_sample = x[\"movie_genres\"]\n",
    "#     item_gen = tf.gather(x[\"movie_genres\"], 0)\n",
    "#     print(item_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3455b83-a3a0-4d07-9542-2e035cae612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in train_dataset.batch(2).take(1):\n",
    "#     print(x[\"user_rating\"])\n",
    "#     # mv_gen_sample = x[\"movie_genres\"]\n",
    "#     # item_gen = tf.gather(x[\"movie_genres\"], 0)\n",
    "#     # print(item_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0415398e-3bbd-4497-aa31-1d618325fbb1",
   "metadata": {},
   "source": [
    "## Sampling Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343c1dee-fc37-4075-8d65-6909d548eb43",
   "metadata": {},
   "source": [
    "#### item sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bfea1d42-c08f-4b3f-b4b8-97aefc6dd622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f6d643f-ae9f-4174-9f22-e1f1cdf56824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in train_dataset.batch(2).take(1):\n",
    "#     ratings_list = x[\"user_rating\"] #[0]\n",
    "#     indices = tf.argsort(ratings_list, direction=\"DESCENDING\")\n",
    "    \n",
    "#     mv_ids = test_mv_id_model(x[\"movie_id\"])\n",
    "#     # mv_ids_sliced = tf.slice(mv_ids, begin=[0,0,0], size=[HPARAMS['num_slots']])\n",
    "    \n",
    "#     mv_gens = test_mv_gen_model(x[\"movie_genres\"])\n",
    "#     # mv_gens_sliced = tf.slice(mv_gens, begin=[0,0,0], size=[HPARAMS['num_slots']])\n",
    "    \n",
    "# #     concat_embeddings = tf.concat(\n",
    "# #         [mv_ids, mv_gens], axis=-1\n",
    "# #     )\n",
    "    \n",
    "# #     ordered_concat = tf.gather(concat_embeddings, indices, batch_dims=1)\n",
    "    \n",
    "# #     stacked_mvs = tf.stack(concat_embeddings, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "58eadd47-746a-4b9f-8370-564e0cdafd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(ratings_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e8883e1c-0448-4486-bc2e-4ae3e3e54919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_per_arm_features(x):\n",
    "    \"\"\"\n",
    "    This function generates a single per-arm observation vector.\n",
    "    \"\"\"\n",
    "    ratings_list = x[\"user_rating\"] #[0]\n",
    "    indices = tf.argsort(ratings_list, direction=\"DESCENDING\")\n",
    "    _batch_size = len(ratings_list)\n",
    "    \n",
    "    mv_ids = test_mv_id_model(x[\"movie_id\"])\n",
    "    mv_gens = test_mv_gen_model(x[\"movie_genres\"])\n",
    "    \n",
    "    concat_embeddings = tf.concat(\n",
    "        [mv_ids, mv_gens], axis=-1\n",
    "    )\n",
    "    \n",
    "    ordered_concat = tf.gather(concat_embeddings, indices, batch_dims=1)\n",
    "    # feedback = tf.gather_nd(concat_embeddings, indices)\n",
    "    # print(f\"ordered_concat_embeddings: {ordered_concat_embeddings}\")\n",
    "    # ordered_concat = tf.reduce_sum(ordered_concat, axis=0)\n",
    "    \n",
    "    slotted_ordered_concat = tf.slice(\n",
    "        ordered_concat, begin=[0, 0, 0], size=[_batch_size, NUM_SLOTS, MV_EMBEDDING_SIZE * NUM_SLOTS]\n",
    "    )\n",
    "    \n",
    "    return slotted_ordered_concat\n",
    "    # return slotted_ordered_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d985e45c-7247-467d-80fb-fa977957e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 64), dtype=float32, numpy=\n",
       "array([[[-0.03763245, -0.03134408, -0.03013839, -0.02073256,\n",
       "         -0.02715528,  0.03340855,  0.03647807, -0.00189767,\n",
       "          0.04697769,  0.00709448, -0.03711182,  0.00252603,\n",
       "         -0.0352978 , -0.01233221, -0.00518265,  0.01322826,\n",
       "         -0.02511042, -0.04917243, -0.0058673 ,  0.01373788,\n",
       "         -0.04607867, -0.04854529,  0.01649073, -0.02633615,\n",
       "          0.03487164, -0.02753892, -0.01247466, -0.04335777,\n",
       "          0.01681933,  0.01664496,  0.00685073, -0.00219759,\n",
       "         -0.03107576, -0.01460776, -0.03411764, -0.01686355,\n",
       "         -0.03049396,  0.0227044 ,  0.01983554, -0.02619834,\n",
       "          0.0258412 ,  0.0134943 ,  0.0032429 , -0.00345822,\n",
       "         -0.00692091,  0.04543713, -0.01839808,  0.01852553,\n",
       "         -0.00302775, -0.03992827, -0.03634677,  0.00243723,\n",
       "         -0.03530606,  0.03298659, -0.00171708, -0.03774018,\n",
       "         -0.01813754,  0.03456208,  0.02867026, -0.04483645,\n",
       "         -0.00297464,  0.01042732,  0.00702989, -0.04469549],\n",
       "        [-0.01020818,  0.0203963 ,  0.03782905,  0.04259365,\n",
       "          0.03883089,  0.01513633, -0.04341742,  0.04280907,\n",
       "         -0.01687434, -0.03803598, -0.03476577, -0.0257284 ,\n",
       "          0.00540622,  0.04206529,  0.01691098,  0.02106353,\n",
       "          0.03780023,  0.01914278,  0.01268687, -0.02212795,\n",
       "          0.0497325 ,  0.01239011, -0.02221676, -0.01827216,\n",
       "          0.04054283,  0.04269342, -0.04910258,  0.04734648,\n",
       "         -0.04832636,  0.04406605, -0.00252738,  0.00890038,\n",
       "         -0.01172165,  0.04488413,  0.04784555, -0.04033741,\n",
       "         -0.02281132,  0.02662319, -0.03772918, -0.0362082 ,\n",
       "         -0.01156131, -0.02120118,  0.01844202,  0.02179832,\n",
       "         -0.01430397,  0.03169998, -0.01258159, -0.02852133,\n",
       "          0.00277523,  0.04502774, -0.0332548 ,  0.04514119,\n",
       "         -0.0104882 ,  0.01668752, -0.00065576, -0.02984524,\n",
       "          0.01878712,  0.04776387, -0.01532439,  0.04177114,\n",
       "         -0.0025756 , -0.02670593, -0.03738177,  0.04541738]],\n",
       "\n",
       "       [[-0.00502688, -0.04748916,  0.03598137, -0.01282561,\n",
       "          0.00173561,  0.02133541,  0.0051677 ,  0.03267263,\n",
       "          0.03650409, -0.0147603 , -0.01901113,  0.03063556,\n",
       "          0.01867506,  0.02718576, -0.01208514, -0.020456  ,\n",
       "          0.03048507, -0.01870884, -0.04766476, -0.04082619,\n",
       "          0.00280104, -0.04275346,  0.04804785,  0.00695702,\n",
       "          0.01046621, -0.02828567, -0.02460854, -0.04849586,\n",
       "         -0.01088408, -0.04097252, -0.01057831, -0.00605819,\n",
       "         -0.03107576, -0.01460776, -0.03411764, -0.01686355,\n",
       "         -0.03049396,  0.0227044 ,  0.01983554, -0.02619834,\n",
       "          0.0258412 ,  0.0134943 ,  0.0032429 , -0.00345822,\n",
       "         -0.00692091,  0.04543713, -0.01839808,  0.01852553,\n",
       "         -0.00302775, -0.03992827, -0.03634677,  0.00243723,\n",
       "         -0.03530606,  0.03298659, -0.00171708, -0.03774018,\n",
       "         -0.01813754,  0.03456208,  0.02867026, -0.04483645,\n",
       "         -0.00297464,  0.01042732,  0.00702989, -0.04469549],\n",
       "        [ 0.02636525, -0.04152696,  0.02956093, -0.02302301,\n",
       "         -0.03302749,  0.0054371 ,  0.03791343, -0.0495281 ,\n",
       "         -0.02071489,  0.0446693 , -0.04857337,  0.02176132,\n",
       "         -0.01926235, -0.03959622, -0.04760096,  0.04907677,\n",
       "          0.02691067, -0.02390422,  0.00318686,  0.00247221,\n",
       "          0.02324957, -0.03531566, -0.01373967,  0.03298518,\n",
       "         -0.01823809, -0.04613268,  0.03259948, -0.02411982,\n",
       "         -0.02030431,  0.01693154,  0.02539021, -0.04381316,\n",
       "          0.01816568, -0.00061094, -0.04824369, -0.04828063,\n",
       "         -0.00194399, -0.03037736,  0.01328603, -0.03463365,\n",
       "         -0.00266731,  0.028347  , -0.03446684, -0.01833577,\n",
       "          0.03419787, -0.02768232, -0.00292246,  0.02893326,\n",
       "          0.02061426, -0.01907414,  0.04460824,  0.02107116,\n",
       "          0.02729681, -0.00997581, -0.04440759,  0.02640006,\n",
       "          0.00248321,  0.01139009,  0.03134146, -0.02829974,\n",
       "          0.00262358, -0.04676609,  0.02710042,  0.02590528]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arms = _get_per_arm_features(data)\n",
    "test_arms #.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd9b8a0a-6374-4584-8c99-1fd6adcbaea5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER_ARM_DIM: 64\n"
     ]
    }
   ],
   "source": [
    "test_arms = _get_per_arm_features(data)\n",
    "\n",
    "PER_ARM_DIM = test_arms.shape[2]            \n",
    "print(f\"PER_ARM_DIM: {PER_ARM_DIM}\")\n",
    "\n",
    "# test_arms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b01f1f2-a576-4b18-91ca-ee6c5bd90117",
   "metadata": {},
   "source": [
    "#### global sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dbffe5f6-8b37-448e-aadd-b578cfbe1395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_global_context_features(x):\n",
    "    \"\"\"\n",
    "    This function generates a single global observation vector.\n",
    "    \"\"\"\n",
    "    \n",
    "    return test_user_id_model(x['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1644300b-f7b7-4f38-9f31-f83ba74ecf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL_DIM: 64\n"
     ]
    }
   ],
   "source": [
    "test_globals = _get_global_context_features(data)\n",
    "\n",
    "GLOBAL_DIM = test_globals.shape[1] \n",
    "print(f\"GLOBAL_DIM: {GLOBAL_DIM}\")\n",
    "\n",
    "# test_globals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ada148e-e36b-4c98-ae5b-234aa9940055",
   "metadata": {},
   "source": [
    "# Ranking Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7fd210-4772-4073-9630-1173ac4f93e4",
   "metadata": {},
   "source": [
    "## Feedback type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a0da21-0b0f-4876-8b43-c012d1cc64c2",
   "metadata": {},
   "source": [
    "Ranking agents assume either a `score_vector` or `cascading feedback` framework for the feedback signal (reward). \n",
    "\n",
    "* `score_vector`: feedback is a vector of scores for every item in the slots. \n",
    "* `cascading feedback`: if the kth item was clicked, then the items up to k-1 receive a score of -1, the kth item receives a score based on a feedback value, while the rest of the items receive feedback of 0. \n",
    "\n",
    "Ranking agent objective: train the scoring network to be able to estimate the above scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c49a7375-ec9f-403d-aa86-810134cd430c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feedback_model = ranking_environment.FeedbackModel.CASCADING\n",
    "feedback_model = FeedbackModel.SCORE_VECTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b20c76-2950-4459-ab07-148cded078f2",
   "metadata": {},
   "source": [
    "## Tensor Specs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b43561b-f486-454e-a851-8cedfd6999d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "example Tensor Spec structures..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cbb948-52c5-44a3-80ab-4e57ba6968ea",
   "metadata": {},
   "source": [
    "`observation_spec()`\n",
    "\n",
    "```python\n",
    "{'global': TensorSpec(shape=(9,), dtype=tf.float32, name=None),\n",
    " 'per_arm': TensorSpec(shape=(50, 11), dtype=tf.float32, name=None)}\n",
    "```\n",
    "\n",
    "`action_spec()`\n",
    "\n",
    "```python\n",
    "BoundedTensorSpec(shape=(3,), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(49, dtype=int32))\n",
    "```\n",
    "\n",
    "`reward_spec()`\n",
    "\n",
    "```python\n",
    "{'chosen_index': BoundedTensorSpec(shape=(), dtype=tf.int32, name='chosen_index', minimum=array(0, dtype=int32), maximum=array(3, dtype=int32)),\n",
    " 'chosen_value': TensorSpec(shape=(), dtype=tf.float32, name='chosen_value')}\n",
    "```\n",
    "\n",
    "`time_step_spec()`\n",
    "\n",
    "```python\n",
    "TimeStep(\n",
    "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
    " 'observation': {'global': TensorSpec(shape=(9,), dtype=tf.float32, name=None),\n",
    "                 'per_arm': TensorSpec(shape=(50, 11), dtype=tf.float32, name=None)},\n",
    " 'reward': {'chosen_index': BoundedTensorSpec(shape=(), dtype=tf.int32, name='chosen_index', minimum=array(0, dtype=int32), maximum=array(3, dtype=int32)),\n",
    "            'chosen_value': TensorSpec(shape=(), dtype=tf.float32, name='chosen_value')},\n",
    " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8ab95f3-187b-45fc-a0bc-d4b53d4c5ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1):\n",
    "    \n",
    "#     iterator = iter(train_dataset.batch(2))\n",
    "#     data_1 = next(iterator)\n",
    "\n",
    "# data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ecb5c85a-ca16-4474-8f0e-12df37e34107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_spec = array_spec.ArraySpec.from_array(_get_global_context_features(data_1).numpy())\n",
    "# global_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4900700f-a344-45f3-b411-d761ac67f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _get_per_arm_features(data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3d6bc4ac-a7a3-4eef-9990-f277b12a5aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_spec = array_spec.add_outer_dims_nest(\n",
    "#     array_spec.ArraySpec.from_array(_get_per_arm_features(data_1).numpy()), (NUM_ITEMS,)\n",
    "# )\n",
    "# item_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6601ec58-da4a-42dc-9f92-d6b1cbe18582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL_KEY = bandit_spec_utils.GLOBAL_FEATURE_KEY\n",
    "# PER_ARM_KEY = bandit_spec_utils.PER_ARM_FEATURE_KEY\n",
    "\n",
    "# observation_spec_test = {GLOBAL_KEY: global_spec, PER_ARM_KEY: item_spec}\n",
    "# observation_spec_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3d69220f-5d64-4220-8ccd-62889036b98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _global_dim = global_spec.shape[0]\n",
    "# _global_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "92671d22-f376-4a00-8451-1bb4e0f7a3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _item_dim = item_spec.shape[-1]\n",
    "# _item_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d9cf3f-ac83-4580-a8f6-d98d93e49275",
   "metadata": {},
   "source": [
    "**from [ranking_environment.py](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/environments/ranking_environment.py#L152C1-L166C6)**\n",
    "\n",
    "```\n",
    "    global_spec = array_spec.ArraySpec.from_array(global_sampling_fn())\n",
    "    item_spec = array_spec.add_outer_dims_nest(\n",
    "        array_spec.ArraySpec.from_array(item_sampling_fn()), (num_items,)\n",
    "    )\n",
    "    observation_spec = {GLOBAL_KEY: global_spec, PER_ARM_KEY: item_spec}\n",
    "    self._global_dim = global_spec.shape[0]\n",
    "    self._item_dim = item_spec.shape[-1]\n",
    "\n",
    "    action_spec = array_spec.BoundedArraySpec(\n",
    "        shape=(num_slots,),\n",
    "        dtype=np.int32,\n",
    "        minimum=0,\n",
    "        maximum=num_items - 1,\n",
    "        name='action',\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae68b8a-8656-45cc-8977-70613629ce75",
   "metadata": {},
   "source": [
    "set vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5426bb09-834b-4cb3-9bf4-8d84482307e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE         : 5\n",
      "EVAL_BATCH_SIZE    : 1\n",
      "NUM_ITEMS          : 3\n",
      "NUM_SLOTS          : 2\n",
      "DISTANCE_THRESHOLD : 0.5\n",
      "GLOBAL_DIM         : 64\n",
      "PER_ARM_DIM        : 64\n"
     ]
    }
   ],
   "source": [
    "from tf_agents.specs import array_spec\n",
    "\n",
    "print(f\"BATCH_SIZE         : {BATCH_SIZE}\")\n",
    "print(f\"EVAL_BATCH_SIZE    : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"NUM_ITEMS          : {NUM_ITEMS}\")\n",
    "print(f\"NUM_SLOTS          : {NUM_SLOTS}\")\n",
    "print(f\"DISTANCE_THRESHOLD : {DISTANCE_THRESHOLD}\")\n",
    "print(f\"GLOBAL_DIM         : {GLOBAL_DIM}\")\n",
    "print(f\"PER_ARM_DIM        : {PER_ARM_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc572702-592c-4d60-8719-50739f611e16",
   "metadata": {},
   "source": [
    "### Observation spec\n",
    "\n",
    "* The observation the agent ingests contains the global features and the features\n",
    "of the items in the recommendation slots. \n",
    "* The item features are stored in the `per_arm` part of the observation, in the order of how they are recommended.\n",
    "* Since this ordered list of items expresses what action was taken by the policy, the `action` value of the trajectory is not used by the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0b97866b-fb8c-4724-ac6f-ce789d5b7368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_spec = {\n",
    "    'global': tf.TensorSpec([GLOBAL_DIM], tf.float32),\n",
    "    # 'per_arm': tf.TensorSpec([NUM_ITEMS, PER_ARM_DIM], tf.float32)\n",
    "    'per_arm': tf.TensorSpec([NUM_SLOTS, PER_ARM_DIM], tf.float32)\n",
    "}\n",
    "observation_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80565f15-d41e-46db-99b3-6ea6a73ab6aa",
   "metadata": {},
   "source": [
    "### Action spec\n",
    "\n",
    "> Action spec for ranking models must have rank 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "73b90ec0-1fe2-4b08-8a47-1fd32058705f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_spec rank: (2,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(2,), dtype=dtype('int32'), name='action', minimum=0, maximum=2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec = array_spec.BoundedArraySpec(\n",
    "    shape=(NUM_SLOTS,),\n",
    "    dtype=np.int32,\n",
    "    minimum=0,\n",
    "    maximum=NUM_ITEMS - 1,\n",
    "    name='action',\n",
    ")\n",
    "\n",
    "print(f\"action_spec rank: {action_spec.shape}\")\n",
    "\n",
    "action_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdacef1-fd61-4569-9bf7-299c52903710",
   "metadata": {},
   "source": [
    "### Reward spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "166f53bd-cdb9-49c4-a4d8-2904a6300f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(2,), dtype=tf.float32, name='score_vector')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if feedback_model == ranking_environment.FeedbackModel.CASCADING:\n",
    "    # `chosen_index == num_slots` means no recommended item was clicked.\n",
    "    reward_spec = {\n",
    "        'chosen_index': array_spec.BoundedArraySpec(\n",
    "            shape=[],\n",
    "            minimum=0,\n",
    "            maximum=NUM_SLOTS,\n",
    "            dtype=np.int32,\n",
    "            name='chosen_index',\n",
    "        ),\n",
    "        'chosen_value': array_spec.ArraySpec(\n",
    "            shape=[], dtype=np.float32, name='chosen_value'\n",
    "        ),\n",
    "    }\n",
    "elif feedback_model == ranking_environment.FeedbackModel.SCORE_VECTOR:\n",
    "    reward_spec = tf.TensorSpec(\n",
    "        shape=[NUM_SLOTS], dtype=np.float32, name='score_vector'\n",
    "    )\n",
    "    # reward_spec = array_spec.ArraySpec(\n",
    "    #     shape=[NUM_SLOTS], dtype=np.float32, name='score_vector'\n",
    "    # )\n",
    "else:\n",
    "    reward_spec = f\"Feedback model: {feedback_model}, not implemented\"\n",
    "    \n",
    "reward_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0deb69-a259-4495-a58e-81c0fd2a97ab",
   "metadata": {},
   "source": [
    "### TimeStep spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aa7a5d0e-d4c2-4f8c-b67e-84fe6d1e4fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
       " 'reward': TensorSpec(shape=(2,), dtype=tf.float32, name='score_vector'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - investigate adding reward_spec\n",
    "\"\"\"\n",
    "TypeError: Expected observation and reward specs to \n",
    "both be either tensor or array specs, but saw spec values \n",
    "TensorSpec(shape=(64,), dtype=tf.float32, name=None) \n",
    "vs. ArraySpec(shape=(2,), dtype=dtype('float32'), name='score_vector')\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "time_step_spec = ts.time_step_spec(\n",
    "    observation_spec = observation_spec, \n",
    "    reward_spec = reward_spec             # TODO\n",
    ")\n",
    "time_step_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ecc66c-ce8b-480b-8306-40eaf399f120",
   "metadata": {},
   "source": [
    "Inspect chosen arm features spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "164a5760-3ca3-4397-85b3-26bbcd987b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec.observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad033e89-1f1c-4f63-9084-bf6a6807915f",
   "metadata": {},
   "source": [
    "## Policy and Scoring Network\n",
    "\n",
    "> all ranking agents train a network that estimates scores of item/user pairs\n",
    "\n",
    "**Ranking Policies**\n",
    "* `DESCENDING_SCORES` - Stack rank deterministically by scores\n",
    "* `NO_PENALTY` - Sampling sequentially based on scores; no penalty applied\n",
    "* `COSINE_DISTANCE` - Sampling sequentally and taking diversity into account\n",
    "\n",
    "`penalty_mixture` parameter governs the balance between ranking based on scores and accounting for diversity\n",
    "* low positive value --> ranking has less diversity\n",
    "* higher value --> enforces more diversity\n",
    "\n",
    "`logits_temperature` - temperature parameter for non-deterministic policies\n",
    "* This value must be positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ce99346-5745-4d87-a469-9a36cb270987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL_DIM  : 64\n",
      "PER_ARM_DIM : 64\n"
     ]
    }
   ],
   "source": [
    "print(f\"GLOBAL_DIM  : {GLOBAL_DIM}\")\n",
    "print(f\"PER_ARM_DIM : {PER_ARM_DIM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c5aea87d-c993-4cd6-80ad-0522dcc91956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 5,\n",
      " 'common_layers': [16, 8],\n",
      " 'eval_batch_size': 1,\n",
      " 'feedback_model': 2,\n",
      " 'global_layers': [64, 32, 16],\n",
      " 'learning_rate': 0.005,\n",
      " 'logits_temperature': 1.0,\n",
      " 'model_type': 'Ranking',\n",
      " 'network_type': 'dotproduct',\n",
      " 'num_items': 3,\n",
      " 'num_slots': 2,\n",
      " 'penalty_mixture': 1.0,\n",
      " 'per_arm_layers': [64, 32, 16],\n",
      " 'policy_type': <RankingPolicyType.COSINE_DISTANCE: 1>}\n"
     ]
    }
   ],
   "source": [
    "AGENT_TYPE = \"Ranking\"\n",
    "NETWORK_TYPE = \"dotproduct\"\n",
    "POLICY_TYPE = ranking_agent.RankingPolicyType.COSINE_DISTANCE # COSINE_DISTANCE | NO_PENALTY | DESCENDING_SCORES\n",
    "\n",
    "PENALTY_MIXTURE = 1.0\n",
    "LOGITS_TEMPERATURE = 1.0\n",
    "\n",
    "LEARNING_RATE = 0.005\n",
    "\n",
    "GLOBAL_LAYERS   = [64, 32, 16]\n",
    "ARM_LAYERS      = [64, 32, 16]\n",
    "COMMON_LAYERS   = [16, 8]\n",
    "\n",
    "HPARAMS = {  # TODO - streamline and consolidate\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"eval_batch_size\" : EVAL_BATCH_SIZE,\n",
    "    \"num_items\": NUM_ITEMS,\n",
    "    \"num_slots\": NUM_SLOTS,\n",
    "    \"model_type\": AGENT_TYPE,\n",
    "    \"network_type\": NETWORK_TYPE,\n",
    "    \"global_layers\": GLOBAL_LAYERS,\n",
    "    \"per_arm_layers\": ARM_LAYERS,\n",
    "    \"common_layers\": COMMON_LAYERS,\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"policy_type\": POLICY_TYPE,\n",
    "    \"feedback_model\" : feedback_model,\n",
    "    \"penalty_mixture\": PENALTY_MIXTURE,\n",
    "    \"logits_temperature\": LOGITS_TEMPERATURE,\n",
    "}\n",
    "pprint(HPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "80d4e8a9-6582-425d-9c50-499aa883b2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network: GlobalAndArmDotProductNetwork\n"
     ]
    }
   ],
   "source": [
    "if NETWORK_TYPE == 'commontower':\n",
    "    scoring_network = global_and_arm_feature_network.create_feed_forward_common_tower_network(\n",
    "        observation_spec = observation_spec, \n",
    "        global_layers = GLOBAL_LAYERS, \n",
    "        arm_layers = ARM_LAYERS, \n",
    "        common_layers = COMMON_LAYERS,\n",
    "        # output_dim = output_dim,\n",
    "    )\n",
    "    \n",
    "elif NETWORK_TYPE == 'dotproduct':\n",
    "    scoring_network = global_and_arm_feature_network.create_feed_forward_dot_product_network(\n",
    "        observation_spec = observation_spec, \n",
    "        global_layers = GLOBAL_LAYERS, \n",
    "        arm_layers = ARM_LAYERS\n",
    "    )\n",
    "    \n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {scoring_network.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1939dc-7ee9-414c-aa89-85b08bcfb4cb",
   "metadata": {},
   "source": [
    "## Define Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5dad7dd6-3d19-4c79-8a72-078253f046e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank_agent: ranking_agent\n"
     ]
    }
   ],
   "source": [
    "rank_agent = ranking_agent.RankingAgent(\n",
    "    time_step_spec=time_step_spec,\n",
    "    action_spec=action_spec,\n",
    "    scoring_network=scoring_network,\n",
    "    optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=HPARAMS['learning_rate']),\n",
    "    feedback_model=ranking_agent.FeedbackModel.SCORE_VECTOR, # FeedbackModel.SCORE_VECTOR, # feedback_model,\n",
    "    policy_type=HPARAMS['policy_type'],\n",
    "    logits_temperature=HPARAMS['logits_temperature'],\n",
    "    penalty_mixture_coefficient=HPARAMS['penalty_mixture'],\n",
    "    summarize_grads_and_vars=True\n",
    ")\n",
    "\n",
    "rank_agent.initialize()\n",
    "\n",
    "print(f'rank_agent: {rank_agent.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a38e772e-80b8-4dfe-811d-83fae71c912c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(2,), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(2, dtype=int32))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_agent.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "735ef8c6-1854-4118-aa9f-3ba875a664b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_step_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1616e93e-7555-4a52-a7e1-f9b895873620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank_agent.time_step_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bff1a577-d86d-46d9-9071-0f10df0ca0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank_agent.training_data_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fd594bbd-383b-41a8-bc5e-317db5b93a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_agent.training_data_spec.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7c38d4d1-6baf-47c1-8da7-d8a08ee15bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank_agent.policy.action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "21e2f27b-79b6-4ce6-bf61-0e777db54d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}),\n",
       " 'reward': TensorSpec(shape=(2,), dtype=tf.float32, name='score_vector'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_agent.policy.time_step_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d6040423-c390-4e1a-90a9-69b9ab58b23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(Trajectory(\n",
       "{'action': BoundedTensorSpec(shape=(2,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(1, dtype=int32)),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}),\n",
       " 'policy_info': PolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=()),\n",
       " 'reward': TensorSpec(shape=(2,), dtype=tf.float32, name='score_vector'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_agent.policy.trajectory_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46435a9d-c901-4d32-8baa-1da60c427788",
   "metadata": {},
   "source": [
    "### Reward function\n",
    "\n",
    "**TODO**\n",
    "* `_create_ranking_reward_features`\n",
    "* `_get_rewards_from_arm_features` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "90b521c4-bb43-4cc5-b0fa-67d420b64834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_ranking_rewards_sv(x):\n",
    "    \"\"\"Calculates reward for the actions.\"\"\"\n",
    "    \n",
    "    # rating_scores_list = []\n",
    "    ratings_list = x[\"user_rating\"] #[0]\n",
    "    indices = tf.argsort(ratings_list, direction=\"DESCENDING\")\n",
    "    \n",
    "    feedback = tf.gather(ratings_list, indices, batch_dims=-1) #.numpy()\n",
    "    \n",
    "    # feedback = tf.math.top_k(feedback, k=HPARAMS['num_slots']).values\n",
    "    top_n_ratings = tf.slice(feedback, begin=[0, 0], size=[-1, HPARAMS['num_slots']])\n",
    "    \n",
    "    return top_n_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "997dbdd4-7048-4d9f-8f65-f5e99a28ef1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[4., 3.],\n",
       "       [5., 4.]], dtype=float32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ratings = _get_ranking_rewards_sv(data)\n",
    "test_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "31976a8d-c4ba-4fc1-a429-e24f812aac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rank_trajectory_fn(element): # hparams\n",
    "    \"\"\"Converts a dataset element into a trajectory.\"\"\"\n",
    "    # global_features = _get_global_context_features(element)\n",
    "    # arm_features = _get_per_arm_features(element)\n",
    "    \n",
    "    global_features = _get_global_context_features(element)\n",
    "    arm_features = _get_per_arm_features(element)\n",
    "    \n",
    "    # obs spec\n",
    "    observation = {\n",
    "        bandit_spec_utils.GLOBAL_FEATURE_KEY:\n",
    "            train_utils._add_outer_dimension(global_features),\n",
    "            # global_features,\n",
    "        bandit_spec_utils.PER_ARM_FEATURE_KEY: \n",
    "            train_utils._add_outer_dimension(arm_features)\n",
    "            # arm_features\n",
    "    }\n",
    "    \n",
    "    # reward = element['user_rating']\n",
    "    ranking_rewards = _get_ranking_rewards_sv(element)\n",
    "\n",
    "    \n",
    "    # action = np.zeros((HPARAMS['num_slots']), dtype=np.int32)\n",
    "    action=tf.zeros_like(HPARAMS['num_slots'], dtype=tf.int32)\n",
    "    \n",
    "    # discount = np.zeros((HPARAMS['num_slots']), dtype=np.float32)\n",
    "    discount=tf.zeros_like(HPARAMS['num_slots'], dtype=tf.int32)\n",
    "    return trajectory.single_step(\n",
    "        observation=observation,\n",
    "        action=action,\n",
    "        policy_info=(), #policy_info,\n",
    "        reward=ranking_rewards,\n",
    "        discount=discount\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c8221e8a-cdf2-4944-9856-6a2371d3f782",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in train_dataset.batch(HPARAMS['batch_size']).take(1):\n",
    "    test_traj = _rank_trajectory_fn(x)\n",
    "    \n",
    "# test_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "57fd5848-4d75-4fae-8cd7-0d7310562508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.observation.shape: (5, 1, 64)\n",
      "test_traj.observation.shape: (5, 1, 2, 64)\n",
      "test_traj.discount.shape   : ()\n",
      "expected_num_actions: 3\n",
      "predicted_rewards_mean: TensorSpec(shape=(3,), dtype=tf.float32, name=None)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.observation.shape: {test_traj.observation['global'].shape}\")\n",
    "print(f\"test_traj.observation.shape: {test_traj.observation['per_arm'].shape}\")\n",
    "print(f\"test_traj.discount.shape   : {test_traj.discount.shape}\") \n",
    "\n",
    "expected_num_actions = action_spec.maximum - action_spec.minimum + 1\n",
    "print(f\"expected_num_actions: {expected_num_actions}\")\n",
    "\n",
    "predicted_rewards_mean = tensor_spec.TensorSpec([expected_num_actions])\n",
    "print(f\"predicted_rewards_mean: {predicted_rewards_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f5ac56-3153-48e3-999a-a818ca673129",
   "metadata": {},
   "source": [
    "# Train Ranking Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "43cd93ee-4ed8-4b11-9350-5e606ccca87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : local-ranker-rec-bandits-v2\n",
      "RUN_NAME          : run-20231018-200554\n",
      "\n",
      "BASE_OUTPUT_DIR   : gs://rec-bandits-v2-hybrid-vertex-bucket/local-ranker-rec-bandits-v2/run-20231018-200554\n",
      "LOG_DIR           : gs://rec-bandits-v2-hybrid-vertex-bucket/local-ranker-rec-bandits-v2/run-20231018-200554/logs\n",
      "ROOT_DIR          : gs://rec-bandits-v2-hybrid-vertex-bucket/local-ranker-rec-bandits-v2/run-20231018-200554/root\n",
      "ARTIFACTS_DIR     : gs://rec-bandits-v2-hybrid-vertex-bucket/local-ranker-rec-bandits-v2/run-20231018-200554/artifacts\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME   = f'local-ranker-{PREFIX}'\n",
    "\n",
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "99169818-818e-4148-b045-25eded36f553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_agents version: 0.17.0\n",
      "tensorflow version: 2.13.0\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.policies import tf_policy\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.metrics import export_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.utils import common\n",
    "\n",
    "import tf_agents\n",
    "\n",
    "print(f\"tf_agents version: {tf_agents.__version__}\")\n",
    "print(f\"tensorflow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f7b1cc-a927-45c0-b64d-30a70250fb8d",
   "metadata": {},
   "source": [
    "### logs & checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e6f63092-48ba-4cb2-8ee4-9b30bd4c23c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent: ranking_agent\n",
      "agent: penalize_cosine_distance_ranking_policy\n"
     ]
    }
   ],
   "source": [
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "rank_agent.initialize()\n",
    "print(f'agent: {rank_agent.name}')\n",
    "print(f'agent: {rank_agent.policy.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dd893a5d-449e-4c21-b9fc-3cf5114dd2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('metrics: [<tf_agents.metrics.tf_metrics.AverageReturnMetric object at '\n",
      " '0x7f53cf1d7df0>]')\n",
      "setting checkpoint_manager: gs://rec-bandits-v2-hybrid-vertex-bucket/local-ranker-rec-bandits-v2/run-20231018-200554/root/chkpoint\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    f\"{LOG_DIR}\", flush_millis=10 * 1000\n",
    ")\n",
    "# train_summary_writer.set_as_default()\n",
    "\n",
    "# eval_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "#     f\"{LOG_DIR}/eval\", flush_millis=10 * 1000\n",
    "# )\n",
    "# ====================================================\n",
    "# metrics\n",
    "# ====================================================\n",
    "# `step_metric` records the number of individual rounds of bandit interaction;\n",
    "# that is, (number of trajectories) * batch_size\n",
    "step_metric = tf_metrics.EnvironmentSteps()\n",
    "\n",
    "if feedback_model == ranking_environment.FeedbackModel.SCORE_VECTOR:\n",
    "    reward_metric = tf_metrics.AverageReturnMetric(\n",
    "        batch_size=HPARAMS['batch_size'],\n",
    "        buffer_size=20\n",
    "    )\n",
    "else:\n",
    "    reward_metric = tf_metrics.AverageReturnMultiMetric(\n",
    "        reward_spec=environment.reward_spec(),\n",
    "        batch_size=HPARAMS['batch_size'],\n",
    "        buffer_size=20\n",
    "    )\n",
    "    \n",
    "metrics = [reward_metric]\n",
    "\n",
    "pprint(f\"metrics: {metrics}\")\n",
    "\n",
    "# ====================================================\n",
    "# get checkpoint manager\n",
    "# ====================================================\n",
    "CHKPOINT_DIR = f\"{ROOT_DIR}/chkpoint\"\n",
    "print(f\"setting checkpoint_manager: {CHKPOINT_DIR}\")\n",
    "\n",
    "checkpoint_manager = train_utils.restore_and_get_checkpoint_manager(\n",
    "    root_dir=CHKPOINT_DIR, \n",
    "    agent=rank_agent, \n",
    "    metrics=metrics, \n",
    "    step_metric=step_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e6e434-f8dd-43ac-8dfc-d6e5ceeb10d0",
   "metadata": {},
   "source": [
    "#### Saving Ranking Bandits\n",
    "\n",
    "> Note: [open issue](https://github.com/tensorflow/agents/issues/891) regarding saving ranking bandit models\n",
    "\n",
    "Until this is resolved, use the `checkpoint_manager` to restore the latest trained policy. \n",
    "\n",
    "More on this in the `Inference` section below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dd8bc05c-81f1-4919-9668-a0236f35a061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ====================================================\n",
    "# # policy saver\n",
    "# # ====================================================\n",
    "# saver = policy_saver.PolicySaver(\n",
    "#     policy = rank_agent.policy, \n",
    "#     # train_step=global_step\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4bb1d475-446e-498f-a4c1-a813de6352e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.bandits.policies.ranking_policy.PenalizeCosineDistanceRankingPolicy at 0x7f53cf1b3280>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = rank_agent.policy\n",
    "policy\n",
    "# isinstance(policy, tf_policy.TFPolicy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9ca1261c-7ed9-4661-a705-7b5d674a7ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "917"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9af553-9512-47e0-ae9d-d593139143e0",
   "metadata": {},
   "source": [
    "## Train config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "50ef435c-3d9b-432d-a5e2-ab5d60e93cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_DATA_SIZE : 900\n",
      "NUM_TRAIN_STEPS : 100\n",
      "EVAL_DATA_SIZE : 900\n",
      "NUM_EVAL_STEPS : 100\n",
      "CHKPT_INTERVAL: 99\n",
      "LOG_INTERVAL : 10\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA_SIZE = 900          # len(list(train_dataset))\n",
    "NUM_TRAIN_STEPS = 100            # TRAIN_DATA_SIZE // HPARAMS['batch_size']\n",
    "\n",
    "EVAL_DATA_SIZE  = 900          # len(list(val_dataset))\n",
    "NUM_EVAL_STEPS  = 100           # EVAL_DATA_SIZE // HPARAMS['eval_batch_size']\n",
    "\n",
    "CHKPT_INTERVAL  = NUM_TRAIN_STEPS - 1 # // 5\n",
    "LOG_INTERVAL    = 10\n",
    "# EVAL_INTERVAL = NUM_TRAIN_STEPS // 2\n",
    "\n",
    "print(f\"TRAIN_DATA_SIZE : {TRAIN_DATA_SIZE}\")\n",
    "print(f\"NUM_TRAIN_STEPS : {NUM_TRAIN_STEPS}\")\n",
    "print(f\"EVAL_DATA_SIZE : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS : {NUM_EVAL_STEPS}\")\n",
    "print(f\"CHKPT_INTERVAL: {CHKPT_INTERVAL}\")\n",
    "print(f\"LOG_INTERVAL : {LOG_INTERVAL}\")\n",
    "# print(f\"EVAL_INTERVAL : {EVAL_INTERVAL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d4fa546c-bb88-4fef-976d-98b245ee842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "train_ds_iterator = iter(train_dataset.batch(HPARAMS['batch_size']))\n",
    "# train_ds_iterator = iter(train_dataset)\n",
    "\n",
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS[\"eval_batch_size\"])\n",
    "# eval_ds = val_dataset.batch(HPARAMS[\"batch_size\"])\n",
    "\n",
    "if NUM_EVAL_STEPS > 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)\n",
    "\n",
    "# eval_ds = eval_ds.prefetch(tf.data.AUTOTUNE)\n",
    "# eval_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4d8449-6285-478a-8876-3f67c47cc6be",
   "metadata": {},
   "source": [
    "[ranking_agent](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/agents/ranking_agent.py#L288C1-L310C8)\n",
    "\n",
    "```\n",
    "  def _loss(\n",
    "      self,\n",
    "      experience: types.NestedTensor,\n",
    "      weights: Optional[types.Tensor] = None,\n",
    "      training: bool = False,\n",
    "  ) -> tf_agent.LossInfo:\n",
    "    \"\"\"Computes loss for training the reward and constraint networks.\n",
    "\n",
    "    Args:\n",
    "      experience: A batch of experience data in the form of a `Trajectory` or\n",
    "        `Transition`.\n",
    "      weights: Optional scalar or elementwise (per-batch-entry) importance\n",
    "        weights.  The output batch loss will be scaled by these weights, and the\n",
    "        final scalar loss is the mean of these values.\n",
    "      training: Whether the loss is being used for training.\n",
    "\n",
    "    Returns:\n",
    "      A `LossInfo` containing the loss for the training step.\n",
    "\n",
    "    Raises:\n",
    "      ValueError:\n",
    "        if the number of actions is greater than 1.\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "adae35ea-e3ff-4245-8c34-739dc70dec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# train setp function\n",
    "# ====================================================\n",
    "@tf.function\n",
    "def _train_step_fn():\n",
    "\n",
    "    data = next(train_ds_iterator)\n",
    "    trajectories = _rank_trajectory_fn(data)\n",
    "    loss = rank_agent.train(experience=trajectories)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "032770fc-8c04-4d3f-af21-9938501a7c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting train loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/__autograph_generated_fileunvq05zn.py:14: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  retval_ = ag__.and_(lambda : ag__.ld(state) is not None, lambda : ag__.and_(lambda : ag__.ld(state) is not (), lambda : ag__.ld(state) is not []))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0: train loss = 17.40999984741211\n",
      "step = 10: train loss = 2.7699999809265137\n",
      "step = 20: train loss = 2.0299999713897705\n",
      "step = 30: train loss = 2.2300000190734863\n",
      "step = 40: train loss = 0.9100000262260437\n",
      "step = 50: train loss = 0.7900000214576721\n",
      "step = 60: train loss = 0.5600000023841858\n",
      "step = 70: train loss = 0.38999998569488525\n",
      "step = 80: train loss = 0.9700000286102295\n",
      "step = 90: train loss = 1.350000023841858\n",
      "saved policy to: gs://rec-bandits-v2-hybrid-vertex-bucket/local-ranker-rec-bandits-v2/run-20231018-200554/root/chkpoint\n",
      "train runtime_mins: 6\n"
     ]
    }
   ],
   "source": [
    "list_o_loss = []\n",
    "\n",
    "rank_agent.train_step_counter.assign(0)\n",
    "\n",
    "print(f\"starting train loop...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(NUM_TRAIN_STEPS):\n",
    "    \n",
    "    with train_summary_writer.as_default():\n",
    "\n",
    "        step = rank_agent.train_step_counter.numpy()\n",
    "        \n",
    "#         data = next(train_ds_iterator)\n",
    "#         trajectories = _rank_trajectory_fn(data)\n",
    "\n",
    "#         # All tensors in experience must be shaped [batch, time, ...] \n",
    "#         loss = rank_agent.train(experience=trajectories)\n",
    "\n",
    "        loss = _train_step_fn()\n",
    "        list_o_loss.append(loss.loss.numpy())\n",
    "        \n",
    "        train_utils._export_metrics_and_summaries(\n",
    "            step=i, \n",
    "            metrics=metrics\n",
    "        )\n",
    "        \n",
    "        # print step loss\n",
    "        if step % LOG_INTERVAL == 0:\n",
    "            print(\n",
    "                'step = {0}: train loss = {1}'.format(\n",
    "                    step, round(loss.loss.numpy(), 2)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if i > 0 and i % CHKPT_INTERVAL == 0:\n",
    "            checkpoint_manager.save()\n",
    "            # saver.save(os.path.join(CHKPOINT_DIR, 'policy_%d' % step_metric.result()))\n",
    "            print(f\"saved policy to: {CHKPOINT_DIR}\")\n",
    "            \n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"train runtime_mins: {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b818bc45-7a81-4cc8-974d-4da4f171b8d6",
   "metadata": {},
   "source": [
    "## Evaluate train job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "01e6207f-de75-4e93-b7e0-4e2fecbc6211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_o_loss)\n",
    "# plt.ylim([0, 10])\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3e6532-1bb5-4816-a37e-980074468239",
   "metadata": {},
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e657df42-b168-46f2-9b21-f99a91315a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/local-ranker-rec-bandits-v2/run-20231018-200554/logs/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/local-ranker-rec-bandits-v2/run-20231018-200554/logs/events.out.tfevents.1697659556.jt-tfa-bandit-rankers-2023-v2.2960816.1.v2\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls $LOG_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "6b5e10ef-9f79-4030-b863-c821b695b957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "85177c16-2b71-4be4-b378-59aa2cc8913a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-26e13d0fea06c846\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-26e13d0fea06c846\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=$LOG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265ca435-3e97-4d4e-b583-2f83040f041c",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "**Prediction response**\n",
    "> **TODO:** explain prediction response, e.g., `predicted_rewards_mean=array([3.1828353, 3.6808753]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "36d9b4d5-1ce0-4245-b0e5-a6c7e3135a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.bandits.policies.ranking_policy.PenalizeCosineDistanceRankingPolicy at 0x7f53cf1b3280>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_agent = rank_agent.policy\n",
    "deployment_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "977399bc-1d75-4dc2-bb2d-e7ff0a957a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.PyTFEagerPolicy at 0x7f52fda8d180>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(deployment_agent, use_tf_function=True)\n",
    "post_policy_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "891e9faf-b5d7-4ba7-bbe8-591b29819382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# post_policy_tf.policy_step_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ae476659-942d-4d79-af35-f27d5c7cbcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# post_policy_tf.time_step_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2c987585-7870-45a7-85dc-44c6a4f3b620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# post_policy_tf.trajectory_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a948171e-984a-46c7-871a-02fbfb67ee1b",
   "metadata": {},
   "source": [
    "## Get Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cf4fd4-6f7f-4505-b86e-49ee44fc66f8",
   "metadata": {},
   "source": [
    "To generate an inference request, we need to create a single [TimeStep](https://github.com/tensorflow/agents/blob/master/tf_agents/trajectories/time_step.py#L54C1-L64C3) with the following schema:\n",
    "\n",
    "```python\n",
    "class TimeStep(\n",
    "    NamedTuple(\n",
    "        'TimeStep',\n",
    "        [\n",
    "            ('step_type', types.SpecTensorOrArray),\n",
    "            ('reward', types.NestedSpecTensorOrArray),\n",
    "            ('discount', types.SpecTensorOrArray),\n",
    "            ('observation', types.NestedSpecTensorOrArray),\n",
    "        ],\n",
    "    )\n",
    "):\n",
    "```\n",
    "* the `infer_step` below is functionally equivalent to:\n",
    "\n",
    "```python\n",
    "prediction = post_policy_tf.action(\n",
    "    ts.restart(observation, batch_size=HPARAMS['eval_batch_size']), ()\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a627a3fa-890b-434c-8681-339327ec02f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "# dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "SKIP_NUM = 10\n",
    "\n",
    "for x in eval_ds.skip(SKIP_NUM).take(INFER_SIZE):\n",
    "    \n",
    "    # global context features\n",
    "    global_features = _get_global_context_features(x)\n",
    "    global_features = tf.reshape(global_features, [GLOBAL_DIM]) # flatten\n",
    "    \n",
    "    # TODO: pass   : NUM_ITEMS items to trained policy\n",
    "    #       return : ranking for NUM_SLOTS\n",
    "    arm_features = _get_per_arm_features(x)\n",
    "    arm_feat_infer = tf.reshape(arm_features, [ HPARAMS['num_slots'], HPARAMS['eval_batch_size'], PER_ARM_DIM ]) # perarm_dim\n",
    "    arm_feat_infer = train_utils._remove_outer_dimension(arm_feat_infer)\n",
    "    \n",
    "    # train observation\n",
    "    observation = {'global': global_features, 'per_arm': arm_feat_infer}\n",
    "    \n",
    "    ranking_rewards = _get_ranking_rewards_sv(x)\n",
    "    \n",
    "    action = np.zeros((HPARAMS['num_slots']), dtype=np.int32)\n",
    "    discount = np.zeros((HPARAMS['num_slots']), dtype=np.float32)\n",
    "    \n",
    "    infer_step = ts.TimeStep(\n",
    "        step_type = tf.constant(\n",
    "            ts.StepType.FIRST, \n",
    "            dtype=tf.int32, \n",
    "            shape=[],\n",
    "            name='step_type'\n",
    "        ),\n",
    "        reward = ranking_rewards,\n",
    "        discount = tf.constant(\n",
    "            1.0, dtype=tf.float32, shape=[], name='discount'\n",
    "        ),\n",
    "        observation = observation\n",
    "    )\n",
    "    \n",
    "    prediction = post_policy_tf.action(infer_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8990e512-7099-476d-bd55-44be8f49256b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array([0, 1], dtype=int32), state=(), info=PolicyInfo(log_probability=(), predicted_rewards_mean=array([4.618629 , 3.9566088], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=()))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "082cee1d-703e-4143-8c78-d1976a6d341c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6112efc7-3e76-46d4-902e-a7c009a1d13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.618629 , 3.9566088], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info.predicted_rewards_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0f915f18-b44d-4c20-8b14-4c97403be803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# infer_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ec5e5d29-62f7-43b7-9916-306bdce6e7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranking_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "abd5a80e-b1d4-466f-a950-af263d1a860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6066995c-5c9c-485c-96a2-973b65107471",
   "metadata": {},
   "source": [
    "### tmp - debugging\n",
    "\n",
    "> compare to prediction from infer_steps, where actual rewards are provided.. does this impact?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a2450fbd-ad0d-4270-a4db-d662c9ef09b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array([0, 1], dtype=int32), state=(), info=PolicyInfo(log_probability=(), predicted_rewards_mean=array([4.618629 , 3.9566088], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=()))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = post_policy_tf.action(\n",
    "    ts.restart(observation, batch_size=HPARAMS['eval_batch_size']), ()\n",
    ")\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bddd75a-21b0-4d09-9518-785246bd0a10",
   "metadata": {},
   "source": [
    "## Load a trained Ranking Bandit policy\n",
    "\n",
    "Here we'll show how to load a trained policy, as you would for a prediction endpoint. You need 3 objects to restore a trained policy from the last checkpoint:\n",
    "* **agent**: a tf-agents agent object following the same specs used during training\n",
    "* **metrics**: metrics tracked during training\n",
    "* **step metric**: `tf_metrics.EnvironmentSteps()` \n",
    "\n",
    "Becasue we already have these initialized in this notebook session, we can resuse them here and just pass the root folder of latest checkpoint (e.g., `CHKPOINT_DIR`)\n",
    "* this restores the `agent` object to reflect the checkpointed policy\n",
    "> Note: when restoring the checkpointed policy in a new environment, we'll need to also initialize the three python objects above\n",
    "\n",
    "Then, we wrap the loaded policy with [PyTFEagerPolicy()](https://www.tensorflow.org/agents/api_docs/python/tf_agents/policies/PyTFEagerPolicy) to use it in eager mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5ac794d1-b753-468e-9d3a-aee50620c910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/local-ranker-rec-bandits-v2/run-20231018-200554/root/chkpoint/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/local-ranker-rec-bandits-v2/run-20231018-200554/root/chkpoint/checkpoint\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/local-ranker-rec-bandits-v2/run-20231018-200554/root/chkpoint/ckpt-1.data-00000-of-00001\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/local-ranker-rec-bandits-v2/run-20231018-200554/root/chkpoint/ckpt-1.index\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $CHKPOINT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5e33ce02-664f-4d64-9405-90b368425862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank_agent\n",
    "# metrics\n",
    "# step_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2fecf83a-57b7-4fde-85bc-8f6f8a142816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint_management.CheckpointManager at 0x7f521030d960>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restore_policy = train_utils.restore_and_get_checkpoint_manager(\n",
    "      CHKPOINT_DIR, rank_agent, metrics, step_metric\n",
    "  )\n",
    "restore_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c5fe51de-a204-43c3-8ff6-cab00ae79908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.PyTFEagerPolicy at 0x7f52104fc400>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "deployment_agent = rank_agent.policy\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(deployment_agent, use_tf_function=True)\n",
    "post_policy_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e852bc-3af3-4bac-b107-d070eb93740b",
   "metadata": {},
   "source": [
    "#### Test inference with restored policy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e1a82da1-5db4-4b57-aa52-d7f674e4ea88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array([0, 1], dtype=int32), state=(), info=PolicyInfo(log_probability=(), predicted_rewards_mean=array([4.618629 , 3.9566088], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=()))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = post_policy_tf.action(\n",
    "    ts.restart(observation, batch_size=HPARAMS['eval_batch_size']), ()\n",
    ")\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f05ccfd-7263-40a7-813e-453ad90daad0",
   "metadata": {},
   "source": [
    "# Evaluation Loop\n",
    "\n",
    "> Evaluate the agent's policy after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "30e5df69-e6c0-4345-98cc-2a0d3d1abcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _levenshtein_distance(hypothesis, truth):\n",
    "    dist_tensor = tf.edit_distance(\n",
    "        tf.sparse.from_dense(tf.constant(hypothesis, dtype=tf.int32)),\n",
    "        tf.sparse.from_dense(tf.constant(truth, dtype=tf.int32)),\n",
    "    )\n",
    "    return dist_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "da61e837-0482-4cd6-b36e-22404ba732ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFER_SIZE = 1\n",
    "# dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "# SKIP_NUM = 10\n",
    "\n",
    "def evaluate_ranking(\n",
    "    candidate_ranking: np.ndarray,\n",
    "    data_samples: Dict[str, tf.Tensor],\n",
    "    batch_size: int,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \n",
    "    # logged rewards\n",
    "    # actual_rewards = _get_ranking_rewards_sv(data_samples)\n",
    "    inference_batch_size, _ = candidate_ranking.shape\n",
    "    print(f\"inference_batch_size: {inference_batch_size}\")\n",
    "    \n",
    "    # global_features = _get_global_context_features(data_samples)\n",
    "    # flat_global_infer = tf.reshape(global_features, [GLOBAL_DIM])\n",
    "    \n",
    "    # arm_features = _get_per_arm_features(data_samples)\n",
    "    # arm_feat_infer = tf.reshape(arm_features, [HPARAMS['num_slots'], HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    # arm_feat_infer = train_utils._remove_outer_dimension(arm_feat_infer)\n",
    "    \n",
    "    # observation = {'global': flat_global_infer, 'per_arm': arm_features}\n",
    "    \n",
    "    # get prediction\n",
    "    # pred_test = post_policy_tf.action(\n",
    "    #     ts.restart(observation, batch_size=inference_batch_size), ()\n",
    "    # )\n",
    "    \n",
    "    # rewards calc\n",
    "    optimal_ranking = np.argsort(actual_rewards)[:, ::-1][\n",
    "      :, :HPARAMS['num_slots']\n",
    "    ]\n",
    "    optimal_rewards = np.take(actual_rewards, optimal_ranking, axis=None)\n",
    "    candidate_ranking = prediction.info.predicted_rewards_mean\n",
    "    # candidate_ranking = candidate_ranking[:, :HPARAMS['num_slots']]\n",
    "    \n",
    "    actual_rewards_int = actual_rewards.numpy().astype(int)\n",
    "    valid_candidate_ranking_int = candidate_ranking.astype(int)\n",
    "    \n",
    "    batched_candidate_rewards = np.take(\n",
    "        actual_rewards_int, \n",
    "        valid_candidate_ranking_int,\n",
    "        axis=None\n",
    "    )\n",
    "    batched_rewards_diff = np.abs(optimal_rewards - batched_candidate_rewards)\n",
    "    batched_edit_dist = _levenshtein_distance(valid_candidate_ranking, optimal_ranking)\n",
    "    \n",
    "    return batched_rewards_diff, batched_edit_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "9e9781d8-fb68-4772-9561-570cacd35101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array([0, 1], dtype=int32), state=(), info=PolicyInfo(log_probability=(), predicted_rewards_mean=array([3.5218358, 3.5991795], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=()))"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c386576-8345-49f9-9eb1-7b83aabbc536",
   "metadata": {},
   "source": [
    "### tmp -debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a11d8137-d52f-49ed-9267-d9a40e44ba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_LOOP_BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b2e07d16-41ca-403e-a2dd-0bd9c7dad6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie_genres': <tf.Tensor: shape=(1, 3), dtype=int64, numpy=array([[3, 0, 0]])>,\n",
       " 'movie_id': <tf.Tensor: shape=(1, 3), dtype=string, numpy=array([[b'94', b'245', b'403']], dtype=object)>,\n",
       " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'346'], dtype=object)>,\n",
       " 'user_rating': <tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[3., 4., 3.]], dtype=float32)>}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    \n",
    "    iterator = iter(train_dataset.batch(EVAL_LOOP_BATCH_SIZE))\n",
    "    data = next(iterator)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "267036eb-8157-48a4-a413-78774b95811a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global shape : (1, 64)\n",
      "per_arm shape: (1, 2, 64)\n"
     ]
    }
   ],
   "source": [
    "global_features = _get_global_context_features(data)\n",
    "arm_features = _get_per_arm_features(data)\n",
    "\n",
    "observation = {'global': global_features, 'per_arm': arm_features}\n",
    "# observation = {\n",
    "#     'global': train_utils._add_outer_dimension(global_features), \n",
    "#     'per_arm': train_utils._add_outer_dimension(arm_features)\n",
    "# }\n",
    "print(f\"global shape : {observation['global'].shape}\")\n",
    "print(f\"per_arm shape: {observation['per_arm'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3a3c13c5-2310-4cc6-bc11-f3699ccee9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 64), dtype=float32, numpy=\n",
       "array([[-0.03763245, -0.03134408, -0.03013839, -0.02073256, -0.02715528,\n",
       "         0.03340855,  0.03647807, -0.00189767,  0.04697769,  0.00709448,\n",
       "        -0.03711182,  0.00252603, -0.0352978 , -0.01233221, -0.00518265,\n",
       "         0.01322826, -0.02511042, -0.04917243, -0.0058673 ,  0.01373788,\n",
       "        -0.04607867, -0.04854529,  0.01649073, -0.02633615,  0.03487164,\n",
       "        -0.02753892, -0.01247466, -0.04335777,  0.01681933,  0.01664496,\n",
       "         0.00685073, -0.00219759, -0.03107576, -0.01460776, -0.03411764,\n",
       "        -0.01686355, -0.03049396,  0.0227044 ,  0.01983554, -0.02619834,\n",
       "         0.0258412 ,  0.0134943 ,  0.0032429 , -0.00345822, -0.00692091,\n",
       "         0.04543713, -0.01839808,  0.01852553, -0.00302775, -0.03992827,\n",
       "        -0.03634677,  0.00243723, -0.03530606,  0.03298659, -0.00171708,\n",
       "        -0.03774018, -0.01813754,  0.03456208,  0.02867026, -0.04483645,\n",
       "        -0.00297464,  0.01042732,  0.00702989, -0.04469549],\n",
       "       [-0.01020818,  0.0203963 ,  0.03782905,  0.04259365,  0.03883089,\n",
       "         0.01513633, -0.04341742,  0.04280907, -0.01687434, -0.03803598,\n",
       "        -0.03476577, -0.0257284 ,  0.00540622,  0.04206529,  0.01691098,\n",
       "         0.02106353,  0.03780023,  0.01914278,  0.01268687, -0.02212795,\n",
       "         0.0497325 ,  0.01239011, -0.02221676, -0.01827216,  0.04054283,\n",
       "         0.04269342, -0.04910258,  0.04734648, -0.04832636,  0.04406605,\n",
       "        -0.00252738,  0.00890038, -0.01172165,  0.04488413,  0.04784555,\n",
       "        -0.04033741, -0.02281132,  0.02662319, -0.03772918, -0.0362082 ,\n",
       "        -0.01156131, -0.02120118,  0.01844202,  0.02179832, -0.01430397,\n",
       "         0.03169998, -0.01258159, -0.02852133,  0.00277523,  0.04502774,\n",
       "        -0.0332548 ,  0.04514119, -0.0104882 ,  0.01668752, -0.00065576,\n",
       "        -0.02984524,  0.01878712,  0.04776387, -0.01532439,  0.04177114,\n",
       "        -0.0025756 , -0.02670593, -0.03738177,  0.04541738]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation['per_arm'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b07d7b1-eb53-4de9-86bd-c6c546c71e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "461dab88-e1de-4a59-8ece-91af3a21705a",
   "metadata": {},
   "source": [
    "##### get arm rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ab07e4bb-3a4a-4505-881e-9b88e1e93cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_rewards_from_arm_features(\n",
    "    arm_features: Iterable[tf.Tensor],\n",
    ") -> tf.Tensor:\n",
    "    \n",
    "    return tf.math.reduce_prod(\n",
    "        [tf.cast(arm_feature, tf.float32) for arm_feature in arm_features], 0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a0dd9964-d967-414b-b21a-05ae1c425fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
       "array([ 3.84158804e-04, -6.39303355e-04, -1.14010635e-03, -8.83075234e-04,\n",
       "       -1.05446368e-03,  5.05682721e-04, -1.58378365e-03, -8.12375074e-05,\n",
       "       -7.92717270e-04, -2.69845477e-04,  1.29022088e-03, -6.49908179e-05,\n",
       "       -1.90827792e-04, -5.18758083e-04, -8.76436316e-05,  2.78633961e-04,\n",
       "       -9.49179695e-04, -9.41296981e-04, -7.44377321e-05, -3.03991197e-04,\n",
       "       -2.29160720e-03, -6.01481705e-04, -3.66370659e-04,  4.81218332e-04,\n",
       "        1.41379505e-03, -1.17573084e-03,  6.12537842e-04, -2.05283775e-03,\n",
       "       -8.12817132e-04,  7.33477471e-04, -1.73143890e-05, -1.95593548e-05,\n",
       "        3.64259176e-04, -6.55656855e-04, -1.63237727e-03,  6.80231780e-04,\n",
       "        6.95607509e-04,  6.04463508e-04, -7.48378807e-04,  9.48594767e-04,\n",
       "       -2.98758212e-04, -2.86095135e-04,  5.98056140e-05, -7.53834684e-05,\n",
       "        9.89965192e-05,  1.44035625e-03,  2.31477083e-04, -5.28372824e-04,\n",
       "       -8.40269604e-06, -1.79787958e-03,  1.20870466e-03,  1.10019646e-04,\n",
       "        3.70297028e-04,  5.50464552e-04,  1.12599048e-06,  1.12636469e-03,\n",
       "       -3.40752071e-04,  1.65081862e-03, -4.39354335e-04, -1.87286967e-03,\n",
       "        7.66148059e-06, -2.78471271e-04, -2.62789748e-04, -2.02995189e-03],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arm_feat_test = observation['per_arm'][0]\n",
    "\n",
    "unmasked_rewards = _get_rewards_from_arm_features(\n",
    "    arm_feat_test\n",
    ")\n",
    "\n",
    "unmasked_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "acc8f83b-960d-4e93-9c01-44d9576577bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64]"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_arms_test = unmasked_rewards.get_shape().as_list()\n",
    "num_arms_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "630d6a4e-84f3-4d28-b310-6020ccd247cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[4., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_rewards = _get_ranking_rewards_sv(data)\n",
    "actual_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "78e07bf5-e809-427b-bde3-c017a4d80d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# actual_rewards.numpy()\n",
    "actual_rewards.get_shape().as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d860b351-b338-4b88-a934-e0d3dd2f4452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=bool, numpy=array([[ True,  True]])>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_arms=2\n",
    "num_slots=2\n",
    "\n",
    "mask = tf.expand_dims(tf.range(num_arms), axis=0) < tf.expand_dims(\n",
    "    num_slots, axis=-1\n",
    ")\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8c22cb7e-f54c-4dd5-b707-f2cd2b0de045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_rewards_from_input_features(\n",
    "    data: Dict[str, tf.Tensor],\n",
    "    num_slots: int,\n",
    ") -> tf.Tensor:\n",
    "    \n",
    "    # arm_feature_tensors = input_features['per_arm']\n",
    "    unmasked_rewards = _get_ranking_rewards_sv(data)\n",
    "    \n",
    "    _, num_arms = unmasked_rewards.get_shape().as_list()\n",
    "    mask = tf.expand_dims(tf.range(num_arms), axis=0) < tf.expand_dims(\n",
    "        num_slots, axis=1\n",
    "    )\n",
    "    masked_rewards = tf.where(mask, unmasked_rewards, float('-5000000'))\n",
    "    \n",
    "    return masked_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3d9f8f13-a7a3-4815-b54c-4f4cba92511d",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__ExpandDims_device_/job:localhost/replica:0/task:0/device:GPU:0}} Tried to expand dim index 1 for tensor with 0 dimensions. [Op:ExpandDims] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[129], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m unranked_rewards \u001b[38;5;241m=\u001b[39m \u001b[43m_get_rewards_from_input_features\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_slots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHPARAMS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_slots\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m unranked_rewards\n",
      "Cell \u001b[0;32mIn[128], line 12\u001b[0m, in \u001b[0;36m_get_rewards_from_input_features\u001b[0;34m(input_features, num_slots)\u001b[0m\n\u001b[1;32m      8\u001b[0m unmasked_rewards \u001b[38;5;241m=\u001b[39m _get_rewards_from_arm_features(\n\u001b[1;32m      9\u001b[0m     arm_feature_tensors\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m _, num_arms \u001b[38;5;241m=\u001b[39m unmasked_rewards\u001b[38;5;241m.\u001b[39mget_shape()\u001b[38;5;241m.\u001b[39mas_list()\n\u001b[0;32m---> 12\u001b[0m mask \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(tf\u001b[38;5;241m.\u001b[39mrange(num_arms), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_slots\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m masked_rewards \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mwhere(mask, unmasked_rewards, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-5000000\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m masked_rewards\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:6656\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6654\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   6655\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 6656\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__ExpandDims_device_/job:localhost/replica:0/task:0/device:GPU:0}} Tried to expand dim index 1 for tensor with 0 dimensions. [Op:ExpandDims] name: "
     ]
    }
   ],
   "source": [
    "unranked_rewards = _get_rewards_from_input_features(\n",
    "    input_features=observation, \n",
    "    num_slots=HPARAMS['num_slots']\n",
    ")\n",
    "\n",
    "unranked_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "c0a00f1e-02a0-4959-9f48-65f065b9ef3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arm_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "dde71a67-3da7-4ecc-b83d-efc61223594d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[4., 3.],\n",
       "       [5., 4.]], dtype=float32)>"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_rewards = _get_ranking_rewards_sv(data)\n",
    "actual_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "fca8019e-d552-4504-87fe-72f19294f5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_batch_size = actual_rewards.shape[0]\n",
    "inference_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "fc0a7a28-502f-4865-898d-67758cc8a5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'action': BoundedArraySpec(shape=(2,), dtype=dtype('int32'), name=None, minimum=0, maximum=1),\n",
       " 'discount': BoundedArraySpec(shape=(), dtype=dtype('float32'), name='discount', minimum=0.0, maximum=1.0),\n",
       " 'next_step_type': ArraySpec(shape=(), dtype=dtype('int32'), name='step_type'),\n",
       " 'observation': DictWrapper({'global': ArraySpec(shape=(64,), dtype=dtype('float32'), name=None), 'per_arm': ArraySpec(shape=(2, 64), dtype=dtype('float32'), name=None)}),\n",
       " 'policy_info': PolicyInfo(log_probability=(), predicted_rewards_mean=ArraySpec(shape=(2,), dtype=dtype('float32'), name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=()),\n",
       " 'reward': ArraySpec(shape=(2,), dtype=dtype('float32'), name='score_vector'),\n",
       " 'step_type': ArraySpec(shape=(), dtype=dtype('int32'), name='step_type')})"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_policy_tf.trajectory_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "867f4f06-9297-4dd5-bfe8-a21f76bd1408",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 7 but is rank 3 for '{{node PlackettLuce/sample/Tile}} = Tile[T=DT_FLOAT, Tmultiples=DT_INT32](PlackettLuce/sample/GatherV2, PlackettLuce/sample/Tile/multiples)' with input shapes: [1,2,1,1,1,2,64], [3].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[388], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred_test \u001b[38;5;241m=\u001b[39m \u001b[43mpost_policy_tf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestart\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_batch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m pred_test\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/policies/py_policy.py:161\u001b[0m, in \u001b[0;36mPyPolicy.action\u001b[0;34m(self, time_step, policy_state, seed)\u001b[0m\n\u001b[1;32m    159\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_action(time_step, policy_state, seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/policies/py_tf_eager_policy.py:104\u001b[0m, in \u001b[0;36mPyTFEagerPolicyBase._action\u001b[0;34m(self, time_step, policy_state, seed)\u001b[0m\n\u001b[1;32m    102\u001b[0m   policy_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy_action_fn(time_step, policy_state, seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m   policy_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_policy_action_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_time_steps:\n\u001b[1;32m    106\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m policy_step\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/policies/tf_policy.py:324\u001b[0m, in \u001b[0;36mTFPolicy.action\u001b[0;34m(self, time_step, policy_state, seed)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_automatic_state_reset:\n\u001b[1;32m    323\u001b[0m   policy_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_reset_state(time_step, policy_state)\n\u001b[0;32m--> 324\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[43maction_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclip_action\u001b[39m(action, action_spec):\n\u001b[1;32m    327\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(action_spec, tensor_spec\u001b[38;5;241m.\u001b[39mBoundedTensorSpec):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/utils/common.py:188\u001b[0m, in \u001b[0;36mfunction_in_tf1.<locals>.maybe_wrap.<locals>.with_check_resource_vars\u001b[0;34m(*fn_args, **fn_kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m check_tf1_allowed()\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_eager_been_enabled():\n\u001b[1;32m    186\u001b[0m   \u001b[38;5;66;03m# We're either in eager mode or in tf.function mode (no in-between); so\u001b[39;00m\n\u001b[1;32m    187\u001b[0m   \u001b[38;5;66;03m# autodep-like behavior is already expected of fn.\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m resource_variables_enabled():\n\u001b[1;32m    190\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(MISSING_RESOURCE_VARIABLES_ERROR)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/policies/tf_policy.py:561\u001b[0m, in \u001b[0;36mTFPolicy._action\u001b[0;34m(self, time_step, policy_state, seed)\u001b[0m\n\u001b[1;32m    559\u001b[0m seed_stream \u001b[38;5;241m=\u001b[39m tfp\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mSeedStream(seed\u001b[38;5;241m=\u001b[39mseed, salt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf_agents_tf_policy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    560\u001b[0m distribution_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution(time_step, policy_state)  \u001b[38;5;66;03m# pytype: disable=wrong-arg-types\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m actions \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreparameterized_sampling\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m info \u001b[38;5;241m=\u001b[39m distribution_step\u001b[38;5;241m.\u001b[39minfo\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memit_log_probability:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/policies/tf_policy.py:562\u001b[0m, in \u001b[0;36mTFPolicy._action.<locals>.<lambda>\u001b[0;34m(d)\u001b[0m\n\u001b[1;32m    559\u001b[0m seed_stream \u001b[38;5;241m=\u001b[39m tfp\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mSeedStream(seed\u001b[38;5;241m=\u001b[39mseed, salt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf_agents_tf_policy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    560\u001b[0m distribution_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution(time_step, policy_state)  \u001b[38;5;66;03m# pytype: disable=wrong-arg-types\u001b[39;00m\n\u001b[1;32m    561\u001b[0m actions \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[0;32m--> 562\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m d: \u001b[43mreparameterized_sampling\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    563\u001b[0m     distribution_step\u001b[38;5;241m.\u001b[39maction)\n\u001b[1;32m    564\u001b[0m info \u001b[38;5;241m=\u001b[39m distribution_step\u001b[38;5;241m.\u001b[39minfo\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memit_log_probability:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/distributions/reparameterized_sampling.py:50\u001b[0m, in \u001b[0;36msample\u001b[0;34m(distribution, reparam, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m distribution\u001b[38;5;241m.\u001b[39mconvert_to_one_hot(samples)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:1205\u001b[0m, in \u001b[0;36mDistribution.sample\u001b[0;34m(self, sample_shape, seed, name, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate samples of the specified shape.\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03mNote that a call to `sample()` without arguments will generate a single\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;124;03m  samples: a `Tensor` with prepended dimensions `sample_shape`.\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_and_control_scope(name):\n\u001b[0;32m-> 1205\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_sample_n\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:1182\u001b[0m, in \u001b[0;36mDistribution._call_sample_n\u001b[0;34m(self, sample_shape, seed, **kwargs)\u001b[0m\n\u001b[1;32m   1178\u001b[0m sample_shape \u001b[38;5;241m=\u001b[39m ps\u001b[38;5;241m.\u001b[39mconvert_to_shape_tensor(\n\u001b[1;32m   1179\u001b[0m     ps\u001b[38;5;241m.\u001b[39mcast(sample_shape, tf\u001b[38;5;241m.\u001b[39mint32), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1180\u001b[0m sample_shape, n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_sample_shape_to_vector(\n\u001b[1;32m   1181\u001b[0m     sample_shape, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1182\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample_n\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1184\u001b[0m samples \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m   1185\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: tf\u001b[38;5;241m.\u001b[39mreshape(x, ps\u001b[38;5;241m.\u001b[39mconcat([sample_shape, ps\u001b[38;5;241m.\u001b[39mshape(x)[\u001b[38;5;241m1\u001b[39m:]], \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m   1186\u001b[0m     samples)\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_sample_static_shape(samples, sample_shape, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/bandits/policies/ranking_policy.py:82\u001b[0m, in \u001b[0;36mPenalizedPlackettLuce._sample_n\u001b[0;34m(self, n, seed)\u001b[0m\n\u001b[1;32m     80\u001b[0m   slots\u001b[38;5;241m.\u001b[39mappend(items)\n\u001b[1;32m     81\u001b[0m   logits \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mone_hot(items, sample_shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], on_value\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39minf)\n\u001b[0;32m---> 82\u001b[0m   logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_penalizer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslots\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m sample \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(tf\u001b[38;5;241m.\u001b[39mstack(slots, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sample\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/bandits/policies/ranking_policy.py:109\u001b[0m, in \u001b[0;36mCosinePenalizedPlackettLuce._penalizer_fn\u001b[0;34m(self, logits, features, slots)\u001b[0m\n\u001b[1;32m    102\u001b[0m slotted_features \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m    103\u001b[0m     features, tf\u001b[38;5;241m.\u001b[39mminimum(slot_tensor, num_items \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m), batch_dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# Calculate the similarity between all pairs from\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# `slotted_features x all_features`.\u001b[39;00m\n\u001b[1;32m    107\u001b[0m all_sims \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mcosine_similarity(\n\u001b[1;32m    108\u001b[0m     tf\u001b[38;5;241m.\u001b[39mrepeat(features, num_slotted, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m--> 109\u001b[0m     \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslotted_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    111\u001b[0m sim_matrix \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(all_sims, shape\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, num_items, num_slotted])\n\u001b[1;32m    112\u001b[0m similarity_boosts \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_min(sim_matrix, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape must be rank 7 but is rank 3 for '{{node PlackettLuce/sample/Tile}} = Tile[T=DT_FLOAT, Tmultiples=DT_INT32](PlackettLuce/sample/GatherV2, PlackettLuce/sample/Tile/multiples)' with input shapes: [1,2,1,1,1,2,64], [3]."
     ]
    }
   ],
   "source": [
    "pred_test = post_policy_tf.action(\n",
    "    ts.restart(observation, batch_size=inference_batch_size), ()\n",
    ")\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f717b7a1-f8be-4b96-ba54-bc728706ba58",
   "metadata": {},
   "source": [
    "### tmp - debugging cascade feedback\n",
    "\n",
    "_get_rewards_from_arm_features()\n",
    "\n",
    "* Computes the reward for each arm based on the arm's features.\n",
    "* NOTE: The reward for an arm is simply the product of its features.\n",
    "\n",
    "_get_rewards_from_input_features()\n",
    "* Computes rewards from the input (that is, context and arm features).\n",
    "* The reward for each arm depends only on the arm features (and not the context features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d869d79-a5cb-43ff-942a-c94ede9c1d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _get_rewards_from_arm_features(\n",
    "  self, arm_features: Iterable[tf.Tensor]\n",
    ") -> tf.Tensor:\n",
    "\"\"\"Computes the reward for each arm based on the arm's features.\n",
    "\n",
    "NOTE: The reward for an arm is simply the product of its features.\n",
    "\n",
    "Args:\n",
    "  arm_features: 2-dimensional tensors [t_0, t_1, ..., t_{n-1}], where\n",
    "    t_j[batch_id, i] represents the jth feature of the ith arm.\n",
    "\n",
    "Returns:\n",
    "  A 2-dimensional tensor `r` of size (batch_size, num_arms), where\n",
    "  r[batch_id, i] corresponds to the reward for selecting the ith arm in\n",
    "  batch `batch_id`.\n",
    "\"\"\"\n",
    "return tf.math.reduce_prod(\n",
    "    [tf.cast(arm_feature, tf.float32) for arm_feature in arm_features], 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2142f91-b0ed-443c-bffa-83b931f37f07",
   "metadata": {},
   "source": [
    "### tmp - debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99f3c84-8928-415f-b1b2-17c2171847f0",
   "metadata": {},
   "source": [
    "#### actual predictions & optimal rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "e7661cad-e3cd-45dd-a435-551cec2fe2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[4., 3.],\n",
       "       [5., 4.]], dtype=float32)>"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_rewards = _get_ranking_rewards_sv(data)\n",
    "actual_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "7ea60997-803c-41f2-8f7a-db22b88785ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_batch_size, _ = actual_rewards.shape\n",
    "inference_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "7a0dbd2e-0f00-495b-a487-b68b5d9e3821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_ranking = np.argsort(actual_rewards)[:, ::-1][\n",
    "  :, :HPARAMS['num_slots']\n",
    "]\n",
    "optimal_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0246a2e7-eb0c-4e89-9c63-8921c0860f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_rewards = np.take(actual_rewards, optimal_ranking, axis=None)\n",
    "optimal_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11ec36f-c51e-4d39-b3e3-6992884895b9",
   "metadata": {},
   "source": [
    "#### candidate predictions & rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "07ca75e2-2b65-481f-9236-31fea3f8650b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.5218358, 3.5991795],\n",
       "       [3.5218358, 3.5991795]], dtype=float32)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_rewards = prediction.info.predicted_rewards_mean\n",
    "candidate_rewards = np.stack((candidate_rewards,candidate_rewards))\n",
    "candidate_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de892b5-90cb-49d0-8a78-1acdfada7323",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_ranking = np.argsort(candidate_rewards)[:, ::-1][\n",
    "  :, :HPARAMS['num_slots']\n",
    "]\n",
    "candidate_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "59da27af-157f-4adb-97b9-b4967d825b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.5218358, 3.5991795],\n",
       "       [3.5218358, 3.5991795]], dtype=float32)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_candidate_ranking = candidate_rewards[:, :HPARAMS['num_slots']]\n",
    "valid_candidate_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "84904412-a910-46a3-a21f-9dc32d800d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_valid_indices = tf.math.minimum(HPARAMS['num_slots'], HPARAMS['num_slots'])\n",
    "# num_valid_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "21e35cee-b0ee-4067-885e-144ad9c2554f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 3.],\n",
       "       [4., 3.]], dtype=float32)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimal_rewards = np.take(actual_rewards, optimal_ranking, axis=None)\n",
    "# optimal_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "fe03006a-8f19-45b1-b988-53fcbe20e7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 3],\n",
       "       [5, 4]])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = map(lambda x: float(x),actual_rewards)\n",
    "actual_rewards_test = actual_rewards.numpy().astype(int)\n",
    "actual_rewards_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "47832975-d2b6-4611-bd74-dd99ff22ce43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actual_rewards_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "bc7df6df-6932-450d-9a94-428a4b6ca12b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 3],\n",
       "       [3, 3]])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b = map(float,valid_candidate_ranking)\n",
    "valid_candidate_ranking_test = valid_candidate_ranking.astype(int)\n",
    "valid_candidate_ranking_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "6005e40f-85c0-40b0-b831-43be11b7156c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_candidate_ranking_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c47c9c-3f49-4e93-9277-2d018570ec3d",
   "metadata": {},
   "source": [
    "#### batched candidate rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "c0f44b94-998c-43c2-b1c4-1443a5083ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 4],\n",
       "       [4, 4]])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = map(float,a)\n",
    "# b = map(float,b)\n",
    "\n",
    "batched_candidate_rewards = np.take(\n",
    "    actual_rewards_test, valid_candidate_ranking_test,axis=None\n",
    ")\n",
    "batched_candidate_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e31c47f-61f3-4656-83ae-c6780dd1d831",
   "metadata": {},
   "source": [
    "#### metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "907c1573-cccd-422f-911e-06c5cb8e6ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_rewards_diff = np.abs(optimal_rewards - batched_candidate_rewards)\n",
    "batched_rewards_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "831750b7-e5f6-4657-b1ac-82cf1ada544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _levenshtein_distance(hypothesis, truth):\n",
    "    dist_tensor = tf.edit_distance(\n",
    "        tf.sparse.from_dense(tf.constant(hypothesis, dtype=tf.int32)),\n",
    "        tf.sparse.from_dense(tf.constant(truth, dtype=tf.int32)),\n",
    "    )\n",
    "    return dist_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "a8962bfd-9a0a-41f1-8667-a9c685719023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 2.], dtype=float32)>"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_levenshtein_distance(valid_candidate_ranking, optimal_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "940e8a03-b696-4ece-b7f7-ca377425fbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_random_ranking(\n",
    "    num_ranked_items: int, num_allowed_values: int, batch_size: int\n",
    "):\n",
    "    \"\"\"Returns a batch of `batch_size` rankings each of length `num_ranked_items`.\n",
    "\n",
    "    1. If `num_ranked_items` is no greater than `num_allowed_values`, each ranking\n",
    "    is a subset of [0, 1, ..., num_allowed_values - 1], of size\n",
    "    `num_ranked_items`.\n",
    "    2. If `num_ranked_items` is greater than `num_allowed_values`, the first\n",
    "    `num_allowed_values` of each ranking is a permutation of\n",
    "    [0, 1, ... num_allowed_values - 1]. The remaining `num_ranked_items -\n",
    "    num_allowed_values` of the ranking are unspecified.\n",
    "\n",
    "    Args:\n",
    "    num_ranked_items: the expected number of items in the output ranking, as\n",
    "      specified in the study config.\n",
    "    num_allowed_values: the number of items to select from.\n",
    "    batch_size: the number of batches of random rankings to return.\n",
    "    \"\"\"\n",
    "    num_valid_indices = min(num_ranked_items, num_allowed_values)\n",
    "    ranking = np.full(\n",
    "        (batch_size, num_ranked_items), np.iinfo(np.int32).max, dtype=np.int32\n",
    "    )\n",
    "    for idx in range(batch_size):\n",
    "        ranking[idx, :num_valid_indices] = np.random.choice(\n",
    "            num_allowed_values, size=num_valid_indices, replace=False\n",
    "        )\n",
    "    return ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "1de89282-54f3-470c-b833-f2ff46a1b223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [2, 0],\n",
       "       [1, 0],\n",
       "       [0, 2]], dtype=int32)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_rank_batch = _create_random_ranking(\n",
    "    num_ranked_items=HPARAMS['num_slots'],\n",
    "    num_allowed_values=HPARAMS['num_items'],\n",
    "    batch_size=HPARAMS['batch_size']\n",
    ")\n",
    "rand_rank_batch"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
