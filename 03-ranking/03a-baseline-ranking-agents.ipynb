{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f462e3ae-0544-4a09-8345-01fc822192f0",
   "metadata": {},
   "source": [
    "# Contextual Bandits for Ranking with TF-Agents\n",
    "\n",
    "> see [ranking tutorial](https://www.tensorflow.org/agents/tutorials/ranking_tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214b2409-ca72-4a2f-972b-32185fbf441c",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "* The contextual bandits approach is classified as an extension of multi-armed bandits\n",
    "* a contextual multi-armed banded problem is a simplified reinforcement learning algorithm where the agent takes an action from a set of possible actions \n",
    "\n",
    "> **TODO**\n",
    "\n",
    "The **Bandit Ranking** agent will be similar to the `NeuralEpsilonGreedy` agent. Main differences:\n",
    "\n",
    "* The item features are stored in the `per_arm` part of the observation, in the order of how they are recommended\n",
    "* Since this ordered list of items expresses what action was taken by the policy,\n",
    "the `action` value of the trajectory is not used by the agent.\n",
    "\n",
    "> Note: difference between the \"per-arm\" observation recieved by the policy vs the agent:\n",
    "\n",
    "While the agent receives the items in the recommendation slots, the policy receives the items that are available for recommendation. The user is responsible for converting the observation to the\n",
    "syntax required by the agent.\n",
    "\n",
    "\n",
    "The training observation contains the global features and the features of the items in the recommendation slots \n",
    "* The item features are stored in the `per_arm` part of the observation, in the order of how they are recommended\n",
    "* Note: since this ordered list of items expresses what action was taken by the policy, the action value of the trajectory is not used by the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce53b012-c8db-4874-90bc-e13ac83fae19",
   "metadata": {},
   "source": [
    "## Load notebook config\n",
    "\n",
    "* use the prefix defined in `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "056b54b6-79d5-4ed6-b94a-6a776fc7db36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "VERSION        = \"v2\"                       # TODO\n",
    "PREFIX         = f'rec-bandits-{VERSION}'   # TODO\n",
    "\n",
    "# PREFIX = 'mabv1'\n",
    "\n",
    "print(f\"PREFIX: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d3596a1-670b-4974-b643-2079a5db0afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"rec-bandits-v2\"\n",
      "VERSION                  = \"v2\"\n",
      "\n",
      "BUCKET_NAME              = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_ID      = \"hybrid_vertex.movielens_ds_rec_bandits_v2\"\n",
      "BIGQUERY_TABLE_ID        = \"hybrid_vertex.movielens_ds_rec_bandits_v2.training_dataset\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-rec-bandits-v2\"\n",
      "IMAGE_NAME               = \"train-perarm-feats-v2\"\n",
      "DOCKERNAME               = \"Dockerfile_perarm_feats\"\n",
      "\n",
      "IMAGE_URI_01             = \"gcr.io/hybrid-vertex/train-perarm-feats-v2-01\"\n",
      "IMAGE_URI_02             = \"gcr.io/hybrid-vertex/train-perarm-feats-v2-02\"\n",
      "\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/train-perarm-feats-v2\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940507dd-369b-4b93-a0c5-4b2d0e079269",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4fec363-3a69-4fc6-ab38-706230fba418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70e611f2-2d75-4b8d-9c9b-3b4421f8e04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/03-ranking\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93b706f8-8739-426b-b3c0-49c5ae2163f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from collections import defaultdict\n",
    "from typing import Callable, Dict, List, Optional, TypeVar, Iterable, Tuple\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "# from tf_agents.agents import TFAgent\n",
    "\n",
    "# from tf_agents.bandits.environments import stationary_stochastic_per_arm_py_environment as p_a_env\n",
    "from tf_agents.bandits.environments.ranking_environment import FeedbackModel\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "# from tf_agents.drivers import dynamic_step_driver\n",
    "# from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "# from tf_agents.bandits.agents import lin_ucb_agent\n",
    "# from tf_agents.bandits.agents import linear_thompson_sampling_agent as lin_ts_agent\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent\n",
    "from tf_agents.bandits.agents import neural_linucb_agent\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "from tf_agents.bandits.policies import policy_utilities\n",
    "\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.bandits.environments import ranking_environment\n",
    "from tf_agents.bandits.agents import ranking_agent\n",
    "\n",
    "from tf_agents.utils import nest_utils\n",
    "from tf_agents.specs import array_spec\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# this repo\n",
    "from src.per_arm_rl import data_utils\n",
    "from src.per_arm_rl import data_config\n",
    "from src.per_arm_rl import train_utils as train_utils\n",
    "\n",
    "from src.per_arm_rl import utils_config as utils_config\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5bc92e4-dac3-468e-a0f5-26d48ec63620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d4c0818-64e0-4629-a9d8-2fed58a7086f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28167f0d-5870-40bb-ba1e-b4a2cc4bd7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b249f6-2e74-4e2a-bf04-be4bfd0732bd",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c726bc2-ff41-41b0-9671-113a499e55d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de644e7f-8a6b-4c64-858f-1618fc76e373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT: listwise-3n-val\n"
     ]
    }
   ],
   "source": [
    "# 3 | 5\n",
    "NUM_EXAMPLES_PER_LIST = utils_config.NUM_EXAMPLES_PER_LIST\n",
    "\n",
    "# SPLIT = \"val\"\n",
    "# SPLIT = \"listwise-val\"\n",
    "SPLIT = f\"listwise-{NUM_EXAMPLES_PER_LIST}n-val\"\n",
    "\n",
    "print(f\"SPLIT: {SPLIT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56222181-f72a-4a9c-946e-5cd94ab40caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/listwise-3n-val/ml-100k-listwise-3n-val.tfrecord\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls $BUCKET_URI/$DATA_GCS_PREFIX/$SPLIT/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b22408a-fbfc-4b56-8f4b-b12462329fd3",
   "metadata": {},
   "source": [
    "### Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8afaa02e-5638-40a8-964e-e51b27d433d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_genres': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([3, 0, 0])>,\n",
      " 'movie_id': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'94', b'245', b'403'], dtype=object)>,\n",
      " 'user_id': <tf.Tensor: shape=(), dtype=string, numpy=b'346'>,\n",
      " 'user_rating': <tf.Tensor: shape=(3,), dtype=float32, numpy=array([3., 4., 3.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "# SPLIT = \"val\"\n",
    "# SPLIT = \"listwise-val\"\n",
    "SPLIT = f\"listwise-{NUM_EXAMPLES_PER_LIST}n-val\"\n",
    "\n",
    "val_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        val_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "val_dataset = tf.data.TFRecordDataset(val_files)\n",
    "val_dataset = val_dataset.map(data_utils.parse_lw_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "for example in val_dataset.take(1):\n",
    "    pprint(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46862c4-dcbb-4b2d-aa53-765204f79250",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e814c64-1c96-47fd-a0f4-4c56bb15e0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT = \"train\"\n",
    "# SPLIT = \"listwise-train\"\n",
    "# SPLIT = f\"listwise-{NUM_EXAMPLES_PER_LIST}n-train\"\n",
    "\n",
    "# train_files = []\n",
    "# for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "#     if '.tfrecord' in blob.name:\n",
    "#         train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "# train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "# train_dataset = train_dataset.map(data_utils.parse_lw_tfrecord)\n",
    "\n",
    "# for x in train_dataset.batch(1).take(1):\n",
    "#     pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6ca4675-7c73-49b5-8146-0e2966fd3cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9501973f-6c96-46ba-adaa-6d85450c1256",
   "metadata": {},
   "source": [
    "### Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4099e809-1152-4b27-b4aa-bc627652e45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE_VOCABS: False\n"
     ]
    }
   ],
   "source": [
    "GENERATE_VOCABS = False\n",
    "\n",
    "print(f\"GENERATE_VOCABS: {GENERATE_VOCABS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b136aa91-bc57-4acf-80f2-fff09b33acf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://mabv1-hybrid-vertex-bucket/vocabs/vocab_dict.pkl [Content-Type=application/octet-stream]...\n",
      "/ [1 files][142.9 KiB/142.9 KiB]                                                \n",
      "Operation completed over 1 objects/142.9 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{VOCAB_SUBDIR}/{VOCAB_FILENAME}'\n",
    "\n",
    "!gsutil cp gs://mabv1-hybrid-vertex-bucket/vocabs/vocab_dict.pkl $EXISTING_VOCAB_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2d881e8-b633-4c06-b8b0-c788e1806fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded storage object vocabs/vocab_dict.pkl from bucket rec-bandits-v2-hybrid-vertex-bucket to local file vocab_dict.pkl.\n",
      "'movie_id'\n",
      "'user_id'\n",
      "'user_occupation_text'\n",
      "'movie_genres'\n",
      "'bucketized_user_age'\n",
      "'max_timestamp'\n",
      "'min_timestamp'\n",
      "'timestamp_buckets'\n"
     ]
    }
   ],
   "source": [
    "data_utils.download_blob(\n",
    "    project_id = PROJECT_ID,\n",
    "    bucket_name = BUCKET_NAME, \n",
    "    source_blob_name = f\"{VOCAB_SUBDIR}/{VOCAB_FILENAME}\", \n",
    "    destination_file_name= VOCAB_FILENAME\n",
    ")\n",
    "\n",
    "filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "vocab_dict = pkl.load(filehandler)\n",
    "filehandler.close()\n",
    "\n",
    "for key in vocab_dict.keys():\n",
    "    pprint(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c58d83-52f1-4490-931b-3d65c157cc13",
   "metadata": {},
   "source": [
    "# Global & Per-Arm feature embedding models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5dc1c53-af82-400a-b841-32775855578d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_OOV_BUCKETS    : 2\n",
      "GLOBAL_EMB_SIZE    : 64\n",
      "MV_EMB_SIZE        : 32\n",
      "BATCH_SIZE         : 5\n",
      "EVAL_BATCH_SIZE    : 1\n",
      "NUM_ITEMS          : 3\n",
      "NUM_SLOTS          : 2\n",
      "DISTANCE_THRESHOLD : 0.5\n"
     ]
    }
   ],
   "source": [
    "NUM_OOV_BUCKETS       = 2\n",
    "GLOBAL_EMBEDDING_SIZE = 64 #64\n",
    "MV_EMBEDDING_SIZE     = 32 #32\n",
    "\n",
    "BATCH_SIZE            = 5 #128\n",
    "EVAL_BATCH_SIZE       = 1\n",
    "\n",
    "NUM_ITEMS             = NUM_EXAMPLES_PER_LIST # 3 | 5 \n",
    "NUM_SLOTS             = 2\n",
    "\n",
    "DISTANCE_THRESHOLD    = 0.5\n",
    "\n",
    "print(f\"NUM_OOV_BUCKETS    : {NUM_OOV_BUCKETS}\")\n",
    "print(f\"GLOBAL_EMB_SIZE    : {GLOBAL_EMBEDDING_SIZE}\")\n",
    "print(f\"MV_EMB_SIZE        : {MV_EMBEDDING_SIZE}\")\n",
    "print(f\"BATCH_SIZE         : {BATCH_SIZE}\")\n",
    "print(f\"EVAL_BATCH_SIZE    : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"NUM_ITEMS          : {NUM_ITEMS}\")\n",
    "print(f\"NUM_SLOTS          : {NUM_SLOTS}\")\n",
    "print(f\"DISTANCE_THRESHOLD : {DISTANCE_THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "833f62ac-e6bf-4892-a168-b5d075771fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie_genres': <tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n",
       " array([[3, 0, 0],\n",
       "        [7, 0, 0]])>,\n",
       " 'movie_id': <tf.Tensor: shape=(2, 3), dtype=string, numpy=\n",
       " array([[b'94', b'245', b'403'],\n",
       "        [b'678', b'127', b'343']], dtype=object)>,\n",
       " 'user_id': <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'346', b'602'], dtype=object)>,\n",
       " 'user_rating': <tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       " array([[3., 4., 3.],\n",
       "        [4., 5., 2.]], dtype=float32)>}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    \n",
    "    iterator = iter(train_dataset.batch(2))\n",
    "    data = next(iterator)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a281a7ae-be08-41c6-a648-caab55ad1235",
   "metadata": {},
   "source": [
    "## Embedding layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec8212d-0b97-4db8-8126-6693af06d55a",
   "metadata": {},
   "source": [
    "#### User ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcc2d6f1-4559-466d-8f0f-53fc5c3bd4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_input_layer = tf.keras.Input(\n",
    "    name=\"user_id\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.string\n",
    ")\n",
    "\n",
    "user_id_lookup = tf.keras.layers.StringLookup(\n",
    "    max_tokens=len(vocab_dict['user_id']) + NUM_OOV_BUCKETS,\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    mask_token=None,\n",
    "    vocabulary=vocab_dict['user_id'],\n",
    ")(user_id_input_layer)\n",
    "\n",
    "user_id_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['user_id']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=GLOBAL_EMBEDDING_SIZE\n",
    ")(user_id_lookup)\n",
    "\n",
    "user_id_embedding = tf.reduce_sum(user_id_embedding, axis=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c31717b-900e-44dd-8fa8-4692caa4dc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'346'], shape=(1,), dtype=string)\n",
      "tf.Tensor(\n",
      "[[ 0.01613015  0.03515496  0.04895956  0.0183218  -0.02177055  0.01258607\n",
      "  -0.01236415  0.04808902  0.01442678 -0.01456574  0.04135848  0.01911206\n",
      "  -0.03989476  0.02624268  0.01911247  0.04844285  0.0291761   0.03430704\n",
      "  -0.01235609 -0.00962294  0.04942075 -0.04217992 -0.04846033 -0.03170864\n",
      "  -0.04928488  0.02918265 -0.0189646   0.04843452 -0.02558212  0.04956542\n",
      "  -0.04315468 -0.01044549 -0.0359639   0.01732657  0.00810555  0.00390307\n",
      "  -0.02984715  0.0241153  -0.01502736 -0.0421452  -0.01656608  0.0298694\n",
      "   0.03945348  0.00177764  0.04102132  0.02414116  0.01932603 -0.00929775\n",
      "   0.03001661 -0.00097046 -0.02854075 -0.01492475 -0.03814771  0.00644939\n",
      "  -0.02516584 -0.0028646   0.04007084 -0.02587288  0.03632675 -0.01278766\n",
      "   0.02854398 -0.00335284  0.03236416  0.03132742]], shape=(1, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_user_id_model = tf.keras.Model(inputs=user_id_input_layer, outputs=user_id_embedding)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(x[\"user_id\"])\n",
    "    print(test_user_id_model(x[\"user_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a114a3-1cdd-46c7-b68d-3f9f55e06280",
   "metadata": {},
   "source": [
    "#### Movie ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bcc5a95f-8298-4d68-92c0-7d3887b8364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(vocab_dict['movie_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7c494c2-5a71-4de4-a1a0-746653f805dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_id_input_layer = tf.keras.Input(\n",
    "    name=\"movie_id\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.string\n",
    ")\n",
    "\n",
    "mv_id_lookup = tf.keras.layers.StringLookup(\n",
    "    max_tokens=len(vocab_dict['movie_id']) + NUM_OOV_BUCKETS,\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    mask_token=None,\n",
    "    vocabulary=vocab_dict['movie_id'],\n",
    ")(mv_id_input_layer)\n",
    "\n",
    "mv_id_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['movie_id']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=MV_EMBEDDING_SIZE\n",
    ")(mv_id_lookup)\n",
    "\n",
    "# mv_id_embedding = tf.reduce_sum(mv_id_embedding, axis=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c448c58-fbc8-42b1-aa3e-d69f113ee093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[b'94' b'245' b'403']], shape=(1, 3), dtype=string)\n",
      "tf.Tensor(\n",
      "[[[ 0.00013316  0.04895015  0.02818337 -0.04840449 -0.04661055\n",
      "   -0.01564706 -0.01958129  0.0399063  -0.01568232  0.0415514\n",
      "    0.02152411 -0.03113018 -0.03099501  0.01219279 -0.03870075\n",
      "   -0.02409307 -0.03055674  0.01682501  0.01112263 -0.0314456\n",
      "    0.02230572  0.02973416  0.02924712  0.04999478  0.04427471\n",
      "    0.0248139   0.00895657  0.02490362  0.03504861 -0.02663008\n",
      "    0.01413668 -0.03319204]\n",
      "  [-0.02398738  0.02958026  0.00810616  0.02553025 -0.04302403\n",
      "   -0.02460514  0.03688903  0.01346837  0.03231626 -0.04592575\n",
      "   -0.0047382  -0.04345177 -0.01077005 -0.02802256  0.02449692\n",
      "   -0.02475969  0.0218987  -0.00883849  0.02296201  0.04700841\n",
      "   -0.01257882  0.021038    0.02455218 -0.04920684  0.00958956\n",
      "    0.04887657 -0.03161689  0.01387948 -0.01212573 -0.04705524\n",
      "    0.01933043  0.01015653]\n",
      "  [-0.0341586  -0.04097832 -0.04706652  0.03487917 -0.02935388\n",
      "   -0.01947178 -0.04396171 -0.03631431  0.03207027  0.02034134\n",
      "   -0.03019514 -0.03228628 -0.02113354  0.00540805 -0.0498249\n",
      "    0.01562742 -0.02072402  0.00245496 -0.0484009  -0.01431601\n",
      "   -0.00082099  0.00045862 -0.00768296  0.01080898  0.02892189\n",
      "   -0.04029553 -0.04241345 -0.0247661   0.01384176 -0.00797833\n",
      "    0.0440509  -0.04055905]]], shape=(1, 3, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_mv_id_model = tf.keras.Model(inputs=mv_id_input_layer, outputs=mv_id_embedding)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(x[\"movie_id\"])\n",
    "    list_length = x[\"movie_id\"].shape[1]\n",
    "    print(test_mv_id_model(x[\"movie_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5886b2a-011b-4648-9834-b8a1e2d343f2",
   "metadata": {},
   "source": [
    "#### Movie Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dee33311-d565-4003-8d28-0d3dfc0ca68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(vocab_dict['movie_genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "052db904-0935-44db-bbba-548aa7b01c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_genre_input_layer = tf.keras.Input(\n",
    "    name=\"movie_genres\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "mv_genre_lookup = tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=vocab_dict['movie_genres'],\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    oov_value=0,\n",
    ")(mv_genre_input_layer)\n",
    "\n",
    "mv_genre_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['movie_genres']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=MV_EMBEDDING_SIZE\n",
    ")(mv_genre_lookup)\n",
    "\n",
    "# mv_genre_embedding = tf.reduce_sum(mv_genre_embedding, axis=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0cd72900-c9bc-4349-8984-8c0218c08efe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[3 0 0]\n",
      " [7 0 0]], shape=(2, 3), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-0.01724131 -0.01028286 -0.01322908  0.04692398  0.04421682\n",
      "   -0.02140205 -0.02071586 -0.00234731 -0.00912101  0.00610358\n",
      "   -0.01958064  0.04159904 -0.02407217 -0.03780401 -0.04049866\n",
      "   -0.01618289 -0.04671479  0.01718879  0.00345079  0.02134296\n",
      "    0.03920614  0.04106207 -0.00289091 -0.01663973  0.01643122\n",
      "   -0.02590045 -0.03513824 -0.00151982 -0.04036096  0.04003278\n",
      "    0.03928861  0.00544984]\n",
      "  [-0.0247295   0.04951986  0.03499622 -0.02994104  0.04372753\n",
      "    0.00317229 -0.01695908 -0.00500456  0.04673144 -0.00585605\n",
      "    0.02500658  0.00412931  0.03228942 -0.01143207 -0.00046587\n",
      "    0.02004487 -0.00367295  0.00794754 -0.00496797  0.0198354\n",
      "   -0.01514472 -0.04392944 -0.02159487 -0.0494297  -0.02362077\n",
      "    0.04345102 -0.00715888 -0.03815008  0.0448342  -0.00055359\n",
      "    0.04495633 -0.01777088]\n",
      "  [-0.0247295   0.04951986  0.03499622 -0.02994104  0.04372753\n",
      "    0.00317229 -0.01695908 -0.00500456  0.04673144 -0.00585605\n",
      "    0.02500658  0.00412931  0.03228942 -0.01143207 -0.00046587\n",
      "    0.02004487 -0.00367295  0.00794754 -0.00496797  0.0198354\n",
      "   -0.01514472 -0.04392944 -0.02159487 -0.0494297  -0.02362077\n",
      "    0.04345102 -0.00715888 -0.03815008  0.0448342  -0.00055359\n",
      "    0.04495633 -0.01777088]]\n",
      "\n",
      " [[ 0.01092995 -0.00931108  0.03349234 -0.00635824 -0.01173073\n",
      "   -0.00948254  0.00937134  0.03263909 -0.04418753 -0.04247069\n",
      "    0.04086028  0.01707676 -0.01341909  0.00187688  0.04358209\n",
      "    0.02756386 -0.01634718  0.03363171 -0.0412508   0.04998043\n",
      "    0.01867186  0.03287945 -0.0443128   0.02524887 -0.04501238\n",
      "   -0.00730024 -0.01079996  0.03507197 -0.03378179 -0.02385304\n",
      "    0.04937084 -0.02223898]\n",
      "  [-0.0247295   0.04951986  0.03499622 -0.02994104  0.04372753\n",
      "    0.00317229 -0.01695908 -0.00500456  0.04673144 -0.00585605\n",
      "    0.02500658  0.00412931  0.03228942 -0.01143207 -0.00046587\n",
      "    0.02004487 -0.00367295  0.00794754 -0.00496797  0.0198354\n",
      "   -0.01514472 -0.04392944 -0.02159487 -0.0494297  -0.02362077\n",
      "    0.04345102 -0.00715888 -0.03815008  0.0448342  -0.00055359\n",
      "    0.04495633 -0.01777088]\n",
      "  [-0.0247295   0.04951986  0.03499622 -0.02994104  0.04372753\n",
      "    0.00317229 -0.01695908 -0.00500456  0.04673144 -0.00585605\n",
      "    0.02500658  0.00412931  0.03228942 -0.01143207 -0.00046587\n",
      "    0.02004487 -0.00367295  0.00794754 -0.00496797  0.0198354\n",
      "   -0.01514472 -0.04392944 -0.02159487 -0.0494297  -0.02362077\n",
      "    0.04345102 -0.00715888 -0.03815008  0.0448342  -0.00055359\n",
      "    0.04495633 -0.01777088]]], shape=(2, 3, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_mv_gen_model = tf.keras.Model(inputs=mv_genre_input_layer, outputs=mv_genre_embedding)\n",
    "\n",
    "for x in train_dataset.batch(2).take(1):\n",
    "    print(x[\"movie_genres\"])\n",
    "    print(test_mv_gen_model(x[\"movie_genres\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0415398e-3bbd-4497-aa31-1d618325fbb1",
   "metadata": {},
   "source": [
    "## Sampling Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343c1dee-fc37-4075-8d65-6909d548eb43",
   "metadata": {},
   "source": [
    "#### item sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8883e1c-0448-4486-bc2e-4ae3e3e54919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_per_arm_features(x):\n",
    "    \"\"\"\n",
    "    This function generates a single per-arm observation vector.\n",
    "    \"\"\"\n",
    "    ratings_list = x[\"user_rating\"] #[0]\n",
    "    indices = tf.argsort(ratings_list, direction=\"DESCENDING\")\n",
    "    _batch_size = len(ratings_list)\n",
    "    \n",
    "    mv_ids = test_mv_id_model(x[\"movie_id\"])\n",
    "    mv_gens = test_mv_gen_model(x[\"movie_genres\"])\n",
    "    \n",
    "    concat_embeddings = tf.concat(\n",
    "        [mv_ids, mv_gens], axis=-1\n",
    "    )\n",
    "    \n",
    "    ordered_concat = tf.gather(concat_embeddings, indices, batch_dims=1)\n",
    "    # feedback = tf.gather_nd(concat_embeddings, indices)\n",
    "    # print(f\"ordered_concat_embeddings: {ordered_concat_embeddings}\")\n",
    "    # ordered_concat = tf.reduce_sum(ordered_concat, axis=0)\n",
    "    \n",
    "    slotted_ordered_concat = tf.slice(\n",
    "        ordered_concat, begin=[0, 0, 0], size=[_batch_size, NUM_SLOTS, MV_EMBEDDING_SIZE * NUM_SLOTS]\n",
    "    )\n",
    "    \n",
    "    return slotted_ordered_concat\n",
    "    # return slotted_ordered_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d985e45c-7247-467d-80fb-fa977957e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 64), dtype=float32, numpy=\n",
       "array([[[-0.02398738,  0.02958026,  0.00810616,  0.02553025,\n",
       "         -0.04302403, -0.02460514,  0.03688903,  0.01346837,\n",
       "          0.03231626, -0.04592575, -0.0047382 , -0.04345177,\n",
       "         -0.01077005, -0.02802256,  0.02449692, -0.02475969,\n",
       "          0.0218987 , -0.00883849,  0.02296201,  0.04700841,\n",
       "         -0.01257882,  0.021038  ,  0.02455218, -0.04920684,\n",
       "          0.00958956,  0.04887657, -0.03161689,  0.01387948,\n",
       "         -0.01212573, -0.04705524,  0.01933043,  0.01015653,\n",
       "         -0.0247295 ,  0.04951986,  0.03499622, -0.02994104,\n",
       "          0.04372753,  0.00317229, -0.01695908, -0.00500456,\n",
       "          0.04673144, -0.00585605,  0.02500658,  0.00412931,\n",
       "          0.03228942, -0.01143207, -0.00046587,  0.02004487,\n",
       "         -0.00367295,  0.00794754, -0.00496797,  0.0198354 ,\n",
       "         -0.01514472, -0.04392944, -0.02159487, -0.0494297 ,\n",
       "         -0.02362077,  0.04345102, -0.00715888, -0.03815008,\n",
       "          0.0448342 , -0.00055359,  0.04495633, -0.01777088],\n",
       "        [ 0.00013316,  0.04895015,  0.02818337, -0.04840449,\n",
       "         -0.04661055, -0.01564706, -0.01958129,  0.0399063 ,\n",
       "         -0.01568232,  0.0415514 ,  0.02152411, -0.03113018,\n",
       "         -0.03099501,  0.01219279, -0.03870075, -0.02409307,\n",
       "         -0.03055674,  0.01682501,  0.01112263, -0.0314456 ,\n",
       "          0.02230572,  0.02973416,  0.02924712,  0.04999478,\n",
       "          0.04427471,  0.0248139 ,  0.00895657,  0.02490362,\n",
       "          0.03504861, -0.02663008,  0.01413668, -0.03319204,\n",
       "         -0.01724131, -0.01028286, -0.01322908,  0.04692398,\n",
       "          0.04421682, -0.02140205, -0.02071586, -0.00234731,\n",
       "         -0.00912101,  0.00610358, -0.01958064,  0.04159904,\n",
       "         -0.02407217, -0.03780401, -0.04049866, -0.01618289,\n",
       "         -0.04671479,  0.01718879,  0.00345079,  0.02134296,\n",
       "          0.03920614,  0.04106207, -0.00289091, -0.01663973,\n",
       "          0.01643122, -0.02590045, -0.03513824, -0.00151982,\n",
       "         -0.04036096,  0.04003278,  0.03928861,  0.00544984]],\n",
       "\n",
       "       [[ 0.0237636 ,  0.00446006, -0.03232886, -0.01382831,\n",
       "          0.01434955, -0.04550555, -0.0412771 ,  0.04917813,\n",
       "          0.01623943, -0.01852387,  0.03330353,  0.03380105,\n",
       "          0.01381734, -0.01058704, -0.02268572,  0.00781363,\n",
       "          0.02677969, -0.03423192,  0.00151638, -0.04395211,\n",
       "          0.01438853, -0.02939714,  0.00373709,  0.00809037,\n",
       "          0.01671833,  0.02273372, -0.03841472, -0.02008003,\n",
       "         -0.04853182,  0.02471879, -0.04347352, -0.01306022,\n",
       "         -0.0247295 ,  0.04951986,  0.03499622, -0.02994104,\n",
       "          0.04372753,  0.00317229, -0.01695908, -0.00500456,\n",
       "          0.04673144, -0.00585605,  0.02500658,  0.00412931,\n",
       "          0.03228942, -0.01143207, -0.00046587,  0.02004487,\n",
       "         -0.00367295,  0.00794754, -0.00496797,  0.0198354 ,\n",
       "         -0.01514472, -0.04392944, -0.02159487, -0.0494297 ,\n",
       "         -0.02362077,  0.04345102, -0.00715888, -0.03815008,\n",
       "          0.0448342 , -0.00055359,  0.04495633, -0.01777088],\n",
       "        [-0.01469912,  0.00597753, -0.02422603,  0.01161458,\n",
       "          0.03480054,  0.009276  , -0.01537907, -0.02081977,\n",
       "          0.04556039, -0.03751128,  0.0050744 ,  0.0294312 ,\n",
       "          0.02312359,  0.04944139,  0.02541722, -0.03451584,\n",
       "          0.03352256, -0.04614853, -0.03992542,  0.04748435,\n",
       "         -0.02631575, -0.03368755,  0.02135921,  0.04139042,\n",
       "         -0.03494384, -0.02021861, -0.04218239,  0.04679159,\n",
       "          0.02927388, -0.0373907 ,  0.04961791, -0.03656096,\n",
       "          0.01092995, -0.00931108,  0.03349234, -0.00635824,\n",
       "         -0.01173073, -0.00948254,  0.00937134,  0.03263909,\n",
       "         -0.04418753, -0.04247069,  0.04086028,  0.01707676,\n",
       "         -0.01341909,  0.00187688,  0.04358209,  0.02756386,\n",
       "         -0.01634718,  0.03363171, -0.0412508 ,  0.04998043,\n",
       "          0.01867186,  0.03287945, -0.0443128 ,  0.02524887,\n",
       "         -0.04501238, -0.00730024, -0.01079996,  0.03507197,\n",
       "         -0.03378179, -0.02385304,  0.04937084, -0.02223898]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arms = _get_per_arm_features(data)\n",
    "test_arms #.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd9b8a0a-6374-4584-8c99-1fd6adcbaea5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER_ARM_DIM: 64\n"
     ]
    }
   ],
   "source": [
    "test_arms = _get_per_arm_features(data)\n",
    "\n",
    "PER_ARM_DIM = test_arms.shape[2]            \n",
    "print(f\"PER_ARM_DIM: {PER_ARM_DIM}\")\n",
    "\n",
    "# test_arms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b01f1f2-a576-4b18-91ca-ee6c5bd90117",
   "metadata": {},
   "source": [
    "#### global sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbffe5f6-8b37-448e-aadd-b578cfbe1395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_global_context_features(x):\n",
    "    \"\"\"\n",
    "    This function generates a single global observation vector.\n",
    "    \"\"\"\n",
    "    \n",
    "    return test_user_id_model(x['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1644300b-f7b7-4f38-9f31-f83ba74ecf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL_DIM: 64\n"
     ]
    }
   ],
   "source": [
    "test_globals = _get_global_context_features(data)\n",
    "\n",
    "GLOBAL_DIM = test_globals.shape[1] \n",
    "print(f\"GLOBAL_DIM: {GLOBAL_DIM}\")\n",
    "\n",
    "# test_globals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ada148e-e36b-4c98-ae5b-234aa9940055",
   "metadata": {},
   "source": [
    "# Ranking Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7fd210-4772-4073-9630-1173ac4f93e4",
   "metadata": {},
   "source": [
    "## Feedback type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a0da21-0b0f-4876-8b43-c012d1cc64c2",
   "metadata": {},
   "source": [
    "Ranking agents assume either a `score_vector` or `cascading feedback` framework for the feedback signal (reward). \n",
    "\n",
    "* `score_vector`: feedback is a vector of scores for every item in the slots. \n",
    "* `cascading feedback`: if the kth item was clicked, then the items up to k-1 receive a score of -1, the kth item receives a score based on a feedback value, while the rest of the items receive feedback of 0. \n",
    "\n",
    "Ranking agent objective: train the scoring network to be able to estimate the above scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c49a7375-ec9f-403d-aa86-810134cd430c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feedback_model = ranking_environment.FeedbackModel.CASCADING\n",
    "feedback_model = FeedbackModel.SCORE_VECTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b20c76-2950-4459-ab07-148cded078f2",
   "metadata": {},
   "source": [
    "## Tensor Specs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b43561b-f486-454e-a851-8cedfd6999d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "example Tensor Spec structures..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cbb948-52c5-44a3-80ab-4e57ba6968ea",
   "metadata": {},
   "source": [
    "`observation_spec()`\n",
    "\n",
    "```python\n",
    "{'global': TensorSpec(shape=(9,), dtype=tf.float32, name=None),\n",
    " 'per_arm': TensorSpec(shape=(50, 11), dtype=tf.float32, name=None)}\n",
    "```\n",
    "\n",
    "`action_spec()`\n",
    "\n",
    "```python\n",
    "BoundedTensorSpec(shape=(3,), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(49, dtype=int32))\n",
    "```\n",
    "\n",
    "`reward_spec()`\n",
    "\n",
    "```python\n",
    "{'chosen_index': BoundedTensorSpec(shape=(), dtype=tf.int32, name='chosen_index', minimum=array(0, dtype=int32), maximum=array(3, dtype=int32)),\n",
    " 'chosen_value': TensorSpec(shape=(), dtype=tf.float32, name='chosen_value')}\n",
    "```\n",
    "\n",
    "`time_step_spec()`\n",
    "\n",
    "```python\n",
    "TimeStep(\n",
    "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
    " 'observation': {'global': TensorSpec(shape=(9,), dtype=tf.float32, name=None),\n",
    "                 'per_arm': TensorSpec(shape=(50, 11), dtype=tf.float32, name=None)},\n",
    " 'reward': {'chosen_index': BoundedTensorSpec(shape=(), dtype=tf.int32, name='chosen_index', minimum=array(0, dtype=int32), maximum=array(3, dtype=int32)),\n",
    "            'chosen_value': TensorSpec(shape=(), dtype=tf.float32, name='chosen_value')},\n",
    " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d9cf3f-ac83-4580-a8f6-d98d93e49275",
   "metadata": {},
   "source": [
    "**from [ranking_environment.py](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/environments/ranking_environment.py#L152C1-L166C6)**\n",
    "\n",
    "```\n",
    "    global_spec = array_spec.ArraySpec.from_array(global_sampling_fn())\n",
    "    item_spec = array_spec.add_outer_dims_nest(\n",
    "        array_spec.ArraySpec.from_array(item_sampling_fn()), (num_items,)\n",
    "    )\n",
    "    observation_spec = {GLOBAL_KEY: global_spec, PER_ARM_KEY: item_spec}\n",
    "    self._global_dim = global_spec.shape[0]\n",
    "    self._item_dim = item_spec.shape[-1]\n",
    "\n",
    "    action_spec = array_spec.BoundedArraySpec(\n",
    "        shape=(num_slots,),\n",
    "        dtype=np.int32,\n",
    "        minimum=0,\n",
    "        maximum=num_items - 1,\n",
    "        name='action',\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae68b8a-8656-45cc-8977-70613629ce75",
   "metadata": {},
   "source": [
    "set vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5426bb09-834b-4cb3-9bf4-8d84482307e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE         : 5\n",
      "EVAL_BATCH_SIZE    : 1\n",
      "NUM_ITEMS          : 3\n",
      "NUM_SLOTS          : 2\n",
      "DISTANCE_THRESHOLD : 0.5\n",
      "GLOBAL_DIM         : 64\n",
      "PER_ARM_DIM        : 64\n"
     ]
    }
   ],
   "source": [
    "from tf_agents.specs import array_spec\n",
    "\n",
    "print(f\"BATCH_SIZE         : {BATCH_SIZE}\")\n",
    "print(f\"EVAL_BATCH_SIZE    : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"NUM_ITEMS          : {NUM_ITEMS}\")\n",
    "print(f\"NUM_SLOTS          : {NUM_SLOTS}\")\n",
    "print(f\"DISTANCE_THRESHOLD : {DISTANCE_THRESHOLD}\")\n",
    "print(f\"GLOBAL_DIM         : {GLOBAL_DIM}\")\n",
    "print(f\"PER_ARM_DIM        : {PER_ARM_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc572702-592c-4d60-8719-50739f611e16",
   "metadata": {},
   "source": [
    "### Observation spec\n",
    "\n",
    "* The observation the agent ingests contains the global features and the features\n",
    "of the items in the recommendation slots. \n",
    "* The item features are stored in the `per_arm` part of the observation, in the order of how they are recommended.\n",
    "* Since this ordered list of items expresses what action was taken by the policy, the `action` value of the trajectory is not used by the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b97866b-fb8c-4724-ac6f-ce789d5b7368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_spec = {\n",
    "    'global': tf.TensorSpec([GLOBAL_DIM], tf.float32),\n",
    "    # 'per_arm': tf.TensorSpec([NUM_ITEMS, PER_ARM_DIM], tf.float32)\n",
    "    'per_arm': tf.TensorSpec([NUM_SLOTS, PER_ARM_DIM], tf.float32)\n",
    "}\n",
    "observation_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80565f15-d41e-46db-99b3-6ea6a73ab6aa",
   "metadata": {},
   "source": [
    "### Action spec\n",
    "\n",
    "> Action spec for ranking models must have rank 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73b90ec0-1fe2-4b08-8a47-1fd32058705f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_spec rank: (2,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(2,), dtype=dtype('int32'), name='action', minimum=0, maximum=2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec = array_spec.BoundedArraySpec(\n",
    "    shape=(NUM_SLOTS,),\n",
    "    dtype=np.int32,\n",
    "    minimum=0,\n",
    "    maximum=NUM_ITEMS - 1,\n",
    "    name='action',\n",
    ")\n",
    "\n",
    "print(f\"action_spec rank: {action_spec.shape}\")\n",
    "\n",
    "action_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdacef1-fd61-4569-9bf7-299c52903710",
   "metadata": {},
   "source": [
    "### Reward spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "166f53bd-cdb9-49c4-a4d8-2904a6300f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(2,), dtype=tf.float32, name='score_vector')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if feedback_model == ranking_environment.FeedbackModel.CASCADING:\n",
    "    # `chosen_index == num_slots` means no recommended item was clicked.\n",
    "    reward_spec = {\n",
    "        'chosen_index': array_spec.BoundedArraySpec(\n",
    "            shape=[],\n",
    "            minimum=0,\n",
    "            maximum=NUM_SLOTS,\n",
    "            dtype=np.int32,\n",
    "            name='chosen_index',\n",
    "        ),\n",
    "        'chosen_value': array_spec.ArraySpec(\n",
    "            shape=[], dtype=np.float32, name='chosen_value'\n",
    "        ),\n",
    "    }\n",
    "elif feedback_model == ranking_environment.FeedbackModel.SCORE_VECTOR:\n",
    "    reward_spec = tf.TensorSpec(\n",
    "        shape=[NUM_SLOTS], dtype=np.float32, name='score_vector'\n",
    "    )\n",
    "    # reward_spec = array_spec.ArraySpec(\n",
    "    #     shape=[NUM_SLOTS], dtype=np.float32, name='score_vector'\n",
    "    # )\n",
    "else:\n",
    "    reward_spec = f\"Feedback model: {feedback_model}, not implemented\"\n",
    "    \n",
    "reward_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0deb69-a259-4495-a58e-81c0fd2a97ab",
   "metadata": {},
   "source": [
    "### TimeStep spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa7a5d0e-d4c2-4f8c-b67e-84fe6d1e4fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
       " 'reward': TensorSpec(shape=(2,), dtype=tf.float32, name='score_vector'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - investigate adding reward_spec\n",
    "\"\"\"\n",
    "TypeError: Expected observation and reward specs to \n",
    "both be either tensor or array specs, but saw spec values \n",
    "TensorSpec(shape=(64,), dtype=tf.float32, name=None) \n",
    "vs. ArraySpec(shape=(2,), dtype=dtype('float32'), name='score_vector')\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "time_step_spec = ts.time_step_spec(\n",
    "    observation_spec = observation_spec, \n",
    "    reward_spec = reward_spec             # TODO\n",
    ")\n",
    "time_step_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ecc66c-ce8b-480b-8306-40eaf399f120",
   "metadata": {},
   "source": [
    "Inspect chosen arm features spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "164a5760-3ca3-4397-85b3-26bbcd987b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec.observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad033e89-1f1c-4f63-9084-bf6a6807915f",
   "metadata": {},
   "source": [
    "## Policy and Scoring Network\n",
    "\n",
    "> all ranking agents train a network that estimates scores of item/user pairs\n",
    "\n",
    "**Ranking Policies**\n",
    "* `DESCENDING_SCORES` - Stack rank deterministically by scores\n",
    "* `NO_PENALTY` - Sampling sequentially based on scores; no penalty applied\n",
    "* `COSINE_DISTANCE` - Sampling sequentally and taking diversity into account\n",
    "\n",
    "`penalty_mixture` parameter governs the balance between ranking based on scores and accounting for diversity\n",
    "* low positive value --> ranking has less diversity\n",
    "* higher value --> enforces more diversity\n",
    "\n",
    "`logits_temperature` - temperature parameter for non-deterministic policies\n",
    "* This value must be positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ce99346-5745-4d87-a469-9a36cb270987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL_DIM  : 64\n",
      "PER_ARM_DIM : 64\n"
     ]
    }
   ],
   "source": [
    "print(f\"GLOBAL_DIM  : {GLOBAL_DIM}\")\n",
    "print(f\"PER_ARM_DIM : {PER_ARM_DIM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5aea87d-c993-4cd6-80ad-0522dcc91956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 5,\n",
      " 'common_layers': [16, 8],\n",
      " 'eval_batch_size': 1,\n",
      " 'feedback_model': 2,\n",
      " 'global_layers': [64, 32, 16],\n",
      " 'learning_rate': 0.005,\n",
      " 'logits_temperature': 1.0,\n",
      " 'model_type': 'Ranking',\n",
      " 'network_type': 'dotproduct',\n",
      " 'num_items': 3,\n",
      " 'num_slots': 2,\n",
      " 'penalty_mixture': 1.0,\n",
      " 'per_arm_layers': [64, 32, 16],\n",
      " 'policy_type': <RankingPolicyType.DESCENDING_SCORES: 3>}\n"
     ]
    }
   ],
   "source": [
    "AGENT_TYPE = \"Ranking\"\n",
    "NETWORK_TYPE = \"dotproduct\"\n",
    "POLICY_TYPE = ranking_agent.RankingPolicyType.DESCENDING_SCORES # COSINE_DISTANCE | NO_PENALTY | DESCENDING_SCORES\n",
    "\n",
    "PENALTY_MIXTURE = 1.0\n",
    "LOGITS_TEMPERATURE = 1.0\n",
    "\n",
    "LEARNING_RATE = 0.005\n",
    "\n",
    "GLOBAL_LAYERS   = [64, 32, 16]\n",
    "ARM_LAYERS      = [64, 32, 16]\n",
    "COMMON_LAYERS   = [16, 8]\n",
    "\n",
    "HPARAMS = {  # TODO - streamline and consolidate\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"eval_batch_size\" : EVAL_BATCH_SIZE,\n",
    "    \"num_items\": NUM_ITEMS,\n",
    "    \"num_slots\": NUM_SLOTS,\n",
    "    \"model_type\": AGENT_TYPE,\n",
    "    \"network_type\": NETWORK_TYPE,\n",
    "    \"global_layers\": GLOBAL_LAYERS,\n",
    "    \"per_arm_layers\": ARM_LAYERS,\n",
    "    \"common_layers\": COMMON_LAYERS,\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"policy_type\": POLICY_TYPE,\n",
    "    \"feedback_model\" : feedback_model,\n",
    "    \"penalty_mixture\": PENALTY_MIXTURE,\n",
    "    \"logits_temperature\": LOGITS_TEMPERATURE,\n",
    "}\n",
    "pprint(HPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80d4e8a9-6582-425d-9c50-499aa883b2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network: GlobalAndArmDotProductNetwork\n"
     ]
    }
   ],
   "source": [
    "if NETWORK_TYPE == 'commontower':\n",
    "    scoring_network = global_and_arm_feature_network.create_feed_forward_common_tower_network(\n",
    "        observation_spec = observation_spec, \n",
    "        global_layers = GLOBAL_LAYERS, \n",
    "        arm_layers = ARM_LAYERS, \n",
    "        common_layers = COMMON_LAYERS,\n",
    "        # output_dim = output_dim,\n",
    "    )\n",
    "    \n",
    "elif NETWORK_TYPE == 'dotproduct':\n",
    "    scoring_network = global_and_arm_feature_network.create_feed_forward_dot_product_network(\n",
    "        observation_spec = observation_spec, \n",
    "        global_layers = GLOBAL_LAYERS, \n",
    "        arm_layers = ARM_LAYERS\n",
    "    )\n",
    "    \n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {scoring_network.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1939dc-7ee9-414c-aa89-85b08bcfb4cb",
   "metadata": {},
   "source": [
    "## Define Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5dad7dd6-3d19-4c79-8a72-078253f046e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank_agent: ranking_agent\n"
     ]
    }
   ],
   "source": [
    "rank_agent = ranking_agent.RankingAgent(\n",
    "    time_step_spec=time_step_spec,\n",
    "    action_spec=action_spec,\n",
    "    scoring_network=scoring_network,\n",
    "    optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=HPARAMS['learning_rate']),\n",
    "    feedback_model=ranking_agent.FeedbackModel.SCORE_VECTOR, # FeedbackModel.SCORE_VECTOR, # feedback_model,\n",
    "    policy_type=HPARAMS['policy_type'],\n",
    "    logits_temperature=HPARAMS['logits_temperature'],\n",
    "    penalty_mixture_coefficient=HPARAMS['penalty_mixture'],\n",
    "    summarize_grads_and_vars=True\n",
    ")\n",
    "\n",
    "rank_agent.initialize()\n",
    "\n",
    "print(f'rank_agent: {rank_agent.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cf04067d-7f83-43f7-bb97-88ddfd1b3d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.bandits.policies.ranking_policy.DescendingScoreRankingPolicy at 0x7f929b9ad000>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_agent.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a38e772e-80b8-4dfe-811d-83fae71c912c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(2,), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(2, dtype=int32))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_agent.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fd594bbd-383b-41a8-bc5e-317db5b93a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_agent.training_data_spec.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "21e2f27b-79b6-4ce6-bf61-0e777db54d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}),\n",
       " 'reward': TensorSpec(shape=(2,), dtype=tf.float32, name='score_vector'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_agent.policy.time_step_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d6040423-c390-4e1a-90a9-69b9ab58b23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(Trajectory(\n",
       "{'action': BoundedTensorSpec(shape=(2,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(1, dtype=int32)),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}),\n",
       " 'policy_info': PolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=()),\n",
       " 'reward': TensorSpec(shape=(2,), dtype=tf.float32, name='score_vector'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_agent.policy.trajectory_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46435a9d-c901-4d32-8baa-1da60c427788",
   "metadata": {},
   "source": [
    "### Reward function\n",
    "\n",
    "**TODO**\n",
    "* `_create_ranking_reward_features`\n",
    "* `_get_rewards_from_arm_features` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "90b521c4-bb43-4cc5-b0fa-67d420b64834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_ranking_rewards_sv(x):\n",
    "    \"\"\"Calculates reward for the actions.\"\"\"\n",
    "    \n",
    "    # rating_scores_list = []\n",
    "    ratings_list = x[\"user_rating\"] #[0]\n",
    "    indices = tf.argsort(ratings_list, direction=\"DESCENDING\")\n",
    "    \n",
    "    feedback = tf.gather(ratings_list, indices, batch_dims=-1) #.numpy()\n",
    "    \n",
    "    # feedback = tf.math.top_k(feedback, k=HPARAMS['num_slots']).values\n",
    "    top_n_ratings = tf.slice(feedback, begin=[0, 0], size=[-1, HPARAMS['num_slots']])\n",
    "    \n",
    "    return top_n_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "997dbdd4-7048-4d9f-8f65-f5e99a28ef1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[4., 3.],\n",
       "       [5., 4.]], dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ratings = _get_ranking_rewards_sv(data)\n",
    "test_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "31976a8d-c4ba-4fc1-a429-e24f812aac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rank_trajectory_fn(element): # hparams\n",
    "    \"\"\"Converts a dataset element into a trajectory.\"\"\"\n",
    "    # global_features = _get_global_context_features(element)\n",
    "    # arm_features = _get_per_arm_features(element)\n",
    "    \n",
    "    global_features = _get_global_context_features(element)\n",
    "    arm_features = _get_per_arm_features(element)\n",
    "    \n",
    "    # obs spec\n",
    "    observation = {\n",
    "        bandit_spec_utils.GLOBAL_FEATURE_KEY:\n",
    "            train_utils._add_outer_dimension(global_features),\n",
    "            # global_features,\n",
    "        bandit_spec_utils.PER_ARM_FEATURE_KEY: \n",
    "            train_utils._add_outer_dimension(arm_features)\n",
    "            # arm_features\n",
    "    }\n",
    "    \n",
    "    # reward = element['user_rating']\n",
    "    ranking_rewards = _get_ranking_rewards_sv(element)\n",
    "\n",
    "    \n",
    "    # action = np.zeros((HPARAMS['num_slots']), dtype=np.int32)\n",
    "    action=tf.zeros_like(HPARAMS['num_slots'], dtype=tf.int32)\n",
    "    \n",
    "    # discount = np.zeros((HPARAMS['num_slots']), dtype=np.float32)\n",
    "    discount=tf.zeros_like(HPARAMS['num_slots'], dtype=tf.int32)\n",
    "    return trajectory.single_step(\n",
    "        observation=observation,\n",
    "        action=action,\n",
    "        policy_info=(), #policy_info,\n",
    "        reward=ranking_rewards,\n",
    "        discount=discount\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c8221e8a-cdf2-4944-9856-6a2371d3f782",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in train_dataset.batch(HPARAMS['batch_size']).take(1):\n",
    "    test_traj = _rank_trajectory_fn(x)\n",
    "    \n",
    "# test_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "57fd5848-4d75-4fae-8cd7-0d7310562508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.observation.shape: (5, 1, 64)\n",
      "test_traj.observation.shape: (5, 1, 2, 64)\n",
      "test_traj.discount.shape   : ()\n",
      "expected_num_actions: 3\n",
      "predicted_rewards_mean: TensorSpec(shape=(3,), dtype=tf.float32, name=None)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.observation.shape: {test_traj.observation['global'].shape}\")\n",
    "print(f\"test_traj.observation.shape: {test_traj.observation['per_arm'].shape}\")\n",
    "print(f\"test_traj.discount.shape   : {test_traj.discount.shape}\") \n",
    "\n",
    "expected_num_actions = action_spec.maximum - action_spec.minimum + 1\n",
    "print(f\"expected_num_actions: {expected_num_actions}\")\n",
    "\n",
    "predicted_rewards_mean = tensor_spec.TensorSpec([expected_num_actions])\n",
    "print(f\"predicted_rewards_mean: {predicted_rewards_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f5ac56-3153-48e3-999a-a818ca673129",
   "metadata": {},
   "source": [
    "# Train Ranking Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "43cd93ee-4ed8-4b11-9350-5e606ccca87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : local-ranker-rec-bandits-v2\n",
      "RUN_NAME          : run-20231018-230837\n",
      "\n",
      "BASE_OUTPUT_DIR   : gs://rec-bandits-v2-hybrid-vertex-bucket/local-ranker-rec-bandits-v2/run-20231018-230837\n",
      "LOG_DIR           : gs://rec-bandits-v2-hybrid-vertex-bucket/local-ranker-rec-bandits-v2/run-20231018-230837/logs\n",
      "ROOT_DIR          : gs://rec-bandits-v2-hybrid-vertex-bucket/local-ranker-rec-bandits-v2/run-20231018-230837/root\n",
      "ARTIFACTS_DIR     : gs://rec-bandits-v2-hybrid-vertex-bucket/local-ranker-rec-bandits-v2/run-20231018-230837/artifacts\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME   = f'local-ranker-{PREFIX}'\n",
    "\n",
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "99169818-818e-4148-b045-25eded36f553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_agents version: 0.17.0\n",
      "tensorflow version: 2.13.0\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.policies import tf_policy\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.metrics import export_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.utils import common\n",
    "\n",
    "import tf_agents\n",
    "\n",
    "print(f\"tf_agents version: {tf_agents.__version__}\")\n",
    "print(f\"tensorflow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f7b1cc-a927-45c0-b64d-30a70250fb8d",
   "metadata": {},
   "source": [
    "### logs & checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e6f63092-48ba-4cb2-8ee4-9b30bd4c23c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent: ranking_agent\n",
      "agent: descending_score_ranking_policy\n"
     ]
    }
   ],
   "source": [
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "rank_agent.initialize()\n",
    "print(f'agent: {rank_agent.name}')\n",
    "print(f'agent: {rank_agent.policy.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dd893a5d-449e-4c21-b9fc-3cf5114dd2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('metrics: [<tf_agents.metrics.tf_metrics.AverageReturnMetric object at '\n",
      " '0x7f929b980790>]')\n",
      "setting checkpoint_manager: gs://rec-bandits-v2-hybrid-vertex-bucket/local-ranker-rec-bandits-v2/run-20231018-230837/root/chkpoint\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    f\"{LOG_DIR}\", flush_millis=10 * 1000\n",
    ")\n",
    "# train_summary_writer.set_as_default()\n",
    "\n",
    "# eval_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "#     f\"{LOG_DIR}/eval\", flush_millis=10 * 1000\n",
    "# )\n",
    "# ====================================================\n",
    "# metrics\n",
    "# ====================================================\n",
    "# `step_metric` records the number of individual rounds of bandit interaction;\n",
    "# that is, (number of trajectories) * batch_size\n",
    "step_metric = tf_metrics.EnvironmentSteps()\n",
    "\n",
    "if feedback_model == ranking_environment.FeedbackModel.SCORE_VECTOR:\n",
    "    reward_metric = tf_metrics.AverageReturnMetric(\n",
    "        batch_size=HPARAMS['batch_size'],\n",
    "        buffer_size=20\n",
    "    )\n",
    "else:\n",
    "    reward_metric = tf_metrics.AverageReturnMultiMetric(\n",
    "        reward_spec=environment.reward_spec(),\n",
    "        batch_size=HPARAMS['batch_size'],\n",
    "        buffer_size=20\n",
    "    )\n",
    "    \n",
    "metrics = [reward_metric]\n",
    "\n",
    "pprint(f\"metrics: {metrics}\")\n",
    "\n",
    "# ====================================================\n",
    "# get checkpoint manager\n",
    "# ====================================================\n",
    "CHKPOINT_DIR = f\"{ROOT_DIR}/chkpoint\"\n",
    "print(f\"setting checkpoint_manager: {CHKPOINT_DIR}\")\n",
    "\n",
    "checkpoint_manager = train_utils.restore_and_get_checkpoint_manager(\n",
    "    root_dir=CHKPOINT_DIR, \n",
    "    agent=rank_agent, \n",
    "    metrics=metrics, \n",
    "    step_metric=step_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e6e434-f8dd-43ac-8dfc-d6e5ceeb10d0",
   "metadata": {},
   "source": [
    "#### Saving Ranking Bandits\n",
    "\n",
    "> Note: [open issue](https://github.com/tensorflow/agents/issues/891) regarding saving ranking bandit models\n",
    "\n",
    "Until this is resolved, use the `checkpoint_manager` to restore the latest trained policy. \n",
    "\n",
    "More on this in the `Inference` section below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dd8bc05c-81f1-4919-9668-a0236f35a061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ====================================================\n",
    "# # policy saver\n",
    "# # ====================================================\n",
    "# saver = policy_saver.PolicySaver(\n",
    "#     policy = rank_agent.policy, \n",
    "#     # train_step=global_step\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4bb1d475-446e-498f-a4c1-a813de6352e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.bandits.policies.ranking_policy.DescendingScoreRankingPolicy at 0x7f929b9ad000>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = rank_agent.policy\n",
    "policy\n",
    "# isinstance(policy, tf_policy.TFPolicy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9ca1261c-7ed9-4661-a705-7b5d674a7ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "917"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9af553-9512-47e0-ae9d-d593139143e0",
   "metadata": {},
   "source": [
    "## Train config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "50ef435c-3d9b-432d-a5e2-ab5d60e93cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_DATA_SIZE : 900\n",
      "NUM_TRAIN_STEPS : 100\n",
      "EVAL_DATA_SIZE : 900\n",
      "NUM_EVAL_STEPS : 100\n",
      "CHKPT_INTERVAL: 99\n",
      "LOG_INTERVAL : 10\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA_SIZE = 900          # len(list(train_dataset))\n",
    "NUM_TRAIN_STEPS = 100            # TRAIN_DATA_SIZE // HPARAMS['batch_size']\n",
    "\n",
    "EVAL_DATA_SIZE  = 900          # len(list(val_dataset))\n",
    "NUM_EVAL_STEPS  = 100           # EVAL_DATA_SIZE // HPARAMS['eval_batch_size']\n",
    "\n",
    "CHKPT_INTERVAL  = NUM_TRAIN_STEPS - 1 # // 5\n",
    "LOG_INTERVAL    = 10\n",
    "# EVAL_INTERVAL = NUM_TRAIN_STEPS // 2\n",
    "\n",
    "print(f\"TRAIN_DATA_SIZE : {TRAIN_DATA_SIZE}\")\n",
    "print(f\"NUM_TRAIN_STEPS : {NUM_TRAIN_STEPS}\")\n",
    "print(f\"EVAL_DATA_SIZE : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS : {NUM_EVAL_STEPS}\")\n",
    "print(f\"CHKPT_INTERVAL: {CHKPT_INTERVAL}\")\n",
    "print(f\"LOG_INTERVAL : {LOG_INTERVAL}\")\n",
    "# print(f\"EVAL_INTERVAL : {EVAL_INTERVAL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d4fa546c-bb88-4fef-976d-98b245ee842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "train_ds_iterator = iter(train_dataset.batch(HPARAMS['batch_size']))\n",
    "# train_ds_iterator = iter(train_dataset)\n",
    "\n",
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS[\"eval_batch_size\"])\n",
    "# eval_ds = val_dataset.batch(HPARAMS[\"batch_size\"])\n",
    "\n",
    "if NUM_EVAL_STEPS > 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)\n",
    "\n",
    "# eval_ds = eval_ds.prefetch(tf.data.AUTOTUNE)\n",
    "# eval_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4d8449-6285-478a-8876-3f67c47cc6be",
   "metadata": {},
   "source": [
    "[ranking_agent](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/agents/ranking_agent.py#L288C1-L310C8)\n",
    "\n",
    "```\n",
    "  def _loss(\n",
    "      self,\n",
    "      experience: types.NestedTensor,\n",
    "      weights: Optional[types.Tensor] = None,\n",
    "      training: bool = False,\n",
    "  ) -> tf_agent.LossInfo:\n",
    "    \"\"\"Computes loss for training the reward and constraint networks.\n",
    "\n",
    "    Args:\n",
    "      experience: A batch of experience data in the form of a `Trajectory` or\n",
    "        `Transition`.\n",
    "      weights: Optional scalar or elementwise (per-batch-entry) importance\n",
    "        weights.  The output batch loss will be scaled by these weights, and the\n",
    "        final scalar loss is the mean of these values.\n",
    "      training: Whether the loss is being used for training.\n",
    "\n",
    "    Returns:\n",
    "      A `LossInfo` containing the loss for the training step.\n",
    "\n",
    "    Raises:\n",
    "      ValueError:\n",
    "        if the number of actions is greater than 1.\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "adae35ea-e3ff-4245-8c34-739dc70dec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# train setp function\n",
    "# ====================================================\n",
    "@tf.function\n",
    "def _train_step_fn():\n",
    "\n",
    "    data = next(train_ds_iterator)\n",
    "    trajectories = _rank_trajectory_fn(data)\n",
    "    loss = rank_agent.train(experience=trajectories)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "032770fc-8c04-4d3f-af21-9938501a7c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting train loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/__autograph_generated_filedfnvme4y.py:14: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  retval_ = ag__.and_(lambda : ag__.ld(state) is not None, lambda : ag__.and_(lambda : ag__.ld(state) is not (), lambda : ag__.ld(state) is not []))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0: train loss = 17.450000762939453\n",
      "step = 10: train loss = 3.009999990463257\n",
      "step = 20: train loss = 1.4500000476837158\n",
      "step = 30: train loss = 1.1200000047683716\n",
      "step = 40: train loss = 0.5899999737739563\n",
      "step = 50: train loss = 0.4699999988079071\n",
      "step = 60: train loss = 0.5400000214576721\n",
      "step = 70: train loss = 0.8199999928474426\n",
      "step = 80: train loss = 0.8700000047683716\n",
      "step = 90: train loss = 1.149999976158142\n",
      "saved policy to: gs://rec-bandits-v2-hybrid-vertex-bucket/local-ranker-rec-bandits-v2/run-20231018-230837/root/chkpoint\n",
      "train runtime_mins: 6\n"
     ]
    }
   ],
   "source": [
    "list_o_loss = []\n",
    "\n",
    "rank_agent.train_step_counter.assign(0)\n",
    "\n",
    "print(f\"starting train loop...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(NUM_TRAIN_STEPS):\n",
    "    \n",
    "    with train_summary_writer.as_default():\n",
    "\n",
    "        step = rank_agent.train_step_counter.numpy()\n",
    "        \n",
    "#         data = next(train_ds_iterator)\n",
    "#         trajectories = _rank_trajectory_fn(data)\n",
    "\n",
    "#         # All tensors in experience must be shaped [batch, time, ...] \n",
    "#         loss = rank_agent.train(experience=trajectories)\n",
    "\n",
    "        loss = _train_step_fn()\n",
    "        list_o_loss.append(loss.loss.numpy())\n",
    "        \n",
    "        train_utils._export_metrics_and_summaries(\n",
    "            step=i, \n",
    "            metrics=metrics\n",
    "        )\n",
    "        \n",
    "        # print step loss\n",
    "        if step % LOG_INTERVAL == 0:\n",
    "            print(\n",
    "                'step = {0}: train loss = {1}'.format(\n",
    "                    step, round(loss.loss.numpy(), 2)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if i > 0 and i % CHKPT_INTERVAL == 0:\n",
    "            checkpoint_manager.save()\n",
    "            # saver.save(os.path.join(CHKPOINT_DIR, 'policy_%d' % step_metric.result()))\n",
    "            print(f\"saved policy to: {CHKPOINT_DIR}\")\n",
    "            \n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"train runtime_mins: {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b818bc45-7a81-4cc8-974d-4da4f171b8d6",
   "metadata": {},
   "source": [
    "## Evaluate train job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "01e6207f-de75-4e93-b7e0-4e2fecbc6211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_o_loss)\n",
    "# plt.ylim([0, 10])\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3e6532-1bb5-4816-a37e-980074468239",
   "metadata": {},
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e657df42-b168-46f2-9b21-f99a91315a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/local-ranker-rec-bandits-v2/run-20231018-230837/logs/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/local-ranker-rec-bandits-v2/run-20231018-230837/logs/events.out.tfevents.1697670521.jt-tfa-bandit-rankers-2023-v2.3003352.0.v2\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls $LOG_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6b5e10ef-9f79-4030-b863-c821b695b957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "85177c16-2b71-4be4-b378-59aa2cc8913a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ff302a4ba1c706f6\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ff302a4ba1c706f6\");\n",
       "          const url = new URL(\"/proxy/6007/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=$LOG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265ca435-3e97-4d4e-b583-2f83040f041c",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "**Prediction response**\n",
    "> **TODO:** explain prediction response, e.g., `predicted_rewards_mean=array([3.1828353, 3.6808753]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "36d9b4d5-1ce0-4245-b0e5-a6c7e3135a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.bandits.policies.ranking_policy.DescendingScoreRankingPolicy at 0x7f929b9ad000>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_agent = rank_agent.policy\n",
    "deployment_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "977399bc-1d75-4dc2-bb2d-e7ff0a957a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.PyTFEagerPolicy at 0x7f910c6157b0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(deployment_agent, use_tf_function=True)\n",
    "post_policy_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a948171e-984a-46c7-871a-02fbfb67ee1b",
   "metadata": {},
   "source": [
    "## Get Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cf4fd4-6f7f-4505-b86e-49ee44fc66f8",
   "metadata": {},
   "source": [
    "To generate an inference request, we need to create a single [TimeStep](https://github.com/tensorflow/agents/blob/master/tf_agents/trajectories/time_step.py#L54C1-L64C3) with the following schema:\n",
    "\n",
    "```python\n",
    "class TimeStep(\n",
    "    NamedTuple(\n",
    "        'TimeStep',\n",
    "        [\n",
    "            ('step_type', types.SpecTensorOrArray),\n",
    "            ('reward', types.NestedSpecTensorOrArray),\n",
    "            ('discount', types.SpecTensorOrArray),\n",
    "            ('observation', types.NestedSpecTensorOrArray),\n",
    "        ],\n",
    "    )\n",
    "):\n",
    "```\n",
    "* the `infer_step` below is functionally equivalent to:\n",
    "\n",
    "```python\n",
    "prediction = post_policy_tf.action(\n",
    "    ts.restart(observation, batch_size=HPARAMS['eval_batch_size']), ()\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a627a3fa-890b-434c-8681-339327ec02f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "# dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "SKIP_NUM = 10\n",
    "\n",
    "for x in eval_ds.skip(SKIP_NUM).take(INFER_SIZE):\n",
    "    \n",
    "    # global context features\n",
    "    global_features = _get_global_context_features(x)\n",
    "    global_features = tf.reshape(global_features, [GLOBAL_DIM]) # flatten\n",
    "    \n",
    "    # TODO: pass   : NUM_ITEMS items to trained policy\n",
    "    #       return : ranking for NUM_SLOTS\n",
    "    arm_features = _get_per_arm_features(x)\n",
    "    arm_feat_infer = tf.reshape(arm_features, [ HPARAMS['num_slots'], HPARAMS['eval_batch_size'], PER_ARM_DIM ]) # perarm_dim\n",
    "    arm_feat_infer = train_utils._remove_outer_dimension(arm_feat_infer)\n",
    "    \n",
    "    # train observation\n",
    "    observation = {'global': global_features, 'per_arm': arm_feat_infer}\n",
    "    \n",
    "    ranking_rewards = _get_ranking_rewards_sv(x)\n",
    "    \n",
    "    action = np.zeros((HPARAMS['num_slots']), dtype=np.int32)\n",
    "    discount = np.zeros((HPARAMS['num_slots']), dtype=np.float32)\n",
    "    \n",
    "    infer_step = ts.TimeStep(\n",
    "        step_type = tf.constant(\n",
    "            ts.StepType.FIRST, \n",
    "            dtype=tf.int32, \n",
    "            shape=[],\n",
    "            name='step_type'\n",
    "        ),\n",
    "        reward = ranking_rewards,\n",
    "        discount = tf.constant(\n",
    "            1.0, dtype=tf.float32, shape=[], name='discount'\n",
    "        ),\n",
    "        observation = observation\n",
    "    )\n",
    "    \n",
    "    prediction = post_policy_tf.action(infer_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8990e512-7099-476d-bd55-44be8f49256b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array([0, 1], dtype=int32), state=(), info=PolicyInfo(log_probability=(), predicted_rewards_mean=array([3.4593716, 3.2745495], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=()))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "082cee1d-703e-4143-8c78-d1976a6d341c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6112efc7-3e76-46d4-902e-a7c009a1d13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.4593716, 3.2745495], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info.predicted_rewards_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6066995c-5c9c-485c-96a2-973b65107471",
   "metadata": {},
   "source": [
    "### tmp - debugging\n",
    "\n",
    "> compare to prediction from infer_steps, where actual rewards are provided.. does this impact?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a2450fbd-ad0d-4270-a4db-d662c9ef09b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array([0, 1], dtype=int32), state=(), info=PolicyInfo(log_probability=(), predicted_rewards_mean=array([3.4593716, 3.2745495], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=()))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = post_policy_tf.action(\n",
    "    ts.restart(observation, batch_size=HPARAMS['eval_batch_size']), ()\n",
    ")\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bddd75a-21b0-4d09-9518-785246bd0a10",
   "metadata": {},
   "source": [
    "## Load a trained Ranking Bandit policy\n",
    "\n",
    "Here we'll show how to load a trained policy, as you would for a prediction endpoint. You need 3 objects to restore a trained policy from the last checkpoint:\n",
    "* **agent**: a tf-agents agent object following the same specs used during training\n",
    "* **metrics**: metrics tracked during training\n",
    "* **step metric**: `tf_metrics.EnvironmentSteps()` \n",
    "\n",
    "Becasue we already have these initialized in this notebook session, we can resuse them here and just pass the root folder of latest checkpoint (e.g., `CHKPOINT_DIR`)\n",
    "* this restores the `agent` object to reflect the checkpointed policy\n",
    "> Note: when restoring the checkpointed policy in a new environment, we'll need to also initialize the three python objects above\n",
    "\n",
    "Then, we wrap the loaded policy with [PyTFEagerPolicy()](https://www.tensorflow.org/agents/api_docs/python/tf_agents/policies/PyTFEagerPolicy) to use it in eager mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5ac794d1-b753-468e-9d3a-aee50620c910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/local-ranker-rec-bandits-v2/run-20231018-230837/root/chkpoint/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/local-ranker-rec-bandits-v2/run-20231018-230837/root/chkpoint/checkpoint\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/local-ranker-rec-bandits-v2/run-20231018-230837/root/chkpoint/ckpt-1.data-00000-of-00001\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/local-ranker-rec-bandits-v2/run-20231018-230837/root/chkpoint/ckpt-1.index\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $CHKPOINT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5e33ce02-664f-4d64-9405-90b368425862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank_agent\n",
    "# metrics\n",
    "# step_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2fecf83a-57b7-4fde-85bc-8f6f8a142816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint_management.CheckpointManager at 0x7f910c457ca0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restore_policy = train_utils.restore_and_get_checkpoint_manager(\n",
    "      CHKPOINT_DIR, rank_agent, metrics, step_metric\n",
    "  )\n",
    "restore_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c5fe51de-a204-43c3-8ff6-cab00ae79908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.PyTFEagerPolicy at 0x7f91c0550970>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "deployment_agent = rank_agent.policy\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(deployment_agent, use_tf_function=True)\n",
    "post_policy_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e852bc-3af3-4bac-b107-d070eb93740b",
   "metadata": {},
   "source": [
    "#### Test inference with restored policy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e1a82da1-5db4-4b57-aa52-d7f674e4ea88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array([0, 1], dtype=int32), state=(), info=PolicyInfo(log_probability=(), predicted_rewards_mean=array([3.4593716, 3.2745495], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=()))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = post_policy_tf.action(\n",
    "    ts.restart(observation, batch_size=HPARAMS['eval_batch_size']), ()\n",
    ")\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f05ccfd-7263-40a7-813e-453ad90daad0",
   "metadata": {},
   "source": [
    "# Evaluation Loop\n",
    "\n",
    "> Evaluate the agent's policy after training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce0ee84-05e9-4e70-83c7-799ef0b37187",
   "metadata": {},
   "source": [
    "### Sampling rankings\n",
    "We will use the above critic model to compute scores for each of the items to rank.\n",
    "A simple way to produce a ranking is to score each item and sort them by predicted rewards.\n",
    "To induce exploration, we could occasionally ignore the predicted reward and produce random lists in an epsilon-greedy manner.\n",
    "\n",
    "Alternatively, we could produce a score of all the items and use the Plackett Luce distribution to sample permutations of the items.\n",
    "An implementation exists in tf probability:\n",
    "\n",
    "```python\n",
    "scores = [...]\n",
    "dist = tfd.PlackettLuce(scores)  # Scores have to be non-negative.\n",
    "sample = dist.sample(...)\n",
    "# We can also compute sampling probabilities of the ranking\n",
    "prob = dist.prob(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "30e5df69-e6c0-4345-98cc-2a0d3d1abcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _levenshtein_distance(hypothesis, truth):\n",
    "    dist_tensor = tf.edit_distance(\n",
    "        tf.sparse.from_dense(tf.constant(hypothesis, dtype=tf.int32)),\n",
    "        tf.sparse.from_dense(tf.constant(truth, dtype=tf.int32)),\n",
    "    )\n",
    "    return dist_tensor\n",
    "\n",
    "def _get_rewards_from_input_features(\n",
    "    data: Dict[str, tf.Tensor],\n",
    "    num_slots: int,\n",
    ") -> tf.Tensor:\n",
    "    \n",
    "    unmasked_rewards = _get_ranking_rewards_sv(data)\n",
    "    \n",
    "    _, num_arms = unmasked_rewards.get_shape().as_list()\n",
    "    mask = tf.expand_dims(tf.range(num_arms), axis=0) < tf.expand_dims(\n",
    "        num_slots, axis=-1\n",
    "    )\n",
    "    masked_rewards = tf.where(mask, unmasked_rewards, float('-5000000'))\n",
    "    \n",
    "    return masked_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "da61e837-0482-4cd6-b36e-22404ba732ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFER_SIZE = 1\n",
    "# dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "# SKIP_NUM = 10\n",
    "\n",
    "def evaluate_ranking(\n",
    "    agent_policy,\n",
    "    data: Dict[str, tf.Tensor],\n",
    "    batch_size: int,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \n",
    "    unranked_rewards = _get_rewards_from_input_features(\n",
    "        data=data, \n",
    "        num_slots=HPARAMS['num_slots']\n",
    "    )\n",
    "    # rewards calc - array([[0, 1]])\n",
    "    optimal_ranking = np.argsort(unranked_rewards)[:, ::-1][\n",
    "      :, :HPARAMS['num_slots']\n",
    "    ]\n",
    "    optimal_rewards = np.take(unranked_rewards, optimal_ranking, axis=None)\n",
    "    \n",
    "    # global context features\n",
    "    global_features = _get_global_context_features(data)\n",
    "    global_features = tf.reshape(global_features, [GLOBAL_DIM]) # flatten\n",
    "    \n",
    "    # TODO: pass   : NUM_ITEMS items to trained policy\n",
    "    #       return : ranking for NUM_SLOTS\n",
    "    arm_features = _get_per_arm_features(x)\n",
    "    arm_feat_infer = tf.reshape(\n",
    "        arm_features, \n",
    "        [ HPARAMS['num_slots'], HPARAMS['eval_batch_size'], PER_ARM_DIM ]\n",
    "    )\n",
    "    arm_feat_infer = train_utils._remove_outer_dimension(arm_feat_infer)\n",
    "    \n",
    "    # train observation\n",
    "    observation = {'global': global_features, 'per_arm': arm_feat_infer}\n",
    "    \n",
    "    # get predicted rewards / ranking\n",
    "    prediction = agent_policy.action(\n",
    "        ts.restart(observation, batch_size=HPARAMS['eval_batch_size']), ()\n",
    "    )\n",
    "    candidate_rewards = prediction.info.predicted_rewards_mean\n",
    "    candidate_ranking = pred_test.action\n",
    "    valid_candidate_ranking = candidate_ranking[:HPARAMS['num_slots']]\n",
    "    \n",
    "    batched_candidate_rewards = np.take(\n",
    "        candidate_rewards, valid_candidate_ranking\n",
    "    )\n",
    "    \n",
    "    # compute metrics\n",
    "    batched_rewards_diff = np.abs(optimal_rewards - batched_candidate_rewards)\n",
    "    mean_rewards_diff = tf.math.reduce_mean(\n",
    "        batched_rewards_diff, axis=None,\n",
    "    )\n",
    "    \n",
    "    # TODO\n",
    "    # batched_edit_dist = _levenshtein_distance(valid_candidate_ranking, optimal_ranking)\n",
    "    \n",
    "    return mean_rewards_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0bdd5b77-1446-47b0-8287-8b85d8ca744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_LOOP_BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0a4a09c5-0eb4-4d43-b250-1b8080e7d514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie_genres': <tf.Tensor: shape=(1, 3), dtype=int64, numpy=array([[3, 0, 0]])>,\n",
       " 'movie_id': <tf.Tensor: shape=(1, 3), dtype=string, numpy=array([[b'94', b'245', b'403']], dtype=object)>,\n",
       " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'346'], dtype=object)>,\n",
       " 'user_rating': <tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[3., 4., 3.]], dtype=float32)>}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    \n",
    "    iterator = iter(train_dataset.batch(EVAL_LOOP_BATCH_SIZE))\n",
    "    data = next(iterator)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9e9781d8-fb68-4772-9561-570cacd35101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.95380306>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_test = evaluate_ranking(\n",
    "    agent_policy=post_policy_tf,\n",
    "    data=data,\n",
    "    batch_size=HPARAMS['eval_batch_size']\n",
    ")\n",
    "eval_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9719344-0c90-43a0-97b3-88e64f15f4ab",
   "metadata": {},
   "source": [
    "### Compare with untrained policy and random rankings\n",
    "\n",
    "> **TODO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "940e8a03-b696-4ece-b7f7-ca377425fbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_random_ranking(\n",
    "    num_ranked_items: int, num_allowed_values: int, batch_size: int\n",
    "):\n",
    "    \"\"\"Returns a batch of `batch_size` rankings each of length `num_ranked_items`.\n",
    "\n",
    "    1. If `num_ranked_items` is no greater than `num_allowed_values`, each ranking\n",
    "    is a subset of [0, 1, ..., num_allowed_values - 1], of size\n",
    "    `num_ranked_items`.\n",
    "    2. If `num_ranked_items` is greater than `num_allowed_values`, the first\n",
    "    `num_allowed_values` of each ranking is a permutation of\n",
    "    [0, 1, ... num_allowed_values - 1]. The remaining `num_ranked_items -\n",
    "    num_allowed_values` of the ranking are unspecified.\n",
    "\n",
    "    Args:\n",
    "    num_ranked_items: the expected number of items in the output ranking, as\n",
    "      specified in the study config.\n",
    "    num_allowed_values: the number of items to select from.\n",
    "    batch_size: the number of batches of random rankings to return.\n",
    "    \"\"\"\n",
    "    num_valid_indices = min(num_ranked_items, num_allowed_values)\n",
    "    ranking = np.full(\n",
    "        (batch_size, num_ranked_items), np.iinfo(np.int32).max, dtype=np.int32\n",
    "    )\n",
    "    for idx in range(batch_size):\n",
    "        ranking[idx, :num_valid_indices] = np.random.choice(\n",
    "            num_allowed_values, size=num_valid_indices, replace=False\n",
    "        )\n",
    "    return ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "1de89282-54f3-470c-b833-f2ff46a1b223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [2, 0],\n",
       "       [1, 0],\n",
       "       [0, 2]], dtype=int32)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_rank_batch = _create_random_ranking(\n",
    "    num_ranked_items=HPARAMS['num_slots'],\n",
    "    num_allowed_values=HPARAMS['num_items'],\n",
    "    batch_size=HPARAMS['batch_size']\n",
    ")\n",
    "rand_rank_batch"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
