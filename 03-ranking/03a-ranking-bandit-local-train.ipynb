{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f462e3ae-0544-4a09-8345-01fc822192f0",
   "metadata": {},
   "source": [
    "# Contextual Bandits for Ranking with TF-Agents\n",
    "\n",
    "> see [ranking tutorial](https://www.tensorflow.org/agents/tutorials/ranking_tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214b2409-ca72-4a2f-972b-32185fbf441c",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "* The contextual bandits approach is classified as an extension of multi-armed bandits\n",
    "* a contextual multi-armed banded problem is a simplified reinforcement learning algorithm where the agent takes an action from a set of possible actions \n",
    "\n",
    "> **TODO**\n",
    "\n",
    "The **Bandit Ranking** agent will be similar to the `NeuralEpsilonGreedy` agent. Main differences:\n",
    "\n",
    "* The item features are stored in the `per_arm` part of the observation, in the order of how they are recommended\n",
    "* Since this ordered list of items expresses what action was taken by the policy,\n",
    "the `action` value of the trajectory is not used by the agent.\n",
    "\n",
    "> Note: difference between the \"per-arm\" observation recieved by the policy vs the agent:\n",
    "\n",
    "While the agent receives the items in the recommendation slots, the policy receives the items that are available for recommendation. The user is responsible for converting the observation to the\n",
    "syntax required by the agent.\n",
    "\n",
    "\n",
    "The training observation contains the global features and the features of the items in the recommendation slots \n",
    "* The item features are stored in the `per_arm` part of the observation, in the order of how they are recommended\n",
    "* Note: since this ordered list of items expresses what action was taken by the policy, the action value of the trajectory is not used by the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce53b012-c8db-4874-90bc-e13ac83fae19",
   "metadata": {},
   "source": [
    "## Load notebook config\n",
    "\n",
    "* use the prefix defined in `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "056b54b6-79d5-4ed6-b94a-6a776fc7db36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "VERSION        = \"v2\"                       # TODO\n",
    "PREFIX         = f'rec-bandits-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d3596a1-670b-4974-b643-2079a5db0afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"rec-bandits-v2\"\n",
      "VERSION                  = \"v2\"\n",
      "\n",
      "BUCKET_NAME              = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_NAME    = \"mvlens_rec_bandits_v2\"\n",
      "BIGQUERY_TABLE_NAME      = \"training_dataset\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-rec-bandits-v2\"\n",
      "\n",
      "DOCKERNAME_01            = \"Dockerfile_train_my_perarm_env\"\n",
      "IMAGE_NAME_01            = \"train-my-perarm-env-v2\"\n",
      "IMAGE_URI_01             = \"gcr.io/hybrid-vertex/train-my-perarm-env-v2\"\n",
      "\n",
      "DOCKERNAME_02            = \"Dockerfile_perarm_feats\"\n",
      "IMAGE_NAME_02            = \"train-perarm-feats-v2\"\n",
      "IMAGE_URI_02             = \"gcr.io/hybrid-vertex/train-perarm-feats-v2\"\n",
      "\n",
      "DOCKERNAME_03            = \"Dockerfile_ranking_bandit\"\n",
      "IMAGE_NAME_03            = \"train-rank-bandit-v2\"\n",
      "IMAGE_URI_03             = \"gcr.io/hybrid-vertex/train-rank-bandit-v2\"\n",
      "\n",
      "DOCKERNAME_04            = \"Dockerfile_train_bandit_e2e\"\n",
      "IMAGE_NAME_04            = \"train-mab-e2e-v2\"\n",
      "IMAGE_URI_04             = \"gcr.io/hybrid-vertex/train-mab-e2e-v2\"\n",
      "\n",
      "DOCKERNAME_04_pred       = \"Dockerfile_pred_bandit_e2e\"\n",
      "IMAGE_NAME_04_pred       = \"pred-mab-e2e-v2\"\n",
      "IMAGE_URI_04_pred        = \"gcr.io/hybrid-vertex/pred-mab-e2e-v2\"\n",
      "\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/local_docker_tfa\"\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940507dd-369b-4b93-a0c5-4b2d0e079269",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4fec363-3a69-4fc6-ab38-706230fba418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70e611f2-2d75-4b8d-9c9b-3b4421f8e04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/03-ranking\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93b706f8-8739-426b-b3c0-49c5ae2163f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from collections import defaultdict\n",
    "from typing import Callable, Dict, List, Optional, TypeVar, Iterable, Tuple\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "# from tf_agents.agents import TFAgent\n",
    "\n",
    "# from tf_agents.bandits.environments import stationary_stochastic_per_arm_py_environment as p_a_env\n",
    "from tf_agents.bandits.environments.ranking_environment import FeedbackModel\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "# from tf_agents.drivers import dynamic_step_driver\n",
    "# from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "# from tf_agents.bandits.agents import lin_ucb_agent\n",
    "# from tf_agents.bandits.agents import linear_thompson_sampling_agent as lin_ts_agent\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent\n",
    "from tf_agents.bandits.agents import neural_linucb_agent\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "from tf_agents.bandits.policies import policy_utilities\n",
    "\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.bandits.environments import ranking_environment\n",
    "from tf_agents.bandits.agents import ranking_agent\n",
    "\n",
    "from tf_agents.utils import nest_utils\n",
    "from tf_agents.specs import array_spec\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# this repo\n",
    "from src.utils import train_utils\n",
    "from src.data import data_utils, data_config\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5bc92e4-dac3-468e-a0f5-26d48ec63620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d4c0818-64e0-4629-a9d8-2fed58a7086f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28167f0d-5870-40bb-ba1e-b4a2cc4bd7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b249f6-2e74-4e2a-bf04-be4bfd0732bd",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c726bc2-ff41-41b0-9671-113a499e55d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO\n",
    "\n",
    "MAX_LIST_LENGTH = 3\n",
    "\n",
    "def get_all_lw_features(MAX_LIST_LENGTH):\n",
    "    '''\n",
    "    listwise features\n",
    "    '''\n",
    "    feats = {\n",
    "        'user_id': tf.io.FixedLenFeature(shape=(), dtype=tf.string),\n",
    "        \"movie_id\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_LIST_LENGTH,)), \n",
    "        \"movie_genres\": tf.io.FixedLenFeature(dtype=tf.int64, shape=(MAX_LIST_LENGTH,)), \n",
    "        \"user_rating\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_LIST_LENGTH,))\n",
    "    }\n",
    "    return feats\n",
    "\n",
    "def parse_lw_tfrecord(example):\n",
    "    \"\"\"\n",
    "    Reads a serialized example from GCS and converts to tfrecord\n",
    "    \"\"\"\n",
    "    feats = get_all_lw_features(MAX_LIST_LENGTH)\n",
    "    \n",
    "    # example = tf.io.parse_single_example(\n",
    "    example = tf.io.parse_example(\n",
    "        example,\n",
    "        feats\n",
    "        # features=feats\n",
    "    )\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de644e7f-8a6b-4c64-858f-1618fc76e373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT: listwise-3n-val\n"
     ]
    }
   ],
   "source": [
    "# 3 | 5\n",
    "NUM_EXAMPLES_PER_LIST = MAX_LIST_LENGTH\n",
    "\n",
    "# SPLIT = \"val\"\n",
    "# SPLIT = \"listwise-val\"\n",
    "SPLIT = f\"listwise-{NUM_EXAMPLES_PER_LIST}n-val\"\n",
    "\n",
    "print(f\"SPLIT: {SPLIT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56222181-f72a-4a9c-946e-5cd94ab40caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/listwise-3n-val/ml-100k-listwise-3n-val.tfrecord\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls $BUCKET_URI/$DATA_GCS_PREFIX/$SPLIT/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b22408a-fbfc-4b56-8f4b-b12462329fd3",
   "metadata": {},
   "source": [
    "### Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8afaa02e-5638-40a8-964e-e51b27d433d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_genres': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([3, 0, 0])>,\n",
      " 'movie_id': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'94', b'245', b'403'], dtype=object)>,\n",
      " 'user_id': <tf.Tensor: shape=(), dtype=string, numpy=b'346'>,\n",
      " 'user_rating': <tf.Tensor: shape=(3,), dtype=float32, numpy=array([3., 4., 3.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "# SPLIT = \"val\"\n",
    "# SPLIT = \"listwise-val\"\n",
    "SPLIT = f\"listwise-{NUM_EXAMPLES_PER_LIST}n-val\"\n",
    "\n",
    "val_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        val_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "val_dataset = tf.data.TFRecordDataset(val_files)\n",
    "val_dataset = val_dataset.map(parse_lw_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "for example in val_dataset.take(1):\n",
    "    pprint(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46862c4-dcbb-4b2d-aa53-765204f79250",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e814c64-1c96-47fd-a0f4-4c56bb15e0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT = \"train\"\n",
    "# SPLIT = \"listwise-train\"\n",
    "# SPLIT = f\"listwise-{NUM_EXAMPLES_PER_LIST}n-train\"\n",
    "\n",
    "# train_files = []\n",
    "# for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "#     if '.tfrecord' in blob.name:\n",
    "#         train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "# train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "# train_dataset = train_dataset.map(data_utils.parse_lw_tfrecord)\n",
    "\n",
    "# for x in train_dataset.batch(1).take(1):\n",
    "#     pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6ca4675-7c73-49b5-8146-0e2966fd3cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9501973f-6c96-46ba-adaa-6d85450c1256",
   "metadata": {},
   "source": [
    "### Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4099e809-1152-4b27-b4aa-bc627652e45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE_VOCABS: False\n"
     ]
    }
   ],
   "source": [
    "GENERATE_VOCABS = False\n",
    "\n",
    "print(f\"GENERATE_VOCABS: {GENERATE_VOCABS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b136aa91-bc57-4acf-80f2-fff09b33acf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://mabv1-hybrid-vertex-bucket/vocabs/vocab_dict.pkl [Content-Type=application/octet-stream]...\n",
      "/ [1 files][142.9 KiB/142.9 KiB]                                                \n",
      "Operation completed over 1 objects/142.9 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{VOCAB_SUBDIR}/{VOCAB_FILENAME}'\n",
    "\n",
    "!gsutil cp gs://mabv1-hybrid-vertex-bucket/vocabs/vocab_dict.pkl $EXISTING_VOCAB_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2d881e8-b633-4c06-b8b0-c788e1806fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded storage object vocabs/vocab_dict.pkl from bucket rec-bandits-v2-hybrid-vertex-bucket to local file vocab_dict.pkl.\n",
      "'movie_id'\n",
      "'user_id'\n",
      "'user_occupation_text'\n",
      "'movie_genres'\n",
      "'bucketized_user_age'\n",
      "'max_timestamp'\n",
      "'min_timestamp'\n",
      "'timestamp_buckets'\n"
     ]
    }
   ],
   "source": [
    "data_utils.download_blob(\n",
    "    project_id = PROJECT_ID,\n",
    "    bucket_name = BUCKET_NAME, \n",
    "    source_blob_name = f\"{VOCAB_SUBDIR}/{VOCAB_FILENAME}\", \n",
    "    destination_file_name= VOCAB_FILENAME\n",
    ")\n",
    "\n",
    "filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "vocab_dict = pkl.load(filehandler)\n",
    "filehandler.close()\n",
    "\n",
    "for key in vocab_dict.keys():\n",
    "    pprint(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c58d83-52f1-4490-931b-3d65c157cc13",
   "metadata": {},
   "source": [
    "# Global & Per-Arm feature embedding models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5dc1c53-af82-400a-b841-32775855578d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_OOV_BUCKETS    : 2\n",
      "GLOBAL_EMB_SIZE    : 64\n",
      "MV_EMB_SIZE        : 32\n",
      "BATCH_SIZE         : 5\n",
      "EVAL_BATCH_SIZE    : 1\n",
      "NUM_ITEMS          : 3\n",
      "NUM_SLOTS          : 2\n",
      "DISTANCE_THRESHOLD : 0.5\n"
     ]
    }
   ],
   "source": [
    "NUM_OOV_BUCKETS       = 2\n",
    "GLOBAL_EMBEDDING_SIZE = 64 #64\n",
    "MV_EMBEDDING_SIZE     = 32 #32\n",
    "\n",
    "BATCH_SIZE            = 5 #128\n",
    "EVAL_BATCH_SIZE       = 1\n",
    "\n",
    "NUM_ITEMS             = NUM_EXAMPLES_PER_LIST # 3 | 5 \n",
    "NUM_SLOTS             = 2\n",
    "\n",
    "DISTANCE_THRESHOLD    = 0.5\n",
    "\n",
    "print(f\"NUM_OOV_BUCKETS    : {NUM_OOV_BUCKETS}\")\n",
    "print(f\"GLOBAL_EMB_SIZE    : {GLOBAL_EMBEDDING_SIZE}\")\n",
    "print(f\"MV_EMB_SIZE        : {MV_EMBEDDING_SIZE}\")\n",
    "print(f\"BATCH_SIZE         : {BATCH_SIZE}\")\n",
    "print(f\"EVAL_BATCH_SIZE    : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"NUM_ITEMS          : {NUM_ITEMS}\")\n",
    "print(f\"NUM_SLOTS          : {NUM_SLOTS}\")\n",
    "print(f\"DISTANCE_THRESHOLD : {DISTANCE_THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "833f62ac-e6bf-4892-a168-b5d075771fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie_genres': <tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n",
       " array([[3, 0, 0],\n",
       "        [7, 0, 0]])>,\n",
       " 'movie_id': <tf.Tensor: shape=(2, 3), dtype=string, numpy=\n",
       " array([[b'94', b'245', b'403'],\n",
       "        [b'678', b'127', b'343']], dtype=object)>,\n",
       " 'user_id': <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'346', b'602'], dtype=object)>,\n",
       " 'user_rating': <tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       " array([[3., 4., 3.],\n",
       "        [4., 5., 2.]], dtype=float32)>}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    \n",
    "    iterator = iter(train_dataset.batch(2))\n",
    "    data = next(iterator)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a281a7ae-be08-41c6-a648-caab55ad1235",
   "metadata": {},
   "source": [
    "## Embedding layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec8212d-0b97-4db8-8126-6693af06d55a",
   "metadata": {},
   "source": [
    "#### User ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcc2d6f1-4559-466d-8f0f-53fc5c3bd4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_input_layer = tf.keras.Input(\n",
    "    name=\"user_id\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.string\n",
    ")\n",
    "\n",
    "user_id_lookup = tf.keras.layers.StringLookup(\n",
    "    max_tokens=len(vocab_dict['user_id']) + NUM_OOV_BUCKETS,\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    mask_token=None,\n",
    "    vocabulary=vocab_dict['user_id'],\n",
    ")(user_id_input_layer)\n",
    "\n",
    "user_id_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['user_id']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=GLOBAL_EMBEDDING_SIZE\n",
    ")(user_id_lookup)\n",
    "\n",
    "user_id_embedding = tf.reduce_sum(user_id_embedding, axis=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c31717b-900e-44dd-8fa8-4692caa4dc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'346'], shape=(1,), dtype=string)\n",
      "tf.Tensor(\n",
      "[[ 0.04010255 -0.04543778  0.03528844 -0.02779794  0.01606346 -0.04410873\n",
      "   0.04941808  0.0084687   0.01206052  0.01402486 -0.01412093  0.03570401\n",
      "  -0.0354185  -0.00425742 -0.01662344 -0.00486838 -0.00718958  0.04732435\n",
      "  -0.02156346 -0.03570483 -0.03814508 -0.00841403  0.03560263 -0.02045989\n",
      "   0.03032671 -0.02340677 -0.03341466 -0.03881024 -0.01437631 -0.01886618\n",
      "  -0.03466279 -0.03282207  0.02514832  0.03716724 -0.02097406 -0.0461323\n",
      "  -0.02238611 -0.00361068 -0.00236709  0.02596292 -0.03855576  0.04814751\n",
      "  -0.00220082  0.00584515 -0.03362983  0.0282759  -0.00984144 -0.00417044\n",
      "   0.02766863  0.0040696  -0.01099653  0.01732634  0.0488448  -0.03796885\n",
      "   0.04882551 -0.00986376 -0.01510724 -0.03468521  0.03058935 -0.02681868\n",
      "   0.04078403 -0.02335308 -0.02481594 -0.03962201]], shape=(1, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_user_id_model = tf.keras.Model(inputs=user_id_input_layer, outputs=user_id_embedding)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(x[\"user_id\"])\n",
    "    print(test_user_id_model(x[\"user_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a114a3-1cdd-46c7-b68d-3f9f55e06280",
   "metadata": {},
   "source": [
    "#### Movie ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcc5a95f-8298-4d68-92c0-7d3887b8364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(vocab_dict['movie_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7c494c2-5a71-4de4-a1a0-746653f805dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_id_input_layer = tf.keras.Input(\n",
    "    name=\"movie_id\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.string\n",
    ")\n",
    "\n",
    "mv_id_lookup = tf.keras.layers.StringLookup(\n",
    "    max_tokens=len(vocab_dict['movie_id']) + NUM_OOV_BUCKETS,\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    mask_token=None,\n",
    "    vocabulary=vocab_dict['movie_id'],\n",
    ")(mv_id_input_layer)\n",
    "\n",
    "mv_id_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['movie_id']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=MV_EMBEDDING_SIZE\n",
    ")(mv_id_lookup)\n",
    "\n",
    "# mv_id_embedding = tf.reduce_sum(mv_id_embedding, axis=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c448c58-fbc8-42b1-aa3e-d69f113ee093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[b'94' b'245' b'403']], shape=(1, 3), dtype=string)\n",
      "tf.Tensor(\n",
      "[[[-0.02003234  0.04092951 -0.01339108 -0.02332037 -0.03724347\n",
      "   -0.02322731  0.03572148 -0.00112619 -0.01248081 -0.01089336\n",
      "   -0.04623542 -0.02553597  0.03432171  0.01875414 -0.03330195\n",
      "   -0.04585771 -0.00612348  0.00440346 -0.033195   -0.03314169\n",
      "    0.00309873  0.03147713  0.03995421 -0.03706999 -0.02855443\n",
      "    0.01179143  0.0096094   0.0160183   0.00089573 -0.03819654\n",
      "   -0.04810771  0.03284815]\n",
      "  [ 0.0452336  -0.0446237   0.01004624  0.01029867 -0.01470722\n",
      "   -0.01632408 -0.03594297 -0.01454274 -0.02415115  0.02342155\n",
      "    0.02150175  0.04178706  0.01034798 -0.01028613 -0.04637237\n",
      "    0.01532267 -0.0175491   0.04616717  0.01536964  0.01000583\n",
      "   -0.03586798 -0.04893023  0.02780337 -0.03170166  0.0254856\n",
      "    0.00300222 -0.01086091 -0.0410918   0.02990567 -0.01655321\n",
      "    0.03629005  0.02382785]\n",
      "  [-0.01028194 -0.00552274 -0.03291034 -0.04362024  0.03851095\n",
      "   -0.01557256 -0.03715938 -0.01013677  0.03757526  0.01967008\n",
      "    0.04958241 -0.04741151  0.04801014 -0.02157028 -0.02625756\n",
      "    0.04665891 -0.04955626 -0.0395178  -0.0224408  -0.04810356\n",
      "    0.03861208 -0.03178404 -0.00736641  0.03964093  0.01508414\n",
      "    0.01574398 -0.04806153 -0.02318398  0.01017133  0.04579265\n",
      "   -0.01798474 -0.01295393]]], shape=(1, 3, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_mv_id_model = tf.keras.Model(inputs=mv_id_input_layer, outputs=mv_id_embedding)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(x[\"movie_id\"])\n",
    "    list_length = x[\"movie_id\"].shape[1]\n",
    "    print(test_mv_id_model(x[\"movie_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5886b2a-011b-4648-9834-b8a1e2d343f2",
   "metadata": {},
   "source": [
    "#### Movie Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dee33311-d565-4003-8d28-0d3dfc0ca68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(vocab_dict['movie_genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "052db904-0935-44db-bbba-548aa7b01c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_genre_input_layer = tf.keras.Input(\n",
    "    name=\"movie_genres\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "mv_genre_lookup = tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=vocab_dict['movie_genres'],\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    oov_value=0,\n",
    ")(mv_genre_input_layer)\n",
    "\n",
    "mv_genre_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['movie_genres']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=MV_EMBEDDING_SIZE\n",
    ")(mv_genre_lookup)\n",
    "\n",
    "# mv_genre_embedding = tf.reduce_sum(mv_genre_embedding, axis=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0cd72900-c9bc-4349-8984-8c0218c08efe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[3 0 0]\n",
      " [7 0 0]], shape=(2, 3), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-0.01231396 -0.02697052 -0.03185751  0.02671099 -0.04963989\n",
      "    0.0131535   0.00195374 -0.00433568 -0.02522801  0.03704992\n",
      "    0.01592027 -0.00546492 -0.047193   -0.04109423 -0.00881087\n",
      "    0.01254534 -0.04379457 -0.02866324  0.00020381 -0.00356206\n",
      "   -0.02703892  0.00540763 -0.03531309 -0.00675507 -0.00898786\n",
      "   -0.00167026 -0.03961641  0.00648559  0.03052847  0.04439399\n",
      "    0.03153162 -0.02140764]\n",
      "  [-0.01852424 -0.0212498   0.00283723  0.0308897   0.04614348\n",
      "   -0.04954416  0.01516707 -0.0140155  -0.04853408  0.03793415\n",
      "   -0.04167362  0.04353284 -0.01230878 -0.03490299 -0.00195529\n",
      "    0.01163899 -0.04779117  0.02383946  0.01208454 -0.00476938\n",
      "   -0.01498324 -0.02871478 -0.03535169 -0.04151267 -0.04982547\n",
      "    0.00022034 -0.0248103  -0.00853004  0.03795015 -0.022112\n",
      "   -0.03966822  0.04155074]\n",
      "  [-0.01852424 -0.0212498   0.00283723  0.0308897   0.04614348\n",
      "   -0.04954416  0.01516707 -0.0140155  -0.04853408  0.03793415\n",
      "   -0.04167362  0.04353284 -0.01230878 -0.03490299 -0.00195529\n",
      "    0.01163899 -0.04779117  0.02383946  0.01208454 -0.00476938\n",
      "   -0.01498324 -0.02871478 -0.03535169 -0.04151267 -0.04982547\n",
      "    0.00022034 -0.0248103  -0.00853004  0.03795015 -0.022112\n",
      "   -0.03966822  0.04155074]]\n",
      "\n",
      " [[-0.0327348   0.01579306  0.01932282 -0.02961146  0.03214499\n",
      "    0.00660412  0.01358132  0.02532453 -0.02173284  0.00680885\n",
      "    0.03834474  0.02170448 -0.04685168 -0.03316953 -0.01937813\n",
      "   -0.03860035 -0.0024457  -0.02461908  0.04333209  0.03092437\n",
      "   -0.03725444  0.04414568 -0.02300518  0.03885132 -0.03654063\n",
      "    0.01512465  0.02209142  0.00982436 -0.04249685 -0.00303226\n",
      "    0.03315354 -0.0067763 ]\n",
      "  [-0.01852424 -0.0212498   0.00283723  0.0308897   0.04614348\n",
      "   -0.04954416  0.01516707 -0.0140155  -0.04853408  0.03793415\n",
      "   -0.04167362  0.04353284 -0.01230878 -0.03490299 -0.00195529\n",
      "    0.01163899 -0.04779117  0.02383946  0.01208454 -0.00476938\n",
      "   -0.01498324 -0.02871478 -0.03535169 -0.04151267 -0.04982547\n",
      "    0.00022034 -0.0248103  -0.00853004  0.03795015 -0.022112\n",
      "   -0.03966822  0.04155074]\n",
      "  [-0.01852424 -0.0212498   0.00283723  0.0308897   0.04614348\n",
      "   -0.04954416  0.01516707 -0.0140155  -0.04853408  0.03793415\n",
      "   -0.04167362  0.04353284 -0.01230878 -0.03490299 -0.00195529\n",
      "    0.01163899 -0.04779117  0.02383946  0.01208454 -0.00476938\n",
      "   -0.01498324 -0.02871478 -0.03535169 -0.04151267 -0.04982547\n",
      "    0.00022034 -0.0248103  -0.00853004  0.03795015 -0.022112\n",
      "   -0.03966822  0.04155074]]], shape=(2, 3, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_mv_gen_model = tf.keras.Model(inputs=mv_genre_input_layer, outputs=mv_genre_embedding)\n",
    "\n",
    "for x in train_dataset.batch(2).take(1):\n",
    "    print(x[\"movie_genres\"])\n",
    "    print(test_mv_gen_model(x[\"movie_genres\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0415398e-3bbd-4497-aa31-1d618325fbb1",
   "metadata": {},
   "source": [
    "## Sampling Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343c1dee-fc37-4075-8d65-6909d548eb43",
   "metadata": {},
   "source": [
    "#### item sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8883e1c-0448-4486-bc2e-4ae3e3e54919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_per_arm_features(x):\n",
    "    \"\"\"\n",
    "    This function generates a single per-arm observation vector.\n",
    "    \"\"\"\n",
    "    ratings_list = x[\"user_rating\"] #[0]\n",
    "    indices = tf.argsort(ratings_list, direction=\"DESCENDING\")\n",
    "    _batch_size = len(ratings_list)\n",
    "    \n",
    "    mv_ids = test_mv_id_model(x[\"movie_id\"])\n",
    "    mv_gens = test_mv_gen_model(x[\"movie_genres\"])\n",
    "    \n",
    "    concat_embeddings = tf.concat(\n",
    "        [mv_ids, mv_gens], axis=-1\n",
    "    )\n",
    "    \n",
    "    ordered_concat = tf.gather(concat_embeddings, indices, batch_dims=1)\n",
    "    # feedback = tf.gather_nd(concat_embeddings, indices)\n",
    "    # print(f\"ordered_concat_embeddings: {ordered_concat_embeddings}\")\n",
    "    # ordered_concat = tf.reduce_sum(ordered_concat, axis=0)\n",
    "    \n",
    "    slotted_ordered_concat = tf.slice(\n",
    "        ordered_concat, begin=[0, 0, 0], size=[_batch_size, NUM_SLOTS, MV_EMBEDDING_SIZE * NUM_SLOTS]\n",
    "    )\n",
    "    \n",
    "    return slotted_ordered_concat\n",
    "    # return slotted_ordered_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d985e45c-7247-467d-80fb-fa977957e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 64), dtype=float32, numpy=\n",
       "array([[[ 0.0452336 , -0.0446237 ,  0.01004624,  0.01029867,\n",
       "         -0.01470722, -0.01632408, -0.03594297, -0.01454274,\n",
       "         -0.02415115,  0.02342155,  0.02150175,  0.04178706,\n",
       "          0.01034798, -0.01028613, -0.04637237,  0.01532267,\n",
       "         -0.0175491 ,  0.04616717,  0.01536964,  0.01000583,\n",
       "         -0.03586798, -0.04893023,  0.02780337, -0.03170166,\n",
       "          0.0254856 ,  0.00300222, -0.01086091, -0.0410918 ,\n",
       "          0.02990567, -0.01655321,  0.03629005,  0.02382785,\n",
       "         -0.01852424, -0.0212498 ,  0.00283723,  0.0308897 ,\n",
       "          0.04614348, -0.04954416,  0.01516707, -0.0140155 ,\n",
       "         -0.04853408,  0.03793415, -0.04167362,  0.04353284,\n",
       "         -0.01230878, -0.03490299, -0.00195529,  0.01163899,\n",
       "         -0.04779117,  0.02383946,  0.01208454, -0.00476938,\n",
       "         -0.01498324, -0.02871478, -0.03535169, -0.04151267,\n",
       "         -0.04982547,  0.00022034, -0.0248103 , -0.00853004,\n",
       "          0.03795015, -0.022112  , -0.03966822,  0.04155074],\n",
       "        [-0.02003234,  0.04092951, -0.01339108, -0.02332037,\n",
       "         -0.03724347, -0.02322731,  0.03572148, -0.00112619,\n",
       "         -0.01248081, -0.01089336, -0.04623542, -0.02553597,\n",
       "          0.03432171,  0.01875414, -0.03330195, -0.04585771,\n",
       "         -0.00612348,  0.00440346, -0.033195  , -0.03314169,\n",
       "          0.00309873,  0.03147713,  0.03995421, -0.03706999,\n",
       "         -0.02855443,  0.01179143,  0.0096094 ,  0.0160183 ,\n",
       "          0.00089573, -0.03819654, -0.04810771,  0.03284815,\n",
       "         -0.01231396, -0.02697052, -0.03185751,  0.02671099,\n",
       "         -0.04963989,  0.0131535 ,  0.00195374, -0.00433568,\n",
       "         -0.02522801,  0.03704992,  0.01592027, -0.00546492,\n",
       "         -0.047193  , -0.04109423, -0.00881087,  0.01254534,\n",
       "         -0.04379457, -0.02866324,  0.00020381, -0.00356206,\n",
       "         -0.02703892,  0.00540763, -0.03531309, -0.00675507,\n",
       "         -0.00898786, -0.00167026, -0.03961641,  0.00648559,\n",
       "          0.03052847,  0.04439399,  0.03153162, -0.02140764]],\n",
       "\n",
       "       [[ 0.03543215, -0.04916773, -0.03895855,  0.00633373,\n",
       "          0.00239933,  0.00790938, -0.00980097, -0.0028178 ,\n",
       "          0.04659594,  0.04171318, -0.01142697, -0.04696081,\n",
       "         -0.03278029, -0.01134853,  0.04062054, -0.01673611,\n",
       "          0.04319901, -0.01485408,  0.00768442, -0.00463817,\n",
       "         -0.03359784,  0.00431353,  0.04448256,  0.03320609,\n",
       "          0.03406382,  0.03834243,  0.03757345,  0.02173704,\n",
       "         -0.04862395, -0.02998655, -0.03879618,  0.0198445 ,\n",
       "         -0.01852424, -0.0212498 ,  0.00283723,  0.0308897 ,\n",
       "          0.04614348, -0.04954416,  0.01516707, -0.0140155 ,\n",
       "         -0.04853408,  0.03793415, -0.04167362,  0.04353284,\n",
       "         -0.01230878, -0.03490299, -0.00195529,  0.01163899,\n",
       "         -0.04779117,  0.02383946,  0.01208454, -0.00476938,\n",
       "         -0.01498324, -0.02871478, -0.03535169, -0.04151267,\n",
       "         -0.04982547,  0.00022034, -0.0248103 , -0.00853004,\n",
       "          0.03795015, -0.022112  , -0.03966822,  0.04155074],\n",
       "        [-0.02916787,  0.02099413, -0.0385459 ,  0.02292526,\n",
       "         -0.00742173,  0.01109351, -0.01062198, -0.03163775,\n",
       "          0.00712135, -0.00932329, -0.04612897, -0.02845101,\n",
       "         -0.04703759,  0.03618786,  0.04855777, -0.03665332,\n",
       "         -0.00113835, -0.0282829 , -0.03319444,  0.00853463,\n",
       "          0.00246701,  0.03233236,  0.04507393, -0.02064228,\n",
       "          0.02356709, -0.04339688, -0.00105531,  0.04618407,\n",
       "         -0.02700489,  0.02899834,  0.0201818 , -0.04990762,\n",
       "         -0.0327348 ,  0.01579306,  0.01932282, -0.02961146,\n",
       "          0.03214499,  0.00660412,  0.01358132,  0.02532453,\n",
       "         -0.02173284,  0.00680885,  0.03834474,  0.02170448,\n",
       "         -0.04685168, -0.03316953, -0.01937813, -0.03860035,\n",
       "         -0.0024457 , -0.02461908,  0.04333209,  0.03092437,\n",
       "         -0.03725444,  0.04414568, -0.02300518,  0.03885132,\n",
       "         -0.03654063,  0.01512465,  0.02209142,  0.00982436,\n",
       "         -0.04249685, -0.00303226,  0.03315354, -0.0067763 ]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arms = _get_per_arm_features(data)\n",
    "test_arms #.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd9b8a0a-6374-4584-8c99-1fd6adcbaea5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER_ARM_DIM: 64\n"
     ]
    }
   ],
   "source": [
    "test_arms = _get_per_arm_features(data)\n",
    "\n",
    "PER_ARM_DIM = test_arms.shape[2]            \n",
    "print(f\"PER_ARM_DIM: {PER_ARM_DIM}\")\n",
    "\n",
    "# test_arms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b01f1f2-a576-4b18-91ca-ee6c5bd90117",
   "metadata": {},
   "source": [
    "#### global sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dbffe5f6-8b37-448e-aadd-b578cfbe1395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_global_context_features(x):\n",
    "    \"\"\"\n",
    "    This function generates a single global observation vector.\n",
    "    \"\"\"\n",
    "    \n",
    "    return test_user_id_model(x['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1644300b-f7b7-4f38-9f31-f83ba74ecf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL_DIM: 64\n"
     ]
    }
   ],
   "source": [
    "test_globals = _get_global_context_features(data)\n",
    "\n",
    "GLOBAL_DIM = test_globals.shape[1] \n",
    "print(f\"GLOBAL_DIM: {GLOBAL_DIM}\")\n",
    "\n",
    "# test_globals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ada148e-e36b-4c98-ae5b-234aa9940055",
   "metadata": {},
   "source": [
    "# Ranking Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7fd210-4772-4073-9630-1173ac4f93e4",
   "metadata": {},
   "source": [
    "## Feedback type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a0da21-0b0f-4876-8b43-c012d1cc64c2",
   "metadata": {},
   "source": [
    "Ranking agents assume either a `score_vector` or `cascading feedback` framework for the feedback signal (reward). \n",
    "\n",
    "* `score_vector`: feedback is a vector of scores for every item in the slots. \n",
    "* `cascading feedback`: if the kth item was clicked, then the items up to k-1 receive a score of -1, the kth item receives a score based on a feedback value, while the rest of the items receive feedback of 0. \n",
    "\n",
    "Ranking agent objective: train the scoring network to be able to estimate the above scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c49a7375-ec9f-403d-aa86-810134cd430c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feedback_model = ranking_environment.FeedbackModel.CASCADING\n",
    "feedback_model = FeedbackModel.SCORE_VECTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b20c76-2950-4459-ab07-148cded078f2",
   "metadata": {},
   "source": [
    "## Tensor Specs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b43561b-f486-454e-a851-8cedfd6999d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "example Tensor Spec structures..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cbb948-52c5-44a3-80ab-4e57ba6968ea",
   "metadata": {},
   "source": [
    "`observation_spec()`\n",
    "\n",
    "```python\n",
    "{'global': TensorSpec(shape=(9,), dtype=tf.float32, name=None),\n",
    " 'per_arm': TensorSpec(shape=(50, 11), dtype=tf.float32, name=None)}\n",
    "```\n",
    "\n",
    "`action_spec()`\n",
    "\n",
    "```python\n",
    "BoundedTensorSpec(shape=(3,), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(49, dtype=int32))\n",
    "```\n",
    "\n",
    "`reward_spec()`\n",
    "\n",
    "```python\n",
    "{'chosen_index': BoundedTensorSpec(shape=(), dtype=tf.int32, name='chosen_index', minimum=array(0, dtype=int32), maximum=array(3, dtype=int32)),\n",
    " 'chosen_value': TensorSpec(shape=(), dtype=tf.float32, name='chosen_value')}\n",
    "```\n",
    "\n",
    "`time_step_spec()`\n",
    "\n",
    "```python\n",
    "TimeStep(\n",
    "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
    " 'observation': {'global': TensorSpec(shape=(9,), dtype=tf.float32, name=None),\n",
    "                 'per_arm': TensorSpec(shape=(50, 11), dtype=tf.float32, name=None)},\n",
    " 'reward': {'chosen_index': BoundedTensorSpec(shape=(), dtype=tf.int32, name='chosen_index', minimum=array(0, dtype=int32), maximum=array(3, dtype=int32)),\n",
    "            'chosen_value': TensorSpec(shape=(), dtype=tf.float32, name='chosen_value')},\n",
    " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d9cf3f-ac83-4580-a8f6-d98d93e49275",
   "metadata": {},
   "source": [
    "**from [ranking_environment.py](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/environments/ranking_environment.py#L152C1-L166C6)**\n",
    "\n",
    "```\n",
    "    global_spec = array_spec.ArraySpec.from_array(global_sampling_fn())\n",
    "    item_spec = array_spec.add_outer_dims_nest(\n",
    "        array_spec.ArraySpec.from_array(item_sampling_fn()), (num_items,)\n",
    "    )\n",
    "    observation_spec = {GLOBAL_KEY: global_spec, PER_ARM_KEY: item_spec}\n",
    "    self._global_dim = global_spec.shape[0]\n",
    "    self._item_dim = item_spec.shape[-1]\n",
    "\n",
    "    action_spec = array_spec.BoundedArraySpec(\n",
    "        shape=(num_slots,),\n",
    "        dtype=np.int32,\n",
    "        minimum=0,\n",
    "        maximum=num_items - 1,\n",
    "        name='action',\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae68b8a-8656-45cc-8977-70613629ce75",
   "metadata": {},
   "source": [
    "set vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5426bb09-834b-4cb3-9bf4-8d84482307e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE         : 5\n",
      "EVAL_BATCH_SIZE    : 1\n",
      "NUM_ITEMS          : 3\n",
      "NUM_SLOTS          : 2\n",
      "DISTANCE_THRESHOLD : 0.5\n",
      "GLOBAL_DIM         : 64\n",
      "PER_ARM_DIM        : 64\n"
     ]
    }
   ],
   "source": [
    "from tf_agents.specs import array_spec\n",
    "\n",
    "print(f\"BATCH_SIZE         : {BATCH_SIZE}\")\n",
    "print(f\"EVAL_BATCH_SIZE    : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"NUM_ITEMS          : {NUM_ITEMS}\")\n",
    "print(f\"NUM_SLOTS          : {NUM_SLOTS}\")\n",
    "print(f\"DISTANCE_THRESHOLD : {DISTANCE_THRESHOLD}\")\n",
    "print(f\"GLOBAL_DIM         : {GLOBAL_DIM}\")\n",
    "print(f\"PER_ARM_DIM        : {PER_ARM_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc572702-592c-4d60-8719-50739f611e16",
   "metadata": {},
   "source": [
    "### Observation spec\n",
    "\n",
    "* The observation the agent ingests contains the global features and the features\n",
    "of the items in the recommendation slots. \n",
    "* The item features are stored in the `per_arm` part of the observation, in the order of how they are recommended.\n",
    "* Since this ordered list of items expresses what action was taken by the policy, the `action` value of the trajectory is not used by the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b97866b-fb8c-4724-ac6f-ce789d5b7368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_spec = {\n",
    "    'global': tf.TensorSpec([GLOBAL_DIM], tf.float32),\n",
    "    # 'per_arm': tf.TensorSpec([NUM_ITEMS, PER_ARM_DIM], tf.float32)\n",
    "    'per_arm': tf.TensorSpec([NUM_SLOTS, PER_ARM_DIM], tf.float32)\n",
    "}\n",
    "observation_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80565f15-d41e-46db-99b3-6ea6a73ab6aa",
   "metadata": {},
   "source": [
    "### Action spec\n",
    "\n",
    "> Action spec for ranking models must have rank 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73b90ec0-1fe2-4b08-8a47-1fd32058705f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_spec rank: (2,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(2,), dtype=dtype('int32'), name='action', minimum=0, maximum=2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec = array_spec.BoundedArraySpec(\n",
    "    shape=(NUM_SLOTS,),\n",
    "    dtype=np.int32,\n",
    "    minimum=0,\n",
    "    maximum=NUM_ITEMS - 1,\n",
    "    name='action',\n",
    ")\n",
    "\n",
    "print(f\"action_spec rank: {action_spec.shape}\")\n",
    "\n",
    "action_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdacef1-fd61-4569-9bf7-299c52903710",
   "metadata": {},
   "source": [
    "### Reward spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "166f53bd-cdb9-49c4-a4d8-2904a6300f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(2,), dtype=tf.float32, name='score_vector')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if feedback_model == ranking_environment.FeedbackModel.CASCADING:\n",
    "    # `chosen_index == num_slots` means no recommended item was clicked.\n",
    "    reward_spec = {\n",
    "        'chosen_index': array_spec.BoundedArraySpec(\n",
    "            shape=[],\n",
    "            minimum=0,\n",
    "            maximum=NUM_SLOTS,\n",
    "            dtype=np.int32,\n",
    "            name='chosen_index',\n",
    "        ),\n",
    "        'chosen_value': array_spec.ArraySpec(\n",
    "            shape=[], dtype=np.float32, name='chosen_value'\n",
    "        ),\n",
    "    }\n",
    "elif feedback_model == ranking_environment.FeedbackModel.SCORE_VECTOR:\n",
    "    reward_spec = tf.TensorSpec(\n",
    "        shape=[NUM_SLOTS], dtype=np.float32, name='score_vector'\n",
    "    )\n",
    "    # reward_spec = array_spec.ArraySpec(\n",
    "    #     shape=[NUM_SLOTS], dtype=np.float32, name='score_vector'\n",
    "    # )\n",
    "else:\n",
    "    reward_spec = f\"Feedback model: {feedback_model}, not implemented\"\n",
    "    \n",
    "reward_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0deb69-a259-4495-a58e-81c0fd2a97ab",
   "metadata": {},
   "source": [
    "### TimeStep spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa7a5d0e-d4c2-4f8c-b67e-84fe6d1e4fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
       " 'reward': TensorSpec(shape=(2,), dtype=tf.float32, name='score_vector'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - investigate adding reward_spec\n",
    "\"\"\"\n",
    "TypeError: Expected observation and reward specs to \n",
    "both be either tensor or array specs, but saw spec values \n",
    "TensorSpec(shape=(64,), dtype=tf.float32, name=None) \n",
    "vs. ArraySpec(shape=(2,), dtype=dtype('float32'), name='score_vector')\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "time_step_spec = ts.time_step_spec(\n",
    "    observation_spec = observation_spec, \n",
    "    reward_spec = reward_spec             # TODO\n",
    ")\n",
    "time_step_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ecc66c-ce8b-480b-8306-40eaf399f120",
   "metadata": {},
   "source": [
    "Inspect chosen arm features spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "164a5760-3ca3-4397-85b3-26bbcd987b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec.observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad033e89-1f1c-4f63-9084-bf6a6807915f",
   "metadata": {},
   "source": [
    "## Policy and Scoring Network\n",
    "\n",
    "> all ranking agents train a network that estimates scores of item/user pairs\n",
    "\n",
    "**Ranking Policies**\n",
    "* `DESCENDING_SCORES` - Stack rank deterministically by scores\n",
    "* `NO_PENALTY` - Sampling sequentially based on scores; no penalty applied\n",
    "* `COSINE_DISTANCE` - Sampling sequentally and taking diversity into account\n",
    "\n",
    "`penalty_mixture` parameter governs the balance between ranking based on scores and accounting for diversity\n",
    "* low positive value --> ranking has less diversity\n",
    "* higher value --> enforces more diversity\n",
    "\n",
    "`logits_temperature` - temperature parameter for non-deterministic policies\n",
    "* This value must be positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ce99346-5745-4d87-a469-9a36cb270987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL_DIM  : 64\n",
      "PER_ARM_DIM : 64\n"
     ]
    }
   ],
   "source": [
    "print(f\"GLOBAL_DIM  : {GLOBAL_DIM}\")\n",
    "print(f\"PER_ARM_DIM : {PER_ARM_DIM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c5aea87d-c993-4cd6-80ad-0522dcc91956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 5,\n",
      " 'common_layers': [16, 8],\n",
      " 'eval_batch_size': 1,\n",
      " 'feedback_model': 2,\n",
      " 'global_layers': [64, 32, 16],\n",
      " 'learning_rate': 0.005,\n",
      " 'logits_temperature': 1.0,\n",
      " 'model_type': 'Ranking',\n",
      " 'network_type': 'dotproduct',\n",
      " 'num_items': 3,\n",
      " 'num_slots': 2,\n",
      " 'penalty_mixture': 1.0,\n",
      " 'per_arm_layers': [64, 32, 16],\n",
      " 'policy_type': <RankingPolicyType.DESCENDING_SCORES: 3>}\n"
     ]
    }
   ],
   "source": [
    "AGENT_TYPE = \"Ranking\"\n",
    "NETWORK_TYPE = \"dotproduct\"\n",
    "POLICY_TYPE = ranking_agent.RankingPolicyType.DESCENDING_SCORES # COSINE_DISTANCE | NO_PENALTY | DESCENDING_SCORES\n",
    "\n",
    "PENALTY_MIXTURE = 1.0\n",
    "LOGITS_TEMPERATURE = 1.0\n",
    "\n",
    "LEARNING_RATE = 0.005\n",
    "\n",
    "GLOBAL_LAYERS   = [64, 32, 16]\n",
    "ARM_LAYERS      = [64, 32, 16]\n",
    "COMMON_LAYERS   = [16, 8]\n",
    "\n",
    "HPARAMS = {  # TODO - streamline and consolidate\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"eval_batch_size\" : EVAL_BATCH_SIZE,\n",
    "    \"num_items\": NUM_ITEMS,\n",
    "    \"num_slots\": NUM_SLOTS,\n",
    "    \"model_type\": AGENT_TYPE,\n",
    "    \"network_type\": NETWORK_TYPE,\n",
    "    \"global_layers\": GLOBAL_LAYERS,\n",
    "    \"per_arm_layers\": ARM_LAYERS,\n",
    "    \"common_layers\": COMMON_LAYERS,\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"policy_type\": POLICY_TYPE,\n",
    "    \"feedback_model\" : feedback_model,\n",
    "    \"penalty_mixture\": PENALTY_MIXTURE,\n",
    "    \"logits_temperature\": LOGITS_TEMPERATURE,\n",
    "}\n",
    "pprint(HPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "80d4e8a9-6582-425d-9c50-499aa883b2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network: GlobalAndArmDotProductNetwork\n"
     ]
    }
   ],
   "source": [
    "if NETWORK_TYPE == 'commontower':\n",
    "    scoring_network = global_and_arm_feature_network.create_feed_forward_common_tower_network(\n",
    "        observation_spec = observation_spec, \n",
    "        global_layers = GLOBAL_LAYERS, \n",
    "        arm_layers = ARM_LAYERS, \n",
    "        common_layers = COMMON_LAYERS,\n",
    "        # output_dim = output_dim,\n",
    "    )\n",
    "    \n",
    "elif NETWORK_TYPE == 'dotproduct':\n",
    "    scoring_network = global_and_arm_feature_network.create_feed_forward_dot_product_network(\n",
    "        observation_spec = observation_spec, \n",
    "        global_layers = GLOBAL_LAYERS, \n",
    "        arm_layers = ARM_LAYERS\n",
    "    )\n",
    "    \n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {scoring_network.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1939dc-7ee9-414c-aa89-85b08bcfb4cb",
   "metadata": {},
   "source": [
    "## Define Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5dad7dd6-3d19-4c79-8a72-078253f046e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank_agent: ranking_agent\n"
     ]
    }
   ],
   "source": [
    "rank_agent = ranking_agent.RankingAgent(\n",
    "    time_step_spec=time_step_spec,\n",
    "    action_spec=action_spec,\n",
    "    scoring_network=scoring_network,\n",
    "    optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=HPARAMS['learning_rate']),\n",
    "    feedback_model=ranking_agent.FeedbackModel.SCORE_VECTOR, # FeedbackModel.SCORE_VECTOR, # feedback_model,\n",
    "    policy_type=HPARAMS['policy_type'],\n",
    "    logits_temperature=HPARAMS['logits_temperature'],\n",
    "    penalty_mixture_coefficient=HPARAMS['penalty_mixture'],\n",
    "    summarize_grads_and_vars=True\n",
    ")\n",
    "\n",
    "rank_agent.initialize()\n",
    "\n",
    "print(f'rank_agent: {rank_agent.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf04067d-7f83-43f7-bb97-88ddfd1b3d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.bandits.policies.ranking_policy.DescendingScoreRankingPolicy at 0x7f90acfbefe0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_agent.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a38e772e-80b8-4dfe-811d-83fae71c912c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(2,), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(2, dtype=int32))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_agent.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fd594bbd-383b-41a8-bc5e-317db5b93a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_agent.training_data_spec.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "21e2f27b-79b6-4ce6-bf61-0e777db54d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}),\n",
       " 'reward': TensorSpec(shape=(2,), dtype=tf.float32, name='score_vector'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_agent.policy.time_step_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d6040423-c390-4e1a-90a9-69b9ab58b23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(Trajectory(\n",
       "{'action': BoundedTensorSpec(shape=(2,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(1, dtype=int32)),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}),\n",
       " 'policy_info': PolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=()),\n",
       " 'reward': TensorSpec(shape=(2,), dtype=tf.float32, name='score_vector'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_agent.policy.trajectory_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46435a9d-c901-4d32-8baa-1da60c427788",
   "metadata": {},
   "source": [
    "### Reward function\n",
    "\n",
    "**TODO**\n",
    "* `_create_ranking_reward_features`\n",
    "* `_get_rewards_from_arm_features` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "90b521c4-bb43-4cc5-b0fa-67d420b64834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_ranking_rewards_sv(x):\n",
    "    \"\"\"Calculates reward for the actions.\"\"\"\n",
    "    \n",
    "    # rating_scores_list = []\n",
    "    ratings_list = x[\"user_rating\"] #[0]\n",
    "    indices = tf.argsort(ratings_list, direction=\"DESCENDING\")\n",
    "    \n",
    "    feedback = tf.gather(ratings_list, indices, batch_dims=-1) #.numpy()\n",
    "    \n",
    "    # feedback = tf.math.top_k(feedback, k=HPARAMS['num_slots']).values\n",
    "    top_n_ratings = tf.slice(feedback, begin=[0, 0], size=[-1, HPARAMS['num_slots']])\n",
    "    \n",
    "    return top_n_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "997dbdd4-7048-4d9f-8f65-f5e99a28ef1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[4., 3.],\n",
       "       [5., 4.]], dtype=float32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ratings = _get_ranking_rewards_sv(data)\n",
    "test_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "31976a8d-c4ba-4fc1-a429-e24f812aac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rank_trajectory_fn(element): # hparams\n",
    "    \"\"\"Converts a dataset element into a trajectory.\"\"\"\n",
    "    # global_features = _get_global_context_features(element)\n",
    "    # arm_features = _get_per_arm_features(element)\n",
    "    \n",
    "    global_features = _get_global_context_features(element)\n",
    "    arm_features = _get_per_arm_features(element)\n",
    "    \n",
    "    # obs spec\n",
    "    observation = {\n",
    "        bandit_spec_utils.GLOBAL_FEATURE_KEY:\n",
    "            train_utils._add_outer_dimension(global_features),\n",
    "            # global_features,\n",
    "        bandit_spec_utils.PER_ARM_FEATURE_KEY: \n",
    "            train_utils._add_outer_dimension(arm_features)\n",
    "            # arm_features\n",
    "    }\n",
    "    \n",
    "    # reward = element['user_rating']\n",
    "    ranking_rewards = _get_ranking_rewards_sv(element)\n",
    "\n",
    "    \n",
    "    # action = np.zeros((HPARAMS['num_slots']), dtype=np.int32)\n",
    "    action=tf.zeros_like(HPARAMS['num_slots'], dtype=tf.int32)\n",
    "    \n",
    "    # discount = np.zeros((HPARAMS['num_slots']), dtype=np.float32)\n",
    "    discount=tf.zeros_like(HPARAMS['num_slots'], dtype=tf.int32)\n",
    "    return trajectory.single_step(\n",
    "        observation=observation,\n",
    "        action=action,\n",
    "        policy_info=(), #policy_info,\n",
    "        reward=ranking_rewards,\n",
    "        discount=discount\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c8221e8a-cdf2-4944-9856-6a2371d3f782",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in train_dataset.batch(HPARAMS['batch_size']).take(1):\n",
    "    test_traj = _rank_trajectory_fn(x)\n",
    "    \n",
    "# test_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4d231c92-cf2a-496b-baa4-afeaee1af872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'action': <tf.Tensor: shape=(), dtype=int32, numpy=0>,\n",
       " 'discount': <tf.Tensor: shape=(), dtype=int32, numpy=0>,\n",
       " 'next_step_type': <tf.Tensor: shape=(), dtype=int32, numpy=2>,\n",
       " 'observation': {'global': <tf.Tensor: shape=(5, 1, 64), dtype=float32, numpy=\n",
       "array([[[ 0.04010255, -0.04543778,  0.03528844, -0.02779794,\n",
       "          0.01606346, -0.04410873,  0.04941808,  0.0084687 ,\n",
       "          0.01206052,  0.01402486, -0.01412093,  0.03570401,\n",
       "         -0.0354185 , -0.00425742, -0.01662344, -0.00486838,\n",
       "         -0.00718958,  0.04732435, -0.02156346, -0.03570483,\n",
       "         -0.03814508, -0.00841403,  0.03560263, -0.02045989,\n",
       "          0.03032671, -0.02340677, -0.03341466, -0.03881024,\n",
       "         -0.01437631, -0.01886618, -0.03466279, -0.03282207,\n",
       "          0.02514832,  0.03716724, -0.02097406, -0.0461323 ,\n",
       "         -0.02238611, -0.00361068, -0.00236709,  0.02596292,\n",
       "         -0.03855576,  0.04814751, -0.00220082,  0.00584515,\n",
       "         -0.03362983,  0.0282759 , -0.00984144, -0.00417044,\n",
       "          0.02766863,  0.0040696 , -0.01099653,  0.01732634,\n",
       "          0.0488448 , -0.03796885,  0.04882551, -0.00986376,\n",
       "         -0.01510724, -0.03468521,  0.03058935, -0.02681868,\n",
       "          0.04078403, -0.02335308, -0.02481594, -0.03962201]],\n",
       "\n",
       "       [[-0.01152606,  0.03594421, -0.00911896, -0.04928284,\n",
       "         -0.02271801,  0.02434542, -0.0057652 ,  0.03290001,\n",
       "          0.02997411, -0.04091697, -0.03353206, -0.02342552,\n",
       "          0.0036379 ,  0.0290713 ,  0.02740598, -0.01387304,\n",
       "          0.0264538 , -0.02338488,  0.03342943, -0.04379736,\n",
       "          0.01792904,  0.0278102 , -0.01919855,  0.04509497,\n",
       "          0.03876598, -0.02595126,  0.00334353, -0.00461161,\n",
       "          0.00854585,  0.01098721, -0.02128713,  0.01202487,\n",
       "         -0.00734518, -0.043897  , -0.03092794, -0.01306651,\n",
       "         -0.02124653,  0.01264303,  0.02344029, -0.00182533,\n",
       "          0.01925718,  0.01960888,  0.03121327, -0.00137477,\n",
       "         -0.02546294, -0.03917826,  0.00450692, -0.00861216,\n",
       "         -0.03340881,  0.04033032,  0.00557487,  0.02779287,\n",
       "          0.00297873, -0.02655277, -0.0114954 , -0.03719244,\n",
       "         -0.01924161,  0.00413508,  0.04353012,  0.04753416,\n",
       "         -0.01963796, -0.04622989, -0.01381927, -0.00669716]],\n",
       "\n",
       "       [[ 0.0015469 ,  0.01754535,  0.00399267, -0.0055296 ,\n",
       "          0.00064398,  0.01645349, -0.00033689,  0.02559854,\n",
       "         -0.00874727, -0.00166274,  0.03599792,  0.0262425 ,\n",
       "          0.02348328,  0.03356346, -0.042302  ,  0.00697637,\n",
       "         -0.02525492,  0.02208858, -0.02158276, -0.01764239,\n",
       "          0.03981756, -0.02219757,  0.04292735,  0.00258404,\n",
       "          0.03520026, -0.04009378,  0.04748509,  0.02946253,\n",
       "         -0.00591663, -0.02378091,  0.04001805, -0.02346085,\n",
       "          0.03108864,  0.03235512, -0.00831161, -0.03903353,\n",
       "          0.02972217,  0.01473786, -0.03838177,  0.02493565,\n",
       "          0.02068004,  0.04322514,  0.04738574, -0.01807059,\n",
       "         -0.0203588 ,  0.02760228,  0.03367204,  0.04258137,\n",
       "         -0.03414442, -0.02597353,  0.0104713 ,  0.04242137,\n",
       "          0.00487416, -0.00792228, -0.00841844, -0.00902056,\n",
       "          0.00273133,  0.03870464,  0.04640372,  0.03802044,\n",
       "          0.00987128,  0.03881988,  0.04756195,  0.04842117]],\n",
       "\n",
       "       [[ 0.01349377,  0.01663426, -0.0393452 , -0.0117512 ,\n",
       "          0.00922812,  0.02018308,  0.01211909,  0.04388077,\n",
       "         -0.03390666, -0.01607041,  0.03970755,  0.02969202,\n",
       "          0.04832883,  0.01022764, -0.03235294,  0.00530346,\n",
       "          0.0319143 , -0.02259212,  0.04071592,  0.01120801,\n",
       "          0.00444139, -0.04098669,  0.0344494 , -0.01991117,\n",
       "          0.004993  , -0.01659577,  0.03816882,  0.01455386,\n",
       "         -0.02734569, -0.00141286,  0.04313484,  0.00282564,\n",
       "         -0.01262282,  0.00056355, -0.00559915,  0.03155598,\n",
       "         -0.01435474,  0.03045578, -0.03463749, -0.01410576,\n",
       "          0.02563694, -0.0279599 , -0.03882655, -0.04827375,\n",
       "          0.02943169,  0.0443589 , -0.03608658, -0.02072829,\n",
       "          0.00647161, -0.02592818,  0.03995992, -0.01330014,\n",
       "         -0.03542512, -0.04876338, -0.0287209 , -0.0439366 ,\n",
       "          0.0210547 , -0.00791851,  0.04847899, -0.01573193,\n",
       "         -0.02779462, -0.03477566, -0.02794285, -0.00122429]],\n",
       "\n",
       "       [[-0.03916588, -0.03033378,  0.01695855, -0.04366891,\n",
       "         -0.04073608, -0.01738139, -0.03227096,  0.04127233,\n",
       "         -0.03316592, -0.02865493,  0.01385322, -0.0285206 ,\n",
       "         -0.00418639, -0.0487812 ,  0.0421455 ,  0.01738285,\n",
       "         -0.0396651 , -0.04009274,  0.02030912,  0.00990188,\n",
       "          0.01501874,  0.02738868,  0.04217017,  0.01840586,\n",
       "          0.00637816,  0.01284549, -0.03933347,  0.01238502,\n",
       "          0.00337372, -0.01518202,  0.03852478,  0.02157779,\n",
       "         -0.04223606,  0.02629134, -0.04462556, -0.03924287,\n",
       "          0.04874188,  0.03713585,  0.00253098, -0.00583059,\n",
       "          0.04715118,  0.0189671 , -0.03074936, -0.04138135,\n",
       "          0.04486015,  0.04103345, -0.00871824, -0.04508727,\n",
       "         -0.00854445, -0.0473178 , -0.03479688, -0.00941309,\n",
       "          0.02860144, -0.0489854 ,  0.01646198, -0.00482661,\n",
       "          0.04113993, -0.01252395, -0.00368024,  0.04316869,\n",
       "         -0.03337084,  0.04143644, -0.048086  , -0.0038434 ]]],\n",
       "      dtype=float32)>,\n",
       "                 'per_arm': <tf.Tensor: shape=(5, 1, 2, 64), dtype=float32, numpy=\n",
       "array([[[[ 0.0452336 , -0.0446237 ,  0.01004624,  0.01029867,\n",
       "          -0.01470722, -0.01632408, -0.03594297, -0.01454274,\n",
       "          -0.02415115,  0.02342155,  0.02150175,  0.04178706,\n",
       "           0.01034798, -0.01028613, -0.04637237,  0.01532267,\n",
       "          -0.0175491 ,  0.04616717,  0.01536964,  0.01000583,\n",
       "          -0.03586798, -0.04893023,  0.02780337, -0.03170166,\n",
       "           0.0254856 ,  0.00300222, -0.01086091, -0.0410918 ,\n",
       "           0.02990567, -0.01655321,  0.03629005,  0.02382785,\n",
       "          -0.01852424, -0.0212498 ,  0.00283723,  0.0308897 ,\n",
       "           0.04614348, -0.04954416,  0.01516707, -0.0140155 ,\n",
       "          -0.04853408,  0.03793415, -0.04167362,  0.04353284,\n",
       "          -0.01230878, -0.03490299, -0.00195529,  0.01163899,\n",
       "          -0.04779117,  0.02383946,  0.01208454, -0.00476938,\n",
       "          -0.01498324, -0.02871478, -0.03535169, -0.04151267,\n",
       "          -0.04982547,  0.00022034, -0.0248103 , -0.00853004,\n",
       "           0.03795015, -0.022112  , -0.03966822,  0.04155074],\n",
       "         [-0.02003234,  0.04092951, -0.01339108, -0.02332037,\n",
       "          -0.03724347, -0.02322731,  0.03572148, -0.00112619,\n",
       "          -0.01248081, -0.01089336, -0.04623542, -0.02553597,\n",
       "           0.03432171,  0.01875414, -0.03330195, -0.04585771,\n",
       "          -0.00612348,  0.00440346, -0.033195  , -0.03314169,\n",
       "           0.00309873,  0.03147713,  0.03995421, -0.03706999,\n",
       "          -0.02855443,  0.01179143,  0.0096094 ,  0.0160183 ,\n",
       "           0.00089573, -0.03819654, -0.04810771,  0.03284815,\n",
       "          -0.01231396, -0.02697052, -0.03185751,  0.02671099,\n",
       "          -0.04963989,  0.0131535 ,  0.00195374, -0.00433568,\n",
       "          -0.02522801,  0.03704992,  0.01592027, -0.00546492,\n",
       "          -0.047193  , -0.04109423, -0.00881087,  0.01254534,\n",
       "          -0.04379457, -0.02866324,  0.00020381, -0.00356206,\n",
       "          -0.02703892,  0.00540763, -0.03531309, -0.00675507,\n",
       "          -0.00898786, -0.00167026, -0.03961641,  0.00648559,\n",
       "           0.03052847,  0.04439399,  0.03153162, -0.02140764]]],\n",
       "\n",
       "\n",
       "       [[[ 0.03543215, -0.04916773, -0.03895855,  0.00633373,\n",
       "           0.00239933,  0.00790938, -0.00980097, -0.0028178 ,\n",
       "           0.04659594,  0.04171318, -0.01142697, -0.04696081,\n",
       "          -0.03278029, -0.01134853,  0.04062054, -0.01673611,\n",
       "           0.04319901, -0.01485408,  0.00768442, -0.00463817,\n",
       "          -0.03359784,  0.00431353,  0.04448256,  0.03320609,\n",
       "           0.03406382,  0.03834243,  0.03757345,  0.02173704,\n",
       "          -0.04862395, -0.02998655, -0.03879618,  0.0198445 ,\n",
       "          -0.01852424, -0.0212498 ,  0.00283723,  0.0308897 ,\n",
       "           0.04614348, -0.04954416,  0.01516707, -0.0140155 ,\n",
       "          -0.04853408,  0.03793415, -0.04167362,  0.04353284,\n",
       "          -0.01230878, -0.03490299, -0.00195529,  0.01163899,\n",
       "          -0.04779117,  0.02383946,  0.01208454, -0.00476938,\n",
       "          -0.01498324, -0.02871478, -0.03535169, -0.04151267,\n",
       "          -0.04982547,  0.00022034, -0.0248103 , -0.00853004,\n",
       "           0.03795015, -0.022112  , -0.03966822,  0.04155074],\n",
       "         [-0.02916787,  0.02099413, -0.0385459 ,  0.02292526,\n",
       "          -0.00742173,  0.01109351, -0.01062198, -0.03163775,\n",
       "           0.00712135, -0.00932329, -0.04612897, -0.02845101,\n",
       "          -0.04703759,  0.03618786,  0.04855777, -0.03665332,\n",
       "          -0.00113835, -0.0282829 , -0.03319444,  0.00853463,\n",
       "           0.00246701,  0.03233236,  0.04507393, -0.02064228,\n",
       "           0.02356709, -0.04339688, -0.00105531,  0.04618407,\n",
       "          -0.02700489,  0.02899834,  0.0201818 , -0.04990762,\n",
       "          -0.0327348 ,  0.01579306,  0.01932282, -0.02961146,\n",
       "           0.03214499,  0.00660412,  0.01358132,  0.02532453,\n",
       "          -0.02173284,  0.00680885,  0.03834474,  0.02170448,\n",
       "          -0.04685168, -0.03316953, -0.01937813, -0.03860035,\n",
       "          -0.0024457 , -0.02461908,  0.04333209,  0.03092437,\n",
       "          -0.03725444,  0.04414568, -0.02300518,  0.03885132,\n",
       "          -0.03654063,  0.01512465,  0.02209142,  0.00982436,\n",
       "          -0.04249685, -0.00303226,  0.03315354, -0.0067763 ]]],\n",
       "\n",
       "\n",
       "       [[[-0.01120303,  0.04464025, -0.03794692, -0.01269655,\n",
       "          -0.00753846,  0.04187322, -0.00903572, -0.00587891,\n",
       "           0.02665583,  0.01680635,  0.0165992 , -0.02183621,\n",
       "           0.00782214, -0.04063305, -0.00340043, -0.04104849,\n",
       "           0.0491049 , -0.00952163, -0.00872936,  0.02942841,\n",
       "          -0.04348835, -0.00633348, -0.0491582 , -0.03021177,\n",
       "          -0.03947653, -0.00265895, -0.04430984,  0.03599373,\n",
       "           0.04095869,  0.03547944,  0.04362306,  0.02298293,\n",
       "          -0.04425373, -0.02331542, -0.00885147,  0.02102016,\n",
       "           0.04650437, -0.0215982 , -0.01947412,  0.02295244,\n",
       "           0.04287547, -0.01086481, -0.01573907,  0.01484335,\n",
       "          -0.02486124,  0.01990033,  0.04925129,  0.02691462,\n",
       "           0.0473074 , -0.00204263,  0.04679689,  0.00896007,\n",
       "          -0.03934366, -0.03492532, -0.02872576,  0.01911731,\n",
       "          -0.0239509 , -0.0233881 ,  0.03671112, -0.01719984,\n",
       "          -0.00715537, -0.04603363,  0.01753395, -0.01034344],\n",
       "         [-0.02108214,  0.0348958 ,  0.0146665 , -0.04985892,\n",
       "          -0.0471722 , -0.01848589,  0.01385413, -0.01055914,\n",
       "           0.00199514, -0.00043672, -0.01774458,  0.00683006,\n",
       "           0.00800461,  0.0323304 ,  0.03135436, -0.03216539,\n",
       "           0.00276252, -0.0198832 , -0.00873382, -0.03576421,\n",
       "          -0.04334221,  0.02148196,  0.04498676,  0.04269384,\n",
       "           0.04651778, -0.02622103,  0.02434239, -0.03920059,\n",
       "           0.02269215,  0.02423677,  0.02564509,  0.01065923,\n",
       "          -0.0327348 ,  0.01579306,  0.01932282, -0.02961146,\n",
       "           0.03214499,  0.00660412,  0.01358132,  0.02532453,\n",
       "          -0.02173284,  0.00680885,  0.03834474,  0.02170448,\n",
       "          -0.04685168, -0.03316953, -0.01937813, -0.03860035,\n",
       "          -0.0024457 , -0.02461908,  0.04333209,  0.03092437,\n",
       "          -0.03725444,  0.04414568, -0.02300518,  0.03885132,\n",
       "          -0.03654063,  0.01512465,  0.02209142,  0.00982436,\n",
       "          -0.04249685, -0.00303226,  0.03315354, -0.0067763 ]]],\n",
       "\n",
       "\n",
       "       [[[-0.00644968,  0.03276106, -0.01673726,  0.04792818,\n",
       "          -0.03736073, -0.00985062, -0.02771441,  0.0479345 ,\n",
       "           0.04614264,  0.02038458, -0.01716744,  0.01715491,\n",
       "           0.01129594,  0.02069629,  0.01246477,  0.02072963,\n",
       "           0.0475792 , -0.04919056,  0.01301287, -0.01489934,\n",
       "          -0.01390288, -0.02746675, -0.02890581, -0.01561587,\n",
       "           0.04638398,  0.00453828, -0.01129702, -0.03906096,\n",
       "          -0.03600761, -0.01482545, -0.03364439, -0.03560364,\n",
       "          -0.04425373, -0.02331542, -0.00885147,  0.02102016,\n",
       "           0.04650437, -0.0215982 , -0.01947412,  0.02295244,\n",
       "           0.04287547, -0.01086481, -0.01573907,  0.01484335,\n",
       "          -0.02486124,  0.01990033,  0.04925129,  0.02691462,\n",
       "           0.0473074 , -0.00204263,  0.04679689,  0.00896007,\n",
       "          -0.03934366, -0.03492532, -0.02872576,  0.01911731,\n",
       "          -0.0239509 , -0.0233881 ,  0.03671112, -0.01719984,\n",
       "          -0.00715537, -0.04603363,  0.01753395, -0.01034344],\n",
       "         [-0.02861797, -0.02011002,  0.03197886,  0.03334654,\n",
       "          -0.00362016,  0.03207984,  0.04705508, -0.0325874 ,\n",
       "          -0.03243606,  0.00285896,  0.03426376, -0.00922365,\n",
       "          -0.04616647,  0.03128758, -0.03498994,  0.03625594,\n",
       "          -0.04597322,  0.04125119,  0.01472588,  0.03242255,\n",
       "           0.03572172, -0.03084807,  0.02385204, -0.02155588,\n",
       "           0.04266134, -0.00585356,  0.0097695 ,  0.0379699 ,\n",
       "           0.00494809,  0.02805999,  0.02845443, -0.02564691,\n",
       "          -0.01852424, -0.0212498 ,  0.00283723,  0.0308897 ,\n",
       "           0.04614348, -0.04954416,  0.01516707, -0.0140155 ,\n",
       "          -0.04853408,  0.03793415, -0.04167362,  0.04353284,\n",
       "          -0.01230878, -0.03490299, -0.00195529,  0.01163899,\n",
       "          -0.04779117,  0.02383946,  0.01208454, -0.00476938,\n",
       "          -0.01498324, -0.02871478, -0.03535169, -0.04151267,\n",
       "          -0.04982547,  0.00022034, -0.0248103 , -0.00853004,\n",
       "           0.03795015, -0.022112  , -0.03966822,  0.04155074]]],\n",
       "\n",
       "\n",
       "       [[[ 0.0473083 ,  0.04120061,  0.03353537, -0.04863477,\n",
       "          -0.02162957, -0.04492195,  0.04873085, -0.02809834,\n",
       "          -0.00359499,  0.01721633, -0.00652818, -0.02283325,\n",
       "          -0.04383202,  0.02497305, -0.03804306,  0.02364418,\n",
       "          -0.04621357, -0.04551397, -0.04069616,  0.04077441,\n",
       "           0.04543128,  0.00152541,  0.0183943 ,  0.01455175,\n",
       "          -0.03938919,  0.03943812,  0.04862412, -0.00397948,\n",
       "          -0.04129051,  0.04928477, -0.03271475,  0.00050896,\n",
       "          -0.0327348 ,  0.01579306,  0.01932282, -0.02961146,\n",
       "           0.03214499,  0.00660412,  0.01358132,  0.02532453,\n",
       "          -0.02173284,  0.00680885,  0.03834474,  0.02170448,\n",
       "          -0.04685168, -0.03316953, -0.01937813, -0.03860035,\n",
       "          -0.0024457 , -0.02461908,  0.04333209,  0.03092437,\n",
       "          -0.03725444,  0.04414568, -0.02300518,  0.03885132,\n",
       "          -0.03654063,  0.01512465,  0.02209142,  0.00982436,\n",
       "          -0.04249685, -0.00303226,  0.03315354, -0.0067763 ],\n",
       "         [ 0.01042508, -0.01453025, -0.02881366,  0.04204467,\n",
       "          -0.01718391, -0.01909288,  0.01797564,  0.01009574,\n",
       "           0.01917403, -0.04008397, -0.04049336,  0.01133575,\n",
       "          -0.01932999, -0.00961398, -0.03473051,  0.02519876,\n",
       "          -0.00876047, -0.02912145, -0.03063102, -0.01514106,\n",
       "           0.0050322 , -0.00409357,  0.01325123,  0.00482899,\n",
       "           0.03013846,  0.0413007 , -0.01650895, -0.02079592,\n",
       "          -0.00040606,  0.04231929, -0.0100977 ,  0.04988373,\n",
       "          -0.01852424, -0.0212498 ,  0.00283723,  0.0308897 ,\n",
       "           0.04614348, -0.04954416,  0.01516707, -0.0140155 ,\n",
       "          -0.04853408,  0.03793415, -0.04167362,  0.04353284,\n",
       "          -0.01230878, -0.03490299, -0.00195529,  0.01163899,\n",
       "          -0.04779117,  0.02383946,  0.01208454, -0.00476938,\n",
       "          -0.01498324, -0.02871478, -0.03535169, -0.04151267,\n",
       "          -0.04982547,  0.00022034, -0.0248103 , -0.00853004,\n",
       "           0.03795015, -0.022112  , -0.03966822,  0.04155074]]]],\n",
       "      dtype=float32)>},\n",
       " 'policy_info': (),\n",
       " 'reward': <tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
       "array([[4., 3.],\n",
       "       [5., 4.],\n",
       "       [4., 3.],\n",
       "       [5., 5.],\n",
       "       [5., 3.]], dtype=float32)>,\n",
       " 'step_type': <tf.Tensor: shape=(), dtype=int32, numpy=0>})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "57fd5848-4d75-4fae-8cd7-0d7310562508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.observation.shape: (5, 1, 64)\n",
      "test_traj.observation.shape: (5, 1, 2, 64)\n",
      "test_traj.discount.shape   : ()\n",
      "expected_num_actions: 3\n",
      "predicted_rewards_mean: TensorSpec(shape=(3,), dtype=tf.float32, name=None)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.observation.shape: {test_traj.observation['global'].shape}\")\n",
    "print(f\"test_traj.observation.shape: {test_traj.observation['per_arm'].shape}\")\n",
    "print(f\"test_traj.discount.shape   : {test_traj.discount.shape}\") \n",
    "\n",
    "expected_num_actions = action_spec.maximum - action_spec.minimum + 1\n",
    "print(f\"expected_num_actions: {expected_num_actions}\")\n",
    "\n",
    "predicted_rewards_mean = tensor_spec.TensorSpec([expected_num_actions])\n",
    "print(f\"predicted_rewards_mean: {predicted_rewards_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f5ac56-3153-48e3-999a-a818ca673129",
   "metadata": {},
   "source": [
    "# Train Ranking Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "43cd93ee-4ed8-4b11-9350-5e606ccca87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : new-ranker-v1\n",
      "RUN_NAME          : run-20240404-175630\n",
      "\n",
      "CHECKPT_DIR       : gs://rec-bandits-v2-hybrid-vertex-bucket/new-ranker-v1/chkpoint\n",
      "BASE_OUTPUT_DIR   : gs://rec-bandits-v2-hybrid-vertex-bucket/new-ranker-v1/run-20240404-175630\n",
      "LOG_DIR           : gs://rec-bandits-v2-hybrid-vertex-bucket/new-ranker-v1/run-20240404-175630/logs\n",
      "ROOT_DIR          : gs://rec-bandits-v2-hybrid-vertex-bucket/new-ranker-v1/run-20240404-175630/root\n",
      "ARTIFACTS_DIR     : gs://rec-bandits-v2-hybrid-vertex-bucket/new-ranker-v1/run-20240404-175630/artifacts\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME   = 'new-ranker-v1'\n",
    "\n",
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "CHECKPT_DIR       = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/chkpoint\"\n",
    "BASE_OUTPUT_DIR   = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}\"\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"CHECKPT_DIR       : {CHECKPT_DIR}\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "99169818-818e-4148-b045-25eded36f553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_agents version: 0.17.0\n",
      "tensorflow version: 2.13.0\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.policies import tf_policy\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.metrics import export_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.utils import common\n",
    "\n",
    "import tf_agents\n",
    "\n",
    "print(f\"tf_agents version: {tf_agents.__version__}\")\n",
    "print(f\"tensorflow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f7b1cc-a927-45c0-b64d-30a70250fb8d",
   "metadata": {},
   "source": [
    "### logs & checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e6f63092-48ba-4cb2-8ee4-9b30bd4c23c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent: ranking_agent\n",
      "agent: descending_score_ranking_policy\n"
     ]
    }
   ],
   "source": [
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "rank_agent.initialize()\n",
    "print(f'agent: {rank_agent.name}')\n",
    "print(f'agent: {rank_agent.policy.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dd893a5d-449e-4c21-b9fc-3cf5114dd2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('metrics: [<tf_agents.metrics.tf_metrics.AverageReturnMetric object at '\n",
      " '0x7f90acf13250>]')\n",
      "setting checkpoint_manager: gs://rec-bandits-v2-hybrid-vertex-bucket/new-ranker-v1/chkpoint\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    f\"{LOG_DIR}\", flush_millis=10 * 1000\n",
    ")\n",
    "# train_summary_writer.set_as_default()\n",
    "\n",
    "# eval_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "#     f\"{LOG_DIR}/eval\", flush_millis=10 * 1000\n",
    "# )\n",
    "# ====================================================\n",
    "# metrics\n",
    "# ====================================================\n",
    "# `step_metric` records the number of individual rounds of bandit interaction;\n",
    "# that is, (number of trajectories) * batch_size\n",
    "step_metric = tf_metrics.EnvironmentSteps()\n",
    "\n",
    "if feedback_model == ranking_environment.FeedbackModel.SCORE_VECTOR:\n",
    "    reward_metric = tf_metrics.AverageReturnMetric(\n",
    "        batch_size=HPARAMS['batch_size'],\n",
    "        buffer_size=20\n",
    "    )\n",
    "else:\n",
    "    reward_metric = tf_metrics.AverageReturnMultiMetric(\n",
    "        reward_spec=environment.reward_spec(),\n",
    "        batch_size=HPARAMS['batch_size'],\n",
    "        buffer_size=20\n",
    "    )\n",
    "    \n",
    "metrics = [reward_metric]\n",
    "\n",
    "pprint(f\"metrics: {metrics}\")\n",
    "# ====================================================\n",
    "# get checkpoint manager\n",
    "# ====================================================\n",
    "print(f\"setting checkpoint_manager: {CHECKPT_DIR}\\n\")\n",
    "\n",
    "checkpoint_manager = train_utils.restore_and_get_checkpoint_manager(\n",
    "    root_dir=CHECKPT_DIR, \n",
    "    agent=rank_agent, \n",
    "    metrics=metrics, \n",
    "    step_metric=step_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e6e434-f8dd-43ac-8dfc-d6e5ceeb10d0",
   "metadata": {},
   "source": [
    "#### Saving Ranking Bandits\n",
    "\n",
    "> Note: [open issue](https://github.com/tensorflow/agents/issues/891) regarding saving ranking bandit models\n",
    "\n",
    "Until this is resolved, use the `checkpoint_manager` to restore the latest trained policy. \n",
    "\n",
    "More on this in the `Inference` section below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd8bc05c-81f1-4919-9668-a0236f35a061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# policy saver\n",
    "# ====================================================\n",
    "\n",
    "# saver = policy_saver.PolicySaver(\n",
    "#     policy = rank_agent.policy, \n",
    "#     # train_step=global_step\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4bb1d475-446e-498f-a4c1-a813de6352e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.bandits.policies.ranking_policy.DescendingScoreRankingPolicy at 0x7f90acfbefe0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = rank_agent.policy\n",
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9ca1261c-7ed9-4661-a705-7b5d674a7ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "917"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9af553-9512-47e0-ae9d-d593139143e0",
   "metadata": {},
   "source": [
    "## Train config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "50ef435c-3d9b-432d-a5e2-ab5d60e93cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_DATA_SIZE : 900\n",
      "NUM_TRAIN_STEPS : 100\n",
      "EVAL_DATA_SIZE : 900\n",
      "NUM_EVAL_STEPS : 100\n",
      "CHKPT_INTERVAL: 99\n",
      "LOG_INTERVAL : 10\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA_SIZE = 900          # len(list(train_dataset))\n",
    "NUM_TRAIN_STEPS = 50            # TRAIN_DATA_SIZE // HPARAMS['batch_size']\n",
    "\n",
    "EVAL_DATA_SIZE  = 900          # len(list(val_dataset))\n",
    "NUM_EVAL_STEPS  = 100           # EVAL_DATA_SIZE // HPARAMS['eval_batch_size']\n",
    "\n",
    "CHKPT_INTERVAL  = NUM_TRAIN_STEPS - 1 # // 5\n",
    "LOG_INTERVAL    = 10\n",
    "# EVAL_INTERVAL = NUM_TRAIN_STEPS // 2\n",
    "\n",
    "print(f\"TRAIN_DATA_SIZE : {TRAIN_DATA_SIZE}\")\n",
    "print(f\"NUM_TRAIN_STEPS : {NUM_TRAIN_STEPS}\")\n",
    "print(f\"EVAL_DATA_SIZE : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS : {NUM_EVAL_STEPS}\")\n",
    "print(f\"CHKPT_INTERVAL: {CHKPT_INTERVAL}\")\n",
    "print(f\"LOG_INTERVAL : {LOG_INTERVAL}\")\n",
    "# print(f\"EVAL_INTERVAL : {EVAL_INTERVAL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d4fa546c-bb88-4fef-976d-98b245ee842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "train_ds_iterator = iter(train_dataset.batch(HPARAMS['batch_size']))\n",
    "\n",
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS[\"eval_batch_size\"])\n",
    "\n",
    "if NUM_EVAL_STEPS > 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4d8449-6285-478a-8876-3f67c47cc6be",
   "metadata": {},
   "source": [
    "[ranking_agent](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/agents/ranking_agent.py#L288C1-L310C8)\n",
    "\n",
    "```\n",
    "  def _loss(\n",
    "      self,\n",
    "      experience: types.NestedTensor,\n",
    "      weights: Optional[types.Tensor] = None,\n",
    "      training: bool = False,\n",
    "  ) -> tf_agent.LossInfo:\n",
    "    \"\"\"Computes loss for training the reward and constraint networks.\n",
    "\n",
    "    Args:\n",
    "      experience: A batch of experience data in the form of a `Trajectory` or\n",
    "        `Transition`.\n",
    "      weights: Optional scalar or elementwise (per-batch-entry) importance\n",
    "        weights.  The output batch loss will be scaled by these weights, and the\n",
    "        final scalar loss is the mean of these values.\n",
    "      training: Whether the loss is being used for training.\n",
    "\n",
    "    Returns:\n",
    "      A `LossInfo` containing the loss for the training step.\n",
    "\n",
    "    Raises:\n",
    "      ValueError:\n",
    "        if the number of actions is greater than 1.\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "adae35ea-e3ff-4245-8c34-739dc70dec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# train setp function\n",
    "# ====================================================\n",
    "@tf.function\n",
    "def _train_step_fn():\n",
    "\n",
    "    data = next(train_ds_iterator)\n",
    "    trajectories = _rank_trajectory_fn(data)\n",
    "    loss = rank_agent.train(experience=trajectories)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "032770fc-8c04-4d3f-af21-9938501a7c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting train loop...\n",
      "step = 0: train loss = 17.469999313354492\n",
      "step = 10: train loss = 7.909999847412109\n",
      "step = 20: train loss = 0.8600000143051147\n",
      "step = 30: train loss = 1.3300000429153442\n",
      "step = 40: train loss = 0.7699999809265137\n",
      "step = 50: train loss = 0.3499999940395355\n",
      "step = 60: train loss = 0.6000000238418579\n",
      "step = 70: train loss = 0.46000000834465027\n",
      "step = 80: train loss = 1.0399999618530273\n",
      "step = 90: train loss = 2.200000047683716\n",
      "saved to checkpoint_manager: gs://rec-bandits-v2-hybrid-vertex-bucket/new-ranker-v1/chkpoint\n",
      "train runtime_mins: 6\n"
     ]
    }
   ],
   "source": [
    "list_o_loss = []\n",
    "\n",
    "rank_agent.train_step_counter.assign(0)\n",
    "\n",
    "print(f\"starting train loop...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(NUM_TRAIN_STEPS):\n",
    "    \n",
    "    with train_summary_writer.as_default():\n",
    "\n",
    "        step = rank_agent.train_step_counter.numpy()\n",
    "        \n",
    "#         data = next(train_ds_iterator)\n",
    "#         trajectories = _rank_trajectory_fn(data)\n",
    "\n",
    "#         # All tensors in experience must be shaped [batch, time, ...] \n",
    "#         loss = rank_agent.train(experience=trajectories)\n",
    "\n",
    "        loss = _train_step_fn()\n",
    "        list_o_loss.append(loss.loss.numpy())\n",
    "        \n",
    "        train_utils._export_metrics_and_summaries(\n",
    "            step=i, \n",
    "            metrics=metrics\n",
    "        )\n",
    "        \n",
    "        # print step loss\n",
    "        if step % LOG_INTERVAL == 0:\n",
    "            print(\n",
    "                'step = {0}: train loss = {1}'.format(\n",
    "                    step, round(loss.loss.numpy(), 2)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "checkpoint_manager.save(global_step)\n",
    "print(f\"saved to checkpoint_manager: {CHECKPT_DIR}\")\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"train runtime_mins: {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b818bc45-7a81-4cc8-974d-4da4f171b8d6",
   "metadata": {},
   "source": [
    "## Evaluate train job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "01e6207f-de75-4e93-b7e0-4e2fecbc6211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_o_loss)\n",
    "# plt.ylim([0, 10])\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3e6532-1bb5-4816-a37e-980074468239",
   "metadata": {},
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e657df42-b168-46f2-9b21-f99a91315a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/new-ranker-v1/run-20240404-175630/logs/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/new-ranker-v1/run-20240404-175630/logs/events.out.tfevents.1712253400.jt-tfa-bandit-rankers-2023-v2.2350123.0.v2\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls $LOG_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6b5e10ef-9f79-4030-b863-c821b695b957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "85177c16-2b71-4be4-b378-59aa2cc8913a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f5e6b055971267ea\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f5e6b055971267ea\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=$LOG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c33700d-7294-4beb-9436-9ad7d724b850",
   "metadata": {},
   "source": [
    "## Save Ranking Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da892f30-e6c8-4f63-a366-04ac8ca32fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(model, export_dir, signatures=signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7bb321-ad58-46dd-a64b-ab72bcb5aab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "265ca435-3e97-4d4e-b583-2f83040f041c",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "**Prediction response**\n",
    "> **TODO:** explain prediction response, e.g., `predicted_rewards_mean=array([3.1828353, 3.6808753]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "36d9b4d5-1ce0-4245-b0e5-a6c7e3135a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.bandits.policies.ranking_policy.DescendingScoreRankingPolicy at 0x7f90acfbefe0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_agent = rank_agent.policy\n",
    "deployment_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "977399bc-1d75-4dc2-bb2d-e7ff0a957a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.PyTFEagerPolicy at 0x7f90acee9b10>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(deployment_agent, use_tf_function=True)\n",
    "post_policy_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a948171e-984a-46c7-871a-02fbfb67ee1b",
   "metadata": {},
   "source": [
    "## Get Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cf4fd4-6f7f-4505-b86e-49ee44fc66f8",
   "metadata": {},
   "source": [
    "To generate an inference request, we need to create a single [TimeStep](https://github.com/tensorflow/agents/blob/master/tf_agents/trajectories/time_step.py#L54C1-L64C3) with the following schema:\n",
    "\n",
    "```python\n",
    "class TimeStep(\n",
    "    NamedTuple(\n",
    "        'TimeStep',\n",
    "        [\n",
    "            ('step_type', types.SpecTensorOrArray),\n",
    "            ('reward', types.NestedSpecTensorOrArray),\n",
    "            ('discount', types.SpecTensorOrArray),\n",
    "            ('observation', types.NestedSpecTensorOrArray),\n",
    "        ],\n",
    "    )\n",
    "):\n",
    "```\n",
    "* the `infer_step` below is functionally equivalent to:\n",
    "\n",
    "```python\n",
    "prediction = post_policy_tf.action(\n",
    "    ts.restart(observation, batch_size=HPARAMS['eval_batch_size']), ()\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a627a3fa-890b-434c-8681-339327ec02f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "# dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "SKIP_NUM = 10\n",
    "\n",
    "for x in eval_ds.skip(SKIP_NUM).take(INFER_SIZE):\n",
    "    \n",
    "    # global context features\n",
    "    global_features = _get_global_context_features(x)\n",
    "    global_features = tf.reshape(global_features, [GLOBAL_DIM]) # flatten\n",
    "    \n",
    "    # TODO: pass   : NUM_ITEMS items to trained policy\n",
    "    #       return : ranking for NUM_SLOTS\n",
    "    arm_features = _get_per_arm_features(x)\n",
    "    arm_feat_infer = tf.reshape(arm_features, [ HPARAMS['num_slots'], HPARAMS['eval_batch_size'], PER_ARM_DIM ]) # perarm_dim\n",
    "    arm_feat_infer = train_utils._remove_outer_dimension(arm_feat_infer)\n",
    "    \n",
    "    # train observation\n",
    "    observation = {'global': global_features, 'per_arm': arm_feat_infer}\n",
    "    \n",
    "    ranking_rewards = _get_ranking_rewards_sv(x)\n",
    "    \n",
    "    action = np.zeros((HPARAMS['num_slots']), dtype=np.int32)\n",
    "    discount = np.zeros((HPARAMS['num_slots']), dtype=np.float32)\n",
    "    \n",
    "    infer_step = ts.TimeStep(\n",
    "        step_type = tf.constant(\n",
    "            ts.StepType.FIRST, \n",
    "            dtype=tf.int32, \n",
    "            shape=[],\n",
    "            name='step_type'\n",
    "        ),\n",
    "        reward = ranking_rewards,\n",
    "        discount = tf.constant(\n",
    "            1.0, dtype=tf.float32, shape=[], name='discount'\n",
    "        ),\n",
    "        observation = observation\n",
    "    )\n",
    "    \n",
    "    prediction = post_policy_tf.action(infer_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8990e512-7099-476d-bd55-44be8f49256b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array([0, 1], dtype=int32), state=(), info=PolicyInfo(log_probability=(), predicted_rewards_mean=array([3.8431058, 3.4367683], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=()))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "082cee1d-703e-4143-8c78-d1976a6d341c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6112efc7-3e76-46d4-902e-a7c009a1d13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.8431058, 3.4367683], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info.predicted_rewards_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6066995c-5c9c-485c-96a2-973b65107471",
   "metadata": {},
   "source": [
    "### tmp - debugging\n",
    "\n",
    "> compare to prediction from infer_steps, where actual rewards are provided.. does this impact?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a2450fbd-ad0d-4270-a4db-d662c9ef09b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array([0, 1], dtype=int32), state=(), info=PolicyInfo(log_probability=(), predicted_rewards_mean=array([3.8431058, 3.4367683], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=()))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = post_policy_tf.action(\n",
    "    ts.restart(observation, batch_size=HPARAMS['eval_batch_size']), ()\n",
    ")\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bddd75a-21b0-4d09-9518-785246bd0a10",
   "metadata": {},
   "source": [
    "## Load a trained Ranking Bandit policy\n",
    "\n",
    "Here we'll show how to load a trained policy, as you would for a prediction endpoint. You need 3 objects to restore a trained policy from the last checkpoint:\n",
    "* **agent**: a tf-agents agent object following the same specs used during training\n",
    "* **metrics**: metrics tracked during training\n",
    "* **step metric**: `tf_metrics.EnvironmentSteps()` \n",
    "\n",
    "Becasue we already have these initialized in this notebook session, we can resuse them here and just pass the root folder of latest checkpoint (e.g., `CHECKPT_DIR`)\n",
    "* this restores the `agent` object to reflect the checkpointed policy\n",
    "> Note: when restoring the checkpointed policy in a new environment, we'll need to also initialize the three python objects above\n",
    "\n",
    "Then, we wrap the loaded policy with [PyTFEagerPolicy()](https://www.tensorflow.org/agents/api_docs/python/tf_agents/policies/PyTFEagerPolicy) to use it in eager mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5ac794d1-b753-468e-9d3a-aee50620c910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/new-ranker-v1/chkpoint/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/new-ranker-v1/chkpoint/checkpoint\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/new-ranker-v1/chkpoint/ckpt-100.data-00000-of-00001\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/new-ranker-v1/chkpoint/ckpt-100.index\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $CHECKPT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5e33ce02-664f-4d64-9405-90b368425862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank_agent\n",
    "# metrics\n",
    "# step_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2fecf83a-57b7-4fde-85bc-8f6f8a142816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint_management.CheckpointManager at 0x7f8f10047fa0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restore_policy = train_utils.restore_and_get_checkpoint_manager(\n",
    "      CHECKPT_DIR, rank_agent, metrics, step_metric\n",
    "  )\n",
    "restore_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c5fe51de-a204-43c3-8ff6-cab00ae79908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.PyTFEagerPolicy at 0x7f8f10047be0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "deployment_agent = rank_agent.policy\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(deployment_agent, use_tf_function=True)\n",
    "post_policy_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8d2f81ba-f0f0-432a-adea-cc6b7a98c00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.PyTFEagerPolicy at 0x7f8f10047be0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26e852bc-3af3-4bac-b107-d070eb93740b",
   "metadata": {},
   "source": [
    "#### Test inference with restored policy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e1a82da1-5db4-4b57-aa52-d7f674e4ea88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array([0, 1], dtype=int32), state=(), info=PolicyInfo(log_probability=(), predicted_rewards_mean=array([3.4593716, 3.2745495], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=()))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = post_policy_tf.action(\n",
    "    ts.restart(observation, batch_size=HPARAMS['eval_batch_size']), ()\n",
    ")\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f05ccfd-7263-40a7-813e-453ad90daad0",
   "metadata": {},
   "source": [
    "# Evaluation Loop\n",
    "\n",
    "> Evaluate the agent's policy after training\n",
    "\n",
    "**TODOs**\n",
    "* Need better ranking metric for listwise data\n",
    "* Latest version of [TF-Ranking](https://github.com/tensorflow/ranking) (`0.5.3`) requires `tensorflow==2.11.0`. Currently using `tensorflow==2.13.0` (consider downgrading?) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce0ee84-05e9-4e70-83c7-799ef0b37187",
   "metadata": {},
   "source": [
    "### Sampling rankings\n",
    "\n",
    "A simple way to produce a ranking is to score each item and sort them by predicted rewards.\n",
    "* To induce exploration, we could occasionally ignore the predicted reward and produce random lists in an epsilon-greedy manner.\n",
    "\n",
    "Alternatively, we could produce a score of all the items and use the `Plackett Luce` distribution to sample permutations of the items.\n",
    "* An implementation exists in `tf-probability`:\n",
    "\n",
    "```python\n",
    "scores = [...]\n",
    "dist = tfd.PlackettLuce(scores)  # Scores have to be non-negative.\n",
    "sample = dist.sample(...)\n",
    "# We can also compute sampling probabilities of the ranking\n",
    "prob = dist.prob(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "30e5df69-e6c0-4345-98cc-2a0d3d1abcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _levenshtein_distance(hypothesis, truth):\n",
    "    dist_tensor = tf.edit_distance(\n",
    "        tf.sparse.from_dense(tf.constant(hypothesis, dtype=tf.int32)),\n",
    "        tf.sparse.from_dense(tf.constant(truth, dtype=tf.int32)),\n",
    "    )\n",
    "    return dist_tensor\n",
    "\n",
    "def _get_rewards_from_input_features(\n",
    "    data: Dict[str, tf.Tensor],\n",
    "    num_slots: int,\n",
    ") -> tf.Tensor:\n",
    "    \n",
    "    unmasked_rewards = _get_ranking_rewards_sv(data)\n",
    "    \n",
    "    _, num_arms = unmasked_rewards.get_shape().as_list()\n",
    "    mask = tf.expand_dims(tf.range(num_arms), axis=0) < tf.expand_dims(\n",
    "        num_slots, axis=-1\n",
    "    )\n",
    "    masked_rewards = tf.where(mask, unmasked_rewards, float('-5000000'))\n",
    "    \n",
    "    return masked_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "da61e837-0482-4cd6-b36e-22404ba732ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFER_SIZE = 1\n",
    "# dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "# SKIP_NUM = 10\n",
    "\n",
    "def evaluate_ranking(\n",
    "    agent_policy,\n",
    "    data: Dict[str, tf.Tensor],\n",
    "    batch_size: int,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \n",
    "    unranked_rewards = _get_rewards_from_input_features(\n",
    "        data=data, \n",
    "        num_slots=HPARAMS['num_slots']\n",
    "    )\n",
    "    # rewards calc - array([[0, 1]])\n",
    "    optimal_ranking = np.argsort(unranked_rewards)[:, ::-1][\n",
    "      :, :HPARAMS['num_slots']\n",
    "    ]\n",
    "    optimal_rewards = np.take(unranked_rewards, optimal_ranking, axis=None)\n",
    "    \n",
    "    # global context features\n",
    "    global_features = _get_global_context_features(data)\n",
    "    global_features = tf.reshape(global_features, [GLOBAL_DIM]) # flatten\n",
    "    \n",
    "    # TODO: pass   : NUM_ITEMS items to trained policy\n",
    "    #       return : ranking for NUM_SLOTS\n",
    "    arm_features = _get_per_arm_features(x)\n",
    "    arm_feat_infer = tf.reshape(\n",
    "        arm_features, \n",
    "        [ HPARAMS['num_slots'], HPARAMS['eval_batch_size'], PER_ARM_DIM ]\n",
    "    )\n",
    "    arm_feat_infer = train_utils._remove_outer_dimension(arm_feat_infer)\n",
    "    \n",
    "    # train observation\n",
    "    observation = {'global': global_features, 'per_arm': arm_feat_infer}\n",
    "    \n",
    "    # get predicted rewards / ranking\n",
    "    prediction = agent_policy.action(\n",
    "        ts.restart(observation, batch_size=HPARAMS['eval_batch_size']), ()\n",
    "    )\n",
    "    candidate_rewards = prediction.info.predicted_rewards_mean\n",
    "    candidate_ranking = pred_test.action\n",
    "    valid_candidate_ranking = candidate_ranking[:HPARAMS['num_slots']]\n",
    "    \n",
    "    batched_candidate_rewards = np.take(\n",
    "        candidate_rewards, valid_candidate_ranking\n",
    "    )\n",
    "    \n",
    "    # compute metrics\n",
    "    batched_rewards_diff = np.abs(optimal_rewards - batched_candidate_rewards)\n",
    "    mean_rewards_diff = tf.math.reduce_mean(\n",
    "        batched_rewards_diff, axis=None,\n",
    "    )\n",
    "    \n",
    "    # TODO\n",
    "    # batched_edit_dist = _levenshtein_distance(valid_candidate_ranking, optimal_ranking)\n",
    "    \n",
    "    return mean_rewards_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0bdd5b77-1446-47b0-8287-8b85d8ca744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_LOOP_BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0a4a09c5-0eb4-4d43-b250-1b8080e7d514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie_genres': <tf.Tensor: shape=(1, 3), dtype=int64, numpy=array([[3, 0, 0]])>,\n",
       " 'movie_id': <tf.Tensor: shape=(1, 3), dtype=string, numpy=array([[b'94', b'245', b'403']], dtype=object)>,\n",
       " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'346'], dtype=object)>,\n",
       " 'user_rating': <tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[3., 4., 3.]], dtype=float32)>}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    \n",
    "    iterator = iter(train_dataset.batch(EVAL_LOOP_BATCH_SIZE))\n",
    "    data = next(iterator)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9e9781d8-fb68-4772-9561-570cacd35101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.95380306>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_test = evaluate_ranking(\n",
    "    agent_policy=post_policy_tf,\n",
    "    data=data,\n",
    "    batch_size=HPARAMS['eval_batch_size']\n",
    ")\n",
    "eval_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9719344-0c90-43a0-97b3-88e64f15f4ab",
   "metadata": {},
   "source": [
    "### Compare with untrained policy and random rankings\n",
    "\n",
    "> **TODO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "940e8a03-b696-4ece-b7f7-ca377425fbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_random_ranking(\n",
    "    num_ranked_items: int, num_allowed_values: int, batch_size: int\n",
    "):\n",
    "    \"\"\"Returns a batch of `batch_size` rankings each of length `num_ranked_items`.\n",
    "\n",
    "    1. If `num_ranked_items` is no greater than `num_allowed_values`, each ranking\n",
    "    is a subset of [0, 1, ..., num_allowed_values - 1], of size\n",
    "    `num_ranked_items`.\n",
    "    2. If `num_ranked_items` is greater than `num_allowed_values`, the first\n",
    "    `num_allowed_values` of each ranking is a permutation of\n",
    "    [0, 1, ... num_allowed_values - 1]. The remaining `num_ranked_items -\n",
    "    num_allowed_values` of the ranking are unspecified.\n",
    "\n",
    "    Args:\n",
    "    num_ranked_items: the expected number of items in the output ranking, as\n",
    "      specified in the study config.\n",
    "    num_allowed_values: the number of items to select from.\n",
    "    batch_size: the number of batches of random rankings to return.\n",
    "    \"\"\"\n",
    "    num_valid_indices = min(num_ranked_items, num_allowed_values)\n",
    "    ranking = np.full(\n",
    "        (batch_size, num_ranked_items), np.iinfo(np.int32).max, dtype=np.int32\n",
    "    )\n",
    "    for idx in range(batch_size):\n",
    "        ranking[idx, :num_valid_indices] = np.random.choice(\n",
    "            num_allowed_values, size=num_valid_indices, replace=False\n",
    "        )\n",
    "    return ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "1de89282-54f3-470c-b833-f2ff46a1b223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [2, 0],\n",
       "       [1, 0],\n",
       "       [0, 2]], dtype=int32)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_rank_batch = _create_random_ranking(\n",
    "    num_ranked_items=HPARAMS['num_slots'],\n",
    "    num_allowed_values=HPARAMS['num_items'],\n",
    "    batch_size=HPARAMS['batch_size']\n",
    ")\n",
    "rand_rank_batch"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
