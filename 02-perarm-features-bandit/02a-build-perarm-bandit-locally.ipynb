{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385307d6-2058-47ec-8da0-57f7ef5c43d6",
   "metadata": {},
   "source": [
    "# Train Bandits with per-arm features\n",
    "\n",
    "**Exploring linear and nonlinear** (e.g., those with neural network-based value functions) bandit methods for recommendations using TF-Agents\n",
    "\n",
    "> Neural linear bandits provide a nice way to leverage the representation power of deep learning and the bandit approach for uncertainty measure and efficient exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1e9956-66cd-4bf4-9b4d-8c2c646f0313",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "\n",
    "In this notebook, we explore the following topics for training contextual bandits with per-arm features:\n",
    "\n",
    "1. Data preperation\n",
    "2. Sampling functions\n",
    "3. TensorSpecs\n",
    "4. Agent, Network, training policy\n",
    "5. Reward function\n",
    "6. Trajectory function\n",
    "7. Train & Eval loops\n",
    "8. Getting predictions -\n",
    "9. Preparing the training application - abstracting all steps above to be used in subsequent notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fd257-b98b-426a-a2cd-024429b014f1",
   "metadata": {},
   "source": [
    "## Load notebook config\n",
    "\n",
    "* use the prefix defined in `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f39c9d08-d118-4013-a47f-88450f49f19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "# PREFIX = 'mabv1'\n",
    "VERSION        = \"v2\"                       # TODO\n",
    "PREFIX         = f'rec-bandits-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908f6b95-b539-4a9f-a836-840d26ea3b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"rec-bandits-v2\"\n",
      "VERSION                  = \"v2\"\n",
      "\n",
      "BUCKET_NAME              = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "DATA_PATH_KFP_DEMO       = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data/kfp_demo_data/u.data\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_NAME    = \"mvlens_rec_bandits_v2\"\n",
      "BIGQUERY_TABLE_NAME      = \"training_dataset\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-rec-bandits-v2\"\n",
      "\n",
      "DOCKERNAME_01            = \"Dockerfile_train_my_perarm_env\"\n",
      "IMAGE_NAME_01            = \"train-my-perarm-env-v2\"\n",
      "IMAGE_URI_01             = \"gcr.io/hybrid-vertex/train-my-perarm-env-v2\"\n",
      "\n",
      "DOCKERNAME_02            = \"Dockerfile_perarm_feats\"\n",
      "IMAGE_NAME_02            = \"train-perarm-feats-v2\"\n",
      "IMAGE_URI_02             = \"gcr.io/hybrid-vertex/train-perarm-feats-v2\"\n",
      "\n",
      "DOCKERNAME_03            = \"Dockerfile_ranking_bandit\"\n",
      "IMAGE_NAME_03            = \"train-rank-bandit-v2\"\n",
      "IMAGE_URI_03             = \"gcr.io/hybrid-vertex/train-rank-bandit-v2\"\n",
      "\n",
      "DOCKERNAME_04            = \"Dockerfile_train_mab_e2e\"\n",
      "IMAGE_NAME_04            = \"train-mab-e2e-v2\"\n",
      "IMAGE_URI_04             = \"gcr.io/hybrid-vertex/train-mab-e2e-v2\"\n",
      "\n",
      "DOCKERNAME_04_pred       = \"Dockerfile_pred_mab_e2e\"\n",
      "IMAGE_NAME_04_pred       = \"pred-mab-e2e-v2\"\n",
      "IMAGE_URI_04_pred        = \"gcr.io/hybrid-vertex/pred-mab-e2e-v2\"\n",
      "\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/local_docker_tfa\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c690a9-e2bd-4759-ba41-4e2469098aee",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d0dfe4-695c-4dd4-9f24-67f7488ce1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c669f1a1-1af7-4efb-ab2d-6bf3b3847991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from collections import defaultdict\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pickle as pkl\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "# from tf_agents.agents import TFAgent\n",
    "\n",
    "# from tf_agents.bandits.environments import stationary_stochastic_per_arm_py_environment as p_a_env\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "# from tf_agents.drivers import dynamic_step_driver\n",
    "# from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "# from tf_agents.bandits.agents import lin_ucb_agent\n",
    "# from tf_agents.bandits.agents import linear_thompson_sampling_agent as lin_ts_agent\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent\n",
    "from tf_agents.bandits.agents import neural_linucb_agent\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "from tf_agents.bandits.policies import policy_utilities\n",
    "\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "\n",
    "nest = tf.nest\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# this repo\n",
    "from src.per_arm_rl import data_utils\n",
    "from src.per_arm_rl import data_config\n",
    "from src.per_arm_rl import train_utils as train_utils\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29e58dd7-ab2b-419f-9771-bf1e98db758b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4969d3e-1fc0-45db-8a69-aa6b342019de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "274e7f4a-1802-4946-888e-876638f5c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a866b1-85b9-43e6-9546-edfbbf886bce",
   "metadata": {},
   "source": [
    "# [1] Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d4ed28-23d7-4785-b327-e5b543b0edb9",
   "metadata": {},
   "source": [
    "**Overview**\n",
    "* Load train and eval datasets from TFRecords created in the `01-movielens-data-prep.ipynb` notebook\n",
    "* training examples represent historical (previously collected) interaction data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd5b953-14c0-42ed-a511-77147a1bc0ac",
   "metadata": {},
   "source": [
    "### Read TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d0157c8-a04c-4dbd-b6d9-a1ede97687a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da0cdac-76af-4608-b70e-be7dbe0584b5",
   "metadata": {},
   "source": [
    "**Train data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c934c06-bf08-4c7f-b0cc-0de04ef3515c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://rec-bandits-v2-hybrid-vertex-bucket/data/train/ml-ratings-100k-train.tfrecord']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPLIT = \"train\" # \"train\" | \"val\"\n",
    "\n",
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7511e4d-bf81-4800-bde7-8b16dec9aeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([35.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'898'], dtype=object)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([885409515])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'681'], dtype=object)>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'marketing'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "train_dataset = train_dataset.map(data_utils.parse_tfrecord)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452750c1-46a0-4ee1-84d4-0c3b227de38f",
   "metadata": {},
   "source": [
    "**Val data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7b5376f-9438-4304-84aa-de09c30f5e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = \"val\"\n",
    "\n",
    "val_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        val_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "val_dataset = tf.data.TFRecordDataset(val_files)\n",
    "val_dataset = val_dataset.map(data_utils.parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8959967-522e-41c8-9a1b-050ca8bc191f",
   "metadata": {},
   "source": [
    "### get vocab\n",
    "\n",
    "**TODO:** \n",
    "* streamline vocab calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b9169bc-d6dc-497e-9dff-6ebb175282ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE_VOCABS: False\n"
     ]
    }
   ],
   "source": [
    "GENERATE_VOCABS = False\n",
    "\n",
    "print(f\"GENERATE_VOCABS: {GENERATE_VOCABS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3ccf137-7a72-42e7-aa89-3c81a99cf40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab...\n",
      "Downloaded vocab from: gs://rec-bandits-v2-hybrid-vertex-bucket/vocabs/vocab_dict.pkl\n",
      "\n",
      "'movie_id'\n",
      "'user_id'\n",
      "'user_occupation_text'\n",
      "'movie_genres'\n",
      "'bucketized_user_age'\n",
      "'max_timestamp'\n",
      "'min_timestamp'\n",
      "'timestamp_buckets'\n"
     ]
    }
   ],
   "source": [
    "if not GENERATE_VOCABS:\n",
    "\n",
    "    EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{VOCAB_SUBDIR}/{VOCAB_FILENAME}'\n",
    "    print(f\"Downloading vocab...\")\n",
    "    \n",
    "    os.system(f'gsutil -q cp {EXISTING_VOCAB_FILE} .')\n",
    "    print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "    filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "    vocab_dict = pkl.load(filehandler)\n",
    "    filehandler.close()\n",
    "    \n",
    "    for key in vocab_dict.keys():\n",
    "        pprint(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccaef62-882a-46ff-a1b1-3837e69fdf74",
   "metadata": {},
   "source": [
    "## helper functions\n",
    "\n",
    "**TODO:**\n",
    "* modularize in a train_utils or similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138a295-2b0d-4359-8496-af8552ec8cff",
   "metadata": {},
   "source": [
    "# [2] Preprocessing layers for global and arm features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e28c002-8d3a-4cf4-b69b-de56a6abab90",
   "metadata": {},
   "source": [
    "The preproccesing layers will ultimately feed the two sampling functions described below. These sampling functions will be used to create [trajectories](https://github.com/tensorflow/agents/blob/master/tf_agents/trajectories/trajectory.py#L36) (i.e., the training examples for our model)\n",
    "\n",
    "`global_context_sampling_fn`: \n",
    "* A function that outputs a random 1d array or list of ints or floats\n",
    "* This output is the global context. Its shape and type must be consistent across calls.\n",
    "\n",
    "`arm_context_sampling_fn`: \n",
    "* A function that outputs a random 1 array or list of ints or floats (same type as the output of `global_context_sampling_fn`). * This output is the per-arm context. Its shape must be consistent across calls.\n",
    "\n",
    "See `debug-and-learn-emb-models.ipynb` for more details and debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ea1f7-0621-44b8-b062-1f59b0964d72",
   "metadata": {},
   "source": [
    "## Global & Per-Arm feature embedding models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8d77956-635c-438a-916a-185eec52f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OOV_BUCKETS        = 1\n",
    "GLOBAL_EMBEDDING_SIZE  = 16\n",
    "MV_EMBEDDING_SIZE      = 32 #32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea335991-dcec-40b3-ba0d-a0fdfb9c2ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test emb models\n",
    "for i in range(1):\n",
    "    \n",
    "    iterator = iter(train_dataset.batch(1))\n",
    "    data = next(iterator)\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48178fff-491f-4f03-b156-7765d1fa9707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.perarm_features.emb_features.EmbeddingModel at 0x7fc9f7383e20>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.perarm_features import emb_features as emb_features\n",
    "\n",
    "embs = emb_features.EmbeddingModel(\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "903c63c5-2468-4443-bcb8-5ff6d69810dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL_DIM: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.01810407,  0.032564  , -0.0062706 ,  0.0309868 , -0.0272228 ,\n",
       "        -0.01757262, -0.03960016,  0.00432544,  0.03885197, -0.00325105,\n",
       "         0.00154034,  0.04416389,  0.03228017, -0.03888809, -0.033764  ,\n",
       "        -0.00138956, -0.01082438,  0.00167775,  0.02631923, -0.01807901,\n",
       "         0.0294415 ,  0.01956115,  0.00896766,  0.04761857,  0.01687798,\n",
       "        -0.00422556,  0.02346866,  0.01720954, -0.04211826,  0.04761162,\n",
       "        -0.00720436, -0.04526744, -0.0190041 , -0.03204851,  0.0233526 ,\n",
       "        -0.04602716, -0.03257034,  0.02344317,  0.02641275,  0.04447928,\n",
       "         0.02498324, -0.01448477, -0.04694686, -0.04686499, -0.04437753,\n",
       "         0.0464378 , -0.01847339,  0.02646515,  0.03076328,  0.04318489,\n",
       "         0.04045675, -0.02841884, -0.04550834,  0.04069594, -0.01132815,\n",
       "         0.02849385, -0.04279239,  0.04827495, -0.00890119,  0.00613732,\n",
       "         0.02685295,  0.01416891, -0.02016617, -0.00187195]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_globals = embs._get_global_context_features(data)\n",
    "\n",
    "GLOBAL_DIM = test_globals.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"GLOBAL_DIM: {GLOBAL_DIM}\")\n",
    "\n",
    "test_globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebec4863-c614-4248-b680-8e29ec5b730d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER_ARM_DIM: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.47008726e-03,  1.16656646e-02, -2.89814603e-02,\n",
       "         6.65774196e-03,  2.82903761e-03, -7.80528784e-03,\n",
       "         6.38371706e-03, -1.21672265e-02, -1.77460685e-02,\n",
       "         3.64712216e-02, -3.76471989e-02, -1.39979273e-03,\n",
       "        -3.40401307e-02, -1.35427602e-02,  3.14848088e-02,\n",
       "         3.41090299e-02,  9.10026953e-03,  2.45635174e-02,\n",
       "         2.74624564e-02,  1.47986300e-02,  9.83469561e-03,\n",
       "         3.42671163e-02, -1.90417171e-02,  2.34365501e-02,\n",
       "        -1.92968380e-02,  3.77066843e-02, -1.24067776e-02,\n",
       "        -1.27585046e-02, -3.05344108e-02, -3.13029513e-02,\n",
       "         3.93779390e-02, -1.98574662e-02,  4.21640314e-02,\n",
       "        -3.01978588e-02, -1.45035759e-02,  3.56054567e-02,\n",
       "         4.97174375e-02, -4.28780913e-05,  4.36874889e-02,\n",
       "         2.30555870e-02, -2.26068497e-03, -4.78602909e-02,\n",
       "        -4.60366718e-02,  3.19037102e-02, -2.52004750e-02,\n",
       "        -3.53382938e-02, -4.33557406e-02, -5.99738210e-03,\n",
       "         1.88460611e-02, -4.95309941e-02, -3.90300155e-02,\n",
       "         3.82728092e-02,  8.40513781e-03, -4.25373428e-02,\n",
       "         8.03827122e-03,  1.40767358e-02,  5.98169863e-04,\n",
       "         1.53817646e-02, -4.94487993e-02, -3.33356857e-02,\n",
       "         4.35486771e-02, -3.18807252e-02, -5.22886589e-03,\n",
       "         1.33740045e-02]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arms = embs._get_per_arm_features(data)\n",
    "\n",
    "PER_ARM_DIM = test_arms.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"PER_ARM_DIM: {PER_ARM_DIM}\")\n",
    "\n",
    "test_arms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ff9baaf-987d-448d-a981-742a79b581e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE      : 128\n",
      "EVAL_BATCH_SIZE : 1\n",
      "NUM_ACTIONS     : 20\n",
      "GLOBAL_DIM      : 64\n",
      "PER_ARM_DIM     : 64\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE      = 128\n",
    "EVAL_BATCH_SIZE = 1\n",
    "\n",
    "NUM_ACTIONS     = 20 #this is kinda deceptive - \n",
    "#our approach is to learn by \"flashing\" one movie rating at a time per user context. \n",
    "#The n_actions = show/don't show the movie with one degree of freedom (n-1)\n",
    "\n",
    "\n",
    "print(f\"BATCH_SIZE      : {BATCH_SIZE}\")\n",
    "print(f\"EVAL_BATCH_SIZE : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"NUM_ACTIONS     : {NUM_ACTIONS}\")\n",
    "print(f\"GLOBAL_DIM      : {GLOBAL_DIM}\")\n",
    "print(f\"PER_ARM_DIM     : {PER_ARM_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeb4902-5bb9-4587-8d29-c01d78b006be",
   "metadata": {},
   "source": [
    "# [3] TensorSpecs\n",
    "\n",
    "* say you have a global observation spec of `[17]`. And you have two batch dimensions `[4, 5]`. Then your observation has to have the shape `[4, 5, 17]`\n",
    "* and then if you have arm_obs_spec with shape `[9, 13]`, then the arm obs shape has to be exactly `[4, 5, 9, 13]`\n",
    "* and this has to be true for every single tensor in your tensor nest\n",
    "* the first 2 dims are the outer dims that are the same for all tensors, the rest of the dimensions have to follow the spec for each tensor\n",
    "\n",
    "**TODO:**\n",
    "* explain relationship between Tensor Specs and their Tensor counterparts\n",
    "* highlight the errors, lessons learned, and utility functions to address these"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20eca8d-8c73-4ec8-9d0f-f2b428055ac2",
   "metadata": {},
   "source": [
    "## Implementing MAB with TF-Agents\n",
    "\n",
    "In TF-Agents, the *per-arm features* implementation differs from the *global-only* feature examples in the following aspects:\n",
    "* Reward is modeled not per-arm, but globally.\n",
    "* The arms are permutation invariant: it doesn’t matter which arm is arm 1 or arm 2, only their features.\n",
    "* One can have a different number of arms to choose from in every step (note that unspecified/dynamically changing number of arms will have a problem with XLA compatibility).\n",
    "\n",
    "When implementing per-arm features in TF-Bandits, the following details have to be discussed:\n",
    "* Observation spec and observations,\n",
    "* Action spec and actions,\n",
    "* Implementation of specific policies and agents.\n",
    "\n",
    "\n",
    "**TODO:**\n",
    "* outline the components and highlight their interactions, dependencies on eachother, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f68ebe8-116d-43b3-a6e1-4f5a5c7f4741",
   "metadata": {},
   "source": [
    "### Observation spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9c4746-d01b-4ca4-aa53-ab68da54d37a",
   "metadata": {},
   "source": [
    "**This observation spec allows the user to have a global observation of fixed dimension**, and an unspecified number of *per-arm* features (also of fixed dimension)\n",
    "* The actions output by the policy are still integers as usual, and they indicate which row of the arm-features it has chosen \n",
    "* The action spec must be a single integer value without boundaries:\n",
    "\n",
    "```python\n",
    "global_spec = tensor_spec.TensorSpec([GLOBAL_DIM], tf.float32)\n",
    "per_arm_spec = tensor_spec.TensorSpec([None, PER_ARM_DIM], tf.float32)\n",
    "observation_spec = {'global': global_spec, 'per_arm': per_arm_spec}\n",
    "\n",
    "action_spec = tensor_spec.TensorSpec((), tf.int32)\n",
    "```\n",
    "> Here the only difference compared to the action spec with global features only is that the tensor spec is not bounded, as we don’t know how many arms there will be at any time step\n",
    "\n",
    "**XLA compatibility:**\n",
    "* Since dynamic tensor shapes are not compatible with XLA, the number of arm features (and consequently, number of arms for a step) cannot be dynamic. \n",
    "* One workaround is to fix the maximum number of arms for a problem, then pad the arm features in steps with fewer arms, and use action masking to indicate how many arms are actually active.\n",
    "\n",
    "```python\n",
    "per_arm_spec = tensor_spec.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32)\n",
    "\n",
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=(), dtype=tf.int32, minimum = 0, maximum = NUM_ACTIONS - 1\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36bd3b33-635a-4274-8b9e-7172696ebb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(20, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_spec = {\n",
    "    'global': tf.TensorSpec([GLOBAL_DIM], tf.float32),\n",
    "    'per_arm': tf.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32) #excluding action dim here\n",
    "}\n",
    "observation_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a2da92-7db2-4f42-94a7-b7bad1c8fc42",
   "metadata": {},
   "source": [
    "### Action spec\n",
    "\n",
    "> The time_step_spec and action_spec are specifications for the input time step and the output action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5af42c7-18d7-480f-a7f3-d7da3f4840eb",
   "metadata": {},
   "source": [
    "```python\n",
    "    if (\n",
    "        not tensor_spec.is_bounded(action_spec)\n",
    "        or not tensor_spec.is_discrete(action_spec)\n",
    "        or action_spec.shape.rank > 1\n",
    "        or action_spec.shape.num_elements() != 1\n",
    "    ):\n",
    "      raise NotImplementedError(\n",
    "          'action_spec must be a BoundedTensorSpec of type int32 and shape (). '\n",
    "          'Found {}.'.format(action_spec)\n",
    "      )\n",
    "```\n",
    "\n",
    "* [src](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_base_policy.py#L97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "549a123c-349a-4103-b39a-4502f47d1e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(19, dtype=int32))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=[], \n",
    "    dtype=tf.int32,\n",
    "    minimum=tf.constant(0),            \n",
    "    maximum=NUM_ACTIONS-1, # n degrees of freedom and will dictate the expected mean reward spec shape\n",
    "    name=\"action_spec\"\n",
    ")\n",
    "\n",
    "action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36ee2635-d4e3-4468-886c-ae9c62e3c80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_num_actions: 20\n",
      "predicted_rewards_mean: TensorSpec(shape=(20,), dtype=tf.float32, name=None)\n"
     ]
    }
   ],
   "source": [
    "expected_num_actions = action_spec.maximum - action_spec.minimum + 1\n",
    "print(f\"expected_num_actions: {expected_num_actions}\")\n",
    "\n",
    "predicted_rewards_mean = tensor_spec.TensorSpec([expected_num_actions])\n",
    "print(f\"predicted_rewards_mean: {predicted_rewards_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a51efce-9f1b-42d1-bec4-7b788e3fd7e0",
   "metadata": {},
   "source": [
    "### TimeStep spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95f05860-0fbf-4a5a-8273-9c81761e0ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       "                 'per_arm': TensorSpec(shape=(20, 64), dtype=tf.float32, name=None)},\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec = ts.time_step_spec(\n",
    "    observation_spec = observation_spec, \n",
    "    # reward_spec = _reward_spec\n",
    ")\n",
    "time_step_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9181303-6565-45f5-a293-08d50420a805",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Inspect chosen arm features spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6b526a5-997c-4621-b21c-82c6ca1d6a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(20, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90d3e03e-619e-4fa4-b817-f02b4cefd6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(64,), dtype=tf.float32, name=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_arm_features_info = (\n",
    "  policy_utilities.create_chosen_arm_features_info_spec(\n",
    "      time_step_spec.observation,\n",
    "  )\n",
    ")\n",
    "chosen_arm_features_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc427092-beb7-4baf-a2e9-b8d10629182c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandit_policy_type = (\n",
    "    policy_utilities.BanditPolicyType.GREEDY\n",
    ")\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a4a2a33-c7d4-4d81-8082-80dfc3596741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandit_policy_type = (\n",
    "    policy_utilities.create_bandit_policy_type_tensor_spec(shape=[1])\n",
    ")\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e7ac02b-18bd-4519-92fe-5541b1a8ddc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(20,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_spec = policy_utilities.PerArmPolicyInfo(\n",
    "  predicted_rewards_mean=predicted_rewards_mean,\n",
    "  bandit_policy_type=bandit_policy_type,\n",
    "  chosen_arm_features=chosen_arm_features_info,\n",
    ")\n",
    "info_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21f28b9b-8183-495a-89b6-a01f30ea8637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PerArmPolicyInfo(\n",
    "#     log_probability=(), \n",
    "#     predicted_rewards_mean=TensorSpec(shape=(2,), \n",
    "#                                       dtype=tf.float32, name=None), \n",
    "#     multiobjective_scalarized_predicted_rewards_mean=(), \n",
    "#     predicted_rewards_optimistic=(), \n",
    "#     predicted_rewards_sampled=(), \n",
    "#     bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), \n",
    "#     chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9c197-ae9b-461d-8956-f078b929ac12",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [4] The Agent\n",
    "\n",
    "**Note** that contextual bandits form a special case of RL, where the actions taken by the agent do not alter the state of the environment \n",
    "\n",
    "> “Contextual” refers to the fact that the agent chooses among a set of actions while having knowledge of the context (environment observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81d6e84-688e-48c5-aea1-77df031348c9",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Agent & Network defined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aadb01-eb5c-4870-ae14-9e66624ba594",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Agent types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d075e8a6-11a9-4346-8725-3653fba4bac4",
   "metadata": {},
   "source": [
    "> `AGENT_TYPE = ['LinUCB', 'LinTS', 'epsGreedy', 'NeuralLinUCB']`\n",
    "\n",
    "LinearUCBAgent: (`LinUCB`) \n",
    "* An agent implementing the Linear UCB bandit algorithm ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/lin_ucb_agent/LinearUCBAgent))\n",
    "\n",
    "LinearThompsonSamplingAgent: (`LinTS`) \n",
    "* Implements the Linear Thompson Sampling Agent from the [paper](https://arxiv.org/abs/1209.3352): *Thompson Sampling for Contextual Bandits with Linear Payoffs* ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/linear_thompson_sampling_agent/LinearThompsonSamplingAgent))\n",
    "\n",
    "NeuralEpsilonGreedyAgent: (`epsGreedy`) \n",
    "* A neural network based epsilon greedy agent ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_epsilon_greedy_agent/NeuralEpsilonGreedyAgent))\n",
    "\n",
    "NeuralLinUCBAgent: (`NeuralLinUCB`) \n",
    "* An agent implementing the LinUCB algorithm on top of a neural network ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_linucb_agent/NeuralLinUCBAgent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b8e88e-c8ea-4193-a911-0d974ef3b1a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Network types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f547087d-5fad-4521-a584-cb46ce52897d",
   "metadata": {},
   "source": [
    "Which network architecture to use for the `epsGreedy` or `NeuralLinUCB` agents\n",
    "\n",
    "```\n",
    "NETWORK_TYPE = ['commontower', 'dotproduct']\n",
    "```\n",
    "\n",
    "**GlobalAndArmCommonTowerNetwork:** (`commontower`)\n",
    "* This network takes the output of the global and per-arm networks, and leads them through a common network, that in turn outputs reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "> * `COMMON_LAYERS` - Iterable of ints. Specifies the layers of the common tower\n",
    "* The network produced by this function can be used either in `GreedyRewardPredictionPolicy`, or `NeuralLinUCBPolicy`\n",
    "> * In the former case, the network must have `output_dim=1`, it is going to be an instance of `QNetwork`, and used in the policy as a reward prediction network\n",
    "> * In the latter case, the network will be an encoding network with its output consumed by a reward layer or a `LinUCB` method. The specified `output_dim` will be the encoding dimension\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmCommonTowerNetwork)\n",
    "\n",
    "**GlobalAndArmDotProductNetwork:** (`dotproduct`)\n",
    "* This network calculates the **dot product** of the output of the global and per-arm networks and returns them as reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmDotProductNetwork)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3dc270-deb5-4e96-8276-74759a06c318",
   "metadata": {},
   "source": [
    "### Agent config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbe29263-453d-405e-ac50-fee7f379f335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\n",
      "\n",
      "time_step_spec:  TimeStep(\n",
      "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
      "                 'per_arm': TensorSpec(shape=(20, 64), dtype=tf.float32, name=None)},\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n",
      "\n",
      "action_spec:  BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(19, dtype=int32))\n",
      "\n",
      "observation_spec:  {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(20, 64), dtype=tf.float32, name=None)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\")\n",
    "print(\"\\ntime_step_spec: \", time_step_spec)\n",
    "print(\"\\naction_spec: \", action_spec)\n",
    "print(\"\\nobservation_spec: \", observation_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d817bf2-1fa6-4bae-af90-745fad996b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'common_layers': [16, 8],\n",
      " 'encoding_dim': 1,\n",
      " 'epsilon': 0.01,\n",
      " 'eval_batch_size': 1,\n",
      " 'global_layers': [64, 32, 16],\n",
      " 'learning_rate': 0.05,\n",
      " 'model_type': 'LinUCB',\n",
      " 'network_type': 'commontower',\n",
      " 'num_actions': 20,\n",
      " 'per_arm_layers': [64, 32, 16]}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Agents\n",
    "# ================================\n",
    "AGENT_TYPE      = 'LinUCB' # 'LinUCB' | 'LinTS |, 'epsGreedy' | 'NeuralLinUCB'\n",
    "\n",
    "# Parameters for linear agents (LinUCB and LinTS).\n",
    "AGENT_ALPHA     = 0.1\n",
    "\n",
    "# Parameters for neural agents (NeuralEpsGreedy and NerualLinUCB).\n",
    "EPSILON         = 0.01\n",
    "LR              = 0.05\n",
    "\n",
    "# Parameters for NeuralLinUCB\n",
    "ENCODING_DIM    = 1\n",
    "EPS_PHASE_STEPS = 1000\n",
    "\n",
    "# ================================\n",
    "# Agent's Preprocess Network\n",
    "# ================================\n",
    "GLOBAL_LAYERS   = [64, 32, 16] # beginning should be of size: GLOBAL_DIM\n",
    "ARM_LAYERS      = [64, 32, 16] # beginning should be of size: PER_ARM_DIM\n",
    "COMMON_LAYERS   = [16, 8]\n",
    "\n",
    "NETWORK_TYPE    = \"commontower\" # 'commontower' | 'dotproduct'\n",
    "\n",
    "if AGENT_TYPE == 'NeuralLinUCB':\n",
    "    NETWORK_TYPE = 'commontower'\n",
    "    ENCODING_DIM = COMMON_LAYERS[-1]\n",
    "\n",
    "\n",
    "HPARAMS = {  # TODO - streamline and consolidate\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"eval_batch_size\" : EVAL_BATCH_SIZE,\n",
    "    \"num_actions\": NUM_ACTIONS,\n",
    "    \"model_type\": AGENT_TYPE,\n",
    "    \"network_type\": NETWORK_TYPE,\n",
    "    \"global_layers\": GLOBAL_LAYERS,\n",
    "    \"per_arm_layers\": ARM_LAYERS,\n",
    "    \"common_layers\": COMMON_LAYERS,\n",
    "    \"learning_rate\": LR,\n",
    "    \"epsilon\": EPSILON,\n",
    "    \"encoding_dim\": ENCODING_DIM\n",
    "}\n",
    "pprint(HPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2bf060bb-9880-40b4-8583-dd7a3f915bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent: linear_ucb_agent\n",
      "Network: commontower\n"
     ]
    }
   ],
   "source": [
    "from src.perarm_features import agent_factory as agent_factory\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "    agent_type = AGENT_TYPE,\n",
    "    network_type = NETWORK_TYPE,\n",
    "    time_step_spec = time_step_spec,\n",
    "    action_spec = action_spec,\n",
    "    observation_spec=observation_spec,\n",
    "    global_layers = GLOBAL_LAYERS,\n",
    "    arm_layers = ARM_LAYERS,\n",
    "    common_layers = COMMON_LAYERS,\n",
    "    agent_alpha = AGENT_ALPHA,\n",
    "    learning_rate = LR,\n",
    "    epsilon = EPSILON,\n",
    "    train_step_counter = global_step,\n",
    "    output_dim = ENCODING_DIM,\n",
    "    eps_phase_steps = EPS_PHASE_STEPS,\n",
    "    summarize_grads_and_vars = True,\n",
    "    debug_summaries = True\n",
    ")\n",
    "      \n",
    "agent.initialize()\n",
    "print(f'agent: {agent.name}')\n",
    "\n",
    "# if network:\n",
    "#     print(f\"Network: {network}\")\n",
    "\n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {NETWORK_TYPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d77d1-a0b3-4898-adf0-0b32bfaf5bd7",
   "metadata": {},
   "source": [
    "#### Inspect the specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78ca56e7-a386-4bf4-8c2b-3d1665521f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(19, dtype=int32))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41483f5a-bda6-48a4-9e1c-88d8b4afeea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(20, 64), dtype=tf.float32, name=None)}),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.time_step_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f205716-f265-4ca8-81a7-4799de8f60a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(Trajectory(\n",
       "{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(19, dtype=int32)),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None)}),\n",
       " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=(), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None)),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.training_data_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d404dae-3cc3-4f81-962b-4641455ca4f2",
   "metadata": {},
   "source": [
    "# [5] Reward function\n",
    "\n",
    "> see `reward_factory.py`\n",
    "\n",
    "* Since we are training a policy with previously collected interaction data, we model the reward function from actual rewards\n",
    "* We will simply pass the `user_rating` (values 0-5) as rewards to the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df9aecd6-d20a-48a7-9ead-4da3bbcfdae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _get_rewards(element):\n",
    "#     \"\"\"Calculates reward for the actions.\"\"\"\n",
    "\n",
    "#     def _calc_reward(x):\n",
    "#         \"\"\"Calculates reward for a single action.\"\"\"\n",
    "#         r0 = lambda: tf.constant(0.0)\n",
    "#         r1 = lambda: tf.constant(1.0)\n",
    "#         r2 = lambda: tf.constant(2.0)\n",
    "#         r3 = lambda: tf.constant(3.0)\n",
    "#         r4 = lambda: tf.constant(4.0)\n",
    "#         r5 = lambda: tf.constant(5.0)\n",
    "#         c1 = tf.equal(x, 1.0)\n",
    "#         c2 = tf.equal(x, 2.0)\n",
    "#         c3 = tf.equal(x, 3.0)\n",
    "#         c4 = tf.equal(x, 4.0)\n",
    "#         c5 = tf.equal(x, 5.0)\n",
    "#         return tf.case(\n",
    "#             [(c1, r1), (c2, r2), (c3, r3),(c4, r4),(c5, r5)], \n",
    "#             default=r0, exclusive=True\n",
    "#         )\n",
    "\n",
    "#     return tf.map_fn(\n",
    "#         fn=_calc_reward, \n",
    "#         elems=element['user_rating'], \n",
    "#         dtype=tf.float32\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac59703a-9a00-4eba-a3b7-45b21b738dd4",
   "metadata": {},
   "source": [
    "# [6] Trajectory function\n",
    "\n",
    "> This function will convert training samples from the TF Records to `trajectories` which the Agent interprets as training records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c16aa7b-f328-425e-b02e-a3fc7f200859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.perarm_features import reward_factory as reward_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3605d9f-d239-4871-9a61-6e9b21f9c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _trajectory_fn(element): # hparams\n",
    "    \n",
    "    \"\"\"Converts a dataset element into a trajectory.\"\"\"\n",
    "    # global_features = _get_global_context_features(element)\n",
    "    # arm_features = _get_per_arm_features(element)\n",
    "    \n",
    "    global_features = embs._get_global_context_features(element)\n",
    "    arm_features = embs._get_per_arm_features(element)\n",
    "    \n",
    "    # Adds a time dimension.\n",
    "    arm_features = train_utils._add_outer_dimension(arm_features)\n",
    "\n",
    "    # obs spec\n",
    "    observation = {\n",
    "        bandit_spec_utils.GLOBAL_FEATURE_KEY:\n",
    "            train_utils._add_outer_dimension(global_features),\n",
    "    }\n",
    "\n",
    "    # reward = train_utils._add_outer_dimension(_get_rewards(element))\n",
    "    reward = train_utils._add_outer_dimension(reward_factory._get_rewards(element))\n",
    "\n",
    "    # To emit the predicted rewards in policy_info, we need to create dummy\n",
    "    # rewards to match the definition in TensorSpec for the ones specified in\n",
    "    # emit_policy_info set.\n",
    "    dummy_rewards = tf.zeros([HPARAMS['batch_size'], 1, HPARAMS['num_actions']])\n",
    "    policy_info = policy_utilities.PerArmPolicyInfo(\n",
    "        chosen_arm_features=arm_features,\n",
    "        # Pass dummy mean rewards here to match the model_spec for emitting\n",
    "        # mean rewards in policy info\n",
    "        predicted_rewards_mean=dummy_rewards,\n",
    "        bandit_policy_type=tf.zeros([HPARAMS['batch_size'], 1, 1], dtype=tf.int32)\n",
    "        # policy_utilities.create_bandit_policy_type_tensor_spec(shape=[1]) # policy_utilities.BanditPolicyType.GREEDY\n",
    "        # tf.zeros([batch_size, 1, 1], dtype=tf.int32)\n",
    "    )\n",
    "    \n",
    "    if HPARAMS['model_type'] == 'neural_ucb':\n",
    "        policy_info = policy_info._replace(\n",
    "            predicted_rewards_optimistic=dummy_rewards\n",
    "        )\n",
    "        \n",
    "    return trajectory.single_step(\n",
    "        observation=observation,\n",
    "        action=tf.zeros_like(\n",
    "            reward, dtype=tf.int32\n",
    "        ),  # Arm features are copied from policy info, put dummy zeros here\n",
    "        policy_info=policy_info,\n",
    "        reward=reward,\n",
    "        discount=tf.zeros_like(reward)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a0989c-5a06-4fd5-a12d-d92dbbe71a76",
   "metadata": {},
   "source": [
    "Inspect the trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "257791d1-c97c-48c0-bc92-f5a4737b6c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in train_dataset.batch(HPARAMS['batch_size']).take(1):\n",
    "    test_traj = _trajectory_fn(x)\n",
    "    \n",
    "# test_traj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d8994e-ce28-4fd9-8e3b-153451d014d9",
   "metadata": {},
   "source": [
    "#### Inspect shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a0e451f-1ad8-4af2-84d6-ddc5eaac0e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.action.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.action.shape: {test_traj.action.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "52ed1767-12ce-404c-9caf-0974d55ec5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.discount.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.discount.shape: {test_traj.discount.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "033ff16b-0158-477f-835f-99deec636b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.reward.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.reward.shape: {test_traj.reward.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee5aded7-7f9c-4a88-868c-f6ab58a0e704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.observation.shape: (128, 1, 64)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.observation.shape: {test_traj.observation['global'].shape}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcbfc9a-049e-49b9-b2a3-ecb9fd4b9964",
   "metadata": {},
   "source": [
    "# [7] Training the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13adc1ef-b50e-41a3-9b95-c128d0c55a2b",
   "metadata": {},
   "source": [
    "## set Vertex Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e861fb27-df24-4821-8448-cf1346b186f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : v2-local-2a-v1\n",
      "RUN_NAME          : run-20231101-124200\n",
      "\n",
      "BASE_OUTPUT_DIR   : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231101-124200\n",
      "LOG_DIR           : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231101-124200/logs\n",
      "ROOT_DIR          : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231101-124200/root\n",
      "ARTIFACTS_DIR     : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231101-124200/artifacts\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME   = f'v2-local-2a-v1'\n",
    "\n",
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b7a5e4-efff-490b-b431-53037a2f4a16",
   "metadata": {},
   "source": [
    "## eval loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba0392e-90c8-4dc8-8df2-6d2af1ade490",
   "metadata": {},
   "source": [
    "> When evaluating an epsilon-greedy bandit, we need to remove those predictions that come from the `uniform_random` policy. We only want the predictions from the `GREEDY` policy, becasue we want to know how the model performs when it is actually used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b3d3c-75f7-46f4-9a1b-6329e419b7f5",
   "metadata": {},
   "source": [
    "## train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "97cfe7c3-4022-47a9-83c2-df0ad8a2abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.metrics import export_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.utils import common\n",
    "\n",
    "# from src.per_arm_rl import train_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bb7ffc-00df-4d46-857b-86c87b78f597",
   "metadata": {},
   "source": [
    "`agent.train(experience=...)`\n",
    "\n",
    "where `experience` is a batch of trajectories data in the form of a Trajectory. \n",
    "* The structure of experience must match that of `self.training_data_spec`. \n",
    "* All tensors in experience must be shaped [batch, time, ...] where time must be equal to self.train_step_length if that property is not None."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94d6d45-c71e-4fe4-9af8-af9a8bda4e4f",
   "metadata": {},
   "source": [
    "### logs & checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "049ee49b-3b1a-4b12-a360-15e759dff7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('metrics: [<tf_agents.metrics.tf_metrics.AverageReturnMetric object at '\n",
      " '0x7fc93c1a6950>]')\n",
      "setting checkpoint_manager: gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231101-124200/root/chkpoint\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    f\"{LOG_DIR}/train\", flush_millis=10 * 1000\n",
    ")\n",
    "# train_summary_writer.set_as_default()\n",
    "\n",
    "# eval_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "#     f\"{LOG_DIR}/eval\", flush_millis=10 * 1000\n",
    "# )\n",
    "# ====================================================\n",
    "# metrics\n",
    "# ====================================================\n",
    "step_metric = tf_metrics.EnvironmentSteps()\n",
    "metrics = [\n",
    "    # tf_metrics.NumberOfEpisodes(),\n",
    "    # tf_metrics.AverageEpisodeLengthMetric(batch_size=HPARAMS['batch_size']),\n",
    "    tf_metrics.AverageReturnMetric(batch_size=HPARAMS['batch_size'])\n",
    "]\n",
    "\n",
    "pprint(f\"metrics: {metrics}\")\n",
    "\n",
    "# ====================================================\n",
    "# get checkpoint manager\n",
    "# ====================================================\n",
    "CHKPOINT_DIR = f\"{ROOT_DIR}/chkpoint\"\n",
    "print(f\"setting checkpoint_manager: {CHKPOINT_DIR}\")\n",
    "\n",
    "checkpoint_manager = train_utils.restore_and_get_checkpoint_manager(\n",
    "    root_dir=CHKPOINT_DIR, \n",
    "    agent=agent, \n",
    "    metrics=metrics, \n",
    "    step_metric=step_metric\n",
    ")\n",
    "# ====================================================\n",
    "# policy saver\n",
    "# ====================================================\n",
    "saver = policy_saver.PolicySaver(\n",
    "    agent.policy, \n",
    "    train_step=global_step\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83683f4b-8a1a-44b9-8d5f-7ee3304c794c",
   "metadata": {},
   "source": [
    "### config\n",
    "\n",
    "* calculate train & val dataset sizes\n",
    "* define logging and chkpt intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f9432613-6583-4828-8a2a-dd939adbc3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_DATA_SIZE : 80000\n",
      "NUM_TRAIN_STEPS : 100\n",
      "EVAL_DATA_SIZE : 1000\n",
      "NUM_EVAL_STEPS : 1000\n",
      "CHKPT_INTERVAL: 100\n",
      "LOG_INTERVAL : 10\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA_SIZE = 80000          # len(list(train_dataset))\n",
    "NUM_TRAIN_STEPS = 100            # TRAIN_DATA_SIZE // HPARAMS['batch_size']\n",
    "\n",
    "EVAL_DATA_SIZE  = 1000          # len(list(val_dataset))\n",
    "NUM_EVAL_STEPS  = 1000           # EVAL_DATA_SIZE // HPARAMS['eval_batch_size']\n",
    "\n",
    "CHKPT_INTERVAL  = NUM_TRAIN_STEPS # // 5\n",
    "LOG_INTERVAL    = 10\n",
    "# EVAL_INTERVAL = NUM_TRAIN_STEPS // 2\n",
    "\n",
    "print(f\"TRAIN_DATA_SIZE : {TRAIN_DATA_SIZE}\")\n",
    "print(f\"NUM_TRAIN_STEPS : {NUM_TRAIN_STEPS}\")\n",
    "print(f\"EVAL_DATA_SIZE : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS : {NUM_EVAL_STEPS}\")\n",
    "print(f\"CHKPT_INTERVAL: {CHKPT_INTERVAL}\")\n",
    "print(f\"LOG_INTERVAL : {LOG_INTERVAL}\")\n",
    "# print(f\"EVAL_INTERVAL : {EVAL_INTERVAL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "379ffc65-4eec-4af1-8fd4-912ef65a9808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec={'bucketized_user_age': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'movie_genres': TensorSpec(shape=(None, 1), dtype=tf.int64, name=None), 'movie_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'timestamp': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'user_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_occupation_text': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_rating': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data\n",
    "train_ds_iterator = iter(train_dataset.batch(HPARAMS['batch_size']).repeat())\n",
    "\n",
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS[\"eval_batch_size\"])\n",
    "\n",
    "if NUM_EVAL_STEPS > 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)\n",
    "\n",
    "# eval_ds = eval_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "eval_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e498d7e3-d166-4e1d-94a5-f721de58694a",
   "metadata": {},
   "source": [
    "### run train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5dd64d98-7d5b-4474-a567-b42426d630a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.perarm_features import eval_perarm as eval_perarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "da4680f3-693b-4530-8e4d-88bc43036c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating pre-trained Agent...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/tf_agents/policies/tf_policy.py:253: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if policy_state is ():  # pylint: disable=literal-comparison\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/tf_agents/policies/tf_policy.py:315: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if not (policy_state is None or policy_state is () or policy_state is []):  # pylint: disable=literal-comparison\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/tf_agents/policies/tf_policy.py:253: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if policy_state is ():  # pylint: disable=literal-comparison\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/tf_agents/policies/tf_policy.py:315: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if not (policy_state is None or policy_state is () or policy_state is []):  # pylint: disable=literal-comparison\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/tf_agents/utils/common.py:1443: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  return state is not None and state is not () and state is not []\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/tf_agents/utils/common.py:1443: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  return state is not None and state is not () and state is not []\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/tf_agents/policies/tf_policy.py:253: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if policy_state is ():  # pylint: disable=literal-comparison\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/tf_agents/policies/tf_policy.py:315: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if not (policy_state is None or policy_state is () or policy_state is []):  # pylint: disable=literal-comparison\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/tf_agents/policies/tf_policy.py:253: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if policy_state is ():  # pylint: disable=literal-comparison\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/tf_agents/policies/tf_policy.py:315: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if not (policy_state is None or policy_state is () or policy_state is []):  # pylint: disable=literal-comparison\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arm observation shape is expected to be [None, 20, 64]. Got [1, 2, 64].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluating pre-trained Agent...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 17\u001b[0m pre_val_loss, pre_preds, pre_tr_rewards \u001b[38;5;241m=\u001b[39m \u001b[43meval_perarm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_bandit_eval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpre_policy_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43meval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mHPARAMS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meval_batch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_arm_dim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mPER_ARM_DIM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobal_dim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mGLOBAL_DIM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvocab_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_oov_buckets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mNUM_OOV_BUCKETS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobal_emb_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mGLOBAL_EMBEDDING_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmv_emb_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mMV_EMBEDDING_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m runtime_mins \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m((time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpre-train val_loss     : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpre_val_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/tf_vertex_agents/02-perarm-features-bandit/../src/perarm_features/eval_perarm.py:72\u001b[0m, in \u001b[0;36m_run_bandit_eval\u001b[0;34m(policy, data, eval_batch_size, per_arm_dim, global_dim, vocab_dict, num_oov_buckets, global_emb_size, mv_emb_size)\u001b[0m\n\u001b[1;32m     69\u001b[0m trajectory_step \u001b[38;5;241m=\u001b[39m train_utils\u001b[38;5;241m.\u001b[39m_get_eval_step(feature, actual_reward)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# pred w/ trained agent\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrajectory_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m predicted_rewards_mean \u001b[38;5;241m=\u001b[39m prediction\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mpredicted_rewards_mean \u001b[38;5;66;03m#[0]\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# pred_rewards_mean_list.append(predicted_rewards_mean)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/policies/py_policy.py:161\u001b[0m, in \u001b[0;36mPyPolicy.action\u001b[0;34m(self, time_step, policy_state, seed)\u001b[0m\n\u001b[1;32m    159\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_action(time_step, policy_state, seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/policies/py_tf_eager_policy.py:104\u001b[0m, in \u001b[0;36mPyTFEagerPolicyBase._action\u001b[0;34m(self, time_step, policy_state, seed)\u001b[0m\n\u001b[1;32m    102\u001b[0m   policy_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy_action_fn(time_step, policy_state, seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m   policy_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_policy_action_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_time_steps:\n\u001b[1;32m    106\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m policy_step\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/policies/tf_policy.py:324\u001b[0m, in \u001b[0;36mTFPolicy.action\u001b[0;34m(self, time_step, policy_state, seed)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_automatic_state_reset:\n\u001b[1;32m    323\u001b[0m   policy_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_reset_state(time_step, policy_state)\n\u001b[0;32m--> 324\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[43maction_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclip_action\u001b[39m(action, action_spec):\n\u001b[1;32m    327\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(action_spec, tensor_spec\u001b[38;5;241m.\u001b[39mBoundedTensorSpec):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/utils/common.py:188\u001b[0m, in \u001b[0;36mfunction_in_tf1.<locals>.maybe_wrap.<locals>.with_check_resource_vars\u001b[0;34m(*fn_args, **fn_kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m check_tf1_allowed()\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_eager_been_enabled():\n\u001b[1;32m    186\u001b[0m   \u001b[38;5;66;03m# We're either in eager mode or in tf.function mode (no in-between); so\u001b[39;00m\n\u001b[1;32m    187\u001b[0m   \u001b[38;5;66;03m# autodep-like behavior is already expected of fn.\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m resource_variables_enabled():\n\u001b[1;32m    190\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(MISSING_RESOURCE_VARIABLES_ERROR)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/policies/tf_policy.py:560\u001b[0m, in \u001b[0;36mTFPolicy._action\u001b[0;34m(self, time_step, policy_state, seed)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implementation of `action`.\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \n\u001b[1;32m    547\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;124;03m    `info`: Optional side information such as action log probabilities.\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    559\u001b[0m seed_stream \u001b[38;5;241m=\u001b[39m tfp\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mSeedStream(seed\u001b[38;5;241m=\u001b[39mseed, salt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf_agents_tf_policy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 560\u001b[0m distribution_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_state\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pytype: disable=wrong-arg-types\u001b[39;00m\n\u001b[1;32m    561\u001b[0m actions \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m d: reparameterized_sampling\u001b[38;5;241m.\u001b[39msample(d, seed\u001b[38;5;241m=\u001b[39mseed_stream()),\n\u001b[1;32m    563\u001b[0m     distribution_step\u001b[38;5;241m.\u001b[39maction)\n\u001b[1;32m    564\u001b[0m info \u001b[38;5;241m=\u001b[39m distribution_step\u001b[38;5;241m.\u001b[39minfo\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/bandits/policies/linear_bandit_policy.py:335\u001b[0m, in \u001b[0;36mLinearBanditPolicy._distribution\u001b[0;34m(self, time_step, policy_state)\u001b[0m\n\u001b[1;32m    331\u001b[0m   observation, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_and_action_constraint_splitter(\n\u001b[1;32m    332\u001b[0m       observation)\n\u001b[1;32m    333\u001b[0m observation \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m o: tf\u001b[38;5;241m.\u001b[39mcast(o, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype),\n\u001b[1;32m    334\u001b[0m                                     observation)\n\u001b[0;32m--> 335\u001b[0m global_observation, arm_observations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split_observation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_bias:\n\u001b[1;32m    338\u001b[0m   \u001b[38;5;66;03m# The bias is added via a constant 1 feature.\u001b[39;00m\n\u001b[1;32m    339\u001b[0m   global_observation \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat([\n\u001b[1;32m    340\u001b[0m       global_observation,\n\u001b[1;32m    341\u001b[0m       tf\u001b[38;5;241m.\u001b[39mones([tf\u001b[38;5;241m.\u001b[39mshape(global_observation)[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype)\n\u001b[1;32m    342\u001b[0m   ],\n\u001b[1;32m    343\u001b[0m                                  axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/bandits/policies/linear_bandit_policy.py:491\u001b[0m, in \u001b[0;36mLinearBanditPolicy._split_observation\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    488\u001b[0m   arm_observations \u001b[38;5;241m=\u001b[39m observation[bandit_spec_utils\u001b[38;5;241m.\u001b[39mPER_ARM_FEATURE_KEY]\n\u001b[1;32m    489\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m arm_observations\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mis_compatible_with(\n\u001b[1;32m    490\u001b[0m       [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arm_context_dim]):\n\u001b[0;32m--> 491\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    492\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArm observation shape is expected to be \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    493\u001b[0m             [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arm_context_dim],\n\u001b[1;32m    494\u001b[0m             arm_observations\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mas_list()))\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m   global_observation \u001b[38;5;241m=\u001b[39m observation\n",
      "\u001b[0;31mValueError\u001b[0m: Arm observation shape is expected to be [None, 20, 64]. Got [1, 2, 64]."
     ]
    }
   ],
   "source": [
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "# agent.train = common.function(agent.train)\n",
    "\n",
    "list_o_loss = []\n",
    "\n",
    "# ====================================================\n",
    "# Evaluate the agent's policy once before training\n",
    "# ====================================================\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "pre_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "\n",
    "print(f\"evaluating pre-trained Agent...\")\n",
    "start_time = time.time()\n",
    "\n",
    "pre_val_loss, pre_preds, pre_tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = pre_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"pre-train val_loss     : {pre_val_loss}\")\n",
    "print(f\"pre-train eval runtime : {runtime_mins}\")\n",
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "print(f\"starting train loop...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# for i in tqdm(range(NUM_TRAIN_STEPS)):\n",
    "for i in range(NUM_TRAIN_STEPS):\n",
    "    \n",
    "    with train_summary_writer.as_default():\n",
    "\n",
    "        data = next(train_ds_iterator)\n",
    "        trajectories = _trajectory_fn(data)\n",
    "\n",
    "        # All tensors in experience must be shaped [batch, time, ...] \n",
    "        step = agent.train_step_counter.numpy()\n",
    "        loss = agent.train(experience=trajectories)\n",
    "        list_o_loss.append(loss.loss.numpy())\n",
    "\n",
    "        train_utils._export_metrics_and_summaries(\n",
    "            step=i, \n",
    "            metrics=metrics\n",
    "        )\n",
    "\n",
    "        # print step loss\n",
    "        if step % LOG_INTERVAL == 0:\n",
    "            print(\n",
    "                'step = {0}: train loss = {1}'.format(\n",
    "                    step, round(loss.loss.numpy(), 2)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if i > 0 and i % CHKPT_INTERVAL == 0:\n",
    "            saver.save(os.path.join(CHKPOINT_DIR, 'policy_%d' % step_metric.result()))\n",
    "            print(f\"saved policy to: {CHKPOINT_DIR}\")\n",
    "   \n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"train runtime_mins: {runtime_mins}\")\n",
    "\n",
    "saver.save(ARTIFACTS_DIR)\n",
    "print(f\"saved trained policy to: {ARTIFACTS_DIR}\")\n",
    "\n",
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = post_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "17b2b0d2-9795-4367-b57b-c331e94d1000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.894"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb1ed8-f67b-4e7b-9cbc-70edd50e49ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate train job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff31fe28-2f05-499f-b1cc-505f3c9074e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### train loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "41937f9a-6c28-48d2-bc7c-bfe4372c7cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_o_loss)\n",
    "# plt.ylim([0, 10])\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e947e1-67f4-4205-99af-6921c6e9c896",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e0f77a33-0962-4af0-af97-cf05f895cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5d0509cb-0777-4d35-86c6-28c8acbcc793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6fdfa2c5c65ab6ec\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6fdfa2c5c65ab6ec\");\n",
       "          const url = new URL(\"/proxy/6007/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=$LOG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc40143-30b1-479f-b9b1-fa4c07b1690e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [8] Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6c94a0-122f-4ba6-acef-5653a3cc7850",
   "metadata": {
    "tags": []
   },
   "source": [
    "## load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b1c382b5-e2e0-45a2-9c5f-ef2c468d0f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231025-203917/artifacts\n"
     ]
    }
   ],
   "source": [
    "POLICY_URI = ARTIFACTS_DIR\n",
    "\n",
    "print(POLICY_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "68592d97-1272-4c6d-a4bd-43a6f7fe6c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7ff2e0533430>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910a06f-678f-4bfa-a132-10b885f871c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## get predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1762c936-3c49-4ec5-a9eb-4df5816dc888",
   "metadata": {},
   "source": [
    "TODO - explain bandit_policy_type()\n",
    "\n",
    "**UNIFORM Random policy:**\n",
    "```\n",
    "PolicyStep(action=array(1, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.637535 , 3.5557823], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([2], dtype=int32), chosen_arm_features=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)))\n",
    "```\n",
    "\n",
    "**GREEDY policy:**\n",
    "```\n",
    "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.8278818, 3.607565 ], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([ 0.04054676, -0.04735027,  0.02202327,  0.01276748, -0.01367382,\n",
    "       -0.04838754,  0.00104916, -0.01956806,  0.01028793, -0.00256665,\n",
    "       -0.04376553,  0.03900594,  0.02388967, -0.04016995, -0.04945569,\n",
    "       -0.04539652,  0.04423274, -0.04630332,  0.00390794,  0.03986299,\n",
    "       -0.0398974 ,  0.01655747, -0.0471294 , -0.00690235, -0.03643382,\n",
    "       -0.0437116 ,  0.04757959, -0.00991895,  0.0281055 , -0.04633433,\n",
    "        0.01897702, -0.00824345,  0.03232259, -0.04980658, -0.01144745,\n",
    "        0.01690939,  0.02536928,  0.03384003, -0.01558131,  0.04731432,\n",
    "        0.04579857, -0.03305101,  0.03521084, -0.03915765,  0.04927064,\n",
    "        0.04695194,  0.03792156,  0.040496  ,  0.02574866, -0.00665367,\n",
    "       -0.03839222, -0.01564004, -0.04710373,  0.03557512, -0.01392462,\n",
    "        0.01368621,  0.02792176, -0.01799218,  0.00246101,  0.02263175,\n",
    "        0.0170817 ,  0.01388383, -0.03048695,  0.01198485], dtype=float32)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "567f64e1-8149-4364-b561-1a9d12581b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "aff30396-e0fd-4f43-acaa-6af8b20b12cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "SKIP_NUM = 10\n",
    "\n",
    "for x in eval_ds.skip(SKIP_NUM).take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    \n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "    \n",
    "    # rewards = _get_rewards(x)\n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e58af9ab-f4da-4857-afe5-6b8de26ed0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.5550702, 3.5550702], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=array([-0.01929036, -0.02172024,  0.01377299, -0.00532972,  0.02284466,\n",
       "       -0.02805343, -0.03023201,  0.03354845,  0.03322053, -0.00431641,\n",
       "        0.0483649 , -0.00075575, -0.02115787, -0.00305598, -0.0275287 ,\n",
       "       -0.03679287,  0.04149821, -0.03460801,  0.04615477,  0.0285993 ,\n",
       "        0.03156564, -0.01458676, -0.02109743,  0.03455236, -0.04664432,\n",
       "       -0.0134761 , -0.01483031, -0.02110547, -0.04333172, -0.01489835,\n",
       "        0.01027884, -0.00122058, -0.0098555 ,  0.00815544, -0.03566443,\n",
       "       -0.02027269,  0.04845773,  0.04720775,  0.02366752,  0.04742989,\n",
       "        0.00555807,  0.04847962,  0.04149976, -0.04798621, -0.02944094,\n",
       "        0.01162374, -0.02891099, -0.0143748 , -0.02160816,  0.02245394,\n",
       "       -0.00364623, -0.04530915,  0.0057974 ,  0.04152076,  0.0273583 ,\n",
       "       -0.04900859,  0.01624484, -0.01421613,  0.00868339, -0.00246233,\n",
       "        0.02421555, -0.03096279,  0.03535439,  0.02782346], dtype=float32)))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6676778c-d191-4b1e-a180-61f068b3b8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.5550702, 3.5550702], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=array([-0.01929036, -0.02172024,  0.01377299, -0.00532972,  0.02284466,\n",
      "       -0.02805343, -0.03023201,  0.03354845,  0.03322053, -0.00431641,\n",
      "        0.0483649 , -0.00075575, -0.02115787, -0.00305598, -0.0275287 ,\n",
      "       -0.03679287,  0.04149821, -0.03460801,  0.04615477,  0.0285993 ,\n",
      "        0.03156564, -0.01458676, -0.02109743,  0.03455236, -0.04664432,\n",
      "       -0.0134761 , -0.01483031, -0.02110547, -0.04333172, -0.01489835,\n",
      "        0.01027884, -0.00122058, -0.0098555 ,  0.00815544, -0.03566443,\n",
      "       -0.02027269,  0.04845773,  0.04720775,  0.02366752,  0.04742989,\n",
      "        0.00555807,  0.04847962,  0.04149976, -0.04798621, -0.02944094,\n",
      "        0.01162374, -0.02891099, -0.0143748 , -0.02160816,  0.02245394,\n",
      "       -0.00364623, -0.04530915,  0.0057974 ,  0.04152076,  0.0273583 ,\n",
      "       -0.04900859,  0.01624484, -0.01421613,  0.00868339, -0.00246233,\n",
      "        0.02421555, -0.03096279,  0.03535439,  0.02782346], dtype=float32)))\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c85a0087-7388-4f03-9278-aace31121233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0, dtype=int32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a8266c7c-3688-46a5-a1c8-a63bb7146128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info.bandit_policy_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9712bc00-7ea0-4003-a3c7-81a0be5bc995",
   "metadata": {},
   "source": [
    "# [9] Prepare training application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f62966-123f-410e-9610-832f20566635",
   "metadata": {},
   "source": [
    "To scale this training in Vertex AI's managed training service, we need to package all our code into a python application\n",
    "\n",
    "* This means, we need to modularize all steps executed up until this point. For example, the training loop we ran above is further parameterized in `train_perarm.py`, which will be called from our `task.py` when we submit the job to Vertex AI\n",
    "* This training package will eventually be used to create a custom training image (more on that in `04b-build-training-image` notebook)\n",
    "* For additional details on preparing the training application for Vertex AI, check out [the documentation](https://cloud.google.com/vertex-ai/docs/training/code-requirements) and [this code example](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage2/get_started_vertex_training.ipynb) (which also has good, related commentary)\n",
    "\n",
    "**The remaining cells will repeat steps executed above**\n",
    "> we are just illustrating / validating that they are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1129ee41-b43c-4d5a-b656-cdac6b79688c",
   "metadata": {},
   "source": [
    "#### Vertex Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ef509680-4d19-4efa-9f01-21039e0d573b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : v2-local-2a-v1\n"
     ]
    }
   ],
   "source": [
    "# using same experiment name \n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7ad98430-d836-40f1-8e4f-eb46f0c91fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : v2-local-2a-v1\n",
      "RUN_NAME          : run-20231025-205628\n",
      "\n",
      "BASE_OUTPUT_DIR   : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231025-205628\n",
      "LOG_DIR           : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231025-205628/logs\n",
      "ROOT_DIR          : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231025-205628/root\n",
      "ARTIFACTS_DIR     : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231025-205628/artifacts\n"
     ]
    }
   ],
   "source": [
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fbdecf78-94c5-4f8c-a6c0-86f2eace4663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: neural_linucb_agent\n",
      "Network: commontower\n"
     ]
    }
   ],
   "source": [
    "# from src.perarm_features import agent_factory as agent_factory\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "    agent_type = AGENT_TYPE,\n",
    "    network_type = NETWORK_TYPE,\n",
    "    time_step_spec = time_step_spec,\n",
    "    action_spec = action_spec,\n",
    "    observation_spec=observation_spec,\n",
    "    global_layers = GLOBAL_LAYERS,\n",
    "    arm_layers = ARM_LAYERS,\n",
    "    common_layers = COMMON_LAYERS,\n",
    "    agent_alpha = AGENT_ALPHA,\n",
    "    learning_rate = LR,\n",
    "    epsilon = EPSILON,\n",
    "    train_step_counter = global_step,\n",
    "    output_dim = ENCODING_DIM,\n",
    "    eps_phase_steps = EPS_PHASE_STEPS,\n",
    ")\n",
    "\n",
    "print(f\"Agent: {agent.name}\")\n",
    "\n",
    "# if network:\n",
    "#     print(f\"Network: {network}\")\n",
    "\n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {NETWORK_TYPE}\")\n",
    "        \n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "108ed33c-d8ef-4524-97e9-ced9e01c154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHKPT_INTERVAL    : 200\n",
      "eval_batch_size   : 1\n",
      "EVAL_DATA_SIZE    : 1000\n",
      "NUM_EVAL_STEPS    : 100\n",
      "TOTAL_TRAIN_TAKE  : 10000\n"
     ]
    }
   ],
   "source": [
    "from src.perarm_features import train_perarm as train_perarm\n",
    "\n",
    "# train args\n",
    "TRAINING_LOOPS        = 150\n",
    "STEPS_PER_LOOP        = 1\n",
    "\n",
    "drop_arm_feature_fn   = None\n",
    "ASYNC_STEPS_PER_LOOP  = 1\n",
    "\n",
    "LOG_INTERVAL          = 10\n",
    "CHKPT_INTERVAL        = 200\n",
    "\n",
    "# eval args\n",
    "NUM_EVAL_STEPS = 100\n",
    "\n",
    "TOTAL_TRAIN_TAKE = 10000 #TRAINING_LOOPS * HPARAMS['batch_size']\n",
    "\n",
    "print(f\"CHKPT_INTERVAL    : {CHKPT_INTERVAL}\")\n",
    "print(f\"eval_batch_size   : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"EVAL_DATA_SIZE    : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS    : {NUM_EVAL_STEPS}\")\n",
    "print(f\"TOTAL_TRAIN_TAKE  : {TOTAL_TRAIN_TAKE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f66ff927-9a39-4abf-b247-845f0dc7721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS['eval_batch_size'])\n",
    "\n",
    "if NUM_EVAL_STEPS >= 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f6c98398-d545-4dcc-a71f-32249b5f0336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_files: ['gs://rec-bandits-v2-hybrid-vertex-bucket/data/train/ml-ratings-100k-train.tfrecord']\n",
      "train_ds_iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7fee19d1a7d0>\n",
      "setting checkpoint_manager: gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231025-205628/root/chkpoint\n",
      "wrapping agent.train in tf-function\n",
      "starting_loop: 0\n",
      "starting train loop...\n",
      "step = 100: loss = 14.420000076293945\n",
      "step = 110: loss = 13.15999984741211\n",
      "step = 120: loss = 12.9399995803833\n",
      "step = 130: loss = 14.020000457763672\n",
      "step = 140: loss = 13.5\n",
      "step = 150: loss = 13.390000343322754\n",
      "step = 160: loss = 10.4399995803833\n",
      "step = 170: loss = 2.0899999141693115\n",
      "step = 180: loss = 1.350000023841858\n",
      "step = 190: loss = 1.6200000047683716\n",
      "step = 200: loss = 1.8700000047683716\n",
      "step = 210: loss = 1.4900000095367432\n",
      "step = 220: loss = 1.149999976158142\n",
      "step = 230: loss = 1.0399999618530273\n",
      "step = 240: loss = 1.159999966621399\n",
      "runtime_mins: 1\n",
      "saved trained policy to: gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231025-205628/artifacts\n",
      "complete train job in 1 minutes\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    f\"{LOG_DIR}/train\", flush_millis=10 * 1000\n",
    ")\n",
    "\n",
    "#start the timer and training\n",
    "start_time = time.time()\n",
    "\n",
    "metric_results, agent = train_perarm.train_perarm(\n",
    "    agent = agent,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    num_iterations = TRAINING_LOOPS,\n",
    "    steps_per_loop = STEPS_PER_LOOP,\n",
    "    num_eval_steps = NUM_EVAL_STEPS,\n",
    "    # data\n",
    "    batch_size = HPARAMS['batch_size'],\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    # functions\n",
    "    _trajectory_fn = _trajectory_fn,\n",
    "    # _run_bandit_eval_fn = _run_bandit_eval,\n",
    "    # train intervals\n",
    "    chkpt_interval = CHKPT_INTERVAL,\n",
    "    log_interval = LOG_INTERVAL,\n",
    "    # dirs\n",
    "    bucket_name = BUCKET_NAME,\n",
    "    data_dir_prefix_path = DATA_GCS_PREFIX,\n",
    "    log_dir = LOG_DIR,\n",
    "    model_dir = ARTIFACTS_DIR,\n",
    "    root_dir = ROOT_DIR,\n",
    "    async_steps_per_loop = ASYNC_STEPS_PER_LOOP,\n",
    "    resume_training_loops = False,\n",
    "    use_gpu = True,\n",
    "    use_tpu = False,\n",
    "    profiler = False,\n",
    "    global_step = global_step,\n",
    "    total_train_take = TOTAL_TRAIN_TAKE,\n",
    "    train_summary_writer = train_summary_writer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"complete train job in {runtime_mins} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "177aa3ab-05b4-48f9-b434-9335bd9eb54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4213634"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(metric_results)\n",
    "metric_results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ba65417f-54e0-436e-b0d4-93cffb981ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(metric_results)\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7ba747-00d5-4908-8d0b-334ae9d2c791",
   "metadata": {},
   "source": [
    "#### eval trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c5cf9366-d9cd-4c9d-951a-99a50877a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af82506e-95d7-4a4e-a821-e08512615db7",
   "metadata": {},
   "source": [
    "After training, our `agent.policy` is used as the deployment \"model\" that will generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6c82396a-7822-41fb-830f-1f6eb9c9b213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.bandits.policies.neural_linucb_policy.NeuralLinUCBPolicy at 0x7fee19d0a4a0>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_agent = agent.policy\n",
    "deployment_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f6706224-ef5b-4185-bde4-bccb7c8e7ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating trained Agent...\n",
      "post-train val_loss     : 1.5351909399032593\n",
      "post-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(deployment_agent, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = post_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f899120f-3706-4b72-8f2c-2169221dd66b",
   "metadata": {},
   "source": [
    "## Using Trained Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b0f691-860e-4853-928e-4c7ece714dd0",
   "metadata": {},
   "source": [
    "### load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ea029f73-0638-462a-8f00-54b05c54d69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/artifacts\n"
     ]
    }
   ],
   "source": [
    "POLICY_URI = ARTIFACTS_DIR\n",
    "\n",
    "print(POLICY_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "66d1d819-0152-437c-aefc-45ffd34d808a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/artifacts/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/artifacts/fingerprint.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/artifacts/policy_specs.pbtxt\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/artifacts/saved_model.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/artifacts/assets/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/artifacts/variables/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $POLICY_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6aad948e-e346-4da3-8cb2-747435c8dc4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f94eb67aef0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "483f8fa5-cbd1-4e3c-8e62-47f91f42e137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(), dtype=dtype('int32'), name='action_spec', minimum=0, maximum=1)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_policy.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8f658891-bc09-49b8-bc58-000a7926df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "SKIP_NUM = 10\n",
    "\n",
    "for x in eval_ds.skip(SKIP_NUM).take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    \n",
    "    # global_feat_infer = _get_global_context_features(x)\n",
    "    # arm_feat_infer = _get_per_arm_features(x)\n",
    "    \n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "    \n",
    "    # rewards = _get_rewards(x)\n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f515fcd0-2228-4f68-9ef9-665ce1fc3fb2",
   "metadata": {},
   "source": [
    "### view prediction response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6af4c297-d2e8-4f7b-bed5-e1da997dfe34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.2646697, 3.2237158], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([-0.04211991,  0.03355854,  0.00062222, -0.03559208,  0.03014546,\n",
       "       -0.00911941,  0.03367225, -0.01702491, -0.04207989,  0.02439343,\n",
       "        0.03417565,  0.03412655, -0.01548523, -0.04152564, -0.01327814,\n",
       "        0.04441997, -0.01887345, -0.03676014, -0.01746018, -0.00505089,\n",
       "       -0.00495514, -0.02221038,  0.00734597, -0.02457649,  0.01958629,\n",
       "       -0.00150286, -0.00817053,  0.02833397,  0.03182454,  0.00413366,\n",
       "        0.04550329, -0.03923135,  0.03378687,  0.00785377, -0.0018571 ,\n",
       "       -0.02951536, -0.02467777, -0.02666589, -0.04103365, -0.00640677,\n",
       "       -0.03457658,  0.03871839, -0.03362087, -0.00123868,  0.0398059 ,\n",
       "       -0.01511135, -0.02833097,  0.03514184,  0.03603243,  0.03224551,\n",
       "        0.03410349, -0.04499953, -0.02059256, -0.01573974, -0.0066855 ,\n",
       "       -0.04533432, -0.0378898 ,  0.0453725 ,  0.01792984, -0.01493819,\n",
       "        0.03005158, -0.02943999, -0.00384724, -0.01675253], dtype=float32)))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd58d4b-6749-4177-8342-83ee969408c9",
   "metadata": {},
   "source": [
    "#### chosen action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d49adbbb-f747-4e4c-b82d-df88373c644f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0, dtype=int32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd12013-1d12-4197-8254-cef9138df42c",
   "metadata": {},
   "source": [
    "#### Per Arm Policy Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d6126290-546b-4702-8a1e-91f18adb05c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.2646697, 3.2237158], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([-0.04211991,  0.03355854,  0.00062222, -0.03559208,  0.03014546,\n",
       "       -0.00911941,  0.03367225, -0.01702491, -0.04207989,  0.02439343,\n",
       "        0.03417565,  0.03412655, -0.01548523, -0.04152564, -0.01327814,\n",
       "        0.04441997, -0.01887345, -0.03676014, -0.01746018, -0.00505089,\n",
       "       -0.00495514, -0.02221038,  0.00734597, -0.02457649,  0.01958629,\n",
       "       -0.00150286, -0.00817053,  0.02833397,  0.03182454,  0.00413366,\n",
       "        0.04550329, -0.03923135,  0.03378687,  0.00785377, -0.0018571 ,\n",
       "       -0.02951536, -0.02467777, -0.02666589, -0.04103365, -0.00640677,\n",
       "       -0.03457658,  0.03871839, -0.03362087, -0.00123868,  0.0398059 ,\n",
       "       -0.01511135, -0.02833097,  0.03514184,  0.03603243,  0.03224551,\n",
       "        0.03410349, -0.04499953, -0.02059256, -0.01573974, -0.0066855 ,\n",
       "       -0.04533432, -0.0378898 ,  0.0453725 ,  0.01792984, -0.01493819,\n",
       "        0.03005158, -0.02943999, -0.00384724, -0.01675253], dtype=float32))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f66961-ebb5-4ae5-8e6f-ad73114d8353",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
