{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385307d6-2058-47ec-8da0-57f7ef5c43d6",
   "metadata": {},
   "source": [
    "# Train Bandits with per-arm features\n",
    "\n",
    "**Exploring linear and nonlinear** (e.g., those with neural network-based value functions) bandit methods for recommendations using TF-Agents\n",
    "\n",
    "> Neural linear bandits provide a nice way to leverage the representation power of deep learning and the bandit approach for uncertainty measure and efficient exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1e9956-66cd-4bf4-9b4d-8c2c646f0313",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "\n",
    "In this notebook, we explore the following topics for training contextual bandits with per-arm features:\n",
    "\n",
    "1. Data preperation\n",
    "2. Sampling functions\n",
    "3. TensorSpecs\n",
    "4. Agent, Network, training policy\n",
    "5. Reward function\n",
    "6. Trajectory function\n",
    "7. Train & Eval loops\n",
    "8. Getting predictions -\n",
    "9. Preparing the training application - abstracting all steps above to be used in subsequent notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fd257-b98b-426a-a2cd-024429b014f1",
   "metadata": {},
   "source": [
    "## Load notebook config\n",
    "\n",
    "* use the prefix defined in `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f39c9d08-d118-4013-a47f-88450f49f19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "# PREFIX = 'mabv1'\n",
    "VERSION        = \"v2\"                       # TODO\n",
    "PREFIX         = f'rec-bandits-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908f6b95-b539-4a9f-a836-840d26ea3b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"rec-bandits-v2\"\n",
      "VERSION                  = \"v2\"\n",
      "\n",
      "BUCKET_NAME              = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "DATA_PATH_KFP_DEMO       = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data/kfp_demo_data/u.data\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_NAME    = \"mvlens_rec_bandits_v2\"\n",
      "BIGQUERY_TABLE_NAME      = \"training_dataset\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-rec-bandits-v2\"\n",
      "\n",
      "DOCKERNAME_01            = \"Dockerfile_train_my_perarm_env\"\n",
      "IMAGE_NAME_01            = \"train-my-perarm-env-v2\"\n",
      "IMAGE_URI_01             = \"gcr.io/hybrid-vertex/train-my-perarm-env-v2\"\n",
      "\n",
      "DOCKERNAME_02            = \"Dockerfile_perarm_feats\"\n",
      "IMAGE_NAME_02            = \"train-perarm-feats-v2\"\n",
      "IMAGE_URI_02             = \"gcr.io/hybrid-vertex/train-perarm-feats-v2\"\n",
      "\n",
      "DOCKERNAME_03            = \"Dockerfile_ranking_bandit\"\n",
      "IMAGE_NAME_03            = \"train-rank-bandit-v2\"\n",
      "IMAGE_URI_03             = \"gcr.io/hybrid-vertex/train-rank-bandit-v2\"\n",
      "\n",
      "DOCKERNAME_04            = \"Dockerfile_train_mab_e2e\"\n",
      "IMAGE_NAME_04            = \"train-mab-e2e-v2\"\n",
      "IMAGE_URI_04             = \"gcr.io/hybrid-vertex/train-mab-e2e-v2\"\n",
      "\n",
      "DOCKERNAME_04_pred       = \"Dockerfile_pred_mab_e2e\"\n",
      "IMAGE_NAME_04_pred       = \"pred-mab-e2e-v2\"\n",
      "IMAGE_URI_04_pred        = \"gcr.io/hybrid-vertex/pred-mab-e2e-v2\"\n",
      "\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/local_docker_tfa\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c690a9-e2bd-4759-ba41-4e2469098aee",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d0dfe4-695c-4dd4-9f24-67f7488ce1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c669f1a1-1af7-4efb-ab2d-6bf3b3847991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from collections import defaultdict\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pickle as pkl\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "# from tf_agents.agents import TFAgent\n",
    "\n",
    "# from tf_agents.bandits.environments import stationary_stochastic_per_arm_py_environment as p_a_env\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "# from tf_agents.drivers import dynamic_step_driver\n",
    "# from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "# from tf_agents.bandits.agents import lin_ucb_agent\n",
    "# from tf_agents.bandits.agents import linear_thompson_sampling_agent as lin_ts_agent\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent\n",
    "from tf_agents.bandits.agents import neural_linucb_agent\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "from tf_agents.bandits.policies import policy_utilities\n",
    "\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "\n",
    "nest = tf.nest\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# this repo\n",
    "from src.per_arm_rl import data_utils\n",
    "from src.per_arm_rl import data_config\n",
    "from src.per_arm_rl import train_utils as train_utils\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29e58dd7-ab2b-419f-9771-bf1e98db758b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4969d3e-1fc0-45db-8a69-aa6b342019de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "274e7f4a-1802-4946-888e-876638f5c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a866b1-85b9-43e6-9546-edfbbf886bce",
   "metadata": {},
   "source": [
    "# [1] Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d4ed28-23d7-4785-b327-e5b543b0edb9",
   "metadata": {},
   "source": [
    "**Overview**\n",
    "* Load train and eval datasets from TFRecords created in the `01-movielens-data-prep.ipynb` notebook\n",
    "* training examples represent historical (previously collected) interaction data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd5b953-14c0-42ed-a511-77147a1bc0ac",
   "metadata": {},
   "source": [
    "### Read TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d0157c8-a04c-4dbd-b6d9-a1ede97687a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da0cdac-76af-4608-b70e-be7dbe0584b5",
   "metadata": {},
   "source": [
    "**Train data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c934c06-bf08-4c7f-b0cc-0de04ef3515c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://rec-bandits-v2-hybrid-vertex-bucket/data/train/ml-ratings-100k-train.tfrecord']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPLIT = \"train\" # \"train\" | \"val\"\n",
    "\n",
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7511e4d-bf81-4800-bde7-8b16dec9aeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([35.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'898'], dtype=object)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([885409515])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'681'], dtype=object)>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'marketing'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "train_dataset = train_dataset.map(data_utils.parse_tfrecord)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452750c1-46a0-4ee1-84d4-0c3b227de38f",
   "metadata": {},
   "source": [
    "**Val data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7b5376f-9438-4304-84aa-de09c30f5e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = \"val\"\n",
    "\n",
    "val_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        val_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "val_dataset = tf.data.TFRecordDataset(val_files)\n",
    "val_dataset = val_dataset.map(data_utils.parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8959967-522e-41c8-9a1b-050ca8bc191f",
   "metadata": {},
   "source": [
    "### get vocab\n",
    "\n",
    "**TODO:** \n",
    "* streamline vocab calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b9169bc-d6dc-497e-9dff-6ebb175282ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE_VOCABS: False\n"
     ]
    }
   ],
   "source": [
    "GENERATE_VOCABS = False\n",
    "\n",
    "print(f\"GENERATE_VOCABS: {GENERATE_VOCABS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3ccf137-7a72-42e7-aa89-3c81a99cf40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab...\n",
      "Downloaded vocab from: gs://rec-bandits-v2-hybrid-vertex-bucket/vocabs/vocab_dict.pkl\n",
      "\n",
      "'movie_id'\n",
      "'user_id'\n",
      "'user_occupation_text'\n",
      "'movie_genres'\n",
      "'bucketized_user_age'\n",
      "'max_timestamp'\n",
      "'min_timestamp'\n",
      "'timestamp_buckets'\n"
     ]
    }
   ],
   "source": [
    "if not GENERATE_VOCABS:\n",
    "\n",
    "    EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{VOCAB_SUBDIR}/{VOCAB_FILENAME}'\n",
    "    print(f\"Downloading vocab...\")\n",
    "    \n",
    "    os.system(f'gsutil -q cp {EXISTING_VOCAB_FILE} .')\n",
    "    print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "    filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "    vocab_dict = pkl.load(filehandler)\n",
    "    filehandler.close()\n",
    "    \n",
    "    for key in vocab_dict.keys():\n",
    "        pprint(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccaef62-882a-46ff-a1b1-3837e69fdf74",
   "metadata": {},
   "source": [
    "## helper functions\n",
    "\n",
    "**TODO:**\n",
    "* modularize in a train_utils or similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138a295-2b0d-4359-8496-af8552ec8cff",
   "metadata": {},
   "source": [
    "# [2] Preprocessing layers for global and arm features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e28c002-8d3a-4cf4-b69b-de56a6abab90",
   "metadata": {},
   "source": [
    "The preproccesing layers will ultimately feed the two sampling functions described below. These sampling functions will be used to create [trajectories](https://github.com/tensorflow/agents/blob/master/tf_agents/trajectories/trajectory.py#L36) (i.e., the training examples for our model)\n",
    "\n",
    "`global_context_sampling_fn`: \n",
    "* A function that outputs a random 1d array or list of ints or floats\n",
    "* This output is the global context. Its shape and type must be consistent across calls.\n",
    "\n",
    "`arm_context_sampling_fn`: \n",
    "* A function that outputs a random 1 array or list of ints or floats (same type as the output of `global_context_sampling_fn`). * This output is the per-arm context. Its shape must be consistent across calls.\n",
    "\n",
    "See `debug-and-learn-emb-models.ipynb` for more details and debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ea1f7-0621-44b8-b062-1f59b0964d72",
   "metadata": {},
   "source": [
    "## Global & Per-Arm feature embedding models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8d77956-635c-438a-916a-185eec52f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OOV_BUCKETS        = 1\n",
    "GLOBAL_EMBEDDING_SIZE  = 16\n",
    "MV_EMBEDDING_SIZE      = 32 #32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea335991-dcec-40b3-ba0d-a0fdfb9c2ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test emb models\n",
    "for i in range(1):\n",
    "    \n",
    "    iterator = iter(train_dataset.batch(1))\n",
    "    data = next(iterator)\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48178fff-491f-4f03-b156-7765d1fa9707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.perarm_features.emb_features.EmbeddingModel at 0x7fe61acf6aa0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.perarm_features import emb_features as emb_features\n",
    "\n",
    "embs = emb_features.EmbeddingModel(\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "903c63c5-2468-4443-bcb8-5ff6d69810dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL_DIM: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.01532255,  0.0389137 ,  0.02818141,  0.03414938, -0.02974174,\n",
       "         0.01841216,  0.04289437, -0.03991847,  0.01129884, -0.0444306 ,\n",
       "         0.03803419, -0.0033327 ,  0.00946841,  0.02116772, -0.01133622,\n",
       "         0.03806726,  0.04609768, -0.00465218,  0.03110934, -0.02929218,\n",
       "         0.01136889, -0.00358035,  0.03751209, -0.02989444, -0.00885681,\n",
       "        -0.01170083, -0.01783239, -0.00489355,  0.03842261, -0.01032375,\n",
       "         0.02171626, -0.01583026, -0.02555913,  0.01258169,  0.00791571,\n",
       "         0.0199278 , -0.00535649,  0.0166517 , -0.0294104 ,  0.04086335,\n",
       "        -0.01934995,  0.02041486, -0.02467816, -0.04868826, -0.02194636,\n",
       "        -0.04138388,  0.03597874, -0.02616059, -0.04495857,  0.00778084,\n",
       "        -0.04705818, -0.02825017, -0.02538953, -0.02211368, -0.02578236,\n",
       "        -0.00223947,  0.04027517, -0.02274809,  0.02888802, -0.02070003,\n",
       "        -0.00010145, -0.00086613, -0.01698775, -0.01038671]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_globals = embs._get_global_context_features(data)\n",
    "\n",
    "GLOBAL_DIM = test_globals.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"GLOBAL_DIM: {GLOBAL_DIM}\")\n",
    "\n",
    "test_globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebec4863-c614-4248-b680-8e29ec5b730d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER_ARM_DIM: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00078917, -0.01914835,  0.02577287,  0.0417925 , -0.00133055,\n",
       "         0.01731328,  0.00012255, -0.01488259, -0.03913279, -0.03003212,\n",
       "         0.01361518, -0.02369593,  0.01408393, -0.01544755,  0.03236214,\n",
       "         0.00541812, -0.01380652, -0.01879265,  0.04452092, -0.00304625,\n",
       "         0.01059411,  0.01903615,  0.04014946, -0.04424319, -0.03766892,\n",
       "        -0.01399187, -0.04911239,  0.03588877, -0.00957873, -0.00734109,\n",
       "        -0.03424877,  0.00716799, -0.04614605, -0.02790066, -0.02654055,\n",
       "        -0.00086435, -0.04556495,  0.01514352,  0.03515935, -0.03073185,\n",
       "         0.01615486, -0.03763211, -0.01269769, -0.00125878, -0.0089695 ,\n",
       "        -0.00668029,  0.03949113,  0.01551357, -0.02229415, -0.02347057,\n",
       "         0.00276691, -0.00840928,  0.03644626, -0.03384774, -0.04377778,\n",
       "        -0.01624724,  0.02428106, -0.04081696,  0.00108535,  0.02536676,\n",
       "         0.0219964 , -0.03997756,  0.01750362,  0.04317484]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arms = embs._get_per_arm_features(data)\n",
    "\n",
    "PER_ARM_DIM = test_arms.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"PER_ARM_DIM: {PER_ARM_DIM}\")\n",
    "\n",
    "test_arms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ff9baaf-987d-448d-a981-742a79b581e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE      : 128\n",
      "EVAL_BATCH_SIZE : 1\n",
      "NUM_ACTIONS     : 2\n",
      "GLOBAL_DIM      : 64\n",
      "PER_ARM_DIM     : 64\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE      = 128\n",
    "EVAL_BATCH_SIZE = 1\n",
    "\n",
    "NUM_ACTIONS     = 2 #this is kinda deceptive - \n",
    "#our approach is to learn by \"flashing\" one movie rating at a time per user context. \n",
    "#The n_actions = show/don't show the movie with one degree of freedom (n-1)\n",
    "\n",
    "\n",
    "print(f\"BATCH_SIZE      : {BATCH_SIZE}\")\n",
    "print(f\"EVAL_BATCH_SIZE : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"NUM_ACTIONS     : {NUM_ACTIONS}\")\n",
    "print(f\"GLOBAL_DIM      : {GLOBAL_DIM}\")\n",
    "print(f\"PER_ARM_DIM     : {PER_ARM_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeb4902-5bb9-4587-8d29-c01d78b006be",
   "metadata": {},
   "source": [
    "# [3] TensorSpecs\n",
    "\n",
    "* say you have a global observation spec of `[17]`. And you have two batch dimensions `[4, 5]`. Then your observation has to have the shape `[4, 5, 17]`\n",
    "* and then if you have arm_obs_spec with shape `[9, 13]`, then the arm obs shape has to be exactly `[4, 5, 9, 13]`\n",
    "* and this has to be true for every single tensor in your tensor nest\n",
    "* the first 2 dims are the outer dims that are the same for all tensors, the rest of the dimensions have to follow the spec for each tensor\n",
    "\n",
    "**TODO:**\n",
    "* explain relationship between Tensor Specs and their Tensor counterparts\n",
    "* highlight the errors, lessons learned, and utility functions to address these"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20eca8d-8c73-4ec8-9d0f-f2b428055ac2",
   "metadata": {},
   "source": [
    "## Implementing MAB with TF-Agents\n",
    "\n",
    "In TF-Agents, the *per-arm features* implementation differs from the *global-only* feature examples in the following aspects:\n",
    "* Reward is modeled not per-arm, but globally.\n",
    "* The arms are permutation invariant: it doesn’t matter which arm is arm 1 or arm 2, only their features.\n",
    "* One can have a different number of arms to choose from in every step (note that unspecified/dynamically changing number of arms will have a problem with XLA compatibility).\n",
    "\n",
    "When implementing per-arm features in TF-Bandits, the following details have to be discussed:\n",
    "* Observation spec and observations,\n",
    "* Action spec and actions,\n",
    "* Implementation of specific policies and agents.\n",
    "\n",
    "\n",
    "**TODO:**\n",
    "* outline the components and highlight their interactions, dependencies on eachother, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f68ebe8-116d-43b3-a6e1-4f5a5c7f4741",
   "metadata": {},
   "source": [
    "### Observation spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9c4746-d01b-4ca4-aa53-ab68da54d37a",
   "metadata": {},
   "source": [
    "**This observation spec allows the user to have a global observation of fixed dimension**, and an unspecified number of *per-arm* features (also of fixed dimension)\n",
    "* The actions output by the policy are still integers as usual, and they indicate which row of the arm-features it has chosen \n",
    "* The action spec must be a single integer value without boundaries:\n",
    "\n",
    "```python\n",
    "global_spec = tensor_spec.TensorSpec([GLOBAL_DIM], tf.float32)\n",
    "per_arm_spec = tensor_spec.TensorSpec([None, PER_ARM_DIM], tf.float32)\n",
    "observation_spec = {'global': global_spec, 'per_arm': per_arm_spec}\n",
    "\n",
    "action_spec = tensor_spec.TensorSpec((), tf.int32)\n",
    "```\n",
    "> Here the only difference compared to the action spec with global features only is that the tensor spec is not bounded, as we don’t know how many arms there will be at any time step\n",
    "\n",
    "**XLA compatibility:**\n",
    "* Since dynamic tensor shapes are not compatible with XLA, the number of arm features (and consequently, number of arms for a step) cannot be dynamic. \n",
    "* One workaround is to fix the maximum number of arms for a problem, then pad the arm features in steps with fewer arms, and use action masking to indicate how many arms are actually active.\n",
    "\n",
    "```python\n",
    "per_arm_spec = tensor_spec.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32)\n",
    "\n",
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=(), dtype=tf.int32, minimum = 0, maximum = NUM_ACTIONS - 1\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36bd3b33-635a-4274-8b9e-7172696ebb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_spec = {\n",
    "    'global': tf.TensorSpec([GLOBAL_DIM], tf.float32),\n",
    "    'per_arm': tf.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32) #excluding action dim here\n",
    "}\n",
    "observation_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a2da92-7db2-4f42-94a7-b7bad1c8fc42",
   "metadata": {},
   "source": [
    "### Action spec\n",
    "\n",
    "> The time_step_spec and action_spec are specifications for the input time step and the output action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5af42c7-18d7-480f-a7f3-d7da3f4840eb",
   "metadata": {},
   "source": [
    "```python\n",
    "    if (\n",
    "        not tensor_spec.is_bounded(action_spec)\n",
    "        or not tensor_spec.is_discrete(action_spec)\n",
    "        or action_spec.shape.rank > 1\n",
    "        or action_spec.shape.num_elements() != 1\n",
    "    ):\n",
    "      raise NotImplementedError(\n",
    "          'action_spec must be a BoundedTensorSpec of type int32 and shape (). '\n",
    "          'Found {}.'.format(action_spec)\n",
    "      )\n",
    "```\n",
    "\n",
    "* [src](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_base_policy.py#L97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "549a123c-349a-4103-b39a-4502f47d1e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=[], \n",
    "    dtype=tf.int32,\n",
    "    minimum=tf.constant(0),            \n",
    "    maximum=NUM_ACTIONS-1, # n degrees of freedom and will dictate the expected mean reward spec shape\n",
    "    name=\"action_spec\"\n",
    ")\n",
    "\n",
    "action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36ee2635-d4e3-4468-886c-ae9c62e3c80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_num_actions: 2\n",
      "predicted_rewards_mean: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n"
     ]
    }
   ],
   "source": [
    "expected_num_actions = action_spec.maximum - action_spec.minimum + 1\n",
    "print(f\"expected_num_actions: {expected_num_actions}\")\n",
    "\n",
    "predicted_rewards_mean = tensor_spec.TensorSpec([expected_num_actions])\n",
    "print(f\"predicted_rewards_mean: {predicted_rewards_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a51efce-9f1b-42d1-bec4-7b788e3fd7e0",
   "metadata": {},
   "source": [
    "### TimeStep spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95f05860-0fbf-4a5a-8273-9c81761e0ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec = ts.time_step_spec(\n",
    "    observation_spec = observation_spec, \n",
    "    # reward_spec = _reward_spec\n",
    ")\n",
    "time_step_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9181303-6565-45f5-a293-08d50420a805",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Inspect chosen arm features spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6b526a5-997c-4621-b21c-82c6ca1d6a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90d3e03e-619e-4fa4-b817-f02b4cefd6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(64,), dtype=tf.float32, name=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_arm_features_info = (\n",
    "  policy_utilities.create_chosen_arm_features_info_spec(\n",
    "      time_step_spec.observation,\n",
    "  )\n",
    ")\n",
    "chosen_arm_features_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc427092-beb7-4baf-a2e9-b8d10629182c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandit_policy_type = (\n",
    "    policy_utilities.BanditPolicyType.GREEDY\n",
    ")\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a4a2a33-c7d4-4d81-8082-80dfc3596741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandit_policy_type = (\n",
    "    policy_utilities.create_bandit_policy_type_tensor_spec(shape=[1])\n",
    ")\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e7ac02b-18bd-4519-92fe-5541b1a8ddc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_spec = policy_utilities.PerArmPolicyInfo(\n",
    "  predicted_rewards_mean=predicted_rewards_mean,\n",
    "  bandit_policy_type=bandit_policy_type,\n",
    "  chosen_arm_features=chosen_arm_features_info,\n",
    ")\n",
    "info_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21f28b9b-8183-495a-89b6-a01f30ea8637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PerArmPolicyInfo(\n",
    "#     log_probability=(), \n",
    "#     predicted_rewards_mean=TensorSpec(shape=(2,), \n",
    "#                                       dtype=tf.float32, name=None), \n",
    "#     multiobjective_scalarized_predicted_rewards_mean=(), \n",
    "#     predicted_rewards_optimistic=(), \n",
    "#     predicted_rewards_sampled=(), \n",
    "#     bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), \n",
    "#     chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9c197-ae9b-461d-8956-f078b929ac12",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [4] The Agent\n",
    "\n",
    "**Note** that contextual bandits form a special case of RL, where the actions taken by the agent do not alter the state of the environment \n",
    "\n",
    "> “Contextual” refers to the fact that the agent chooses among a set of actions while having knowledge of the context (environment observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81d6e84-688e-48c5-aea1-77df031348c9",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Agent & Network defined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aadb01-eb5c-4870-ae14-9e66624ba594",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Agent types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d075e8a6-11a9-4346-8725-3653fba4bac4",
   "metadata": {},
   "source": [
    "> `AGENT_TYPE = ['LinUCB', 'LinTS', 'epsGreedy', 'NeuralLinUCB']`\n",
    "\n",
    "LinearUCBAgent: (`LinUCB`) \n",
    "* An agent implementing the Linear UCB bandit algorithm ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/lin_ucb_agent/LinearUCBAgent))\n",
    "\n",
    "LinearThompsonSamplingAgent: (`LinTS`) \n",
    "* Implements the Linear Thompson Sampling Agent from the [paper](https://arxiv.org/abs/1209.3352): *Thompson Sampling for Contextual Bandits with Linear Payoffs* ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/linear_thompson_sampling_agent/LinearThompsonSamplingAgent))\n",
    "\n",
    "NeuralEpsilonGreedyAgent: (`epsGreedy`) \n",
    "* A neural network based epsilon greedy agent ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_epsilon_greedy_agent/NeuralEpsilonGreedyAgent))\n",
    "\n",
    "NeuralLinUCBAgent: (`NeuralLinUCB`) \n",
    "* An agent implementing the LinUCB algorithm on top of a neural network ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_linucb_agent/NeuralLinUCBAgent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b8e88e-c8ea-4193-a911-0d974ef3b1a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Network types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f547087d-5fad-4521-a584-cb46ce52897d",
   "metadata": {},
   "source": [
    "Which network architecture to use for the `epsGreedy` or `NeuralLinUCB` agents\n",
    "\n",
    "```\n",
    "NETWORK_TYPE = ['commontower', 'dotproduct']\n",
    "```\n",
    "\n",
    "**GlobalAndArmCommonTowerNetwork:** (`commontower`)\n",
    "* This network takes the output of the global and per-arm networks, and leads them through a common network, that in turn outputs reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "> * `COMMON_LAYERS` - Iterable of ints. Specifies the layers of the common tower\n",
    "* The network produced by this function can be used either in `GreedyRewardPredictionPolicy`, or `NeuralLinUCBPolicy`\n",
    "> * In the former case, the network must have `output_dim=1`, it is going to be an instance of `QNetwork`, and used in the policy as a reward prediction network\n",
    "> * In the latter case, the network will be an encoding network with its output consumed by a reward layer or a `LinUCB` method. The specified `output_dim` will be the encoding dimension\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmCommonTowerNetwork)\n",
    "\n",
    "**GlobalAndArmDotProductNetwork:** (`dotproduct`)\n",
    "* This network calculates the **dot product** of the output of the global and per-arm networks and returns them as reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmDotProductNetwork)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3dc270-deb5-4e96-8276-74759a06c318",
   "metadata": {},
   "source": [
    "### Agent config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bbe29263-453d-405e-ac50-fee7f379f335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\n",
      "\n",
      "time_step_spec:  TimeStep(\n",
      "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
      "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n",
      "\n",
      "action_spec:  BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))\n",
      "\n",
      "observation_spec:  {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\")\n",
    "print(\"\\ntime_step_spec: \", time_step_spec)\n",
    "print(\"\\naction_spec: \", action_spec)\n",
    "print(\"\\nobservation_spec: \", observation_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d817bf2-1fa6-4bae-af90-745fad996b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'common_layers': [16, 8],\n",
      " 'encoding_dim': 1,\n",
      " 'epsilon': 0.01,\n",
      " 'eval_batch_size': 1,\n",
      " 'global_layers': [64, 32, 16],\n",
      " 'learning_rate': 0.05,\n",
      " 'model_type': 'LinTS',\n",
      " 'network_type': 'commontower',\n",
      " 'num_actions': 2,\n",
      " 'per_arm_layers': [64, 32, 16]}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Agents\n",
    "# ================================\n",
    "AGENT_TYPE      = 'LinTS' # 'LinUCB' | 'LinTS |, 'epsGreedy' | 'NeuralLinUCB'\n",
    "\n",
    "# Parameters for linear agents (LinUCB and LinTS).\n",
    "AGENT_ALPHA     = 0.1\n",
    "\n",
    "# Parameters for neural agents (NeuralEpsGreedy and NerualLinUCB).\n",
    "EPSILON         = 0.01\n",
    "LR              = 0.05\n",
    "\n",
    "# Parameters for NeuralLinUCB\n",
    "ENCODING_DIM    = 1\n",
    "EPS_PHASE_STEPS = 1000\n",
    "\n",
    "# ================================\n",
    "# Agent's Preprocess Network\n",
    "# ================================\n",
    "GLOBAL_LAYERS   = [64, 32, 16] # beginning should be of size: GLOBAL_DIM\n",
    "ARM_LAYERS      = [64, 32, 16] # beginning should be of size: PER_ARM_DIM\n",
    "COMMON_LAYERS   = [16, 8]\n",
    "\n",
    "NETWORK_TYPE    = \"commontower\" # 'commontower' | 'dotproduct'\n",
    "\n",
    "if AGENT_TYPE == 'NeuralLinUCB':\n",
    "    NETWORK_TYPE = 'commontower'\n",
    "    ENCODING_DIM = COMMON_LAYERS[-1]\n",
    "\n",
    "\n",
    "HPARAMS = {  # TODO - streamline and consolidate\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"eval_batch_size\" : EVAL_BATCH_SIZE,\n",
    "    \"num_actions\": NUM_ACTIONS,\n",
    "    \"model_type\": AGENT_TYPE,\n",
    "    \"network_type\": NETWORK_TYPE,\n",
    "    \"global_layers\": GLOBAL_LAYERS,\n",
    "    \"per_arm_layers\": ARM_LAYERS,\n",
    "    \"common_layers\": COMMON_LAYERS,\n",
    "    \"learning_rate\": LR,\n",
    "    \"epsilon\": EPSILON,\n",
    "    \"encoding_dim\": ENCODING_DIM\n",
    "}\n",
    "pprint(HPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2bf060bb-9880-40b4-8583-dd7a3f915bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent: linear_thompson_sampling_agent\n",
      "Network: commontower\n"
     ]
    }
   ],
   "source": [
    "from src.perarm_features import agent_factory as agent_factory\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "    agent_type = AGENT_TYPE,\n",
    "    network_type = NETWORK_TYPE,\n",
    "    time_step_spec = time_step_spec,\n",
    "    action_spec = action_spec,\n",
    "    observation_spec=observation_spec,\n",
    "    global_layers = GLOBAL_LAYERS,\n",
    "    arm_layers = ARM_LAYERS,\n",
    "    common_layers = COMMON_LAYERS,\n",
    "    agent_alpha = AGENT_ALPHA,\n",
    "    learning_rate = LR,\n",
    "    epsilon = EPSILON,\n",
    "    train_step_counter = global_step,\n",
    "    output_dim = ENCODING_DIM,\n",
    "    eps_phase_steps = EPS_PHASE_STEPS,\n",
    "    summarize_grads_and_vars = True,\n",
    "    debug_summaries = True\n",
    ")\n",
    "      \n",
    "agent.initialize()\n",
    "print(f'agent: {agent.name}')\n",
    "\n",
    "# if network:\n",
    "#     print(f\"Network: {network}\")\n",
    "\n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {NETWORK_TYPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d77d1-a0b3-4898-adf0-0b32bfaf5bd7",
   "metadata": {},
   "source": [
    "#### Inspect the specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78ca56e7-a386-4bf4-8c2b-3d1665521f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41483f5a-bda6-48a4-9e1c-88d8b4afeea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.time_step_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f205716-f265-4ca8-81a7-4799de8f60a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(Trajectory(\n",
       "{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32)),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None)}),\n",
       " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None)),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.training_data_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d404dae-3cc3-4f81-962b-4641455ca4f2",
   "metadata": {},
   "source": [
    "# [5] Reward function\n",
    "\n",
    "> see `reward_factory.py`\n",
    "\n",
    "* Since we are training a policy with previously collected interaction data, we model the reward function from actual rewards\n",
    "* We will simply pass the `user_rating` (values 0-5) as rewards to the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df9aecd6-d20a-48a7-9ead-4da3bbcfdae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _get_rewards(element):\n",
    "#     \"\"\"Calculates reward for the actions.\"\"\"\n",
    "\n",
    "#     def _calc_reward(x):\n",
    "#         \"\"\"Calculates reward for a single action.\"\"\"\n",
    "#         r0 = lambda: tf.constant(0.0)\n",
    "#         r1 = lambda: tf.constant(1.0)\n",
    "#         r2 = lambda: tf.constant(2.0)\n",
    "#         r3 = lambda: tf.constant(3.0)\n",
    "#         r4 = lambda: tf.constant(4.0)\n",
    "#         r5 = lambda: tf.constant(5.0)\n",
    "#         c1 = tf.equal(x, 1.0)\n",
    "#         c2 = tf.equal(x, 2.0)\n",
    "#         c3 = tf.equal(x, 3.0)\n",
    "#         c4 = tf.equal(x, 4.0)\n",
    "#         c5 = tf.equal(x, 5.0)\n",
    "#         return tf.case(\n",
    "#             [(c1, r1), (c2, r2), (c3, r3),(c4, r4),(c5, r5)], \n",
    "#             default=r0, exclusive=True\n",
    "#         )\n",
    "\n",
    "#     return tf.map_fn(\n",
    "#         fn=_calc_reward, \n",
    "#         elems=element['user_rating'], \n",
    "#         dtype=tf.float32\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac59703a-9a00-4eba-a3b7-45b21b738dd4",
   "metadata": {},
   "source": [
    "# [6] Trajectory function\n",
    "\n",
    "> This function will convert training samples from the TF Records to `trajectories` which the Agent interprets as training records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c16aa7b-f328-425e-b02e-a3fc7f200859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.perarm_features import reward_factory as reward_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3605d9f-d239-4871-9a61-6e9b21f9c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _trajectory_fn(element): # hparams\n",
    "    \n",
    "    \"\"\"Converts a dataset element into a trajectory.\"\"\"\n",
    "    # global_features = _get_global_context_features(element)\n",
    "    # arm_features = _get_per_arm_features(element)\n",
    "    \n",
    "    global_features = embs._get_global_context_features(element)\n",
    "    arm_features = embs._get_per_arm_features(element)\n",
    "    \n",
    "    # Adds a time dimension.\n",
    "    arm_features = train_utils._add_outer_dimension(arm_features)\n",
    "\n",
    "    # obs spec\n",
    "    observation = {\n",
    "        bandit_spec_utils.GLOBAL_FEATURE_KEY:\n",
    "            train_utils._add_outer_dimension(global_features),\n",
    "    }\n",
    "\n",
    "    # reward = train_utils._add_outer_dimension(_get_rewards(element))\n",
    "    reward = train_utils._add_outer_dimension(reward_factory._get_rewards(element))\n",
    "\n",
    "    # To emit the predicted rewards in policy_info, we need to create dummy\n",
    "    # rewards to match the definition in TensorSpec for the ones specified in\n",
    "    # emit_policy_info set.\n",
    "    dummy_rewards = tf.zeros([HPARAMS['batch_size'], 1, HPARAMS['num_actions']])\n",
    "    policy_info = policy_utilities.PerArmPolicyInfo(\n",
    "        chosen_arm_features=arm_features,\n",
    "        # Pass dummy mean rewards here to match the model_spec for emitting\n",
    "        # mean rewards in policy info\n",
    "        predicted_rewards_mean=dummy_rewards,\n",
    "        bandit_policy_type=tf.zeros([HPARAMS['batch_size'], 1, 1], dtype=tf.int32)\n",
    "        # policy_utilities.create_bandit_policy_type_tensor_spec(shape=[1]) # policy_utilities.BanditPolicyType.GREEDY\n",
    "        # tf.zeros([batch_size, 1, 1], dtype=tf.int32)\n",
    "    )\n",
    "    \n",
    "    if HPARAMS['model_type'] == 'neural_ucb':\n",
    "        policy_info = policy_info._replace(\n",
    "            predicted_rewards_optimistic=dummy_rewards\n",
    "        )\n",
    "        \n",
    "    return trajectory.single_step(\n",
    "        observation=observation,\n",
    "        action=tf.zeros_like(\n",
    "            reward, dtype=tf.int32\n",
    "        ),  # Arm features are copied from policy info, put dummy zeros here\n",
    "        policy_info=policy_info,\n",
    "        reward=reward,\n",
    "        discount=tf.zeros_like(reward)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a0989c-5a06-4fd5-a12d-d92dbbe71a76",
   "metadata": {},
   "source": [
    "Inspect the trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "257791d1-c97c-48c0-bc92-f5a4737b6c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in train_dataset.batch(HPARAMS['batch_size']).take(1):\n",
    "    test_traj = _trajectory_fn(x)\n",
    "    \n",
    "# test_traj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d8994e-ce28-4fd9-8e3b-153451d014d9",
   "metadata": {},
   "source": [
    "#### Inspect shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a0e451f-1ad8-4af2-84d6-ddc5eaac0e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.action.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.action.shape: {test_traj.action.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "52ed1767-12ce-404c-9caf-0974d55ec5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.discount.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.discount.shape: {test_traj.discount.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "033ff16b-0158-477f-835f-99deec636b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.reward.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.reward.shape: {test_traj.reward.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee5aded7-7f9c-4a88-868c-f6ab58a0e704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.observation.shape: (128, 1, 64)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.observation.shape: {test_traj.observation['global'].shape}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcbfc9a-049e-49b9-b2a3-ecb9fd4b9964",
   "metadata": {},
   "source": [
    "# [7] Training the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13adc1ef-b50e-41a3-9b95-c128d0c55a2b",
   "metadata": {},
   "source": [
    "## set Vertex Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e861fb27-df24-4821-8448-cf1346b186f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : v2-local-2a-v1\n",
      "RUN_NAME          : run-20231107-175607\n",
      "\n",
      "BASE_OUTPUT_DIR   : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231107-175607\n",
      "LOG_DIR           : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231107-175607/logs\n",
      "ROOT_DIR          : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231107-175607/root\n",
      "ARTIFACTS_DIR     : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231107-175607/artifacts\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME   = f'v2-local-2a-v1'\n",
    "\n",
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b7a5e4-efff-490b-b431-53037a2f4a16",
   "metadata": {},
   "source": [
    "## eval loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba0392e-90c8-4dc8-8df2-6d2af1ade490",
   "metadata": {},
   "source": [
    "> When evaluating an epsilon-greedy bandit, we need to remove those predictions that come from the `uniform_random` policy. We only want the predictions from the `GREEDY` policy, becasue we want to know how the model performs when it is actually used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b3d3c-75f7-46f4-9a1b-6329e419b7f5",
   "metadata": {},
   "source": [
    "## train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97cfe7c3-4022-47a9-83c2-df0ad8a2abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.metrics import export_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.utils import common\n",
    "\n",
    "# from src.per_arm_rl import train_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bb7ffc-00df-4d46-857b-86c87b78f597",
   "metadata": {},
   "source": [
    "`agent.train(experience=...)`\n",
    "\n",
    "where `experience` is a batch of trajectories data in the form of a Trajectory. \n",
    "* The structure of experience must match that of `self.training_data_spec`. \n",
    "* All tensors in experience must be shaped [batch, time, ...] where time must be equal to self.train_step_length if that property is not None."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94d6d45-c71e-4fe4-9af8-af9a8bda4e4f",
   "metadata": {},
   "source": [
    "### logs & checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "049ee49b-3b1a-4b12-a360-15e759dff7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('metrics: [<tf_agents.metrics.tf_metrics.AverageReturnMetric object at '\n",
      " '0x7fe61acf5480>]')\n",
      "setting checkpoint_manager: gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231107-175607/root/chkpoint\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    f\"{LOG_DIR}/train\", flush_millis=10 * 1000\n",
    ")\n",
    "# train_summary_writer.set_as_default()\n",
    "\n",
    "# eval_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "#     f\"{LOG_DIR}/eval\", flush_millis=10 * 1000\n",
    "# )\n",
    "# ====================================================\n",
    "# metrics\n",
    "# ====================================================\n",
    "step_metric = tf_metrics.EnvironmentSteps()\n",
    "metrics = [\n",
    "    # tf_metrics.NumberOfEpisodes(),\n",
    "    # tf_metrics.AverageEpisodeLengthMetric(batch_size=HPARAMS['batch_size']),\n",
    "    tf_metrics.AverageReturnMetric(batch_size=HPARAMS['batch_size'])\n",
    "]\n",
    "\n",
    "pprint(f\"metrics: {metrics}\")\n",
    "\n",
    "# ====================================================\n",
    "# get checkpoint manager\n",
    "# ====================================================\n",
    "CHKPOINT_DIR = f\"{ROOT_DIR}/chkpoint\"\n",
    "print(f\"setting checkpoint_manager: {CHKPOINT_DIR}\")\n",
    "\n",
    "checkpoint_manager = train_utils.restore_and_get_checkpoint_manager(\n",
    "    root_dir=CHKPOINT_DIR, \n",
    "    agent=agent, \n",
    "    metrics=metrics, \n",
    "    step_metric=step_metric\n",
    ")\n",
    "# ====================================================\n",
    "# policy saver\n",
    "# ====================================================\n",
    "saver = policy_saver.PolicySaver(\n",
    "    agent.policy, \n",
    "    train_step=global_step\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83683f4b-8a1a-44b9-8d5f-7ee3304c794c",
   "metadata": {},
   "source": [
    "### config\n",
    "\n",
    "* calculate train & val dataset sizes\n",
    "* define logging and chkpt intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f9432613-6583-4828-8a2a-dd939adbc3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_DATA_SIZE : 80000\n",
      "NUM_TRAIN_STEPS : 50\n",
      "EVAL_DATA_SIZE : 1000\n",
      "NUM_EVAL_STEPS : 1000\n",
      "CHKPT_INTERVAL: 50\n",
      "LOG_INTERVAL : 10\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA_SIZE = 80000          # len(list(train_dataset))\n",
    "NUM_TRAIN_STEPS = 50            # TRAIN_DATA_SIZE // HPARAMS['batch_size']\n",
    "\n",
    "EVAL_DATA_SIZE  = 1000          # len(list(val_dataset))\n",
    "NUM_EVAL_STEPS  = 1000           # EVAL_DATA_SIZE // HPARAMS['eval_batch_size']\n",
    "\n",
    "CHKPT_INTERVAL  = NUM_TRAIN_STEPS # // 5\n",
    "LOG_INTERVAL    = 10\n",
    "# EVAL_INTERVAL = NUM_TRAIN_STEPS // 2\n",
    "\n",
    "print(f\"TRAIN_DATA_SIZE : {TRAIN_DATA_SIZE}\")\n",
    "print(f\"NUM_TRAIN_STEPS : {NUM_TRAIN_STEPS}\")\n",
    "print(f\"EVAL_DATA_SIZE : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS : {NUM_EVAL_STEPS}\")\n",
    "print(f\"CHKPT_INTERVAL: {CHKPT_INTERVAL}\")\n",
    "print(f\"LOG_INTERVAL : {LOG_INTERVAL}\")\n",
    "# print(f\"EVAL_INTERVAL : {EVAL_INTERVAL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "379ffc65-4eec-4af1-8fd4-912ef65a9808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec={'bucketized_user_age': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'movie_genres': TensorSpec(shape=(None, 1), dtype=tf.int64, name=None), 'movie_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'timestamp': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'user_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_occupation_text': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_rating': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data\n",
    "train_ds_iterator = iter(train_dataset.batch(HPARAMS['batch_size']).repeat())\n",
    "\n",
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS[\"eval_batch_size\"])\n",
    "\n",
    "if NUM_EVAL_STEPS > 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)\n",
    "\n",
    "# eval_ds = eval_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "eval_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e498d7e3-d166-4e1d-94a5-f721de58694a",
   "metadata": {},
   "source": [
    "### run train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5dd64d98-7d5b-4474-a567-b42426d630a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.perarm_features import eval_perarm as eval_perarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "da4680f3-693b-4530-8e4d-88bc43036c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating pre-trained Agent...\n",
      "pre-train val_loss     : 13.894000053405762\n",
      "pre-train eval runtime : 0\n",
      "starting train loop...\n",
      "step = 0: train loss = 14.420000076293945\n",
      "step = 640: train loss = 2.4800000190734863\n",
      "step = 1280: train loss = 1.5299999713897705\n",
      "step = 1920: train loss = 2.130000114440918\n",
      "step = 2560: train loss = 1.6100000143051147\n",
      "step = 3200: train loss = 1.7699999809265137\n",
      "step = 3840: train loss = 1.6799999475479126\n",
      "step = 4480: train loss = 1.6100000143051147\n",
      "step = 5120: train loss = 1.409999966621399\n",
      "step = 5760: train loss = 1.440000057220459\n",
      "train runtime_mins: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:475: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved trained policy to: gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231107-175607/artifacts\n",
      "evaluating trained Agent...\n",
      "post-train val_loss     : 15.704875946044922\n",
      "post-train eval runtime : 1\n"
     ]
    }
   ],
   "source": [
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "# agent.train = common.function(agent.train)\n",
    "\n",
    "list_o_loss = []\n",
    "\n",
    "# ====================================================\n",
    "# Evaluate the agent's policy once before training\n",
    "# ====================================================\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "pre_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "\n",
    "print(f\"evaluating pre-trained Agent...\")\n",
    "start_time = time.time()\n",
    "\n",
    "pre_val_loss, pre_preds, pre_tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = pre_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"pre-train val_loss     : {pre_val_loss}\")\n",
    "print(f\"pre-train eval runtime : {runtime_mins}\")\n",
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "print(f\"starting train loop...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# for i in tqdm(range(NUM_TRAIN_STEPS)):\n",
    "for i in range(NUM_TRAIN_STEPS):\n",
    "    \n",
    "    with train_summary_writer.as_default():\n",
    "\n",
    "        data = next(train_ds_iterator)\n",
    "        trajectories = _trajectory_fn(data)\n",
    "\n",
    "        # All tensors in experience must be shaped [batch, time, ...] \n",
    "        step = agent.train_step_counter.numpy()\n",
    "        loss = agent.train(experience=trajectories)\n",
    "        list_o_loss.append(loss.loss.numpy())\n",
    "\n",
    "        train_utils._export_metrics_and_summaries(\n",
    "            step=i, \n",
    "            metrics=metrics\n",
    "        )\n",
    "\n",
    "        # print step loss\n",
    "        if step % LOG_INTERVAL == 0:\n",
    "            print(\n",
    "                'step = {0}: train loss = {1}'.format(\n",
    "                    step, round(loss.loss.numpy(), 2)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if i > 0 and i % CHKPT_INTERVAL == 0:\n",
    "            saver.save(os.path.join(CHKPOINT_DIR, 'policy_%d' % step_metric.result()))\n",
    "            print(f\"saved policy to: {CHKPOINT_DIR}\")\n",
    "   \n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"train runtime_mins: {runtime_mins}\")\n",
    "\n",
    "saver.save(ARTIFACTS_DIR)\n",
    "print(f\"saved trained policy to: {ARTIFACTS_DIR}\")\n",
    "\n",
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = post_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "17b2b0d2-9795-4367-b57b-c331e94d1000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.704876"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb1ed8-f67b-4e7b-9cbc-70edd50e49ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate train job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff31fe28-2f05-499f-b1cc-505f3c9074e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### train loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41937f9a-6c28-48d2-bc7c-bfe4372c7cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_o_loss)\n",
    "# plt.ylim([0, 10])\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e947e1-67f4-4205-99af-6921c6e9c896",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e0f77a33-0962-4af0-af97-cf05f895cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5d0509cb-0777-4d35-86c6-28c8acbcc793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f73b2879ee0536b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f73b2879ee0536b\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=$LOG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc40143-30b1-479f-b9b1-fa4c07b1690e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [8] Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6c94a0-122f-4ba6-acef-5653a3cc7850",
   "metadata": {
    "tags": []
   },
   "source": [
    "## load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b1c382b5-e2e0-45a2-9c5f-ef2c468d0f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231107-175607/artifacts\n"
     ]
    }
   ],
   "source": [
    "POLICY_URI = ARTIFACTS_DIR\n",
    "\n",
    "print(POLICY_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "68592d97-1272-4c6d-a4bd-43a6f7fe6c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7fe4ec29dc30>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910a06f-678f-4bfa-a132-10b885f871c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## get predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1762c936-3c49-4ec5-a9eb-4df5816dc888",
   "metadata": {},
   "source": [
    "TODO - explain bandit_policy_type()\n",
    "\n",
    "**UNIFORM Random policy:**\n",
    "```\n",
    "PolicyStep(action=array(1, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.637535 , 3.5557823], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([2], dtype=int32), chosen_arm_features=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)))\n",
    "```\n",
    "\n",
    "**GREEDY policy:**\n",
    "```\n",
    "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.8278818, 3.607565 ], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([ 0.04054676, -0.04735027,  0.02202327,  0.01276748, -0.01367382,\n",
    "       -0.04838754,  0.00104916, -0.01956806,  0.01028793, -0.00256665,\n",
    "       -0.04376553,  0.03900594,  0.02388967, -0.04016995, -0.04945569,\n",
    "       -0.04539652,  0.04423274, -0.04630332,  0.00390794,  0.03986299,\n",
    "       -0.0398974 ,  0.01655747, -0.0471294 , -0.00690235, -0.03643382,\n",
    "       -0.0437116 ,  0.04757959, -0.00991895,  0.0281055 , -0.04633433,\n",
    "        0.01897702, -0.00824345,  0.03232259, -0.04980658, -0.01144745,\n",
    "        0.01690939,  0.02536928,  0.03384003, -0.01558131,  0.04731432,\n",
    "        0.04579857, -0.03305101,  0.03521084, -0.03915765,  0.04927064,\n",
    "        0.04695194,  0.03792156,  0.040496  ,  0.02574866, -0.00665367,\n",
    "       -0.03839222, -0.01564004, -0.04710373,  0.03557512, -0.01392462,\n",
    "        0.01368621,  0.02792176, -0.01799218,  0.00246101,  0.02263175,\n",
    "        0.0170817 ,  0.01388383, -0.03048695,  0.01198485], dtype=float32)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "567f64e1-8149-4364-b561-1a9d12581b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2bcd1e82-168e-4df3-92bd-4cd34ecd3a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([25.], dtype=float32)>,\n",
       " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[0]])>,\n",
       " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'148'], dtype=object)>,\n",
       " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([884991303])>,\n",
       " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'345'], dtype=object)>,\n",
       " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'librarian'], dtype=object)>,\n",
       " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([3.], dtype=float32)>}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aff30396-e0fd-4f43-acaa-6af8b20b12cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "SKIP_NUM = 10\n",
    "\n",
    "for x in eval_ds.skip(SKIP_NUM).take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    \n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "    \n",
    "    # rewards = _get_rewards(x)\n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e58af9ab-f4da-4857-afe5-6b8de26ed0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.138678 , 1.0932529], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=array([ 0.00099449,  0.013002  , -0.00578594, -0.04500312,  0.01407028,\n",
       "        0.01357737,  0.0026253 , -0.01258489, -0.02989874,  0.04868433,\n",
       "        0.04757868, -0.00746198,  0.02669555, -0.01077186, -0.03305279,\n",
       "       -0.01358125, -0.02688495, -0.0241619 ,  0.03716041,  0.00723317,\n",
       "        0.03048239,  0.04786749, -0.03836683, -0.02123759, -0.00625535,\n",
       "        0.01838556,  0.04832575, -0.02616814, -0.0095857 ,  0.03815243,\n",
       "       -0.03382741, -0.02196823,  0.03129211, -0.02950814,  0.00519753,\n",
       "       -0.02397066, -0.04590176, -0.04253147,  0.00814832, -0.00978438,\n",
       "       -0.04153304,  0.00969982,  0.02132619,  0.02143966, -0.02294428,\n",
       "       -0.01316526,  0.02754202, -0.04867667, -0.00137611, -0.03298157,\n",
       "        0.039253  , -0.03228735, -0.04390458,  0.01295708, -0.00149374,\n",
       "       -0.04927201,  0.00156647, -0.01547524, -0.00889243, -0.00967405,\n",
       "       -0.04653727,  0.03461238,  0.01047853,  0.0095127 ], dtype=float32)))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6676778c-d191-4b1e-a180-61f068b3b8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.2813993, 2.0153742], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=array([ 3.55582573e-02, -2.18220949e-02,  4.20112498e-02, -1.11235380e-02,\n",
      "        4.00512256e-02, -4.90373373e-03, -1.36996135e-02, -1.88551098e-03,\n",
      "        3.10717113e-02, -1.14222616e-03,  4.12169807e-02,  2.07231753e-02,\n",
      "       -4.97411974e-02,  7.49480724e-03,  9.07403231e-03,  4.82893847e-02,\n",
      "       -2.63148677e-02,  4.92172316e-03,  2.20768526e-03, -1.32639185e-02,\n",
      "        1.44581869e-03, -1.20093226e-02, -1.19462013e-02, -4.75545041e-02,\n",
      "        9.28267837e-05, -2.37927791e-02, -8.33554193e-03, -3.96247990e-02,\n",
      "       -1.11187585e-02,  2.81793810e-02, -1.73517689e-02, -1.26001351e-02,\n",
      "        2.41725780e-02, -3.44446078e-02, -8.15976411e-04, -4.01634574e-02,\n",
      "       -1.00275762e-02, -1.64780244e-02, -1.59956217e-02, -1.31887086e-02,\n",
      "        4.16045524e-02,  5.17237186e-03, -6.78043440e-03, -2.47217305e-02,\n",
      "       -4.94759940e-02, -1.23101473e-02, -1.18348710e-02,  2.00027227e-03,\n",
      "        3.90228964e-02,  5.48280776e-04, -1.12056360e-02,  2.22543217e-02,\n",
      "        1.33486055e-02,  3.48489992e-02, -2.50560045e-03,  4.79648821e-02,\n",
      "       -3.54809538e-02, -2.72746570e-02,  1.19618177e-02, -1.63096189e-02,\n",
      "        9.59426165e-03,  1.51497014e-02,  2.58859284e-02,  4.88124005e-02],\n",
      "      dtype=float32)))\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c85a0087-7388-4f03-9278-aace31121233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0, dtype=int32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a8266c7c-3688-46a5-a1c8-a63bb7146128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info.bandit_policy_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9712bc00-7ea0-4003-a3c7-81a0be5bc995",
   "metadata": {},
   "source": [
    "# [9] Prepare training application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f62966-123f-410e-9610-832f20566635",
   "metadata": {},
   "source": [
    "To scale this training in Vertex AI's managed training service, we need to package all our code into a python application\n",
    "\n",
    "* This means, we need to modularize all steps executed up until this point. For example, the training loop we ran above is further parameterized in `train_perarm.py`, which will be called from our `task.py` when we submit the job to Vertex AI\n",
    "* This training package will eventually be used to create a custom training image (more on that in `04b-build-training-image` notebook)\n",
    "* For additional details on preparing the training application for Vertex AI, check out [the documentation](https://cloud.google.com/vertex-ai/docs/training/code-requirements) and [this code example](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage2/get_started_vertex_training.ipynb) (which also has good, related commentary)\n",
    "\n",
    "**The remaining cells will repeat steps executed above**\n",
    "> we are just illustrating / validating that they are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1129ee41-b43c-4d5a-b656-cdac6b79688c",
   "metadata": {},
   "source": [
    "#### Vertex Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ef509680-4d19-4efa-9f01-21039e0d573b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : v2-local-2a-v1\n"
     ]
    }
   ],
   "source": [
    "# using same experiment name \n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7ad98430-d836-40f1-8e4f-eb46f0c91fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : v2-local-2a-v1\n",
      "RUN_NAME          : run-20231102-131852\n",
      "\n",
      "BASE_OUTPUT_DIR   : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-131852\n",
      "LOG_DIR           : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-131852/logs\n",
      "ROOT_DIR          : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-131852/root\n",
      "ARTIFACTS_DIR     : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-131852/artifacts\n"
     ]
    }
   ],
   "source": [
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fbdecf78-94c5-4f8c-a6c0-86f2eace4663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: linear_thompson_sampling_agent\n",
      "Network: commontower\n"
     ]
    }
   ],
   "source": [
    "# from src.perarm_features import agent_factory as agent_factory\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "    agent_type = AGENT_TYPE,\n",
    "    network_type = NETWORK_TYPE,\n",
    "    time_step_spec = time_step_spec,\n",
    "    action_spec = action_spec,\n",
    "    observation_spec=observation_spec,\n",
    "    global_layers = GLOBAL_LAYERS,\n",
    "    arm_layers = ARM_LAYERS,\n",
    "    common_layers = COMMON_LAYERS,\n",
    "    agent_alpha = AGENT_ALPHA,\n",
    "    learning_rate = LR,\n",
    "    epsilon = EPSILON,\n",
    "    train_step_counter = global_step,\n",
    "    output_dim = ENCODING_DIM,\n",
    "    eps_phase_steps = EPS_PHASE_STEPS,\n",
    ")\n",
    "\n",
    "print(f\"Agent: {agent.name}\")\n",
    "\n",
    "# if network:\n",
    "#     print(f\"Network: {network}\")\n",
    "\n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {NETWORK_TYPE}\")\n",
    "        \n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "108ed33c-d8ef-4524-97e9-ced9e01c154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHKPT_INTERVAL    : 200\n",
      "eval_batch_size   : 1\n",
      "EVAL_DATA_SIZE    : 1000\n",
      "NUM_EVAL_STEPS    : 100\n",
      "TOTAL_TRAIN_TAKE  : 10000\n"
     ]
    }
   ],
   "source": [
    "from src.perarm_features import train_perarm as train_perarm\n",
    "\n",
    "# train args\n",
    "TRAINING_LOOPS        = 150\n",
    "STEPS_PER_LOOP        = 1\n",
    "\n",
    "drop_arm_feature_fn   = None\n",
    "ASYNC_STEPS_PER_LOOP  = 1\n",
    "\n",
    "LOG_INTERVAL          = 10\n",
    "CHKPT_INTERVAL        = 200\n",
    "\n",
    "# eval args\n",
    "NUM_EVAL_STEPS = 100\n",
    "\n",
    "TOTAL_TRAIN_TAKE = 10000 #TRAINING_LOOPS * HPARAMS['batch_size']\n",
    "\n",
    "print(f\"CHKPT_INTERVAL    : {CHKPT_INTERVAL}\")\n",
    "print(f\"eval_batch_size   : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"EVAL_DATA_SIZE    : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS    : {NUM_EVAL_STEPS}\")\n",
    "print(f\"TOTAL_TRAIN_TAKE  : {TOTAL_TRAIN_TAKE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f66ff927-9a39-4abf-b247-845f0dc7721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS['eval_batch_size'])\n",
    "\n",
    "if NUM_EVAL_STEPS >= 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f6c98398-d545-4dcc-a71f-32249b5f0336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_files: ['gs://rec-bandits-v2-hybrid-vertex-bucket/data/train/ml-ratings-100k-train.tfrecord']\n",
      "train_ds_iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7fa4c3a83220>\n",
      "setting checkpoint_manager: gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-125815/root/chkpoint\n",
      "wrapping agent.train in tf-function\n",
      "starting_loop: 0\n",
      "starting train loop...\n",
      "step = 100: loss = 15.920000076293945\n",
      "step = 110: loss = 8.529999732971191\n",
      "step = 120: loss = 4.760000228881836\n",
      "step = 130: loss = 1.7200000286102295\n",
      "step = 140: loss = 1.0099999904632568\n",
      "step = 150: loss = 1.2699999809265137\n",
      "step = 160: loss = 1.399999976158142\n",
      "step = 170: loss = 1.4500000476837158\n",
      "step = 180: loss = 1.309999942779541\n",
      "step = 190: loss = 1.2699999809265137\n",
      "step = 200: loss = 1.4800000190734863\n",
      "step = 210: loss = 1.340000033378601\n",
      "step = 220: loss = 1.159999966621399\n",
      "step = 230: loss = 0.9900000095367432\n",
      "step = 240: loss = 1.090000033378601\n",
      "runtime_mins: 1\n",
      "saved trained policy to: gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-125815/artifacts\n",
      "complete train job in 1 minutes\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    f\"{LOG_DIR}/train\", flush_millis=10 * 1000\n",
    ")\n",
    "\n",
    "#start the timer and training\n",
    "start_time = time.time()\n",
    "\n",
    "metric_results, agent = train_perarm.train_perarm(\n",
    "    agent = agent,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    num_iterations = TRAINING_LOOPS,\n",
    "    steps_per_loop = STEPS_PER_LOOP,\n",
    "    num_eval_steps = NUM_EVAL_STEPS,\n",
    "    # data\n",
    "    batch_size = HPARAMS['batch_size'],\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    # functions\n",
    "    _trajectory_fn = _trajectory_fn,\n",
    "    # _run_bandit_eval_fn = _run_bandit_eval,\n",
    "    # train intervals\n",
    "    chkpt_interval = CHKPT_INTERVAL,\n",
    "    log_interval = LOG_INTERVAL,\n",
    "    # dirs\n",
    "    bucket_name = BUCKET_NAME,\n",
    "    data_dir_prefix_path = DATA_GCS_PREFIX,\n",
    "    log_dir = LOG_DIR,\n",
    "    model_dir = ARTIFACTS_DIR,\n",
    "    root_dir = ROOT_DIR,\n",
    "    async_steps_per_loop = ASYNC_STEPS_PER_LOOP,\n",
    "    resume_training_loops = False,\n",
    "    use_gpu = True,\n",
    "    use_tpu = False,\n",
    "    profiler = False,\n",
    "    global_step = global_step,\n",
    "    total_train_take = TOTAL_TRAIN_TAKE,\n",
    "    train_summary_writer = train_summary_writer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"complete train job in {runtime_mins} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "177aa3ab-05b4-48f9-b434-9335bd9eb54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3170915"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(metric_results)\n",
    "metric_results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ba65417f-54e0-436e-b0d4-93cffb981ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(metric_results)\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7ba747-00d5-4908-8d0b-334ae9d2c791",
   "metadata": {},
   "source": [
    "#### eval trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c5cf9366-d9cd-4c9d-951a-99a50877a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af82506e-95d7-4a4e-a821-e08512615db7",
   "metadata": {},
   "source": [
    "After training, our `agent.policy` is used as the deployment \"model\" that will generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6c82396a-7822-41fb-830f-1f6eb9c9b213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.epsilon_greedy_policy.EpsilonGreedyPolicy at 0x7fa249118f40>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_agent = agent.policy\n",
    "deployment_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f6706224-ef5b-4185-bde4-bccb7c8e7ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating trained Agent...\n",
      "post-train val_loss     : 1.5708459615707397\n",
      "post-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(deployment_agent, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = post_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f899120f-3706-4b72-8f2c-2169221dd66b",
   "metadata": {},
   "source": [
    "## Using Trained Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b0f691-860e-4853-928e-4c7ece714dd0",
   "metadata": {},
   "source": [
    "### load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ea029f73-0638-462a-8f00-54b05c54d69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-125815/artifacts\n"
     ]
    }
   ],
   "source": [
    "POLICY_URI = ARTIFACTS_DIR\n",
    "\n",
    "print(POLICY_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "66d1d819-0152-437c-aefc-45ffd34d808a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-125815/artifacts/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-125815/artifacts/fingerprint.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-125815/artifacts/policy_specs.pbtxt\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-125815/artifacts/saved_model.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-125815/artifacts/assets/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-125815/artifacts/variables/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $POLICY_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6aad948e-e346-4da3-8cb2-747435c8dc4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7fa250123e20>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "483f8fa5-cbd1-4e3c-8e62-47f91f42e137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(), dtype=dtype('int32'), name='action_spec', minimum=0, maximum=1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_policy.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8f658891-bc09-49b8-bc58-000a7926df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "SKIP_NUM = 11\n",
    "\n",
    "for x in eval_ds.skip(SKIP_NUM).take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    \n",
    "    # global_feat_infer = _get_global_context_features(x)\n",
    "    # arm_feat_infer = _get_per_arm_features(x)\n",
    "    \n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "    \n",
    "    # rewards = _get_rewards(x)\n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f515fcd0-2228-4f68-9ef9-665ce1fc3fb2",
   "metadata": {},
   "source": [
    "### view prediction response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6af4c297-d2e8-4f7b-bed5-e1da997dfe34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.6190686, 3.5386474], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([ 0.04723081, -0.00867967,  0.04708156, -0.03933126, -0.0163753 ,\n",
       "        0.03221614, -0.00812034,  0.03025604, -0.00139519, -0.01085867,\n",
       "       -0.04029781,  0.0091498 , -0.03974545,  0.02500229,  0.04061163,\n",
       "        0.02293222,  0.04802493,  0.02706862,  0.0281891 , -0.01032796,\n",
       "       -0.04305793, -0.02473137, -0.04823209,  0.00154727, -0.01362272,\n",
       "       -0.04433399,  0.03943019,  0.02756845,  0.04255528,  0.02866485,\n",
       "        0.02758962, -0.01789205, -0.03551181, -0.04373939, -0.03780063,\n",
       "       -0.01569076,  0.03239497, -0.04540162, -0.04852632, -0.04640068,\n",
       "        0.01821334,  0.04800499,  0.02693653, -0.0252457 , -0.0466018 ,\n",
       "       -0.01528662, -0.03378588, -0.0479337 ,  0.02295439,  0.02298584,\n",
       "       -0.00286614,  0.03048781,  0.04000706,  0.0086909 ,  0.03541512,\n",
       "       -0.02764381, -0.04142791,  0.02987594,  0.03857592,  0.00146597,\n",
       "        0.00950818, -0.0389257 ,  0.03083934,  0.00741061], dtype=float32)))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd58d4b-6749-4177-8342-83ee969408c9",
   "metadata": {},
   "source": [
    "#### chosen action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d49adbbb-f747-4e4c-b82d-df88373c644f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0, dtype=int32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd12013-1d12-4197-8254-cef9138df42c",
   "metadata": {},
   "source": [
    "#### Per Arm Policy Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d6126290-546b-4702-8a1e-91f18adb05c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.6190686, 3.5386474], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([ 0.04723081, -0.00867967,  0.04708156, -0.03933126, -0.0163753 ,\n",
       "        0.03221614, -0.00812034,  0.03025604, -0.00139519, -0.01085867,\n",
       "       -0.04029781,  0.0091498 , -0.03974545,  0.02500229,  0.04061163,\n",
       "        0.02293222,  0.04802493,  0.02706862,  0.0281891 , -0.01032796,\n",
       "       -0.04305793, -0.02473137, -0.04823209,  0.00154727, -0.01362272,\n",
       "       -0.04433399,  0.03943019,  0.02756845,  0.04255528,  0.02866485,\n",
       "        0.02758962, -0.01789205, -0.03551181, -0.04373939, -0.03780063,\n",
       "       -0.01569076,  0.03239497, -0.04540162, -0.04852632, -0.04640068,\n",
       "        0.01821334,  0.04800499,  0.02693653, -0.0252457 , -0.0466018 ,\n",
       "       -0.01528662, -0.03378588, -0.0479337 ,  0.02295439,  0.02298584,\n",
       "       -0.00286614,  0.03048781,  0.04000706,  0.0086909 ,  0.03541512,\n",
       "       -0.02764381, -0.04142791,  0.02987594,  0.03857592,  0.00146597,\n",
       "        0.00950818, -0.0389257 ,  0.03083934,  0.00741061], dtype=float32))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f66961-ebb5-4ae5-8e6f-ad73114d8353",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
