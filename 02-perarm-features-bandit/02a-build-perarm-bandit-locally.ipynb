{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385307d6-2058-47ec-8da0-57f7ef5c43d6",
   "metadata": {},
   "source": [
    "# Train Bandits with per-arm features\n",
    "\n",
    "**Exploring linear and nonlinear** (e.g., those with neural network-based value functions) bandit methods for recommendations using TF-Agents\n",
    "\n",
    "> Neural linear bandits provide a nice way to leverage the representation power of deep learning and the bandit approach for uncertainty measure and efficient exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fd257-b98b-426a-a2cd-024429b014f1",
   "metadata": {},
   "source": [
    "## Load notebook config\n",
    "\n",
    "* use the prefix defined in `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f39c9d08-d118-4013-a47f-88450f49f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = 'mabv1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908f6b95-b539-4a9f-a836-840d26ea3b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"mabv1\"\n",
      "VERSION                  = \"v1\"\n",
      "\n",
      "BUCKET_NAME              = \"mabv1-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://mabv1-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://mabv1-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_ID      = \"hybrid-vertex.movielens_dataset_mabv1\"\n",
      "BIGQUERY_TABLE_ID        = \"hybrid-vertex.movielens_dataset_mabv1.training_dataset\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-mabv1\"\n",
      "IMAGE_NAME               = \"train-perarm-feats-v1\"\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-mabv1/train-perarm-feats-v1\"\n",
      "DOCKERNAME               = \"Dockerfile_perarm_feats\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c690a9-e2bd-4759-ba41-4e2469098aee",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d0dfe4-695c-4dd4-9f24-67f7488ce1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c669f1a1-1af7-4efb-ab2d-6bf3b3847991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from collections import defaultdict\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pickle as pkl\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "# from tf_agents.agents import TFAgent\n",
    "\n",
    "# from tf_agents.bandits.environments import stationary_stochastic_per_arm_py_environment as p_a_env\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "# from tf_agents.drivers import dynamic_step_driver\n",
    "# from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "# from tf_agents.bandits.agents import lin_ucb_agent\n",
    "# from tf_agents.bandits.agents import linear_thompson_sampling_agent as lin_ts_agent\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent\n",
    "from tf_agents.bandits.agents import neural_linucb_agent\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "from tf_agents.bandits.policies import policy_utilities\n",
    "\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# this repo\n",
    "from src.per_arm_rl import data_utils\n",
    "from src.per_arm_rl import data_config\n",
    "from src.per_arm_rl import train_utils as train_utils\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29e58dd7-ab2b-419f-9771-bf1e98db758b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4969d3e-1fc0-45db-8a69-aa6b342019de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "274e7f4a-1802-4946-888e-876638f5c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a866b1-85b9-43e6-9546-edfbbf886bce",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd5b953-14c0-42ed-a511-77147a1bc0ac",
   "metadata": {},
   "source": [
    "### Read TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d0157c8-a04c-4dbd-b6d9-a1ede97687a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da0cdac-76af-4608-b70e-be7dbe0584b5",
   "metadata": {},
   "source": [
    "**Train data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c934c06-bf08-4c7f-b0cc-0de04ef3515c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://mabv1-hybrid-vertex-bucket/data/train/ml-ratings-100k-train.tfrecord']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPLIT = \"train\" # \"train\" | \"val\"\n",
    "\n",
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7511e4d-bf81-4800-bde7-8b16dec9aeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([35.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'898'], dtype=object)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([885409515])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'681'], dtype=object)>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'marketing'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "train_dataset = train_dataset.map(data_utils.parse_tfrecord)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452750c1-46a0-4ee1-84d4-0c3b227de38f",
   "metadata": {},
   "source": [
    "**Val data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7b5376f-9438-4304-84aa-de09c30f5e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = \"val\"\n",
    "\n",
    "val_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        val_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "val_dataset = tf.data.TFRecordDataset(val_files)\n",
    "val_dataset = val_dataset.map(data_utils.parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8959967-522e-41c8-9a1b-050ca8bc191f",
   "metadata": {},
   "source": [
    "### get vocab\n",
    "\n",
    "**TODO:** \n",
    "* streamline vocab calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b9169bc-d6dc-497e-9dff-6ebb175282ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE_VOCABS: False\n"
     ]
    }
   ],
   "source": [
    "GENERATE_VOCABS = False\n",
    "\n",
    "print(f\"GENERATE_VOCABS: {GENERATE_VOCABS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3ccf137-7a72-42e7-aa89-3c81a99cf40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab...\n",
      "Downloaded vocab from: gs://mabv1-hybrid-vertex-bucket/vocabs/vocab_dict.pkl\n",
      "\n",
      "'movie_id'\n",
      "'user_id'\n",
      "'user_occupation_text'\n",
      "'movie_genres'\n",
      "'bucketized_user_age'\n",
      "'max_timestamp'\n",
      "'min_timestamp'\n",
      "'timestamp_buckets'\n"
     ]
    }
   ],
   "source": [
    "if not GENERATE_VOCABS:\n",
    "\n",
    "    EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{VOCAB_SUBDIR}/{VOCAB_FILENAME}'\n",
    "    print(f\"Downloading vocab...\")\n",
    "    \n",
    "    os.system(f'gsutil -q cp {EXISTING_VOCAB_FILE} .')\n",
    "    print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "    filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "    vocab_dict = pkl.load(filehandler)\n",
    "    filehandler.close()\n",
    "    \n",
    "    for key in vocab_dict.keys():\n",
    "        pprint(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccaef62-882a-46ff-a1b1-3837e69fdf74",
   "metadata": {},
   "source": [
    "## helper functions\n",
    "\n",
    "**TODO:**\n",
    "* modularize in a train_utils or similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b941063b-ad48-4817-aef0-9afa8a444632",
   "metadata": {},
   "source": [
    "# Multi-Armed Bandits (MAB) with Per-Arm Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28770b8d-836b-448d-8dd1-203d76fc6d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "\n",
    "nest = tf.nest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138a295-2b0d-4359-8496-af8552ec8cff",
   "metadata": {},
   "source": [
    "# [1] Preprocessing layers for global and arm features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e28c002-8d3a-4cf4-b69b-de56a6abab90",
   "metadata": {},
   "source": [
    "The preproccesing layers will ultimately feed the two sampling functions described below. These sampling functions will be used to create [trajectories](https://github.com/tensorflow/agents/blob/master/tf_agents/trajectories/trajectory.py#L36) (i.e., the training examples for our model)\n",
    "\n",
    "`global_context_sampling_fn`: \n",
    "* A function that outputs a random 1d array or list of ints or floats\n",
    "* This output is the global context. Its shape and type must be consistent across calls.\n",
    "\n",
    "`arm_context_sampling_fn`: \n",
    "* A function that outputs a random 1 array or list of ints or floats (same type as the output of `global_context_sampling_fn`). * This output is the per-arm context. Its shape must be consistent across calls.\n",
    "\n",
    "See `debug-and-learn-emb-models.ipynb` for more details and debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ea1f7-0621-44b8-b062-1f59b0964d72",
   "metadata": {},
   "source": [
    "## Global & Per-Arm feature embedding models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8d77956-635c-438a-916a-185eec52f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OOV_BUCKETS        = 1\n",
    "GLOBAL_EMBEDDING_SIZE  = 16\n",
    "MV_EMBEDDING_SIZE      = 32 #32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea335991-dcec-40b3-ba0d-a0fdfb9c2ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test emb models\n",
    "for i in range(1):\n",
    "    \n",
    "    iterator = iter(train_dataset.batch(1))\n",
    "    data = next(iterator)\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48178fff-491f-4f03-b156-7765d1fa9707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.perarm_features.emb_features.EmbeddingModel at 0x7f99a0ad6050>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.perarm_features import emb_features as emb_features\n",
    "\n",
    "embs = emb_features.EmbeddingModel(\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "903c63c5-2468-4443-bcb8-5ff6d69810dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL_DIM: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.01362586, -0.04988756,  0.03048554,  0.04449072, -0.01136512,\n",
       "        -0.02239702,  0.00837423,  0.04680732,  0.03794596,  0.03344572,\n",
       "        -0.00116323,  0.01867263, -0.04601565,  0.0116892 ,  0.04361529,\n",
       "        -0.04165899, -0.01679122,  0.04923126,  0.02252525,  0.03148906,\n",
       "        -0.04847206,  0.03981299, -0.00233589, -0.02748783,  0.04909572,\n",
       "         0.03964679, -0.01373868, -0.04840099,  0.00493308,  0.04196289,\n",
       "         0.04107133,  0.03003153, -0.00576909, -0.01322661, -0.00053878,\n",
       "         0.03963916, -0.0345714 , -0.03214889, -0.01172547, -0.03761981,\n",
       "        -0.0136793 , -0.03116498, -0.01635205, -0.02373698,  0.04972466,\n",
       "        -0.03964754, -0.02963117, -0.02799257,  0.0012099 ,  0.02726069,\n",
       "        -0.02169406, -0.03501824,  0.01960224, -0.03049548, -0.01720958,\n",
       "         0.0300359 , -0.04914521,  0.02623589, -0.01773109, -0.02652361,\n",
       "        -0.02169201,  0.02833224, -0.04767934, -0.00536357]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_globals = embs._get_global_context_features(data)\n",
    "\n",
    "GLOBAL_DIM = test_globals.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"GLOBAL_DIM: {GLOBAL_DIM}\")\n",
    "\n",
    "test_globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebec4863-c614-4248-b680-8e29ec5b730d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER_ARM_DIM: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.0010171 , -0.00364555,  0.02840364, -0.03518631, -0.02084396,\n",
       "         0.03898186, -0.03518055,  0.03570561, -0.03826578,  0.00216038,\n",
       "         0.02932997, -0.04268716,  0.02205317,  0.01447716,  0.01202064,\n",
       "        -0.02222115, -0.04677717, -0.02149534,  0.03913459, -0.03937551,\n",
       "         0.01407114, -0.04517975,  0.02516757, -0.00247971,  0.04017961,\n",
       "         0.01340159,  0.01487417, -0.02480367, -0.01052805,  0.03124446,\n",
       "        -0.02619127, -0.01760169, -0.01599788,  0.01823736, -0.02997134,\n",
       "        -0.01893301,  0.01177077,  0.02342832,  0.02878157,  0.02146578,\n",
       "         0.00292154,  0.02080574, -0.04407905,  0.04468654, -0.02988057,\n",
       "         0.02450515, -0.0221763 , -0.03897078,  0.01386515, -0.03331778,\n",
       "        -0.02367387, -0.04894983, -0.04106905, -0.01283066, -0.01771212,\n",
       "         0.02127278,  0.01233027, -0.02528392,  0.03718239,  0.04796181,\n",
       "         0.02563049,  0.00052577, -0.00447654,  0.01834431]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arms = embs._get_per_arm_features(data)\n",
    "\n",
    "PER_ARM_DIM = test_arms.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"PER_ARM_DIM: {PER_ARM_DIM}\")\n",
    "\n",
    "test_arms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac6836c-67b7-4fd4-917a-24ddad708edd",
   "metadata": {},
   "source": [
    "# [2] Implementing MAB with TF-Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1877c79c-b6c8-4048-b1ce-05f011e8d69e",
   "metadata": {},
   "source": [
    "In TF-Agents, the *per-arm features* implementation differs from the *global-only* feature examples in the following aspects:\n",
    "* Reward is modeled not per-arm, but globally.\n",
    "* The arms are permutation invariant: it doesn’t matter which arm is arm 1 or arm 2, only their features.\n",
    "* One can have a different number of arms to choose from in every step (note that unspecified/dynamically changing number of arms will have a problem with XLA compatibility).\n",
    "\n",
    "When implementing per-arm features in TF-Bandits, the following details have to be discussed:\n",
    "* Observation spec and observations,\n",
    "* Action spec and actions,\n",
    "* Implementation of specific policies and agents.\n",
    "\n",
    "\n",
    "**TODO:**\n",
    "* outline the components and highlight their interactions, dependencies on eachother, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ff9baaf-987d-448d-a981-742a79b581e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE      : 128\n",
      "EVAL_BATCH_SIZE : 1\n",
      "NUM_ACTIONS     : 2\n",
      "GLOBAL_DIM      : 64\n",
      "PER_ARM_DIM     : 64\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE      = 128\n",
    "EVAL_BATCH_SIZE = 1\n",
    "\n",
    "NUM_ACTIONS     = 2 #this is kinda deceptive - \n",
    "#our approach is to learn by \"flashing\" one movie rating at a time per user context. \n",
    "#The n_actions = show/don't show the movie with one degree of freedom (n-1)\n",
    "\n",
    "\n",
    "print(f\"BATCH_SIZE      : {BATCH_SIZE}\")\n",
    "print(f\"EVAL_BATCH_SIZE : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"NUM_ACTIONS     : {NUM_ACTIONS}\")\n",
    "print(f\"GLOBAL_DIM      : {GLOBAL_DIM}\")\n",
    "print(f\"PER_ARM_DIM     : {PER_ARM_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeb4902-5bb9-4587-8d29-c01d78b006be",
   "metadata": {},
   "source": [
    "## Tensor Specs\n",
    "\n",
    "* say you have a global observation spec of `[17]`. And you have two batch dimensions `[4, 5]`. Then your observation has to have the shape `[4, 5, 17]`\n",
    "* and then if you have arm_obs_spec with shape `[9, 13]`, then the arm obs shape has to be exactly `[4, 5, 9, 13]`\n",
    "* and this has to be true for every single tensor in your tensor nest\n",
    "* the first 2 dims are the outer dims that are the same for all tensors, the rest of the dimensions have to follow the spec for each tensor\n",
    "\n",
    "**TODO:**\n",
    "* explain relationship between Tensor Specs and their Tensor counterparts\n",
    "* highlight the errors, lessons learned, and utility functions to address these"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f68ebe8-116d-43b3-a6e1-4f5a5c7f4741",
   "metadata": {},
   "source": [
    "### Observation spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9c4746-d01b-4ca4-aa53-ab68da54d37a",
   "metadata": {},
   "source": [
    "**This observation spec allows the user to have a global observation of fixed dimension**, and an unspecified number of *per-arm* features (also of fixed dimension)\n",
    "* The actions output by the policy are still integers as usual, and they indicate which row of the arm-features it has chosen \n",
    "* The action spec must be a single integer value without boundaries:\n",
    "\n",
    "```python\n",
    "global_spec = tensor_spec.TensorSpec([GLOBAL_DIM], tf.float32)\n",
    "per_arm_spec = tensor_spec.TensorSpec([None, PER_ARM_DIM], tf.float32)\n",
    "observation_spec = {'global': global_spec, 'per_arm': per_arm_spec}\n",
    "\n",
    "action_spec = tensor_spec.TensorSpec((), tf.int32)\n",
    "```\n",
    "> Here the only difference compared to the action spec with global features only is that the tensor spec is not bounded, as we don’t know how many arms there will be at any time step\n",
    "\n",
    "**XLA compatibility:**\n",
    "* Since dynamic tensor shapes are not compatible with XLA, the number of arm features (and consequently, number of arms for a step) cannot be dynamic. \n",
    "* One workaround is to fix the maximum number of arms for a problem, then pad the arm features in steps with fewer arms, and use action masking to indicate how many arms are actually active.\n",
    "\n",
    "```python\n",
    "per_arm_spec = tensor_spec.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32)\n",
    "\n",
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=(), dtype=tf.int32, minimum = 0, maximum = NUM_ACTIONS - 1\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36bd3b33-635a-4274-8b9e-7172696ebb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_spec = {\n",
    "    'global': tf.TensorSpec([GLOBAL_DIM], tf.float32),\n",
    "    'per_arm': tf.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32) #excluding action dim here\n",
    "}\n",
    "observation_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a2da92-7db2-4f42-94a7-b7bad1c8fc42",
   "metadata": {},
   "source": [
    "### Action spec\n",
    "\n",
    "> The time_step_spec and action_spec are specifications for the input time step and the output action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5af42c7-18d7-480f-a7f3-d7da3f4840eb",
   "metadata": {},
   "source": [
    "```python\n",
    "    if (\n",
    "        not tensor_spec.is_bounded(action_spec)\n",
    "        or not tensor_spec.is_discrete(action_spec)\n",
    "        or action_spec.shape.rank > 1\n",
    "        or action_spec.shape.num_elements() != 1\n",
    "    ):\n",
    "      raise NotImplementedError(\n",
    "          'action_spec must be a BoundedTensorSpec of type int32 and shape (). '\n",
    "          'Found {}.'.format(action_spec)\n",
    "      )\n",
    "```\n",
    "\n",
    "* [src](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_base_policy.py#L97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "549a123c-349a-4103-b39a-4502f47d1e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=[], \n",
    "    dtype=tf.int32,\n",
    "    minimum=tf.constant(0),            \n",
    "    maximum=NUM_ACTIONS-1, # n degrees of freedom and will dictate the expected mean reward spec shape\n",
    "    name=\"action_spec\"\n",
    ")\n",
    "\n",
    "action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36ee2635-d4e3-4468-886c-ae9c62e3c80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_num_actions: 2\n",
      "predicted_rewards_mean: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n"
     ]
    }
   ],
   "source": [
    "expected_num_actions = action_spec.maximum - action_spec.minimum + 1\n",
    "print(f\"expected_num_actions: {expected_num_actions}\")\n",
    "\n",
    "predicted_rewards_mean = tensor_spec.TensorSpec([expected_num_actions])\n",
    "print(f\"predicted_rewards_mean: {predicted_rewards_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a51efce-9f1b-42d1-bec4-7b788e3fd7e0",
   "metadata": {},
   "source": [
    "### TimeStep spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95f05860-0fbf-4a5a-8273-9c81761e0ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec = ts.time_step_spec(\n",
    "    observation_spec = observation_spec, \n",
    "    # reward_spec = _reward_spec\n",
    ")\n",
    "time_step_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9181303-6565-45f5-a293-08d50420a805",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Inspect chosen arm features spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6b526a5-997c-4621-b21c-82c6ca1d6a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90d3e03e-619e-4fa4-b817-f02b4cefd6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(64,), dtype=tf.float32, name=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_arm_features_info = (\n",
    "  policy_utilities.create_chosen_arm_features_info_spec(\n",
    "      time_step_spec.observation,\n",
    "  )\n",
    ")\n",
    "chosen_arm_features_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc427092-beb7-4baf-a2e9-b8d10629182c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - dont understand this\n",
    "bandit_policy_type = (\n",
    "    policy_utilities.BanditPolicyType.GREEDY\n",
    ")\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a4a2a33-c7d4-4d81-8082-80dfc3596741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - dont understand this\n",
    "bandit_policy_type = (\n",
    "    policy_utilities.create_bandit_policy_type_tensor_spec(shape=[1])\n",
    ")\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e7ac02b-18bd-4519-92fe-5541b1a8ddc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_spec = policy_utilities.PerArmPolicyInfo(\n",
    "  predicted_rewards_mean=predicted_rewards_mean,\n",
    "  bandit_policy_type=bandit_policy_type,\n",
    "  chosen_arm_features=chosen_arm_features_info,\n",
    ")\n",
    "info_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9c197-ae9b-461d-8956-f078b929ac12",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The Agent\n",
    "\n",
    "**Note** that contextual bandits form a special case of RL, where the actions taken by the agent do not alter the state of the environment \n",
    "\n",
    "> “Contextual” refers to the fact that the agent chooses among a set of actions while having knowledge of the context (environment observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81d6e84-688e-48c5-aea1-77df031348c9",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Agent & Network defined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aadb01-eb5c-4870-ae14-9e66624ba594",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Agent types**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d075e8a6-11a9-4346-8725-3653fba4bac4",
   "metadata": {},
   "source": [
    "> `AGENT_TYPE = ['LinUCB', 'LinTS', 'epsGreedy', 'NeuralLinUCB']`\n",
    "\n",
    "LinearUCBAgent: (`LinUCB`) \n",
    "* An agent implementing the Linear UCB bandit algorithm ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/lin_ucb_agent/LinearUCBAgent))\n",
    "\n",
    "LinearThompsonSamplingAgent: (`LinTS`) \n",
    "* Implements the Linear Thompson Sampling Agent from the [paper](https://arxiv.org/abs/1209.3352): *Thompson Sampling for Contextual Bandits with Linear Payoffs* ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/linear_thompson_sampling_agent/LinearThompsonSamplingAgent))\n",
    "\n",
    "NeuralEpsilonGreedyAgent: (`epsGreedy`) \n",
    "* A neural network based epsilon greedy agent ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_epsilon_greedy_agent/NeuralEpsilonGreedyAgent))\n",
    "\n",
    "NeuralLinUCBAgent: (`NeuralLinUCB`) \n",
    "* An agent implementing the LinUCB algorithm on top of a neural network ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_linucb_agent/NeuralLinUCBAgent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b8e88e-c8ea-4193-a911-0d974ef3b1a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Network types**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f547087d-5fad-4521-a584-cb46ce52897d",
   "metadata": {},
   "source": [
    "Which network architecture to use for the `epsGreedy` or `NeuralLinUCB` agents\n",
    "\n",
    "```\n",
    "NETWORK_TYPE = ['commontower', 'dotproduct']\n",
    "```\n",
    "\n",
    "**GlobalAndArmCommonTowerNetwork:** (`commontower`)\n",
    "* This network takes the output of the global and per-arm networks, and leads them through a common network, that in turn outputs reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "> * `COMMON_LAYERS` - Iterable of ints. Specifies the layers of the common tower\n",
    "* The network produced by this function can be used either in `GreedyRewardPredictionPolicy`, or `NeuralLinUCBPolicy`\n",
    "> * In the former case, the network must have `output_dim=1`, it is going to be an instance of `QNetwork`, and used in the policy as a reward prediction network\n",
    "> * In the latter case, the network will be an encoding network with its output consumed by a reward layer or a `LinUCB` method. The specified `output_dim` will be the encoding dimension\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmCommonTowerNetwork)\n",
    "\n",
    "**GlobalAndArmDotProductNetwork:** (`dotproduct`)\n",
    "* This network calculates the **dot product** of the output of the global and per-arm networks and returns them as reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmDotProductNetwork)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3dc270-deb5-4e96-8276-74759a06c318",
   "metadata": {},
   "source": [
    "### Agent config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bbe29263-453d-405e-ac50-fee7f379f335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\n",
      "\n",
      "time_step_spec:  TimeStep(\n",
      "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
      "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n",
      "\n",
      "action_spec:  BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))\n",
      "\n",
      "observation_spec:  {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\")\n",
    "print(\"\\ntime_step_spec: \", time_step_spec)\n",
    "print(\"\\naction_spec: \", action_spec)\n",
    "print(\"\\nobservation_spec: \", observation_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d817bf2-1fa6-4bae-af90-745fad996b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'common_layers': [16, 8],\n",
      " 'epsilon': 0.01,\n",
      " 'eval_batch_size': 1,\n",
      " 'global_layers': [64, 32, 16],\n",
      " 'learning_rate': 0.05,\n",
      " 'model_type': 'epsGreedy',\n",
      " 'network_type': 'commontower',\n",
      " 'num_actions': 2,\n",
      " 'per_arm_layers': [64, 32, 16]}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Agents\n",
    "# ================================\n",
    "AGENT_TYPE      = 'epsGreedy' # 'LinUCB' | 'LinTS |, 'epsGreedy' | 'NeuralLinUCB'\n",
    "\n",
    "# Parameters for linear agents (LinUCB and LinTS).\n",
    "AGENT_ALPHA     = 0.1\n",
    "\n",
    "# Parameters for neural agents (NeuralEpsGreedy and NerualLinUCB).\n",
    "EPSILON         = 0.01\n",
    "LR              = 0.05\n",
    "\n",
    "# Parameters for NeuralLinUCB\n",
    "ENCODING_DIM    = 1\n",
    "EPS_PHASE_STEPS = 1000\n",
    "\n",
    "# ================================\n",
    "# Agent's Preprocess Network\n",
    "# ================================\n",
    "NETWORK_TYPE    = \"commontower\" # 'commontower' | 'dotproduct'\n",
    "\n",
    "if AGENT_TYPE == 'NeuralLinUCB':\n",
    "    NETWORK_TYPE = 'commontower'\n",
    "    \n",
    "GLOBAL_LAYERS   = [64, 32, 16]\n",
    "ARM_LAYERS      = [64, 32, 16]\n",
    "COMMON_LAYERS   = [16, 8]\n",
    "\n",
    "HPARAMS = {  # TODO - streamline and consolidate\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"eval_batch_size\" : EVAL_BATCH_SIZE,\n",
    "    \"num_actions\": NUM_ACTIONS,\n",
    "    \"model_type\": AGENT_TYPE,\n",
    "    \"network_type\": NETWORK_TYPE,\n",
    "    \"global_layers\": GLOBAL_LAYERS,\n",
    "    \"per_arm_layers\": ARM_LAYERS,\n",
    "    \"common_layers\": COMMON_LAYERS,\n",
    "    \"learning_rate\": LR,\n",
    "    \"epsilon\": EPSILON,\n",
    "}\n",
    "pprint(HPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2bf060bb-9880-40b4-8583-dd7a3f915bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent: NeuralEpsGreedyAgent\n",
      "Network: commontower\n"
     ]
    }
   ],
   "source": [
    "from src.perarm_features import agent_factory as agent_factory\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "    agent_type = AGENT_TYPE,\n",
    "    network_type = NETWORK_TYPE,\n",
    "    time_step_spec = time_step_spec,\n",
    "    action_spec = action_spec,\n",
    "    observation_spec=observation_spec,\n",
    "    global_layers = GLOBAL_LAYERS,\n",
    "    arm_layers = ARM_LAYERS,\n",
    "    common_layers = COMMON_LAYERS,\n",
    "    agent_alpha = AGENT_ALPHA,\n",
    "    learning_rate = LR,\n",
    "    epsilon = EPSILON,\n",
    "    train_step_counter = global_step,\n",
    "    output_dim = ENCODING_DIM,\n",
    "    eps_phase_steps = EPS_PHASE_STEPS,\n",
    ")\n",
    "      \n",
    "agent.initialize()\n",
    "print(f'agent: {agent.name}')\n",
    "\n",
    "# if network:\n",
    "#     print(f\"Network: {network}\")\n",
    "\n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {NETWORK_TYPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d77d1-a0b3-4898-adf0-0b32bfaf5bd7",
   "metadata": {},
   "source": [
    "#### tmp - debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78ca56e7-a386-4bf4-8c2b-3d1665521f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41483f5a-bda6-48a4-9e1c-88d8b4afeea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.time_step_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f205716-f265-4ca8-81a7-4799de8f60a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(Trajectory(\n",
       "{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32)),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None)}),\n",
       " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None)),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.training_data_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d404dae-3cc3-4f81-962b-4641455ca4f2",
   "metadata": {},
   "source": [
    "## Reward function\n",
    "\n",
    "> see `reward_factory.py`\n",
    "\n",
    "**TODO:**\n",
    "* explain how to translate reward to this common recommendation objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df9aecd6-d20a-48a7-9ead-4da3bbcfdae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _get_rewards(element):\n",
    "#     \"\"\"Calculates reward for the actions.\"\"\"\n",
    "\n",
    "#     def _calc_reward(x):\n",
    "#         \"\"\"Calculates reward for a single action.\"\"\"\n",
    "#         r0 = lambda: tf.constant(0.0)\n",
    "#         r1 = lambda: tf.constant(1.0)\n",
    "#         r2 = lambda: tf.constant(2.0)\n",
    "#         r3 = lambda: tf.constant(3.0)\n",
    "#         r4 = lambda: tf.constant(4.0)\n",
    "#         r5 = lambda: tf.constant(5.0)\n",
    "#         c1 = tf.equal(x, 1.0)\n",
    "#         c2 = tf.equal(x, 2.0)\n",
    "#         c3 = tf.equal(x, 3.0)\n",
    "#         c4 = tf.equal(x, 4.0)\n",
    "#         c5 = tf.equal(x, 5.0)\n",
    "#         return tf.case(\n",
    "#             [(c1, r1), (c2, r2), (c3, r3),(c4, r4),(c5, r5)], \n",
    "#             default=r0, exclusive=True\n",
    "#         )\n",
    "\n",
    "#     return tf.map_fn(\n",
    "#         fn=_calc_reward, \n",
    "#         elems=element['user_rating'], \n",
    "#         dtype=tf.float32\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac59703a-9a00-4eba-a3b7-45b21b738dd4",
   "metadata": {},
   "source": [
    "## Trajectory function\n",
    "\n",
    "**parking lot**\n",
    "* does trajectory fn need concept of `dummy_chosen_arm_features`, similar to [this](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_base_policy.py#L297)\n",
    "\n",
    "```python\n",
    "      dummy_chosen_arm_features = tf.nest.map_structure(\n",
    "          lambda obs: tf.zeros_like(obs[:, 0, ...]),\n",
    "          time_step.observation[bandit_spec_utils.PER_ARM_FEATURE_KEY],\n",
    "      )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3c16aa7b-f328-425e-b02e-a3fc7f200859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.perarm_features import reward_factory as reward_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f3605d9f-d239-4871-9a61-6e9b21f9c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _trajectory_fn(element): # hparams\n",
    "    \n",
    "    \"\"\"Converts a dataset element into a trajectory.\"\"\"\n",
    "    # global_features = _get_global_context_features(element)\n",
    "    # arm_features = _get_per_arm_features(element)\n",
    "    \n",
    "    global_features = embs._get_global_context_features(element)\n",
    "    arm_features = embs._get_per_arm_features(element)\n",
    "    \n",
    "    # Adds a time dimension.\n",
    "    arm_features = train_utils._add_outer_dimension(arm_features)\n",
    "\n",
    "    # obs spec\n",
    "    observation = {\n",
    "        bandit_spec_utils.GLOBAL_FEATURE_KEY:\n",
    "            train_utils._add_outer_dimension(global_features),\n",
    "    }\n",
    "\n",
    "    # reward = train_utils._add_outer_dimension(_get_rewards(element))\n",
    "    reward = train_utils._add_outer_dimension(reward_factory._get_rewards(element))\n",
    "\n",
    "    # To emit the predicted rewards in policy_info, we need to create dummy\n",
    "    # rewards to match the definition in TensorSpec for the ones specified in\n",
    "    # emit_policy_info set.\n",
    "    dummy_rewards = tf.zeros([HPARAMS['batch_size'], 1, HPARAMS['num_actions']])\n",
    "    policy_info = policy_utilities.PerArmPolicyInfo(\n",
    "        chosen_arm_features=arm_features,\n",
    "        # Pass dummy mean rewards here to match the model_spec for emitting\n",
    "        # mean rewards in policy info\n",
    "        predicted_rewards_mean=dummy_rewards,\n",
    "        bandit_policy_type=tf.zeros([HPARAMS['batch_size'], 1, 1], dtype=tf.int32)\n",
    "        # policy_utilities.create_bandit_policy_type_tensor_spec(shape=[1]) # policy_utilities.BanditPolicyType.GREEDY\n",
    "        # tf.zeros([batch_size, 1, 1], dtype=tf.int32)\n",
    "    )\n",
    "    \n",
    "    if HPARAMS['model_type'] == 'neural_ucb':\n",
    "        policy_info = policy_info._replace(\n",
    "            predicted_rewards_optimistic=dummy_rewards\n",
    "        )\n",
    "        \n",
    "    return trajectory.single_step(\n",
    "        observation=observation,\n",
    "        action=tf.zeros_like(\n",
    "            reward, dtype=tf.int32\n",
    "        ),  # Arm features are copied from policy info, put dummy zeros here\n",
    "        policy_info=policy_info,\n",
    "        reward=reward,\n",
    "        discount=tf.zeros_like(reward)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a0989c-5a06-4fd5-a12d-d92dbbe71a76",
   "metadata": {},
   "source": [
    "Inspect the trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "257791d1-c97c-48c0-bc92-f5a4737b6c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in train_dataset.batch(HPARAMS['batch_size']).take(1):\n",
    "    test_traj = _trajectory_fn(x)\n",
    "    \n",
    "# test_traj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d8994e-ce28-4fd9-8e3b-153451d014d9",
   "metadata": {},
   "source": [
    "#### tmp - debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a0e451f-1ad8-4af2-84d6-ddc5eaac0e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.action.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.action.shape: {test_traj.action.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "52ed1767-12ce-404c-9caf-0974d55ec5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.discount.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.discount.shape: {test_traj.discount.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "033ff16b-0158-477f-835f-99deec636b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.reward.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.reward.shape: {test_traj.reward.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee5aded7-7f9c-4a88-868c-f6ab58a0e704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.observation.shape: (128, 1, 64)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.observation.shape: {test_traj.observation['global'].shape}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcbfc9a-049e-49b9-b2a3-ecb9fd4b9964",
   "metadata": {},
   "source": [
    "# [3] Training the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13adc1ef-b50e-41a3-9b95-c128d0c55a2b",
   "metadata": {},
   "source": [
    "## set Vertex Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e861fb27-df24-4821-8448-cf1346b186f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : mab-local-classy-v3\n",
      "RUN_NAME          : run-20231004-134205\n",
      "\n",
      "BASE_OUTPUT_DIR   : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v3/run-20231004-134205\n",
      "LOG_DIR           : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v3/run-20231004-134205/logs\n",
      "ROOT_DIR          : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v3/run-20231004-134205/root\n",
      "ARTIFACTS_DIR     : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v3/run-20231004-134205/artifacts\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME   = f'mab-local-classy-v3'\n",
    "\n",
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b7a5e4-efff-490b-b431-53037a2f4a16",
   "metadata": {},
   "source": [
    "## eval loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba0392e-90c8-4dc8-8df2-6d2af1ade490",
   "metadata": {},
   "source": [
    "> When evaluating an epsilon-greedy bandit, we need to remove those predictions that come from the `uniform_random` policy. We only want the predictions from the `GREEDY` policy, becasue we want to know how the model performs when it is actually used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b3d3c-75f7-46f4-9a1b-6329e419b7f5",
   "metadata": {},
   "source": [
    "## train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97cfe7c3-4022-47a9-83c2-df0ad8a2abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.metrics import export_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.utils import common\n",
    "\n",
    "# from src.per_arm_rl import train_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bb7ffc-00df-4d46-857b-86c87b78f597",
   "metadata": {},
   "source": [
    "`agent.train(experience=...)`\n",
    "\n",
    "where `experience` is a batch of trajectories data in the form of a Trajectory. \n",
    "* The structure of experience must match that of `self.training_data_spec`. \n",
    "* All tensors in experience must be shaped [batch, time, ...] where time must be equal to self.train_step_length if that property is not None."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94d6d45-c71e-4fe4-9af8-af9a8bda4e4f",
   "metadata": {},
   "source": [
    "### logs & checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "049ee49b-3b1a-4b12-a360-15e759dff7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('metrics: [<tf_agents.metrics.tf_metrics.AverageReturnMetric object at '\n",
      " '0x7f99a085ad40>]')\n",
      "setting checkpoint_manager: gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v3/run-20231004-134205/root/chkpoint\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    f\"{LOG_DIR}/train\", flush_millis=10 * 1000\n",
    ")\n",
    "# train_summary_writer.set_as_default()\n",
    "\n",
    "# eval_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "#     f\"{LOG_DIR}/eval\", flush_millis=10 * 1000\n",
    "# )\n",
    "# ====================================================\n",
    "# metrics\n",
    "# ====================================================\n",
    "step_metric = tf_metrics.EnvironmentSteps()\n",
    "metrics = [\n",
    "    # tf_metrics.NumberOfEpisodes(),\n",
    "    # tf_metrics.AverageEpisodeLengthMetric(batch_size=HPARAMS['batch_size']),\n",
    "    tf_metrics.AverageReturnMetric(batch_size=HPARAMS['batch_size'])\n",
    "]\n",
    "\n",
    "pprint(f\"metrics: {metrics}\")\n",
    "\n",
    "# ====================================================\n",
    "# get checkpoint manager\n",
    "# ====================================================\n",
    "CHKPOINT_DIR = f\"{ROOT_DIR}/chkpoint\"\n",
    "print(f\"setting checkpoint_manager: {CHKPOINT_DIR}\")\n",
    "\n",
    "checkpoint_manager = train_utils.restore_and_get_checkpoint_manager(\n",
    "    root_dir=CHKPOINT_DIR, \n",
    "    agent=agent, \n",
    "    metrics=metrics, \n",
    "    step_metric=step_metric\n",
    ")\n",
    "# ====================================================\n",
    "# policy saver\n",
    "# ====================================================\n",
    "saver = policy_saver.PolicySaver(\n",
    "    agent.policy, \n",
    "    train_step=global_step\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83683f4b-8a1a-44b9-8d5f-7ee3304c794c",
   "metadata": {},
   "source": [
    "### config\n",
    "\n",
    "* calculate train & val dataset sizes\n",
    "* define logging and chkpt intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f9432613-6583-4828-8a2a-dd939adbc3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_DATA_SIZE : 80000\n",
      "NUM_TRAIN_STEPS : 150\n",
      "EVAL_DATA_SIZE : 1000\n",
      "NUM_EVAL_STEPS : 1000\n",
      "CHKPT_INTERVAL: 150\n",
      "LOG_INTERVAL : 10\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA_SIZE = 80000          # len(list(train_dataset))\n",
    "NUM_TRAIN_STEPS = 150            # TRAIN_DATA_SIZE // HPARAMS['batch_size']\n",
    "\n",
    "EVAL_DATA_SIZE  = 1000          # len(list(val_dataset))\n",
    "NUM_EVAL_STEPS  = 1000           # EVAL_DATA_SIZE // HPARAMS['eval_batch_size']\n",
    "\n",
    "CHKPT_INTERVAL  = NUM_TRAIN_STEPS # // 5\n",
    "LOG_INTERVAL    = 10\n",
    "# EVAL_INTERVAL = NUM_TRAIN_STEPS // 2\n",
    "\n",
    "print(f\"TRAIN_DATA_SIZE : {TRAIN_DATA_SIZE}\")\n",
    "print(f\"NUM_TRAIN_STEPS : {NUM_TRAIN_STEPS}\")\n",
    "print(f\"EVAL_DATA_SIZE : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS : {NUM_EVAL_STEPS}\")\n",
    "print(f\"CHKPT_INTERVAL: {CHKPT_INTERVAL}\")\n",
    "print(f\"LOG_INTERVAL : {LOG_INTERVAL}\")\n",
    "# print(f\"EVAL_INTERVAL : {EVAL_INTERVAL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "379ffc65-4eec-4af1-8fd4-912ef65a9808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec={'bucketized_user_age': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'movie_genres': TensorSpec(shape=(None, 1), dtype=tf.int64, name=None), 'movie_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'timestamp': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'user_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_occupation_text': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_rating': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data\n",
    "train_ds_iterator = iter(train_dataset.batch(HPARAMS['batch_size']).repeat())\n",
    "\n",
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS[\"eval_batch_size\"])\n",
    "\n",
    "if NUM_EVAL_STEPS > 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)\n",
    "\n",
    "# eval_ds = eval_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "eval_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e498d7e3-d166-4e1d-94a5-f721de58694a",
   "metadata": {},
   "source": [
    "### run train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5dd64d98-7d5b-4474-a567-b42426d630a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.perarm_features import eval_perarm as eval_perarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da4680f3-693b-4530-8e4d-88bc43036c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating pre-trained Agent...\n",
      "pre-train val_loss     : 15.352850914001465\n",
      "pre-train eval runtime : 0\n",
      "starting train loop...\n",
      "step = 0: train loss = 15.90999984741211\n",
      "step = 10: train loss = 1.2599999904632568\n",
      "step = 20: train loss = 1.4700000286102295\n",
      "step = 30: train loss = 1.2100000381469727\n",
      "step = 40: train loss = 0.9900000095367432\n",
      "step = 50: train loss = 1.2300000190734863\n",
      "step = 60: train loss = 1.4299999475479126\n",
      "step = 70: train loss = 1.4299999475479126\n",
      "step = 80: train loss = 1.2599999904632568\n",
      "step = 90: train loss = 1.2100000381469727\n",
      "step = 100: train loss = 1.309999942779541\n",
      "step = 110: train loss = 1.2200000286102295\n",
      "step = 120: train loss = 1.100000023841858\n",
      "step = 130: train loss = 0.949999988079071\n",
      "step = 140: train loss = 1.100000023841858\n",
      "train runtime_mins: 17\n",
      "saved trained policy to: gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v3/run-20231004-134205/artifacts\n",
      "evaluating trained Agent...\n",
      "post-train val_loss     : 1.4373482465744019\n",
      "post-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "# agent.train = common.function(agent.train)\n",
    "\n",
    "list_o_loss = []\n",
    "\n",
    "# ====================================================\n",
    "# Evaluate the agent's policy once before training\n",
    "# ====================================================\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "pre_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "\n",
    "print(f\"evaluating pre-trained Agent...\")\n",
    "start_time = time.time()\n",
    "\n",
    "pre_val_loss, pre_preds, pre_tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = pre_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"pre-train val_loss     : {pre_val_loss}\")\n",
    "print(f\"pre-train eval runtime : {runtime_mins}\")\n",
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "print(f\"starting train loop...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# for i in tqdm(range(NUM_TRAIN_STEPS)):\n",
    "for i in range(NUM_TRAIN_STEPS):\n",
    "    \n",
    "    with train_summary_writer.as_default():\n",
    "\n",
    "        data = next(train_ds_iterator)\n",
    "        trajectories = _trajectory_fn(data)\n",
    "\n",
    "        # All tensors in experience must be shaped [batch, time, ...] \n",
    "        step = agent.train_step_counter.numpy()\n",
    "        loss = agent.train(experience=trajectories)\n",
    "        list_o_loss.append(loss.loss.numpy())\n",
    "\n",
    "        train_utils._export_metrics_and_summaries(\n",
    "            step=i, \n",
    "            metrics=metrics\n",
    "        )\n",
    "\n",
    "        # print step loss\n",
    "        if step % LOG_INTERVAL == 0:\n",
    "            print(\n",
    "                'step = {0}: train loss = {1}'.format(\n",
    "                    step, round(loss.loss.numpy(), 2)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if i > 0 and i % CHKPT_INTERVAL == 0:\n",
    "            saver.save(os.path.join(CHKPOINT_DIR, 'policy_%d' % step_metric.result()))\n",
    "            print(f\"saved policy to: {CHKPOINT_DIR}\")\n",
    "   \n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"train runtime_mins: {runtime_mins}\")\n",
    "\n",
    "saver.save(ARTIFACTS_DIR)\n",
    "print(f\"saved trained policy to: {ARTIFACTS_DIR}\")\n",
    "\n",
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = post_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "17b2b0d2-9795-4367-b57b-c331e94d1000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4373482"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb1ed8-f67b-4e7b-9cbc-70edd50e49ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate train job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff31fe28-2f05-499f-b1cc-505f3c9074e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### train loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "41937f9a-6c28-48d2-bc7c-bfe4372c7cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_o_loss)\n",
    "# plt.ylim([0, 10])\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e947e1-67f4-4205-99af-6921c6e9c896",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TensorBoard\n",
    "\n",
    "<img src=\"imgs/getting_profiler.png\" \n",
    "     align=\"center\" \n",
    "     width=\"850\"\n",
    "     height=\"850\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e0f77a33-0962-4af0-af97-cf05f895cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5d0509cb-0777-4d35-86c6-28c8acbcc793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ff1848b4da93012e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ff1848b4da93012e\");\n",
       "          const url = new URL(\"/proxy/6007/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=$LOG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc40143-30b1-479f-b9b1-fa4c07b1690e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [4] Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6c94a0-122f-4ba6-acef-5653a3cc7850",
   "metadata": {
    "tags": []
   },
   "source": [
    "## load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b1c382b5-e2e0-45a2-9c5f-ef2c468d0f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v3/run-20231004-134205/artifacts\n"
     ]
    }
   ],
   "source": [
    "POLICY_URI = ARTIFACTS_DIR\n",
    "\n",
    "print(POLICY_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "68592d97-1272-4c6d-a4bd-43a6f7fe6c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f98a84c0d90>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910a06f-678f-4bfa-a132-10b885f871c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## get predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1762c936-3c49-4ec5-a9eb-4df5816dc888",
   "metadata": {},
   "source": [
    "TODO - explain bandit_policy_type()\n",
    "\n",
    "**UNIFORM Random policy:**\n",
    "```\n",
    "PolicyStep(action=array(1, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.637535 , 3.5557823], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([2], dtype=int32), chosen_arm_features=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)))\n",
    "```\n",
    "\n",
    "**GREEDY policy:**\n",
    "```\n",
    "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.8278818, 3.607565 ], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([ 0.04054676, -0.04735027,  0.02202327,  0.01276748, -0.01367382,\n",
    "       -0.04838754,  0.00104916, -0.01956806,  0.01028793, -0.00256665,\n",
    "       -0.04376553,  0.03900594,  0.02388967, -0.04016995, -0.04945569,\n",
    "       -0.04539652,  0.04423274, -0.04630332,  0.00390794,  0.03986299,\n",
    "       -0.0398974 ,  0.01655747, -0.0471294 , -0.00690235, -0.03643382,\n",
    "       -0.0437116 ,  0.04757959, -0.00991895,  0.0281055 , -0.04633433,\n",
    "        0.01897702, -0.00824345,  0.03232259, -0.04980658, -0.01144745,\n",
    "        0.01690939,  0.02536928,  0.03384003, -0.01558131,  0.04731432,\n",
    "        0.04579857, -0.03305101,  0.03521084, -0.03915765,  0.04927064,\n",
    "        0.04695194,  0.03792156,  0.040496  ,  0.02574866, -0.00665367,\n",
    "       -0.03839222, -0.01564004, -0.04710373,  0.03557512, -0.01392462,\n",
    "        0.01368621,  0.02792176, -0.01799218,  0.00246101,  0.02263175,\n",
    "        0.0170817 ,  0.01388383, -0.03048695,  0.01198485], dtype=float32)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "567f64e1-8149-4364-b561-1a9d12581b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aff30396-e0fd-4f43-acaa-6af8b20b12cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "SKIP_NUM = 10\n",
    "\n",
    "for x in eval_ds.skip(SKIP_NUM).take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    \n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "    \n",
    "    # rewards = _get_rewards(x)\n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e58af9ab-f4da-4857-afe5-6b8de26ed0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.024242 , 2.9861035], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([-0.01145922,  0.0333499 ,  0.04194465,  0.02924841,  0.02588704,\n",
       "        0.03336335,  0.03431097,  0.02311618, -0.01911048,  0.02374114,\n",
       "        0.01993721,  0.02456112,  0.01447138, -0.03547608, -0.03032245,\n",
       "        0.04055632, -0.01400976,  0.04518226,  0.03919622, -0.04492862,\n",
       "        0.033303  , -0.04285715, -0.03196822,  0.02863313,  0.00180746,\n",
       "        0.04936427,  0.01765851,  0.01098241, -0.04361923, -0.01589984,\n",
       "       -0.02924265, -0.0204409 ,  0.02132807, -0.03403205, -0.0187389 ,\n",
       "       -0.02817856, -0.04206375,  0.04845062,  0.03963825, -0.0476598 ,\n",
       "       -0.02314571,  0.01317194, -0.03118326, -0.02247267,  0.00059943,\n",
       "        0.03812375,  0.01901485,  0.03982346,  0.00453164, -0.01962805,\n",
       "        0.00409115,  0.01750101,  0.03579167,  0.02195353,  0.02417346,\n",
       "        0.02960166, -0.032499  , -0.00091688, -0.04869967, -0.02424356,\n",
       "       -0.00491015, -0.02748919,  0.04173739,  0.02887059], dtype=float32)))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6676778c-d191-4b1e-a180-61f068b3b8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.024242 , 2.9861035], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([-0.01145922,  0.0333499 ,  0.04194465,  0.02924841,  0.02588704,\n",
      "        0.03336335,  0.03431097,  0.02311618, -0.01911048,  0.02374114,\n",
      "        0.01993721,  0.02456112,  0.01447138, -0.03547608, -0.03032245,\n",
      "        0.04055632, -0.01400976,  0.04518226,  0.03919622, -0.04492862,\n",
      "        0.033303  , -0.04285715, -0.03196822,  0.02863313,  0.00180746,\n",
      "        0.04936427,  0.01765851,  0.01098241, -0.04361923, -0.01589984,\n",
      "       -0.02924265, -0.0204409 ,  0.02132807, -0.03403205, -0.0187389 ,\n",
      "       -0.02817856, -0.04206375,  0.04845062,  0.03963825, -0.0476598 ,\n",
      "       -0.02314571,  0.01317194, -0.03118326, -0.02247267,  0.00059943,\n",
      "        0.03812375,  0.01901485,  0.03982346,  0.00453164, -0.01962805,\n",
      "        0.00409115,  0.01750101,  0.03579167,  0.02195353,  0.02417346,\n",
      "        0.02960166, -0.032499  , -0.00091688, -0.04869967, -0.02424356,\n",
      "       -0.00491015, -0.02748919,  0.04173739,  0.02887059], dtype=float32)))\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c85a0087-7388-4f03-9278-aace31121233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0, dtype=int32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a8266c7c-3688-46a5-a1c8-a63bb7146128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info.bandit_policy_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9712bc00-7ea0-4003-a3c7-81a0be5bc995",
   "metadata": {},
   "source": [
    "# [5] Prepare training application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f62966-123f-410e-9610-832f20566635",
   "metadata": {},
   "source": [
    "To scale this training in Vertex AI's managed training service, we need to package all our code into a python application\n",
    "\n",
    "* This means, we need to modularize all steps executed up until this point. For example, the training loop we ran above is further parameterized in `train_perarm.py`, which will be called from our `task.py` when we submit the job to Vertex AI\n",
    "* This training package will eventually be used to create a custom training image (more on that in `04b-build-training-image` notebook)\n",
    "* For additional details on preparing the training application for Vertex AI, check out [the documentation](https://cloud.google.com/vertex-ai/docs/training/code-requirements) and [this code example](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage2/get_started_vertex_training.ipynb) (which also has good, related commentary)\n",
    "\n",
    "**The remaining cells will repeat steps executed above**\n",
    "> we are just illustrating / validating that they are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1129ee41-b43c-4d5a-b656-cdac6b79688c",
   "metadata": {},
   "source": [
    "#### Vertex Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ef509680-4d19-4efa-9f01-21039e0d573b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : mab-local-classy-v3\n"
     ]
    }
   ],
   "source": [
    "# using same experiment name \n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7ad98430-d836-40f1-8e4f-eb46f0c91fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : mab-local-classy-v3\n",
      "RUN_NAME          : run-20231004-140538\n",
      "\n",
      "BASE_OUTPUT_DIR   : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v3/run-20231004-140538\n",
      "LOG_DIR           : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v3/run-20231004-140538/logs\n",
      "ROOT_DIR          : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v3/run-20231004-140538/root\n",
      "ARTIFACTS_DIR     : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v3/run-20231004-140538/artifacts\n"
     ]
    }
   ],
   "source": [
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fbdecf78-94c5-4f8c-a6c0-86f2eace4663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: NeuralEpsGreedyAgent\n",
      "Network: commontower\n"
     ]
    }
   ],
   "source": [
    "# from src.perarm_features import agent_factory as agent_factory\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "    agent_type = AGENT_TYPE,\n",
    "    network_type = NETWORK_TYPE,\n",
    "    time_step_spec = time_step_spec,\n",
    "    action_spec = action_spec,\n",
    "    observation_spec=observation_spec,\n",
    "    global_layers = GLOBAL_LAYERS,\n",
    "    arm_layers = ARM_LAYERS,\n",
    "    common_layers = COMMON_LAYERS,\n",
    "    agent_alpha = AGENT_ALPHA,\n",
    "    learning_rate = LR,\n",
    "    epsilon = EPSILON,\n",
    "    train_step_counter = global_step,\n",
    "    output_dim = ENCODING_DIM,\n",
    "    eps_phase_steps = EPS_PHASE_STEPS,\n",
    ")\n",
    "\n",
    "print(f\"Agent: {agent.name}\")\n",
    "\n",
    "# if network:\n",
    "#     print(f\"Network: {network}\")\n",
    "\n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {NETWORK_TYPE}\")\n",
    "        \n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "108ed33c-d8ef-4524-97e9-ced9e01c154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHKPT_INTERVAL    : 200\n",
      "eval_batch_size   : 1\n",
      "EVAL_DATA_SIZE    : 1000\n",
      "NUM_EVAL_STEPS    : 100\n",
      "TOTAL_TRAIN_TAKE  : 10000\n"
     ]
    }
   ],
   "source": [
    "from src.perarm_features import train_perarm as train_perarm\n",
    "\n",
    "# train args\n",
    "TRAINING_LOOPS        = 150\n",
    "STEPS_PER_LOOP        = 1\n",
    "\n",
    "drop_arm_feature_fn   = None\n",
    "ASYNC_STEPS_PER_LOOP  = 1\n",
    "\n",
    "LOG_INTERVAL          = 10\n",
    "CHKPT_INTERVAL        = 200\n",
    "\n",
    "# eval args\n",
    "NUM_EVAL_STEPS = 100\n",
    "\n",
    "TOTAL_TRAIN_TAKE = 10000 #TRAINING_LOOPS * HPARAMS['batch_size']\n",
    "\n",
    "print(f\"CHKPT_INTERVAL    : {CHKPT_INTERVAL}\")\n",
    "print(f\"eval_batch_size   : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"EVAL_DATA_SIZE    : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS    : {NUM_EVAL_STEPS}\")\n",
    "print(f\"TOTAL_TRAIN_TAKE  : {TOTAL_TRAIN_TAKE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f66ff927-9a39-4abf-b247-845f0dc7721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS['eval_batch_size'])\n",
    "\n",
    "if NUM_EVAL_STEPS >= 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f6c98398-d545-4dcc-a71f-32249b5f0336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distribution_strategy: <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f98a85f69b0>\n",
      "train_files: ['gs://mabv1-hybrid-vertex-bucket/data/train/ml-ratings-100k-train.tfrecord']\n",
      "train_ds_iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f97383d5a80>\n",
      "setting checkpoint_manager: gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v3/run-20231004-140538/root/chkpoint\n",
      "wrapping agent.train in tf-function\n",
      "starting_loop: 0\n",
      "starting train loop...\n",
      "step = 150: loss = 15.90999984741211\n",
      "step = 160: loss = 3.640000104904175\n",
      "step = 170: loss = 2.2899999618530273\n",
      "step = 180: loss = 1.2599999904632568\n",
      "step = 190: loss = 0.9599999785423279\n",
      "step = 200: loss = 1.2599999904632568\n",
      "step = 210: loss = 1.399999976158142\n",
      "step = 220: loss = 1.4600000381469727\n",
      "step = 230: loss = 1.2699999809265137\n",
      "step = 240: loss = 1.2999999523162842\n",
      "step = 250: loss = 1.4500000476837158\n",
      "step = 260: loss = 1.4199999570846558\n",
      "step = 270: loss = 1.2400000095367432\n",
      "step = 280: loss = 0.9200000166893005\n",
      "step = 290: loss = 1.2599999904632568\n",
      "runtime_mins: 16\n",
      "saved trained policy to: gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v3/run-20231004-140538/artifacts\n",
      "complete train job in 16 minutes\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    f\"{LOG_DIR}/train\", flush_millis=10 * 1000\n",
    ")\n",
    "\n",
    "#start the timer and training\n",
    "start_time = time.time()\n",
    "\n",
    "metric_results, agent = train_perarm.train_perarm(\n",
    "    agent = agent,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    num_iterations = TRAINING_LOOPS,\n",
    "    steps_per_loop = STEPS_PER_LOOP,\n",
    "    num_eval_steps = NUM_EVAL_STEPS,\n",
    "    # data\n",
    "    batch_size = HPARAMS['batch_size'],\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    # functions\n",
    "    _trajectory_fn = _trajectory_fn,\n",
    "    # _run_bandit_eval_fn = _run_bandit_eval,\n",
    "    # train intervals\n",
    "    chkpt_interval = CHKPT_INTERVAL,\n",
    "    log_interval = LOG_INTERVAL,\n",
    "    # dirs\n",
    "    bucket_name = BUCKET_NAME,\n",
    "    data_dir_prefix_path = DATA_GCS_PREFIX,\n",
    "    log_dir = LOG_DIR,\n",
    "    model_dir = ARTIFACTS_DIR,\n",
    "    root_dir = ROOT_DIR,\n",
    "    async_steps_per_loop = ASYNC_STEPS_PER_LOOP,\n",
    "    resume_training_loops = False,\n",
    "    use_gpu = True,\n",
    "    use_tpu = False,\n",
    "    profiler = False,\n",
    "    global_step = global_step,\n",
    "    total_train_take = TOTAL_TRAIN_TAKE,\n",
    "    train_summary_writer = train_summary_writer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"complete train job in {runtime_mins} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "177aa3ab-05b4-48f9-b434-9335bd9eb54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3580482"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(metric_results)\n",
    "metric_results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba65417f-54e0-436e-b0d4-93cffb981ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(metric_results)\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7ba747-00d5-4908-8d0b-334ae9d2c791",
   "metadata": {},
   "source": [
    "#### eval trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c5cf9366-d9cd-4c9d-951a-99a50877a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af82506e-95d7-4a4e-a821-e08512615db7",
   "metadata": {},
   "source": [
    "After training, our `agent.policy` is used as the deployment \"model\" that will generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6c82396a-7822-41fb-830f-1f6eb9c9b213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.epsilon_greedy_policy.EpsilonGreedyPolicy at 0x7f7af83b81c0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_agent = agent.policy\n",
    "deployment_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f6706224-ef5b-4185-bde4-bccb7c8e7ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating trained Agent...\n",
      "post-train val_loss     : 1.5412297248840332\n",
      "post-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(deployment_agent, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = post_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f899120f-3706-4b72-8f2c-2169221dd66b",
   "metadata": {},
   "source": [
    "## Using Trained Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b0f691-860e-4853-928e-4c7ece714dd0",
   "metadata": {},
   "source": [
    "### load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ea029f73-0638-462a-8f00-54b05c54d69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230830-201328/artifacts\n"
     ]
    }
   ],
   "source": [
    "POLICY_URI = ARTIFACTS_DIR\n",
    "\n",
    "print(POLICY_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "66d1d819-0152-437c-aefc-45ffd34d808a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230830-201328/artifacts/\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230830-201328/artifacts/fingerprint.pb\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230830-201328/artifacts/policy_specs.pbtxt\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230830-201328/artifacts/saved_model.pb\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230830-201328/artifacts/assets/\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230830-201328/artifacts/variables/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $POLICY_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6aad948e-e346-4da3-8cb2-747435c8dc4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f7a3df60d30>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "483f8fa5-cbd1-4e3c-8e62-47f91f42e137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(), dtype=dtype('int32'), name='action_spec', minimum=0, maximum=1)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_policy.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8f658891-bc09-49b8-bc58-000a7926df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "SKIP_NUM = 10\n",
    "\n",
    "for x in eval_ds.skip(SKIP_NUM).take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    \n",
    "    # global_feat_infer = _get_global_context_features(x)\n",
    "    # arm_feat_infer = _get_per_arm_features(x)\n",
    "    \n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "    \n",
    "    # rewards = _get_rewards(x)\n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f515fcd0-2228-4f68-9ef9-665ce1fc3fb2",
   "metadata": {},
   "source": [
    "### view prediction response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6af4c297-d2e8-4f7b-bed5-e1da997dfe34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.419865, 3.419865], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([ 0.01546537,  0.02517445,  0.04813281,  0.04863187, -0.01263794,\n",
       "       -0.04036776, -0.02560099, -0.04624224, -0.02573046, -0.02562919,\n",
       "       -0.03024311,  0.01836432, -0.03906032,  0.01016109, -0.04428653,\n",
       "       -0.03649165, -0.03648589,  0.02401939,  0.00510664,  0.04678353,\n",
       "        0.03368597,  0.03238941, -0.02772726,  0.04693978,  0.02093353,\n",
       "       -0.00620302,  0.00255311, -0.01462817,  0.02184096,  0.03170126,\n",
       "        0.04973349, -0.00305836,  0.0095525 ,  0.04229852, -0.03174093,\n",
       "        0.03040392, -0.04191374,  0.03680452, -0.03654184,  0.01838854,\n",
       "       -0.00716392,  0.0309788 ,  0.02648148, -0.02690156,  0.02595301,\n",
       "        0.00505005,  0.01338584,  0.00843542,  0.00747017,  0.00810472,\n",
       "       -0.02204435,  0.01103472,  0.0089463 , -0.00903088,  0.02441616,\n",
       "       -0.04697675,  0.02787347,  0.00456388, -0.04420676, -0.01055621,\n",
       "       -0.04082857,  0.01326665, -0.03449193,  0.00264472], dtype=float32)))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd58d4b-6749-4177-8342-83ee969408c9",
   "metadata": {},
   "source": [
    "#### chosen action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d49adbbb-f747-4e4c-b82d-df88373c644f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0, dtype=int32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd12013-1d12-4197-8254-cef9138df42c",
   "metadata": {},
   "source": [
    "#### Per Arm Policy Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d6126290-546b-4702-8a1e-91f18adb05c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.419865, 3.419865], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([ 0.01546537,  0.02517445,  0.04813281,  0.04863187, -0.01263794,\n",
       "       -0.04036776, -0.02560099, -0.04624224, -0.02573046, -0.02562919,\n",
       "       -0.03024311,  0.01836432, -0.03906032,  0.01016109, -0.04428653,\n",
       "       -0.03649165, -0.03648589,  0.02401939,  0.00510664,  0.04678353,\n",
       "        0.03368597,  0.03238941, -0.02772726,  0.04693978,  0.02093353,\n",
       "       -0.00620302,  0.00255311, -0.01462817,  0.02184096,  0.03170126,\n",
       "        0.04973349, -0.00305836,  0.0095525 ,  0.04229852, -0.03174093,\n",
       "        0.03040392, -0.04191374,  0.03680452, -0.03654184,  0.01838854,\n",
       "       -0.00716392,  0.0309788 ,  0.02648148, -0.02690156,  0.02595301,\n",
       "        0.00505005,  0.01338584,  0.00843542,  0.00747017,  0.00810472,\n",
       "       -0.02204435,  0.01103472,  0.0089463 , -0.00903088,  0.02441616,\n",
       "       -0.04697675,  0.02787347,  0.00456388, -0.04420676, -0.01055621,\n",
       "       -0.04082857,  0.01326665, -0.03449193,  0.00264472], dtype=float32))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f66961-ebb5-4ae5-8e6f-ad73114d8353",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
