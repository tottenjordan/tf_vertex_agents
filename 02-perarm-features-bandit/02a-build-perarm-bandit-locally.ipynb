{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385307d6-2058-47ec-8da0-57f7ef5c43d6",
   "metadata": {},
   "source": [
    "# Train Bandits with per-arm features\n",
    "\n",
    "**Exploring linear and nonlinear** (e.g., those with neural network-based value functions) bandit methods for recommendations using TF-Agents\n",
    "\n",
    "> Neural linear bandits provide a nice way to leverage the representation power of deep learning and the bandit approach for uncertainty measure and efficient exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1e9956-66cd-4bf4-9b4d-8c2c646f0313",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "\n",
    "In this notebook, we explore the following topics for training contextual bandits with per-arm features:\n",
    "\n",
    "1. Data preperation\n",
    "2. Sampling functions\n",
    "3. TensorSpecs\n",
    "4. Agent, Network, training policy\n",
    "5. Reward function\n",
    "6. Trajectory function\n",
    "7. Train & Eval loops\n",
    "8. Getting predictions -\n",
    "9. Preparing the training application - abstracting all steps above to be used in subsequent notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fd257-b98b-426a-a2cd-024429b014f1",
   "metadata": {},
   "source": [
    "## Load notebook config\n",
    "\n",
    "* use the prefix defined in `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f39c9d08-d118-4013-a47f-88450f49f19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "# PREFIX = 'mabv1'\n",
    "VERSION        = \"v2\"                       # TODO\n",
    "PREFIX         = f'rec-bandits-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908f6b95-b539-4a9f-a836-840d26ea3b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"rec-bandits-v2\"\n",
      "VERSION                  = \"v2\"\n",
      "\n",
      "BUCKET_NAME              = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "DATA_PATH_KFP_DEMO       = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data/kfp_demo_data/u.data\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_NAME    = \"mvlens_rec_bandits_v2\"\n",
      "BIGQUERY_TABLE_NAME      = \"training_dataset\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-rec-bandits-v2\"\n",
      "\n",
      "DOCKERNAME_01            = \"Dockerfile_train_my_perarm_env\"\n",
      "IMAGE_NAME_01            = \"train-my-perarm-env-v2\"\n",
      "IMAGE_URI_01             = \"gcr.io/hybrid-vertex/train-my-perarm-env-v2\"\n",
      "\n",
      "DOCKERNAME_02            = \"Dockerfile_perarm_feats\"\n",
      "IMAGE_NAME_02            = \"train-perarm-feats-v2\"\n",
      "IMAGE_URI_02             = \"gcr.io/hybrid-vertex/train-perarm-feats-v2\"\n",
      "\n",
      "DOCKERNAME_03            = \"Dockerfile_ranking_bandit\"\n",
      "IMAGE_NAME_03            = \"train-rank-bandit-v2\"\n",
      "IMAGE_URI_03             = \"gcr.io/hybrid-vertex/train-rank-bandit-v2\"\n",
      "\n",
      "DOCKERNAME_04            = \"Dockerfile_train_mab_e2e\"\n",
      "IMAGE_NAME_04            = \"train-mab-e2e-v2\"\n",
      "IMAGE_URI_04             = \"gcr.io/hybrid-vertex/train-mab-e2e-v2\"\n",
      "\n",
      "DOCKERNAME_04_pred       = \"Dockerfile_pred_mab_e2e\"\n",
      "IMAGE_NAME_04_pred       = \"pred-mab-e2e-v2\"\n",
      "IMAGE_URI_04_pred        = \"gcr.io/hybrid-vertex/pred-mab-e2e-v2\"\n",
      "\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/local_docker_tfa\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c690a9-e2bd-4759-ba41-4e2469098aee",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d0dfe4-695c-4dd4-9f24-67f7488ce1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c669f1a1-1af7-4efb-ab2d-6bf3b3847991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from collections import defaultdict\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pickle as pkl\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "# from tf_agents.agents import TFAgent\n",
    "\n",
    "# from tf_agents.bandits.environments import stationary_stochastic_per_arm_py_environment as p_a_env\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "# from tf_agents.drivers import dynamic_step_driver\n",
    "# from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "# from tf_agents.bandits.agents import lin_ucb_agent\n",
    "# from tf_agents.bandits.agents import linear_thompson_sampling_agent as lin_ts_agent\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent\n",
    "from tf_agents.bandits.agents import neural_linucb_agent\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "from tf_agents.bandits.policies import policy_utilities\n",
    "\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "\n",
    "nest = tf.nest\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# this repo\n",
    "from src.per_arm_rl import data_utils\n",
    "from src.per_arm_rl import data_config\n",
    "from src.per_arm_rl import train_utils as train_utils\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29e58dd7-ab2b-419f-9771-bf1e98db758b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4969d3e-1fc0-45db-8a69-aa6b342019de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "274e7f4a-1802-4946-888e-876638f5c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a866b1-85b9-43e6-9546-edfbbf886bce",
   "metadata": {},
   "source": [
    "# [1] Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d4ed28-23d7-4785-b327-e5b543b0edb9",
   "metadata": {},
   "source": [
    "**Overview**\n",
    "* Load train and eval datasets from TFRecords created in the `01-movielens-data-prep.ipynb` notebook\n",
    "* training examples represent historical (previously collected) interaction data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd5b953-14c0-42ed-a511-77147a1bc0ac",
   "metadata": {},
   "source": [
    "### Read TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d0157c8-a04c-4dbd-b6d9-a1ede97687a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da0cdac-76af-4608-b70e-be7dbe0584b5",
   "metadata": {},
   "source": [
    "**Train data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c934c06-bf08-4c7f-b0cc-0de04ef3515c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://rec-bandits-v2-hybrid-vertex-bucket/data/train/ml-ratings-100k-train.tfrecord']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPLIT = \"train\" # \"train\" | \"val\"\n",
    "\n",
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7511e4d-bf81-4800-bde7-8b16dec9aeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([35.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'898'], dtype=object)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([885409515])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'681'], dtype=object)>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'marketing'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "train_dataset = train_dataset.map(data_utils.parse_tfrecord)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452750c1-46a0-4ee1-84d4-0c3b227de38f",
   "metadata": {},
   "source": [
    "**Val data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7b5376f-9438-4304-84aa-de09c30f5e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = \"val\"\n",
    "\n",
    "val_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        val_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "val_dataset = tf.data.TFRecordDataset(val_files)\n",
    "val_dataset = val_dataset.map(data_utils.parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8959967-522e-41c8-9a1b-050ca8bc191f",
   "metadata": {},
   "source": [
    "### get vocab\n",
    "\n",
    "**TODO:** \n",
    "* streamline vocab calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b9169bc-d6dc-497e-9dff-6ebb175282ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE_VOCABS: False\n"
     ]
    }
   ],
   "source": [
    "GENERATE_VOCABS = False\n",
    "\n",
    "print(f\"GENERATE_VOCABS: {GENERATE_VOCABS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3ccf137-7a72-42e7-aa89-3c81a99cf40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab...\n",
      "Downloaded vocab from: gs://rec-bandits-v2-hybrid-vertex-bucket/vocabs/vocab_dict.pkl\n",
      "\n",
      "'movie_id'\n",
      "'user_id'\n",
      "'user_occupation_text'\n",
      "'movie_genres'\n",
      "'bucketized_user_age'\n",
      "'max_timestamp'\n",
      "'min_timestamp'\n",
      "'timestamp_buckets'\n"
     ]
    }
   ],
   "source": [
    "if not GENERATE_VOCABS:\n",
    "\n",
    "    EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{VOCAB_SUBDIR}/{VOCAB_FILENAME}'\n",
    "    print(f\"Downloading vocab...\")\n",
    "    \n",
    "    os.system(f'gsutil -q cp {EXISTING_VOCAB_FILE} .')\n",
    "    print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "    filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "    vocab_dict = pkl.load(filehandler)\n",
    "    filehandler.close()\n",
    "    \n",
    "    for key in vocab_dict.keys():\n",
    "        pprint(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccaef62-882a-46ff-a1b1-3837e69fdf74",
   "metadata": {},
   "source": [
    "## helper functions\n",
    "\n",
    "**TODO:**\n",
    "* modularize in a train_utils or similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138a295-2b0d-4359-8496-af8552ec8cff",
   "metadata": {},
   "source": [
    "# [2] Preprocessing layers for global and arm features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e28c002-8d3a-4cf4-b69b-de56a6abab90",
   "metadata": {},
   "source": [
    "The preproccesing layers will ultimately feed the two sampling functions described below. These sampling functions will be used to create [trajectories](https://github.com/tensorflow/agents/blob/master/tf_agents/trajectories/trajectory.py#L36) (i.e., the training examples for our model)\n",
    "\n",
    "`global_context_sampling_fn`: \n",
    "* A function that outputs a random 1d array or list of ints or floats\n",
    "* This output is the global context. Its shape and type must be consistent across calls.\n",
    "\n",
    "`arm_context_sampling_fn`: \n",
    "* A function that outputs a random 1 array or list of ints or floats (same type as the output of `global_context_sampling_fn`). * This output is the per-arm context. Its shape must be consistent across calls.\n",
    "\n",
    "See `debug-and-learn-emb-models.ipynb` for more details and debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ea1f7-0621-44b8-b062-1f59b0964d72",
   "metadata": {},
   "source": [
    "## Global & Per-Arm feature embedding models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8d77956-635c-438a-916a-185eec52f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OOV_BUCKETS        = 1\n",
    "GLOBAL_EMBEDDING_SIZE  = 16\n",
    "MV_EMBEDDING_SIZE      = 32 #32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea335991-dcec-40b3-ba0d-a0fdfb9c2ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test emb models\n",
    "for i in range(1):\n",
    "    \n",
    "    iterator = iter(train_dataset.batch(1))\n",
    "    data = next(iterator)\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48178fff-491f-4f03-b156-7765d1fa9707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.perarm_features.emb_features.EmbeddingModel at 0x7fa4c360c9a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.perarm_features import emb_features as emb_features\n",
    "\n",
    "embs = emb_features.EmbeddingModel(\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "903c63c5-2468-4443-bcb8-5ff6d69810dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL_DIM: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.03690598, -0.01915582,  0.01999066, -0.003372  ,  0.00110877,\n",
       "         0.04114132,  0.02407506,  0.01854947,  0.04920412, -0.01890894,\n",
       "         0.0190177 , -0.00070621, -0.04728947,  0.04579016, -0.01057106,\n",
       "        -0.00805591, -0.00862154,  0.04551705, -0.02696762,  0.02803237,\n",
       "        -0.00705445, -0.03172759,  0.04227248, -0.03449334,  0.0006452 ,\n",
       "        -0.03130615,  0.04670798, -0.02224429, -0.0378935 ,  0.0413164 ,\n",
       "         0.03420163, -0.04178616,  0.00624633,  0.03865223, -0.00816851,\n",
       "        -0.02083771, -0.03506198, -0.00482257, -0.00224816,  0.04015637,\n",
       "         0.04104606,  0.00396786, -0.04312593, -0.03896104, -0.0331222 ,\n",
       "        -0.02902192, -0.01203643,  0.02941723,  0.01641179,  0.01356694,\n",
       "        -0.03559548,  0.03084428, -0.00737579, -0.0123203 , -0.02518617,\n",
       "         0.03094782, -0.04245502, -0.03903151,  0.01023312,  0.04480192,\n",
       "         0.02585656,  0.04602287,  0.00385011, -0.04870807]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_globals = embs._get_global_context_features(data)\n",
    "\n",
    "GLOBAL_DIM = test_globals.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"GLOBAL_DIM: {GLOBAL_DIM}\")\n",
    "\n",
    "test_globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebec4863-c614-4248-b680-8e29ec5b730d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER_ARM_DIM: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.03851307, -0.02215353, -0.03706343,  0.00575564,  0.03592296,\n",
       "         0.04501598, -0.04542446, -0.04888365,  0.0347125 , -0.00388472,\n",
       "         0.02025981, -0.03218315,  0.04521755,  0.0330633 , -0.03141421,\n",
       "         0.00474597, -0.00596744, -0.01221478, -0.02837508,  0.00695883,\n",
       "         0.01859256, -0.01878723, -0.02655107,  0.03903942,  0.00766062,\n",
       "        -0.01346438, -0.00476032,  0.02396953, -0.03564892,  0.00334843,\n",
       "        -0.01546061, -0.01127012,  0.00217793, -0.01999108,  0.01183193,\n",
       "         0.02042868, -0.04999924,  0.04939163, -0.00781318,  0.02067086,\n",
       "        -0.02238281,  0.01307665,  0.04971177,  0.02875289,  0.03224869,\n",
       "        -0.02836367,  0.01075008, -0.00481891, -0.04950982, -0.03066096,\n",
       "        -0.03871374,  0.00224075,  0.02513093, -0.02505703,  0.01832671,\n",
       "         0.04910899,  0.02285447,  0.04497332,  0.02851008, -0.03478972,\n",
       "         0.00241243, -0.01050996, -0.03702139,  0.0007866 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arms = embs._get_per_arm_features(data)\n",
    "\n",
    "PER_ARM_DIM = test_arms.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"PER_ARM_DIM: {PER_ARM_DIM}\")\n",
    "\n",
    "test_arms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ff9baaf-987d-448d-a981-742a79b581e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE      : 128\n",
      "EVAL_BATCH_SIZE : 1\n",
      "NUM_ACTIONS     : 2\n",
      "GLOBAL_DIM      : 64\n",
      "PER_ARM_DIM     : 64\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE      = 128\n",
    "EVAL_BATCH_SIZE = 1\n",
    "\n",
    "NUM_ACTIONS     = 2 #this is kinda deceptive - \n",
    "#our approach is to learn by \"flashing\" one movie rating at a time per user context. \n",
    "#The n_actions = show/don't show the movie with one degree of freedom (n-1)\n",
    "\n",
    "\n",
    "print(f\"BATCH_SIZE      : {BATCH_SIZE}\")\n",
    "print(f\"EVAL_BATCH_SIZE : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"NUM_ACTIONS     : {NUM_ACTIONS}\")\n",
    "print(f\"GLOBAL_DIM      : {GLOBAL_DIM}\")\n",
    "print(f\"PER_ARM_DIM     : {PER_ARM_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeb4902-5bb9-4587-8d29-c01d78b006be",
   "metadata": {},
   "source": [
    "# [3] TensorSpecs\n",
    "\n",
    "* say you have a global observation spec of `[17]`. And you have two batch dimensions `[4, 5]`. Then your observation has to have the shape `[4, 5, 17]`\n",
    "* and then if you have arm_obs_spec with shape `[9, 13]`, then the arm obs shape has to be exactly `[4, 5, 9, 13]`\n",
    "* and this has to be true for every single tensor in your tensor nest\n",
    "* the first 2 dims are the outer dims that are the same for all tensors, the rest of the dimensions have to follow the spec for each tensor\n",
    "\n",
    "**TODO:**\n",
    "* explain relationship between Tensor Specs and their Tensor counterparts\n",
    "* highlight the errors, lessons learned, and utility functions to address these"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20eca8d-8c73-4ec8-9d0f-f2b428055ac2",
   "metadata": {},
   "source": [
    "## Implementing MAB with TF-Agents\n",
    "\n",
    "In TF-Agents, the *per-arm features* implementation differs from the *global-only* feature examples in the following aspects:\n",
    "* Reward is modeled not per-arm, but globally.\n",
    "* The arms are permutation invariant: it doesn’t matter which arm is arm 1 or arm 2, only their features.\n",
    "* One can have a different number of arms to choose from in every step (note that unspecified/dynamically changing number of arms will have a problem with XLA compatibility).\n",
    "\n",
    "When implementing per-arm features in TF-Bandits, the following details have to be discussed:\n",
    "* Observation spec and observations,\n",
    "* Action spec and actions,\n",
    "* Implementation of specific policies and agents.\n",
    "\n",
    "\n",
    "**TODO:**\n",
    "* outline the components and highlight their interactions, dependencies on eachother, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f68ebe8-116d-43b3-a6e1-4f5a5c7f4741",
   "metadata": {},
   "source": [
    "### Observation spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9c4746-d01b-4ca4-aa53-ab68da54d37a",
   "metadata": {},
   "source": [
    "**This observation spec allows the user to have a global observation of fixed dimension**, and an unspecified number of *per-arm* features (also of fixed dimension)\n",
    "* The actions output by the policy are still integers as usual, and they indicate which row of the arm-features it has chosen \n",
    "* The action spec must be a single integer value without boundaries:\n",
    "\n",
    "```python\n",
    "global_spec = tensor_spec.TensorSpec([GLOBAL_DIM], tf.float32)\n",
    "per_arm_spec = tensor_spec.TensorSpec([None, PER_ARM_DIM], tf.float32)\n",
    "observation_spec = {'global': global_spec, 'per_arm': per_arm_spec}\n",
    "\n",
    "action_spec = tensor_spec.TensorSpec((), tf.int32)\n",
    "```\n",
    "> Here the only difference compared to the action spec with global features only is that the tensor spec is not bounded, as we don’t know how many arms there will be at any time step\n",
    "\n",
    "**XLA compatibility:**\n",
    "* Since dynamic tensor shapes are not compatible with XLA, the number of arm features (and consequently, number of arms for a step) cannot be dynamic. \n",
    "* One workaround is to fix the maximum number of arms for a problem, then pad the arm features in steps with fewer arms, and use action masking to indicate how many arms are actually active.\n",
    "\n",
    "```python\n",
    "per_arm_spec = tensor_spec.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32)\n",
    "\n",
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=(), dtype=tf.int32, minimum = 0, maximum = NUM_ACTIONS - 1\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36bd3b33-635a-4274-8b9e-7172696ebb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_spec = {\n",
    "    'global': tf.TensorSpec([GLOBAL_DIM], tf.float32),\n",
    "    'per_arm': tf.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32) #excluding action dim here\n",
    "}\n",
    "observation_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a2da92-7db2-4f42-94a7-b7bad1c8fc42",
   "metadata": {},
   "source": [
    "### Action spec\n",
    "\n",
    "> The time_step_spec and action_spec are specifications for the input time step and the output action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5af42c7-18d7-480f-a7f3-d7da3f4840eb",
   "metadata": {},
   "source": [
    "```python\n",
    "    if (\n",
    "        not tensor_spec.is_bounded(action_spec)\n",
    "        or not tensor_spec.is_discrete(action_spec)\n",
    "        or action_spec.shape.rank > 1\n",
    "        or action_spec.shape.num_elements() != 1\n",
    "    ):\n",
    "      raise NotImplementedError(\n",
    "          'action_spec must be a BoundedTensorSpec of type int32 and shape (). '\n",
    "          'Found {}.'.format(action_spec)\n",
    "      )\n",
    "```\n",
    "\n",
    "* [src](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_base_policy.py#L97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "549a123c-349a-4103-b39a-4502f47d1e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=[], \n",
    "    dtype=tf.int32,\n",
    "    minimum=tf.constant(0),            \n",
    "    maximum=NUM_ACTIONS-1, # n degrees of freedom and will dictate the expected mean reward spec shape\n",
    "    name=\"action_spec\"\n",
    ")\n",
    "\n",
    "action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36ee2635-d4e3-4468-886c-ae9c62e3c80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_num_actions: 2\n",
      "predicted_rewards_mean: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n"
     ]
    }
   ],
   "source": [
    "expected_num_actions = action_spec.maximum - action_spec.minimum + 1\n",
    "print(f\"expected_num_actions: {expected_num_actions}\")\n",
    "\n",
    "predicted_rewards_mean = tensor_spec.TensorSpec([expected_num_actions])\n",
    "print(f\"predicted_rewards_mean: {predicted_rewards_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a51efce-9f1b-42d1-bec4-7b788e3fd7e0",
   "metadata": {},
   "source": [
    "### TimeStep spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95f05860-0fbf-4a5a-8273-9c81761e0ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec = ts.time_step_spec(\n",
    "    observation_spec = observation_spec, \n",
    "    # reward_spec = _reward_spec\n",
    ")\n",
    "time_step_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9181303-6565-45f5-a293-08d50420a805",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Inspect chosen arm features spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6b526a5-997c-4621-b21c-82c6ca1d6a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90d3e03e-619e-4fa4-b817-f02b4cefd6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(64,), dtype=tf.float32, name=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_arm_features_info = (\n",
    "  policy_utilities.create_chosen_arm_features_info_spec(\n",
    "      time_step_spec.observation,\n",
    "  )\n",
    ")\n",
    "chosen_arm_features_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc427092-beb7-4baf-a2e9-b8d10629182c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandit_policy_type = (\n",
    "    policy_utilities.BanditPolicyType.GREEDY\n",
    ")\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a4a2a33-c7d4-4d81-8082-80dfc3596741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandit_policy_type = (\n",
    "    policy_utilities.create_bandit_policy_type_tensor_spec(shape=[1])\n",
    ")\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e7ac02b-18bd-4519-92fe-5541b1a8ddc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_spec = policy_utilities.PerArmPolicyInfo(\n",
    "  predicted_rewards_mean=predicted_rewards_mean,\n",
    "  bandit_policy_type=bandit_policy_type,\n",
    "  chosen_arm_features=chosen_arm_features_info,\n",
    ")\n",
    "info_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21f28b9b-8183-495a-89b6-a01f30ea8637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PerArmPolicyInfo(\n",
    "#     log_probability=(), \n",
    "#     predicted_rewards_mean=TensorSpec(shape=(2,), \n",
    "#                                       dtype=tf.float32, name=None), \n",
    "#     multiobjective_scalarized_predicted_rewards_mean=(), \n",
    "#     predicted_rewards_optimistic=(), \n",
    "#     predicted_rewards_sampled=(), \n",
    "#     bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), \n",
    "#     chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9c197-ae9b-461d-8956-f078b929ac12",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [4] The Agent\n",
    "\n",
    "**Note** that contextual bandits form a special case of RL, where the actions taken by the agent do not alter the state of the environment \n",
    "\n",
    "> “Contextual” refers to the fact that the agent chooses among a set of actions while having knowledge of the context (environment observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81d6e84-688e-48c5-aea1-77df031348c9",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Agent & Network defined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aadb01-eb5c-4870-ae14-9e66624ba594",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Agent types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d075e8a6-11a9-4346-8725-3653fba4bac4",
   "metadata": {},
   "source": [
    "> `AGENT_TYPE = ['LinUCB', 'LinTS', 'epsGreedy', 'NeuralLinUCB']`\n",
    "\n",
    "LinearUCBAgent: (`LinUCB`) \n",
    "* An agent implementing the Linear UCB bandit algorithm ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/lin_ucb_agent/LinearUCBAgent))\n",
    "\n",
    "LinearThompsonSamplingAgent: (`LinTS`) \n",
    "* Implements the Linear Thompson Sampling Agent from the [paper](https://arxiv.org/abs/1209.3352): *Thompson Sampling for Contextual Bandits with Linear Payoffs* ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/linear_thompson_sampling_agent/LinearThompsonSamplingAgent))\n",
    "\n",
    "NeuralEpsilonGreedyAgent: (`epsGreedy`) \n",
    "* A neural network based epsilon greedy agent ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_epsilon_greedy_agent/NeuralEpsilonGreedyAgent))\n",
    "\n",
    "NeuralLinUCBAgent: (`NeuralLinUCB`) \n",
    "* An agent implementing the LinUCB algorithm on top of a neural network ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_linucb_agent/NeuralLinUCBAgent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b8e88e-c8ea-4193-a911-0d974ef3b1a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Network types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f547087d-5fad-4521-a584-cb46ce52897d",
   "metadata": {},
   "source": [
    "Which network architecture to use for the `epsGreedy` or `NeuralLinUCB` agents\n",
    "\n",
    "```\n",
    "NETWORK_TYPE = ['commontower', 'dotproduct']\n",
    "```\n",
    "\n",
    "**GlobalAndArmCommonTowerNetwork:** (`commontower`)\n",
    "* This network takes the output of the global and per-arm networks, and leads them through a common network, that in turn outputs reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "> * `COMMON_LAYERS` - Iterable of ints. Specifies the layers of the common tower\n",
    "* The network produced by this function can be used either in `GreedyRewardPredictionPolicy`, or `NeuralLinUCBPolicy`\n",
    "> * In the former case, the network must have `output_dim=1`, it is going to be an instance of `QNetwork`, and used in the policy as a reward prediction network\n",
    "> * In the latter case, the network will be an encoding network with its output consumed by a reward layer or a `LinUCB` method. The specified `output_dim` will be the encoding dimension\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmCommonTowerNetwork)\n",
    "\n",
    "**GlobalAndArmDotProductNetwork:** (`dotproduct`)\n",
    "* This network calculates the **dot product** of the output of the global and per-arm networks and returns them as reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmDotProductNetwork)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3dc270-deb5-4e96-8276-74759a06c318",
   "metadata": {},
   "source": [
    "### Agent config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbe29263-453d-405e-ac50-fee7f379f335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\n",
      "\n",
      "time_step_spec:  TimeStep(\n",
      "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
      "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n",
      "\n",
      "action_spec:  BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))\n",
      "\n",
      "observation_spec:  {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\")\n",
    "print(\"\\ntime_step_spec: \", time_step_spec)\n",
    "print(\"\\naction_spec: \", action_spec)\n",
    "print(\"\\nobservation_spec: \", observation_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d817bf2-1fa6-4bae-af90-745fad996b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'common_layers': [16, 8],\n",
      " 'encoding_dim': 1,\n",
      " 'epsilon': 0.01,\n",
      " 'eval_batch_size': 1,\n",
      " 'global_layers': [64, 32, 16],\n",
      " 'learning_rate': 0.05,\n",
      " 'model_type': 'epsGreedy',\n",
      " 'network_type': 'commontower',\n",
      " 'num_actions': 2,\n",
      " 'per_arm_layers': [64, 32, 16]}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Agents\n",
    "# ================================\n",
    "AGENT_TYPE      = 'epsGreedy' # 'LinUCB' | 'LinTS |, 'epsGreedy' | 'NeuralLinUCB'\n",
    "\n",
    "# Parameters for linear agents (LinUCB and LinTS).\n",
    "AGENT_ALPHA     = 0.1\n",
    "\n",
    "# Parameters for neural agents (NeuralEpsGreedy and NerualLinUCB).\n",
    "EPSILON         = 0.01\n",
    "LR              = 0.05\n",
    "\n",
    "# Parameters for NeuralLinUCB\n",
    "ENCODING_DIM    = 1\n",
    "EPS_PHASE_STEPS = 1000\n",
    "\n",
    "# ================================\n",
    "# Agent's Preprocess Network\n",
    "# ================================\n",
    "GLOBAL_LAYERS   = [64, 32, 16] # beginning should be of size: GLOBAL_DIM\n",
    "ARM_LAYERS      = [64, 32, 16] # beginning should be of size: PER_ARM_DIM\n",
    "COMMON_LAYERS   = [16, 8]\n",
    "\n",
    "NETWORK_TYPE    = \"commontower\" # 'commontower' | 'dotproduct'\n",
    "\n",
    "if AGENT_TYPE == 'NeuralLinUCB':\n",
    "    NETWORK_TYPE = 'commontower'\n",
    "    ENCODING_DIM = COMMON_LAYERS[-1]\n",
    "\n",
    "\n",
    "HPARAMS = {  # TODO - streamline and consolidate\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"eval_batch_size\" : EVAL_BATCH_SIZE,\n",
    "    \"num_actions\": NUM_ACTIONS,\n",
    "    \"model_type\": AGENT_TYPE,\n",
    "    \"network_type\": NETWORK_TYPE,\n",
    "    \"global_layers\": GLOBAL_LAYERS,\n",
    "    \"per_arm_layers\": ARM_LAYERS,\n",
    "    \"common_layers\": COMMON_LAYERS,\n",
    "    \"learning_rate\": LR,\n",
    "    \"epsilon\": EPSILON,\n",
    "    \"encoding_dim\": ENCODING_DIM\n",
    "}\n",
    "pprint(HPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2bf060bb-9880-40b4-8583-dd7a3f915bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent: NeuralEpsGreedyAgent\n",
      "Network: commontower\n"
     ]
    }
   ],
   "source": [
    "from src.perarm_features import agent_factory as agent_factory\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "    agent_type = AGENT_TYPE,\n",
    "    network_type = NETWORK_TYPE,\n",
    "    time_step_spec = time_step_spec,\n",
    "    action_spec = action_spec,\n",
    "    observation_spec=observation_spec,\n",
    "    global_layers = GLOBAL_LAYERS,\n",
    "    arm_layers = ARM_LAYERS,\n",
    "    common_layers = COMMON_LAYERS,\n",
    "    agent_alpha = AGENT_ALPHA,\n",
    "    learning_rate = LR,\n",
    "    epsilon = EPSILON,\n",
    "    train_step_counter = global_step,\n",
    "    output_dim = ENCODING_DIM,\n",
    "    eps_phase_steps = EPS_PHASE_STEPS,\n",
    "    summarize_grads_and_vars = True,\n",
    "    debug_summaries = True\n",
    ")\n",
    "      \n",
    "agent.initialize()\n",
    "print(f'agent: {agent.name}')\n",
    "\n",
    "# if network:\n",
    "#     print(f\"Network: {network}\")\n",
    "\n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {NETWORK_TYPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d77d1-a0b3-4898-adf0-0b32bfaf5bd7",
   "metadata": {},
   "source": [
    "#### Inspect the specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78ca56e7-a386-4bf4-8c2b-3d1665521f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41483f5a-bda6-48a4-9e1c-88d8b4afeea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.time_step_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f205716-f265-4ca8-81a7-4799de8f60a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(Trajectory(\n",
       "{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32)),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None)}),\n",
       " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None)),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.training_data_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d404dae-3cc3-4f81-962b-4641455ca4f2",
   "metadata": {},
   "source": [
    "# [5] Reward function\n",
    "\n",
    "> see `reward_factory.py`\n",
    "\n",
    "* Since we are training a policy with previously collected interaction data, we model the reward function from actual rewards\n",
    "* We will simply pass the `user_rating` (values 0-5) as rewards to the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df9aecd6-d20a-48a7-9ead-4da3bbcfdae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _get_rewards(element):\n",
    "#     \"\"\"Calculates reward for the actions.\"\"\"\n",
    "\n",
    "#     def _calc_reward(x):\n",
    "#         \"\"\"Calculates reward for a single action.\"\"\"\n",
    "#         r0 = lambda: tf.constant(0.0)\n",
    "#         r1 = lambda: tf.constant(1.0)\n",
    "#         r2 = lambda: tf.constant(2.0)\n",
    "#         r3 = lambda: tf.constant(3.0)\n",
    "#         r4 = lambda: tf.constant(4.0)\n",
    "#         r5 = lambda: tf.constant(5.0)\n",
    "#         c1 = tf.equal(x, 1.0)\n",
    "#         c2 = tf.equal(x, 2.0)\n",
    "#         c3 = tf.equal(x, 3.0)\n",
    "#         c4 = tf.equal(x, 4.0)\n",
    "#         c5 = tf.equal(x, 5.0)\n",
    "#         return tf.case(\n",
    "#             [(c1, r1), (c2, r2), (c3, r3),(c4, r4),(c5, r5)], \n",
    "#             default=r0, exclusive=True\n",
    "#         )\n",
    "\n",
    "#     return tf.map_fn(\n",
    "#         fn=_calc_reward, \n",
    "#         elems=element['user_rating'], \n",
    "#         dtype=tf.float32\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac59703a-9a00-4eba-a3b7-45b21b738dd4",
   "metadata": {},
   "source": [
    "# [6] Trajectory function\n",
    "\n",
    "> This function will convert training samples from the TF Records to `trajectories` which the Agent interprets as training records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c16aa7b-f328-425e-b02e-a3fc7f200859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.perarm_features import reward_factory as reward_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3605d9f-d239-4871-9a61-6e9b21f9c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _trajectory_fn(element): # hparams\n",
    "    \n",
    "    \"\"\"Converts a dataset element into a trajectory.\"\"\"\n",
    "    # global_features = _get_global_context_features(element)\n",
    "    # arm_features = _get_per_arm_features(element)\n",
    "    \n",
    "    global_features = embs._get_global_context_features(element)\n",
    "    arm_features = embs._get_per_arm_features(element)\n",
    "    \n",
    "    # Adds a time dimension.\n",
    "    arm_features = train_utils._add_outer_dimension(arm_features)\n",
    "\n",
    "    # obs spec\n",
    "    observation = {\n",
    "        bandit_spec_utils.GLOBAL_FEATURE_KEY:\n",
    "            train_utils._add_outer_dimension(global_features),\n",
    "    }\n",
    "\n",
    "    # reward = train_utils._add_outer_dimension(_get_rewards(element))\n",
    "    reward = train_utils._add_outer_dimension(reward_factory._get_rewards(element))\n",
    "\n",
    "    # To emit the predicted rewards in policy_info, we need to create dummy\n",
    "    # rewards to match the definition in TensorSpec for the ones specified in\n",
    "    # emit_policy_info set.\n",
    "    dummy_rewards = tf.zeros([HPARAMS['batch_size'], 1, HPARAMS['num_actions']])\n",
    "    policy_info = policy_utilities.PerArmPolicyInfo(\n",
    "        chosen_arm_features=arm_features,\n",
    "        # Pass dummy mean rewards here to match the model_spec for emitting\n",
    "        # mean rewards in policy info\n",
    "        predicted_rewards_mean=dummy_rewards,\n",
    "        bandit_policy_type=tf.zeros([HPARAMS['batch_size'], 1, 1], dtype=tf.int32)\n",
    "        # policy_utilities.create_bandit_policy_type_tensor_spec(shape=[1]) # policy_utilities.BanditPolicyType.GREEDY\n",
    "        # tf.zeros([batch_size, 1, 1], dtype=tf.int32)\n",
    "    )\n",
    "    \n",
    "    if HPARAMS['model_type'] == 'neural_ucb':\n",
    "        policy_info = policy_info._replace(\n",
    "            predicted_rewards_optimistic=dummy_rewards\n",
    "        )\n",
    "        \n",
    "    return trajectory.single_step(\n",
    "        observation=observation,\n",
    "        action=tf.zeros_like(\n",
    "            reward, dtype=tf.int32\n",
    "        ),  # Arm features are copied from policy info, put dummy zeros here\n",
    "        policy_info=policy_info,\n",
    "        reward=reward,\n",
    "        discount=tf.zeros_like(reward)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a0989c-5a06-4fd5-a12d-d92dbbe71a76",
   "metadata": {},
   "source": [
    "Inspect the trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "257791d1-c97c-48c0-bc92-f5a4737b6c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in train_dataset.batch(HPARAMS['batch_size']).take(1):\n",
    "    test_traj = _trajectory_fn(x)\n",
    "    \n",
    "# test_traj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d8994e-ce28-4fd9-8e3b-153451d014d9",
   "metadata": {},
   "source": [
    "#### Inspect shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a0e451f-1ad8-4af2-84d6-ddc5eaac0e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.action.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.action.shape: {test_traj.action.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "52ed1767-12ce-404c-9caf-0974d55ec5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.discount.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.discount.shape: {test_traj.discount.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "033ff16b-0158-477f-835f-99deec636b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.reward.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.reward.shape: {test_traj.reward.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee5aded7-7f9c-4a88-868c-f6ab58a0e704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.observation.shape: (128, 1, 64)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.observation.shape: {test_traj.observation['global'].shape}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcbfc9a-049e-49b9-b2a3-ecb9fd4b9964",
   "metadata": {},
   "source": [
    "# [7] Training the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13adc1ef-b50e-41a3-9b95-c128d0c55a2b",
   "metadata": {},
   "source": [
    "## set Vertex Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e861fb27-df24-4821-8448-cf1346b186f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : v2-local-2a-v1\n",
      "RUN_NAME          : run-20231102-124353\n",
      "\n",
      "BASE_OUTPUT_DIR   : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-124353\n",
      "LOG_DIR           : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-124353/logs\n",
      "ROOT_DIR          : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-124353/root\n",
      "ARTIFACTS_DIR     : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-124353/artifacts\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME   = f'v2-local-2a-v1'\n",
    "\n",
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b7a5e4-efff-490b-b431-53037a2f4a16",
   "metadata": {},
   "source": [
    "## eval loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba0392e-90c8-4dc8-8df2-6d2af1ade490",
   "metadata": {},
   "source": [
    "> When evaluating an epsilon-greedy bandit, we need to remove those predictions that come from the `uniform_random` policy. We only want the predictions from the `GREEDY` policy, becasue we want to know how the model performs when it is actually used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b3d3c-75f7-46f4-9a1b-6329e419b7f5",
   "metadata": {},
   "source": [
    "## train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "97cfe7c3-4022-47a9-83c2-df0ad8a2abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.metrics import export_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.utils import common\n",
    "\n",
    "# from src.per_arm_rl import train_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bb7ffc-00df-4d46-857b-86c87b78f597",
   "metadata": {},
   "source": [
    "`agent.train(experience=...)`\n",
    "\n",
    "where `experience` is a batch of trajectories data in the form of a Trajectory. \n",
    "* The structure of experience must match that of `self.training_data_spec`. \n",
    "* All tensors in experience must be shaped [batch, time, ...] where time must be equal to self.train_step_length if that property is not None."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94d6d45-c71e-4fe4-9af8-af9a8bda4e4f",
   "metadata": {},
   "source": [
    "### logs & checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "049ee49b-3b1a-4b12-a360-15e759dff7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('metrics: [<tf_agents.metrics.tf_metrics.AverageReturnMetric object at '\n",
      " '0x7fa4c398a560>]')\n",
      "setting checkpoint_manager: gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-124353/root/chkpoint\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    f\"{LOG_DIR}/train\", flush_millis=10 * 1000\n",
    ")\n",
    "# train_summary_writer.set_as_default()\n",
    "\n",
    "# eval_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "#     f\"{LOG_DIR}/eval\", flush_millis=10 * 1000\n",
    "# )\n",
    "# ====================================================\n",
    "# metrics\n",
    "# ====================================================\n",
    "step_metric = tf_metrics.EnvironmentSteps()\n",
    "metrics = [\n",
    "    # tf_metrics.NumberOfEpisodes(),\n",
    "    # tf_metrics.AverageEpisodeLengthMetric(batch_size=HPARAMS['batch_size']),\n",
    "    tf_metrics.AverageReturnMetric(batch_size=HPARAMS['batch_size'])\n",
    "]\n",
    "\n",
    "pprint(f\"metrics: {metrics}\")\n",
    "\n",
    "# ====================================================\n",
    "# get checkpoint manager\n",
    "# ====================================================\n",
    "CHKPOINT_DIR = f\"{ROOT_DIR}/chkpoint\"\n",
    "print(f\"setting checkpoint_manager: {CHKPOINT_DIR}\")\n",
    "\n",
    "checkpoint_manager = train_utils.restore_and_get_checkpoint_manager(\n",
    "    root_dir=CHKPOINT_DIR, \n",
    "    agent=agent, \n",
    "    metrics=metrics, \n",
    "    step_metric=step_metric\n",
    ")\n",
    "# ====================================================\n",
    "# policy saver\n",
    "# ====================================================\n",
    "saver = policy_saver.PolicySaver(\n",
    "    agent.policy, \n",
    "    train_step=global_step\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83683f4b-8a1a-44b9-8d5f-7ee3304c794c",
   "metadata": {},
   "source": [
    "### config\n",
    "\n",
    "* calculate train & val dataset sizes\n",
    "* define logging and chkpt intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f9432613-6583-4828-8a2a-dd939adbc3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_DATA_SIZE : 80000\n",
      "NUM_TRAIN_STEPS : 100\n",
      "EVAL_DATA_SIZE : 1000\n",
      "NUM_EVAL_STEPS : 1000\n",
      "CHKPT_INTERVAL: 100\n",
      "LOG_INTERVAL : 10\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA_SIZE = 80000          # len(list(train_dataset))\n",
    "NUM_TRAIN_STEPS = 100            # TRAIN_DATA_SIZE // HPARAMS['batch_size']\n",
    "\n",
    "EVAL_DATA_SIZE  = 1000          # len(list(val_dataset))\n",
    "NUM_EVAL_STEPS  = 1000           # EVAL_DATA_SIZE // HPARAMS['eval_batch_size']\n",
    "\n",
    "CHKPT_INTERVAL  = NUM_TRAIN_STEPS # // 5\n",
    "LOG_INTERVAL    = 10\n",
    "# EVAL_INTERVAL = NUM_TRAIN_STEPS // 2\n",
    "\n",
    "print(f\"TRAIN_DATA_SIZE : {TRAIN_DATA_SIZE}\")\n",
    "print(f\"NUM_TRAIN_STEPS : {NUM_TRAIN_STEPS}\")\n",
    "print(f\"EVAL_DATA_SIZE : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS : {NUM_EVAL_STEPS}\")\n",
    "print(f\"CHKPT_INTERVAL: {CHKPT_INTERVAL}\")\n",
    "print(f\"LOG_INTERVAL : {LOG_INTERVAL}\")\n",
    "# print(f\"EVAL_INTERVAL : {EVAL_INTERVAL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "379ffc65-4eec-4af1-8fd4-912ef65a9808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec={'bucketized_user_age': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'movie_genres': TensorSpec(shape=(None, 1), dtype=tf.int64, name=None), 'movie_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'timestamp': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'user_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_occupation_text': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_rating': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data\n",
    "train_ds_iterator = iter(train_dataset.batch(HPARAMS['batch_size']).repeat())\n",
    "\n",
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS[\"eval_batch_size\"])\n",
    "\n",
    "if NUM_EVAL_STEPS > 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)\n",
    "\n",
    "# eval_ds = eval_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "eval_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e498d7e3-d166-4e1d-94a5-f721de58694a",
   "metadata": {},
   "source": [
    "### run train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5dd64d98-7d5b-4474-a567-b42426d630a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.perarm_features import eval_perarm as eval_perarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "da4680f3-693b-4530-8e4d-88bc43036c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating pre-trained Agent...\n",
      "pre-train val_loss     : 15.352275848388672\n",
      "pre-train eval runtime : 0\n",
      "starting train loop...\n",
      "step = 0: train loss = 15.90999984741211\n",
      "step = 10: train loss = 9.210000038146973\n",
      "step = 20: train loss = 2.059999942779541\n",
      "step = 30: train loss = 1.2000000476837158\n",
      "step = 40: train loss = 1.0\n",
      "step = 50: train loss = 1.409999966621399\n",
      "step = 60: train loss = 1.4299999475479126\n",
      "step = 70: train loss = 1.4800000190734863\n",
      "step = 80: train loss = 1.3200000524520874\n",
      "step = 90: train loss = 1.2799999713897705\n",
      "train runtime_mins: 12\n",
      "saved trained policy to: gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-124353/artifacts\n",
      "evaluating trained Agent...\n",
      "post-train val_loss     : 1.3237148523330688\n",
      "post-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "# agent.train = common.function(agent.train)\n",
    "\n",
    "list_o_loss = []\n",
    "\n",
    "# ====================================================\n",
    "# Evaluate the agent's policy once before training\n",
    "# ====================================================\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "pre_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "\n",
    "print(f\"evaluating pre-trained Agent...\")\n",
    "start_time = time.time()\n",
    "\n",
    "pre_val_loss, pre_preds, pre_tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = pre_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"pre-train val_loss     : {pre_val_loss}\")\n",
    "print(f\"pre-train eval runtime : {runtime_mins}\")\n",
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "print(f\"starting train loop...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# for i in tqdm(range(NUM_TRAIN_STEPS)):\n",
    "for i in range(NUM_TRAIN_STEPS):\n",
    "    \n",
    "    with train_summary_writer.as_default():\n",
    "\n",
    "        data = next(train_ds_iterator)\n",
    "        trajectories = _trajectory_fn(data)\n",
    "\n",
    "        # All tensors in experience must be shaped [batch, time, ...] \n",
    "        step = agent.train_step_counter.numpy()\n",
    "        loss = agent.train(experience=trajectories)\n",
    "        list_o_loss.append(loss.loss.numpy())\n",
    "\n",
    "        train_utils._export_metrics_and_summaries(\n",
    "            step=i, \n",
    "            metrics=metrics\n",
    "        )\n",
    "\n",
    "        # print step loss\n",
    "        if step % LOG_INTERVAL == 0:\n",
    "            print(\n",
    "                'step = {0}: train loss = {1}'.format(\n",
    "                    step, round(loss.loss.numpy(), 2)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if i > 0 and i % CHKPT_INTERVAL == 0:\n",
    "            saver.save(os.path.join(CHKPOINT_DIR, 'policy_%d' % step_metric.result()))\n",
    "            print(f\"saved policy to: {CHKPOINT_DIR}\")\n",
    "   \n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"train runtime_mins: {runtime_mins}\")\n",
    "\n",
    "saver.save(ARTIFACTS_DIR)\n",
    "print(f\"saved trained policy to: {ARTIFACTS_DIR}\")\n",
    "\n",
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = post_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "17b2b0d2-9795-4367-b57b-c331e94d1000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3237149"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb1ed8-f67b-4e7b-9cbc-70edd50e49ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate train job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff31fe28-2f05-499f-b1cc-505f3c9074e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### train loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "41937f9a-6c28-48d2-bc7c-bfe4372c7cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_o_loss)\n",
    "# plt.ylim([0, 10])\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e947e1-67f4-4205-99af-6921c6e9c896",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e0f77a33-0962-4af0-af97-cf05f895cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5d0509cb-0777-4d35-86c6-28c8acbcc793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-37b1527787383cb7\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-37b1527787383cb7\");\n",
       "          const url = new URL(\"/proxy/6007/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=$LOG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc40143-30b1-479f-b9b1-fa4c07b1690e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [8] Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6c94a0-122f-4ba6-acef-5653a3cc7850",
   "metadata": {
    "tags": []
   },
   "source": [
    "## load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b1c382b5-e2e0-45a2-9c5f-ef2c468d0f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-124353/artifacts\n"
     ]
    }
   ],
   "source": [
    "POLICY_URI = ARTIFACTS_DIR\n",
    "\n",
    "print(POLICY_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "68592d97-1272-4c6d-a4bd-43a6f7fe6c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7fa36c70c610>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910a06f-678f-4bfa-a132-10b885f871c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## get predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1762c936-3c49-4ec5-a9eb-4df5816dc888",
   "metadata": {},
   "source": [
    "TODO - explain bandit_policy_type()\n",
    "\n",
    "**UNIFORM Random policy:**\n",
    "```\n",
    "PolicyStep(action=array(1, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.637535 , 3.5557823], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([2], dtype=int32), chosen_arm_features=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)))\n",
    "```\n",
    "\n",
    "**GREEDY policy:**\n",
    "```\n",
    "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.8278818, 3.607565 ], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([ 0.04054676, -0.04735027,  0.02202327,  0.01276748, -0.01367382,\n",
    "       -0.04838754,  0.00104916, -0.01956806,  0.01028793, -0.00256665,\n",
    "       -0.04376553,  0.03900594,  0.02388967, -0.04016995, -0.04945569,\n",
    "       -0.04539652,  0.04423274, -0.04630332,  0.00390794,  0.03986299,\n",
    "       -0.0398974 ,  0.01655747, -0.0471294 , -0.00690235, -0.03643382,\n",
    "       -0.0437116 ,  0.04757959, -0.00991895,  0.0281055 , -0.04633433,\n",
    "        0.01897702, -0.00824345,  0.03232259, -0.04980658, -0.01144745,\n",
    "        0.01690939,  0.02536928,  0.03384003, -0.01558131,  0.04731432,\n",
    "        0.04579857, -0.03305101,  0.03521084, -0.03915765,  0.04927064,\n",
    "        0.04695194,  0.03792156,  0.040496  ,  0.02574866, -0.00665367,\n",
    "       -0.03839222, -0.01564004, -0.04710373,  0.03557512, -0.01392462,\n",
    "        0.01368621,  0.02792176, -0.01799218,  0.00246101,  0.02263175,\n",
    "        0.0170817 ,  0.01388383, -0.03048695,  0.01198485], dtype=float32)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "567f64e1-8149-4364-b561-1a9d12581b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aff30396-e0fd-4f43-acaa-6af8b20b12cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "SKIP_NUM = 10\n",
    "\n",
    "for x in eval_ds.skip(SKIP_NUM).take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    \n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "    \n",
    "    # rewards = _get_rewards(x)\n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e58af9ab-f4da-4857-afe5-6b8de26ed0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(1, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.6323435, 3.6361868], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6676778c-d191-4b1e-a180-61f068b3b8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PolicyStep(action=array(1, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.6323435, 3.6361868], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)))\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c85a0087-7388-4f03-9278-aace31121233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1, dtype=int32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a8266c7c-3688-46a5-a1c8-a63bb7146128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info.bandit_policy_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9712bc00-7ea0-4003-a3c7-81a0be5bc995",
   "metadata": {},
   "source": [
    "# [9] Prepare training application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f62966-123f-410e-9610-832f20566635",
   "metadata": {},
   "source": [
    "To scale this training in Vertex AI's managed training service, we need to package all our code into a python application\n",
    "\n",
    "* This means, we need to modularize all steps executed up until this point. For example, the training loop we ran above is further parameterized in `train_perarm.py`, which will be called from our `task.py` when we submit the job to Vertex AI\n",
    "* This training package will eventually be used to create a custom training image (more on that in `04b-build-training-image` notebook)\n",
    "* For additional details on preparing the training application for Vertex AI, check out [the documentation](https://cloud.google.com/vertex-ai/docs/training/code-requirements) and [this code example](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage2/get_started_vertex_training.ipynb) (which also has good, related commentary)\n",
    "\n",
    "**The remaining cells will repeat steps executed above**\n",
    "> we are just illustrating / validating that they are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1129ee41-b43c-4d5a-b656-cdac6b79688c",
   "metadata": {},
   "source": [
    "#### Vertex Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ef509680-4d19-4efa-9f01-21039e0d573b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : v2-local-2a-v1\n"
     ]
    }
   ],
   "source": [
    "# using same experiment name \n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7ad98430-d836-40f1-8e4f-eb46f0c91fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : v2-local-2a-v1\n",
      "RUN_NAME          : run-20231102-125815\n",
      "\n",
      "BASE_OUTPUT_DIR   : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-125815\n",
      "LOG_DIR           : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-125815/logs\n",
      "ROOT_DIR          : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-125815/root\n",
      "ARTIFACTS_DIR     : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-125815/artifacts\n"
     ]
    }
   ],
   "source": [
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fbdecf78-94c5-4f8c-a6c0-86f2eace4663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: NeuralEpsGreedyAgent\n",
      "Network: commontower\n"
     ]
    }
   ],
   "source": [
    "# from src.perarm_features import agent_factory as agent_factory\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "    agent_type = AGENT_TYPE,\n",
    "    network_type = NETWORK_TYPE,\n",
    "    time_step_spec = time_step_spec,\n",
    "    action_spec = action_spec,\n",
    "    observation_spec=observation_spec,\n",
    "    global_layers = GLOBAL_LAYERS,\n",
    "    arm_layers = ARM_LAYERS,\n",
    "    common_layers = COMMON_LAYERS,\n",
    "    agent_alpha = AGENT_ALPHA,\n",
    "    learning_rate = LR,\n",
    "    epsilon = EPSILON,\n",
    "    train_step_counter = global_step,\n",
    "    output_dim = ENCODING_DIM,\n",
    "    eps_phase_steps = EPS_PHASE_STEPS,\n",
    ")\n",
    "\n",
    "print(f\"Agent: {agent.name}\")\n",
    "\n",
    "# if network:\n",
    "#     print(f\"Network: {network}\")\n",
    "\n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {NETWORK_TYPE}\")\n",
    "        \n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "108ed33c-d8ef-4524-97e9-ced9e01c154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHKPT_INTERVAL    : 200\n",
      "eval_batch_size   : 1\n",
      "EVAL_DATA_SIZE    : 1000\n",
      "NUM_EVAL_STEPS    : 100\n",
      "TOTAL_TRAIN_TAKE  : 10000\n"
     ]
    }
   ],
   "source": [
    "from src.perarm_features import train_perarm as train_perarm\n",
    "\n",
    "# train args\n",
    "TRAINING_LOOPS        = 150\n",
    "STEPS_PER_LOOP        = 1\n",
    "\n",
    "drop_arm_feature_fn   = None\n",
    "ASYNC_STEPS_PER_LOOP  = 1\n",
    "\n",
    "LOG_INTERVAL          = 10\n",
    "CHKPT_INTERVAL        = 200\n",
    "\n",
    "# eval args\n",
    "NUM_EVAL_STEPS = 100\n",
    "\n",
    "TOTAL_TRAIN_TAKE = 10000 #TRAINING_LOOPS * HPARAMS['batch_size']\n",
    "\n",
    "print(f\"CHKPT_INTERVAL    : {CHKPT_INTERVAL}\")\n",
    "print(f\"eval_batch_size   : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"EVAL_DATA_SIZE    : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS    : {NUM_EVAL_STEPS}\")\n",
    "print(f\"TOTAL_TRAIN_TAKE  : {TOTAL_TRAIN_TAKE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f66ff927-9a39-4abf-b247-845f0dc7721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS['eval_batch_size'])\n",
    "\n",
    "if NUM_EVAL_STEPS >= 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f6c98398-d545-4dcc-a71f-32249b5f0336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_files: ['gs://rec-bandits-v2-hybrid-vertex-bucket/data/train/ml-ratings-100k-train.tfrecord']\n",
      "train_ds_iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7fa4c3a83220>\n",
      "setting checkpoint_manager: gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-125815/root/chkpoint\n",
      "wrapping agent.train in tf-function\n",
      "starting_loop: 0\n",
      "starting train loop...\n",
      "step = 100: loss = 15.920000076293945\n",
      "step = 110: loss = 8.529999732971191\n",
      "step = 120: loss = 4.760000228881836\n",
      "step = 130: loss = 1.7200000286102295\n",
      "step = 140: loss = 1.0099999904632568\n",
      "step = 150: loss = 1.2699999809265137\n",
      "step = 160: loss = 1.399999976158142\n",
      "step = 170: loss = 1.4500000476837158\n",
      "step = 180: loss = 1.309999942779541\n",
      "step = 190: loss = 1.2699999809265137\n",
      "step = 200: loss = 1.4800000190734863\n",
      "step = 210: loss = 1.340000033378601\n",
      "step = 220: loss = 1.159999966621399\n",
      "step = 230: loss = 0.9900000095367432\n",
      "step = 240: loss = 1.090000033378601\n",
      "runtime_mins: 1\n",
      "saved trained policy to: gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-125815/artifacts\n",
      "complete train job in 1 minutes\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    f\"{LOG_DIR}/train\", flush_millis=10 * 1000\n",
    ")\n",
    "\n",
    "#start the timer and training\n",
    "start_time = time.time()\n",
    "\n",
    "metric_results, agent = train_perarm.train_perarm(\n",
    "    agent = agent,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    num_iterations = TRAINING_LOOPS,\n",
    "    steps_per_loop = STEPS_PER_LOOP,\n",
    "    num_eval_steps = NUM_EVAL_STEPS,\n",
    "    # data\n",
    "    batch_size = HPARAMS['batch_size'],\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    # functions\n",
    "    _trajectory_fn = _trajectory_fn,\n",
    "    # _run_bandit_eval_fn = _run_bandit_eval,\n",
    "    # train intervals\n",
    "    chkpt_interval = CHKPT_INTERVAL,\n",
    "    log_interval = LOG_INTERVAL,\n",
    "    # dirs\n",
    "    bucket_name = BUCKET_NAME,\n",
    "    data_dir_prefix_path = DATA_GCS_PREFIX,\n",
    "    log_dir = LOG_DIR,\n",
    "    model_dir = ARTIFACTS_DIR,\n",
    "    root_dir = ROOT_DIR,\n",
    "    async_steps_per_loop = ASYNC_STEPS_PER_LOOP,\n",
    "    resume_training_loops = False,\n",
    "    use_gpu = True,\n",
    "    use_tpu = False,\n",
    "    profiler = False,\n",
    "    global_step = global_step,\n",
    "    total_train_take = TOTAL_TRAIN_TAKE,\n",
    "    train_summary_writer = train_summary_writer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"complete train job in {runtime_mins} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "177aa3ab-05b4-48f9-b434-9335bd9eb54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3170915"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(metric_results)\n",
    "metric_results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ba65417f-54e0-436e-b0d4-93cffb981ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(metric_results)\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7ba747-00d5-4908-8d0b-334ae9d2c791",
   "metadata": {},
   "source": [
    "#### eval trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c5cf9366-d9cd-4c9d-951a-99a50877a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af82506e-95d7-4a4e-a821-e08512615db7",
   "metadata": {},
   "source": [
    "After training, our `agent.policy` is used as the deployment \"model\" that will generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6c82396a-7822-41fb-830f-1f6eb9c9b213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.epsilon_greedy_policy.EpsilonGreedyPolicy at 0x7fa249118f40>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_agent = agent.policy\n",
    "deployment_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f6706224-ef5b-4185-bde4-bccb7c8e7ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating trained Agent...\n",
      "post-train val_loss     : 1.5708459615707397\n",
      "post-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(deployment_agent, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = post_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f899120f-3706-4b72-8f2c-2169221dd66b",
   "metadata": {},
   "source": [
    "## Using Trained Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b0f691-860e-4853-928e-4c7ece714dd0",
   "metadata": {},
   "source": [
    "### load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ea029f73-0638-462a-8f00-54b05c54d69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-125815/artifacts\n"
     ]
    }
   ],
   "source": [
    "POLICY_URI = ARTIFACTS_DIR\n",
    "\n",
    "print(POLICY_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "66d1d819-0152-437c-aefc-45ffd34d808a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-125815/artifacts/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-125815/artifacts/fingerprint.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-125815/artifacts/policy_specs.pbtxt\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-125815/artifacts/saved_model.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-125815/artifacts/assets/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231102-125815/artifacts/variables/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $POLICY_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6aad948e-e346-4da3-8cb2-747435c8dc4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7fa250123e20>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "483f8fa5-cbd1-4e3c-8e62-47f91f42e137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(), dtype=dtype('int32'), name='action_spec', minimum=0, maximum=1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_policy.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8f658891-bc09-49b8-bc58-000a7926df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "SKIP_NUM = 11\n",
    "\n",
    "for x in eval_ds.skip(SKIP_NUM).take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    \n",
    "    # global_feat_infer = _get_global_context_features(x)\n",
    "    # arm_feat_infer = _get_per_arm_features(x)\n",
    "    \n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "    \n",
    "    # rewards = _get_rewards(x)\n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f515fcd0-2228-4f68-9ef9-665ce1fc3fb2",
   "metadata": {},
   "source": [
    "### view prediction response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6af4c297-d2e8-4f7b-bed5-e1da997dfe34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.6190686, 3.5386474], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([ 0.04723081, -0.00867967,  0.04708156, -0.03933126, -0.0163753 ,\n",
       "        0.03221614, -0.00812034,  0.03025604, -0.00139519, -0.01085867,\n",
       "       -0.04029781,  0.0091498 , -0.03974545,  0.02500229,  0.04061163,\n",
       "        0.02293222,  0.04802493,  0.02706862,  0.0281891 , -0.01032796,\n",
       "       -0.04305793, -0.02473137, -0.04823209,  0.00154727, -0.01362272,\n",
       "       -0.04433399,  0.03943019,  0.02756845,  0.04255528,  0.02866485,\n",
       "        0.02758962, -0.01789205, -0.03551181, -0.04373939, -0.03780063,\n",
       "       -0.01569076,  0.03239497, -0.04540162, -0.04852632, -0.04640068,\n",
       "        0.01821334,  0.04800499,  0.02693653, -0.0252457 , -0.0466018 ,\n",
       "       -0.01528662, -0.03378588, -0.0479337 ,  0.02295439,  0.02298584,\n",
       "       -0.00286614,  0.03048781,  0.04000706,  0.0086909 ,  0.03541512,\n",
       "       -0.02764381, -0.04142791,  0.02987594,  0.03857592,  0.00146597,\n",
       "        0.00950818, -0.0389257 ,  0.03083934,  0.00741061], dtype=float32)))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd58d4b-6749-4177-8342-83ee969408c9",
   "metadata": {},
   "source": [
    "#### chosen action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d49adbbb-f747-4e4c-b82d-df88373c644f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0, dtype=int32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd12013-1d12-4197-8254-cef9138df42c",
   "metadata": {},
   "source": [
    "#### Per Arm Policy Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d6126290-546b-4702-8a1e-91f18adb05c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.6190686, 3.5386474], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([ 0.04723081, -0.00867967,  0.04708156, -0.03933126, -0.0163753 ,\n",
       "        0.03221614, -0.00812034,  0.03025604, -0.00139519, -0.01085867,\n",
       "       -0.04029781,  0.0091498 , -0.03974545,  0.02500229,  0.04061163,\n",
       "        0.02293222,  0.04802493,  0.02706862,  0.0281891 , -0.01032796,\n",
       "       -0.04305793, -0.02473137, -0.04823209,  0.00154727, -0.01362272,\n",
       "       -0.04433399,  0.03943019,  0.02756845,  0.04255528,  0.02866485,\n",
       "        0.02758962, -0.01789205, -0.03551181, -0.04373939, -0.03780063,\n",
       "       -0.01569076,  0.03239497, -0.04540162, -0.04852632, -0.04640068,\n",
       "        0.01821334,  0.04800499,  0.02693653, -0.0252457 , -0.0466018 ,\n",
       "       -0.01528662, -0.03378588, -0.0479337 ,  0.02295439,  0.02298584,\n",
       "       -0.00286614,  0.03048781,  0.04000706,  0.0086909 ,  0.03541512,\n",
       "       -0.02764381, -0.04142791,  0.02987594,  0.03857592,  0.00146597,\n",
       "        0.00950818, -0.0389257 ,  0.03083934,  0.00741061], dtype=float32))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f66961-ebb5-4ae5-8e6f-ad73114d8353",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
