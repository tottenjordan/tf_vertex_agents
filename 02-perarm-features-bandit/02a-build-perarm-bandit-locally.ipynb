{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385307d6-2058-47ec-8da0-57f7ef5c43d6",
   "metadata": {},
   "source": [
    "# Train Bandits with per-arm features\n",
    "\n",
    "**Exploring linear and nonlinear** (e.g., those with neural network-based value functions) bandit methods for recommendations using TF-Agents\n",
    "\n",
    "> Neural linear bandits provide a nice way to leverage the representation power of deep learning and the bandit approach for uncertainty measure and efficient exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1e9956-66cd-4bf4-9b4d-8c2c646f0313",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "\n",
    "In this notebook, we explore the following topics for training contextual bandits with per-arm features:\n",
    "\n",
    "1. Data preperation\n",
    "2. Sampling functions\n",
    "3. TensorSpecs\n",
    "4. Agent, Network, training policy\n",
    "5. Reward function\n",
    "6. Trajectory function\n",
    "7. Train & Eval loops\n",
    "8. Getting predictions -\n",
    "9. Preparing the training application - abstracting all steps above to be used in subsequent notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fd257-b98b-426a-a2cd-024429b014f1",
   "metadata": {},
   "source": [
    "## Load notebook config\n",
    "\n",
    "* use the prefix defined in `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f39c9d08-d118-4013-a47f-88450f49f19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "# PREFIX = 'mabv1'\n",
    "VERSION        = \"v2\"                       # TODO\n",
    "PREFIX         = f'rec-bandits-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908f6b95-b539-4a9f-a836-840d26ea3b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"rec-bandits-v2\"\n",
      "VERSION                  = \"v2\"\n",
      "\n",
      "BUCKET_NAME              = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "DATA_PATH_KFP_DEMO       = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data/kfp_demo_data/u.data\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_NAME    = \"mvlens_rec_bandits_v2\"\n",
      "BIGQUERY_TABLE_NAME      = \"training_dataset\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-rec-bandits-v2\"\n",
      "\n",
      "DOCKERNAME_01            = \"Dockerfile_train_my_perarm_env\"\n",
      "IMAGE_NAME_01            = \"train-my-perarm-env-v2\"\n",
      "IMAGE_URI_01             = \"gcr.io/hybrid-vertex/train-my-perarm-env-v2\"\n",
      "\n",
      "DOCKERNAME_02            = \"Dockerfile_perarm_feats\"\n",
      "IMAGE_NAME_02            = \"train-perarm-feats-v2\"\n",
      "IMAGE_URI_02             = \"gcr.io/hybrid-vertex/train-perarm-feats-v2\"\n",
      "\n",
      "DOCKERNAME_03            = \"Dockerfile_ranking_bandit\"\n",
      "IMAGE_NAME_03            = \"train-rank-bandit-v2\"\n",
      "IMAGE_URI_03             = \"gcr.io/hybrid-vertex/train-rank-bandit-v2\"\n",
      "\n",
      "DOCKERNAME_04            = \"Dockerfile_train_mab_e2e\"\n",
      "IMAGE_NAME_04            = \"train-mab-e2e-v2\"\n",
      "IMAGE_URI_04             = \"gcr.io/hybrid-vertex/train-mab-e2e-v2\"\n",
      "\n",
      "DOCKERNAME_04_pred       = \"Dockerfile_pred_mab_e2e\"\n",
      "IMAGE_NAME_04_pred       = \"pred-mab-e2e-v2\"\n",
      "IMAGE_URI_04_pred        = \"gcr.io/hybrid-vertex/pred-mab-e2e-v2\"\n",
      "\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/local_docker_tfa\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c690a9-e2bd-4759-ba41-4e2469098aee",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d0dfe4-695c-4dd4-9f24-67f7488ce1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c669f1a1-1af7-4efb-ab2d-6bf3b3847991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from collections import defaultdict\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pickle as pkl\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "# from tf_agents.agents import TFAgent\n",
    "\n",
    "# from tf_agents.bandits.environments import stationary_stochastic_per_arm_py_environment as p_a_env\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "# from tf_agents.drivers import dynamic_step_driver\n",
    "# from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "# from tf_agents.bandits.agents import lin_ucb_agent\n",
    "# from tf_agents.bandits.agents import linear_thompson_sampling_agent as lin_ts_agent\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent\n",
    "from tf_agents.bandits.agents import neural_linucb_agent\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "from tf_agents.bandits.policies import policy_utilities\n",
    "\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "\n",
    "nest = tf.nest\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# this repo\n",
    "from src.per_arm_rl import data_utils\n",
    "from src.per_arm_rl import data_config\n",
    "from src.per_arm_rl import train_utils as train_utils\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29e58dd7-ab2b-419f-9771-bf1e98db758b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4969d3e-1fc0-45db-8a69-aa6b342019de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "274e7f4a-1802-4946-888e-876638f5c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a866b1-85b9-43e6-9546-edfbbf886bce",
   "metadata": {},
   "source": [
    "# [1] Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d4ed28-23d7-4785-b327-e5b543b0edb9",
   "metadata": {},
   "source": [
    "**Overview**\n",
    "* Load train and eval datasets from TFRecords created in the `01-movielens-data-prep.ipynb` notebook\n",
    "* training examples represent historical (previously collected) interaction data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd5b953-14c0-42ed-a511-77147a1bc0ac",
   "metadata": {},
   "source": [
    "### Read TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d0157c8-a04c-4dbd-b6d9-a1ede97687a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da0cdac-76af-4608-b70e-be7dbe0584b5",
   "metadata": {},
   "source": [
    "**Train data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c934c06-bf08-4c7f-b0cc-0de04ef3515c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://rec-bandits-v2-hybrid-vertex-bucket/data/train/ml-ratings-100k-train.tfrecord']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPLIT = \"train\" # \"train\" | \"val\"\n",
    "\n",
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7511e4d-bf81-4800-bde7-8b16dec9aeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([35.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'898'], dtype=object)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([885409515])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'681'], dtype=object)>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'marketing'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "train_dataset = train_dataset.map(data_utils.parse_tfrecord)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452750c1-46a0-4ee1-84d4-0c3b227de38f",
   "metadata": {},
   "source": [
    "**Val data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7b5376f-9438-4304-84aa-de09c30f5e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = \"val\"\n",
    "\n",
    "val_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        val_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "val_dataset = tf.data.TFRecordDataset(val_files)\n",
    "val_dataset = val_dataset.map(data_utils.parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8959967-522e-41c8-9a1b-050ca8bc191f",
   "metadata": {},
   "source": [
    "### get vocab\n",
    "\n",
    "**TODO:** \n",
    "* streamline vocab calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b9169bc-d6dc-497e-9dff-6ebb175282ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE_VOCABS: False\n"
     ]
    }
   ],
   "source": [
    "GENERATE_VOCABS = False\n",
    "\n",
    "print(f\"GENERATE_VOCABS: {GENERATE_VOCABS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3ccf137-7a72-42e7-aa89-3c81a99cf40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab...\n",
      "Downloaded vocab from: gs://rec-bandits-v2-hybrid-vertex-bucket/vocabs/vocab_dict.pkl\n",
      "\n",
      "'movie_id'\n",
      "'user_id'\n",
      "'user_occupation_text'\n",
      "'movie_genres'\n",
      "'bucketized_user_age'\n",
      "'max_timestamp'\n",
      "'min_timestamp'\n",
      "'timestamp_buckets'\n"
     ]
    }
   ],
   "source": [
    "if not GENERATE_VOCABS:\n",
    "\n",
    "    EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{VOCAB_SUBDIR}/{VOCAB_FILENAME}'\n",
    "    print(f\"Downloading vocab...\")\n",
    "    \n",
    "    os.system(f'gsutil -q cp {EXISTING_VOCAB_FILE} .')\n",
    "    print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "    filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "    vocab_dict = pkl.load(filehandler)\n",
    "    filehandler.close()\n",
    "    \n",
    "    for key in vocab_dict.keys():\n",
    "        pprint(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccaef62-882a-46ff-a1b1-3837e69fdf74",
   "metadata": {},
   "source": [
    "## helper functions\n",
    "\n",
    "**TODO:**\n",
    "* modularize in a train_utils or similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138a295-2b0d-4359-8496-af8552ec8cff",
   "metadata": {},
   "source": [
    "# [2] Preprocessing layers for global and arm features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e28c002-8d3a-4cf4-b69b-de56a6abab90",
   "metadata": {},
   "source": [
    "The preproccesing layers will ultimately feed the two sampling functions described below. These sampling functions will be used to create [trajectories](https://github.com/tensorflow/agents/blob/master/tf_agents/trajectories/trajectory.py#L36) (i.e., the training examples for our model)\n",
    "\n",
    "`global_context_sampling_fn`: \n",
    "* A function that outputs a random 1d array or list of ints or floats\n",
    "* This output is the global context. Its shape and type must be consistent across calls.\n",
    "\n",
    "`arm_context_sampling_fn`: \n",
    "* A function that outputs a random 1 array or list of ints or floats (same type as the output of `global_context_sampling_fn`). * This output is the per-arm context. Its shape must be consistent across calls.\n",
    "\n",
    "See `debug-and-learn-emb-models.ipynb` for more details and debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ea1f7-0621-44b8-b062-1f59b0964d72",
   "metadata": {},
   "source": [
    "## Global & Per-Arm feature embedding models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8d77956-635c-438a-916a-185eec52f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OOV_BUCKETS        = 1\n",
    "GLOBAL_EMBEDDING_SIZE  = 16\n",
    "MV_EMBEDDING_SIZE      = 32 #32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea335991-dcec-40b3-ba0d-a0fdfb9c2ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test emb models\n",
    "for i in range(1):\n",
    "    \n",
    "    iterator = iter(train_dataset.batch(1))\n",
    "    data = next(iterator)\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48178fff-491f-4f03-b156-7765d1fa9707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.perarm_features.emb_features.EmbeddingModel at 0x7f7c70449630>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.perarm_features import emb_features as emb_features\n",
    "\n",
    "embs = emb_features.EmbeddingModel(\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "903c63c5-2468-4443-bcb8-5ff6d69810dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL_DIM: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 3.7009981e-02, -1.6898096e-02,  4.5314934e-02, -1.5113793e-02,\n",
       "         2.7632117e-03,  1.5805587e-03,  2.7423564e-02, -2.3219360e-02,\n",
       "         6.9556348e-03,  3.7505258e-02,  2.6031051e-02,  1.8456314e-02,\n",
       "         3.8802251e-03,  6.6775195e-03,  2.8694633e-02, -1.8667430e-05,\n",
       "        -3.1055821e-02,  1.0944381e-03, -4.2600155e-02,  4.7536884e-02,\n",
       "         4.2206082e-02, -4.7131743e-02, -1.8705450e-02,  6.6944584e-03,\n",
       "         9.5512718e-04, -1.7883778e-02, -3.9803185e-02,  1.3982069e-02,\n",
       "        -2.6969945e-02,  1.9766454e-02,  4.6701018e-02, -4.5964777e-02,\n",
       "        -3.8683366e-02,  2.8513636e-02, -8.4408373e-04,  1.5011322e-02,\n",
       "         3.3784721e-02, -2.4461627e-02, -3.0746311e-04,  2.4721909e-02,\n",
       "         3.9633874e-02,  3.4498762e-02,  1.1066876e-02,  7.6824054e-03,\n",
       "        -4.9278405e-02, -6.4639002e-04, -2.1716559e-02, -4.4146933e-02,\n",
       "         1.5076134e-02, -4.1303001e-02,  4.8829447e-02, -2.2100830e-02,\n",
       "         2.8792668e-02, -2.4775302e-02,  1.9975055e-02,  3.3468429e-02,\n",
       "        -2.2024870e-02,  4.4820059e-02,  1.3596978e-02, -1.5863836e-02,\n",
       "        -2.4724806e-02, -4.2769384e-02,  7.4987486e-04,  2.9889081e-02]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_globals = embs._get_global_context_features(data)\n",
    "\n",
    "GLOBAL_DIM = test_globals.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"GLOBAL_DIM: {GLOBAL_DIM}\")\n",
    "\n",
    "test_globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebec4863-c614-4248-b680-8e29ec5b730d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER_ARM_DIM: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.03559345, -0.01525105, -0.02531418, -0.04638652, -0.0288747 ,\n",
       "        -0.04421199, -0.00595653, -0.04809248,  0.02926633,  0.01253483,\n",
       "        -0.03529322,  0.00162913, -0.01197536, -0.02089789, -0.03632528,\n",
       "        -0.02199461, -0.03394563, -0.02274028, -0.04403865, -0.01384576,\n",
       "         0.04682305, -0.0094864 , -0.00073633, -0.0034251 ,  0.01948516,\n",
       "        -0.03576181, -0.01925774,  0.02694848, -0.0432292 ,  0.02317141,\n",
       "         0.04082591, -0.04611867, -0.00282193, -0.03133779,  0.00327445,\n",
       "         0.0090205 ,  0.01476378,  0.01278779, -0.02893505,  0.0363538 ,\n",
       "        -0.00630312,  0.03344974, -0.03160264, -0.0278069 , -0.00934244,\n",
       "        -0.0006615 , -0.0414216 ,  0.02686173, -0.04022552, -0.00033848,\n",
       "         0.04973582, -0.00470967, -0.03291418, -0.03075739,  0.02261225,\n",
       "        -0.01273777,  0.02505549,  0.02921495, -0.0317992 , -0.03531791,\n",
       "        -0.01272005,  0.00488077, -0.03118508, -0.01596042]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arms = embs._get_per_arm_features(data)\n",
    "\n",
    "PER_ARM_DIM = test_arms.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"PER_ARM_DIM: {PER_ARM_DIM}\")\n",
    "\n",
    "test_arms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ff9baaf-987d-448d-a981-742a79b581e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE      : 128\n",
      "EVAL_BATCH_SIZE : 1\n",
      "NUM_ACTIONS     : 2\n",
      "GLOBAL_DIM      : 64\n",
      "PER_ARM_DIM     : 64\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE      = 128\n",
    "EVAL_BATCH_SIZE = 1\n",
    "\n",
    "NUM_ACTIONS     = 2 #this is kinda deceptive - \n",
    "#our approach is to learn by \"flashing\" one movie rating at a time per user context. \n",
    "#The n_actions = show/don't show the movie with one degree of freedom (n-1)\n",
    "\n",
    "\n",
    "print(f\"BATCH_SIZE      : {BATCH_SIZE}\")\n",
    "print(f\"EVAL_BATCH_SIZE : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"NUM_ACTIONS     : {NUM_ACTIONS}\")\n",
    "print(f\"GLOBAL_DIM      : {GLOBAL_DIM}\")\n",
    "print(f\"PER_ARM_DIM     : {PER_ARM_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeb4902-5bb9-4587-8d29-c01d78b006be",
   "metadata": {},
   "source": [
    "# [3] TensorSpecs\n",
    "\n",
    "* say you have a global observation spec of `[17]`. And you have two batch dimensions `[4, 5]`. Then your observation has to have the shape `[4, 5, 17]`\n",
    "* and then if you have arm_obs_spec with shape `[9, 13]`, then the arm obs shape has to be exactly `[4, 5, 9, 13]`\n",
    "* and this has to be true for every single tensor in your tensor nest\n",
    "* the first 2 dims are the outer dims that are the same for all tensors, the rest of the dimensions have to follow the spec for each tensor\n",
    "\n",
    "**TODO:**\n",
    "* explain relationship between Tensor Specs and their Tensor counterparts\n",
    "* highlight the errors, lessons learned, and utility functions to address these"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20eca8d-8c73-4ec8-9d0f-f2b428055ac2",
   "metadata": {},
   "source": [
    "## Implementing MAB with TF-Agents\n",
    "\n",
    "In TF-Agents, the *per-arm features* implementation differs from the *global-only* feature examples in the following aspects:\n",
    "* Reward is modeled not per-arm, but globally.\n",
    "* The arms are permutation invariant: it doesn’t matter which arm is arm 1 or arm 2, only their features.\n",
    "* One can have a different number of arms to choose from in every step (note that unspecified/dynamically changing number of arms will have a problem with XLA compatibility).\n",
    "\n",
    "When implementing per-arm features in TF-Bandits, the following details have to be discussed:\n",
    "* Observation spec and observations,\n",
    "* Action spec and actions,\n",
    "* Implementation of specific policies and agents.\n",
    "\n",
    "\n",
    "**TODO:**\n",
    "* outline the components and highlight their interactions, dependencies on eachother, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f68ebe8-116d-43b3-a6e1-4f5a5c7f4741",
   "metadata": {},
   "source": [
    "### Observation spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9c4746-d01b-4ca4-aa53-ab68da54d37a",
   "metadata": {},
   "source": [
    "**This observation spec allows the user to have a global observation of fixed dimension**, and an unspecified number of *per-arm* features (also of fixed dimension)\n",
    "* The actions output by the policy are still integers as usual, and they indicate which row of the arm-features it has chosen \n",
    "* The action spec must be a single integer value without boundaries:\n",
    "\n",
    "```python\n",
    "global_spec = tensor_spec.TensorSpec([GLOBAL_DIM], tf.float32)\n",
    "per_arm_spec = tensor_spec.TensorSpec([None, PER_ARM_DIM], tf.float32)\n",
    "observation_spec = {'global': global_spec, 'per_arm': per_arm_spec}\n",
    "\n",
    "action_spec = tensor_spec.TensorSpec((), tf.int32)\n",
    "```\n",
    "> Here the only difference compared to the action spec with global features only is that the tensor spec is not bounded, as we don’t know how many arms there will be at any time step\n",
    "\n",
    "**XLA compatibility:**\n",
    "* Since dynamic tensor shapes are not compatible with XLA, the number of arm features (and consequently, number of arms for a step) cannot be dynamic. \n",
    "* One workaround is to fix the maximum number of arms for a problem, then pad the arm features in steps with fewer arms, and use action masking to indicate how many arms are actually active.\n",
    "\n",
    "```python\n",
    "per_arm_spec = tensor_spec.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32)\n",
    "\n",
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=(), dtype=tf.int32, minimum = 0, maximum = NUM_ACTIONS - 1\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36bd3b33-635a-4274-8b9e-7172696ebb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_spec = {\n",
    "    'global': tf.TensorSpec([GLOBAL_DIM], tf.float32),\n",
    "    'per_arm': tf.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32) #excluding action dim here\n",
    "}\n",
    "observation_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a2da92-7db2-4f42-94a7-b7bad1c8fc42",
   "metadata": {},
   "source": [
    "### Action spec\n",
    "\n",
    "> The time_step_spec and action_spec are specifications for the input time step and the output action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5af42c7-18d7-480f-a7f3-d7da3f4840eb",
   "metadata": {},
   "source": [
    "```python\n",
    "    if (\n",
    "        not tensor_spec.is_bounded(action_spec)\n",
    "        or not tensor_spec.is_discrete(action_spec)\n",
    "        or action_spec.shape.rank > 1\n",
    "        or action_spec.shape.num_elements() != 1\n",
    "    ):\n",
    "      raise NotImplementedError(\n",
    "          'action_spec must be a BoundedTensorSpec of type int32 and shape (). '\n",
    "          'Found {}.'.format(action_spec)\n",
    "      )\n",
    "```\n",
    "\n",
    "* [src](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_base_policy.py#L97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "549a123c-349a-4103-b39a-4502f47d1e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=[], \n",
    "    dtype=tf.int32,\n",
    "    minimum=tf.constant(0),            \n",
    "    maximum=NUM_ACTIONS-1, # n degrees of freedom and will dictate the expected mean reward spec shape\n",
    "    name=\"action_spec\"\n",
    ")\n",
    "\n",
    "action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36ee2635-d4e3-4468-886c-ae9c62e3c80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_num_actions: 2\n",
      "predicted_rewards_mean: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n"
     ]
    }
   ],
   "source": [
    "expected_num_actions = action_spec.maximum - action_spec.minimum + 1\n",
    "print(f\"expected_num_actions: {expected_num_actions}\")\n",
    "\n",
    "predicted_rewards_mean = tensor_spec.TensorSpec([expected_num_actions])\n",
    "print(f\"predicted_rewards_mean: {predicted_rewards_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a51efce-9f1b-42d1-bec4-7b788e3fd7e0",
   "metadata": {},
   "source": [
    "### TimeStep spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95f05860-0fbf-4a5a-8273-9c81761e0ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec = ts.time_step_spec(\n",
    "    observation_spec = observation_spec, \n",
    "    # reward_spec = _reward_spec\n",
    ")\n",
    "time_step_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773b129a-6d19-4b3d-a2e7-e27070f57ac0",
   "metadata": {},
   "source": [
    "### Reward Spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48e89aa-e010-4bd9-a7e0-ad62dd4c5949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.specs import array_spec\n",
    "\n",
    "reward_spec = {\n",
    "    \"reward\": array_spec.ArraySpec(shape=[BATCH_SIZE], dtype=np.float32, name=\"reward\")\n",
    "}\n",
    "\n",
    "reward_tensor_spec = train_utils.from_spec(reward_spec)\n",
    "reward_tensor_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9181303-6565-45f5-a293-08d50420a805",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Inspect chosen arm features spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6b526a5-997c-4621-b21c-82c6ca1d6a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90d3e03e-619e-4fa4-b817-f02b4cefd6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(64,), dtype=tf.float32, name=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_arm_features_info = (\n",
    "  policy_utilities.create_chosen_arm_features_info_spec(\n",
    "      time_step_spec.observation,\n",
    "  )\n",
    ")\n",
    "chosen_arm_features_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc427092-beb7-4baf-a2e9-b8d10629182c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandit_policy_type = (\n",
    "    policy_utilities.BanditPolicyType.GREEDY\n",
    ")\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a4a2a33-c7d4-4d81-8082-80dfc3596741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandit_policy_type = (\n",
    "    policy_utilities.create_bandit_policy_type_tensor_spec(shape=[1])\n",
    ")\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e7ac02b-18bd-4519-92fe-5541b1a8ddc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_spec = policy_utilities.PerArmPolicyInfo(\n",
    "  predicted_rewards_mean=predicted_rewards_mean,\n",
    "  bandit_policy_type=bandit_policy_type,\n",
    "  chosen_arm_features=chosen_arm_features_info,\n",
    ")\n",
    "info_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21f28b9b-8183-495a-89b6-a01f30ea8637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PerArmPolicyInfo(\n",
    "#     log_probability=(), \n",
    "#     predicted_rewards_mean=TensorSpec(shape=(2,), \n",
    "#                                       dtype=tf.float32, name=None), \n",
    "#     multiobjective_scalarized_predicted_rewards_mean=(), \n",
    "#     predicted_rewards_optimistic=(), \n",
    "#     predicted_rewards_sampled=(), \n",
    "#     bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), \n",
    "#     chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9c197-ae9b-461d-8956-f078b929ac12",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [4] The Agent\n",
    "\n",
    "**Note** that contextual bandits form a special case of RL, where the actions taken by the agent do not alter the state of the environment \n",
    "\n",
    "> “Contextual” refers to the fact that the agent chooses among a set of actions while having knowledge of the context (environment observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81d6e84-688e-48c5-aea1-77df031348c9",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Agent & Network defined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aadb01-eb5c-4870-ae14-9e66624ba594",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Agent types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d075e8a6-11a9-4346-8725-3653fba4bac4",
   "metadata": {},
   "source": [
    "> `AGENT_TYPE = ['LinUCB', 'LinTS', 'epsGreedy', 'NeuralLinUCB']`\n",
    "\n",
    "LinearUCBAgent: (`LinUCB`) \n",
    "* An agent implementing the Linear UCB bandit algorithm ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/lin_ucb_agent/LinearUCBAgent))\n",
    "\n",
    "LinearThompsonSamplingAgent: (`LinTS`) \n",
    "* Implements the Linear Thompson Sampling Agent from the [paper](https://arxiv.org/abs/1209.3352): *Thompson Sampling for Contextual Bandits with Linear Payoffs* ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/linear_thompson_sampling_agent/LinearThompsonSamplingAgent))\n",
    "\n",
    "NeuralEpsilonGreedyAgent: (`epsGreedy`) \n",
    "* A neural network based epsilon greedy agent ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_epsilon_greedy_agent/NeuralEpsilonGreedyAgent))\n",
    "\n",
    "NeuralLinUCBAgent: (`NeuralLinUCB`) \n",
    "* An agent implementing the LinUCB algorithm on top of a neural network ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_linucb_agent/NeuralLinUCBAgent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b8e88e-c8ea-4193-a911-0d974ef3b1a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Network types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f547087d-5fad-4521-a584-cb46ce52897d",
   "metadata": {},
   "source": [
    "Which network architecture to use for the `epsGreedy` or `NeuralLinUCB` agents\n",
    "\n",
    "```\n",
    "NETWORK_TYPE = ['commontower', 'dotproduct']\n",
    "```\n",
    "\n",
    "**GlobalAndArmCommonTowerNetwork:** (`commontower`)\n",
    "* This network takes the output of the global and per-arm networks, and leads them through a common network, that in turn outputs reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "> * `COMMON_LAYERS` - Iterable of ints. Specifies the layers of the common tower\n",
    "* The network produced by this function can be used either in `GreedyRewardPredictionPolicy`, or `NeuralLinUCBPolicy`\n",
    "> * In the former case, the network must have `output_dim=1`, it is going to be an instance of `QNetwork`, and used in the policy as a reward prediction network\n",
    "> * In the latter case, the network will be an encoding network with its output consumed by a reward layer or a `LinUCB` method. The specified `output_dim` will be the encoding dimension\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmCommonTowerNetwork)\n",
    "\n",
    "**GlobalAndArmDotProductNetwork:** (`dotproduct`)\n",
    "* This network calculates the **dot product** of the output of the global and per-arm networks and returns them as reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmDotProductNetwork)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3dc270-deb5-4e96-8276-74759a06c318",
   "metadata": {},
   "source": [
    "### Agent config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbe29263-453d-405e-ac50-fee7f379f335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\n",
      "\n",
      "time_step_spec:  TimeStep(\n",
      "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
      "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n",
      "\n",
      "action_spec:  BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))\n",
      "\n",
      "observation_spec:  {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\")\n",
    "print(\"\\ntime_step_spec: \", time_step_spec)\n",
    "print(\"\\naction_spec: \", action_spec)\n",
    "print(\"\\nobservation_spec: \", observation_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d817bf2-1fa6-4bae-af90-745fad996b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'common_layers': [16, 8],\n",
      " 'encoding_dim': 1,\n",
      " 'epsilon': 0.01,\n",
      " 'eval_batch_size': 1,\n",
      " 'global_layers': [64, 32, 16],\n",
      " 'learning_rate': 0.05,\n",
      " 'model_type': 'epsGreedy',\n",
      " 'network_type': 'commontower',\n",
      " 'num_actions': 2,\n",
      " 'per_arm_layers': [64, 32, 16]}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Agents\n",
    "# ================================\n",
    "AGENT_TYPE      = 'epsGreedy' # 'LinUCB' | 'LinTS |, 'epsGreedy' | 'NeuralLinUCB'\n",
    "\n",
    "# Parameters for linear agents (LinUCB and LinTS).\n",
    "AGENT_ALPHA     = 0.1\n",
    "\n",
    "# Parameters for neural agents (NeuralEpsGreedy and NerualLinUCB).\n",
    "EPSILON         = 0.01\n",
    "LR              = 0.05\n",
    "\n",
    "# Parameters for NeuralLinUCB\n",
    "ENCODING_DIM    = 1\n",
    "EPS_PHASE_STEPS = 1000\n",
    "\n",
    "# ================================\n",
    "# Agent's Preprocess Network\n",
    "# ================================\n",
    "GLOBAL_LAYERS   = [64, 32, 16] # beginning should be of size: GLOBAL_DIM\n",
    "ARM_LAYERS      = [64, 32, 16] # beginning should be of size: PER_ARM_DIM\n",
    "COMMON_LAYERS   = [16, 8]\n",
    "\n",
    "NETWORK_TYPE    = \"commontower\" # 'commontower' | 'dotproduct'\n",
    "\n",
    "if AGENT_TYPE == 'NeuralLinUCB':\n",
    "    NETWORK_TYPE = 'commontower'\n",
    "    ENCODING_DIM = COMMON_LAYERS[-1]\n",
    "\n",
    "\n",
    "HPARAMS = {  # TODO - streamline and consolidate\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"eval_batch_size\" : EVAL_BATCH_SIZE,\n",
    "    \"num_actions\": NUM_ACTIONS,\n",
    "    \"model_type\": AGENT_TYPE,\n",
    "    \"network_type\": NETWORK_TYPE,\n",
    "    \"global_layers\": GLOBAL_LAYERS,\n",
    "    \"per_arm_layers\": ARM_LAYERS,\n",
    "    \"common_layers\": COMMON_LAYERS,\n",
    "    \"learning_rate\": LR,\n",
    "    \"epsilon\": EPSILON,\n",
    "    \"encoding_dim\": ENCODING_DIM\n",
    "}\n",
    "pprint(HPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2bf060bb-9880-40b4-8583-dd7a3f915bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent: NeuralEpsGreedyAgent\n",
      "Network: commontower\n"
     ]
    }
   ],
   "source": [
    "from src.perarm_features import agent_factory as agent_factory\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "    agent_type = AGENT_TYPE,\n",
    "    network_type = NETWORK_TYPE,\n",
    "    time_step_spec = time_step_spec,\n",
    "    action_spec = action_spec,\n",
    "    observation_spec=observation_spec,\n",
    "    global_layers = GLOBAL_LAYERS,\n",
    "    arm_layers = ARM_LAYERS,\n",
    "    common_layers = COMMON_LAYERS,\n",
    "    agent_alpha = AGENT_ALPHA,\n",
    "    learning_rate = LR,\n",
    "    epsilon = EPSILON,\n",
    "    train_step_counter = global_step,\n",
    "    output_dim = ENCODING_DIM,\n",
    "    eps_phase_steps = EPS_PHASE_STEPS,\n",
    "    summarize_grads_and_vars = True,\n",
    "    debug_summaries = True\n",
    ")\n",
    "      \n",
    "agent.initialize()\n",
    "print(f'agent: {agent.name}')\n",
    "\n",
    "# if network:\n",
    "#     print(f\"Network: {network}\")\n",
    "\n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {NETWORK_TYPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d77d1-a0b3-4898-adf0-0b32bfaf5bd7",
   "metadata": {},
   "source": [
    "#### Inspect the specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78ca56e7-a386-4bf4-8c2b-3d1665521f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41483f5a-bda6-48a4-9e1c-88d8b4afeea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.time_step_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f205716-f265-4ca8-81a7-4799de8f60a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(Trajectory(\n",
       "{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32)),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None)}),\n",
       " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None)),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.training_data_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d404dae-3cc3-4f81-962b-4641455ca4f2",
   "metadata": {},
   "source": [
    "# [5] Reward function\n",
    "\n",
    "> see `reward_factory.py`\n",
    "\n",
    "* Since we are training a policy with previously collected interaction data, we model the reward function from actual rewards\n",
    "* We will simply pass the `user_rating` (values 0-5) as rewards to the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "df9aecd6-d20a-48a7-9ead-4da3bbcfdae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _get_rewards(element):\n",
    "#     \"\"\"Calculates reward for the actions.\"\"\"\n",
    "\n",
    "#     def _calc_reward(x):\n",
    "#         \"\"\"Calculates reward for a single action.\"\"\"\n",
    "#         r0 = lambda: tf.constant(0.0)\n",
    "#         r1 = lambda: tf.constant(1.0)\n",
    "#         r2 = lambda: tf.constant(2.0)\n",
    "#         r3 = lambda: tf.constant(3.0)\n",
    "#         r4 = lambda: tf.constant(4.0)\n",
    "#         r5 = lambda: tf.constant(5.0)\n",
    "#         c1 = tf.equal(x, 1.0)\n",
    "#         c2 = tf.equal(x, 2.0)\n",
    "#         c3 = tf.equal(x, 3.0)\n",
    "#         c4 = tf.equal(x, 4.0)\n",
    "#         c5 = tf.equal(x, 5.0)\n",
    "#         return tf.case(\n",
    "#             [(c1, r1), (c2, r2), (c3, r3),(c4, r4),(c5, r5)], \n",
    "#             default=r0, exclusive=True\n",
    "#         )\n",
    "\n",
    "#     return tf.map_fn(\n",
    "#         fn=_calc_reward, \n",
    "#         elems=element['user_rating'], \n",
    "#         dtype=tf.float32\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac59703a-9a00-4eba-a3b7-45b21b738dd4",
   "metadata": {},
   "source": [
    "# [6] Trajectory function\n",
    "\n",
    "> This function will convert training samples from the TF Records to `trajectories` which the Agent interprets as training records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c16aa7b-f328-425e-b02e-a3fc7f200859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.perarm_features import reward_factory as reward_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f3605d9f-d239-4871-9a61-6e9b21f9c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _trajectory_fn(element): # hparams\n",
    "    \n",
    "    \"\"\"Converts a dataset element into a trajectory.\"\"\"\n",
    "    # global_features = _get_global_context_features(element)\n",
    "    # arm_features = _get_per_arm_features(element)\n",
    "    \n",
    "    global_features = embs._get_global_context_features(element)\n",
    "    arm_features = embs._get_per_arm_features(element)\n",
    "    \n",
    "    # Adds a time dimension.\n",
    "    arm_features = train_utils._add_outer_dimension(arm_features)\n",
    "\n",
    "    # obs spec\n",
    "    observation = {\n",
    "        bandit_spec_utils.GLOBAL_FEATURE_KEY:\n",
    "            train_utils._add_outer_dimension(global_features),\n",
    "    }\n",
    "\n",
    "    # reward = train_utils._add_outer_dimension(_get_rewards(element))\n",
    "    reward = train_utils._add_outer_dimension(reward_factory._get_rewards(element))\n",
    "\n",
    "    # To emit the predicted rewards in policy_info, we need to create dummy\n",
    "    # rewards to match the definition in TensorSpec for the ones specified in\n",
    "    # emit_policy_info set.\n",
    "    dummy_rewards = tf.zeros([HPARAMS['batch_size'], 1, HPARAMS['num_actions']])\n",
    "    policy_info = policy_utilities.PerArmPolicyInfo(\n",
    "        chosen_arm_features=arm_features,\n",
    "        # Pass dummy mean rewards here to match the model_spec for emitting\n",
    "        # mean rewards in policy info\n",
    "        predicted_rewards_mean=dummy_rewards,\n",
    "        bandit_policy_type=tf.zeros([HPARAMS['batch_size'], 1, 1], dtype=tf.int32)\n",
    "        # policy_utilities.create_bandit_policy_type_tensor_spec(shape=[1]) # policy_utilities.BanditPolicyType.GREEDY\n",
    "        # tf.zeros([batch_size, 1, 1], dtype=tf.int32)\n",
    "    )\n",
    "    \n",
    "    if HPARAMS['model_type'] == 'neural_ucb':\n",
    "        policy_info = policy_info._replace(\n",
    "            predicted_rewards_optimistic=dummy_rewards\n",
    "        )\n",
    "        \n",
    "    return trajectory.single_step(\n",
    "        observation=observation,\n",
    "        action=tf.zeros_like(\n",
    "            reward, dtype=tf.int32\n",
    "        ),  # Arm features are copied from policy info, put dummy zeros here\n",
    "        policy_info=policy_info,\n",
    "        reward=reward,\n",
    "        discount=tf.zeros_like(reward)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a0989c-5a06-4fd5-a12d-d92dbbe71a76",
   "metadata": {},
   "source": [
    "Inspect the trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "257791d1-c97c-48c0-bc92-f5a4737b6c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in train_dataset.batch(HPARAMS['batch_size']).take(1):\n",
    "    test_traj = _trajectory_fn(x)\n",
    "    \n",
    "# test_traj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d8994e-ce28-4fd9-8e3b-153451d014d9",
   "metadata": {},
   "source": [
    "#### Inspect shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a0e451f-1ad8-4af2-84d6-ddc5eaac0e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.action.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.action.shape: {test_traj.action.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52ed1767-12ce-404c-9caf-0974d55ec5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.discount.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.discount.shape: {test_traj.discount.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "033ff16b-0158-477f-835f-99deec636b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.reward.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.reward.shape: {test_traj.reward.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ee5aded7-7f9c-4a88-868c-f6ab58a0e704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.observation.shape: (128, 1, 64)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.observation.shape: {test_traj.observation['global'].shape}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcbfc9a-049e-49b9-b2a3-ecb9fd4b9964",
   "metadata": {},
   "source": [
    "# [7] Training the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13adc1ef-b50e-41a3-9b95-c128d0c55a2b",
   "metadata": {},
   "source": [
    "## set Vertex Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e861fb27-df24-4821-8448-cf1346b186f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : 02a-deep-bandits-local-rec-bandits-v2\n",
      "RUN_NAME          : run-20231114-181327\n",
      "\n",
      "BASE_OUTPUT_DIR   : gs://rec-bandits-v2-hybrid-vertex-bucket/02a-deep-bandits-local-rec-bandits-v2/run-20231114-181327\n",
      "LOG_DIR           : gs://rec-bandits-v2-hybrid-vertex-bucket/02a-deep-bandits-local-rec-bandits-v2/run-20231114-181327/logs\n",
      "ROOT_DIR          : gs://rec-bandits-v2-hybrid-vertex-bucket/02a-deep-bandits-local-rec-bandits-v2/run-20231114-181327/root\n",
      "ARTIFACTS_DIR     : gs://rec-bandits-v2-hybrid-vertex-bucket/02a-deep-bandits-local-rec-bandits-v2/run-20231114-181327/artifacts\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME   = f'02a-deep-bandits-local-{PREFIX}'\n",
    "\n",
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "# aiplatform.init(\n",
    "#     project=PROJECT_ID,\n",
    "#     location=REGION,\n",
    "#     experiment=EXPERIMENT_NAME\n",
    "# )\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de729bad-0bc9-429e-b4cb-7b24bf615aa1",
   "metadata": {},
   "source": [
    "### Create TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "db63052a-7eea-4982-964d-1f7ecab0665d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TB_RESOURCE_NAME : projects/934903580331/locations/us-central1/tensorboards/4978452311127883776\n",
      "TB display name  : 02a-deep-bandits-local-rec-bandits-v2-run-20231114-181327\n",
      "TB_ID            : 4978452311127883776\n"
     ]
    }
   ],
   "source": [
    "# # create new TB instance\n",
    "TENSORBOARD_DISPLAY_NAME=f\"{EXPERIMENT_NAME}-{RUN_NAME}\"\n",
    "\n",
    "tensorboard = aiplatform.Tensorboard.create(\n",
    "    display_name=TENSORBOARD_DISPLAY_NAME\n",
    "    , project=PROJECT_ID\n",
    "    , location=REGION\n",
    ")\n",
    "\n",
    "TB_RESOURCE_NAME = tensorboard.resource_name\n",
    "\n",
    "TB_ID = TB_RESOURCE_NAME.split('/')[-1]\n",
    "\n",
    "print(f\"TB_RESOURCE_NAME : {TB_RESOURCE_NAME}\")\n",
    "print(f\"TB display name  : {tensorboard.display_name}\")\n",
    "print(f\"TB_ID            : {TB_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9c891d27-d9d1-4e64-8981-1a1ae343c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME,\n",
    "    experiment_tensorboard=TB_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b7a5e4-efff-490b-b431-53037a2f4a16",
   "metadata": {},
   "source": [
    "## eval loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba0392e-90c8-4dc8-8df2-6d2af1ade490",
   "metadata": {},
   "source": [
    "> When evaluating an epsilon-greedy bandit, we need to remove those predictions that come from the `uniform_random` policy. We only want the predictions from the `GREEDY` policy, becasue we want to know how the model performs when it is actually used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b3d3c-75f7-46f4-9a1b-6329e419b7f5",
   "metadata": {},
   "source": [
    "## train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "97cfe7c3-4022-47a9-83c2-df0ad8a2abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.metrics import export_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.utils import common\n",
    "\n",
    "# from src.per_arm_rl import train_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bb7ffc-00df-4d46-857b-86c87b78f597",
   "metadata": {},
   "source": [
    "`agent.train(experience=...)`\n",
    "\n",
    "where `experience` is a batch of trajectories data in the form of a Trajectory. \n",
    "* The structure of experience must match that of `self.training_data_spec`. \n",
    "* All tensors in experience must be shaped [batch, time, ...] where time must be equal to self.train_step_length if that property is not None."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94d6d45-c71e-4fe4-9af8-af9a8bda4e4f",
   "metadata": {},
   "source": [
    "### logs & checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "049ee49b-3b1a-4b12-a360-15e759dff7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('metrics: [<tf_agents.metrics.tf_metrics.AverageReturnMetric object at '\n",
      " '0x7f7c18214880>]')\n",
      "setting checkpoint_manager: gs://rec-bandits-v2-hybrid-vertex-bucket/02a-deep-bandits-local-rec-bandits-v2/run-20231114-181327/root/chkpoint\n",
      "\n",
      "'saver: <tf_agents.policies.policy_saver.PolicySaver object at 0x7f7d3aa330d0>'\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    f\"{LOG_DIR}/train\", flush_millis=10 * 1000\n",
    ")\n",
    "# train_summary_writer.set_as_default()\n",
    "\n",
    "# eval_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "#     f\"{LOG_DIR}/eval\", flush_millis=10 * 1000\n",
    "# )\n",
    "# ====================================================\n",
    "# metrics\n",
    "# ====================================================\n",
    "step_metric = tf_metrics.EnvironmentSteps()\n",
    "metrics = [\n",
    "    # tf_metrics.NumberOfEpisodes(),\n",
    "    # tf_metrics.AverageEpisodeLengthMetric(batch_size=HPARAMS['batch_size']),\n",
    "    tf_metrics.AverageReturnMetric(batch_size=HPARAMS['batch_size'])\n",
    "]\n",
    "\n",
    "pprint(f\"metrics: {metrics}\")\n",
    "\n",
    "# ====================================================\n",
    "# get checkpoint manager\n",
    "# ====================================================\n",
    "CHKPOINT_DIR = f\"{ROOT_DIR}/chkpoint\"\n",
    "print(f\"setting checkpoint_manager: {CHKPOINT_DIR}\\n\")\n",
    "\n",
    "checkpoint_manager = train_utils.restore_and_get_checkpoint_manager(\n",
    "    root_dir=CHKPOINT_DIR, \n",
    "    agent=agent, \n",
    "    metrics=metrics, \n",
    "    step_metric=step_metric\n",
    ")\n",
    "# ====================================================\n",
    "# policy saver\n",
    "# ====================================================\n",
    "saver = policy_saver.PolicySaver(\n",
    "    agent.policy, \n",
    "    train_step=global_step\n",
    ")\n",
    "pprint(f\"saver: {saver}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d155f1f4-0d95-40a8-a37c-c608a64af803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x7f7c12fb5f60>,\n",
       " 'get_initial_state': <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x7f7c12fb4f10>,\n",
       " 'get_train_step': <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x7f7c12f18220>,\n",
       " 'get_metadata': <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x7f7c12f187c0>}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83683f4b-8a1a-44b9-8d5f-7ee3304c794c",
   "metadata": {},
   "source": [
    "### config\n",
    "\n",
    "* calculate train & val dataset sizes\n",
    "* define logging and chkpt intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f9432613-6583-4828-8a2a-dd939adbc3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_DATA_SIZE : 80000\n",
      "NUM_TRAIN_STEPS : 50\n",
      "EVAL_DATA_SIZE : 1000\n",
      "NUM_EVAL_STEPS : 1000\n",
      "CHKPT_INTERVAL: 50\n",
      "LOG_INTERVAL : 10\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA_SIZE = 80000          # len(list(train_dataset))\n",
    "NUM_TRAIN_STEPS = 50            # TRAIN_DATA_SIZE // HPARAMS['batch_size']\n",
    "\n",
    "EVAL_DATA_SIZE  = 1000          # len(list(val_dataset))\n",
    "NUM_EVAL_STEPS  = 1000           # EVAL_DATA_SIZE // HPARAMS['eval_batch_size']\n",
    "\n",
    "CHKPT_INTERVAL  = NUM_TRAIN_STEPS # // 5\n",
    "LOG_INTERVAL    = 10\n",
    "# EVAL_INTERVAL = NUM_TRAIN_STEPS // 2\n",
    "\n",
    "print(f\"TRAIN_DATA_SIZE : {TRAIN_DATA_SIZE}\")\n",
    "print(f\"NUM_TRAIN_STEPS : {NUM_TRAIN_STEPS}\")\n",
    "print(f\"EVAL_DATA_SIZE : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS : {NUM_EVAL_STEPS}\")\n",
    "print(f\"CHKPT_INTERVAL: {CHKPT_INTERVAL}\")\n",
    "print(f\"LOG_INTERVAL : {LOG_INTERVAL}\")\n",
    "# print(f\"EVAL_INTERVAL : {EVAL_INTERVAL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "379ffc65-4eec-4af1-8fd4-912ef65a9808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec={'bucketized_user_age': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'movie_genres': TensorSpec(shape=(None, 1), dtype=tf.int64, name=None), 'movie_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'timestamp': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'user_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_occupation_text': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_rating': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data\n",
    "train_ds_iterator = iter(train_dataset.batch(HPARAMS['batch_size']).repeat())\n",
    "\n",
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS[\"eval_batch_size\"])\n",
    "\n",
    "if NUM_EVAL_STEPS > 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)\n",
    "\n",
    "# eval_ds = eval_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "eval_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e498d7e3-d166-4e1d-94a5-f721de58694a",
   "metadata": {},
   "source": [
    "### run train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5dd64d98-7d5b-4474-a567-b42426d630a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.perarm_features import eval_perarm as eval_perarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "da4680f3-693b-4530-8e4d-88bc43036c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating pre-trained Agent...\n",
      "pre-train val_loss     : 15.350085258483887\n",
      "pre-train eval runtime : 0\n",
      "starting train loop...\n",
      "View your Tensorboard at https://us-central1.tensorboard.googleusercontent.com/experiment/projects+934903580331+locations+us-central1+tensorboards+4978452311127883776+experiments+02a-deep-bandits-local-rec-bandits-v2\n",
      "step = 0: train loss = 15.90999984741211\n",
      "step = 10: train loss = 10.869999885559082\n",
      "step = 20: train loss = 1.559999942779541\n",
      "step = 30: train loss = 1.4199999570846558\n",
      "step = 40: train loss = 1.1100000143051147\n",
      "train runtime_mins: 5\n",
      "saved trained policy to: gs://rec-bandits-v2-hybrid-vertex-bucket/02a-deep-bandits-local-rec-bandits-v2/run-20231114-181327/artifacts\n",
      "evaluating trained Agent...\n",
      "post-train val_loss     : 1.3096089363098145\n",
      "post-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "# agent.train = common.function(agent.train)\n",
    "\n",
    "list_o_loss = []\n",
    "\n",
    "# ====================================================\n",
    "# Evaluate the agent's policy once before training\n",
    "# ====================================================\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "pre_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "\n",
    "print(f\"evaluating pre-trained Agent...\")\n",
    "start_time = time.time()\n",
    "\n",
    "pre_val_loss, pre_preds, pre_tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = pre_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"pre-train val_loss     : {pre_val_loss}\")\n",
    "print(f\"pre-train eval runtime : {runtime_mins}\")\n",
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "print(f\"starting train loop...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Continuous monitoring\n",
    "aiplatform.start_upload_tb_log(\n",
    "    # tensorboard_id=TB_RESOURCE_NAME,\n",
    "    tensorboard_experiment_name=EXPERIMENT_NAME,\n",
    "    logdir=LOG_DIR,\n",
    "    experiment_display_name=EXPERIMENT_NAME,\n",
    "    run_name_prefix=RUN_NAME,\n",
    "    # description=description,\n",
    ")\n",
    "\n",
    "# for i in tqdm(range(NUM_TRAIN_STEPS)):\n",
    "for i in range(NUM_TRAIN_STEPS):\n",
    "    \n",
    "    with train_summary_writer.as_default():\n",
    "\n",
    "        data = next(train_ds_iterator)\n",
    "        trajectories = _trajectory_fn(data)\n",
    "\n",
    "        # All tensors in experience must be shaped [batch, time, ...] \n",
    "        step = agent.train_step_counter.numpy()\n",
    "        loss = agent.train(experience=trajectories)\n",
    "        list_o_loss.append(loss.loss.numpy())\n",
    "\n",
    "        train_utils._export_metrics_and_summaries(\n",
    "            step=i, \n",
    "            metrics=metrics\n",
    "        )\n",
    "\n",
    "        # print step loss\n",
    "        if step % LOG_INTERVAL == 0:\n",
    "            print(\n",
    "                'step = {0}: train loss = {1}'.format(\n",
    "                    step, round(loss.loss.numpy(), 2)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if i > 0 and i % CHKPT_INTERVAL == 0:\n",
    "            saver.save(os.path.join(CHKPOINT_DIR, 'policy_%d' % step_metric.result()))\n",
    "            print(f\"saved policy to: {CHKPOINT_DIR}\")\n",
    "            \n",
    "aiplatform.end_upload_tb_log()\n",
    "   \n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"train runtime_mins: {runtime_mins}\")\n",
    "\n",
    "saver.save(ARTIFACTS_DIR)\n",
    "print(f\"saved trained policy to: {ARTIFACTS_DIR}\")\n",
    "\n",
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = post_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "17b2b0d2-9795-4367-b57b-c331e94d1000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3096089"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb1ed8-f67b-4e7b-9cbc-70edd50e49ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate train job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff31fe28-2f05-499f-b1cc-505f3c9074e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### train loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "41937f9a-6c28-48d2-bc7c-bfe4372c7cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_o_loss)\n",
    "# plt.ylim([0, 10])\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e947e1-67f4-4205-99af-6921c6e9c896",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e0f77a33-0962-4af0-af97-cf05f895cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5d0509cb-0777-4d35-86c6-28c8acbcc793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-42977f71fe5f5f27\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-42977f71fe5f5f27\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=$LOG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc40143-30b1-479f-b9b1-fa4c07b1690e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [8] Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6c94a0-122f-4ba6-acef-5653a3cc7850",
   "metadata": {
    "tags": []
   },
   "source": [
    "## load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b1c382b5-e2e0-45a2-9c5f-ef2c468d0f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-deep-bandits-local-rec-bandits-v2/run-20231114-181327/artifacts\n"
     ]
    }
   ],
   "source": [
    "POLICY_URI = ARTIFACTS_DIR\n",
    "\n",
    "print(POLICY_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "68592d97-1272-4c6d-a4bd-43a6f7fe6c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f7c12fd3520>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910a06f-678f-4bfa-a132-10b885f871c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## get predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1762c936-3c49-4ec5-a9eb-4df5816dc888",
   "metadata": {},
   "source": [
    "TODO - explain bandit_policy_type()\n",
    "\n",
    "**UNIFORM Random policy:**\n",
    "```\n",
    "PolicyStep(action=array(1, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.637535 , 3.5557823], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([2], dtype=int32), chosen_arm_features=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)))\n",
    "```\n",
    "\n",
    "**GREEDY policy:**\n",
    "```\n",
    "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.8278818, 3.607565 ], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([ 0.04054676, -0.04735027,  0.02202327,  0.01276748, -0.01367382,\n",
    "       -0.04838754,  0.00104916, -0.01956806,  0.01028793, -0.00256665,\n",
    "       -0.04376553,  0.03900594,  0.02388967, -0.04016995, -0.04945569,\n",
    "       -0.04539652,  0.04423274, -0.04630332,  0.00390794,  0.03986299,\n",
    "       -0.0398974 ,  0.01655747, -0.0471294 , -0.00690235, -0.03643382,\n",
    "       -0.0437116 ,  0.04757959, -0.00991895,  0.0281055 , -0.04633433,\n",
    "        0.01897702, -0.00824345,  0.03232259, -0.04980658, -0.01144745,\n",
    "        0.01690939,  0.02536928,  0.03384003, -0.01558131,  0.04731432,\n",
    "        0.04579857, -0.03305101,  0.03521084, -0.03915765,  0.04927064,\n",
    "        0.04695194,  0.03792156,  0.040496  ,  0.02574866, -0.00665367,\n",
    "       -0.03839222, -0.01564004, -0.04710373,  0.03557512, -0.01392462,\n",
    "        0.01368621,  0.02792176, -0.01799218,  0.00246101,  0.02263175,\n",
    "        0.0170817 ,  0.01388383, -0.03048695,  0.01198485], dtype=float32)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "567f64e1-8149-4364-b561-1a9d12581b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aff30396-e0fd-4f43-acaa-6af8b20b12cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "SKIP_NUM = 10\n",
    "\n",
    "for x in eval_ds.skip(SKIP_NUM).take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    \n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "    \n",
    "    # rewards = _get_rewards(x)\n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2bcd1e82-168e-4df3-92bd-4cd34ecd3a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e58af9ab-f4da-4857-afe5-6b8de26ed0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.5269365, 3.5269365], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([ 0.04417836,  0.0042143 ,  0.01476171, -0.01075346, -0.03879399,\n",
       "       -0.03170788, -0.03070482, -0.03846798, -0.00567259, -0.0084719 ,\n",
       "        0.04563639,  0.04118444,  0.02316036,  0.0450406 ,  0.02278822,\n",
       "        0.04542594,  0.03308986, -0.02887132, -0.02882729,  0.01908516,\n",
       "        0.03522357,  0.01145212,  0.03982096,  0.00816395, -0.02409197,\n",
       "        0.0238    ,  0.00860413,  0.00408996,  0.00797186, -0.03680779,\n",
       "        0.00344441,  0.03594974,  0.01939248, -0.03228567, -0.04118516,\n",
       "        0.03787581, -0.02526753, -0.0171231 ,  0.00624735, -0.00253562,\n",
       "       -0.03594334, -0.00905972, -0.03110718, -0.00201958, -0.04955996,\n",
       "       -0.04063612,  0.01172239, -0.04141263, -0.01899779,  0.04338549,\n",
       "        0.04404794, -0.01299664, -0.00431968,  0.02721551, -0.01097221,\n",
       "       -0.01419299,  0.00993526, -0.00188918, -0.0051996 , -0.02858189,\n",
       "       -0.03889323, -0.01242021,  0.019621  , -0.01073984], dtype=float32)))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6676778c-d191-4b1e-a180-61f068b3b8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.5269365, 3.5269365], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([ 0.04417836,  0.0042143 ,  0.01476171, -0.01075346, -0.03879399,\n",
      "       -0.03170788, -0.03070482, -0.03846798, -0.00567259, -0.0084719 ,\n",
      "        0.04563639,  0.04118444,  0.02316036,  0.0450406 ,  0.02278822,\n",
      "        0.04542594,  0.03308986, -0.02887132, -0.02882729,  0.01908516,\n",
      "        0.03522357,  0.01145212,  0.03982096,  0.00816395, -0.02409197,\n",
      "        0.0238    ,  0.00860413,  0.00408996,  0.00797186, -0.03680779,\n",
      "        0.00344441,  0.03594974,  0.01939248, -0.03228567, -0.04118516,\n",
      "        0.03787581, -0.02526753, -0.0171231 ,  0.00624735, -0.00253562,\n",
      "       -0.03594334, -0.00905972, -0.03110718, -0.00201958, -0.04955996,\n",
      "       -0.04063612,  0.01172239, -0.04141263, -0.01899779,  0.04338549,\n",
      "        0.04404794, -0.01299664, -0.00431968,  0.02721551, -0.01097221,\n",
      "       -0.01419299,  0.00993526, -0.00188918, -0.0051996 , -0.02858189,\n",
      "       -0.03889323, -0.01242021,  0.019621  , -0.01073984], dtype=float32)))\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c85a0087-7388-4f03-9278-aace31121233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0, dtype=int32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a8266c7c-3688-46a5-a1c8-a63bb7146128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info.bandit_policy_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9712bc00-7ea0-4003-a3c7-81a0be5bc995",
   "metadata": {},
   "source": [
    "# [9] Prepare training application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f62966-123f-410e-9610-832f20566635",
   "metadata": {},
   "source": [
    "To scale this training in Vertex AI's managed training service, we need to package all our code into a python application\n",
    "\n",
    "* This means, we need to modularize all steps executed up until this point. For example, the training loop we ran above is further parameterized in `train_perarm.py`, which will be called from our `task.py` when we submit the job to Vertex AI\n",
    "* This training package will eventually be used to create a custom training image (more on that in `04b-build-training-image` notebook)\n",
    "* For additional details on preparing the training application for Vertex AI, check out [the documentation](https://cloud.google.com/vertex-ai/docs/training/code-requirements) and [this code example](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage2/get_started_vertex_training.ipynb) (which also has good, related commentary)\n",
    "\n",
    "**The remaining cells will repeat steps executed above**\n",
    "> we are just illustrating / validating that they are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1129ee41-b43c-4d5a-b656-cdac6b79688c",
   "metadata": {},
   "source": [
    "#### Vertex Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ef509680-4d19-4efa-9f01-21039e0d573b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : 02a-deep-bandits-local-rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "# using same experiment name \n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7ad98430-d836-40f1-8e4f-eb46f0c91fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : 02a-deep-bandits-local-rec-bandits-v2\n",
      "RUN_NAME          : run-20231114-182136\n",
      "\n",
      "BASE_OUTPUT_DIR   : gs://rec-bandits-v2-hybrid-vertex-bucket/02a-deep-bandits-local-rec-bandits-v2/run-20231114-182136\n",
      "LOG_DIR           : gs://rec-bandits-v2-hybrid-vertex-bucket/02a-deep-bandits-local-rec-bandits-v2/run-20231114-182136/logs\n",
      "ROOT_DIR          : gs://rec-bandits-v2-hybrid-vertex-bucket/02a-deep-bandits-local-rec-bandits-v2/run-20231114-182136/root\n",
      "ARTIFACTS_DIR     : gs://rec-bandits-v2-hybrid-vertex-bucket/02a-deep-bandits-local-rec-bandits-v2/run-20231114-182136/artifacts\n"
     ]
    }
   ],
   "source": [
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "# aiplatform.init(\n",
    "#     project=PROJECT_ID,\n",
    "#     location=REGION,\n",
    "#     experiment=EXPERIMENT_NAME\n",
    "# )\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83de7c4-f7c7-4290-b44a-9e9194bac882",
   "metadata": {},
   "source": [
    "### Create TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "17576ce0-727d-4297-a52d-f64fb75ca78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TB_RESOURCE_NAME : projects/934903580331/locations/us-central1/tensorboards/3163501661297573888\n",
      "TB display name  : 02a-deep-bandits-local-rec-bandits-v2-run-20231114-182136\n",
      "TB_ID            : 3163501661297573888\n"
     ]
    }
   ],
   "source": [
    "# # create new TB instance\n",
    "TENSORBOARD_DISPLAY_NAME=f\"{EXPERIMENT_NAME}-{RUN_NAME}\"\n",
    "\n",
    "tensorboard = aiplatform.Tensorboard.create(\n",
    "    display_name=TENSORBOARD_DISPLAY_NAME\n",
    "    , project=PROJECT_ID\n",
    "    , location=REGION\n",
    ")\n",
    "\n",
    "TB_RESOURCE_NAME = tensorboard.resource_name\n",
    "\n",
    "TB_ID = TB_RESOURCE_NAME.split('/')[-1]\n",
    "\n",
    "print(f\"TB_RESOURCE_NAME : {TB_RESOURCE_NAME}\")\n",
    "print(f\"TB display name  : {tensorboard.display_name}\")\n",
    "print(f\"TB_ID            : {TB_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "71d43cf9-db3f-437e-98ee-3791ac0c5e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME,\n",
    "    experiment_tensorboard=TB_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fbdecf78-94c5-4f8c-a6c0-86f2eace4663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: NeuralEpsGreedyAgent\n",
      "Network: commontower\n"
     ]
    }
   ],
   "source": [
    "# from src.perarm_features import agent_factory as agent_factory\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "    agent_type = AGENT_TYPE,\n",
    "    network_type = NETWORK_TYPE,\n",
    "    time_step_spec = time_step_spec,\n",
    "    action_spec = action_spec,\n",
    "    observation_spec=observation_spec,\n",
    "    global_layers = GLOBAL_LAYERS,\n",
    "    arm_layers = ARM_LAYERS,\n",
    "    common_layers = COMMON_LAYERS,\n",
    "    agent_alpha = AGENT_ALPHA,\n",
    "    learning_rate = LR,\n",
    "    epsilon = EPSILON,\n",
    "    train_step_counter = global_step,\n",
    "    output_dim = ENCODING_DIM,\n",
    "    eps_phase_steps = EPS_PHASE_STEPS,\n",
    "    summarize_grads_and_vars = True,\n",
    "    debug_summaries = True\n",
    ")\n",
    "\n",
    "print(f\"Agent: {agent.name}\")\n",
    "\n",
    "# if network:\n",
    "#     print(f\"Network: {network}\")\n",
    "\n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {NETWORK_TYPE}\")\n",
    "        \n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "108ed33c-d8ef-4524-97e9-ced9e01c154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHKPT_INTERVAL    : 200\n",
      "eval_batch_size   : 1\n",
      "EVAL_DATA_SIZE    : 1000\n",
      "NUM_EVAL_STEPS    : 100\n",
      "TOTAL_TRAIN_TAKE  : 10000\n"
     ]
    }
   ],
   "source": [
    "from src.perarm_features import train_perarm as train_perarm\n",
    "\n",
    "# train args\n",
    "TRAINING_LOOPS        = 150\n",
    "STEPS_PER_LOOP        = 1\n",
    "\n",
    "drop_arm_feature_fn   = None\n",
    "ASYNC_STEPS_PER_LOOP  = 1\n",
    "\n",
    "LOG_INTERVAL          = 10\n",
    "CHKPT_INTERVAL        = 200\n",
    "\n",
    "# eval args\n",
    "NUM_EVAL_STEPS = 100\n",
    "\n",
    "TOTAL_TRAIN_TAKE = 10000 #TRAINING_LOOPS * HPARAMS['batch_size']\n",
    "\n",
    "print(f\"CHKPT_INTERVAL    : {CHKPT_INTERVAL}\")\n",
    "print(f\"eval_batch_size   : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"EVAL_DATA_SIZE    : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS    : {NUM_EVAL_STEPS}\")\n",
    "print(f\"TOTAL_TRAIN_TAKE  : {TOTAL_TRAIN_TAKE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f66ff927-9a39-4abf-b247-845f0dc7721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS['eval_batch_size'])\n",
    "\n",
    "if NUM_EVAL_STEPS >= 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f6c98398-d545-4dcc-a71f-32249b5f0336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_files: ['gs://rec-bandits-v2-hybrid-vertex-bucket/data/train/ml-ratings-100k-train.tfrecord']\n",
      "train_ds_iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f77747e7160>\n",
      "setting checkpoint_manager: gs://rec-bandits-v2-hybrid-vertex-bucket/02a-deep-bandits-local-rec-bandits-v2/run-20231114-182136/root/chkpoint\n",
      "wrapping agent.train in tf-function\n",
      "starting_loop: 0\n",
      "starting train loop...\n",
      "step = 50: loss = 15.920000076293945\n",
      "step = 60: loss = 3.799999952316284\n",
      "step = 70: loss = 2.009999990463257\n",
      "step = 80: loss = 1.6100000143051147\n",
      "step = 90: loss = 1.0399999618530273\n",
      "step = 100: loss = 1.2699999809265137\n",
      "step = 110: loss = 1.3600000143051147\n",
      "step = 120: loss = 1.399999976158142\n",
      "step = 130: loss = 1.2999999523162842\n",
      "step = 140: loss = 1.2799999713897705\n",
      "step = 150: loss = 1.6399999856948853\n",
      "step = 160: loss = 1.2400000095367432\n",
      "step = 170: loss = 1.149999976158142\n",
      "step = 180: loss = 0.9700000286102295\n",
      "step = 190: loss = 1.1299999952316284\n",
      "runtime_mins: 38\n",
      "saved trained policy to: gs://rec-bandits-v2-hybrid-vertex-bucket/02a-deep-bandits-local-rec-bandits-v2/run-20231114-182136/artifacts\n",
      "complete train job in 38 minutes\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    f\"{LOG_DIR}\", flush_millis=10 * 1000\n",
    ")\n",
    "\n",
    "# # Continuous monitoring\n",
    "# aiplatform.start_upload_tb_log(\n",
    "#     # tensorboard_id=TB_RESOURCE_NAME,\n",
    "#     tensorboard_experiment_name=EXPERIMENT_NAME,\n",
    "#     logdir=LOG_DIR,\n",
    "#     experiment_display_name=EXPERIMENT_NAME,\n",
    "#     run_name_prefix=RUN_NAME,\n",
    "#     # description=description,\n",
    "# )\n",
    "\n",
    "#start the timer and training\n",
    "start_time = time.time()\n",
    "\n",
    "metric_results, agent = train_perarm.train_perarm(\n",
    "    agent = agent,\n",
    "    reward_spec = reward_tensor_spec,\n",
    "    epsilon = HPARAMS['epsilon'],\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    num_iterations = TRAINING_LOOPS,\n",
    "    steps_per_loop = STEPS_PER_LOOP,\n",
    "    num_eval_steps = NUM_EVAL_STEPS,\n",
    "    # data\n",
    "    batch_size = HPARAMS['batch_size'],\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    # functions\n",
    "    _trajectory_fn = _trajectory_fn,\n",
    "    # _run_bandit_eval_fn = _run_bandit_eval,\n",
    "    # train intervals\n",
    "    chkpt_interval = CHKPT_INTERVAL,\n",
    "    log_interval = LOG_INTERVAL,\n",
    "    # dirs\n",
    "    bucket_name = BUCKET_NAME,\n",
    "    data_dir_prefix_path = DATA_GCS_PREFIX,\n",
    "    log_dir = LOG_DIR,\n",
    "    model_dir = ARTIFACTS_DIR,\n",
    "    root_dir = ROOT_DIR,\n",
    "    async_steps_per_loop = ASYNC_STEPS_PER_LOOP,\n",
    "    resume_training_loops = False,\n",
    "    use_gpu = True,\n",
    "    use_tpu = False,\n",
    "    profiler = False,\n",
    "    global_step = global_step,\n",
    "    total_train_take = TOTAL_TRAIN_TAKE,\n",
    "    train_summary_writer = train_summary_writer\n",
    ")\n",
    "\n",
    "# aiplatform.end_upload_tb_log()\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"complete train job in {runtime_mins} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "177aa3ab-05b4-48f9-b434-9335bd9eb54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3140751"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(metric_results)\n",
    "metric_results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ba65417f-54e0-436e-b0d4-93cffb981ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(metric_results)\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61464938-a3e7-4ab0-9149-4a9124199dc1",
   "metadata": {},
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9108f8b6-7aea-48d6-a763-461b30671c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "083c2351-5ac8-4218-9bef-e249777aee97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e9c3af136862639a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e9c3af136862639a\");\n",
       "          const url = new URL(\"/proxy/6007/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=$LOG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7ba747-00d5-4908-8d0b-334ae9d2c791",
   "metadata": {},
   "source": [
    "#### eval trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5cf9366-d9cd-4c9d-951a-99a50877a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af82506e-95d7-4a4e-a821-e08512615db7",
   "metadata": {},
   "source": [
    "After training, our `agent.policy` is used as the deployment \"model\" that will generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6c82396a-7822-41fb-830f-1f6eb9c9b213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.epsilon_greedy_policy.EpsilonGreedyPolicy at 0x7f77747cc040>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_agent = agent.policy\n",
    "deployment_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f6706224-ef5b-4185-bde4-bccb7c8e7ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating trained Agent...\n",
      "post-train val_loss     : 1.4865119457244873\n",
      "post-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(deployment_agent, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = post_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f899120f-3706-4b72-8f2c-2169221dd66b",
   "metadata": {},
   "source": [
    "## Using Trained Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b0f691-860e-4853-928e-4c7ece714dd0",
   "metadata": {},
   "source": [
    "### load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ea029f73-0638-462a-8f00-54b05c54d69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-deep-bandits-local-rec-bandits-v2/run-20231114-182136/artifacts\n"
     ]
    }
   ],
   "source": [
    "POLICY_URI = ARTIFACTS_DIR\n",
    "\n",
    "print(POLICY_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "66d1d819-0152-437c-aefc-45ffd34d808a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-deep-bandits-local-rec-bandits-v2/run-20231114-182136/artifacts/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-deep-bandits-local-rec-bandits-v2/run-20231114-182136/artifacts/fingerprint.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-deep-bandits-local-rec-bandits-v2/run-20231114-182136/artifacts/policy_specs.pbtxt\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-deep-bandits-local-rec-bandits-v2/run-20231114-182136/artifacts/saved_model.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-deep-bandits-local-rec-bandits-v2/run-20231114-182136/artifacts/assets/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-deep-bandits-local-rec-bandits-v2/run-20231114-182136/artifacts/variables/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $POLICY_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6aad948e-e346-4da3-8cb2-747435c8dc4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f77744534c0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "483f8fa5-cbd1-4e3c-8e62-47f91f42e137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(), dtype=dtype('int32'), name='action_spec', minimum=0, maximum=1)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_policy.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8f658891-bc09-49b8-bc58-000a7926df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "SKIP_NUM = 10\n",
    "\n",
    "for x in eval_ds.skip(SKIP_NUM).take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    \n",
    "    # global_feat_infer = _get_global_context_features(x)\n",
    "    # arm_feat_infer = _get_per_arm_features(x)\n",
    "    \n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "    \n",
    "    # rewards = _get_rewards(x)\n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f515fcd0-2228-4f68-9ef9-665ce1fc3fb2",
   "metadata": {},
   "source": [
    "### view prediction response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6af4c297-d2e8-4f7b-bed5-e1da997dfe34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(1, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.3707776, 3.50277  ], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd58d4b-6749-4177-8342-83ee969408c9",
   "metadata": {},
   "source": [
    "#### chosen action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d49adbbb-f747-4e4c-b82d-df88373c644f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1, dtype=int32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd12013-1d12-4197-8254-cef9138df42c",
   "metadata": {},
   "source": [
    "#### Per Arm Policy Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d6126290-546b-4702-8a1e-91f18adb05c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.3707776, 3.50277  ], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f66961-ebb5-4ae5-8e6f-ad73114d8353",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
