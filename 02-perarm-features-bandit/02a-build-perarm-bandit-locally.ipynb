{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385307d6-2058-47ec-8da0-57f7ef5c43d6",
   "metadata": {},
   "source": [
    "# Train Bandits with per-arm features\n",
    "\n",
    "**Exploring linear and nonlinear** (e.g., those with neural network-based value functions) bandit methods for recommendations using TF-Agents\n",
    "\n",
    "> Neural linear bandits provide a nice way to leverage the representation power of deep learning and the bandit approach for uncertainty measure and efficient exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fd257-b98b-426a-a2cd-024429b014f1",
   "metadata": {},
   "source": [
    "## Load notebook config\n",
    "\n",
    "* use the prefix defined in `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f39c9d08-d118-4013-a47f-88450f49f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = 'mabv1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908f6b95-b539-4a9f-a836-840d26ea3b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"mabv1\"\n",
      "VERSION                  = \"v1\"\n",
      "\n",
      "BUCKET_NAME              = \"mabv1-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://mabv1-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://mabv1-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_ID      = \"hybrid-vertex.movielens_dataset_mabv1\"\n",
      "BIGQUERY_TABLE_ID        = \"hybrid-vertex.movielens_dataset_mabv1.training_dataset\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-mabv1\"\n",
      "IMAGE_NAME               = \"train-perarm-feats-v1\"\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-mabv1/train-perarm-feats-v1\"\n",
      "DOCKERNAME               = \"Dockerfile_perarm_feats\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c690a9-e2bd-4759-ba41-4e2469098aee",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d0dfe4-695c-4dd4-9f24-67f7488ce1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c669f1a1-1af7-4efb-ab2d-6bf3b3847991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from collections import defaultdict\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pickle as pkl\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "# from tf_agents.agents import TFAgent\n",
    "\n",
    "# from tf_agents.bandits.environments import stationary_stochastic_per_arm_py_environment as p_a_env\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "# from tf_agents.drivers import dynamic_step_driver\n",
    "# from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "# from tf_agents.bandits.agents import lin_ucb_agent\n",
    "# from tf_agents.bandits.agents import linear_thompson_sampling_agent as lin_ts_agent\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent\n",
    "from tf_agents.bandits.agents import neural_linucb_agent\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "from tf_agents.bandits.policies import policy_utilities\n",
    "\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# this repo\n",
    "from src.per_arm_rl import data_utils\n",
    "from src.per_arm_rl import data_config\n",
    "from src.per_arm_rl import train_utils as train_utils\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29e58dd7-ab2b-419f-9771-bf1e98db758b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4969d3e-1fc0-45db-8a69-aa6b342019de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "274e7f4a-1802-4946-888e-876638f5c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a866b1-85b9-43e6-9546-edfbbf886bce",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd5b953-14c0-42ed-a511-77147a1bc0ac",
   "metadata": {},
   "source": [
    "### Read TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d0157c8-a04c-4dbd-b6d9-a1ede97687a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da0cdac-76af-4608-b70e-be7dbe0584b5",
   "metadata": {},
   "source": [
    "**Train data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c934c06-bf08-4c7f-b0cc-0de04ef3515c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://mabv1-hybrid-vertex-bucket/data/train/ml-ratings-100k-train.tfrecord']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPLIT = \"train\" # \"train\" | \"val\"\n",
    "\n",
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7511e4d-bf81-4800-bde7-8b16dec9aeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([35.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'898'], dtype=object)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([885409515])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'681'], dtype=object)>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'marketing'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "train_dataset = train_dataset.map(data_utils.parse_tfrecord)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452750c1-46a0-4ee1-84d4-0c3b227de38f",
   "metadata": {},
   "source": [
    "**Val data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7b5376f-9438-4304-84aa-de09c30f5e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = \"val\"\n",
    "\n",
    "val_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        val_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "val_dataset = tf.data.TFRecordDataset(val_files)\n",
    "val_dataset = val_dataset.map(data_utils.parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8959967-522e-41c8-9a1b-050ca8bc191f",
   "metadata": {},
   "source": [
    "### get vocab\n",
    "\n",
    "**TODO:** \n",
    "* streamline vocab calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b9169bc-d6dc-497e-9dff-6ebb175282ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE_VOCABS: False\n"
     ]
    }
   ],
   "source": [
    "GENERATE_VOCABS = False\n",
    "\n",
    "print(f\"GENERATE_VOCABS: {GENERATE_VOCABS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3ccf137-7a72-42e7-aa89-3c81a99cf40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab...\n",
      "Downloaded vocab from: gs://mabv1-hybrid-vertex-bucket/vocabs/vocab_dict.pkl\n",
      "\n",
      "'movie_id'\n",
      "'user_id'\n",
      "'user_occupation_text'\n",
      "'movie_genres'\n",
      "'bucketized_user_age'\n",
      "'max_timestamp'\n",
      "'min_timestamp'\n",
      "'timestamp_buckets'\n"
     ]
    }
   ],
   "source": [
    "if not GENERATE_VOCABS:\n",
    "\n",
    "    EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{VOCAB_SUBDIR}/{VOCAB_FILENAME}'\n",
    "    print(f\"Downloading vocab...\")\n",
    "    \n",
    "    os.system(f'gsutil -q cp {EXISTING_VOCAB_FILE} .')\n",
    "    print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "    filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "    vocab_dict = pkl.load(filehandler)\n",
    "    filehandler.close()\n",
    "    \n",
    "    for key in vocab_dict.keys():\n",
    "        pprint(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccaef62-882a-46ff-a1b1-3837e69fdf74",
   "metadata": {},
   "source": [
    "## helper functions\n",
    "\n",
    "**TODO:**\n",
    "* modularize in a train_utils or similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b941063b-ad48-4817-aef0-9afa8a444632",
   "metadata": {},
   "source": [
    "# Multi-Armed Bandits (MAB) with Per-Arm Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28770b8d-836b-448d-8dd1-203d76fc6d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "\n",
    "nest = tf.nest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138a295-2b0d-4359-8496-af8552ec8cff",
   "metadata": {},
   "source": [
    "# [1] Preprocessing layers for global and arm features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e28c002-8d3a-4cf4-b69b-de56a6abab90",
   "metadata": {},
   "source": [
    "The preproccesing layers will ultimately feed the two sampling functions described below. These sampling functions will be used to create [trajectories](https://github.com/tensorflow/agents/blob/master/tf_agents/trajectories/trajectory.py#L36) (i.e., the training examples for our model)\n",
    "\n",
    "`global_context_sampling_fn`: \n",
    "* A function that outputs a random 1d array or list of ints or floats\n",
    "* This output is the global context. Its shape and type must be consistent across calls.\n",
    "\n",
    "`arm_context_sampling_fn`: \n",
    "* A function that outputs a random 1 array or list of ints or floats (same type as the output of `global_context_sampling_fn`). * This output is the per-arm context. Its shape must be consistent across calls.\n",
    "\n",
    "See `debug-and-learn-emb-models.ipynb` for more details and debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ea1f7-0621-44b8-b062-1f59b0964d72",
   "metadata": {},
   "source": [
    "## Global & Per-Arm feature embedding models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8d77956-635c-438a-916a-185eec52f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OOV_BUCKETS        = 1\n",
    "GLOBAL_EMBEDDING_SIZE  = 16\n",
    "MV_EMBEDDING_SIZE      = 32 #32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea335991-dcec-40b3-ba0d-a0fdfb9c2ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test emb models\n",
    "for i in range(1):\n",
    "    \n",
    "    iterator = iter(train_dataset.batch(1))\n",
    "    data = next(iterator)\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48178fff-491f-4f03-b156-7765d1fa9707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.perarm_features.emb_features.EmbeddingModel at 0x7f8065923d30>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.perarm_features import emb_features as emb_features\n",
    "\n",
    "embs = emb_features.EmbeddingModel(\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "903c63c5-2468-4443-bcb8-5ff6d69810dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL_DIM: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.04360062,  0.01982746,  0.01891526,  0.04281279,  0.02269018,\n",
       "         0.00387505, -0.04900599,  0.04374513,  0.03681452,  0.02024222,\n",
       "         0.01830291,  0.02012858,  0.04506693,  0.04232433, -0.02152755,\n",
       "        -0.01721226,  0.03328567, -0.00138474,  0.00352358,  0.0110101 ,\n",
       "         0.04030529,  0.01439022, -0.01870336,  0.01071304, -0.04736821,\n",
       "         0.0274067 ,  0.00630553, -0.0159687 ,  0.01835043, -0.03003188,\n",
       "        -0.03190394, -0.04196042, -0.0439741 ,  0.04753515, -0.04022377,\n",
       "        -0.01244865, -0.0199724 ,  0.00246739,  0.01671925, -0.04206381,\n",
       "        -0.0286765 ,  0.0287874 ,  0.04942865,  0.01062218, -0.01228283,\n",
       "         0.04885687,  0.02656486, -0.01058139,  0.01556465, -0.01392704,\n",
       "        -0.03072294,  0.03056374,  0.03475677,  0.01437903,  0.01958603,\n",
       "        -0.003898  ,  0.00886957, -0.00086032, -0.04408565, -0.03083476,\n",
       "         0.02320757,  0.02315737,  0.01511011,  0.02455762]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_globals = embs._get_global_context_features(data)\n",
    "\n",
    "GLOBAL_DIM = test_globals.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"GLOBAL_DIM: {GLOBAL_DIM}\")\n",
    "\n",
    "test_globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebec4863-c614-4248-b680-8e29ec5b730d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER_ARM_DIM: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 4.5921717e-02, -3.0820906e-02, -9.0945587e-03, -1.2761377e-02,\n",
       "         4.0599074e-02,  2.1070566e-02,  4.6412896e-02, -4.7335364e-02,\n",
       "        -2.5428049e-03, -4.0415108e-02, -4.8204578e-02,  3.1880271e-02,\n",
       "        -2.1806205e-02, -7.6606162e-03,  1.0447253e-02, -2.9734647e-02,\n",
       "         4.7389660e-02,  2.3952868e-02,  3.5765495e-02, -3.2432556e-02,\n",
       "         4.5502532e-02, -1.8103838e-02,  3.5875414e-02,  6.4315200e-03,\n",
       "         2.0111088e-02, -2.3654509e-02, -4.9144067e-02,  2.4117995e-02,\n",
       "         2.6095640e-02,  3.0670155e-02,  3.4437623e-02,  2.2393513e-02,\n",
       "        -8.0980770e-03,  2.5321338e-02,  3.2791983e-02,  3.8469400e-02,\n",
       "        -2.9426789e-02, -3.6091052e-02,  1.0568012e-02, -1.2845770e-03,\n",
       "         2.1276835e-02,  1.8856857e-02,  2.2199500e-02, -3.4929730e-02,\n",
       "        -1.3991989e-02,  1.0041308e-02, -3.3168398e-02, -4.7071077e-02,\n",
       "         1.9799918e-05,  2.0597223e-02, -1.6948581e-03,  3.3590581e-02,\n",
       "         1.5581455e-02,  4.2060290e-02, -1.0099292e-02,  3.5594452e-02,\n",
       "         1.9820224e-02, -4.7085345e-02,  1.9501273e-02, -3.5112619e-02,\n",
       "        -3.5179459e-02,  3.9893929e-02,  4.6212856e-02, -2.3693597e-02]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arms = embs._get_per_arm_features(data)\n",
    "\n",
    "PER_ARM_DIM = test_arms.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"PER_ARM_DIM: {PER_ARM_DIM}\")\n",
    "\n",
    "test_arms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac6836c-67b7-4fd4-917a-24ddad708edd",
   "metadata": {},
   "source": [
    "# [2] Implementing MAB with TF-Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1877c79c-b6c8-4048-b1ce-05f011e8d69e",
   "metadata": {},
   "source": [
    "In TF-Agents, the *per-arm features* implementation differs from the *global-only* feature examples in the following aspects:\n",
    "* Reward is modeled not per-arm, but globally.\n",
    "* The arms are permutation invariant: it doesn’t matter which arm is arm 1 or arm 2, only their features.\n",
    "* One can have a different number of arms to choose from in every step (note that unspecified/dynamically changing number of arms will have a problem with XLA compatibility).\n",
    "\n",
    "When implementing per-arm features in TF-Bandits, the following details have to be discussed:\n",
    "* Observation spec and observations,\n",
    "* Action spec and actions,\n",
    "* Implementation of specific policies and agents.\n",
    "\n",
    "\n",
    "**TODO:**\n",
    "* outline the components and highlight their interactions, dependencies on eachother, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ff9baaf-987d-448d-a981-742a79b581e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE      : 128\n",
      "EVAL_BATCH_SIZE : 1\n",
      "NUM_ACTIONS     : 2\n",
      "GLOBAL_DIM      : 64\n",
      "PER_ARM_DIM     : 64\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE      = 128\n",
    "EVAL_BATCH_SIZE = 1\n",
    "\n",
    "NUM_ACTIONS     = 2 #this is kinda deceptive - \n",
    "#our approach is to learn by \"flashing\" one movie rating at a time per user context. \n",
    "#The n_actions = show/don't show the movie with one degree of freedom (n-1)\n",
    "\n",
    "\n",
    "print(f\"BATCH_SIZE      : {BATCH_SIZE}\")\n",
    "print(f\"EVAL_BATCH_SIZE : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"NUM_ACTIONS     : {NUM_ACTIONS}\")\n",
    "print(f\"GLOBAL_DIM      : {GLOBAL_DIM}\")\n",
    "print(f\"PER_ARM_DIM     : {PER_ARM_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeb4902-5bb9-4587-8d29-c01d78b006be",
   "metadata": {},
   "source": [
    "## Tensor Specs\n",
    "\n",
    "* say you have a global observation spec of `[17]`. And you have two batch dimensions `[4, 5]`. Then your observation has to have the shape `[4, 5, 17]`\n",
    "* and then if you have arm_obs_spec with shape `[9, 13]`, then the arm obs shape has to be exactly `[4, 5, 9, 13]`\n",
    "* and this has to be true for every single tensor in your tensor nest\n",
    "* the first 2 dims are the outer dims that are the same for all tensors, the rest of the dimensions have to follow the spec for each tensor\n",
    "\n",
    "**TODO:**\n",
    "* explain relationship between Tensor Specs and their Tensor counterparts\n",
    "* highlight the errors, lessons learned, and utility functions to address these"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f68ebe8-116d-43b3-a6e1-4f5a5c7f4741",
   "metadata": {},
   "source": [
    "### Observation spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9c4746-d01b-4ca4-aa53-ab68da54d37a",
   "metadata": {},
   "source": [
    "**This observation spec allows the user to have a global observation of fixed dimension**, and an unspecified number of *per-arm* features (also of fixed dimension)\n",
    "* The actions output by the policy are still integers as usual, and they indicate which row of the arm-features it has chosen \n",
    "* The action spec must be a single integer value without boundaries:\n",
    "\n",
    "```python\n",
    "global_spec = tensor_spec.TensorSpec([GLOBAL_DIM], tf.float32)\n",
    "per_arm_spec = tensor_spec.TensorSpec([None, PER_ARM_DIM], tf.float32)\n",
    "observation_spec = {'global': global_spec, 'per_arm': per_arm_spec}\n",
    "\n",
    "action_spec = tensor_spec.TensorSpec((), tf.int32)\n",
    "```\n",
    "> Here the only difference compared to the action spec with global features only is that the tensor spec is not bounded, as we don’t know how many arms there will be at any time step\n",
    "\n",
    "**XLA compatibility:**\n",
    "* Since dynamic tensor shapes are not compatible with XLA, the number of arm features (and consequently, number of arms for a step) cannot be dynamic. \n",
    "* One workaround is to fix the maximum number of arms for a problem, then pad the arm features in steps with fewer arms, and use action masking to indicate how many arms are actually active.\n",
    "\n",
    "```python\n",
    "per_arm_spec = tensor_spec.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32)\n",
    "\n",
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=(), dtype=tf.int32, minimum = 0, maximum = NUM_ACTIONS - 1\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36bd3b33-635a-4274-8b9e-7172696ebb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_spec = {\n",
    "    'global': tf.TensorSpec([GLOBAL_DIM], tf.float32),\n",
    "    'per_arm': tf.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32) #excluding action dim here\n",
    "}\n",
    "observation_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a2da92-7db2-4f42-94a7-b7bad1c8fc42",
   "metadata": {},
   "source": [
    "### Action spec\n",
    "\n",
    "> The time_step_spec and action_spec are specifications for the input time step and the output action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5af42c7-18d7-480f-a7f3-d7da3f4840eb",
   "metadata": {},
   "source": [
    "```python\n",
    "    if (\n",
    "        not tensor_spec.is_bounded(action_spec)\n",
    "        or not tensor_spec.is_discrete(action_spec)\n",
    "        or action_spec.shape.rank > 1\n",
    "        or action_spec.shape.num_elements() != 1\n",
    "    ):\n",
    "      raise NotImplementedError(\n",
    "          'action_spec must be a BoundedTensorSpec of type int32 and shape (). '\n",
    "          'Found {}.'.format(action_spec)\n",
    "      )\n",
    "```\n",
    "\n",
    "* [src](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_base_policy.py#L97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "549a123c-349a-4103-b39a-4502f47d1e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=[], \n",
    "    dtype=tf.int32,\n",
    "    minimum=tf.constant(0),            \n",
    "    maximum=NUM_ACTIONS-1, # n degrees of freedom and will dictate the expected mean reward spec shape\n",
    "    name=\"action_spec\"\n",
    ")\n",
    "\n",
    "action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36ee2635-d4e3-4468-886c-ae9c62e3c80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_num_actions: 2\n",
      "predicted_rewards_mean: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n"
     ]
    }
   ],
   "source": [
    "expected_num_actions = action_spec.maximum - action_spec.minimum + 1\n",
    "print(f\"expected_num_actions: {expected_num_actions}\")\n",
    "\n",
    "predicted_rewards_mean = tensor_spec.TensorSpec([expected_num_actions])\n",
    "print(f\"predicted_rewards_mean: {predicted_rewards_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a51efce-9f1b-42d1-bec4-7b788e3fd7e0",
   "metadata": {},
   "source": [
    "### TimeStep spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95f05860-0fbf-4a5a-8273-9c81761e0ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec = ts.time_step_spec(\n",
    "    observation_spec = observation_spec, \n",
    "    # reward_spec = _reward_spec\n",
    ")\n",
    "time_step_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9181303-6565-45f5-a293-08d50420a805",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Inspect chosen arm features spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6b526a5-997c-4621-b21c-82c6ca1d6a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90d3e03e-619e-4fa4-b817-f02b4cefd6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(64,), dtype=tf.float32, name=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_arm_features_info = (\n",
    "  policy_utilities.create_chosen_arm_features_info_spec(\n",
    "      time_step_spec.observation,\n",
    "  )\n",
    ")\n",
    "chosen_arm_features_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc427092-beb7-4baf-a2e9-b8d10629182c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - dont understand this\n",
    "bandit_policy_type = (\n",
    "    policy_utilities.BanditPolicyType.GREEDY\n",
    ")\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a4a2a33-c7d4-4d81-8082-80dfc3596741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - dont understand this\n",
    "bandit_policy_type = (\n",
    "    policy_utilities.create_bandit_policy_type_tensor_spec(shape=[1])\n",
    ")\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e7ac02b-18bd-4519-92fe-5541b1a8ddc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_spec = policy_utilities.PerArmPolicyInfo(\n",
    "  predicted_rewards_mean=predicted_rewards_mean,\n",
    "  bandit_policy_type=bandit_policy_type,\n",
    "  chosen_arm_features=chosen_arm_features_info,\n",
    ")\n",
    "info_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9c197-ae9b-461d-8956-f078b929ac12",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The Agent\n",
    "\n",
    "**Note** that contextual bandits form a special case of RL, where the actions taken by the agent do not alter the state of the environment \n",
    "\n",
    "> “Contextual” refers to the fact that the agent chooses among a set of actions while having knowledge of the context (environment observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81d6e84-688e-48c5-aea1-77df031348c9",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Agent & Network defined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aadb01-eb5c-4870-ae14-9e66624ba594",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Agent types**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d075e8a6-11a9-4346-8725-3653fba4bac4",
   "metadata": {},
   "source": [
    "> `AGENT_TYPE = ['LinUCB', 'LinTS', 'epsGreedy', 'NeuralLinUCB']`\n",
    "\n",
    "LinearUCBAgent: (`LinUCB`) \n",
    "* An agent implementing the Linear UCB bandit algorithm ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/lin_ucb_agent/LinearUCBAgent))\n",
    "\n",
    "LinearThompsonSamplingAgent: (`LinTS`) \n",
    "* Implements the Linear Thompson Sampling Agent from the [paper](https://arxiv.org/abs/1209.3352): *Thompson Sampling for Contextual Bandits with Linear Payoffs* ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/linear_thompson_sampling_agent/LinearThompsonSamplingAgent))\n",
    "\n",
    "NeuralEpsilonGreedyAgent: (`epsGreedy`) \n",
    "* A neural network based epsilon greedy agent ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_epsilon_greedy_agent/NeuralEpsilonGreedyAgent))\n",
    "\n",
    "NeuralLinUCBAgent: (`NeuralLinUCB`) \n",
    "* An agent implementing the LinUCB algorithm on top of a neural network ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_linucb_agent/NeuralLinUCBAgent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b8e88e-c8ea-4193-a911-0d974ef3b1a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Network types**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f547087d-5fad-4521-a584-cb46ce52897d",
   "metadata": {},
   "source": [
    "Which network architecture to use for the `epsGreedy` or `NeuralLinUCB` agents\n",
    "\n",
    "```\n",
    "NETWORK_TYPE = ['commontower', 'dotproduct']\n",
    "```\n",
    "\n",
    "**GlobalAndArmCommonTowerNetwork:** (`commontower`)\n",
    "* This network takes the output of the global and per-arm networks, and leads them through a common network, that in turn outputs reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "> * `COMMON_LAYERS` - Iterable of ints. Specifies the layers of the common tower\n",
    "* The network produced by this function can be used either in `GreedyRewardPredictionPolicy`, or `NeuralLinUCBPolicy`\n",
    "> * In the former case, the network must have `output_dim=1`, it is going to be an instance of `QNetwork`, and used in the policy as a reward prediction network\n",
    "> * In the latter case, the network will be an encoding network with its output consumed by a reward layer or a `LinUCB` method. The specified `output_dim` will be the encoding dimension\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmCommonTowerNetwork)\n",
    "\n",
    "**GlobalAndArmDotProductNetwork:** (`dotproduct`)\n",
    "* This network calculates the **dot product** of the output of the global and per-arm networks and returns them as reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmDotProductNetwork)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3dc270-deb5-4e96-8276-74759a06c318",
   "metadata": {},
   "source": [
    "### Agent config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbe29263-453d-405e-ac50-fee7f379f335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\n",
      "\n",
      "time_step_spec:  TimeStep(\n",
      "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
      "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n",
      "\n",
      "action_spec:  BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))\n",
      "\n",
      "observation_spec:  {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\")\n",
    "print(\"\\ntime_step_spec: \", time_step_spec)\n",
    "print(\"\\naction_spec: \", action_spec)\n",
    "print(\"\\nobservation_spec: \", observation_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d817bf2-1fa6-4bae-af90-745fad996b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'common_layers': [16, 8],\n",
      " 'epsilon': 0.01,\n",
      " 'eval_batch_size': 1,\n",
      " 'global_layers': [64, 32, 16],\n",
      " 'learning_rate': 0.05,\n",
      " 'model_type': 'epsGreedy',\n",
      " 'network_type': 'commontower',\n",
      " 'num_actions': 2,\n",
      " 'per_arm_layers': [64, 32, 16]}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Agents\n",
    "# ================================\n",
    "AGENT_TYPE      = 'epsGreedy' # 'LinUCB' | 'LinTS |, 'epsGreedy' | 'NeuralLinUCB'\n",
    "\n",
    "# Parameters for linear agents (LinUCB and LinTS).\n",
    "AGENT_ALPHA     = 0.1\n",
    "\n",
    "# Parameters for neural agents (NeuralEpsGreedy and NerualLinUCB).\n",
    "EPSILON         = 0.01\n",
    "LR              = 0.05\n",
    "\n",
    "# Parameters for NeuralLinUCB\n",
    "ENCODING_DIM    = 1\n",
    "EPS_PHASE_STEPS = 1000\n",
    "\n",
    "# ================================\n",
    "# Agent's Preprocess Network\n",
    "# ================================\n",
    "NETWORK_TYPE    = \"commontower\" # 'commontower' | 'dotproduct'\n",
    "\n",
    "if AGENT_TYPE == 'NeuralLinUCB':\n",
    "    NETWORK_TYPE = 'commontower'\n",
    "    \n",
    "GLOBAL_LAYERS   = [64, 32, 16]\n",
    "ARM_LAYERS      = [64, 32, 16]\n",
    "COMMON_LAYERS   = [16, 8]\n",
    "\n",
    "HPARAMS = {  # TODO - streamline and consolidate\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"eval_batch_size\" : EVAL_BATCH_SIZE,\n",
    "    \"num_actions\": NUM_ACTIONS,\n",
    "    \"model_type\": AGENT_TYPE,\n",
    "    \"network_type\": NETWORK_TYPE,\n",
    "    \"global_layers\": GLOBAL_LAYERS,\n",
    "    \"per_arm_layers\": ARM_LAYERS,\n",
    "    \"common_layers\": COMMON_LAYERS,\n",
    "    \"learning_rate\": LR,\n",
    "    \"epsilon\": EPSILON,\n",
    "}\n",
    "pprint(HPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2bf060bb-9880-40b4-8583-dd7a3f915bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent: NeuralEpsGreedyAgent\n",
      "Network: commontower\n"
     ]
    }
   ],
   "source": [
    "from src.perarm_features import agent_factory as agent_factory\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "    agent_type = AGENT_TYPE,\n",
    "    network_type = NETWORK_TYPE,\n",
    "    time_step_spec = time_step_spec,\n",
    "    action_spec = action_spec,\n",
    "    observation_spec=observation_spec,\n",
    "    global_layers = GLOBAL_LAYERS,\n",
    "    arm_layers = ARM_LAYERS,\n",
    "    common_layers = COMMON_LAYERS,\n",
    "    agent_alpha = AGENT_ALPHA,\n",
    "    learning_rate = LR,\n",
    "    epsilon = EPSILON,\n",
    "    train_step_counter = global_step,\n",
    "    output_dim = ENCODING_DIM,\n",
    "    eps_phase_steps = EPS_PHASE_STEPS,\n",
    ")\n",
    "      \n",
    "agent.initialize()\n",
    "print(f'agent: {agent.name}')\n",
    "\n",
    "# if network:\n",
    "#     print(f\"Network: {network}\")\n",
    "\n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {NETWORK_TYPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d77d1-a0b3-4898-adf0-0b32bfaf5bd7",
   "metadata": {},
   "source": [
    "#### tmp - debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78ca56e7-a386-4bf4-8c2b-3d1665521f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41483f5a-bda6-48a4-9e1c-88d8b4afeea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.time_step_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f205716-f265-4ca8-81a7-4799de8f60a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(Trajectory(\n",
       "{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32)),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None)}),\n",
       " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None)),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.training_data_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d404dae-3cc3-4f81-962b-4641455ca4f2",
   "metadata": {},
   "source": [
    "## Reward function\n",
    "\n",
    "> see `reward_factory.py`\n",
    "\n",
    "**TODO:**\n",
    "* explain how to translate reward to this common recommendation objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df9aecd6-d20a-48a7-9ead-4da3bbcfdae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _get_rewards(element):\n",
    "#     \"\"\"Calculates reward for the actions.\"\"\"\n",
    "\n",
    "#     def _calc_reward(x):\n",
    "#         \"\"\"Calculates reward for a single action.\"\"\"\n",
    "#         r0 = lambda: tf.constant(0.0)\n",
    "#         r1 = lambda: tf.constant(1.0)\n",
    "#         r2 = lambda: tf.constant(2.0)\n",
    "#         r3 = lambda: tf.constant(3.0)\n",
    "#         r4 = lambda: tf.constant(4.0)\n",
    "#         r5 = lambda: tf.constant(5.0)\n",
    "#         c1 = tf.equal(x, 1.0)\n",
    "#         c2 = tf.equal(x, 2.0)\n",
    "#         c3 = tf.equal(x, 3.0)\n",
    "#         c4 = tf.equal(x, 4.0)\n",
    "#         c5 = tf.equal(x, 5.0)\n",
    "#         return tf.case(\n",
    "#             [(c1, r1), (c2, r2), (c3, r3),(c4, r4),(c5, r5)], \n",
    "#             default=r0, exclusive=True\n",
    "#         )\n",
    "\n",
    "#     return tf.map_fn(\n",
    "#         fn=_calc_reward, \n",
    "#         elems=element['user_rating'], \n",
    "#         dtype=tf.float32\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac59703a-9a00-4eba-a3b7-45b21b738dd4",
   "metadata": {},
   "source": [
    "## Trajectory function\n",
    "\n",
    "**parking lot**\n",
    "* does trajectory fn need concept of `dummy_chosen_arm_features`, similar to [this](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_base_policy.py#L297)\n",
    "\n",
    "```python\n",
    "      dummy_chosen_arm_features = tf.nest.map_structure(\n",
    "          lambda obs: tf.zeros_like(obs[:, 0, ...]),\n",
    "          time_step.observation[bandit_spec_utils.PER_ARM_FEATURE_KEY],\n",
    "      )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c16aa7b-f328-425e-b02e-a3fc7f200859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.perarm_features import reward_factory as reward_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3605d9f-d239-4871-9a61-6e9b21f9c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _trajectory_fn(element): # hparams\n",
    "    \n",
    "    \"\"\"Converts a dataset element into a trajectory.\"\"\"\n",
    "    # global_features = _get_global_context_features(element)\n",
    "    # arm_features = _get_per_arm_features(element)\n",
    "    \n",
    "    global_features = embs._get_global_context_features(element)\n",
    "    arm_features = embs._get_per_arm_features(element)\n",
    "    \n",
    "    # Adds a time dimension.\n",
    "    arm_features = train_utils._add_outer_dimension(arm_features)\n",
    "\n",
    "    # obs spec\n",
    "    observation = {\n",
    "        bandit_spec_utils.GLOBAL_FEATURE_KEY:\n",
    "            train_utils._add_outer_dimension(global_features),\n",
    "    }\n",
    "\n",
    "    # reward = train_utils._add_outer_dimension(_get_rewards(element))\n",
    "    reward = train_utils._add_outer_dimension(reward_factory._get_rewards(element))\n",
    "\n",
    "    # To emit the predicted rewards in policy_info, we need to create dummy\n",
    "    # rewards to match the definition in TensorSpec for the ones specified in\n",
    "    # emit_policy_info set.\n",
    "    dummy_rewards = tf.zeros([HPARAMS['batch_size'], 1, HPARAMS['num_actions']])\n",
    "    policy_info = policy_utilities.PerArmPolicyInfo(\n",
    "        chosen_arm_features=arm_features,\n",
    "        # Pass dummy mean rewards here to match the model_spec for emitting\n",
    "        # mean rewards in policy info\n",
    "        predicted_rewards_mean=dummy_rewards,\n",
    "        bandit_policy_type=tf.zeros([HPARAMS['batch_size'], 1, 1], dtype=tf.int32)\n",
    "        # policy_utilities.create_bandit_policy_type_tensor_spec(shape=[1]) # policy_utilities.BanditPolicyType.GREEDY\n",
    "        # tf.zeros([batch_size, 1, 1], dtype=tf.int32)\n",
    "    )\n",
    "    \n",
    "    if HPARAMS['model_type'] == 'neural_ucb':\n",
    "        policy_info = policy_info._replace(\n",
    "            predicted_rewards_optimistic=dummy_rewards\n",
    "        )\n",
    "        \n",
    "    return trajectory.single_step(\n",
    "        observation=observation,\n",
    "        action=tf.zeros_like(\n",
    "            reward, dtype=tf.int32\n",
    "        ),  # Arm features are copied from policy info, put dummy zeros here\n",
    "        policy_info=policy_info,\n",
    "        reward=reward,\n",
    "        discount=tf.zeros_like(reward)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a0989c-5a06-4fd5-a12d-d92dbbe71a76",
   "metadata": {},
   "source": [
    "Inspect the trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "257791d1-c97c-48c0-bc92-f5a4737b6c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in train_dataset.batch(HPARAMS['batch_size']).take(1):\n",
    "    test_traj = _trajectory_fn(x)\n",
    "    \n",
    "# test_traj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d8994e-ce28-4fd9-8e3b-153451d014d9",
   "metadata": {},
   "source": [
    "#### tmp - debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a0e451f-1ad8-4af2-84d6-ddc5eaac0e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.action.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.action.shape: {test_traj.action.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52ed1767-12ce-404c-9caf-0974d55ec5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.discount.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.discount.shape: {test_traj.discount.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "033ff16b-0158-477f-835f-99deec636b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.reward.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.reward.shape: {test_traj.reward.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee5aded7-7f9c-4a88-868c-f6ab58a0e704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.observation.shape: (128, 1, 64)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.observation.shape: {test_traj.observation['global'].shape}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcbfc9a-049e-49b9-b2a3-ecb9fd4b9964",
   "metadata": {},
   "source": [
    "# [3] Training the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13adc1ef-b50e-41a3-9b95-c128d0c55a2b",
   "metadata": {},
   "source": [
    "## set Vertex Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e861fb27-df24-4821-8448-cf1346b186f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : mab-local-classy-v1\n",
      "RUN_NAME          : run-20230830-193203\n",
      "\n",
      "BASE_OUTPUT_DIR   : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230830-193203\n",
      "LOG_DIR           : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230830-193203/logs\n",
      "ROOT_DIR          : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230830-193203/root\n",
      "ARTIFACTS_DIR     : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230830-193203/artifacts\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME   = f'mab-local-classy-v1'\n",
    "\n",
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b7a5e4-efff-490b-b431-53037a2f4a16",
   "metadata": {},
   "source": [
    "## eval loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba0392e-90c8-4dc8-8df2-6d2af1ade490",
   "metadata": {},
   "source": [
    "> When evaluating an epsilon-greedy bandit, we need to remove those predictions that come from the `uniform_random` policy. We only want the predictions from the `GREEDY` policy, becasue we want to know how the model performs when it is actually used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b3d3c-75f7-46f4-9a1b-6329e419b7f5",
   "metadata": {},
   "source": [
    "## train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "97cfe7c3-4022-47a9-83c2-df0ad8a2abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.metrics import export_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.utils import common\n",
    "\n",
    "# from src.per_arm_rl import train_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bb7ffc-00df-4d46-857b-86c87b78f597",
   "metadata": {},
   "source": [
    "`agent.train(experience=...)`\n",
    "\n",
    "where `experience` is a batch of trajectories data in the form of a Trajectory. \n",
    "* The structure of experience must match that of `self.training_data_spec`. \n",
    "* All tensors in experience must be shaped [batch, time, ...] where time must be equal to self.train_step_length if that property is not None."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94d6d45-c71e-4fe4-9af8-af9a8bda4e4f",
   "metadata": {},
   "source": [
    "### logs & checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "049ee49b-3b1a-4b12-a360-15e759dff7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('metrics: [<tf_agents.metrics.tf_metrics.AverageReturnMetric object at '\n",
      " '0x7f8065922920>]')\n",
      "setting checkpoint_manager: gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230830-193203/root/chkpoint\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    f\"{LOG_DIR}/train\", flush_millis=10 * 1000\n",
    ")\n",
    "# train_summary_writer.set_as_default()\n",
    "\n",
    "# eval_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "#     f\"{LOG_DIR}/eval\", flush_millis=10 * 1000\n",
    "# )\n",
    "# ====================================================\n",
    "# metrics\n",
    "# ====================================================\n",
    "step_metric = tf_metrics.EnvironmentSteps()\n",
    "metrics = [\n",
    "    # tf_metrics.NumberOfEpisodes(),\n",
    "    # tf_metrics.AverageEpisodeLengthMetric(batch_size=HPARAMS['batch_size']),\n",
    "    tf_metrics.AverageReturnMetric(batch_size=HPARAMS['batch_size'])\n",
    "]\n",
    "\n",
    "pprint(f\"metrics: {metrics}\")\n",
    "\n",
    "# ====================================================\n",
    "# get checkpoint manager\n",
    "# ====================================================\n",
    "CHKPOINT_DIR = f\"{ROOT_DIR}/chkpoint\"\n",
    "print(f\"setting checkpoint_manager: {CHKPOINT_DIR}\")\n",
    "\n",
    "checkpoint_manager = train_utils.restore_and_get_checkpoint_manager(\n",
    "    root_dir=CHKPOINT_DIR, \n",
    "    agent=agent, \n",
    "    metrics=metrics, \n",
    "    step_metric=step_metric\n",
    ")\n",
    "# ====================================================\n",
    "# policy saver\n",
    "# ====================================================\n",
    "saver = policy_saver.PolicySaver(\n",
    "    agent.policy, \n",
    "    train_step=global_step\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83683f4b-8a1a-44b9-8d5f-7ee3304c794c",
   "metadata": {},
   "source": [
    "### config\n",
    "\n",
    "* calculate train & val dataset sizes\n",
    "* define logging and chkpt intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9432613-6583-4828-8a2a-dd939adbc3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_DATA_SIZE : 80000\n",
      "NUM_TRAIN_STEPS : 150\n",
      "EVAL_DATA_SIZE : 1000\n",
      "NUM_EVAL_STEPS : 1000\n",
      "CHKPT_INTERVAL: 150\n",
      "LOG_INTERVAL : 10\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA_SIZE = 80000          # len(list(train_dataset))\n",
    "NUM_TRAIN_STEPS = 150            # TRAIN_DATA_SIZE // HPARAMS['batch_size']\n",
    "\n",
    "EVAL_DATA_SIZE  = 1000          # len(list(val_dataset))\n",
    "NUM_EVAL_STEPS  = 1000           # EVAL_DATA_SIZE // HPARAMS['eval_batch_size']\n",
    "\n",
    "CHKPT_INTERVAL  = NUM_TRAIN_STEPS # // 5\n",
    "LOG_INTERVAL    = 10\n",
    "# EVAL_INTERVAL = NUM_TRAIN_STEPS // 2\n",
    "\n",
    "print(f\"TRAIN_DATA_SIZE : {TRAIN_DATA_SIZE}\")\n",
    "print(f\"NUM_TRAIN_STEPS : {NUM_TRAIN_STEPS}\")\n",
    "print(f\"EVAL_DATA_SIZE : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS : {NUM_EVAL_STEPS}\")\n",
    "print(f\"CHKPT_INTERVAL: {CHKPT_INTERVAL}\")\n",
    "print(f\"LOG_INTERVAL : {LOG_INTERVAL}\")\n",
    "# print(f\"EVAL_INTERVAL : {EVAL_INTERVAL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "379ffc65-4eec-4af1-8fd4-912ef65a9808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec={'bucketized_user_age': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'movie_genres': TensorSpec(shape=(None, 1), dtype=tf.int64, name=None), 'movie_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'timestamp': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'user_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_occupation_text': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_rating': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data\n",
    "train_ds_iterator = iter(train_dataset.batch(HPARAMS['batch_size']).repeat())\n",
    "\n",
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS[\"eval_batch_size\"])\n",
    "\n",
    "if NUM_EVAL_STEPS > 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)\n",
    "\n",
    "# eval_ds = eval_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "eval_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e498d7e3-d166-4e1d-94a5-f721de58694a",
   "metadata": {},
   "source": [
    "### run train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5dd64d98-7d5b-4474-a567-b42426d630a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.perarm_features import eval_perarm as eval_perarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "da4680f3-693b-4530-8e4d-88bc43036c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating pre-trained Agent...\n",
      "pre-train val_loss     : 15.336288452148438\n",
      "pre-train eval runtime : 0\n",
      "starting train loop...\n",
      "step = 0: train loss = 15.899999618530273\n",
      "step = 10: train loss = 12.359999656677246\n",
      "step = 20: train loss = 8.489999771118164\n",
      "step = 30: train loss = 3.2899999618530273\n",
      "step = 40: train loss = 1.3899999856948853\n",
      "step = 50: train loss = 1.4299999475479126\n",
      "step = 60: train loss = 1.7200000286102295\n",
      "step = 70: train loss = 1.4500000476837158\n",
      "step = 80: train loss = 1.3200000524520874\n",
      "step = 90: train loss = 1.3200000524520874\n",
      "step = 100: train loss = 1.559999942779541\n",
      "step = 110: train loss = 1.350000023841858\n",
      "step = 120: train loss = 1.1399999856948853\n",
      "step = 130: train loss = 1.0099999904632568\n",
      "step = 140: train loss = 1.1100000143051147\n",
      "train runtime_mins: 1\n",
      "saved trained policy to: gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230830-193203/artifacts\n",
      "evaluating trained Agent...\n",
      "post-train val_loss     : 1.334463357925415\n",
      "post-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "# agent.train = common.function(agent.train)\n",
    "\n",
    "list_o_loss = []\n",
    "\n",
    "# ====================================================\n",
    "# Evaluate the agent's policy once before training\n",
    "# ====================================================\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "pre_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "\n",
    "print(f\"evaluating pre-trained Agent...\")\n",
    "start_time = time.time()\n",
    "\n",
    "pre_val_loss, pre_preds, pre_tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = pre_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"pre-train val_loss     : {pre_val_loss}\")\n",
    "print(f\"pre-train eval runtime : {runtime_mins}\")\n",
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "print(f\"starting train loop...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# for i in tqdm(range(NUM_TRAIN_STEPS)):\n",
    "for i in range(NUM_TRAIN_STEPS):\n",
    "    \n",
    "    with train_summary_writer.as_default():\n",
    "\n",
    "        data = next(train_ds_iterator)\n",
    "        trajectories = _trajectory_fn(data)\n",
    "\n",
    "        # All tensors in experience must be shaped [batch, time, ...] \n",
    "        step = agent.train_step_counter.numpy()\n",
    "        loss = agent.train(experience=trajectories)\n",
    "        list_o_loss.append(loss.loss.numpy())\n",
    "\n",
    "        train_utils._export_metrics_and_summaries(\n",
    "            step=i, \n",
    "            metrics=metrics\n",
    "        )\n",
    "\n",
    "        # print step loss\n",
    "        if step % LOG_INTERVAL == 0:\n",
    "            print(\n",
    "                'step = {0}: train loss = {1}'.format(\n",
    "                    step, round(loss.loss.numpy(), 2)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if i > 0 and i % CHKPT_INTERVAL == 0:\n",
    "            saver.save(os.path.join(CHKPOINT_DIR, 'policy_%d' % step_metric.result()))\n",
    "            print(f\"saved policy to: {CHKPOINT_DIR}\")\n",
    "   \n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"train runtime_mins: {runtime_mins}\")\n",
    "\n",
    "saver.save(ARTIFACTS_DIR)\n",
    "print(f\"saved trained policy to: {ARTIFACTS_DIR}\")\n",
    "\n",
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = post_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "17b2b0d2-9795-4367-b57b-c331e94d1000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3344634"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb1ed8-f67b-4e7b-9cbc-70edd50e49ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate train job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff31fe28-2f05-499f-b1cc-505f3c9074e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### train loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "41937f9a-6c28-48d2-bc7c-bfe4372c7cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_o_loss)\n",
    "# plt.ylim([0, 10])\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e947e1-67f4-4205-99af-6921c6e9c896",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TensorBoard\n",
    "\n",
    "<img src=\"imgs/getting_profiler.png\" \n",
    "     align=\"center\" \n",
    "     width=\"850\"\n",
    "     height=\"850\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e0f77a33-0962-4af0-af97-cf05f895cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5d0509cb-0777-4d35-86c6-28c8acbcc793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8d4467e6e523639d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8d4467e6e523639d\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=$LOG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc40143-30b1-479f-b9b1-fa4c07b1690e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [4] Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6c94a0-122f-4ba6-acef-5653a3cc7850",
   "metadata": {
    "tags": []
   },
   "source": [
    "## load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b1c382b5-e2e0-45a2-9c5f-ef2c468d0f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230830-193203/artifacts\n"
     ]
    }
   ],
   "source": [
    "POLICY_URI = ARTIFACTS_DIR\n",
    "\n",
    "print(POLICY_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "68592d97-1272-4c6d-a4bd-43a6f7fe6c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f7f685501c0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910a06f-678f-4bfa-a132-10b885f871c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## get predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1762c936-3c49-4ec5-a9eb-4df5816dc888",
   "metadata": {},
   "source": [
    "TODO - explain bandit_policy_type()\n",
    "\n",
    "**UNIFORM Random policy:**\n",
    "```\n",
    "PolicyStep(action=array(1, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.637535 , 3.5557823], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([2], dtype=int32), chosen_arm_features=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)))\n",
    "```\n",
    "\n",
    "**GREEDY policy:**\n",
    "```\n",
    "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.8278818, 3.607565 ], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([ 0.04054676, -0.04735027,  0.02202327,  0.01276748, -0.01367382,\n",
    "       -0.04838754,  0.00104916, -0.01956806,  0.01028793, -0.00256665,\n",
    "       -0.04376553,  0.03900594,  0.02388967, -0.04016995, -0.04945569,\n",
    "       -0.04539652,  0.04423274, -0.04630332,  0.00390794,  0.03986299,\n",
    "       -0.0398974 ,  0.01655747, -0.0471294 , -0.00690235, -0.03643382,\n",
    "       -0.0437116 ,  0.04757959, -0.00991895,  0.0281055 , -0.04633433,\n",
    "        0.01897702, -0.00824345,  0.03232259, -0.04980658, -0.01144745,\n",
    "        0.01690939,  0.02536928,  0.03384003, -0.01558131,  0.04731432,\n",
    "        0.04579857, -0.03305101,  0.03521084, -0.03915765,  0.04927064,\n",
    "        0.04695194,  0.03792156,  0.040496  ,  0.02574866, -0.00665367,\n",
    "       -0.03839222, -0.01564004, -0.04710373,  0.03557512, -0.01392462,\n",
    "        0.01368621,  0.02792176, -0.01799218,  0.00246101,  0.02263175,\n",
    "        0.0170817 ,  0.01388383, -0.03048695,  0.01198485], dtype=float32)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "567f64e1-8149-4364-b561-1a9d12581b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aff30396-e0fd-4f43-acaa-6af8b20b12cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "SKIP_NUM = 10\n",
    "\n",
    "for x in eval_ds.skip(SKIP_NUM).take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    \n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "    \n",
    "    # rewards = _get_rewards(x)\n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e58af9ab-f4da-4857-afe5-6b8de26ed0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.3399005, 3.323412 ], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([ 0.01546537,  0.02517445,  0.04813281,  0.04863187, -0.01263794,\n",
       "       -0.04036776, -0.02560099, -0.04624224, -0.02573046, -0.02562919,\n",
       "       -0.03024311,  0.01836432, -0.03906032,  0.01016109, -0.04428653,\n",
       "       -0.03649165, -0.03648589,  0.02401939,  0.00510664,  0.04678353,\n",
       "        0.03368597,  0.03238941, -0.02772726,  0.04693978,  0.02093353,\n",
       "       -0.00620302,  0.00255311, -0.01462817,  0.02184096,  0.03170126,\n",
       "        0.04973349, -0.00305836,  0.0095525 ,  0.04229852, -0.03174093,\n",
       "        0.03040392, -0.04191374,  0.03680452, -0.03654184,  0.01838854,\n",
       "       -0.00716392,  0.0309788 ,  0.02648148, -0.02690156,  0.02595301,\n",
       "        0.00505005,  0.01338584,  0.00843542,  0.00747017,  0.00810472,\n",
       "       -0.02204435,  0.01103472,  0.0089463 , -0.00903088,  0.02441616,\n",
       "       -0.04697675,  0.02787347,  0.00456388, -0.04420676, -0.01055621,\n",
       "       -0.04082857,  0.01326665, -0.03449193,  0.00264472], dtype=float32)))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6676778c-d191-4b1e-a180-61f068b3b8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.3399005, 3.323412 ], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([ 0.01546537,  0.02517445,  0.04813281,  0.04863187, -0.01263794,\n",
      "       -0.04036776, -0.02560099, -0.04624224, -0.02573046, -0.02562919,\n",
      "       -0.03024311,  0.01836432, -0.03906032,  0.01016109, -0.04428653,\n",
      "       -0.03649165, -0.03648589,  0.02401939,  0.00510664,  0.04678353,\n",
      "        0.03368597,  0.03238941, -0.02772726,  0.04693978,  0.02093353,\n",
      "       -0.00620302,  0.00255311, -0.01462817,  0.02184096,  0.03170126,\n",
      "        0.04973349, -0.00305836,  0.0095525 ,  0.04229852, -0.03174093,\n",
      "        0.03040392, -0.04191374,  0.03680452, -0.03654184,  0.01838854,\n",
      "       -0.00716392,  0.0309788 ,  0.02648148, -0.02690156,  0.02595301,\n",
      "        0.00505005,  0.01338584,  0.00843542,  0.00747017,  0.00810472,\n",
      "       -0.02204435,  0.01103472,  0.0089463 , -0.00903088,  0.02441616,\n",
      "       -0.04697675,  0.02787347,  0.00456388, -0.04420676, -0.01055621,\n",
      "       -0.04082857,  0.01326665, -0.03449193,  0.00264472], dtype=float32)))\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c85a0087-7388-4f03-9278-aace31121233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0, dtype=int32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a8266c7c-3688-46a5-a1c8-a63bb7146128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info.bandit_policy_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9712bc00-7ea0-4003-a3c7-81a0be5bc995",
   "metadata": {},
   "source": [
    "# [5] Prepare training application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f62966-123f-410e-9610-832f20566635",
   "metadata": {},
   "source": [
    "To scale this training in Vertex AI's managed training service, we need to package all our code into a python application\n",
    "\n",
    "* This means, we need to modularize all steps executed up until this point. For example, the training loop we ran above is further parameterized in `train_perarm.py`, which will be called from our `task.py` when we submit the job to Vertex AI\n",
    "* This training package will eventually be used to create a custom training image (more on that in `04b-build-training-image` notebook)\n",
    "* For additional details on preparing the training application for Vertex AI, check out [the documentation](https://cloud.google.com/vertex-ai/docs/training/code-requirements) and [this code example](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage2/get_started_vertex_training.ipynb) (which also has good, related commentary)\n",
    "\n",
    "**The remaining cells will repeat steps executed above**\n",
    "> we are just illustrating / validating that they are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1129ee41-b43c-4d5a-b656-cdac6b79688c",
   "metadata": {},
   "source": [
    "#### Vertex Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ef509680-4d19-4efa-9f01-21039e0d573b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : mab-local-classy-v1\n"
     ]
    }
   ],
   "source": [
    "# using same experiment name \n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7ad98430-d836-40f1-8e4f-eb46f0c91fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : mab-local-classy-v1\n",
      "RUN_NAME          : run-20230830-201328\n",
      "\n",
      "BASE_OUTPUT_DIR   : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230830-201328\n",
      "LOG_DIR           : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230830-201328/logs\n",
      "ROOT_DIR          : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230830-201328/root\n",
      "ARTIFACTS_DIR     : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230830-201328/artifacts\n"
     ]
    }
   ],
   "source": [
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fbdecf78-94c5-4f8c-a6c0-86f2eace4663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: NeuralEpsGreedyAgent\n",
      "Network: commontower\n"
     ]
    }
   ],
   "source": [
    "# from src.perarm_features import agent_factory as agent_factory\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "    agent_type = AGENT_TYPE,\n",
    "    network_type = NETWORK_TYPE,\n",
    "    time_step_spec = time_step_spec,\n",
    "    action_spec = action_spec,\n",
    "    observation_spec=observation_spec,\n",
    "    global_layers = GLOBAL_LAYERS,\n",
    "    arm_layers = ARM_LAYERS,\n",
    "    common_layers = COMMON_LAYERS,\n",
    "    agent_alpha = AGENT_ALPHA,\n",
    "    learning_rate = LR,\n",
    "    epsilon = EPSILON,\n",
    "    train_step_counter = global_step,\n",
    "    output_dim = ENCODING_DIM,\n",
    "    eps_phase_steps = EPS_PHASE_STEPS,\n",
    ")\n",
    "\n",
    "print(f\"Agent: {agent.name}\")\n",
    "\n",
    "# if network:\n",
    "#     print(f\"Network: {network}\")\n",
    "\n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {NETWORK_TYPE}\")\n",
    "        \n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "108ed33c-d8ef-4524-97e9-ced9e01c154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHKPT_INTERVAL    : 200\n",
      "eval_batch_size   : 1\n",
      "EVAL_DATA_SIZE    : 1000\n",
      "NUM_EVAL_STEPS    : 100\n",
      "TOTAL_TRAIN_TAKE  : 10000\n"
     ]
    }
   ],
   "source": [
    "from src.perarm_features import train_perarm as train_perarm\n",
    "\n",
    "# train args\n",
    "TRAINING_LOOPS        = 150\n",
    "STEPS_PER_LOOP        = 1\n",
    "\n",
    "drop_arm_feature_fn   = None\n",
    "ASYNC_STEPS_PER_LOOP  = 1\n",
    "\n",
    "LOG_INTERVAL          = 10\n",
    "CHKPT_INTERVAL        = 200\n",
    "\n",
    "# eval args\n",
    "NUM_EVAL_STEPS = 100\n",
    "\n",
    "TOTAL_TRAIN_TAKE = 10000 #TRAINING_LOOPS * HPARAMS['batch_size']\n",
    "\n",
    "print(f\"CHKPT_INTERVAL    : {CHKPT_INTERVAL}\")\n",
    "print(f\"eval_batch_size   : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"EVAL_DATA_SIZE    : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS    : {NUM_EVAL_STEPS}\")\n",
    "print(f\"TOTAL_TRAIN_TAKE  : {TOTAL_TRAIN_TAKE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f66ff927-9a39-4abf-b247-845f0dc7721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS['eval_batch_size'])\n",
    "\n",
    "if NUM_EVAL_STEPS >= 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f6c98398-d545-4dcc-a71f-32249b5f0336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distribution_strategy: <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f8065be0340>\n",
      "train_files: ['gs://mabv1-hybrid-vertex-bucket/data/train/ml-ratings-100k-train.tfrecord']\n",
      "train_ds_iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f7af815bdc0>\n",
      "setting checkpoint_manager: gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230830-201328/root/chkpoint\n",
      "wrapping agent.train in tf-function\n",
      "starting_loop: 0\n",
      "starting train loop...\n",
      "step = 150: loss = 15.920000076293945\n",
      "step = 160: loss = 12.699999809265137\n",
      "step = 170: loss = 10.59000015258789\n",
      "step = 180: loss = 9.319999694824219\n",
      "step = 190: loss = 6.670000076293945\n",
      "step = 200: loss = 5.179999828338623\n",
      "step = 210: loss = 3.3399999141693115\n",
      "step = 220: loss = 2.930000066757202\n",
      "step = 230: loss = 2.569999933242798\n",
      "step = 240: loss = 1.9600000381469727\n",
      "step = 250: loss = 1.5700000524520874\n",
      "step = 260: loss = 1.6100000143051147\n",
      "step = 270: loss = 1.2300000190734863\n",
      "step = 280: loss = 1.1299999952316284\n",
      "step = 290: loss = 1.190000057220459\n",
      "runtime_mins: 0\n",
      "saved trained policy to: gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230830-201328/artifacts\n",
      "complete train job in 1 minutes\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    f\"{LOG_DIR}/train\", flush_millis=10 * 1000\n",
    ")\n",
    "\n",
    "#start the timer and training\n",
    "start_time = time.time()\n",
    "\n",
    "metric_results, agent = train_perarm.train_perarm(\n",
    "    agent = agent,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    num_iterations = TRAINING_LOOPS,\n",
    "    steps_per_loop = STEPS_PER_LOOP,\n",
    "    num_eval_steps = NUM_EVAL_STEPS,\n",
    "    # data\n",
    "    batch_size = HPARAMS['batch_size'],\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    # functions\n",
    "    _trajectory_fn = _trajectory_fn,\n",
    "    # _run_bandit_eval_fn = _run_bandit_eval,\n",
    "    # train intervals\n",
    "    chkpt_interval = CHKPT_INTERVAL,\n",
    "    log_interval = LOG_INTERVAL,\n",
    "    # dirs\n",
    "    bucket_name = BUCKET_NAME,\n",
    "    data_dir_prefix_path = DATA_GCS_PREFIX,\n",
    "    log_dir = LOG_DIR,\n",
    "    model_dir = ARTIFACTS_DIR,\n",
    "    root_dir = ROOT_DIR,\n",
    "    async_steps_per_loop = ASYNC_STEPS_PER_LOOP,\n",
    "    resume_training_loops = False,\n",
    "    use_gpu = True,\n",
    "    use_tpu = False,\n",
    "    profiler = False,\n",
    "    global_step = global_step,\n",
    "    total_train_take = TOTAL_TRAIN_TAKE,\n",
    "    train_summary_writer = train_summary_writer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"complete train job in {runtime_mins} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "177aa3ab-05b4-48f9-b434-9335bd9eb54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4250201"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(metric_results)\n",
    "metric_results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ba65417f-54e0-436e-b0d4-93cffb981ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(metric_results)\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7ba747-00d5-4908-8d0b-334ae9d2c791",
   "metadata": {},
   "source": [
    "#### eval trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c5cf9366-d9cd-4c9d-951a-99a50877a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af82506e-95d7-4a4e-a821-e08512615db7",
   "metadata": {},
   "source": [
    "After training, our `agent.policy` is used as the deployment \"model\" that will generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6c82396a-7822-41fb-830f-1f6eb9c9b213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.epsilon_greedy_policy.EpsilonGreedyPolicy at 0x7f7af83b81c0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_agent = agent.policy\n",
    "deployment_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f6706224-ef5b-4185-bde4-bccb7c8e7ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating trained Agent...\n",
      "post-train val_loss     : 1.5412297248840332\n",
      "post-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(deployment_agent, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = post_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f899120f-3706-4b72-8f2c-2169221dd66b",
   "metadata": {},
   "source": [
    "## Using Trained Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b0f691-860e-4853-928e-4c7ece714dd0",
   "metadata": {},
   "source": [
    "### load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ea029f73-0638-462a-8f00-54b05c54d69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230830-201328/artifacts\n"
     ]
    }
   ],
   "source": [
    "POLICY_URI = ARTIFACTS_DIR\n",
    "\n",
    "print(POLICY_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "66d1d819-0152-437c-aefc-45ffd34d808a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230830-201328/artifacts/\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230830-201328/artifacts/fingerprint.pb\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230830-201328/artifacts/policy_specs.pbtxt\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230830-201328/artifacts/saved_model.pb\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230830-201328/artifacts/assets/\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230830-201328/artifacts/variables/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $POLICY_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6aad948e-e346-4da3-8cb2-747435c8dc4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f7a3df60d30>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "483f8fa5-cbd1-4e3c-8e62-47f91f42e137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(), dtype=dtype('int32'), name='action_spec', minimum=0, maximum=1)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_policy.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8f658891-bc09-49b8-bc58-000a7926df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "SKIP_NUM = 10\n",
    "\n",
    "for x in eval_ds.skip(SKIP_NUM).take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    \n",
    "    # global_feat_infer = _get_global_context_features(x)\n",
    "    # arm_feat_infer = _get_per_arm_features(x)\n",
    "    \n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "    \n",
    "    # rewards = _get_rewards(x)\n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f515fcd0-2228-4f68-9ef9-665ce1fc3fb2",
   "metadata": {},
   "source": [
    "### view prediction response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6af4c297-d2e8-4f7b-bed5-e1da997dfe34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.419865, 3.419865], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([ 0.01546537,  0.02517445,  0.04813281,  0.04863187, -0.01263794,\n",
       "       -0.04036776, -0.02560099, -0.04624224, -0.02573046, -0.02562919,\n",
       "       -0.03024311,  0.01836432, -0.03906032,  0.01016109, -0.04428653,\n",
       "       -0.03649165, -0.03648589,  0.02401939,  0.00510664,  0.04678353,\n",
       "        0.03368597,  0.03238941, -0.02772726,  0.04693978,  0.02093353,\n",
       "       -0.00620302,  0.00255311, -0.01462817,  0.02184096,  0.03170126,\n",
       "        0.04973349, -0.00305836,  0.0095525 ,  0.04229852, -0.03174093,\n",
       "        0.03040392, -0.04191374,  0.03680452, -0.03654184,  0.01838854,\n",
       "       -0.00716392,  0.0309788 ,  0.02648148, -0.02690156,  0.02595301,\n",
       "        0.00505005,  0.01338584,  0.00843542,  0.00747017,  0.00810472,\n",
       "       -0.02204435,  0.01103472,  0.0089463 , -0.00903088,  0.02441616,\n",
       "       -0.04697675,  0.02787347,  0.00456388, -0.04420676, -0.01055621,\n",
       "       -0.04082857,  0.01326665, -0.03449193,  0.00264472], dtype=float32)))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd58d4b-6749-4177-8342-83ee969408c9",
   "metadata": {},
   "source": [
    "#### chosen action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d49adbbb-f747-4e4c-b82d-df88373c644f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0, dtype=int32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd12013-1d12-4197-8254-cef9138df42c",
   "metadata": {},
   "source": [
    "#### Per Arm Policy Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d6126290-546b-4702-8a1e-91f18adb05c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.419865, 3.419865], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([ 0.01546537,  0.02517445,  0.04813281,  0.04863187, -0.01263794,\n",
       "       -0.04036776, -0.02560099, -0.04624224, -0.02573046, -0.02562919,\n",
       "       -0.03024311,  0.01836432, -0.03906032,  0.01016109, -0.04428653,\n",
       "       -0.03649165, -0.03648589,  0.02401939,  0.00510664,  0.04678353,\n",
       "        0.03368597,  0.03238941, -0.02772726,  0.04693978,  0.02093353,\n",
       "       -0.00620302,  0.00255311, -0.01462817,  0.02184096,  0.03170126,\n",
       "        0.04973349, -0.00305836,  0.0095525 ,  0.04229852, -0.03174093,\n",
       "        0.03040392, -0.04191374,  0.03680452, -0.03654184,  0.01838854,\n",
       "       -0.00716392,  0.0309788 ,  0.02648148, -0.02690156,  0.02595301,\n",
       "        0.00505005,  0.01338584,  0.00843542,  0.00747017,  0.00810472,\n",
       "       -0.02204435,  0.01103472,  0.0089463 , -0.00903088,  0.02441616,\n",
       "       -0.04697675,  0.02787347,  0.00456388, -0.04420676, -0.01055621,\n",
       "       -0.04082857,  0.01326665, -0.03449193,  0.00264472], dtype=float32))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f66961-ebb5-4ae5-8e6f-ad73114d8353",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
