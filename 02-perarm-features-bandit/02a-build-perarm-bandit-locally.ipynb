{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385307d6-2058-47ec-8da0-57f7ef5c43d6",
   "metadata": {},
   "source": [
    "# Train Bandits with per-arm features\n",
    "\n",
    "**Exploring linear and nonlinear** (e.g., those with neural network-based value functions) bandit methods for recommendations using TF-Agents\n",
    "\n",
    "> Neural linear bandits provide a nice way to leverage the representation power of deep learning and the bandit approach for uncertainty measure and efficient exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fd257-b98b-426a-a2cd-024429b014f1",
   "metadata": {},
   "source": [
    "## Load notebook config\n",
    "\n",
    "* use the prefix defined in `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f39c9d08-d118-4013-a47f-88450f49f19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "# PREFIX = 'mabv1'\n",
    "VERSION        = \"v2\"                       # TODO\n",
    "PREFIX         = f'rec-bandits-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908f6b95-b539-4a9f-a836-840d26ea3b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"rec-bandits-v2\"\n",
      "VERSION                  = \"v2\"\n",
      "\n",
      "BUCKET_NAME              = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_ID      = \"hybrid_vertex.movielens_ds_rec_bandits_v2\"\n",
      "BIGQUERY_TABLE_ID        = \"hybrid_vertex.movielens_ds_rec_bandits_v2.training_dataset\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-rec-bandits-v2\"\n",
      "IMAGE_NAME               = \"train-perarm-feats-v2\"\n",
      "DOCKERNAME               = \"Dockerfile_perarm_feats\"\n",
      "\n",
      "IMAGE_URI                = \"gcr.io/hybrid-vertex/train-perarm-feats-v2\"\n",
      "\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/train-perarm-feats-v2\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c690a9-e2bd-4759-ba41-4e2469098aee",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d0dfe4-695c-4dd4-9f24-67f7488ce1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c669f1a1-1af7-4efb-ab2d-6bf3b3847991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from collections import defaultdict\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pickle as pkl\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "# from tf_agents.agents import TFAgent\n",
    "\n",
    "# from tf_agents.bandits.environments import stationary_stochastic_per_arm_py_environment as p_a_env\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "# from tf_agents.drivers import dynamic_step_driver\n",
    "# from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "# from tf_agents.bandits.agents import lin_ucb_agent\n",
    "# from tf_agents.bandits.agents import linear_thompson_sampling_agent as lin_ts_agent\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent\n",
    "from tf_agents.bandits.agents import neural_linucb_agent\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "from tf_agents.bandits.policies import policy_utilities\n",
    "\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# this repo\n",
    "from src.per_arm_rl import data_utils\n",
    "from src.per_arm_rl import data_config\n",
    "from src.per_arm_rl import train_utils as train_utils\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29e58dd7-ab2b-419f-9771-bf1e98db758b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4969d3e-1fc0-45db-8a69-aa6b342019de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "274e7f4a-1802-4946-888e-876638f5c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a866b1-85b9-43e6-9546-edfbbf886bce",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd5b953-14c0-42ed-a511-77147a1bc0ac",
   "metadata": {},
   "source": [
    "### Read TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d0157c8-a04c-4dbd-b6d9-a1ede97687a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da0cdac-76af-4608-b70e-be7dbe0584b5",
   "metadata": {},
   "source": [
    "**Train data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c934c06-bf08-4c7f-b0cc-0de04ef3515c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://rec-bandits-v2-hybrid-vertex-bucket/data/train/ml-ratings-100k-train.tfrecord']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPLIT = \"train\" # \"train\" | \"val\"\n",
    "\n",
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7511e4d-bf81-4800-bde7-8b16dec9aeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([35.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'898'], dtype=object)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([885409515])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'681'], dtype=object)>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'marketing'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "train_dataset = train_dataset.map(data_utils.parse_tfrecord)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452750c1-46a0-4ee1-84d4-0c3b227de38f",
   "metadata": {},
   "source": [
    "**Val data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7b5376f-9438-4304-84aa-de09c30f5e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = \"val\"\n",
    "\n",
    "val_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        val_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "val_dataset = tf.data.TFRecordDataset(val_files)\n",
    "val_dataset = val_dataset.map(data_utils.parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8959967-522e-41c8-9a1b-050ca8bc191f",
   "metadata": {},
   "source": [
    "### get vocab\n",
    "\n",
    "**TODO:** \n",
    "* streamline vocab calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b9169bc-d6dc-497e-9dff-6ebb175282ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE_VOCABS: False\n"
     ]
    }
   ],
   "source": [
    "GENERATE_VOCABS = False\n",
    "\n",
    "print(f\"GENERATE_VOCABS: {GENERATE_VOCABS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3ccf137-7a72-42e7-aa89-3c81a99cf40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab...\n",
      "Downloaded vocab from: gs://rec-bandits-v2-hybrid-vertex-bucket/vocabs/vocab_dict.pkl\n",
      "\n",
      "'movie_id'\n",
      "'user_id'\n",
      "'user_occupation_text'\n",
      "'movie_genres'\n",
      "'bucketized_user_age'\n",
      "'max_timestamp'\n",
      "'min_timestamp'\n",
      "'timestamp_buckets'\n"
     ]
    }
   ],
   "source": [
    "if not GENERATE_VOCABS:\n",
    "\n",
    "    EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{VOCAB_SUBDIR}/{VOCAB_FILENAME}'\n",
    "    print(f\"Downloading vocab...\")\n",
    "    \n",
    "    os.system(f'gsutil -q cp {EXISTING_VOCAB_FILE} .')\n",
    "    print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "    filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "    vocab_dict = pkl.load(filehandler)\n",
    "    filehandler.close()\n",
    "    \n",
    "    for key in vocab_dict.keys():\n",
    "        pprint(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccaef62-882a-46ff-a1b1-3837e69fdf74",
   "metadata": {},
   "source": [
    "## helper functions\n",
    "\n",
    "**TODO:**\n",
    "* modularize in a train_utils or similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b941063b-ad48-4817-aef0-9afa8a444632",
   "metadata": {},
   "source": [
    "# Multi-Armed Bandits (MAB) with Per-Arm Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28770b8d-836b-448d-8dd1-203d76fc6d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest = tf.nest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138a295-2b0d-4359-8496-af8552ec8cff",
   "metadata": {},
   "source": [
    "# [1] Preprocessing layers for global and arm features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e28c002-8d3a-4cf4-b69b-de56a6abab90",
   "metadata": {},
   "source": [
    "The preproccesing layers will ultimately feed the two sampling functions described below. These sampling functions will be used to create [trajectories](https://github.com/tensorflow/agents/blob/master/tf_agents/trajectories/trajectory.py#L36) (i.e., the training examples for our model)\n",
    "\n",
    "`global_context_sampling_fn`: \n",
    "* A function that outputs a random 1d array or list of ints or floats\n",
    "* This output is the global context. Its shape and type must be consistent across calls.\n",
    "\n",
    "`arm_context_sampling_fn`: \n",
    "* A function that outputs a random 1 array or list of ints or floats (same type as the output of `global_context_sampling_fn`). * This output is the per-arm context. Its shape must be consistent across calls.\n",
    "\n",
    "See `debug-and-learn-emb-models.ipynb` for more details and debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ea1f7-0621-44b8-b062-1f59b0964d72",
   "metadata": {},
   "source": [
    "## Global & Per-Arm feature embedding models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8d77956-635c-438a-916a-185eec52f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OOV_BUCKETS        = 1\n",
    "GLOBAL_EMBEDDING_SIZE  = 16\n",
    "MV_EMBEDDING_SIZE      = 32 #32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ea335991-dcec-40b3-ba0d-a0fdfb9c2ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test emb models\n",
    "for i in range(1):\n",
    "    \n",
    "    iterator = iter(train_dataset.batch(1))\n",
    "    data = next(iterator)\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "48178fff-491f-4f03-b156-7765d1fa9707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.perarm_features.emb_features.EmbeddingModel at 0x7f95f80c5120>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.perarm_features import emb_features as emb_features\n",
    "\n",
    "embs = emb_features.EmbeddingModel(\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "903c63c5-2468-4443-bcb8-5ff6d69810dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL_DIM: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.03371139, -0.0480986 , -0.00784447,  0.04336171, -0.03726073,\n",
       "        -0.04288805,  0.03887058,  0.0214306 , -0.02067931,  0.0063417 ,\n",
       "        -0.04485219, -0.02128459, -0.0311906 ,  0.01566024, -0.02828428,\n",
       "         0.01183716, -0.02511469, -0.02762323,  0.03422118,  0.00992824,\n",
       "         0.00731212,  0.03368196, -0.02966282, -0.01645806, -0.03171815,\n",
       "        -0.00159658, -0.04958898, -0.02266195, -0.03225473, -0.00149149,\n",
       "         0.03763968,  0.04285051,  0.03492894, -0.00672681, -0.02763638,\n",
       "         0.00558706,  0.00127973,  0.02201568,  0.03606036, -0.04493891,\n",
       "         0.04075691, -0.04195913, -0.01996472,  0.03049437, -0.00167011,\n",
       "         0.02255333, -0.03677454, -0.03182194, -0.02581388,  0.04108084,\n",
       "         0.04261974, -0.008521  ,  0.02934309, -0.04193543,  0.03292122,\n",
       "         0.00259664,  0.03253864, -0.01601571,  0.03629147, -0.00020125,\n",
       "         0.01630738, -0.04970431,  0.01850503, -0.03813527]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_globals = embs._get_global_context_features(data)\n",
    "\n",
    "GLOBAL_DIM = test_globals.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"GLOBAL_DIM: {GLOBAL_DIM}\")\n",
    "\n",
    "test_globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ebec4863-c614-4248-b680-8e29ec5b730d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER_ARM_DIM: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00247353, -0.02493227, -0.00062716, -0.00324398,  0.04452503,\n",
       "         0.0051824 ,  0.02470389,  0.02579452, -0.0372776 , -0.0461687 ,\n",
       "        -0.02143296, -0.01624377,  0.00831189,  0.00532737, -0.04493587,\n",
       "        -0.01603419, -0.02503407,  0.01231784, -0.01713853, -0.00958348,\n",
       "        -0.02011896, -0.0187003 , -0.04183201,  0.04575681,  0.03164799,\n",
       "        -0.01587506, -0.01004306,  0.01231442,  0.03566709, -0.00738306,\n",
       "        -0.02714161,  0.00355067, -0.04783155,  0.02908781, -0.0499506 ,\n",
       "        -0.01748936, -0.01106584, -0.00620397,  0.02811222, -0.02340604,\n",
       "         0.03701547, -0.03244958, -0.02174045,  0.03544117,  0.01054597,\n",
       "         0.02814809, -0.0095594 ,  0.01274072, -0.00908657,  0.03463784,\n",
       "         0.02127761,  0.00326663, -0.03774344,  0.00767465,  0.01113643,\n",
       "         0.03990723,  0.00548577,  0.01249642, -0.03492818,  0.02514634,\n",
       "         0.04420848, -0.01514103, -0.00370481, -0.01175959]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arms = embs._get_per_arm_features(data)\n",
    "\n",
    "PER_ARM_DIM = test_arms.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"PER_ARM_DIM: {PER_ARM_DIM}\")\n",
    "\n",
    "test_arms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac6836c-67b7-4fd4-917a-24ddad708edd",
   "metadata": {},
   "source": [
    "# [2] Implementing MAB with TF-Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1877c79c-b6c8-4048-b1ce-05f011e8d69e",
   "metadata": {},
   "source": [
    "In TF-Agents, the *per-arm features* implementation differs from the *global-only* feature examples in the following aspects:\n",
    "* Reward is modeled not per-arm, but globally.\n",
    "* The arms are permutation invariant: it doesn’t matter which arm is arm 1 or arm 2, only their features.\n",
    "* One can have a different number of arms to choose from in every step (note that unspecified/dynamically changing number of arms will have a problem with XLA compatibility).\n",
    "\n",
    "When implementing per-arm features in TF-Bandits, the following details have to be discussed:\n",
    "* Observation spec and observations,\n",
    "* Action spec and actions,\n",
    "* Implementation of specific policies and agents.\n",
    "\n",
    "\n",
    "**TODO:**\n",
    "* outline the components and highlight their interactions, dependencies on eachother, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7ff9baaf-987d-448d-a981-742a79b581e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE      : 128\n",
      "EVAL_BATCH_SIZE : 1\n",
      "NUM_ACTIONS     : 2\n",
      "GLOBAL_DIM      : 40\n",
      "PER_ARM_DIM     : 50\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE      = 128\n",
    "EVAL_BATCH_SIZE = 1\n",
    "\n",
    "NUM_ACTIONS     = 2 #this is kinda deceptive - \n",
    "#our approach is to learn by \"flashing\" one movie rating at a time per user context. \n",
    "#The n_actions = show/don't show the movie with one degree of freedom (n-1)\n",
    "\n",
    "\n",
    "print(f\"BATCH_SIZE      : {BATCH_SIZE}\")\n",
    "print(f\"EVAL_BATCH_SIZE : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"NUM_ACTIONS     : {NUM_ACTIONS}\")\n",
    "print(f\"GLOBAL_DIM      : {GLOBAL_DIM}\")\n",
    "print(f\"PER_ARM_DIM     : {PER_ARM_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeb4902-5bb9-4587-8d29-c01d78b006be",
   "metadata": {},
   "source": [
    "## Tensor Specs\n",
    "\n",
    "* say you have a global observation spec of `[17]`. And you have two batch dimensions `[4, 5]`. Then your observation has to have the shape `[4, 5, 17]`\n",
    "* and then if you have arm_obs_spec with shape `[9, 13]`, then the arm obs shape has to be exactly `[4, 5, 9, 13]`\n",
    "* and this has to be true for every single tensor in your tensor nest\n",
    "* the first 2 dims are the outer dims that are the same for all tensors, the rest of the dimensions have to follow the spec for each tensor\n",
    "\n",
    "**TODO:**\n",
    "* explain relationship between Tensor Specs and their Tensor counterparts\n",
    "* highlight the errors, lessons learned, and utility functions to address these"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f68ebe8-116d-43b3-a6e1-4f5a5c7f4741",
   "metadata": {},
   "source": [
    "### Observation spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9c4746-d01b-4ca4-aa53-ab68da54d37a",
   "metadata": {},
   "source": [
    "**This observation spec allows the user to have a global observation of fixed dimension**, and an unspecified number of *per-arm* features (also of fixed dimension)\n",
    "* The actions output by the policy are still integers as usual, and they indicate which row of the arm-features it has chosen \n",
    "* The action spec must be a single integer value without boundaries:\n",
    "\n",
    "```python\n",
    "global_spec = tensor_spec.TensorSpec([GLOBAL_DIM], tf.float32)\n",
    "per_arm_spec = tensor_spec.TensorSpec([None, PER_ARM_DIM], tf.float32)\n",
    "observation_spec = {'global': global_spec, 'per_arm': per_arm_spec}\n",
    "\n",
    "action_spec = tensor_spec.TensorSpec((), tf.int32)\n",
    "```\n",
    "> Here the only difference compared to the action spec with global features only is that the tensor spec is not bounded, as we don’t know how many arms there will be at any time step\n",
    "\n",
    "**XLA compatibility:**\n",
    "* Since dynamic tensor shapes are not compatible with XLA, the number of arm features (and consequently, number of arms for a step) cannot be dynamic. \n",
    "* One workaround is to fix the maximum number of arms for a problem, then pad the arm features in steps with fewer arms, and use action masking to indicate how many arms are actually active.\n",
    "\n",
    "```python\n",
    "per_arm_spec = tensor_spec.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32)\n",
    "\n",
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=(), dtype=tf.int32, minimum = 0, maximum = NUM_ACTIONS - 1\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36bd3b33-635a-4274-8b9e-7172696ebb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_spec = {\n",
    "    'global': tf.TensorSpec([GLOBAL_DIM], tf.float32),\n",
    "    'per_arm': tf.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32) #excluding action dim here\n",
    "}\n",
    "observation_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a2da92-7db2-4f42-94a7-b7bad1c8fc42",
   "metadata": {},
   "source": [
    "### Action spec\n",
    "\n",
    "> The time_step_spec and action_spec are specifications for the input time step and the output action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5af42c7-18d7-480f-a7f3-d7da3f4840eb",
   "metadata": {},
   "source": [
    "```python\n",
    "    if (\n",
    "        not tensor_spec.is_bounded(action_spec)\n",
    "        or not tensor_spec.is_discrete(action_spec)\n",
    "        or action_spec.shape.rank > 1\n",
    "        or action_spec.shape.num_elements() != 1\n",
    "    ):\n",
    "      raise NotImplementedError(\n",
    "          'action_spec must be a BoundedTensorSpec of type int32 and shape (). '\n",
    "          'Found {}.'.format(action_spec)\n",
    "      )\n",
    "```\n",
    "\n",
    "* [src](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_base_policy.py#L97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "549a123c-349a-4103-b39a-4502f47d1e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=[], \n",
    "    dtype=tf.int32,\n",
    "    minimum=tf.constant(0),            \n",
    "    maximum=NUM_ACTIONS-1, # n degrees of freedom and will dictate the expected mean reward spec shape\n",
    "    name=\"action_spec\"\n",
    ")\n",
    "\n",
    "action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36ee2635-d4e3-4468-886c-ae9c62e3c80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_num_actions: 2\n",
      "predicted_rewards_mean: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n"
     ]
    }
   ],
   "source": [
    "expected_num_actions = action_spec.maximum - action_spec.minimum + 1\n",
    "print(f\"expected_num_actions: {expected_num_actions}\")\n",
    "\n",
    "predicted_rewards_mean = tensor_spec.TensorSpec([expected_num_actions])\n",
    "print(f\"predicted_rewards_mean: {predicted_rewards_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a51efce-9f1b-42d1-bec4-7b788e3fd7e0",
   "metadata": {},
   "source": [
    "### TimeStep spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95f05860-0fbf-4a5a-8273-9c81761e0ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec = ts.time_step_spec(\n",
    "    observation_spec = observation_spec, \n",
    "    # reward_spec = _reward_spec\n",
    ")\n",
    "time_step_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9181303-6565-45f5-a293-08d50420a805",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Inspect chosen arm features spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6b526a5-997c-4621-b21c-82c6ca1d6a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90d3e03e-619e-4fa4-b817-f02b4cefd6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(64,), dtype=tf.float32, name=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_arm_features_info = (\n",
    "  policy_utilities.create_chosen_arm_features_info_spec(\n",
    "      time_step_spec.observation,\n",
    "  )\n",
    ")\n",
    "chosen_arm_features_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc427092-beb7-4baf-a2e9-b8d10629182c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandit_policy_type = (\n",
    "    policy_utilities.BanditPolicyType.GREEDY\n",
    ")\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a4a2a33-c7d4-4d81-8082-80dfc3596741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandit_policy_type = (\n",
    "    policy_utilities.create_bandit_policy_type_tensor_spec(shape=[1])\n",
    ")\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e7ac02b-18bd-4519-92fe-5541b1a8ddc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_spec = policy_utilities.PerArmPolicyInfo(\n",
    "  predicted_rewards_mean=predicted_rewards_mean,\n",
    "  bandit_policy_type=bandit_policy_type,\n",
    "  chosen_arm_features=chosen_arm_features_info,\n",
    ")\n",
    "info_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21f28b9b-8183-495a-89b6-a01f30ea8637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None))\n"
     ]
    }
   ],
   "source": [
    "# PerArmPolicyInfo(\n",
    "#     log_probability=(), \n",
    "#     predicted_rewards_mean=TensorSpec(shape=(2,), \n",
    "#                                       dtype=tf.float32, name=None), \n",
    "#     multiobjective_scalarized_predicted_rewards_mean=(), \n",
    "#     predicted_rewards_optimistic=(), \n",
    "#     predicted_rewards_sampled=(), \n",
    "#     bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), \n",
    "#     chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9c197-ae9b-461d-8956-f078b929ac12",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The Agent\n",
    "\n",
    "**Note** that contextual bandits form a special case of RL, where the actions taken by the agent do not alter the state of the environment \n",
    "\n",
    "> “Contextual” refers to the fact that the agent chooses among a set of actions while having knowledge of the context (environment observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81d6e84-688e-48c5-aea1-77df031348c9",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Agent & Network defined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aadb01-eb5c-4870-ae14-9e66624ba594",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **Agent types**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d075e8a6-11a9-4346-8725-3653fba4bac4",
   "metadata": {},
   "source": [
    "> `AGENT_TYPE = ['LinUCB', 'LinTS', 'epsGreedy', 'NeuralLinUCB']`\n",
    "\n",
    "LinearUCBAgent: (`LinUCB`) \n",
    "* An agent implementing the Linear UCB bandit algorithm ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/lin_ucb_agent/LinearUCBAgent))\n",
    "\n",
    "LinearThompsonSamplingAgent: (`LinTS`) \n",
    "* Implements the Linear Thompson Sampling Agent from the [paper](https://arxiv.org/abs/1209.3352): *Thompson Sampling for Contextual Bandits with Linear Payoffs* ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/linear_thompson_sampling_agent/LinearThompsonSamplingAgent))\n",
    "\n",
    "NeuralEpsilonGreedyAgent: (`epsGreedy`) \n",
    "* A neural network based epsilon greedy agent ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_epsilon_greedy_agent/NeuralEpsilonGreedyAgent))\n",
    "\n",
    "NeuralLinUCBAgent: (`NeuralLinUCB`) \n",
    "* An agent implementing the LinUCB algorithm on top of a neural network ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_linucb_agent/NeuralLinUCBAgent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b8e88e-c8ea-4193-a911-0d974ef3b1a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **Network types**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f547087d-5fad-4521-a584-cb46ce52897d",
   "metadata": {},
   "source": [
    "Which network architecture to use for the `epsGreedy` or `NeuralLinUCB` agents\n",
    "\n",
    "```\n",
    "NETWORK_TYPE = ['commontower', 'dotproduct']\n",
    "```\n",
    "\n",
    "**GlobalAndArmCommonTowerNetwork:** (`commontower`)\n",
    "* This network takes the output of the global and per-arm networks, and leads them through a common network, that in turn outputs reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "> * `COMMON_LAYERS` - Iterable of ints. Specifies the layers of the common tower\n",
    "* The network produced by this function can be used either in `GreedyRewardPredictionPolicy`, or `NeuralLinUCBPolicy`\n",
    "> * In the former case, the network must have `output_dim=1`, it is going to be an instance of `QNetwork`, and used in the policy as a reward prediction network\n",
    "> * In the latter case, the network will be an encoding network with its output consumed by a reward layer or a `LinUCB` method. The specified `output_dim` will be the encoding dimension\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmCommonTowerNetwork)\n",
    "\n",
    "**GlobalAndArmDotProductNetwork:** (`dotproduct`)\n",
    "* This network calculates the **dot product** of the output of the global and per-arm networks and returns them as reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmDotProductNetwork)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3dc270-deb5-4e96-8276-74759a06c318",
   "metadata": {},
   "source": [
    "### Agent config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbe29263-453d-405e-ac50-fee7f379f335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\n",
      "\n",
      "time_step_spec:  TimeStep(\n",
      "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
      "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n",
      "\n",
      "action_spec:  BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))\n",
      "\n",
      "observation_spec:  {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\")\n",
    "print(\"\\ntime_step_spec: \", time_step_spec)\n",
    "print(\"\\naction_spec: \", action_spec)\n",
    "print(\"\\nobservation_spec: \", observation_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d817bf2-1fa6-4bae-af90-745fad996b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'common_layers': [16, 8],\n",
      " 'epsilon': 0.01,\n",
      " 'eval_batch_size': 1,\n",
      " 'global_layers': [64, 32, 16],\n",
      " 'learning_rate': 0.05,\n",
      " 'model_type': 'epsGreedy',\n",
      " 'network_type': 'commontower',\n",
      " 'num_actions': 2,\n",
      " 'per_arm_layers': [64, 32, 16]}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Agents\n",
    "# ================================\n",
    "AGENT_TYPE      = 'epsGreedy' # 'LinUCB' | 'LinTS |, 'epsGreedy' | 'NeuralLinUCB'\n",
    "\n",
    "# Parameters for linear agents (LinUCB and LinTS).\n",
    "AGENT_ALPHA     = 0.1\n",
    "\n",
    "# Parameters for neural agents (NeuralEpsGreedy and NerualLinUCB).\n",
    "EPSILON         = 0.01\n",
    "LR              = 0.05\n",
    "\n",
    "# Parameters for NeuralLinUCB\n",
    "ENCODING_DIM    = 1\n",
    "EPS_PHASE_STEPS = 1000\n",
    "\n",
    "# ================================\n",
    "# Agent's Preprocess Network\n",
    "# ================================\n",
    "NETWORK_TYPE    = \"commontower\" # 'commontower' | 'dotproduct'\n",
    "\n",
    "if AGENT_TYPE == 'NeuralLinUCB':\n",
    "    NETWORK_TYPE = 'commontower'\n",
    "    \n",
    "GLOBAL_LAYERS   = [64, 32, 16] # beginning should be of size: GLOBAL_DIM\n",
    "ARM_LAYERS      = [64, 32, 16] # beginning should be of size: PER_ARM_DIM\n",
    "COMMON_LAYERS   = [16, 8]\n",
    "\n",
    "HPARAMS = {  # TODO - streamline and consolidate\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"eval_batch_size\" : EVAL_BATCH_SIZE,\n",
    "    \"num_actions\": NUM_ACTIONS,\n",
    "    \"model_type\": AGENT_TYPE,\n",
    "    \"network_type\": NETWORK_TYPE,\n",
    "    \"global_layers\": GLOBAL_LAYERS,\n",
    "    \"per_arm_layers\": ARM_LAYERS,\n",
    "    \"common_layers\": COMMON_LAYERS,\n",
    "    \"learning_rate\": LR,\n",
    "    \"epsilon\": EPSILON,\n",
    "}\n",
    "pprint(HPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2bf060bb-9880-40b4-8583-dd7a3f915bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent: NeuralEpsGreedyAgent\n",
      "Network: commontower\n"
     ]
    }
   ],
   "source": [
    "from src.perarm_features import agent_factory as agent_factory\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "    agent_type = AGENT_TYPE,\n",
    "    network_type = NETWORK_TYPE,\n",
    "    time_step_spec = time_step_spec,\n",
    "    action_spec = action_spec,\n",
    "    observation_spec=observation_spec,\n",
    "    global_layers = GLOBAL_LAYERS,\n",
    "    arm_layers = ARM_LAYERS,\n",
    "    common_layers = COMMON_LAYERS,\n",
    "    agent_alpha = AGENT_ALPHA,\n",
    "    learning_rate = LR,\n",
    "    epsilon = EPSILON,\n",
    "    train_step_counter = global_step,\n",
    "    output_dim = ENCODING_DIM,\n",
    "    eps_phase_steps = EPS_PHASE_STEPS,\n",
    "    summarize_grads_and_vars = False,\n",
    "    debug_summaries = False\n",
    ")\n",
    "      \n",
    "agent.initialize()\n",
    "print(f'agent: {agent.name}')\n",
    "\n",
    "# if network:\n",
    "#     print(f\"Network: {network}\")\n",
    "\n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {NETWORK_TYPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d77d1-a0b3-4898-adf0-0b32bfaf5bd7",
   "metadata": {},
   "source": [
    "#### Inspect the specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78ca56e7-a386-4bf4-8c2b-3d1665521f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41483f5a-bda6-48a4-9e1c-88d8b4afeea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.time_step_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f205716-f265-4ca8-81a7-4799de8f60a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(Trajectory(\n",
       "{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32)),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None)}),\n",
       " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None)),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.training_data_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d404dae-3cc3-4f81-962b-4641455ca4f2",
   "metadata": {},
   "source": [
    "## Reward function\n",
    "\n",
    "> see `reward_factory.py`\n",
    "\n",
    "**TODO:**\n",
    "* explain how to translate reward to this common recommendation objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df9aecd6-d20a-48a7-9ead-4da3bbcfdae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _get_rewards(element):\n",
    "#     \"\"\"Calculates reward for the actions.\"\"\"\n",
    "\n",
    "#     def _calc_reward(x):\n",
    "#         \"\"\"Calculates reward for a single action.\"\"\"\n",
    "#         r0 = lambda: tf.constant(0.0)\n",
    "#         r1 = lambda: tf.constant(1.0)\n",
    "#         r2 = lambda: tf.constant(2.0)\n",
    "#         r3 = lambda: tf.constant(3.0)\n",
    "#         r4 = lambda: tf.constant(4.0)\n",
    "#         r5 = lambda: tf.constant(5.0)\n",
    "#         c1 = tf.equal(x, 1.0)\n",
    "#         c2 = tf.equal(x, 2.0)\n",
    "#         c3 = tf.equal(x, 3.0)\n",
    "#         c4 = tf.equal(x, 4.0)\n",
    "#         c5 = tf.equal(x, 5.0)\n",
    "#         return tf.case(\n",
    "#             [(c1, r1), (c2, r2), (c3, r3),(c4, r4),(c5, r5)], \n",
    "#             default=r0, exclusive=True\n",
    "#         )\n",
    "\n",
    "#     return tf.map_fn(\n",
    "#         fn=_calc_reward, \n",
    "#         elems=element['user_rating'], \n",
    "#         dtype=tf.float32\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac59703a-9a00-4eba-a3b7-45b21b738dd4",
   "metadata": {},
   "source": [
    "## Trajectory function\n",
    "\n",
    "**parking lot**\n",
    "* does trajectory fn need concept of `dummy_chosen_arm_features`, similar to [this](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_base_policy.py#L297)\n",
    "\n",
    "```python\n",
    "      dummy_chosen_arm_features = tf.nest.map_structure(\n",
    "          lambda obs: tf.zeros_like(obs[:, 0, ...]),\n",
    "          time_step.observation[bandit_spec_utils.PER_ARM_FEATURE_KEY],\n",
    "      )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3c16aa7b-f328-425e-b02e-a3fc7f200859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.perarm_features import reward_factory as reward_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f3605d9f-d239-4871-9a61-6e9b21f9c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _trajectory_fn(element): # hparams\n",
    "    \n",
    "    \"\"\"Converts a dataset element into a trajectory.\"\"\"\n",
    "    # global_features = _get_global_context_features(element)\n",
    "    # arm_features = _get_per_arm_features(element)\n",
    "    \n",
    "    global_features = embs._get_global_context_features(element)\n",
    "    arm_features = embs._get_per_arm_features(element)\n",
    "    \n",
    "    # Adds a time dimension.\n",
    "    arm_features = train_utils._add_outer_dimension(arm_features)\n",
    "\n",
    "    # obs spec\n",
    "    observation = {\n",
    "        bandit_spec_utils.GLOBAL_FEATURE_KEY:\n",
    "            train_utils._add_outer_dimension(global_features),\n",
    "    }\n",
    "\n",
    "    # reward = train_utils._add_outer_dimension(_get_rewards(element))\n",
    "    reward = train_utils._add_outer_dimension(reward_factory._get_rewards(element))\n",
    "\n",
    "    # To emit the predicted rewards in policy_info, we need to create dummy\n",
    "    # rewards to match the definition in TensorSpec for the ones specified in\n",
    "    # emit_policy_info set.\n",
    "    dummy_rewards = tf.zeros([HPARAMS['batch_size'], 1, HPARAMS['num_actions']])\n",
    "    policy_info = policy_utilities.PerArmPolicyInfo(\n",
    "        chosen_arm_features=arm_features,\n",
    "        # Pass dummy mean rewards here to match the model_spec for emitting\n",
    "        # mean rewards in policy info\n",
    "        predicted_rewards_mean=dummy_rewards,\n",
    "        bandit_policy_type=tf.zeros([HPARAMS['batch_size'], 1, 1], dtype=tf.int32)\n",
    "        # policy_utilities.create_bandit_policy_type_tensor_spec(shape=[1]) # policy_utilities.BanditPolicyType.GREEDY\n",
    "        # tf.zeros([batch_size, 1, 1], dtype=tf.int32)\n",
    "    )\n",
    "    \n",
    "    if HPARAMS['model_type'] == 'neural_ucb':\n",
    "        policy_info = policy_info._replace(\n",
    "            predicted_rewards_optimistic=dummy_rewards\n",
    "        )\n",
    "        \n",
    "    return trajectory.single_step(\n",
    "        observation=observation,\n",
    "        action=tf.zeros_like(\n",
    "            reward, dtype=tf.int32\n",
    "        ),  # Arm features are copied from policy info, put dummy zeros here\n",
    "        policy_info=policy_info,\n",
    "        reward=reward,\n",
    "        discount=tf.zeros_like(reward)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a0989c-5a06-4fd5-a12d-d92dbbe71a76",
   "metadata": {},
   "source": [
    "Inspect the trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "257791d1-c97c-48c0-bc92-f5a4737b6c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in train_dataset.batch(HPARAMS['batch_size']).take(1):\n",
    "    test_traj = _trajectory_fn(x)\n",
    "    \n",
    "# test_traj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d8994e-ce28-4fd9-8e3b-153451d014d9",
   "metadata": {},
   "source": [
    "#### Inspect shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8a0e451f-1ad8-4af2-84d6-ddc5eaac0e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.action.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.action.shape: {test_traj.action.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "52ed1767-12ce-404c-9caf-0974d55ec5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.discount.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.discount.shape: {test_traj.discount.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "033ff16b-0158-477f-835f-99deec636b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.reward.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.reward.shape: {test_traj.reward.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ee5aded7-7f9c-4a88-868c-f6ab58a0e704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.observation.shape: (128, 1, 64)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.observation.shape: {test_traj.observation['global'].shape}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcbfc9a-049e-49b9-b2a3-ecb9fd4b9964",
   "metadata": {},
   "source": [
    "# [3] Training the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13adc1ef-b50e-41a3-9b95-c128d0c55a2b",
   "metadata": {},
   "source": [
    "## set Vertex Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e861fb27-df24-4821-8448-cf1346b186f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : v2-local-2a-v1\n",
      "RUN_NAME          : run-20231017-202508\n",
      "\n",
      "BASE_OUTPUT_DIR   : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231017-202508\n",
      "LOG_DIR           : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231017-202508/logs\n",
      "ROOT_DIR          : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231017-202508/root\n",
      "ARTIFACTS_DIR     : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231017-202508/artifacts\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME   = f'v2-local-2a-v1'\n",
    "\n",
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b7a5e4-efff-490b-b431-53037a2f4a16",
   "metadata": {},
   "source": [
    "## eval loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba0392e-90c8-4dc8-8df2-6d2af1ade490",
   "metadata": {},
   "source": [
    "> When evaluating an epsilon-greedy bandit, we need to remove those predictions that come from the `uniform_random` policy. We only want the predictions from the `GREEDY` policy, becasue we want to know how the model performs when it is actually used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b3d3c-75f7-46f4-9a1b-6329e419b7f5",
   "metadata": {},
   "source": [
    "## train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "97cfe7c3-4022-47a9-83c2-df0ad8a2abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.metrics import export_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.utils import common\n",
    "\n",
    "# from src.per_arm_rl import train_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bb7ffc-00df-4d46-857b-86c87b78f597",
   "metadata": {},
   "source": [
    "`agent.train(experience=...)`\n",
    "\n",
    "where `experience` is a batch of trajectories data in the form of a Trajectory. \n",
    "* The structure of experience must match that of `self.training_data_spec`. \n",
    "* All tensors in experience must be shaped [batch, time, ...] where time must be equal to self.train_step_length if that property is not None."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94d6d45-c71e-4fe4-9af8-af9a8bda4e4f",
   "metadata": {},
   "source": [
    "### logs & checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "049ee49b-3b1a-4b12-a360-15e759dff7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('metrics: [<tf_agents.metrics.tf_metrics.AverageReturnMetric object at '\n",
      " '0x7f95f80f5570>]')\n",
      "setting checkpoint_manager: gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231017-202508/root/chkpoint\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    f\"{LOG_DIR}/train\", flush_millis=10 * 1000\n",
    ")\n",
    "# train_summary_writer.set_as_default()\n",
    "\n",
    "# eval_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "#     f\"{LOG_DIR}/eval\", flush_millis=10 * 1000\n",
    "# )\n",
    "# ====================================================\n",
    "# metrics\n",
    "# ====================================================\n",
    "step_metric = tf_metrics.EnvironmentSteps()\n",
    "metrics = [\n",
    "    # tf_metrics.NumberOfEpisodes(),\n",
    "    # tf_metrics.AverageEpisodeLengthMetric(batch_size=HPARAMS['batch_size']),\n",
    "    tf_metrics.AverageReturnMetric(batch_size=HPARAMS['batch_size'])\n",
    "]\n",
    "\n",
    "pprint(f\"metrics: {metrics}\")\n",
    "\n",
    "# ====================================================\n",
    "# get checkpoint manager\n",
    "# ====================================================\n",
    "CHKPOINT_DIR = f\"{ROOT_DIR}/chkpoint\"\n",
    "print(f\"setting checkpoint_manager: {CHKPOINT_DIR}\")\n",
    "\n",
    "checkpoint_manager = train_utils.restore_and_get_checkpoint_manager(\n",
    "    root_dir=CHKPOINT_DIR, \n",
    "    agent=agent, \n",
    "    metrics=metrics, \n",
    "    step_metric=step_metric\n",
    ")\n",
    "# ====================================================\n",
    "# policy saver\n",
    "# ====================================================\n",
    "saver = policy_saver.PolicySaver(\n",
    "    agent.policy, \n",
    "    train_step=global_step\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83683f4b-8a1a-44b9-8d5f-7ee3304c794c",
   "metadata": {},
   "source": [
    "### config\n",
    "\n",
    "* calculate train & val dataset sizes\n",
    "* define logging and chkpt intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f9432613-6583-4828-8a2a-dd939adbc3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_DATA_SIZE : 80000\n",
      "NUM_TRAIN_STEPS : 100\n",
      "EVAL_DATA_SIZE : 1000\n",
      "NUM_EVAL_STEPS : 1000\n",
      "CHKPT_INTERVAL: 100\n",
      "LOG_INTERVAL : 10\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA_SIZE = 80000          # len(list(train_dataset))\n",
    "NUM_TRAIN_STEPS = 100            # TRAIN_DATA_SIZE // HPARAMS['batch_size']\n",
    "\n",
    "EVAL_DATA_SIZE  = 1000          # len(list(val_dataset))\n",
    "NUM_EVAL_STEPS  = 1000           # EVAL_DATA_SIZE // HPARAMS['eval_batch_size']\n",
    "\n",
    "CHKPT_INTERVAL  = NUM_TRAIN_STEPS # // 5\n",
    "LOG_INTERVAL    = 10\n",
    "# EVAL_INTERVAL = NUM_TRAIN_STEPS // 2\n",
    "\n",
    "print(f\"TRAIN_DATA_SIZE : {TRAIN_DATA_SIZE}\")\n",
    "print(f\"NUM_TRAIN_STEPS : {NUM_TRAIN_STEPS}\")\n",
    "print(f\"EVAL_DATA_SIZE : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS : {NUM_EVAL_STEPS}\")\n",
    "print(f\"CHKPT_INTERVAL: {CHKPT_INTERVAL}\")\n",
    "print(f\"LOG_INTERVAL : {LOG_INTERVAL}\")\n",
    "# print(f\"EVAL_INTERVAL : {EVAL_INTERVAL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "379ffc65-4eec-4af1-8fd4-912ef65a9808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec={'bucketized_user_age': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'movie_genres': TensorSpec(shape=(None, 1), dtype=tf.int64, name=None), 'movie_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'timestamp': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'user_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_occupation_text': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_rating': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data\n",
    "train_ds_iterator = iter(train_dataset.batch(HPARAMS['batch_size']).repeat())\n",
    "\n",
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS[\"eval_batch_size\"])\n",
    "\n",
    "if NUM_EVAL_STEPS > 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)\n",
    "\n",
    "# eval_ds = eval_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "eval_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e498d7e3-d166-4e1d-94a5-f721de58694a",
   "metadata": {},
   "source": [
    "### run train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5dd64d98-7d5b-4474-a567-b42426d630a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.perarm_features import eval_perarm as eval_perarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "da4680f3-693b-4530-8e4d-88bc43036c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating pre-trained Agent...\n",
      "pre-train val_loss     : 15.35098648071289\n",
      "pre-train eval runtime : 0\n",
      "starting train loop...\n",
      "step = 0: train loss = 15.90999984741211\n",
      "step = 10: train loss = 13.380000114440918\n",
      "step = 20: train loss = 10.710000038146973\n",
      "step = 30: train loss = 9.25\n",
      "step = 40: train loss = 6.659999847412109\n",
      "step = 50: train loss = 5.210000038146973\n",
      "step = 60: train loss = 3.380000114440918\n",
      "step = 70: train loss = 2.9700000286102295\n",
      "step = 80: train loss = 2.609999895095825\n",
      "step = 90: train loss = 1.9900000095367432\n",
      "train runtime_mins: 1\n",
      "saved trained policy to: gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231017-202508/artifacts\n",
      "evaluating trained Agent...\n",
      "post-train val_loss     : 1.6847798824310303\n",
      "post-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "# agent.train = common.function(agent.train)\n",
    "\n",
    "list_o_loss = []\n",
    "\n",
    "# ====================================================\n",
    "# Evaluate the agent's policy once before training\n",
    "# ====================================================\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "pre_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "\n",
    "print(f\"evaluating pre-trained Agent...\")\n",
    "start_time = time.time()\n",
    "\n",
    "pre_val_loss, pre_preds, pre_tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = pre_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"pre-train val_loss     : {pre_val_loss}\")\n",
    "print(f\"pre-train eval runtime : {runtime_mins}\")\n",
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "print(f\"starting train loop...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# for i in tqdm(range(NUM_TRAIN_STEPS)):\n",
    "for i in range(NUM_TRAIN_STEPS):\n",
    "    \n",
    "    with train_summary_writer.as_default():\n",
    "\n",
    "        data = next(train_ds_iterator)\n",
    "        trajectories = _trajectory_fn(data)\n",
    "\n",
    "        # All tensors in experience must be shaped [batch, time, ...] \n",
    "        step = agent.train_step_counter.numpy()\n",
    "        loss = agent.train(experience=trajectories)\n",
    "        list_o_loss.append(loss.loss.numpy())\n",
    "\n",
    "        train_utils._export_metrics_and_summaries(\n",
    "            step=i, \n",
    "            metrics=metrics\n",
    "        )\n",
    "\n",
    "        # print step loss\n",
    "        if step % LOG_INTERVAL == 0:\n",
    "            print(\n",
    "                'step = {0}: train loss = {1}'.format(\n",
    "                    step, round(loss.loss.numpy(), 2)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if i > 0 and i % CHKPT_INTERVAL == 0:\n",
    "            saver.save(os.path.join(CHKPOINT_DIR, 'policy_%d' % step_metric.result()))\n",
    "            print(f\"saved policy to: {CHKPOINT_DIR}\")\n",
    "   \n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"train runtime_mins: {runtime_mins}\")\n",
    "\n",
    "saver.save(ARTIFACTS_DIR)\n",
    "print(f\"saved trained policy to: {ARTIFACTS_DIR}\")\n",
    "\n",
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = post_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "17b2b0d2-9795-4367-b57b-c331e94d1000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6847799"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb1ed8-f67b-4e7b-9cbc-70edd50e49ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate train job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff31fe28-2f05-499f-b1cc-505f3c9074e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### train loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "41937f9a-6c28-48d2-bc7c-bfe4372c7cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_o_loss)\n",
    "# plt.ylim([0, 10])\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e947e1-67f4-4205-99af-6921c6e9c896",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TensorBoard\n",
    "\n",
    "<img src=\"imgs/getting_profiler.png\" \n",
    "     align=\"center\" \n",
    "     width=\"850\"\n",
    "     height=\"850\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e0f77a33-0962-4af0-af97-cf05f895cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5d0509cb-0777-4d35-86c6-28c8acbcc793",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=$LOG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc40143-30b1-479f-b9b1-fa4c07b1690e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [4] Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6c94a0-122f-4ba6-acef-5653a3cc7850",
   "metadata": {
    "tags": []
   },
   "source": [
    "## load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b1c382b5-e2e0-45a2-9c5f-ef2c468d0f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231017-202508/artifacts\n"
     ]
    }
   ],
   "source": [
    "POLICY_URI = ARTIFACTS_DIR\n",
    "\n",
    "print(POLICY_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "68592d97-1272-4c6d-a4bd-43a6f7fe6c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f95b04f4370>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910a06f-678f-4bfa-a132-10b885f871c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## get predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1762c936-3c49-4ec5-a9eb-4df5816dc888",
   "metadata": {},
   "source": [
    "TODO - explain bandit_policy_type()\n",
    "\n",
    "**UNIFORM Random policy:**\n",
    "```\n",
    "PolicyStep(action=array(1, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.637535 , 3.5557823], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([2], dtype=int32), chosen_arm_features=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)))\n",
    "```\n",
    "\n",
    "**GREEDY policy:**\n",
    "```\n",
    "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.8278818, 3.607565 ], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([ 0.04054676, -0.04735027,  0.02202327,  0.01276748, -0.01367382,\n",
    "       -0.04838754,  0.00104916, -0.01956806,  0.01028793, -0.00256665,\n",
    "       -0.04376553,  0.03900594,  0.02388967, -0.04016995, -0.04945569,\n",
    "       -0.04539652,  0.04423274, -0.04630332,  0.00390794,  0.03986299,\n",
    "       -0.0398974 ,  0.01655747, -0.0471294 , -0.00690235, -0.03643382,\n",
    "       -0.0437116 ,  0.04757959, -0.00991895,  0.0281055 , -0.04633433,\n",
    "        0.01897702, -0.00824345,  0.03232259, -0.04980658, -0.01144745,\n",
    "        0.01690939,  0.02536928,  0.03384003, -0.01558131,  0.04731432,\n",
    "        0.04579857, -0.03305101,  0.03521084, -0.03915765,  0.04927064,\n",
    "        0.04695194,  0.03792156,  0.040496  ,  0.02574866, -0.00665367,\n",
    "       -0.03839222, -0.01564004, -0.04710373,  0.03557512, -0.01392462,\n",
    "        0.01368621,  0.02792176, -0.01799218,  0.00246101,  0.02263175,\n",
    "        0.0170817 ,  0.01388383, -0.03048695,  0.01198485], dtype=float32)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "567f64e1-8149-4364-b561-1a9d12581b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aff30396-e0fd-4f43-acaa-6af8b20b12cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "SKIP_NUM = 10\n",
    "\n",
    "for x in eval_ds.skip(SKIP_NUM).take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    \n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "    \n",
    "    # rewards = _get_rewards(x)\n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e58af9ab-f4da-4857-afe5-6b8de26ed0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.7746792, 3.4872231], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([-0.04211991,  0.03355854,  0.00062222, -0.03559208,  0.03014546,\n",
       "       -0.00911941,  0.03367225, -0.01702491, -0.04207989,  0.02439343,\n",
       "        0.03417565,  0.03412655, -0.01548523, -0.04152564, -0.01327814,\n",
       "        0.04441997, -0.01887345, -0.03676014, -0.01746018, -0.00505089,\n",
       "       -0.00495514, -0.02221038,  0.00734597, -0.02457649,  0.01958629,\n",
       "       -0.00150286, -0.00817053,  0.02833397,  0.03182454,  0.00413366,\n",
       "        0.04550329, -0.03923135,  0.03378687,  0.00785377, -0.0018571 ,\n",
       "       -0.02951536, -0.02467777, -0.02666589, -0.04103365, -0.00640677,\n",
       "       -0.03457658,  0.03871839, -0.03362087, -0.00123868,  0.0398059 ,\n",
       "       -0.01511135, -0.02833097,  0.03514184,  0.03603243,  0.03224551,\n",
       "        0.03410349, -0.04499953, -0.02059256, -0.01573974, -0.0066855 ,\n",
       "       -0.04533432, -0.0378898 ,  0.0453725 ,  0.01792984, -0.01493819,\n",
       "        0.03005158, -0.02943999, -0.00384724, -0.01675253], dtype=float32)))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6676778c-d191-4b1e-a180-61f068b3b8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.7746792, 3.4872231], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([-0.04211991,  0.03355854,  0.00062222, -0.03559208,  0.03014546,\n",
      "       -0.00911941,  0.03367225, -0.01702491, -0.04207989,  0.02439343,\n",
      "        0.03417565,  0.03412655, -0.01548523, -0.04152564, -0.01327814,\n",
      "        0.04441997, -0.01887345, -0.03676014, -0.01746018, -0.00505089,\n",
      "       -0.00495514, -0.02221038,  0.00734597, -0.02457649,  0.01958629,\n",
      "       -0.00150286, -0.00817053,  0.02833397,  0.03182454,  0.00413366,\n",
      "        0.04550329, -0.03923135,  0.03378687,  0.00785377, -0.0018571 ,\n",
      "       -0.02951536, -0.02467777, -0.02666589, -0.04103365, -0.00640677,\n",
      "       -0.03457658,  0.03871839, -0.03362087, -0.00123868,  0.0398059 ,\n",
      "       -0.01511135, -0.02833097,  0.03514184,  0.03603243,  0.03224551,\n",
      "        0.03410349, -0.04499953, -0.02059256, -0.01573974, -0.0066855 ,\n",
      "       -0.04533432, -0.0378898 ,  0.0453725 ,  0.01792984, -0.01493819,\n",
      "        0.03005158, -0.02943999, -0.00384724, -0.01675253], dtype=float32)))\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c85a0087-7388-4f03-9278-aace31121233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0, dtype=int32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a8266c7c-3688-46a5-a1c8-a63bb7146128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info.bandit_policy_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9712bc00-7ea0-4003-a3c7-81a0be5bc995",
   "metadata": {},
   "source": [
    "# [5] Prepare training application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f62966-123f-410e-9610-832f20566635",
   "metadata": {},
   "source": [
    "To scale this training in Vertex AI's managed training service, we need to package all our code into a python application\n",
    "\n",
    "* This means, we need to modularize all steps executed up until this point. For example, the training loop we ran above is further parameterized in `train_perarm.py`, which will be called from our `task.py` when we submit the job to Vertex AI\n",
    "* This training package will eventually be used to create a custom training image (more on that in `04b-build-training-image` notebook)\n",
    "* For additional details on preparing the training application for Vertex AI, check out [the documentation](https://cloud.google.com/vertex-ai/docs/training/code-requirements) and [this code example](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage2/get_started_vertex_training.ipynb) (which also has good, related commentary)\n",
    "\n",
    "**The remaining cells will repeat steps executed above**\n",
    "> we are just illustrating / validating that they are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1129ee41-b43c-4d5a-b656-cdac6b79688c",
   "metadata": {},
   "source": [
    "#### Vertex Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ef509680-4d19-4efa-9f01-21039e0d573b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : v2-local-2a-v1\n"
     ]
    }
   ],
   "source": [
    "# using same experiment name \n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7ad98430-d836-40f1-8e4f-eb46f0c91fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : v2-local-2a-v1\n",
      "RUN_NAME          : run-20231010-031407\n",
      "\n",
      "BASE_OUTPUT_DIR   : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407\n",
      "LOG_DIR           : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/logs\n",
      "ROOT_DIR          : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/root\n",
      "ARTIFACTS_DIR     : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/artifacts\n"
     ]
    }
   ],
   "source": [
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fbdecf78-94c5-4f8c-a6c0-86f2eace4663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: NeuralEpsGreedyAgent\n",
      "Network: commontower\n"
     ]
    }
   ],
   "source": [
    "# from src.perarm_features import agent_factory as agent_factory\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "    agent_type = AGENT_TYPE,\n",
    "    network_type = NETWORK_TYPE,\n",
    "    time_step_spec = time_step_spec,\n",
    "    action_spec = action_spec,\n",
    "    observation_spec=observation_spec,\n",
    "    global_layers = GLOBAL_LAYERS,\n",
    "    arm_layers = ARM_LAYERS,\n",
    "    common_layers = COMMON_LAYERS,\n",
    "    agent_alpha = AGENT_ALPHA,\n",
    "    learning_rate = LR,\n",
    "    epsilon = EPSILON,\n",
    "    train_step_counter = global_step,\n",
    "    output_dim = ENCODING_DIM,\n",
    "    eps_phase_steps = EPS_PHASE_STEPS,\n",
    ")\n",
    "\n",
    "print(f\"Agent: {agent.name}\")\n",
    "\n",
    "# if network:\n",
    "#     print(f\"Network: {network}\")\n",
    "\n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {NETWORK_TYPE}\")\n",
    "        \n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "108ed33c-d8ef-4524-97e9-ced9e01c154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHKPT_INTERVAL    : 200\n",
      "eval_batch_size   : 1\n",
      "EVAL_DATA_SIZE    : 1000\n",
      "NUM_EVAL_STEPS    : 100\n",
      "TOTAL_TRAIN_TAKE  : 10000\n"
     ]
    }
   ],
   "source": [
    "from src.perarm_features import train_perarm as train_perarm\n",
    "\n",
    "# train args\n",
    "TRAINING_LOOPS        = 150\n",
    "STEPS_PER_LOOP        = 1\n",
    "\n",
    "drop_arm_feature_fn   = None\n",
    "ASYNC_STEPS_PER_LOOP  = 1\n",
    "\n",
    "LOG_INTERVAL          = 10\n",
    "CHKPT_INTERVAL        = 200\n",
    "\n",
    "# eval args\n",
    "NUM_EVAL_STEPS = 100\n",
    "\n",
    "TOTAL_TRAIN_TAKE = 10000 #TRAINING_LOOPS * HPARAMS['batch_size']\n",
    "\n",
    "print(f\"CHKPT_INTERVAL    : {CHKPT_INTERVAL}\")\n",
    "print(f\"eval_batch_size   : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"EVAL_DATA_SIZE    : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS    : {NUM_EVAL_STEPS}\")\n",
    "print(f\"TOTAL_TRAIN_TAKE  : {TOTAL_TRAIN_TAKE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f66ff927-9a39-4abf-b247-845f0dc7721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS['eval_batch_size'])\n",
    "\n",
    "if NUM_EVAL_STEPS >= 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f6c98398-d545-4dcc-a71f-32249b5f0336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distribution_strategy: <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f9abd18b250>\n",
      "train_files: ['gs://rec-bandits-v2-hybrid-vertex-bucket/data/train/ml-ratings-100k-train.tfrecord']\n",
      "train_ds_iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f94e92e49a0>\n",
      "setting checkpoint_manager: gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/root/chkpoint\n",
      "wrapping agent.train in tf-function\n",
      "starting_loop: 0\n",
      "starting train loop...\n",
      "step = 100: loss = 15.920000076293945\n",
      "step = 110: loss = 9.289999961853027\n",
      "step = 120: loss = 7.329999923706055\n",
      "step = 130: loss = 1.2100000381469727\n",
      "step = 140: loss = 1.0399999618530273\n",
      "step = 150: loss = 1.590000033378601\n",
      "step = 160: loss = 1.6699999570846558\n",
      "step = 170: loss = 1.3700000047683716\n",
      "step = 180: loss = 1.3300000429153442\n",
      "step = 190: loss = 1.309999942779541\n",
      "step = 200: loss = 1.5199999809265137\n",
      "step = 210: loss = 1.309999942779541\n",
      "step = 220: loss = 1.1399999856948853\n",
      "step = 230: loss = 0.949999988079071\n",
      "step = 240: loss = 1.1299999952316284\n",
      "runtime_mins: 17\n",
      "saved trained policy to: gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/artifacts\n",
      "complete train job in 17 minutes\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    f\"{LOG_DIR}/train\", flush_millis=10 * 1000\n",
    ")\n",
    "\n",
    "#start the timer and training\n",
    "start_time = time.time()\n",
    "\n",
    "metric_results, agent = train_perarm.train_perarm(\n",
    "    agent = agent,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    num_iterations = TRAINING_LOOPS,\n",
    "    steps_per_loop = STEPS_PER_LOOP,\n",
    "    num_eval_steps = NUM_EVAL_STEPS,\n",
    "    # data\n",
    "    batch_size = HPARAMS['batch_size'],\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    # functions\n",
    "    _trajectory_fn = _trajectory_fn,\n",
    "    # _run_bandit_eval_fn = _run_bandit_eval,\n",
    "    # train intervals\n",
    "    chkpt_interval = CHKPT_INTERVAL,\n",
    "    log_interval = LOG_INTERVAL,\n",
    "    # dirs\n",
    "    bucket_name = BUCKET_NAME,\n",
    "    data_dir_prefix_path = DATA_GCS_PREFIX,\n",
    "    log_dir = LOG_DIR,\n",
    "    model_dir = ARTIFACTS_DIR,\n",
    "    root_dir = ROOT_DIR,\n",
    "    async_steps_per_loop = ASYNC_STEPS_PER_LOOP,\n",
    "    resume_training_loops = False,\n",
    "    use_gpu = True,\n",
    "    use_tpu = False,\n",
    "    profiler = False,\n",
    "    global_step = global_step,\n",
    "    total_train_take = TOTAL_TRAIN_TAKE,\n",
    "    train_summary_writer = train_summary_writer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"complete train job in {runtime_mins} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "177aa3ab-05b4-48f9-b434-9335bd9eb54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3775473"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(metric_results)\n",
    "metric_results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba65417f-54e0-436e-b0d4-93cffb981ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(metric_results)\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7ba747-00d5-4908-8d0b-334ae9d2c791",
   "metadata": {},
   "source": [
    "#### eval trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c5cf9366-d9cd-4c9d-951a-99a50877a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af82506e-95d7-4a4e-a821-e08512615db7",
   "metadata": {},
   "source": [
    "After training, our `agent.policy` is used as the deployment \"model\" that will generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6c82396a-7822-41fb-830f-1f6eb9c9b213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.epsilon_greedy_policy.EpsilonGreedyPolicy at 0x7f94e9160b80>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_agent = agent.policy\n",
    "deployment_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f6706224-ef5b-4185-bde4-bccb7c8e7ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating trained Agent...\n",
      "post-train val_loss     : 1.5848735570907593\n",
      "post-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(deployment_agent, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = post_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f899120f-3706-4b72-8f2c-2169221dd66b",
   "metadata": {},
   "source": [
    "## Using Trained Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b0f691-860e-4853-928e-4c7ece714dd0",
   "metadata": {},
   "source": [
    "### load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ea029f73-0638-462a-8f00-54b05c54d69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/artifacts\n"
     ]
    }
   ],
   "source": [
    "POLICY_URI = ARTIFACTS_DIR\n",
    "\n",
    "print(POLICY_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "66d1d819-0152-437c-aefc-45ffd34d808a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/artifacts/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/artifacts/fingerprint.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/artifacts/policy_specs.pbtxt\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/artifacts/saved_model.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/artifacts/assets/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/artifacts/variables/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $POLICY_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6aad948e-e346-4da3-8cb2-747435c8dc4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f94eb67aef0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "483f8fa5-cbd1-4e3c-8e62-47f91f42e137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(), dtype=dtype('int32'), name='action_spec', minimum=0, maximum=1)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_policy.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8f658891-bc09-49b8-bc58-000a7926df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "SKIP_NUM = 10\n",
    "\n",
    "for x in eval_ds.skip(SKIP_NUM).take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    \n",
    "    # global_feat_infer = _get_global_context_features(x)\n",
    "    # arm_feat_infer = _get_per_arm_features(x)\n",
    "    \n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "    \n",
    "    # rewards = _get_rewards(x)\n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f515fcd0-2228-4f68-9ef9-665ce1fc3fb2",
   "metadata": {},
   "source": [
    "### view prediction response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6af4c297-d2e8-4f7b-bed5-e1da997dfe34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.2646697, 3.2237158], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([-0.04211991,  0.03355854,  0.00062222, -0.03559208,  0.03014546,\n",
       "       -0.00911941,  0.03367225, -0.01702491, -0.04207989,  0.02439343,\n",
       "        0.03417565,  0.03412655, -0.01548523, -0.04152564, -0.01327814,\n",
       "        0.04441997, -0.01887345, -0.03676014, -0.01746018, -0.00505089,\n",
       "       -0.00495514, -0.02221038,  0.00734597, -0.02457649,  0.01958629,\n",
       "       -0.00150286, -0.00817053,  0.02833397,  0.03182454,  0.00413366,\n",
       "        0.04550329, -0.03923135,  0.03378687,  0.00785377, -0.0018571 ,\n",
       "       -0.02951536, -0.02467777, -0.02666589, -0.04103365, -0.00640677,\n",
       "       -0.03457658,  0.03871839, -0.03362087, -0.00123868,  0.0398059 ,\n",
       "       -0.01511135, -0.02833097,  0.03514184,  0.03603243,  0.03224551,\n",
       "        0.03410349, -0.04499953, -0.02059256, -0.01573974, -0.0066855 ,\n",
       "       -0.04533432, -0.0378898 ,  0.0453725 ,  0.01792984, -0.01493819,\n",
       "        0.03005158, -0.02943999, -0.00384724, -0.01675253], dtype=float32)))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd58d4b-6749-4177-8342-83ee969408c9",
   "metadata": {},
   "source": [
    "#### chosen action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d49adbbb-f747-4e4c-b82d-df88373c644f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0, dtype=int32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd12013-1d12-4197-8254-cef9138df42c",
   "metadata": {},
   "source": [
    "#### Per Arm Policy Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d6126290-546b-4702-8a1e-91f18adb05c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.2646697, 3.2237158], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([-0.04211991,  0.03355854,  0.00062222, -0.03559208,  0.03014546,\n",
       "       -0.00911941,  0.03367225, -0.01702491, -0.04207989,  0.02439343,\n",
       "        0.03417565,  0.03412655, -0.01548523, -0.04152564, -0.01327814,\n",
       "        0.04441997, -0.01887345, -0.03676014, -0.01746018, -0.00505089,\n",
       "       -0.00495514, -0.02221038,  0.00734597, -0.02457649,  0.01958629,\n",
       "       -0.00150286, -0.00817053,  0.02833397,  0.03182454,  0.00413366,\n",
       "        0.04550329, -0.03923135,  0.03378687,  0.00785377, -0.0018571 ,\n",
       "       -0.02951536, -0.02467777, -0.02666589, -0.04103365, -0.00640677,\n",
       "       -0.03457658,  0.03871839, -0.03362087, -0.00123868,  0.0398059 ,\n",
       "       -0.01511135, -0.02833097,  0.03514184,  0.03603243,  0.03224551,\n",
       "        0.03410349, -0.04499953, -0.02059256, -0.01573974, -0.0066855 ,\n",
       "       -0.04533432, -0.0378898 ,  0.0453725 ,  0.01792984, -0.01493819,\n",
       "        0.03005158, -0.02943999, -0.00384724, -0.01675253], dtype=float32))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f66961-ebb5-4ae5-8e6f-ad73114d8353",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
