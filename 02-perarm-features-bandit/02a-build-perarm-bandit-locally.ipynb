{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385307d6-2058-47ec-8da0-57f7ef5c43d6",
   "metadata": {},
   "source": [
    "# Train Bandits with per-arm features\n",
    "\n",
    "**Exploring linear and nonlinear** (e.g., those with neural network-based value functions) bandit methods for recommendations using TF-Agents\n",
    "\n",
    "> Neural linear bandits provide a nice way to leverage the representation power of deep learning and the bandit approach for uncertainty measure and efficient exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fd257-b98b-426a-a2cd-024429b014f1",
   "metadata": {},
   "source": [
    "## Load notebook config\n",
    "\n",
    "* use the prefix defined in `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f39c9d08-d118-4013-a47f-88450f49f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = 'mabv1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908f6b95-b539-4a9f-a836-840d26ea3b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"mabv1\"\n",
      "VERSION                  = \"v1\"\n",
      "\n",
      "BUCKET_NAME              = \"mabv1-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://mabv1-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://mabv1-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_ID      = \"hybrid-vertex.movielens_dataset_mabv1\"\n",
      "BIGQUERY_TABLE_ID        = \"hybrid-vertex.movielens_dataset_mabv1.training_dataset\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-mabv1\"\n",
      "IMAGE_NAME               = \"train-perarm-feats-v1\"\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-mabv1/train-perarm-feats-v1\"\n",
      "DOCKERNAME               = \"Dockerfile_perarm_feats\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c690a9-e2bd-4759-ba41-4e2469098aee",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d0dfe4-695c-4dd4-9f24-67f7488ce1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c669f1a1-1af7-4efb-ab2d-6bf3b3847991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from collections import defaultdict\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pickle as pkl\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "# from tf_agents.agents import TFAgent\n",
    "\n",
    "# from tf_agents.bandits.environments import stationary_stochastic_per_arm_py_environment as p_a_env\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "# from tf_agents.drivers import dynamic_step_driver\n",
    "# from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "# from tf_agents.bandits.agents import lin_ucb_agent\n",
    "# from tf_agents.bandits.agents import linear_thompson_sampling_agent as lin_ts_agent\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent\n",
    "from tf_agents.bandits.agents import neural_linucb_agent\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "from tf_agents.bandits.policies import policy_utilities\n",
    "\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# this repo\n",
    "from src.per_arm_rl import data_utils\n",
    "from src.per_arm_rl import data_config\n",
    "from src.per_arm_rl import train_utils as train_utils\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29e58dd7-ab2b-419f-9771-bf1e98db758b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4969d3e-1fc0-45db-8a69-aa6b342019de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "274e7f4a-1802-4946-888e-876638f5c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a866b1-85b9-43e6-9546-edfbbf886bce",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd5b953-14c0-42ed-a511-77147a1bc0ac",
   "metadata": {},
   "source": [
    "### Read TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d0157c8-a04c-4dbd-b6d9-a1ede97687a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da0cdac-76af-4608-b70e-be7dbe0584b5",
   "metadata": {},
   "source": [
    "**Train data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c934c06-bf08-4c7f-b0cc-0de04ef3515c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://mabv1-hybrid-vertex-bucket/data/train/ml-ratings-100k-train.tfrecord']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPLIT = \"train\" # \"train\" | \"val\"\n",
    "\n",
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7511e4d-bf81-4800-bde7-8b16dec9aeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([35.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'898'], dtype=object)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([885409515])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'681'], dtype=object)>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'marketing'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "train_dataset = train_dataset.map(data_utils.parse_tfrecord)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452750c1-46a0-4ee1-84d4-0c3b227de38f",
   "metadata": {},
   "source": [
    "**Val data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7b5376f-9438-4304-84aa-de09c30f5e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = \"val\"\n",
    "\n",
    "val_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        val_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "val_dataset = tf.data.TFRecordDataset(val_files)\n",
    "val_dataset = val_dataset.map(data_utils.parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8959967-522e-41c8-9a1b-050ca8bc191f",
   "metadata": {},
   "source": [
    "### get vocab\n",
    "\n",
    "**TODO:** \n",
    "* streamline vocab calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b9169bc-d6dc-497e-9dff-6ebb175282ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE_VOCABS: False\n"
     ]
    }
   ],
   "source": [
    "GENERATE_VOCABS = False\n",
    "\n",
    "print(f\"GENERATE_VOCABS: {GENERATE_VOCABS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3ccf137-7a72-42e7-aa89-3c81a99cf40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab...\n",
      "Downloaded vocab from: gs://mabv1-hybrid-vertex-bucket/vocabs/vocab_dict.pkl\n",
      "\n",
      "'movie_id'\n",
      "'user_id'\n",
      "'user_occupation_text'\n",
      "'movie_genres'\n",
      "'bucketized_user_age'\n",
      "'max_timestamp'\n",
      "'min_timestamp'\n",
      "'timestamp_buckets'\n"
     ]
    }
   ],
   "source": [
    "if not GENERATE_VOCABS:\n",
    "\n",
    "    EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{VOCAB_SUBDIR}/{VOCAB_FILENAME}'\n",
    "    print(f\"Downloading vocab...\")\n",
    "    \n",
    "    os.system(f'gsutil -q cp {EXISTING_VOCAB_FILE} .')\n",
    "    print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "    filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "    vocab_dict = pkl.load(filehandler)\n",
    "    filehandler.close()\n",
    "    \n",
    "    for key in vocab_dict.keys():\n",
    "        pprint(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccaef62-882a-46ff-a1b1-3837e69fdf74",
   "metadata": {},
   "source": [
    "## helper functions\n",
    "\n",
    "**TODO:**\n",
    "* modularize in a train_utils or similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b941063b-ad48-4817-aef0-9afa8a444632",
   "metadata": {},
   "source": [
    "# Multi-Armed Bandits (MAB) with Per-Arm Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28770b8d-836b-448d-8dd1-203d76fc6d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "\n",
    "nest = tf.nest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138a295-2b0d-4359-8496-af8552ec8cff",
   "metadata": {},
   "source": [
    "# [1] Preprocessing layers for global and arm features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e28c002-8d3a-4cf4-b69b-de56a6abab90",
   "metadata": {},
   "source": [
    "The preproccesing layers will ultimately feed the two sampling functions described below. These sampling functions will be used to create [trajectories](https://github.com/tensorflow/agents/blob/master/tf_agents/trajectories/trajectory.py#L36) (i.e., the training examples for our model)\n",
    "\n",
    "`global_context_sampling_fn`: \n",
    "* A function that outputs a random 1d array or list of ints or floats\n",
    "* This output is the global context. Its shape and type must be consistent across calls.\n",
    "\n",
    "`arm_context_sampling_fn`: \n",
    "* A function that outputs a random 1 array or list of ints or floats (same type as the output of `global_context_sampling_fn`). * This output is the per-arm context. Its shape must be consistent across calls.\n",
    "\n",
    "See `debug-and-learn-emb-models.ipynb` for more details and debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ea1f7-0621-44b8-b062-1f59b0964d72",
   "metadata": {},
   "source": [
    "## Global & Per-Arm feature embedding models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8d77956-635c-438a-916a-185eec52f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OOV_BUCKETS        = 1\n",
    "GLOBAL_EMBEDDING_SIZE  = 16\n",
    "MV_EMBEDDING_SIZE      = 32 #32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea335991-dcec-40b3-ba0d-a0fdfb9c2ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test emb models\n",
    "for i in range(1):\n",
    "    \n",
    "    iterator = iter(train_dataset.batch(1))\n",
    "    data = next(iterator)\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48178fff-491f-4f03-b156-7765d1fa9707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.perarm_features.emb_features.EmbeddingModel at 0x7fdc03e98b50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.perarm_features import emb_features as emb_features\n",
    "\n",
    "embs = emb_features.EmbeddingModel(\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "903c63c5-2468-4443-bcb8-5ff6d69810dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL_DIM: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.03251201,  0.00829065, -0.02318633,  0.02243404, -0.00780901,\n",
       "        -0.00975193, -0.02958925, -0.04358155, -0.0143814 ,  0.00427138,\n",
       "         0.00503702,  0.01320987, -0.03584567,  0.02827534, -0.04026078,\n",
       "        -0.01091971, -0.0045109 ,  0.03326385,  0.0095135 , -0.03532112,\n",
       "         0.02868105, -0.02276157,  0.03525009,  0.02018645, -0.04322484,\n",
       "        -0.04522879, -0.03629296,  0.02257148,  0.02898121,  0.0136266 ,\n",
       "         0.02766737,  0.01545722, -0.03498756, -0.01622604,  0.03414085,\n",
       "        -0.03191185,  0.01756115,  0.03618162, -0.02317697, -0.02059099,\n",
       "        -0.03795673,  0.04069367, -0.01537473,  0.03380514, -0.02368656,\n",
       "         0.0294126 ,  0.03984281,  0.01620276,  0.04856462,  0.02183762,\n",
       "        -0.02616562,  0.03498492, -0.04644047, -0.04205615,  0.04022701,\n",
       "         0.0433786 , -0.01728719,  0.04571128,  0.02756457, -0.01905054,\n",
       "        -0.04312966,  0.04691458, -0.03492637,  0.04981769]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_globals = embs._get_global_context_features(data)\n",
    "\n",
    "GLOBAL_DIM = test_globals.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"GLOBAL_DIM: {GLOBAL_DIM}\")\n",
    "\n",
    "test_globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebec4863-c614-4248-b680-8e29ec5b730d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER_ARM_DIM: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.02331253,  0.01763456, -0.01509279, -0.00846093, -0.03259729,\n",
       "        -0.03215895, -0.013973  , -0.00315728,  0.04549713,  0.03697778,\n",
       "         0.03952043, -0.02328919, -0.00915731, -0.04105147, -0.02538812,\n",
       "        -0.02549727,  0.04142639,  0.04597969,  0.04345094,  0.02283164,\n",
       "        -0.01721931, -0.04458519, -0.02075685,  0.03568925, -0.00178016,\n",
       "         0.00636301, -0.04166872, -0.01563058, -0.01603962,  0.04067905,\n",
       "         0.03491807,  0.02167085,  0.04499574, -0.04656927,  0.00801452,\n",
       "         0.0406739 , -0.04451339, -0.03209086,  0.00298439, -0.00328119,\n",
       "        -0.01383279, -0.03071114,  0.00951078,  0.03388113, -0.00048409,\n",
       "         0.03062958,  0.00920714,  0.0217711 , -0.03436805, -0.0425965 ,\n",
       "         0.04793845, -0.02773167,  0.00390674, -0.02033259, -0.01817782,\n",
       "         0.00326562,  0.04278379,  0.03872154, -0.03521571, -0.02986544,\n",
       "         0.02474088, -0.00424479, -0.02247034, -0.03386156]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arms = embs._get_per_arm_features(data)\n",
    "\n",
    "PER_ARM_DIM = test_arms.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"PER_ARM_DIM: {PER_ARM_DIM}\")\n",
    "\n",
    "test_arms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac6836c-67b7-4fd4-917a-24ddad708edd",
   "metadata": {},
   "source": [
    "# [2] Implementing MAB with TF-Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1877c79c-b6c8-4048-b1ce-05f011e8d69e",
   "metadata": {},
   "source": [
    "In TF-Agents, the *per-arm features* implementation differs from the *global-only* feature examples in the following aspects:\n",
    "* Reward is modeled not per-arm, but globally.\n",
    "* The arms are permutation invariant: it doesn’t matter which arm is arm 1 or arm 2, only their features.\n",
    "* One can have a different number of arms to choose from in every step (note that unspecified/dynamically changing number of arms will have a problem with XLA compatibility).\n",
    "\n",
    "When implementing per-arm features in TF-Bandits, the following details have to be discussed:\n",
    "* Observation spec and observations,\n",
    "* Action spec and actions,\n",
    "* Implementation of specific policies and agents.\n",
    "\n",
    "\n",
    "**TODO:**\n",
    "* outline the components and highlight their interactions, dependencies on eachother, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ff9baaf-987d-448d-a981-742a79b581e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE      : 128\n",
      "EVAL_BATCH_SIZE : 1\n",
      "NUM_ACTIONS     : 2\n",
      "GLOBAL_DIM      : 64\n",
      "PER_ARM_DIM     : 64\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE      = 128\n",
    "EVAL_BATCH_SIZE = 1\n",
    "\n",
    "NUM_ACTIONS     = 2 #this is kinda deceptive - \n",
    "#our approach is to learn by \"flashing\" one movie rating at a time per user context. \n",
    "#The n_actions = show/don't show the movie with one degree of freedom (n-1)\n",
    "\n",
    "\n",
    "print(f\"BATCH_SIZE      : {BATCH_SIZE}\")\n",
    "print(f\"EVAL_BATCH_SIZE : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"NUM_ACTIONS     : {NUM_ACTIONS}\")\n",
    "print(f\"GLOBAL_DIM      : {GLOBAL_DIM}\")\n",
    "print(f\"PER_ARM_DIM     : {PER_ARM_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeb4902-5bb9-4587-8d29-c01d78b006be",
   "metadata": {},
   "source": [
    "## Tensor Specs\n",
    "\n",
    "* say you have a global observation spec of `[17]`. And you have two batch dimensions `[4, 5]`. Then your observation has to have the shape `[4, 5, 17]`\n",
    "* and then if you have arm_obs_spec with shape `[9, 13]`, then the arm obs shape has to be exactly `[4, 5, 9, 13]`\n",
    "* and this has to be true for every single tensor in your tensor nest\n",
    "* the first 2 dims are the outer dims that are the same for all tensors, the rest of the dimensions have to follow the spec for each tensor\n",
    "\n",
    "**TODO:**\n",
    "* explain relationship between Tensor Specs and their Tensor counterparts\n",
    "* highlight the errors, lessons learned, and utility functions to address these"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f68ebe8-116d-43b3-a6e1-4f5a5c7f4741",
   "metadata": {},
   "source": [
    "### Observation spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9c4746-d01b-4ca4-aa53-ab68da54d37a",
   "metadata": {},
   "source": [
    "**This observation spec allows the user to have a global observation of fixed dimension**, and an unspecified number of *per-arm* features (also of fixed dimension)\n",
    "* The actions output by the policy are still integers as usual, and they indicate which row of the arm-features it has chosen \n",
    "* The action spec must be a single integer value without boundaries:\n",
    "\n",
    "```python\n",
    "global_spec = tensor_spec.TensorSpec([GLOBAL_DIM], tf.float32)\n",
    "per_arm_spec = tensor_spec.TensorSpec([None, PER_ARM_DIM], tf.float32)\n",
    "observation_spec = {'global': global_spec, 'per_arm': per_arm_spec}\n",
    "\n",
    "action_spec = tensor_spec.TensorSpec((), tf.int32)\n",
    "```\n",
    "> Here the only difference compared to the action spec with global features only is that the tensor spec is not bounded, as we don’t know how many arms there will be at any time step\n",
    "\n",
    "**XLA compatibility:**\n",
    "* Since dynamic tensor shapes are not compatible with XLA, the number of arm features (and consequently, number of arms for a step) cannot be dynamic. \n",
    "* One workaround is to fix the maximum number of arms for a problem, then pad the arm features in steps with fewer arms, and use action masking to indicate how many arms are actually active.\n",
    "\n",
    "```python\n",
    "per_arm_spec = tensor_spec.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32)\n",
    "\n",
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=(), dtype=tf.int32, minimum = 0, maximum = NUM_ACTIONS - 1\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36bd3b33-635a-4274-8b9e-7172696ebb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_spec = {\n",
    "    'global': tf.TensorSpec([GLOBAL_DIM], tf.float32),\n",
    "    'per_arm': tf.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32) #excluding action dim here\n",
    "}\n",
    "observation_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a2da92-7db2-4f42-94a7-b7bad1c8fc42",
   "metadata": {},
   "source": [
    "### Action spec\n",
    "\n",
    "> The time_step_spec and action_spec are specifications for the input time step and the output action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5af42c7-18d7-480f-a7f3-d7da3f4840eb",
   "metadata": {},
   "source": [
    "```python\n",
    "    if (\n",
    "        not tensor_spec.is_bounded(action_spec)\n",
    "        or not tensor_spec.is_discrete(action_spec)\n",
    "        or action_spec.shape.rank > 1\n",
    "        or action_spec.shape.num_elements() != 1\n",
    "    ):\n",
    "      raise NotImplementedError(\n",
    "          'action_spec must be a BoundedTensorSpec of type int32 and shape (). '\n",
    "          'Found {}.'.format(action_spec)\n",
    "      )\n",
    "```\n",
    "\n",
    "* [src](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_base_policy.py#L97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "549a123c-349a-4103-b39a-4502f47d1e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=[], \n",
    "    dtype=tf.int32,\n",
    "    minimum=tf.constant(0),            \n",
    "    maximum=NUM_ACTIONS-1, # n degrees of freedom and will dictate the expected mean reward spec shape\n",
    "    name=\"action_spec\"\n",
    ")\n",
    "\n",
    "action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36ee2635-d4e3-4468-886c-ae9c62e3c80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_num_actions: 2\n",
      "predicted_rewards_mean: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n"
     ]
    }
   ],
   "source": [
    "expected_num_actions = action_spec.maximum - action_spec.minimum + 1\n",
    "print(f\"expected_num_actions: {expected_num_actions}\")\n",
    "\n",
    "predicted_rewards_mean = tensor_spec.TensorSpec([expected_num_actions])\n",
    "print(f\"predicted_rewards_mean: {predicted_rewards_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a51efce-9f1b-42d1-bec4-7b788e3fd7e0",
   "metadata": {},
   "source": [
    "### TimeStep spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95f05860-0fbf-4a5a-8273-9c81761e0ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec = ts.time_step_spec(\n",
    "    observation_spec = observation_spec, \n",
    "    # reward_spec = _reward_spec\n",
    ")\n",
    "time_step_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9181303-6565-45f5-a293-08d50420a805",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Inspect chosen arm features spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6b526a5-997c-4621-b21c-82c6ca1d6a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90d3e03e-619e-4fa4-b817-f02b4cefd6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(64,), dtype=tf.float32, name=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_arm_features_info = (\n",
    "  policy_utilities.create_chosen_arm_features_info_spec(\n",
    "      time_step_spec.observation,\n",
    "  )\n",
    ")\n",
    "chosen_arm_features_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc427092-beb7-4baf-a2e9-b8d10629182c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - dont understand this\n",
    "bandit_policy_type = (\n",
    "    policy_utilities.BanditPolicyType.GREEDY\n",
    ")\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a4a2a33-c7d4-4d81-8082-80dfc3596741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - dont understand this\n",
    "bandit_policy_type = (\n",
    "    policy_utilities.create_bandit_policy_type_tensor_spec(shape=[1])\n",
    ")\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e7ac02b-18bd-4519-92fe-5541b1a8ddc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_spec = policy_utilities.PerArmPolicyInfo(\n",
    "  predicted_rewards_mean=predicted_rewards_mean,\n",
    "  bandit_policy_type=bandit_policy_type,\n",
    "  chosen_arm_features=chosen_arm_features_info,\n",
    ")\n",
    "info_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9c197-ae9b-461d-8956-f078b929ac12",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The Agent\n",
    "\n",
    "**Note** that contextual bandits form a special case of RL, where the actions taken by the agent do not alter the state of the environment \n",
    "\n",
    "> “Contextual” refers to the fact that the agent chooses among a set of actions while having knowledge of the context (environment observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81d6e84-688e-48c5-aea1-77df031348c9",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Agent & Network defined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aadb01-eb5c-4870-ae14-9e66624ba594",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Agent types**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d075e8a6-11a9-4346-8725-3653fba4bac4",
   "metadata": {},
   "source": [
    "> `AGENT_TYPE = ['LinUCB', 'LinTS', 'epsGreedy', 'NeuralLinUCB']`\n",
    "\n",
    "LinearUCBAgent: (`LinUCB`) \n",
    "* An agent implementing the Linear UCB bandit algorithm ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/lin_ucb_agent/LinearUCBAgent))\n",
    "\n",
    "LinearThompsonSamplingAgent: (`LinTS`) \n",
    "* Implements the Linear Thompson Sampling Agent from the [paper](https://arxiv.org/abs/1209.3352): *Thompson Sampling for Contextual Bandits with Linear Payoffs* ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/linear_thompson_sampling_agent/LinearThompsonSamplingAgent))\n",
    "\n",
    "NeuralEpsilonGreedyAgent: (`epsGreedy`) \n",
    "* A neural network based epsilon greedy agent ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_epsilon_greedy_agent/NeuralEpsilonGreedyAgent))\n",
    "\n",
    "NeuralLinUCBAgent: (`NeuralLinUCB`) \n",
    "* An agent implementing the LinUCB algorithm on top of a neural network ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_linucb_agent/NeuralLinUCBAgent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b8e88e-c8ea-4193-a911-0d974ef3b1a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Network types**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f547087d-5fad-4521-a584-cb46ce52897d",
   "metadata": {},
   "source": [
    "Which network architecture to use for the `epsGreedy` or `NeuralLinUCB` agents\n",
    "\n",
    "```\n",
    "NETWORK_TYPE = ['commontower', 'dotproduct']\n",
    "```\n",
    "\n",
    "**GlobalAndArmCommonTowerNetwork:** (`commontower`)\n",
    "* This network takes the output of the global and per-arm networks, and leads them through a common network, that in turn outputs reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "> * `COMMON_LAYERS` - Iterable of ints. Specifies the layers of the common tower\n",
    "* The network produced by this function can be used either in `GreedyRewardPredictionPolicy`, or `NeuralLinUCBPolicy`\n",
    "> * In the former case, the network must have `output_dim=1`, it is going to be an instance of `QNetwork`, and used in the policy as a reward prediction network\n",
    "> * In the latter case, the network will be an encoding network with its output consumed by a reward layer or a `LinUCB` method. The specified `output_dim` will be the encoding dimension\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmCommonTowerNetwork)\n",
    "\n",
    "**GlobalAndArmDotProductNetwork:** (`dotproduct`)\n",
    "* This network calculates the **dot product** of the output of the global and per-arm networks and returns them as reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmDotProductNetwork)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3dc270-deb5-4e96-8276-74759a06c318",
   "metadata": {},
   "source": [
    "### Agent config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbe29263-453d-405e-ac50-fee7f379f335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\n",
      "\n",
      "time_step_spec:  TimeStep(\n",
      "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
      "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n",
      "\n",
      "action_spec:  BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))\n",
      "\n",
      "observation_spec:  {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\")\n",
    "print(\"\\ntime_step_spec: \", time_step_spec)\n",
    "print(\"\\naction_spec: \", action_spec)\n",
    "print(\"\\nobservation_spec: \", observation_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d817bf2-1fa6-4bae-af90-745fad996b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'common_layers': [16, 8],\n",
      " 'epsilon': 0.01,\n",
      " 'eval_batch_size': 1,\n",
      " 'global_layers': [64, 32, 16],\n",
      " 'learning_rate': 0.05,\n",
      " 'model_type': 'epsGreedy',\n",
      " 'network_type': 'commontower',\n",
      " 'num_actions': 2,\n",
      " 'per_arm_layers': [64, 32, 16]}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Agents\n",
    "# ================================\n",
    "AGENT_TYPE      = 'epsGreedy' # 'LinUCB' | 'LinTS |, 'epsGreedy' | 'NeuralLinUCB'\n",
    "\n",
    "# Parameters for linear agents (LinUCB and LinTS).\n",
    "AGENT_ALPHA     = 0.1\n",
    "\n",
    "# Parameters for neural agents (NeuralEpsGreedy and NerualLinUCB).\n",
    "EPSILON         = 0.01\n",
    "LR              = 0.05\n",
    "\n",
    "# Parameters for NeuralLinUCB\n",
    "ENCODING_DIM    = 1\n",
    "EPS_PHASE_STEPS = 1000\n",
    "\n",
    "# ================================\n",
    "# Agent's Preprocess Network\n",
    "# ================================\n",
    "NETWORK_TYPE    = \"commontower\" # 'commontower' | 'dotproduct'\n",
    "\n",
    "if AGENT_TYPE == 'NeuralLinUCB':\n",
    "    NETWORK_TYPE = 'commontower'\n",
    "    \n",
    "GLOBAL_LAYERS   = [64, 32, 16]\n",
    "ARM_LAYERS      = [64, 32, 16]\n",
    "COMMON_LAYERS   = [16, 8]\n",
    "\n",
    "HPARAMS = {  # TODO - streamline and consolidate\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"eval_batch_size\" : EVAL_BATCH_SIZE,\n",
    "    \"num_actions\": NUM_ACTIONS,\n",
    "    \"model_type\": AGENT_TYPE,\n",
    "    \"network_type\": NETWORK_TYPE,\n",
    "    \"global_layers\": GLOBAL_LAYERS,\n",
    "    \"per_arm_layers\": ARM_LAYERS,\n",
    "    \"common_layers\": COMMON_LAYERS,\n",
    "    \"learning_rate\": LR,\n",
    "    \"epsilon\": EPSILON,\n",
    "}\n",
    "pprint(HPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2bf060bb-9880-40b4-8583-dd7a3f915bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent: NeuralEpsGreedyAgent\n",
      "Network: commontower\n"
     ]
    }
   ],
   "source": [
    "from src.perarm_features import agent_factory as agent_factory\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "    agent_type = AGENT_TYPE,\n",
    "    network_type = NETWORK_TYPE,\n",
    "    time_step_spec = time_step_spec,\n",
    "    action_spec = action_spec,\n",
    "    observation_spec=observation_spec,\n",
    "    global_layers = GLOBAL_LAYERS,\n",
    "    arm_layers = ARM_LAYERS,\n",
    "    common_layers = COMMON_LAYERS,\n",
    "    agent_alpha = AGENT_ALPHA,\n",
    "    learning_rate = LR,\n",
    "    epsilon = EPSILON,\n",
    "    train_step_counter = global_step,\n",
    "    output_dim = ENCODING_DIM,\n",
    "    eps_phase_steps = EPS_PHASE_STEPS,\n",
    ")\n",
    "      \n",
    "agent.initialize()\n",
    "print(f'agent: {agent.name}')\n",
    "\n",
    "# if network:\n",
    "#     print(f\"Network: {network}\")\n",
    "\n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {NETWORK_TYPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d77d1-a0b3-4898-adf0-0b32bfaf5bd7",
   "metadata": {},
   "source": [
    "#### tmp - debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78ca56e7-a386-4bf4-8c2b-3d1665521f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41483f5a-bda6-48a4-9e1c-88d8b4afeea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.time_step_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f205716-f265-4ca8-81a7-4799de8f60a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(Trajectory(\n",
       "{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32)),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None)}),\n",
       " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None)),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.training_data_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d404dae-3cc3-4f81-962b-4641455ca4f2",
   "metadata": {},
   "source": [
    "## Reward function\n",
    "\n",
    "> see `reward_factory.py`\n",
    "\n",
    "**TODO:**\n",
    "* explain how to translate reward to this common recommendation objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df9aecd6-d20a-48a7-9ead-4da3bbcfdae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _get_rewards(element):\n",
    "#     \"\"\"Calculates reward for the actions.\"\"\"\n",
    "\n",
    "#     def _calc_reward(x):\n",
    "#         \"\"\"Calculates reward for a single action.\"\"\"\n",
    "#         r0 = lambda: tf.constant(0.0)\n",
    "#         r1 = lambda: tf.constant(1.0)\n",
    "#         r2 = lambda: tf.constant(2.0)\n",
    "#         r3 = lambda: tf.constant(3.0)\n",
    "#         r4 = lambda: tf.constant(4.0)\n",
    "#         r5 = lambda: tf.constant(5.0)\n",
    "#         c1 = tf.equal(x, 1.0)\n",
    "#         c2 = tf.equal(x, 2.0)\n",
    "#         c3 = tf.equal(x, 3.0)\n",
    "#         c4 = tf.equal(x, 4.0)\n",
    "#         c5 = tf.equal(x, 5.0)\n",
    "#         return tf.case(\n",
    "#             [(c1, r1), (c2, r2), (c3, r3),(c4, r4),(c5, r5)], \n",
    "#             default=r0, exclusive=True\n",
    "#         )\n",
    "\n",
    "#     return tf.map_fn(\n",
    "#         fn=_calc_reward, \n",
    "#         elems=element['user_rating'], \n",
    "#         dtype=tf.float32\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac59703a-9a00-4eba-a3b7-45b21b738dd4",
   "metadata": {},
   "source": [
    "## Trajectory function\n",
    "\n",
    "**parking lot**\n",
    "* does trajectory fn need concept of `dummy_chosen_arm_features`, similar to [this](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_base_policy.py#L297)\n",
    "\n",
    "```python\n",
    "      dummy_chosen_arm_features = tf.nest.map_structure(\n",
    "          lambda obs: tf.zeros_like(obs[:, 0, ...]),\n",
    "          time_step.observation[bandit_spec_utils.PER_ARM_FEATURE_KEY],\n",
    "      )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c16aa7b-f328-425e-b02e-a3fc7f200859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.perarm_features import reward_factory as reward_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3605d9f-d239-4871-9a61-6e9b21f9c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _trajectory_fn(element): # hparams\n",
    "    \n",
    "    \"\"\"Converts a dataset element into a trajectory.\"\"\"\n",
    "    # global_features = _get_global_context_features(element)\n",
    "    # arm_features = _get_per_arm_features(element)\n",
    "    \n",
    "    global_features = embs._get_global_context_features(element)\n",
    "    arm_features = embs._get_per_arm_features(element)\n",
    "    \n",
    "    # Adds a time dimension.\n",
    "    arm_features = train_utils._add_outer_dimension(arm_features)\n",
    "\n",
    "    # obs spec\n",
    "    observation = {\n",
    "        bandit_spec_utils.GLOBAL_FEATURE_KEY:\n",
    "            train_utils._add_outer_dimension(global_features),\n",
    "    }\n",
    "\n",
    "    # reward = train_utils._add_outer_dimension(_get_rewards(element))\n",
    "    reward = train_utils._add_outer_dimension(reward_factory._get_rewards(element))\n",
    "\n",
    "    # To emit the predicted rewards in policy_info, we need to create dummy\n",
    "    # rewards to match the definition in TensorSpec for the ones specified in\n",
    "    # emit_policy_info set.\n",
    "    dummy_rewards = tf.zeros([HPARAMS['batch_size'], 1, HPARAMS['num_actions']])\n",
    "    policy_info = policy_utilities.PerArmPolicyInfo(\n",
    "        chosen_arm_features=arm_features,\n",
    "        # Pass dummy mean rewards here to match the model_spec for emitting\n",
    "        # mean rewards in policy info\n",
    "        predicted_rewards_mean=dummy_rewards,\n",
    "        bandit_policy_type=policy_utilities.BanditPolicyType.GREEDY\n",
    "    )\n",
    "    \n",
    "    if HPARAMS['model_type'] == 'neural_ucb':\n",
    "        policy_info = policy_info._replace(\n",
    "            predicted_rewards_optimistic=dummy_rewards\n",
    "        )\n",
    "        \n",
    "    return trajectory.single_step(\n",
    "        observation=observation,\n",
    "        action=tf.zeros_like(\n",
    "            reward, dtype=tf.int32\n",
    "        ),  # Arm features are copied from policy info, put dummy zeros here\n",
    "        policy_info=policy_info,\n",
    "        reward=reward,\n",
    "        discount=tf.zeros_like(reward)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a0989c-5a06-4fd5-a12d-d92dbbe71a76",
   "metadata": {},
   "source": [
    "Inspect the trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "257791d1-c97c-48c0-bc92-f5a4737b6c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in train_dataset.batch(HPARAMS['batch_size']).take(1):\n",
    "    test_traj = _trajectory_fn(x)\n",
    "    \n",
    "# test_traj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d8994e-ce28-4fd9-8e3b-153451d014d9",
   "metadata": {},
   "source": [
    "#### tmp - debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a0e451f-1ad8-4af2-84d6-ddc5eaac0e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.action.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.action.shape: {test_traj.action.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52ed1767-12ce-404c-9caf-0974d55ec5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.discount.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.discount.shape: {test_traj.discount.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "033ff16b-0158-477f-835f-99deec636b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.reward.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.reward.shape: {test_traj.reward.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee5aded7-7f9c-4a88-868c-f6ab58a0e704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.observation.shape: (128, 1, 64)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.observation.shape: {test_traj.observation['global'].shape}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cb47f4-03b7-424f-ae40-6d00390782b1",
   "metadata": {},
   "source": [
    "#### TODO: write trajectories to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b9d6180-4b3f-49cc-92f9-b7bce48c329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAJECTORY_SUBDIR = \"trajectories\"\n",
    "# os.mkdir(f'{TRAJECTORY_SUBDIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "52cb38f2-6fcb-4de6-b70f-3d55a5785500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCAL_FILENAME = f\"trajectories_{HPARAMS['batch_size']}\"\n",
    "\n",
    "# print(LOCAL_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcbfc9a-049e-49b9-b2a3-ecb9fd4b9964",
   "metadata": {},
   "source": [
    "# [3] Training the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13adc1ef-b50e-41a3-9b95-c128d0c55a2b",
   "metadata": {},
   "source": [
    "## set Vertex Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e861fb27-df24-4821-8448-cf1346b186f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : mab-local-classy-v1\n",
      "RUN_NAME          : run-20230824-143408\n",
      "\n",
      "BASE_OUTPUT_DIR   : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-143408\n",
      "LOG_DIR           : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-143408/logs\n",
      "ROOT_DIR          : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-143408/root\n",
      "ARTIFACTS_DIR     : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-143408/artifacts\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME   = f'mab-local-classy-v1'\n",
    "\n",
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b7a5e4-efff-490b-b431-53037a2f4a16",
   "metadata": {},
   "source": [
    "## eval loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba0392e-90c8-4dc8-8df2-6d2af1ade490",
   "metadata": {},
   "source": [
    "> When evaluating an epsilon-greedy bandit, we need to remove those predictions that come from the `uniform_random` policy. We only want the predictions from the `GREEDY` policy, becasue we want to know how the model performs when it is actually used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "95b0c355-8976-479f-b61a-3e78fb147d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ====================================================\n",
    "# # eval loop\n",
    "# # ====================================================\n",
    "\n",
    "# def _run_bandit_eval(\n",
    "#     policy,\n",
    "#     data,\n",
    "#     eval_batch_size,\n",
    "#     per_arm_dim,\n",
    "#     global_dim,\n",
    "# ):\n",
    "#     logged_rewards = []\n",
    "#     predicted_rewards = []\n",
    "#     trouble_list = []\n",
    "#     train_loss_results = []\n",
    "    \n",
    "#     dummy_arm = tf.zeros([eval_batch_size, per_arm_dim], dtype=tf.float32)\n",
    "\n",
    "#     for x in data:\n",
    "#         # get feature tensors\n",
    "        \n",
    "#         # global_feat_infer = _get_global_context_features(x)\n",
    "#         # arm_feat_infer = _get_per_arm_features(x)\n",
    "        \n",
    "#         global_feat_infer = embs._get_global_context_features(x)\n",
    "#         arm_feat_infer = embs._get_per_arm_features(x)\n",
    "        \n",
    "#         # rewards = _get_rewards(x)\n",
    "#         rewards = reward_factory._get_rewards(x)\n",
    "\n",
    "#         # reshape arm features\n",
    "#         arm_feat_infer = tf.reshape(arm_feat_infer, [eval_batch_size, per_arm_dim])\n",
    "#         concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "\n",
    "#         # flatten global\n",
    "#         flat_global_infer = tf.reshape(global_feat_infer, [global_dim])\n",
    "#         feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "\n",
    "#         # get actual reward\n",
    "#         actual_reward = rewards.numpy()[0]\n",
    "#         # logged_rewards.append(actual_reward)\n",
    "\n",
    "#         # build trajectory step\n",
    "#         trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "        \n",
    "#         # pred w/ trained agent\n",
    "#         prediction = policy.action(trajectory_step)\n",
    "#         # prediction = trained_policy.action(trajectory_step)\n",
    "#         # prediction_list.append(prediction)\n",
    "\n",
    "#         predicted_rewards_mean = prediction.info.predicted_rewards_mean #[0]\n",
    "#         # pred_rewards_mean_list.append(predicted_rewards_mean)\n",
    "        \n",
    "#         predicted_reward_tf = tf.gather(\n",
    "#             predicted_rewards_mean,\n",
    "#             prediction.action, \n",
    "#             batch_dims=0, \n",
    "#             axis=-1\n",
    "#         )\n",
    "\n",
    "#         pred_reward = float(round(predicted_reward_tf.numpy()))\n",
    "\n",
    "#         # When the uniform random policy is used, the \n",
    "#         #    loss is meaningless for evaluation\n",
    "#         # > discard preds from uniform random policy\n",
    "#         # > keep preds from greedy policy, \n",
    "#         if pred_reward < 0:\n",
    "#             trouble_list.append(pred_reward)\n",
    "#         elif pred_reward > 5:\n",
    "#             trouble_list.append(pred_reward)\n",
    "#         else:\n",
    "#             predicted_rewards.append(pred_reward)\n",
    "\n",
    "#             pred_loss = tf.keras.metrics.mean_squared_error(\n",
    "#                 rewards, predicted_reward_tf\n",
    "#             )\n",
    "#             train_loss_results.append(pred_loss)\n",
    "#             logged_rewards.append(actual_reward)\n",
    "            \n",
    "#     # calculate avg loss\n",
    "#     avg_eval_loss = tf.reduce_mean(train_loss_results)\n",
    "    \n",
    "#     return (\n",
    "#         avg_eval_loss,\n",
    "#         predicted_rewards,\n",
    "#         logged_rewards,\n",
    "#         # train_loss_results\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b3d3c-75f7-46f4-9a1b-6329e419b7f5",
   "metadata": {},
   "source": [
    "## train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97cfe7c3-4022-47a9-83c2-df0ad8a2abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.metrics import export_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.utils import common\n",
    "\n",
    "# from src.per_arm_rl import train_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bb7ffc-00df-4d46-857b-86c87b78f597",
   "metadata": {},
   "source": [
    "`agent.train(experience=...)`\n",
    "\n",
    "where `experience` is a batch of trajectories data in the form of a Trajectory. \n",
    "* The structure of experience must match that of `self.training_data_spec`. \n",
    "* All tensors in experience must be shaped [batch, time, ...] where time must be equal to self.train_step_length if that property is not None."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94d6d45-c71e-4fe4-9af8-af9a8bda4e4f",
   "metadata": {},
   "source": [
    "### logs & checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "049ee49b-3b1a-4b12-a360-15e759dff7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('metrics: [<tf_agents.metrics.tf_metrics.AverageReturnMetric object at '\n",
      " '0x7fdcade25870>]')\n",
      "setting checkpoint_manager: gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-143408/root/chkpoint\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    f\"{LOG_DIR}/train\", flush_millis=10 * 1000\n",
    ")\n",
    "# train_summary_writer.set_as_default()\n",
    "\n",
    "# eval_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "#     f\"{LOG_DIR}/eval\", flush_millis=10 * 1000\n",
    "# )\n",
    "# ====================================================\n",
    "# metrics\n",
    "# ====================================================\n",
    "step_metric = tf_metrics.EnvironmentSteps()\n",
    "metrics = [\n",
    "    # tf_metrics.NumberOfEpisodes(),\n",
    "    # tf_metrics.AverageEpisodeLengthMetric(batch_size=HPARAMS['batch_size']),\n",
    "    tf_metrics.AverageReturnMetric(batch_size=HPARAMS['batch_size'])\n",
    "]\n",
    "\n",
    "pprint(f\"metrics: {metrics}\")\n",
    "\n",
    "# ====================================================\n",
    "# get checkpoint manager\n",
    "# ====================================================\n",
    "CHKPOINT_DIR = f\"{ROOT_DIR}/chkpoint\"\n",
    "print(f\"setting checkpoint_manager: {CHKPOINT_DIR}\")\n",
    "\n",
    "checkpoint_manager = train_utils.restore_and_get_checkpoint_manager(\n",
    "    root_dir=CHKPOINT_DIR, \n",
    "    agent=agent, \n",
    "    metrics=metrics, \n",
    "    step_metric=step_metric\n",
    ")\n",
    "# ====================================================\n",
    "# policy saver\n",
    "# ====================================================\n",
    "saver = policy_saver.PolicySaver(\n",
    "    agent.policy, \n",
    "    train_step=global_step\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83683f4b-8a1a-44b9-8d5f-7ee3304c794c",
   "metadata": {},
   "source": [
    "### config\n",
    "\n",
    "* calculate train & val dataset sizes\n",
    "* define logging and chkpt intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f9432613-6583-4828-8a2a-dd939adbc3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_DATA_SIZE : 80000\n",
      "NUM_TRAIN_STEPS : 200\n",
      "EVAL_DATA_SIZE : 20000\n",
      "NUM_EVAL_STEPS : 1000\n",
      "CHKPT_INTERVAL: 200\n",
      "LOG_INTERVAL : 10\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA_SIZE = 80000          # len(list(train_dataset))\n",
    "NUM_TRAIN_STEPS = 200            # TRAIN_DATA_SIZE // HPARAMS['batch_size']\n",
    "\n",
    "EVAL_DATA_SIZE  = 20000          # len(list(val_dataset))\n",
    "NUM_EVAL_STEPS  = 1000           # EVAL_DATA_SIZE // HPARAMS['eval_batch_size']\n",
    "\n",
    "CHKPT_INTERVAL  = NUM_TRAIN_STEPS # // 5\n",
    "LOG_INTERVAL    = 10\n",
    "# EVAL_INTERVAL = NUM_TRAIN_STEPS // 2\n",
    "\n",
    "print(f\"TRAIN_DATA_SIZE : {TRAIN_DATA_SIZE}\")\n",
    "print(f\"NUM_TRAIN_STEPS : {NUM_TRAIN_STEPS}\")\n",
    "print(f\"EVAL_DATA_SIZE : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS : {NUM_EVAL_STEPS}\")\n",
    "print(f\"CHKPT_INTERVAL: {CHKPT_INTERVAL}\")\n",
    "print(f\"LOG_INTERVAL : {LOG_INTERVAL}\")\n",
    "# print(f\"EVAL_INTERVAL : {EVAL_INTERVAL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "379ffc65-4eec-4af1-8fd4-912ef65a9808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec={'bucketized_user_age': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'movie_genres': TensorSpec(shape=(None, 1), dtype=tf.int64, name=None), 'movie_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'timestamp': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'user_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_occupation_text': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_rating': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data\n",
    "train_ds_iterator = iter(train_dataset.batch(HPARAMS['batch_size']).repeat())\n",
    "\n",
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS[\"eval_batch_size\"])\n",
    "\n",
    "if NUM_EVAL_STEPS > 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)\n",
    "\n",
    "# eval_ds = eval_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "eval_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e498d7e3-d166-4e1d-94a5-f721de58694a",
   "metadata": {},
   "source": [
    "### run train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5dd64d98-7d5b-4474-a567-b42426d630a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.perarm_features import eval_perarm as eval_perarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da4680f3-693b-4530-8e4d-88bc43036c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating pre-trained Agent...\n",
      "pre-train val_loss     : 15.383471488952637\n",
      "pre-train eval runtime : 0\n",
      "starting train loop...\n",
      "step = 0: train loss = 15.920000076293945\n",
      "step = 10: train loss = 12.170000076293945\n",
      "step = 20: train loss = 10.0600004196167\n",
      "step = 30: train loss = 2.940000057220459\n",
      "step = 40: train loss = 1.8899999856948853\n",
      "step = 50: train loss = 1.4299999475479126\n",
      "step = 60: train loss = 1.4299999475479126\n",
      "step = 70: train loss = 1.4600000381469727\n",
      "step = 80: train loss = 1.340000033378601\n",
      "step = 90: train loss = 1.2899999618530273\n",
      "step = 100: train loss = 1.559999942779541\n",
      "step = 110: train loss = 1.3300000429153442\n",
      "step = 120: train loss = 1.149999976158142\n",
      "step = 130: train loss = 0.9599999785423279\n",
      "step = 140: train loss = 1.100000023841858\n",
      "step = 150: train loss = 1.3300000429153442\n",
      "step = 160: train loss = 1.3600000143051147\n",
      "step = 170: train loss = 1.1399999856948853\n",
      "step = 180: train loss = 1.5299999713897705\n",
      "step = 190: train loss = 1.2899999618530273\n",
      "train runtime_mins: 1\n",
      "saved trained policy to: gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-143408/artifacts\n",
      "evaluating trained Agent...\n",
      "post-train val_loss     : 1.3288904428482056\n",
      "post-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "# agent.train = common.function(agent.train)\n",
    "\n",
    "list_o_loss = []\n",
    "\n",
    "# ====================================================\n",
    "# Evaluate the agent's policy once before training\n",
    "# ====================================================\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "pre_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "\n",
    "print(f\"evaluating pre-trained Agent...\")\n",
    "start_time = time.time()\n",
    "\n",
    "pre_val_loss, pre_preds, pre_tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = pre_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"pre-train val_loss     : {pre_val_loss}\")\n",
    "print(f\"pre-train eval runtime : {runtime_mins}\")\n",
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "print(f\"starting train loop...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# for i in tqdm(range(NUM_TRAIN_STEPS)):\n",
    "for i in range(NUM_TRAIN_STEPS):\n",
    "    \n",
    "    with train_summary_writer.as_default():\n",
    "\n",
    "        data = next(train_ds_iterator)\n",
    "        trajectories = _trajectory_fn(data)\n",
    "\n",
    "        # All tensors in experience must be shaped [batch, time, ...] \n",
    "        step = agent.train_step_counter.numpy()\n",
    "        loss = agent.train(experience=trajectories)\n",
    "        list_o_loss.append(loss.loss.numpy())\n",
    "\n",
    "        train_utils._export_metrics_and_summaries(\n",
    "            step=i, \n",
    "            metrics=metrics\n",
    "        )\n",
    "\n",
    "        # print step loss\n",
    "        if step % LOG_INTERVAL == 0:\n",
    "            print(\n",
    "                'step = {0}: train loss = {1}'.format(\n",
    "                    step, round(loss.loss.numpy(), 2)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if i > 0 and i % CHKPT_INTERVAL == 0:\n",
    "            saver.save(os.path.join(CHKPOINT_DIR, 'policy_%d' % step_metric.result()))\n",
    "            print(f\"saved policy to: {CHKPOINT_DIR}\")\n",
    "   \n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"train runtime_mins: {runtime_mins}\")\n",
    "\n",
    "saver.save(ARTIFACTS_DIR)\n",
    "print(f\"saved trained policy to: {ARTIFACTS_DIR}\")\n",
    "\n",
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = post_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "17b2b0d2-9795-4367-b57b-c331e94d1000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3288904"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb1ed8-f67b-4e7b-9cbc-70edd50e49ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate train job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff31fe28-2f05-499f-b1cc-505f3c9074e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### train loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "41937f9a-6c28-48d2-bc7c-bfe4372c7cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_o_loss)\n",
    "# plt.ylim([0, 10])\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e947e1-67f4-4205-99af-6921c6e9c896",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TensorBoard\n",
    "\n",
    "<img src=\"imgs/getting_profiler.png\" \n",
    "     align=\"center\" \n",
    "     width=\"850\"\n",
    "     height=\"850\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e0f77a33-0962-4af0-af97-cf05f895cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5d0509cb-0777-4d35-86c6-28c8acbcc793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-366377a7bfa18fac\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-366377a7bfa18fac\");\n",
       "          const url = new URL(\"/proxy/6008/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=$LOG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc40143-30b1-479f-b9b1-fa4c07b1690e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [4] Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6c94a0-122f-4ba6-acef-5653a3cc7850",
   "metadata": {
    "tags": []
   },
   "source": [
    "## load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b1c382b5-e2e0-45a2-9c5f-ef2c468d0f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-143408/artifacts\n"
     ]
    }
   ],
   "source": [
    "POLICY_URI = ARTIFACTS_DIR\n",
    "\n",
    "print(POLICY_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "68592d97-1272-4c6d-a4bd-43a6f7fe6c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7fdbb8240b20>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910a06f-678f-4bfa-a132-10b885f871c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "567f64e1-8149-4364-b561-1a9d12581b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aff30396-e0fd-4f43-acaa-6af8b20b12cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "for x in eval_ds.take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    \n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "    \n",
    "    # rewards = _get_rewards(x)\n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e58af9ab-f4da-4857-afe5-6b8de26ed0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(1, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.3710606, 3.3710845], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6676778c-d191-4b1e-a180-61f068b3b8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PolicyStep(action=array(1, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.3710606, 3.3710845], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)))\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c85a0087-7388-4f03-9278-aace31121233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1, dtype=int32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a8266c7c-3688-46a5-a1c8-a63bb7146128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info.bandit_policy_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9712bc00-7ea0-4003-a3c7-81a0be5bc995",
   "metadata": {},
   "source": [
    "# [5] Prepare training application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f62966-123f-410e-9610-832f20566635",
   "metadata": {},
   "source": [
    "To scale this training in Vertex AI's managed training service, we need to package all our code into a python application\n",
    "\n",
    "* This means, we need to modularize all steps executed up until this point. For example, the training loop we ran above is further parameterized in `train_perarm.py`, which will be called from our `task.py` when we submit the job to Vertex AI\n",
    "* This training package will eventually be used to create a custom training image (more on that in `04b-build-training-image` notebook)\n",
    "* For additional details on preparing the training application for Vertex AI, check out [the documentation](https://cloud.google.com/vertex-ai/docs/training/code-requirements) and [this code example](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage2/get_started_vertex_training.ipynb) (which also has good, related commentary)\n",
    "\n",
    "**The remaining cells will repeat steps executed above**\n",
    "> we are just illustrating / validating that they are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1129ee41-b43c-4d5a-b656-cdac6b79688c",
   "metadata": {},
   "source": [
    "#### Vertex Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ef509680-4d19-4efa-9f01-21039e0d573b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : mab-local-classy-v1\n"
     ]
    }
   ],
   "source": [
    "# using same experiment name \n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7ad98430-d836-40f1-8e4f-eb46f0c91fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : mab-local-classy-v1\n",
      "RUN_NAME          : run-20230824-144101\n",
      "\n",
      "BASE_OUTPUT_DIR   : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-144101\n",
      "LOG_DIR           : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-144101/logs\n",
      "ROOT_DIR          : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-144101/root\n",
      "ARTIFACTS_DIR     : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-144101/artifacts\n"
     ]
    }
   ],
   "source": [
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fbdecf78-94c5-4f8c-a6c0-86f2eace4663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: NeuralEpsGreedyAgent\n",
      "Network: commontower\n"
     ]
    }
   ],
   "source": [
    "# from src.perarm_features import agent_factory as agent_factory\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "    agent_type = AGENT_TYPE,\n",
    "    network_type = NETWORK_TYPE,\n",
    "    time_step_spec = time_step_spec,\n",
    "    action_spec = action_spec,\n",
    "    observation_spec=observation_spec,\n",
    "    global_layers = GLOBAL_LAYERS,\n",
    "    arm_layers = ARM_LAYERS,\n",
    "    common_layers = COMMON_LAYERS,\n",
    "    agent_alpha = AGENT_ALPHA,\n",
    "    learning_rate = LR,\n",
    "    epsilon = EPSILON,\n",
    "    train_step_counter = global_step,\n",
    "    output_dim = ENCODING_DIM,\n",
    "    eps_phase_steps = EPS_PHASE_STEPS,\n",
    ")\n",
    "\n",
    "print(f\"Agent: {agent.name}\")\n",
    "\n",
    "# if network:\n",
    "#     print(f\"Network: {network}\")\n",
    "\n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {NETWORK_TYPE}\")\n",
    "        \n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "108ed33c-d8ef-4524-97e9-ced9e01c154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHKPT_INTERVAL    : 200\n",
      "eval_batch_size   : 1\n",
      "EVAL_DATA_SIZE    : 20000\n",
      "NUM_EVAL_STEPS    : 100\n",
      "TOTAL_TRAIN_TAKE  : 10000\n"
     ]
    }
   ],
   "source": [
    "from src.perarm_features import train_perarm as train_perarm\n",
    "\n",
    "# train args\n",
    "TRAINING_LOOPS        = 150\n",
    "STEPS_PER_LOOP        = 1\n",
    "\n",
    "drop_arm_feature_fn   = None\n",
    "ASYNC_STEPS_PER_LOOP  = 1\n",
    "\n",
    "LOG_INTERVAL          = 10\n",
    "CHKPT_INTERVAL        = 200\n",
    "\n",
    "# eval args\n",
    "NUM_EVAL_STEPS = 100\n",
    "\n",
    "TOTAL_TRAIN_TAKE = 10000 #TRAINING_LOOPS * HPARAMS['batch_size']\n",
    "\n",
    "print(f\"CHKPT_INTERVAL    : {CHKPT_INTERVAL}\")\n",
    "print(f\"eval_batch_size   : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"EVAL_DATA_SIZE    : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS    : {NUM_EVAL_STEPS}\")\n",
    "print(f\"TOTAL_TRAIN_TAKE  : {TOTAL_TRAIN_TAKE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f66ff927-9a39-4abf-b247-845f0dc7721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS['eval_batch_size'])\n",
    "\n",
    "if NUM_EVAL_STEPS >= 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f6c98398-d545-4dcc-a71f-32249b5f0336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distribution_strategy: <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7fdbb82413f0>\n",
      "train_files: ['gs://mabv1-hybrid-vertex-bucket/data/train/ml-ratings-100k-train.tfrecord']\n",
      "train_ds_iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7fd79657caf0>\n",
      "setting checkpoint_manager: gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-144101/root/chkpoint\n",
      "Did not find a pre-existing checkpoint. Starting from scratch.\n",
      "wrapping agent.train in tf-function\n",
      "starting_loop: 0\n",
      "starting train loop...\n",
      "step = 200: loss = 15.899999618530273\n",
      "step = 210: loss = 13.119999885559082\n",
      "step = 220: loss = 2.759999990463257\n",
      "step = 230: loss = 1.1699999570846558\n",
      "step = 240: loss = 1.2200000286102295\n",
      "step = 250: loss = 1.409999966621399\n",
      "step = 260: loss = 1.4299999475479126\n",
      "step = 270: loss = 1.4800000190734863\n",
      "step = 280: loss = 1.3799999952316284\n",
      "step = 290: loss = 1.350000023841858\n",
      "step = 300: loss = 1.4800000190734863\n",
      "step = 310: loss = 1.340000033378601\n",
      "step = 320: loss = 1.1399999856948853\n",
      "step = 330: loss = 1.0\n",
      "step = 340: loss = 1.149999976158142\n",
      "runtime_mins: 1\n",
      "saved trained policy to: gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-144101/artifacts\n",
      "complete train job in 1 minutes\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    f\"{LOG_DIR}/train\", flush_millis=10 * 1000\n",
    ")\n",
    "\n",
    "#start the timer and training\n",
    "start_time = time.time()\n",
    "\n",
    "metric_results, agent = train_perarm.train_perarm(\n",
    "    agent = agent,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    num_iterations = TRAINING_LOOPS,\n",
    "    steps_per_loop = STEPS_PER_LOOP,\n",
    "    num_eval_steps = NUM_EVAL_STEPS,\n",
    "    # data\n",
    "    batch_size = HPARAMS['batch_size'],\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    # functions\n",
    "    _trajectory_fn = _trajectory_fn,\n",
    "    # _run_bandit_eval_fn = _run_bandit_eval,\n",
    "    # train intervals\n",
    "    chkpt_interval = CHKPT_INTERVAL,\n",
    "    log_interval = LOG_INTERVAL,\n",
    "    # dirs\n",
    "    bucket_name = BUCKET_NAME,\n",
    "    data_dir_prefix_path = DATA_GCS_PREFIX,\n",
    "    log_dir = LOG_DIR,\n",
    "    model_dir = ARTIFACTS_DIR,\n",
    "    root_dir = ROOT_DIR,\n",
    "    async_steps_per_loop = ASYNC_STEPS_PER_LOOP,\n",
    "    resume_training_loops = False,\n",
    "    use_gpu = True,\n",
    "    use_tpu = False,\n",
    "    profiler = False,\n",
    "    global_step = global_step,\n",
    "    total_train_take = TOTAL_TRAIN_TAKE,\n",
    "    train_summary_writer = train_summary_writer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"complete train job in {runtime_mins} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "177aa3ab-05b4-48f9-b434-9335bd9eb54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.421488"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(metric_results)\n",
    "metric_results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ba65417f-54e0-436e-b0d4-93cffb981ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(metric_results)\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7ba747-00d5-4908-8d0b-334ae9d2c791",
   "metadata": {},
   "source": [
    "#### eval trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c5cf9366-d9cd-4c9d-951a-99a50877a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af82506e-95d7-4a4e-a821-e08512615db7",
   "metadata": {},
   "source": [
    "After training, our `agent.policy` is used as the deployment \"model\" that will generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6c82396a-7822-41fb-830f-1f6eb9c9b213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.epsilon_greedy_policy.EpsilonGreedyPolicy at 0x7fd7967eca30>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_agent = agent.policy\n",
    "deployment_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f6706224-ef5b-4185-bde4-bccb7c8e7ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating trained Agent...\n",
      "post-train val_loss     : 1.5376209020614624\n",
      "post-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(deployment_agent, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = post_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f899120f-3706-4b72-8f2c-2169221dd66b",
   "metadata": {},
   "source": [
    "## Using Trained Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b0f691-860e-4853-928e-4c7ece714dd0",
   "metadata": {},
   "source": [
    "### load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ea029f73-0638-462a-8f00-54b05c54d69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-144101/artifacts\n"
     ]
    }
   ],
   "source": [
    "POLICY_URI = ARTIFACTS_DIR\n",
    "\n",
    "print(POLICY_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "66d1d819-0152-437c-aefc-45ffd34d808a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-144101/artifacts/\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-144101/artifacts/fingerprint.pb\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-144101/artifacts/policy_specs.pbtxt\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-144101/artifacts/saved_model.pb\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-144101/artifacts/assets/\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-144101/artifacts/variables/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $POLICY_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6aad948e-e346-4da3-8cb2-747435c8dc4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7fd796460400>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "483f8fa5-cbd1-4e3c-8e62-47f91f42e137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(), dtype=dtype('int32'), name='action_spec', minimum=0, maximum=1)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_policy.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8f658891-bc09-49b8-bc58-000a7926df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "for x in eval_ds.take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    \n",
    "    # global_feat_infer = _get_global_context_features(x)\n",
    "    # arm_feat_infer = _get_per_arm_features(x)\n",
    "    \n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "    \n",
    "    # rewards = _get_rewards(x)\n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f515fcd0-2228-4f68-9ef9-665ce1fc3fb2",
   "metadata": {},
   "source": [
    "### view prediction response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6af4c297-d2e8-4f7b-bed5-e1da997dfe34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.4653637, 3.4653637], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=array([ 0.03921844,  0.02818907, -0.02724521,  0.04905966, -0.01885973,\n",
       "       -0.0310231 , -0.0023816 , -0.03448287, -0.0263405 , -0.04681246,\n",
       "        0.00888371,  0.0258189 , -0.00653335, -0.00452768, -0.01745595,\n",
       "       -0.00543489, -0.02842196, -0.04692044, -0.01531284,  0.02413535,\n",
       "       -0.03162654,  0.04901491,  0.01592496,  0.0089882 ,  0.02119115,\n",
       "       -0.04431317,  0.00069294, -0.02001365,  0.03987988,  0.04838145,\n",
       "        0.04744658,  0.02535354,  0.03248599, -0.04416415,  0.01255823,\n",
       "       -0.02560824,  0.02138222, -0.02508129,  0.0248701 ,  0.01124211,\n",
       "        0.04783237,  0.02409482,  0.03319925, -0.02373859,  0.03231755,\n",
       "        0.04093018, -0.01706355, -0.00962385,  0.0354269 , -0.01918391,\n",
       "       -0.01495469, -0.03295807, -0.01634145,  0.0239275 , -0.00956025,\n",
       "       -0.01065403,  0.01911432, -0.03294803, -0.00290239, -0.04852766,\n",
       "        0.00664618, -0.00247677, -0.01031192,  0.00321487], dtype=float32)))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd58d4b-6749-4177-8342-83ee969408c9",
   "metadata": {},
   "source": [
    "#### chosen action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d49adbbb-f747-4e4c-b82d-df88373c644f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0, dtype=int32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd12013-1d12-4197-8254-cef9138df42c",
   "metadata": {},
   "source": [
    "#### Per Arm Policy Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d6126290-546b-4702-8a1e-91f18adb05c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.4653637, 3.4653637], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=array([ 0.03921844,  0.02818907, -0.02724521,  0.04905966, -0.01885973,\n",
       "       -0.0310231 , -0.0023816 , -0.03448287, -0.0263405 , -0.04681246,\n",
       "        0.00888371,  0.0258189 , -0.00653335, -0.00452768, -0.01745595,\n",
       "       -0.00543489, -0.02842196, -0.04692044, -0.01531284,  0.02413535,\n",
       "       -0.03162654,  0.04901491,  0.01592496,  0.0089882 ,  0.02119115,\n",
       "       -0.04431317,  0.00069294, -0.02001365,  0.03987988,  0.04838145,\n",
       "        0.04744658,  0.02535354,  0.03248599, -0.04416415,  0.01255823,\n",
       "       -0.02560824,  0.02138222, -0.02508129,  0.0248701 ,  0.01124211,\n",
       "        0.04783237,  0.02409482,  0.03319925, -0.02373859,  0.03231755,\n",
       "        0.04093018, -0.01706355, -0.00962385,  0.0354269 , -0.01918391,\n",
       "       -0.01495469, -0.03295807, -0.01634145,  0.0239275 , -0.00956025,\n",
       "       -0.01065403,  0.01911432, -0.03294803, -0.00290239, -0.04852766,\n",
       "        0.00664618, -0.00247677, -0.01031192,  0.00321487], dtype=float32))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288100d3-5cbf-4a5f-88e7-6325ce8f8754",
   "metadata": {},
   "source": [
    "```\n",
    "PolicyStep(action=array(1, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.3710606, 3.3710845], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f66961-ebb5-4ae5-8e6f-ad73114d8353",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f36d1c-69fc-4935-9419-4d696827629a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
