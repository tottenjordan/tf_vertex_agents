{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385307d6-2058-47ec-8da0-57f7ef5c43d6",
   "metadata": {},
   "source": [
    "# Train Bandits with per-arm features\n",
    "\n",
    "**Exploring linear and nonlinear** (e.g., those with neural network-based value functions) bandit methods for recommendations using TF-Agents\n",
    "\n",
    "> Neural linear bandits provide a nice way to leverage the representation power of deep learning and the bandit approach for uncertainty measure and efficient exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fd257-b98b-426a-a2cd-024429b014f1",
   "metadata": {},
   "source": [
    "## Load notebook config\n",
    "\n",
    "* use the prefix defined in `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f39c9d08-d118-4013-a47f-88450f49f19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "# PREFIX = 'mabv1'\n",
    "VERSION        = \"v2\"                       # TODO\n",
    "PREFIX         = f'rec-bandits-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908f6b95-b539-4a9f-a836-840d26ea3b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"rec-bandits-v2\"\n",
      "VERSION                  = \"v2\"\n",
      "\n",
      "BUCKET_NAME              = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_ID      = \"hybrid_vertex.movielens_ds_rec_bandits_v2\"\n",
      "BIGQUERY_TABLE_ID        = \"hybrid_vertex.movielens_ds_rec_bandits_v2.training_dataset\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-rec-bandits-v2\"\n",
      "IMAGE_NAME               = \"train-perarm-feats-v2\"\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/train-perarm-feats-v2\"\n",
      "DOCKERNAME               = \"Dockerfile_perarm_feats\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c690a9-e2bd-4759-ba41-4e2469098aee",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d0dfe4-695c-4dd4-9f24-67f7488ce1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c669f1a1-1af7-4efb-ab2d-6bf3b3847991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from collections import defaultdict\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pickle as pkl\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "# from tf_agents.agents import TFAgent\n",
    "\n",
    "# from tf_agents.bandits.environments import stationary_stochastic_per_arm_py_environment as p_a_env\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "# from tf_agents.drivers import dynamic_step_driver\n",
    "# from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "# from tf_agents.bandits.agents import lin_ucb_agent\n",
    "# from tf_agents.bandits.agents import linear_thompson_sampling_agent as lin_ts_agent\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent\n",
    "from tf_agents.bandits.agents import neural_linucb_agent\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "from tf_agents.bandits.policies import policy_utilities\n",
    "\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# this repo\n",
    "from src.per_arm_rl import data_utils\n",
    "from src.per_arm_rl import data_config\n",
    "from src.per_arm_rl import train_utils as train_utils\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29e58dd7-ab2b-419f-9771-bf1e98db758b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4969d3e-1fc0-45db-8a69-aa6b342019de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "274e7f4a-1802-4946-888e-876638f5c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a866b1-85b9-43e6-9546-edfbbf886bce",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd5b953-14c0-42ed-a511-77147a1bc0ac",
   "metadata": {},
   "source": [
    "### Read TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d0157c8-a04c-4dbd-b6d9-a1ede97687a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da0cdac-76af-4608-b70e-be7dbe0584b5",
   "metadata": {},
   "source": [
    "**Train data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c934c06-bf08-4c7f-b0cc-0de04ef3515c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://rec-bandits-v2-hybrid-vertex-bucket/data/train/ml-ratings-100k-train.tfrecord']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPLIT = \"train\" # \"train\" | \"val\"\n",
    "\n",
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7511e4d-bf81-4800-bde7-8b16dec9aeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([35.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'898'], dtype=object)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([885409515])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'681'], dtype=object)>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'marketing'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "train_dataset = train_dataset.map(data_utils.parse_tfrecord)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452750c1-46a0-4ee1-84d4-0c3b227de38f",
   "metadata": {},
   "source": [
    "**Val data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7b5376f-9438-4304-84aa-de09c30f5e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = \"val\"\n",
    "\n",
    "val_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        val_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "val_dataset = tf.data.TFRecordDataset(val_files)\n",
    "val_dataset = val_dataset.map(data_utils.parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8959967-522e-41c8-9a1b-050ca8bc191f",
   "metadata": {},
   "source": [
    "### get vocab\n",
    "\n",
    "**TODO:** \n",
    "* streamline vocab calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b9169bc-d6dc-497e-9dff-6ebb175282ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE_VOCABS: False\n"
     ]
    }
   ],
   "source": [
    "GENERATE_VOCABS = False\n",
    "\n",
    "print(f\"GENERATE_VOCABS: {GENERATE_VOCABS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3ccf137-7a72-42e7-aa89-3c81a99cf40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab...\n",
      "Downloaded vocab from: gs://rec-bandits-v2-hybrid-vertex-bucket/vocabs/vocab_dict.pkl\n",
      "\n",
      "'movie_id'\n",
      "'user_id'\n",
      "'user_occupation_text'\n",
      "'movie_genres'\n",
      "'bucketized_user_age'\n",
      "'max_timestamp'\n",
      "'min_timestamp'\n",
      "'timestamp_buckets'\n"
     ]
    }
   ],
   "source": [
    "if not GENERATE_VOCABS:\n",
    "\n",
    "    EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{VOCAB_SUBDIR}/{VOCAB_FILENAME}'\n",
    "    print(f\"Downloading vocab...\")\n",
    "    \n",
    "    os.system(f'gsutil -q cp {EXISTING_VOCAB_FILE} .')\n",
    "    print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "    filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "    vocab_dict = pkl.load(filehandler)\n",
    "    filehandler.close()\n",
    "    \n",
    "    for key in vocab_dict.keys():\n",
    "        pprint(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccaef62-882a-46ff-a1b1-3837e69fdf74",
   "metadata": {},
   "source": [
    "## helper functions\n",
    "\n",
    "**TODO:**\n",
    "* modularize in a train_utils or similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b941063b-ad48-4817-aef0-9afa8a444632",
   "metadata": {},
   "source": [
    "# Multi-Armed Bandits (MAB) with Per-Arm Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28770b8d-836b-448d-8dd1-203d76fc6d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "\n",
    "nest = tf.nest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138a295-2b0d-4359-8496-af8552ec8cff",
   "metadata": {},
   "source": [
    "# [1] Preprocessing layers for global and arm features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e28c002-8d3a-4cf4-b69b-de56a6abab90",
   "metadata": {},
   "source": [
    "The preproccesing layers will ultimately feed the two sampling functions described below. These sampling functions will be used to create [trajectories](https://github.com/tensorflow/agents/blob/master/tf_agents/trajectories/trajectory.py#L36) (i.e., the training examples for our model)\n",
    "\n",
    "`global_context_sampling_fn`: \n",
    "* A function that outputs a random 1d array or list of ints or floats\n",
    "* This output is the global context. Its shape and type must be consistent across calls.\n",
    "\n",
    "`arm_context_sampling_fn`: \n",
    "* A function that outputs a random 1 array or list of ints or floats (same type as the output of `global_context_sampling_fn`). * This output is the per-arm context. Its shape must be consistent across calls.\n",
    "\n",
    "See `debug-and-learn-emb-models.ipynb` for more details and debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ea1f7-0621-44b8-b062-1f59b0964d72",
   "metadata": {},
   "source": [
    "## Global & Per-Arm feature embedding models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8d77956-635c-438a-916a-185eec52f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OOV_BUCKETS        = 1\n",
    "GLOBAL_EMBEDDING_SIZE  = 16\n",
    "MV_EMBEDDING_SIZE      = 32 #32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea335991-dcec-40b3-ba0d-a0fdfb9c2ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test emb models\n",
    "for i in range(1):\n",
    "    \n",
    "    iterator = iter(train_dataset.batch(1))\n",
    "    data = next(iterator)\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48178fff-491f-4f03-b156-7765d1fa9707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.perarm_features.emb_features.EmbeddingModel at 0x7f9abccc8d60>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.perarm_features import emb_features as emb_features\n",
    "\n",
    "embs = emb_features.EmbeddingModel(\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "903c63c5-2468-4443-bcb8-5ff6d69810dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL_DIM: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.04051448,  0.02712877,  0.00331603,  0.00995095, -0.04513626,\n",
       "         0.01905818,  0.04317332,  0.04341288,  0.02347055, -0.01931642,\n",
       "         0.02102253,  0.01034527, -0.04646144, -0.00516641, -0.00732   ,\n",
       "        -0.03522148,  0.01987146, -0.01387979, -0.04146259,  0.0474729 ,\n",
       "        -0.0208194 ,  0.03551697, -0.02541736,  0.01498825, -0.04051647,\n",
       "         0.04967235, -0.04262201, -0.03932267, -0.01836985, -0.04285512,\n",
       "        -0.03189041,  0.02306199,  0.00891383, -0.00535281, -0.00822047,\n",
       "         0.04671631,  0.03684281, -0.03260063, -0.04681568,  0.03584572,\n",
       "         0.0433724 ,  0.00095391, -0.03429707, -0.0321902 , -0.01889292,\n",
       "        -0.01845282, -0.04928989, -0.03371853,  0.02650947, -0.03603863,\n",
       "         0.04153066,  0.00032985,  0.00746445, -0.01754099, -0.03169823,\n",
       "         0.01665516, -0.0278749 ,  0.00633656,  0.00233174,  0.03216344,\n",
       "         0.04090217,  0.00242283,  0.03613076, -0.02316915]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_globals = embs._get_global_context_features(data)\n",
    "\n",
    "GLOBAL_DIM = test_globals.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"GLOBAL_DIM: {GLOBAL_DIM}\")\n",
    "\n",
    "test_globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebec4863-c614-4248-b680-8e29ec5b730d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER_ARM_DIM: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.00048177, -0.03114955,  0.02040141, -0.04182448, -0.02068294,\n",
       "         0.04534396,  0.00232643,  0.03015312, -0.04920418,  0.02528406,\n",
       "        -0.0284514 , -0.02776756,  0.04588768,  0.02704866, -0.0043029 ,\n",
       "        -0.02341377, -0.03073402,  0.01161766, -0.0166566 ,  0.01359719,\n",
       "         0.01697883,  0.02930254, -0.01457812, -0.00787462, -0.00720908,\n",
       "         0.00813777,  0.0495875 ,  0.02433784,  0.04018411, -0.00572733,\n",
       "         0.01655989, -0.04136865,  0.04064376,  0.01119175,  0.03475213,\n",
       "         0.01098081, -0.00493066,  0.04492981,  0.02441463,  0.04600373,\n",
       "         0.01444396, -0.02150018, -0.02182286, -0.02605929,  0.00412785,\n",
       "        -0.01374903, -0.03584485, -0.03835983, -0.02374423, -0.0249566 ,\n",
       "         0.00529758, -0.01851134,  0.02474675,  0.01230855,  0.01910527,\n",
       "        -0.04537984,  0.00660525,  0.02420961, -0.01354126,  0.00729102,\n",
       "        -0.02089106, -0.01684665, -0.00154836,  0.0417952 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arms = embs._get_per_arm_features(data)\n",
    "\n",
    "PER_ARM_DIM = test_arms.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"PER_ARM_DIM: {PER_ARM_DIM}\")\n",
    "\n",
    "test_arms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac6836c-67b7-4fd4-917a-24ddad708edd",
   "metadata": {},
   "source": [
    "# [2] Implementing MAB with TF-Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1877c79c-b6c8-4048-b1ce-05f011e8d69e",
   "metadata": {},
   "source": [
    "In TF-Agents, the *per-arm features* implementation differs from the *global-only* feature examples in the following aspects:\n",
    "* Reward is modeled not per-arm, but globally.\n",
    "* The arms are permutation invariant: it doesn’t matter which arm is arm 1 or arm 2, only their features.\n",
    "* One can have a different number of arms to choose from in every step (note that unspecified/dynamically changing number of arms will have a problem with XLA compatibility).\n",
    "\n",
    "When implementing per-arm features in TF-Bandits, the following details have to be discussed:\n",
    "* Observation spec and observations,\n",
    "* Action spec and actions,\n",
    "* Implementation of specific policies and agents.\n",
    "\n",
    "\n",
    "**TODO:**\n",
    "* outline the components and highlight their interactions, dependencies on eachother, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ff9baaf-987d-448d-a981-742a79b581e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE      : 128\n",
      "EVAL_BATCH_SIZE : 1\n",
      "NUM_ACTIONS     : 2\n",
      "GLOBAL_DIM      : 64\n",
      "PER_ARM_DIM     : 64\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE      = 128\n",
    "EVAL_BATCH_SIZE = 1\n",
    "\n",
    "NUM_ACTIONS     = 2 #this is kinda deceptive - \n",
    "#our approach is to learn by \"flashing\" one movie rating at a time per user context. \n",
    "#The n_actions = show/don't show the movie with one degree of freedom (n-1)\n",
    "\n",
    "\n",
    "print(f\"BATCH_SIZE      : {BATCH_SIZE}\")\n",
    "print(f\"EVAL_BATCH_SIZE : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"NUM_ACTIONS     : {NUM_ACTIONS}\")\n",
    "print(f\"GLOBAL_DIM      : {GLOBAL_DIM}\")\n",
    "print(f\"PER_ARM_DIM     : {PER_ARM_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeb4902-5bb9-4587-8d29-c01d78b006be",
   "metadata": {},
   "source": [
    "## Tensor Specs\n",
    "\n",
    "* say you have a global observation spec of `[17]`. And you have two batch dimensions `[4, 5]`. Then your observation has to have the shape `[4, 5, 17]`\n",
    "* and then if you have arm_obs_spec with shape `[9, 13]`, then the arm obs shape has to be exactly `[4, 5, 9, 13]`\n",
    "* and this has to be true for every single tensor in your tensor nest\n",
    "* the first 2 dims are the outer dims that are the same for all tensors, the rest of the dimensions have to follow the spec for each tensor\n",
    "\n",
    "**TODO:**\n",
    "* explain relationship between Tensor Specs and their Tensor counterparts\n",
    "* highlight the errors, lessons learned, and utility functions to address these"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f68ebe8-116d-43b3-a6e1-4f5a5c7f4741",
   "metadata": {},
   "source": [
    "### Observation spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9c4746-d01b-4ca4-aa53-ab68da54d37a",
   "metadata": {},
   "source": [
    "**This observation spec allows the user to have a global observation of fixed dimension**, and an unspecified number of *per-arm* features (also of fixed dimension)\n",
    "* The actions output by the policy are still integers as usual, and they indicate which row of the arm-features it has chosen \n",
    "* The action spec must be a single integer value without boundaries:\n",
    "\n",
    "```python\n",
    "global_spec = tensor_spec.TensorSpec([GLOBAL_DIM], tf.float32)\n",
    "per_arm_spec = tensor_spec.TensorSpec([None, PER_ARM_DIM], tf.float32)\n",
    "observation_spec = {'global': global_spec, 'per_arm': per_arm_spec}\n",
    "\n",
    "action_spec = tensor_spec.TensorSpec((), tf.int32)\n",
    "```\n",
    "> Here the only difference compared to the action spec with global features only is that the tensor spec is not bounded, as we don’t know how many arms there will be at any time step\n",
    "\n",
    "**XLA compatibility:**\n",
    "* Since dynamic tensor shapes are not compatible with XLA, the number of arm features (and consequently, number of arms for a step) cannot be dynamic. \n",
    "* One workaround is to fix the maximum number of arms for a problem, then pad the arm features in steps with fewer arms, and use action masking to indicate how many arms are actually active.\n",
    "\n",
    "```python\n",
    "per_arm_spec = tensor_spec.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32)\n",
    "\n",
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=(), dtype=tf.int32, minimum = 0, maximum = NUM_ACTIONS - 1\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36bd3b33-635a-4274-8b9e-7172696ebb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_spec = {\n",
    "    'global': tf.TensorSpec([GLOBAL_DIM], tf.float32),\n",
    "    'per_arm': tf.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32) #excluding action dim here\n",
    "}\n",
    "observation_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a2da92-7db2-4f42-94a7-b7bad1c8fc42",
   "metadata": {},
   "source": [
    "### Action spec\n",
    "\n",
    "> The time_step_spec and action_spec are specifications for the input time step and the output action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5af42c7-18d7-480f-a7f3-d7da3f4840eb",
   "metadata": {},
   "source": [
    "```python\n",
    "    if (\n",
    "        not tensor_spec.is_bounded(action_spec)\n",
    "        or not tensor_spec.is_discrete(action_spec)\n",
    "        or action_spec.shape.rank > 1\n",
    "        or action_spec.shape.num_elements() != 1\n",
    "    ):\n",
    "      raise NotImplementedError(\n",
    "          'action_spec must be a BoundedTensorSpec of type int32 and shape (). '\n",
    "          'Found {}.'.format(action_spec)\n",
    "      )\n",
    "```\n",
    "\n",
    "* [src](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_base_policy.py#L97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "549a123c-349a-4103-b39a-4502f47d1e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=[], \n",
    "    dtype=tf.int32,\n",
    "    minimum=tf.constant(0),            \n",
    "    maximum=NUM_ACTIONS-1, # n degrees of freedom and will dictate the expected mean reward spec shape\n",
    "    name=\"action_spec\"\n",
    ")\n",
    "\n",
    "action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36ee2635-d4e3-4468-886c-ae9c62e3c80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_num_actions: 2\n",
      "predicted_rewards_mean: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n"
     ]
    }
   ],
   "source": [
    "expected_num_actions = action_spec.maximum - action_spec.minimum + 1\n",
    "print(f\"expected_num_actions: {expected_num_actions}\")\n",
    "\n",
    "predicted_rewards_mean = tensor_spec.TensorSpec([expected_num_actions])\n",
    "print(f\"predicted_rewards_mean: {predicted_rewards_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a51efce-9f1b-42d1-bec4-7b788e3fd7e0",
   "metadata": {},
   "source": [
    "### TimeStep spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95f05860-0fbf-4a5a-8273-9c81761e0ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec = ts.time_step_spec(\n",
    "    observation_spec = observation_spec, \n",
    "    # reward_spec = _reward_spec\n",
    ")\n",
    "time_step_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9181303-6565-45f5-a293-08d50420a805",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Inspect chosen arm features spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6b526a5-997c-4621-b21c-82c6ca1d6a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90d3e03e-619e-4fa4-b817-f02b4cefd6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(64,), dtype=tf.float32, name=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_arm_features_info = (\n",
    "  policy_utilities.create_chosen_arm_features_info_spec(\n",
    "      time_step_spec.observation,\n",
    "  )\n",
    ")\n",
    "chosen_arm_features_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc427092-beb7-4baf-a2e9-b8d10629182c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - dont understand this\n",
    "bandit_policy_type = (\n",
    "    policy_utilities.BanditPolicyType.GREEDY\n",
    ")\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a4a2a33-c7d4-4d81-8082-80dfc3596741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - dont understand this\n",
    "bandit_policy_type = (\n",
    "    policy_utilities.create_bandit_policy_type_tensor_spec(shape=[1])\n",
    ")\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e7ac02b-18bd-4519-92fe-5541b1a8ddc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_spec = policy_utilities.PerArmPolicyInfo(\n",
    "  predicted_rewards_mean=predicted_rewards_mean,\n",
    "  bandit_policy_type=bandit_policy_type,\n",
    "  chosen_arm_features=chosen_arm_features_info,\n",
    ")\n",
    "info_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9c197-ae9b-461d-8956-f078b929ac12",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The Agent\n",
    "\n",
    "**Note** that contextual bandits form a special case of RL, where the actions taken by the agent do not alter the state of the environment \n",
    "\n",
    "> “Contextual” refers to the fact that the agent chooses among a set of actions while having knowledge of the context (environment observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81d6e84-688e-48c5-aea1-77df031348c9",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Agent & Network defined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aadb01-eb5c-4870-ae14-9e66624ba594",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Agent types**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d075e8a6-11a9-4346-8725-3653fba4bac4",
   "metadata": {},
   "source": [
    "> `AGENT_TYPE = ['LinUCB', 'LinTS', 'epsGreedy', 'NeuralLinUCB']`\n",
    "\n",
    "LinearUCBAgent: (`LinUCB`) \n",
    "* An agent implementing the Linear UCB bandit algorithm ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/lin_ucb_agent/LinearUCBAgent))\n",
    "\n",
    "LinearThompsonSamplingAgent: (`LinTS`) \n",
    "* Implements the Linear Thompson Sampling Agent from the [paper](https://arxiv.org/abs/1209.3352): *Thompson Sampling for Contextual Bandits with Linear Payoffs* ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/linear_thompson_sampling_agent/LinearThompsonSamplingAgent))\n",
    "\n",
    "NeuralEpsilonGreedyAgent: (`epsGreedy`) \n",
    "* A neural network based epsilon greedy agent ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_epsilon_greedy_agent/NeuralEpsilonGreedyAgent))\n",
    "\n",
    "NeuralLinUCBAgent: (`NeuralLinUCB`) \n",
    "* An agent implementing the LinUCB algorithm on top of a neural network ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_linucb_agent/NeuralLinUCBAgent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b8e88e-c8ea-4193-a911-0d974ef3b1a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Network types**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f547087d-5fad-4521-a584-cb46ce52897d",
   "metadata": {},
   "source": [
    "Which network architecture to use for the `epsGreedy` or `NeuralLinUCB` agents\n",
    "\n",
    "```\n",
    "NETWORK_TYPE = ['commontower', 'dotproduct']\n",
    "```\n",
    "\n",
    "**GlobalAndArmCommonTowerNetwork:** (`commontower`)\n",
    "* This network takes the output of the global and per-arm networks, and leads them through a common network, that in turn outputs reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "> * `COMMON_LAYERS` - Iterable of ints. Specifies the layers of the common tower\n",
    "* The network produced by this function can be used either in `GreedyRewardPredictionPolicy`, or `NeuralLinUCBPolicy`\n",
    "> * In the former case, the network must have `output_dim=1`, it is going to be an instance of `QNetwork`, and used in the policy as a reward prediction network\n",
    "> * In the latter case, the network will be an encoding network with its output consumed by a reward layer or a `LinUCB` method. The specified `output_dim` will be the encoding dimension\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmCommonTowerNetwork)\n",
    "\n",
    "**GlobalAndArmDotProductNetwork:** (`dotproduct`)\n",
    "* This network calculates the **dot product** of the output of the global and per-arm networks and returns them as reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmDotProductNetwork)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3dc270-deb5-4e96-8276-74759a06c318",
   "metadata": {},
   "source": [
    "### Agent config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbe29263-453d-405e-ac50-fee7f379f335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\n",
      "\n",
      "time_step_spec:  TimeStep(\n",
      "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
      "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n",
      "\n",
      "action_spec:  BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))\n",
      "\n",
      "observation_spec:  {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\")\n",
    "print(\"\\ntime_step_spec: \", time_step_spec)\n",
    "print(\"\\naction_spec: \", action_spec)\n",
    "print(\"\\nobservation_spec: \", observation_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d817bf2-1fa6-4bae-af90-745fad996b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'common_layers': [16, 8],\n",
      " 'epsilon': 0.01,\n",
      " 'eval_batch_size': 1,\n",
      " 'global_layers': [64, 32, 16],\n",
      " 'learning_rate': 0.05,\n",
      " 'model_type': 'epsGreedy',\n",
      " 'network_type': 'commontower',\n",
      " 'num_actions': 2,\n",
      " 'per_arm_layers': [64, 32, 16]}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Agents\n",
    "# ================================\n",
    "AGENT_TYPE      = 'epsGreedy' # 'LinUCB' | 'LinTS |, 'epsGreedy' | 'NeuralLinUCB'\n",
    "\n",
    "# Parameters for linear agents (LinUCB and LinTS).\n",
    "AGENT_ALPHA     = 0.1\n",
    "\n",
    "# Parameters for neural agents (NeuralEpsGreedy and NerualLinUCB).\n",
    "EPSILON         = 0.01\n",
    "LR              = 0.05\n",
    "\n",
    "# Parameters for NeuralLinUCB\n",
    "ENCODING_DIM    = 1\n",
    "EPS_PHASE_STEPS = 1000\n",
    "\n",
    "# ================================\n",
    "# Agent's Preprocess Network\n",
    "# ================================\n",
    "NETWORK_TYPE    = \"commontower\" # 'commontower' | 'dotproduct'\n",
    "\n",
    "if AGENT_TYPE == 'NeuralLinUCB':\n",
    "    NETWORK_TYPE = 'commontower'\n",
    "    \n",
    "GLOBAL_LAYERS   = [64, 32, 16]\n",
    "ARM_LAYERS      = [64, 32, 16]\n",
    "COMMON_LAYERS   = [16, 8]\n",
    "\n",
    "HPARAMS = {  # TODO - streamline and consolidate\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"eval_batch_size\" : EVAL_BATCH_SIZE,\n",
    "    \"num_actions\": NUM_ACTIONS,\n",
    "    \"model_type\": AGENT_TYPE,\n",
    "    \"network_type\": NETWORK_TYPE,\n",
    "    \"global_layers\": GLOBAL_LAYERS,\n",
    "    \"per_arm_layers\": ARM_LAYERS,\n",
    "    \"common_layers\": COMMON_LAYERS,\n",
    "    \"learning_rate\": LR,\n",
    "    \"epsilon\": EPSILON,\n",
    "}\n",
    "pprint(HPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2bf060bb-9880-40b4-8583-dd7a3f915bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent: NeuralEpsGreedyAgent\n",
      "Network: commontower\n"
     ]
    }
   ],
   "source": [
    "from src.perarm_features import agent_factory as agent_factory\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "    agent_type = AGENT_TYPE,\n",
    "    network_type = NETWORK_TYPE,\n",
    "    time_step_spec = time_step_spec,\n",
    "    action_spec = action_spec,\n",
    "    observation_spec=observation_spec,\n",
    "    global_layers = GLOBAL_LAYERS,\n",
    "    arm_layers = ARM_LAYERS,\n",
    "    common_layers = COMMON_LAYERS,\n",
    "    agent_alpha = AGENT_ALPHA,\n",
    "    learning_rate = LR,\n",
    "    epsilon = EPSILON,\n",
    "    train_step_counter = global_step,\n",
    "    output_dim = ENCODING_DIM,\n",
    "    eps_phase_steps = EPS_PHASE_STEPS,\n",
    "    summarize_grads_and_vars = False,\n",
    "    debug_summaries = False\n",
    ")\n",
    "      \n",
    "agent.initialize()\n",
    "print(f'agent: {agent.name}')\n",
    "\n",
    "# if network:\n",
    "#     print(f\"Network: {network}\")\n",
    "\n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {NETWORK_TYPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d77d1-a0b3-4898-adf0-0b32bfaf5bd7",
   "metadata": {},
   "source": [
    "#### tmp - debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78ca56e7-a386-4bf4-8c2b-3d1665521f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41483f5a-bda6-48a4-9e1c-88d8b4afeea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.time_step_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f205716-f265-4ca8-81a7-4799de8f60a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(Trajectory(\n",
       "{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32)),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None)}),\n",
       " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None)),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.training_data_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d404dae-3cc3-4f81-962b-4641455ca4f2",
   "metadata": {},
   "source": [
    "## Reward function\n",
    "\n",
    "> see `reward_factory.py`\n",
    "\n",
    "**TODO:**\n",
    "* explain how to translate reward to this common recommendation objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df9aecd6-d20a-48a7-9ead-4da3bbcfdae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _get_rewards(element):\n",
    "#     \"\"\"Calculates reward for the actions.\"\"\"\n",
    "\n",
    "#     def _calc_reward(x):\n",
    "#         \"\"\"Calculates reward for a single action.\"\"\"\n",
    "#         r0 = lambda: tf.constant(0.0)\n",
    "#         r1 = lambda: tf.constant(1.0)\n",
    "#         r2 = lambda: tf.constant(2.0)\n",
    "#         r3 = lambda: tf.constant(3.0)\n",
    "#         r4 = lambda: tf.constant(4.0)\n",
    "#         r5 = lambda: tf.constant(5.0)\n",
    "#         c1 = tf.equal(x, 1.0)\n",
    "#         c2 = tf.equal(x, 2.0)\n",
    "#         c3 = tf.equal(x, 3.0)\n",
    "#         c4 = tf.equal(x, 4.0)\n",
    "#         c5 = tf.equal(x, 5.0)\n",
    "#         return tf.case(\n",
    "#             [(c1, r1), (c2, r2), (c3, r3),(c4, r4),(c5, r5)], \n",
    "#             default=r0, exclusive=True\n",
    "#         )\n",
    "\n",
    "#     return tf.map_fn(\n",
    "#         fn=_calc_reward, \n",
    "#         elems=element['user_rating'], \n",
    "#         dtype=tf.float32\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac59703a-9a00-4eba-a3b7-45b21b738dd4",
   "metadata": {},
   "source": [
    "## Trajectory function\n",
    "\n",
    "**parking lot**\n",
    "* does trajectory fn need concept of `dummy_chosen_arm_features`, similar to [this](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_base_policy.py#L297)\n",
    "\n",
    "```python\n",
    "      dummy_chosen_arm_features = tf.nest.map_structure(\n",
    "          lambda obs: tf.zeros_like(obs[:, 0, ...]),\n",
    "          time_step.observation[bandit_spec_utils.PER_ARM_FEATURE_KEY],\n",
    "      )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c16aa7b-f328-425e-b02e-a3fc7f200859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.perarm_features import reward_factory as reward_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3605d9f-d239-4871-9a61-6e9b21f9c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _trajectory_fn(element): # hparams\n",
    "    \n",
    "    \"\"\"Converts a dataset element into a trajectory.\"\"\"\n",
    "    # global_features = _get_global_context_features(element)\n",
    "    # arm_features = _get_per_arm_features(element)\n",
    "    \n",
    "    global_features = embs._get_global_context_features(element)\n",
    "    arm_features = embs._get_per_arm_features(element)\n",
    "    \n",
    "    # Adds a time dimension.\n",
    "    arm_features = train_utils._add_outer_dimension(arm_features)\n",
    "\n",
    "    # obs spec\n",
    "    observation = {\n",
    "        bandit_spec_utils.GLOBAL_FEATURE_KEY:\n",
    "            train_utils._add_outer_dimension(global_features),\n",
    "    }\n",
    "\n",
    "    # reward = train_utils._add_outer_dimension(_get_rewards(element))\n",
    "    reward = train_utils._add_outer_dimension(reward_factory._get_rewards(element))\n",
    "\n",
    "    # To emit the predicted rewards in policy_info, we need to create dummy\n",
    "    # rewards to match the definition in TensorSpec for the ones specified in\n",
    "    # emit_policy_info set.\n",
    "    dummy_rewards = tf.zeros([HPARAMS['batch_size'], 1, HPARAMS['num_actions']])\n",
    "    policy_info = policy_utilities.PerArmPolicyInfo(\n",
    "        chosen_arm_features=arm_features,\n",
    "        # Pass dummy mean rewards here to match the model_spec for emitting\n",
    "        # mean rewards in policy info\n",
    "        predicted_rewards_mean=dummy_rewards,\n",
    "        bandit_policy_type=tf.zeros([HPARAMS['batch_size'], 1, 1], dtype=tf.int32)\n",
    "        # policy_utilities.create_bandit_policy_type_tensor_spec(shape=[1]) # policy_utilities.BanditPolicyType.GREEDY\n",
    "        # tf.zeros([batch_size, 1, 1], dtype=tf.int32)\n",
    "    )\n",
    "    \n",
    "    if HPARAMS['model_type'] == 'neural_ucb':\n",
    "        policy_info = policy_info._replace(\n",
    "            predicted_rewards_optimistic=dummy_rewards\n",
    "        )\n",
    "        \n",
    "    return trajectory.single_step(\n",
    "        observation=observation,\n",
    "        action=tf.zeros_like(\n",
    "            reward, dtype=tf.int32\n",
    "        ),  # Arm features are copied from policy info, put dummy zeros here\n",
    "        policy_info=policy_info,\n",
    "        reward=reward,\n",
    "        discount=tf.zeros_like(reward)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a0989c-5a06-4fd5-a12d-d92dbbe71a76",
   "metadata": {},
   "source": [
    "Inspect the trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "257791d1-c97c-48c0-bc92-f5a4737b6c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in train_dataset.batch(HPARAMS['batch_size']).take(1):\n",
    "    test_traj = _trajectory_fn(x)\n",
    "    \n",
    "# test_traj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d8994e-ce28-4fd9-8e3b-153451d014d9",
   "metadata": {},
   "source": [
    "#### tmp - debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a0e451f-1ad8-4af2-84d6-ddc5eaac0e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.action.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.action.shape: {test_traj.action.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52ed1767-12ce-404c-9caf-0974d55ec5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.discount.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.discount.shape: {test_traj.discount.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "033ff16b-0158-477f-835f-99deec636b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.reward.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.reward.shape: {test_traj.reward.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee5aded7-7f9c-4a88-868c-f6ab58a0e704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.observation.shape: (128, 1, 64)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.observation.shape: {test_traj.observation['global'].shape}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcbfc9a-049e-49b9-b2a3-ecb9fd4b9964",
   "metadata": {},
   "source": [
    "# [3] Training the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13adc1ef-b50e-41a3-9b95-c128d0c55a2b",
   "metadata": {},
   "source": [
    "## set Vertex Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e861fb27-df24-4821-8448-cf1346b186f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : v2-local-2a-v1\n",
      "RUN_NAME          : run-20231010-025811\n",
      "\n",
      "BASE_OUTPUT_DIR   : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-025811\n",
      "LOG_DIR           : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-025811/logs\n",
      "ROOT_DIR          : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-025811/root\n",
      "ARTIFACTS_DIR     : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-025811/artifacts\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME   = f'v2-local-2a-v1'\n",
    "\n",
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b7a5e4-efff-490b-b431-53037a2f4a16",
   "metadata": {},
   "source": [
    "## eval loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba0392e-90c8-4dc8-8df2-6d2af1ade490",
   "metadata": {},
   "source": [
    "> When evaluating an epsilon-greedy bandit, we need to remove those predictions that come from the `uniform_random` policy. We only want the predictions from the `GREEDY` policy, becasue we want to know how the model performs when it is actually used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b3d3c-75f7-46f4-9a1b-6329e419b7f5",
   "metadata": {},
   "source": [
    "## train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97cfe7c3-4022-47a9-83c2-df0ad8a2abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.metrics import export_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.utils import common\n",
    "\n",
    "# from src.per_arm_rl import train_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bb7ffc-00df-4d46-857b-86c87b78f597",
   "metadata": {},
   "source": [
    "`agent.train(experience=...)`\n",
    "\n",
    "where `experience` is a batch of trajectories data in the form of a Trajectory. \n",
    "* The structure of experience must match that of `self.training_data_spec`. \n",
    "* All tensors in experience must be shaped [batch, time, ...] where time must be equal to self.train_step_length if that property is not None."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94d6d45-c71e-4fe4-9af8-af9a8bda4e4f",
   "metadata": {},
   "source": [
    "### logs & checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "049ee49b-3b1a-4b12-a360-15e759dff7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('metrics: [<tf_agents.metrics.tf_metrics.AverageReturnMetric object at '\n",
      " '0x7f9abd1c24a0>]')\n",
      "setting checkpoint_manager: gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-025811/root/chkpoint\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    f\"{LOG_DIR}/train\", flush_millis=10 * 1000\n",
    ")\n",
    "# train_summary_writer.set_as_default()\n",
    "\n",
    "# eval_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "#     f\"{LOG_DIR}/eval\", flush_millis=10 * 1000\n",
    "# )\n",
    "# ====================================================\n",
    "# metrics\n",
    "# ====================================================\n",
    "step_metric = tf_metrics.EnvironmentSteps()\n",
    "metrics = [\n",
    "    # tf_metrics.NumberOfEpisodes(),\n",
    "    # tf_metrics.AverageEpisodeLengthMetric(batch_size=HPARAMS['batch_size']),\n",
    "    tf_metrics.AverageReturnMetric(batch_size=HPARAMS['batch_size'])\n",
    "]\n",
    "\n",
    "pprint(f\"metrics: {metrics}\")\n",
    "\n",
    "# ====================================================\n",
    "# get checkpoint manager\n",
    "# ====================================================\n",
    "CHKPOINT_DIR = f\"{ROOT_DIR}/chkpoint\"\n",
    "print(f\"setting checkpoint_manager: {CHKPOINT_DIR}\")\n",
    "\n",
    "checkpoint_manager = train_utils.restore_and_get_checkpoint_manager(\n",
    "    root_dir=CHKPOINT_DIR, \n",
    "    agent=agent, \n",
    "    metrics=metrics, \n",
    "    step_metric=step_metric\n",
    ")\n",
    "# ====================================================\n",
    "# policy saver\n",
    "# ====================================================\n",
    "saver = policy_saver.PolicySaver(\n",
    "    agent.policy, \n",
    "    train_step=global_step\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83683f4b-8a1a-44b9-8d5f-7ee3304c794c",
   "metadata": {},
   "source": [
    "### config\n",
    "\n",
    "* calculate train & val dataset sizes\n",
    "* define logging and chkpt intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f9432613-6583-4828-8a2a-dd939adbc3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_DATA_SIZE : 80000\n",
      "NUM_TRAIN_STEPS : 100\n",
      "EVAL_DATA_SIZE : 1000\n",
      "NUM_EVAL_STEPS : 1000\n",
      "CHKPT_INTERVAL: 100\n",
      "LOG_INTERVAL : 10\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA_SIZE = 80000          # len(list(train_dataset))\n",
    "NUM_TRAIN_STEPS = 100            # TRAIN_DATA_SIZE // HPARAMS['batch_size']\n",
    "\n",
    "EVAL_DATA_SIZE  = 1000          # len(list(val_dataset))\n",
    "NUM_EVAL_STEPS  = 1000           # EVAL_DATA_SIZE // HPARAMS['eval_batch_size']\n",
    "\n",
    "CHKPT_INTERVAL  = NUM_TRAIN_STEPS # // 5\n",
    "LOG_INTERVAL    = 10\n",
    "# EVAL_INTERVAL = NUM_TRAIN_STEPS // 2\n",
    "\n",
    "print(f\"TRAIN_DATA_SIZE : {TRAIN_DATA_SIZE}\")\n",
    "print(f\"NUM_TRAIN_STEPS : {NUM_TRAIN_STEPS}\")\n",
    "print(f\"EVAL_DATA_SIZE : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS : {NUM_EVAL_STEPS}\")\n",
    "print(f\"CHKPT_INTERVAL: {CHKPT_INTERVAL}\")\n",
    "print(f\"LOG_INTERVAL : {LOG_INTERVAL}\")\n",
    "# print(f\"EVAL_INTERVAL : {EVAL_INTERVAL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "379ffc65-4eec-4af1-8fd4-912ef65a9808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec={'bucketized_user_age': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'movie_genres': TensorSpec(shape=(None, 1), dtype=tf.int64, name=None), 'movie_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'timestamp': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'user_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_occupation_text': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_rating': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data\n",
    "train_ds_iterator = iter(train_dataset.batch(HPARAMS['batch_size']).repeat())\n",
    "\n",
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS[\"eval_batch_size\"])\n",
    "\n",
    "if NUM_EVAL_STEPS > 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)\n",
    "\n",
    "# eval_ds = eval_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "eval_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e498d7e3-d166-4e1d-94a5-f721de58694a",
   "metadata": {},
   "source": [
    "### run train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5dd64d98-7d5b-4474-a567-b42426d630a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.perarm_features import eval_perarm as eval_perarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "da4680f3-693b-4530-8e4d-88bc43036c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating pre-trained Agent...\n",
      "pre-train val_loss     : 15.353626251220703\n",
      "pre-train eval runtime : 0\n",
      "starting train loop...\n",
      "step = 0: train loss = 15.90999984741211\n",
      "step = 10: train loss = 11.869999885559082\n",
      "step = 20: train loss = 8.350000381469727\n",
      "step = 30: train loss = 1.3200000524520874\n",
      "step = 40: train loss = 0.9700000286102295\n",
      "step = 50: train loss = 1.649999976158142\n",
      "step = 60: train loss = 1.7400000095367432\n",
      "step = 70: train loss = 1.440000057220459\n",
      "step = 80: train loss = 1.3300000429153442\n",
      "step = 90: train loss = 1.3700000047683716\n",
      "train runtime_mins: 12\n",
      "saved trained policy to: gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-025811/artifacts\n",
      "evaluating trained Agent...\n",
      "post-train val_loss     : 1.3078540563583374\n",
      "post-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "# agent.train = common.function(agent.train)\n",
    "\n",
    "list_o_loss = []\n",
    "\n",
    "# ====================================================\n",
    "# Evaluate the agent's policy once before training\n",
    "# ====================================================\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "pre_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "\n",
    "print(f\"evaluating pre-trained Agent...\")\n",
    "start_time = time.time()\n",
    "\n",
    "pre_val_loss, pre_preds, pre_tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = pre_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"pre-train val_loss     : {pre_val_loss}\")\n",
    "print(f\"pre-train eval runtime : {runtime_mins}\")\n",
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "print(f\"starting train loop...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# for i in tqdm(range(NUM_TRAIN_STEPS)):\n",
    "for i in range(NUM_TRAIN_STEPS):\n",
    "    \n",
    "    with train_summary_writer.as_default():\n",
    "\n",
    "        data = next(train_ds_iterator)\n",
    "        trajectories = _trajectory_fn(data)\n",
    "\n",
    "        # All tensors in experience must be shaped [batch, time, ...] \n",
    "        step = agent.train_step_counter.numpy()\n",
    "        loss = agent.train(experience=trajectories)\n",
    "        list_o_loss.append(loss.loss.numpy())\n",
    "\n",
    "        train_utils._export_metrics_and_summaries(\n",
    "            step=i, \n",
    "            metrics=metrics\n",
    "        )\n",
    "\n",
    "        # print step loss\n",
    "        if step % LOG_INTERVAL == 0:\n",
    "            print(\n",
    "                'step = {0}: train loss = {1}'.format(\n",
    "                    step, round(loss.loss.numpy(), 2)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if i > 0 and i % CHKPT_INTERVAL == 0:\n",
    "            saver.save(os.path.join(CHKPOINT_DIR, 'policy_%d' % step_metric.result()))\n",
    "            print(f\"saved policy to: {CHKPOINT_DIR}\")\n",
    "   \n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"train runtime_mins: {runtime_mins}\")\n",
    "\n",
    "saver.save(ARTIFACTS_DIR)\n",
    "print(f\"saved trained policy to: {ARTIFACTS_DIR}\")\n",
    "\n",
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = post_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "17b2b0d2-9795-4367-b57b-c331e94d1000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.307854"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb1ed8-f67b-4e7b-9cbc-70edd50e49ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate train job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff31fe28-2f05-499f-b1cc-505f3c9074e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### train loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41937f9a-6c28-48d2-bc7c-bfe4372c7cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_o_loss)\n",
    "# plt.ylim([0, 10])\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e947e1-67f4-4205-99af-6921c6e9c896",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TensorBoard\n",
    "\n",
    "<img src=\"imgs/getting_profiler.png\" \n",
    "     align=\"center\" \n",
    "     width=\"850\"\n",
    "     height=\"850\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e0f77a33-0962-4af0-af97-cf05f895cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5d0509cb-0777-4d35-86c6-28c8acbcc793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-aea02b4e0ac274ac\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-aea02b4e0ac274ac\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=$LOG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc40143-30b1-479f-b9b1-fa4c07b1690e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [4] Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6c94a0-122f-4ba6-acef-5653a3cc7850",
   "metadata": {
    "tags": []
   },
   "source": [
    "## load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b1c382b5-e2e0-45a2-9c5f-ef2c468d0f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-025811/artifacts\n"
     ]
    }
   ],
   "source": [
    "POLICY_URI = ARTIFACTS_DIR\n",
    "\n",
    "print(POLICY_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "68592d97-1272-4c6d-a4bd-43a6f7fe6c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f999c556020>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910a06f-678f-4bfa-a132-10b885f871c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## get predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1762c936-3c49-4ec5-a9eb-4df5816dc888",
   "metadata": {},
   "source": [
    "TODO - explain bandit_policy_type()\n",
    "\n",
    "**UNIFORM Random policy:**\n",
    "```\n",
    "PolicyStep(action=array(1, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.637535 , 3.5557823], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([2], dtype=int32), chosen_arm_features=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)))\n",
    "```\n",
    "\n",
    "**GREEDY policy:**\n",
    "```\n",
    "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.8278818, 3.607565 ], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([ 0.04054676, -0.04735027,  0.02202327,  0.01276748, -0.01367382,\n",
    "       -0.04838754,  0.00104916, -0.01956806,  0.01028793, -0.00256665,\n",
    "       -0.04376553,  0.03900594,  0.02388967, -0.04016995, -0.04945569,\n",
    "       -0.04539652,  0.04423274, -0.04630332,  0.00390794,  0.03986299,\n",
    "       -0.0398974 ,  0.01655747, -0.0471294 , -0.00690235, -0.03643382,\n",
    "       -0.0437116 ,  0.04757959, -0.00991895,  0.0281055 , -0.04633433,\n",
    "        0.01897702, -0.00824345,  0.03232259, -0.04980658, -0.01144745,\n",
    "        0.01690939,  0.02536928,  0.03384003, -0.01558131,  0.04731432,\n",
    "        0.04579857, -0.03305101,  0.03521084, -0.03915765,  0.04927064,\n",
    "        0.04695194,  0.03792156,  0.040496  ,  0.02574866, -0.00665367,\n",
    "       -0.03839222, -0.01564004, -0.04710373,  0.03557512, -0.01392462,\n",
    "        0.01368621,  0.02792176, -0.01799218,  0.00246101,  0.02263175,\n",
    "        0.0170817 ,  0.01388383, -0.03048695,  0.01198485], dtype=float32)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "567f64e1-8149-4364-b561-1a9d12581b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aff30396-e0fd-4f43-acaa-6af8b20b12cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "SKIP_NUM = 10\n",
    "\n",
    "for x in eval_ds.skip(SKIP_NUM).take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    \n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "    \n",
    "    # rewards = _get_rewards(x)\n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e58af9ab-f4da-4857-afe5-6b8de26ed0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.7746792, 3.4872231], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([-0.04211991,  0.03355854,  0.00062222, -0.03559208,  0.03014546,\n",
       "       -0.00911941,  0.03367225, -0.01702491, -0.04207989,  0.02439343,\n",
       "        0.03417565,  0.03412655, -0.01548523, -0.04152564, -0.01327814,\n",
       "        0.04441997, -0.01887345, -0.03676014, -0.01746018, -0.00505089,\n",
       "       -0.00495514, -0.02221038,  0.00734597, -0.02457649,  0.01958629,\n",
       "       -0.00150286, -0.00817053,  0.02833397,  0.03182454,  0.00413366,\n",
       "        0.04550329, -0.03923135,  0.03378687,  0.00785377, -0.0018571 ,\n",
       "       -0.02951536, -0.02467777, -0.02666589, -0.04103365, -0.00640677,\n",
       "       -0.03457658,  0.03871839, -0.03362087, -0.00123868,  0.0398059 ,\n",
       "       -0.01511135, -0.02833097,  0.03514184,  0.03603243,  0.03224551,\n",
       "        0.03410349, -0.04499953, -0.02059256, -0.01573974, -0.0066855 ,\n",
       "       -0.04533432, -0.0378898 ,  0.0453725 ,  0.01792984, -0.01493819,\n",
       "        0.03005158, -0.02943999, -0.00384724, -0.01675253], dtype=float32)))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6676778c-d191-4b1e-a180-61f068b3b8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.7746792, 3.4872231], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([-0.04211991,  0.03355854,  0.00062222, -0.03559208,  0.03014546,\n",
      "       -0.00911941,  0.03367225, -0.01702491, -0.04207989,  0.02439343,\n",
      "        0.03417565,  0.03412655, -0.01548523, -0.04152564, -0.01327814,\n",
      "        0.04441997, -0.01887345, -0.03676014, -0.01746018, -0.00505089,\n",
      "       -0.00495514, -0.02221038,  0.00734597, -0.02457649,  0.01958629,\n",
      "       -0.00150286, -0.00817053,  0.02833397,  0.03182454,  0.00413366,\n",
      "        0.04550329, -0.03923135,  0.03378687,  0.00785377, -0.0018571 ,\n",
      "       -0.02951536, -0.02467777, -0.02666589, -0.04103365, -0.00640677,\n",
      "       -0.03457658,  0.03871839, -0.03362087, -0.00123868,  0.0398059 ,\n",
      "       -0.01511135, -0.02833097,  0.03514184,  0.03603243,  0.03224551,\n",
      "        0.03410349, -0.04499953, -0.02059256, -0.01573974, -0.0066855 ,\n",
      "       -0.04533432, -0.0378898 ,  0.0453725 ,  0.01792984, -0.01493819,\n",
      "        0.03005158, -0.02943999, -0.00384724, -0.01675253], dtype=float32)))\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c85a0087-7388-4f03-9278-aace31121233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0, dtype=int32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a8266c7c-3688-46a5-a1c8-a63bb7146128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info.bandit_policy_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9712bc00-7ea0-4003-a3c7-81a0be5bc995",
   "metadata": {},
   "source": [
    "# [5] Prepare training application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f62966-123f-410e-9610-832f20566635",
   "metadata": {},
   "source": [
    "To scale this training in Vertex AI's managed training service, we need to package all our code into a python application\n",
    "\n",
    "* This means, we need to modularize all steps executed up until this point. For example, the training loop we ran above is further parameterized in `train_perarm.py`, which will be called from our `task.py` when we submit the job to Vertex AI\n",
    "* This training package will eventually be used to create a custom training image (more on that in `04b-build-training-image` notebook)\n",
    "* For additional details on preparing the training application for Vertex AI, check out [the documentation](https://cloud.google.com/vertex-ai/docs/training/code-requirements) and [this code example](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage2/get_started_vertex_training.ipynb) (which also has good, related commentary)\n",
    "\n",
    "**The remaining cells will repeat steps executed above**\n",
    "> we are just illustrating / validating that they are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1129ee41-b43c-4d5a-b656-cdac6b79688c",
   "metadata": {},
   "source": [
    "#### Vertex Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ef509680-4d19-4efa-9f01-21039e0d573b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : v2-local-2a-v1\n"
     ]
    }
   ],
   "source": [
    "# using same experiment name \n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7ad98430-d836-40f1-8e4f-eb46f0c91fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : v2-local-2a-v1\n",
      "RUN_NAME          : run-20231010-031407\n",
      "\n",
      "BASE_OUTPUT_DIR   : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407\n",
      "LOG_DIR           : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/logs\n",
      "ROOT_DIR          : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/root\n",
      "ARTIFACTS_DIR     : gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/artifacts\n"
     ]
    }
   ],
   "source": [
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fbdecf78-94c5-4f8c-a6c0-86f2eace4663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: NeuralEpsGreedyAgent\n",
      "Network: commontower\n"
     ]
    }
   ],
   "source": [
    "# from src.perarm_features import agent_factory as agent_factory\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "    agent_type = AGENT_TYPE,\n",
    "    network_type = NETWORK_TYPE,\n",
    "    time_step_spec = time_step_spec,\n",
    "    action_spec = action_spec,\n",
    "    observation_spec=observation_spec,\n",
    "    global_layers = GLOBAL_LAYERS,\n",
    "    arm_layers = ARM_LAYERS,\n",
    "    common_layers = COMMON_LAYERS,\n",
    "    agent_alpha = AGENT_ALPHA,\n",
    "    learning_rate = LR,\n",
    "    epsilon = EPSILON,\n",
    "    train_step_counter = global_step,\n",
    "    output_dim = ENCODING_DIM,\n",
    "    eps_phase_steps = EPS_PHASE_STEPS,\n",
    ")\n",
    "\n",
    "print(f\"Agent: {agent.name}\")\n",
    "\n",
    "# if network:\n",
    "#     print(f\"Network: {network}\")\n",
    "\n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {NETWORK_TYPE}\")\n",
    "        \n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "108ed33c-d8ef-4524-97e9-ced9e01c154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHKPT_INTERVAL    : 200\n",
      "eval_batch_size   : 1\n",
      "EVAL_DATA_SIZE    : 1000\n",
      "NUM_EVAL_STEPS    : 100\n",
      "TOTAL_TRAIN_TAKE  : 10000\n"
     ]
    }
   ],
   "source": [
    "from src.perarm_features import train_perarm as train_perarm\n",
    "\n",
    "# train args\n",
    "TRAINING_LOOPS        = 150\n",
    "STEPS_PER_LOOP        = 1\n",
    "\n",
    "drop_arm_feature_fn   = None\n",
    "ASYNC_STEPS_PER_LOOP  = 1\n",
    "\n",
    "LOG_INTERVAL          = 10\n",
    "CHKPT_INTERVAL        = 200\n",
    "\n",
    "# eval args\n",
    "NUM_EVAL_STEPS = 100\n",
    "\n",
    "TOTAL_TRAIN_TAKE = 10000 #TRAINING_LOOPS * HPARAMS['batch_size']\n",
    "\n",
    "print(f\"CHKPT_INTERVAL    : {CHKPT_INTERVAL}\")\n",
    "print(f\"eval_batch_size   : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"EVAL_DATA_SIZE    : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS    : {NUM_EVAL_STEPS}\")\n",
    "print(f\"TOTAL_TRAIN_TAKE  : {TOTAL_TRAIN_TAKE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f66ff927-9a39-4abf-b247-845f0dc7721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS['eval_batch_size'])\n",
    "\n",
    "if NUM_EVAL_STEPS >= 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f6c98398-d545-4dcc-a71f-32249b5f0336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distribution_strategy: <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f9abd18b250>\n",
      "train_files: ['gs://rec-bandits-v2-hybrid-vertex-bucket/data/train/ml-ratings-100k-train.tfrecord']\n",
      "train_ds_iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f94e92e49a0>\n",
      "setting checkpoint_manager: gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/root/chkpoint\n",
      "wrapping agent.train in tf-function\n",
      "starting_loop: 0\n",
      "starting train loop...\n",
      "step = 100: loss = 15.920000076293945\n",
      "step = 110: loss = 9.289999961853027\n",
      "step = 120: loss = 7.329999923706055\n",
      "step = 130: loss = 1.2100000381469727\n",
      "step = 140: loss = 1.0399999618530273\n",
      "step = 150: loss = 1.590000033378601\n",
      "step = 160: loss = 1.6699999570846558\n",
      "step = 170: loss = 1.3700000047683716\n",
      "step = 180: loss = 1.3300000429153442\n",
      "step = 190: loss = 1.309999942779541\n",
      "step = 200: loss = 1.5199999809265137\n",
      "step = 210: loss = 1.309999942779541\n",
      "step = 220: loss = 1.1399999856948853\n",
      "step = 230: loss = 0.949999988079071\n",
      "step = 240: loss = 1.1299999952316284\n",
      "runtime_mins: 17\n",
      "saved trained policy to: gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/artifacts\n",
      "complete train job in 17 minutes\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    f\"{LOG_DIR}/train\", flush_millis=10 * 1000\n",
    ")\n",
    "\n",
    "#start the timer and training\n",
    "start_time = time.time()\n",
    "\n",
    "metric_results, agent = train_perarm.train_perarm(\n",
    "    agent = agent,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    num_iterations = TRAINING_LOOPS,\n",
    "    steps_per_loop = STEPS_PER_LOOP,\n",
    "    num_eval_steps = NUM_EVAL_STEPS,\n",
    "    # data\n",
    "    batch_size = HPARAMS['batch_size'],\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    # functions\n",
    "    _trajectory_fn = _trajectory_fn,\n",
    "    # _run_bandit_eval_fn = _run_bandit_eval,\n",
    "    # train intervals\n",
    "    chkpt_interval = CHKPT_INTERVAL,\n",
    "    log_interval = LOG_INTERVAL,\n",
    "    # dirs\n",
    "    bucket_name = BUCKET_NAME,\n",
    "    data_dir_prefix_path = DATA_GCS_PREFIX,\n",
    "    log_dir = LOG_DIR,\n",
    "    model_dir = ARTIFACTS_DIR,\n",
    "    root_dir = ROOT_DIR,\n",
    "    async_steps_per_loop = ASYNC_STEPS_PER_LOOP,\n",
    "    resume_training_loops = False,\n",
    "    use_gpu = True,\n",
    "    use_tpu = False,\n",
    "    profiler = False,\n",
    "    global_step = global_step,\n",
    "    total_train_take = TOTAL_TRAIN_TAKE,\n",
    "    train_summary_writer = train_summary_writer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"complete train job in {runtime_mins} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "177aa3ab-05b4-48f9-b434-9335bd9eb54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3775473"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(metric_results)\n",
    "metric_results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba65417f-54e0-436e-b0d4-93cffb981ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(metric_results)\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7ba747-00d5-4908-8d0b-334ae9d2c791",
   "metadata": {},
   "source": [
    "#### eval trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c5cf9366-d9cd-4c9d-951a-99a50877a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af82506e-95d7-4a4e-a821-e08512615db7",
   "metadata": {},
   "source": [
    "After training, our `agent.policy` is used as the deployment \"model\" that will generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6c82396a-7822-41fb-830f-1f6eb9c9b213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.epsilon_greedy_policy.EpsilonGreedyPolicy at 0x7f94e9160b80>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_agent = agent.policy\n",
    "deployment_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f6706224-ef5b-4185-bde4-bccb7c8e7ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating trained Agent...\n",
      "post-train val_loss     : 1.5848735570907593\n",
      "post-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(deployment_agent, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = post_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f899120f-3706-4b72-8f2c-2169221dd66b",
   "metadata": {},
   "source": [
    "## Using Trained Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b0f691-860e-4853-928e-4c7ece714dd0",
   "metadata": {},
   "source": [
    "### load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ea029f73-0638-462a-8f00-54b05c54d69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/artifacts\n"
     ]
    }
   ],
   "source": [
    "POLICY_URI = ARTIFACTS_DIR\n",
    "\n",
    "print(POLICY_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "66d1d819-0152-437c-aefc-45ffd34d808a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/artifacts/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/artifacts/fingerprint.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/artifacts/policy_specs.pbtxt\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/artifacts/saved_model.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/artifacts/assets/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/v2-local-2a-v1/run-20231010-031407/artifacts/variables/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $POLICY_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6aad948e-e346-4da3-8cb2-747435c8dc4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f94eb67aef0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "483f8fa5-cbd1-4e3c-8e62-47f91f42e137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(), dtype=dtype('int32'), name='action_spec', minimum=0, maximum=1)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_policy.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8f658891-bc09-49b8-bc58-000a7926df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "SKIP_NUM = 10\n",
    "\n",
    "for x in eval_ds.skip(SKIP_NUM).take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    \n",
    "    # global_feat_infer = _get_global_context_features(x)\n",
    "    # arm_feat_infer = _get_per_arm_features(x)\n",
    "    \n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "    \n",
    "    # rewards = _get_rewards(x)\n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f515fcd0-2228-4f68-9ef9-665ce1fc3fb2",
   "metadata": {},
   "source": [
    "### view prediction response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6af4c297-d2e8-4f7b-bed5-e1da997dfe34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.2646697, 3.2237158], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([-0.04211991,  0.03355854,  0.00062222, -0.03559208,  0.03014546,\n",
       "       -0.00911941,  0.03367225, -0.01702491, -0.04207989,  0.02439343,\n",
       "        0.03417565,  0.03412655, -0.01548523, -0.04152564, -0.01327814,\n",
       "        0.04441997, -0.01887345, -0.03676014, -0.01746018, -0.00505089,\n",
       "       -0.00495514, -0.02221038,  0.00734597, -0.02457649,  0.01958629,\n",
       "       -0.00150286, -0.00817053,  0.02833397,  0.03182454,  0.00413366,\n",
       "        0.04550329, -0.03923135,  0.03378687,  0.00785377, -0.0018571 ,\n",
       "       -0.02951536, -0.02467777, -0.02666589, -0.04103365, -0.00640677,\n",
       "       -0.03457658,  0.03871839, -0.03362087, -0.00123868,  0.0398059 ,\n",
       "       -0.01511135, -0.02833097,  0.03514184,  0.03603243,  0.03224551,\n",
       "        0.03410349, -0.04499953, -0.02059256, -0.01573974, -0.0066855 ,\n",
       "       -0.04533432, -0.0378898 ,  0.0453725 ,  0.01792984, -0.01493819,\n",
       "        0.03005158, -0.02943999, -0.00384724, -0.01675253], dtype=float32)))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd58d4b-6749-4177-8342-83ee969408c9",
   "metadata": {},
   "source": [
    "#### chosen action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d49adbbb-f747-4e4c-b82d-df88373c644f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0, dtype=int32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd12013-1d12-4197-8254-cef9138df42c",
   "metadata": {},
   "source": [
    "#### Per Arm Policy Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d6126290-546b-4702-8a1e-91f18adb05c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.2646697, 3.2237158], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([-0.04211991,  0.03355854,  0.00062222, -0.03559208,  0.03014546,\n",
       "       -0.00911941,  0.03367225, -0.01702491, -0.04207989,  0.02439343,\n",
       "        0.03417565,  0.03412655, -0.01548523, -0.04152564, -0.01327814,\n",
       "        0.04441997, -0.01887345, -0.03676014, -0.01746018, -0.00505089,\n",
       "       -0.00495514, -0.02221038,  0.00734597, -0.02457649,  0.01958629,\n",
       "       -0.00150286, -0.00817053,  0.02833397,  0.03182454,  0.00413366,\n",
       "        0.04550329, -0.03923135,  0.03378687,  0.00785377, -0.0018571 ,\n",
       "       -0.02951536, -0.02467777, -0.02666589, -0.04103365, -0.00640677,\n",
       "       -0.03457658,  0.03871839, -0.03362087, -0.00123868,  0.0398059 ,\n",
       "       -0.01511135, -0.02833097,  0.03514184,  0.03603243,  0.03224551,\n",
       "        0.03410349, -0.04499953, -0.02059256, -0.01573974, -0.0066855 ,\n",
       "       -0.04533432, -0.0378898 ,  0.0453725 ,  0.01792984, -0.01493819,\n",
       "        0.03005158, -0.02943999, -0.00384724, -0.01675253], dtype=float32))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f66961-ebb5-4ae5-8e6f-ad73114d8353",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
