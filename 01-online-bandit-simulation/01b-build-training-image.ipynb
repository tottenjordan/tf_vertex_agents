{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64583cdb-2502-4f40-a254-8fa68abe7a32",
   "metadata": {},
   "source": [
    "# Build custom container for matrix-factorization-based simulation environment in Vertex AI training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e1beb37-0c48-4110-8ca0-24ab78c72b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/01-online-bandit-simulation\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66298299-d4ad-460e-8ab3-ea9fbc012086",
   "metadata": {},
   "source": [
    "## Load env config\n",
    "\n",
    "* use the prefix from `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1d2542f-d87b-436d-b4bb-08edcbb532ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "# PREFIX = 'mabv1'\n",
    "VERSION        = \"v2\"                       # TODO\n",
    "PREFIX         = f'rec-bandits-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35449112-3c26-4ea9-8c3a-21c283951350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"rec-bandits-v2\"\n",
      "VERSION                  = \"v2\"\n",
      "\n",
      "BUCKET_NAME              = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "DATA_PATH_KFP_DEMO       = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data/kfp_demo_data/u.data\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_NAME    = \"mvlens_rec_bandits_v2\"\n",
      "BIGQUERY_TABLE_NAME      = \"training_dataset\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-rec-bandits-v2\"\n",
      "\n",
      "DOCKERNAME_01            = \"Dockerfile_train_my_perarm_env\"\n",
      "IMAGE_NAME_01            = \"train-my-perarm-env-v2\"\n",
      "IMAGE_URI_01             = \"gcr.io/hybrid-vertex/train-my-perarm-env-v2\"\n",
      "\n",
      "DOCKERNAME_02            = \"Dockerfile_perarm_feats\"\n",
      "IMAGE_NAME_02            = \"train-perarm-feats-v2\"\n",
      "IMAGE_URI_02             = \"gcr.io/hybrid-vertex/train-perarm-feats-v2\"\n",
      "\n",
      "DOCKERNAME_03            = \"Dockerfile_ranking_bandit\"\n",
      "IMAGE_NAME_03            = \"train-rank-bandit-v2\"\n",
      "IMAGE_URI_03             = \"gcr.io/hybrid-vertex/train-rank-bandit-v2\"\n",
      "\n",
      "DOCKERNAME_04            = \"Dockerfile_train_mab_e2e\"\n",
      "IMAGE_NAME_04            = \"train-mab-e2e-v2\"\n",
      "IMAGE_URI_04             = \"gcr.io/hybrid-vertex/train-mab-e2e-v2\"\n",
      "\n",
      "DOCKERNAME_04_pred       = \"Dockerfile_pred_mab_e2e\"\n",
      "IMAGE_NAME_04_pred       = \"pred-mab-e2e-v2\"\n",
      "IMAGE_URI_04_pred        = \"gcr.io/hybrid-vertex/pred-mab-e2e-v2\"\n",
      "\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/local_docker_tfa\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b16af06-e188-4f4e-a04b-4e0eb8873ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gsutil ls $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be79c652-45c8-4b5f-b410-4908829375a3",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92272ed8-bfb5-4b40-b7f4-cdbe029f3bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261a452d-8ce7-427b-8091-d7d41c57e556",
   "metadata": {},
   "source": [
    "# Build Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d192a4dd-b3e1-4c48-b69f-fd022078e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tree src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9bdef1-ac23-49be-96fd-25795f483643",
   "metadata": {},
   "source": [
    "## Container Image Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4076530-a340-4c57-91af-e2decd035b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOCKERNAME_TRAIN_MYENV = \"Dockerfile_train_my_perarm_env\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eedbe408-e2fe-4944-912f-f2b1f6587440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOCKERNAME_01          = Dockerfile_train_my_perarm_env\n",
      "REPOSITORY             = rl-movielens-rec-bandits-v2\n",
      "IMAGE_NAME_01          = train-my-perarm-env-v2\n",
      "REMOTE_IMAGE_NAME      = us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/local_docker_tfa\n",
      "IMAGE_URI_01           = gcr.io/hybrid-vertex/train-my-perarm-env-v2\n"
     ]
    }
   ],
   "source": [
    "print(f\"DOCKERNAME_01          = {DOCKERNAME_01}\")\n",
    "print(f\"REPOSITORY             = {REPOSITORY}\")\n",
    "print(f\"IMAGE_NAME_01          = {IMAGE_NAME_01}\")\n",
    "print(f\"REMOTE_IMAGE_NAME      = {REMOTE_IMAGE_NAME}\")\n",
    "print(f\"IMAGE_URI_01           = {IMAGE_URI_01}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf953a8e-d282-4d7b-9a7d-fd0bee28c70a",
   "metadata": {},
   "source": [
    "## Create Artifact Repository\n",
    "\n",
    "If you don't have an existing artifact repository, create one using the gcloud command below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8288932-054a-46e6-90e8-326e015f2115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gcloud artifacts repositories create $REPOSITORY --repository-format=docker --location=$LOCATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1374bc-7b85-4e65-86ab-2721ce4908b3",
   "metadata": {},
   "source": [
    "## Create Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88a8b25d-e55c-4a00-ab0e-1151eae8eaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/tf_vertex_agents'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root_path = '..'\n",
    "os.chdir(root_path)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bffd9bb-6d22-4d4e-9eb8-893472702837",
   "metadata": {},
   "source": [
    "### Create train image\n",
    "\n",
    "* see [example Dockerfile for GPU](https://github.com/GoogleCloudPlatform/cloudml-samples/blob/main/pytorch/containers/quickstart/mnist/Dockerfile-gpu) jobs in Vertex AI\n",
    "* see deep learning container [example here](https://cloud.google.com/deep-learning-containers/docs/derivative-container), and here for [available DL containers](https://cloud.google.com/deep-learning-containers/docs/choosing-container#versions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7022f8d1-43d0-4291-91b8-4cb27491c2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_profiling : True\n"
     ]
    }
   ],
   "source": [
    "gpu_profiling = True # True | False\n",
    "\n",
    "print(f\"gpu_profiling : {gpu_profiling}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4596864b-f059-438d-a04f-7416c436b644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_BASE_IMAGE : gcr.io/deeplearning-platform-release/tf2-gpu.2-13.py310\n",
      "NVTOP_RUN        : RUN apt update && apt -y install nvtop\n",
      "RUN_EXPORT       : RUN export PYTHONPATH=${PYTHONPATH}:${APP_HOME}/\n"
     ]
    }
   ],
   "source": [
    "if gpu_profiling:\n",
    "    # TRAIN_BASE_IMAGE = 'tensorflow/tensorflow:2.13.0-gpu'\n",
    "    TRAIN_BASE_IMAGE = 'gcr.io/deeplearning-platform-release/tf2-gpu.2-13.py310'\n",
    "    NVTOP_RUN = 'RUN apt update && apt -y install nvtop'\n",
    "    # NVTOP_RUN = 'RUN apt-get update && apt-get -y install nvtop'\n",
    "else:\n",
    "    TRAIN_BASE_IMAGE = 'python:3.10'\n",
    "    NVTOP_RUN = None\n",
    "    \n",
    "RUN_EXPORT = \"RUN export PYTHONPATH=${PYTHONPATH}:${APP_HOME}/\"\n",
    "    \n",
    "print(f\"TRAIN_BASE_IMAGE : {TRAIN_BASE_IMAGE}\")\n",
    "print(f\"NVTOP_RUN        : {NVTOP_RUN}\")\n",
    "print(f\"RUN_EXPORT       : {RUN_EXPORT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b1b1fc6-022b-4e56-b62f-673179bab7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FROM gcr.io/deeplearning-platform-release/tf2-gpu.2-13.py310\n",
      "\n",
      "ENV APP_HOME /workspace\n",
      "\n",
      "WORKDIR $APP_HOME\n",
      "\n",
      "COPY /requirements.txt $APP_HOME/requirements.txt\n",
      "RUN pip install --upgrade pip\n",
      "RUN pip install --no-cache-dir -r $APP_HOME/requirements.txt\n",
      "RUN pip install cloudml-hypertune\n",
      "\n",
      "RUN apt update && apt -y install nvtop\n",
      "\n",
      "COPY src/per_arm_rl $APP_HOME/src/per_arm_rl\n",
      "COPY src/environments $APP_HOME/src/environments\n",
      "COPY src/utils $APP_HOME/src/utils\n",
      "\n",
      "RUN export PYTHONPATH=${PYTHONPATH}:${APP_HOME}/\n",
      "\n",
      "RUN pip freeze | grep wrapt\n",
      "\n",
      "# Sets up the entry point to invoke the task.\n",
      "ENTRYPOINT [\"python3\", \"-m\", \"src.per_arm_rl.perarm_task\"]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dockerfile = f'''\n",
    "FROM {TRAIN_BASE_IMAGE}\n",
    "\n",
    "ENV APP_HOME /workspace\n",
    "\n",
    "WORKDIR $APP_HOME\n",
    "\n",
    "COPY /requirements.txt $APP_HOME/requirements.txt\n",
    "RUN pip install --upgrade pip\n",
    "RUN pip install --no-cache-dir -r $APP_HOME/requirements.txt\n",
    "RUN pip install cloudml-hypertune\n",
    "\n",
    "{NVTOP_RUN}\n",
    "\n",
    "COPY src/per_arm_rl $APP_HOME/src/per_arm_rl\n",
    "COPY src/environments $APP_HOME/src/environments\n",
    "COPY src/utils $APP_HOME/src/utils\n",
    "\n",
    "{RUN_EXPORT}\n",
    "\n",
    "RUN pip freeze | grep wrapt\n",
    "\n",
    "# Sets up the entry point to invoke the task.\n",
    "ENTRYPOINT [\"python3\", \"-m\", \"src.per_arm_rl.perarm_task\"]\n",
    "'''\n",
    "print(dockerfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90f3d2c0-c0ec-48bf-bc04-0b4ec5e07014",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DOCKERNAME_01}', 'w') as f:\n",
    "    f.write(dockerfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04bd12e-c61b-4a5c-b2cb-b7843642ce0e",
   "metadata": {},
   "source": [
    "## Build image with Cloud Build\n",
    "\n",
    "Building images with Cloud Build is best practices\n",
    "* images are centrally stored and better managed for robust CI/CD\n",
    "* building images on local workbench instance can alter notebook image config (base image for notebooks vs train images are different)\n",
    "* if building locally, consider using virutal environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33d4d92a-77fc-4d3a-b730-68330cca68a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb3ef36-2cfe-4199-963b-6c65bd0ec621",
   "metadata": {},
   "source": [
    "#### set `.gcloudignore`\n",
    "* to adjust this see the `gcloudignore` section at the end of `00-env-setup.ipynb` notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4e381c6-6b3c-40e1-a1d3-b959ab7185b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .gcloudignore\n"
     ]
    }
   ],
   "source": [
    "%%writefile .gcloudignore\n",
    ".gcloudignore\n",
    "WIP/*\n",
    "imgs/*\n",
    "learning/*\n",
    "*.pkl\n",
    "*.png\n",
    "*.ipynb\n",
    ".git\n",
    ".github\n",
    ".gitignore\n",
    ".DS_Store\n",
    "*.md\n",
    "*.tfrecord\n",
    ".ipynb_checkpoints/*\n",
    "*cpython-37.pyc\n",
    "**.cpython-310.pyc\n",
    "*/__pycache__/*\n",
    "src/ranking/*\n",
    "src/archive/*\n",
    "src/perarm_features/*\n",
    "04-pipelines/*\n",
    "03-ranking/*\n",
    "02-perarm-features-bandit/*\n",
    "src/pred/*\n",
    "src/serve/*\n",
    "Dockerfile_perarm_feats\n",
    "Dockerfile_perarm_feats_tpu\n",
    "Dockerfile_predict_mab_02\n",
    "vertex_env/*\n",
    "credentials.json\n",
    "05-online-learning/*\n",
    "src/cpr_dir/*\n",
    "src/local_model_dir/*\n",
    "00-data-prep-eda/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f9a8891-faa3-4659-a36e-521bf9f186e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requirements.txt\n",
      "Dockerfile_train_my_perarm_env\n",
      "local_rotors.csv\n",
      "accelerated-bandits-script.py\n",
      "pred_instances.json\n",
      "Dockerfile_predict_mab_02e\n",
      "cloudbuild.yaml\n",
      "src/instances.json\n",
      "src/networks/repeated_network_from_obs_spec.py\n",
      "src/environments/__init__.py\n",
      "src/environments/my_per_arm_py_env.py\n",
      "src/environments/movie_lens_simulator.py\n",
      "src/per_arm_rl/utils_config.py\n",
      "src/per_arm_rl/perarm_task.py\n",
      "src/per_arm_rl/data_config_1m.py\n",
      "src/per_arm_rl/__init__.py\n",
      "src/per_arm_rl/my_per_arm_py_env.py\n",
      "src/per_arm_rl/policy_util.py\n",
      "src/per_arm_rl/train_utils.py\n",
      "src/per_arm_rl/trainer_baseline.py\n",
      "src/per_arm_rl/data_utils.py\n",
      "src/per_arm_rl/data_config.py\n",
      "src/utils/WIP_movielens_history_gen.py\n",
      "src/utils/WIP_dataset_split.py\n",
      "src/utils/WIP_feature_config.py\n",
      "src/utils/__init__.py\n",
      "src/utils/WIP_feature_config_1m.py\n",
      "src/utils/WIP_group_wise_eval.py\n",
      "src/utils/WIP_generate_data.py\n",
      "src/utils/movielens_parsing.py\n",
      "src/utils/WIP_create_tfrecords.py\n",
      "src/utils/movielens_ds_utils.py\n",
      "src/utils/data_config.py\n",
      "src/utils/WIP_download_and_prep_movielens.py\n",
      "src/utils/WIP_movielens_eda_eval_utils.py\n",
      "01-online-bandit-simulation/result.json\n"
     ]
    }
   ],
   "source": [
    "# check eligble files\n",
    "!gcloud meta list-files-for-upload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b72f42a-d45e-44da-82c1-3d55ca6c6d7d",
   "metadata": {},
   "source": [
    "### Submit container to Cloud Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e3b8e87-3e4c-410c-a554-3be3b8ed3e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOCKERNAME_01 : Dockerfile_train_my_perarm_env\n",
      "IMAGE_URI_01  : gcr.io/hybrid-vertex/train-my-perarm-env-v2\n",
      "FILE_LOCATION : .\n",
      "MACHINE_TYPE  : e2-highcpu-32\n"
     ]
    }
   ],
   "source": [
    "# image definitions for training\n",
    "MACHINE_TYPE            ='e2-highcpu-32'\n",
    "FILE_LOCATION           = \".\" # './src'\n",
    "\n",
    "print(f\"DOCKERNAME_01 : {DOCKERNAME_01}\")\n",
    "print(f\"IMAGE_URI_01  : {IMAGE_URI_01}\")\n",
    "print(f\"FILE_LOCATION : {FILE_LOCATION}\")\n",
    "print(f\"MACHINE_TYPE  : {MACHINE_TYPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d11ac85-16f7-4050-8632-cb6e4337a65a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 36 file(s) totalling 332.8 KiB before compression.\n",
      "Uploading tarball of [.] to [gs://hybrid-vertex_cloudbuild/source/1709117629.922363-ea1475f271744c0da1a55bac3705e48e.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/hybrid-vertex/locations/global/builds/46c2d2a0-ef37-4463-90cc-9ad01c0de992].\n",
      "Logs are available at [ https://console.cloud.google.com/cloud-build/builds/46c2d2a0-ef37-4463-90cc-9ad01c0de992?project=934903580331 ].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"46c2d2a0-ef37-4463-90cc-9ad01c0de992\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://hybrid-vertex_cloudbuild/source/1709117629.922363-ea1475f271744c0da1a55bac3705e48e.tgz#1709117630570572\n",
      "Copying gs://hybrid-vertex_cloudbuild/source/1709117629.922363-ea1475f271744c0da1a55bac3705e48e.tgz#1709117630570572...\n",
      "/ [1 files][ 95.9 KiB/ 95.9 KiB]                                                \n",
      "Operation completed over 1 objects/95.9 KiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  388.6kB\n",
      "Step 1/14 : FROM gcr.io/deeplearning-platform-release/tf2-gpu.2-13.py310\n",
      "latest: Pulling from deeplearning-platform-release/tf2-gpu.2-13.py310\n",
      "aece8493d397: Pulling fs layer\n",
      "5e3b7ee77381: Pulling fs layer\n",
      "5bd037f007fd: Pulling fs layer\n",
      "4cda774ad2ec: Pulling fs layer\n",
      "775f22adee62: Pulling fs layer\n",
      "263fc748118f: Pulling fs layer\n",
      "4cda774ad2ec: Waiting\n",
      "16c36d0187d0: Pulling fs layer\n",
      "e7a56570655c: Pulling fs layer\n",
      "263fc748118f: Waiting\n",
      "507fc9045cba: Pulling fs layer\n",
      "23b7d8e07c16: Pulling fs layer\n",
      "922ac8fcb889: Pulling fs layer\n",
      "68075f2beca1: Pulling fs layer\n",
      "507fc9045cba: Waiting\n",
      "ab469be7031c: Pulling fs layer\n",
      "fa0dd808981f: Pulling fs layer\n",
      "e7a56570655c: Waiting\n",
      "68075f2beca1: Waiting\n",
      "ab469be7031c: Waiting\n",
      "fa0dd808981f: Waiting\n",
      "4f4fb700ef54: Pulling fs layer\n",
      "922ac8fcb889: Waiting\n",
      "2b9e183bdcba: Pulling fs layer\n",
      "5078dd28e1e7: Pulling fs layer\n",
      "1ad725b9d957: Pulling fs layer\n",
      "72b6e816ddc4: Pulling fs layer\n",
      "0da9da1b3052: Pulling fs layer\n",
      "79636e9c32ab: Pulling fs layer\n",
      "6ab459bc0640: Pulling fs layer\n",
      "69c998ec6fa8: Pulling fs layer\n",
      "368540bd0dc5: Pulling fs layer\n",
      "2b9e183bdcba: Waiting\n",
      "4f4fb700ef54: Waiting\n",
      "1ad725b9d957: Waiting\n",
      "5078dd28e1e7: Waiting\n",
      "8c78aeff5cd4: Pulling fs layer\n",
      "cbfff329d014: Pulling fs layer\n",
      "72b6e816ddc4: Waiting\n",
      "79636e9c32ab: Waiting\n",
      "1b0e0ae28123: Pulling fs layer\n",
      "0da9da1b3052: Waiting\n",
      "5b039d7cb54a: Pulling fs layer\n",
      "69c998ec6fa8: Waiting\n",
      "0ba89511f204: Pulling fs layer\n",
      "6ab459bc0640: Waiting\n",
      "aeb771cd05f7: Pulling fs layer\n",
      "368540bd0dc5: Waiting\n",
      "1da4ce9babe3: Pulling fs layer\n",
      "1b0e0ae28123: Waiting\n",
      "297d85c96186: Pulling fs layer\n",
      "8c78aeff5cd4: Waiting\n",
      "5b039d7cb54a: Waiting\n",
      "6783fd43effb: Pulling fs layer\n",
      "cbfff329d014: Waiting\n",
      "e82969b6ce7e: Pulling fs layer\n",
      "0ba89511f204: Waiting\n",
      "b21bb3731c3b: Pulling fs layer\n",
      "aeb771cd05f7: Waiting\n",
      "67639c61f271: Pulling fs layer\n",
      "1da4ce9babe3: Waiting\n",
      "87ba59c677fa: Pulling fs layer\n",
      "c5cf04f21c4e: Pulling fs layer\n",
      "6783fd43effb: Waiting\n",
      "e82969b6ce7e: Waiting\n",
      "8ccd1e0626f2: Pulling fs layer\n",
      "3e88c81a0def: Pulling fs layer\n",
      "b21bb3731c3b: Waiting\n",
      "b9ef80396cc7: Pulling fs layer\n",
      "945305c74278: Pulling fs layer\n",
      "67639c61f271: Waiting\n",
      "87ba59c677fa: Waiting\n",
      "c5cf04f21c4e: Waiting\n",
      "3e88c81a0def: Waiting\n",
      "945305c74278: Waiting\n",
      "5e3b7ee77381: Download complete\n",
      "4cda774ad2ec: Verifying Checksum\n",
      "4cda774ad2ec: Download complete\n",
      "aece8493d397: Verifying Checksum\n",
      "aece8493d397: Download complete\n",
      "5bd037f007fd: Verifying Checksum\n",
      "5bd037f007fd: Download complete\n",
      "775f22adee62: Download complete\n",
      "16c36d0187d0: Verifying Checksum\n",
      "16c36d0187d0: Download complete\n",
      "e7a56570655c: Verifying Checksum\n",
      "e7a56570655c: Download complete\n",
      "507fc9045cba: Verifying Checksum\n",
      "507fc9045cba: Download complete\n",
      "922ac8fcb889: Verifying Checksum\n",
      "922ac8fcb889: Download complete\n",
      "aece8493d397: Pull complete\n",
      "5e3b7ee77381: Pull complete\n",
      "5bd037f007fd: Pull complete\n",
      "4cda774ad2ec: Pull complete\n",
      "775f22adee62: Pull complete\n",
      "263fc748118f: Verifying Checksum\n",
      "263fc748118f: Download complete\n",
      "ab469be7031c: Verifying Checksum\n",
      "ab469be7031c: Download complete\n",
      "68075f2beca1: Verifying Checksum\n",
      "68075f2beca1: Download complete\n",
      "fa0dd808981f: Verifying Checksum\n",
      "fa0dd808981f: Download complete\n",
      "4f4fb700ef54: Download complete\n",
      "5078dd28e1e7: Verifying Checksum\n",
      "5078dd28e1e7: Download complete\n",
      "2b9e183bdcba: Verifying Checksum\n",
      "2b9e183bdcba: Download complete\n",
      "1ad725b9d957: Verifying Checksum\n",
      "1ad725b9d957: Download complete\n",
      "72b6e816ddc4: Verifying Checksum\n",
      "72b6e816ddc4: Download complete\n",
      "79636e9c32ab: Download complete\n",
      "0da9da1b3052: Verifying Checksum\n",
      "0da9da1b3052: Download complete\n",
      "6ab459bc0640: Download complete\n",
      "69c998ec6fa8: Download complete\n",
      "8c78aeff5cd4: Verifying Checksum\n",
      "8c78aeff5cd4: Download complete\n",
      "cbfff329d014: Verifying Checksum\n",
      "1b0e0ae28123: Download complete\n",
      "5b039d7cb54a: Verifying Checksum\n",
      "5b039d7cb54a: Download complete\n",
      "0ba89511f204: Verifying Checksum\n",
      "0ba89511f204: Download complete\n",
      "aeb771cd05f7: Verifying Checksum\n",
      "aeb771cd05f7: Download complete\n",
      "368540bd0dc5: Verifying Checksum\n",
      "368540bd0dc5: Download complete\n",
      "1da4ce9babe3: Verifying Checksum\n",
      "1da4ce9babe3: Download complete\n",
      "6783fd43effb: Verifying Checksum\n",
      "6783fd43effb: Download complete\n",
      "297d85c96186: Verifying Checksum\n",
      "297d85c96186: Download complete\n",
      "e82969b6ce7e: Verifying Checksum\n",
      "e82969b6ce7e: Download complete\n",
      "b21bb3731c3b: Verifying Checksum\n",
      "b21bb3731c3b: Download complete\n",
      "87ba59c677fa: Download complete\n",
      "23b7d8e07c16: Verifying Checksum\n",
      "23b7d8e07c16: Download complete\n",
      "8ccd1e0626f2: Verifying Checksum\n",
      "8ccd1e0626f2: Download complete\n",
      "b9ef80396cc7: Verifying Checksum\n",
      "b9ef80396cc7: Download complete\n",
      "945305c74278: Verifying Checksum\n",
      "945305c74278: Download complete\n",
      "67639c61f271: Verifying Checksum\n",
      "67639c61f271: Download complete\n",
      "263fc748118f: Pull complete\n",
      "16c36d0187d0: Pull complete\n",
      "e7a56570655c: Pull complete\n",
      "507fc9045cba: Pull complete\n",
      "c5cf04f21c4e: Verifying Checksum\n",
      "c5cf04f21c4e: Download complete\n",
      "23b7d8e07c16: Pull complete\n",
      "922ac8fcb889: Pull complete\n",
      "68075f2beca1: Pull complete\n",
      "ab469be7031c: Pull complete\n",
      "fa0dd808981f: Pull complete\n",
      "4f4fb700ef54: Pull complete\n",
      "2b9e183bdcba: Pull complete\n",
      "5078dd28e1e7: Pull complete\n",
      "1ad725b9d957: Pull complete\n",
      "72b6e816ddc4: Pull complete\n",
      "0da9da1b3052: Pull complete\n",
      "79636e9c32ab: Pull complete\n",
      "6ab459bc0640: Pull complete\n",
      "69c998ec6fa8: Pull complete\n",
      "368540bd0dc5: Pull complete\n",
      "8c78aeff5cd4: Pull complete\n",
      "cbfff329d014: Pull complete\n",
      "1b0e0ae28123: Pull complete\n",
      "5b039d7cb54a: Pull complete\n",
      "0ba89511f204: Pull complete\n",
      "aeb771cd05f7: Pull complete\n",
      "1da4ce9babe3: Pull complete\n",
      "297d85c96186: Pull complete\n",
      "6783fd43effb: Pull complete\n",
      "e82969b6ce7e: Pull complete\n",
      "b21bb3731c3b: Pull complete\n",
      "67639c61f271: Pull complete\n",
      "87ba59c677fa: Pull complete\n",
      "c5cf04f21c4e: Pull complete\n",
      "8ccd1e0626f2: Pull complete\n",
      "3e88c81a0def: Pull complete\n",
      "b9ef80396cc7: Pull complete\n",
      "945305c74278: Pull complete\n",
      "Digest: sha256:c6c5e9ab227a60791a3f9806c4aade5f6db82c2c33c3e5a569d934eab1a299e2\n",
      "Status: Downloaded newer image for gcr.io/deeplearning-platform-release/tf2-gpu.2-13.py310:latest\n",
      " ---> 2c21d0f99de2\n",
      "Step 2/14 : ENV APP_HOME /workspace\n",
      " ---> Running in 3b97d9e4b53e\n",
      "Removing intermediate container 3b97d9e4b53e\n",
      " ---> 923df7098584\n",
      "Step 3/14 : WORKDIR $APP_HOME\n",
      " ---> Running in cf73820bb8e0\n",
      "Removing intermediate container cf73820bb8e0\n",
      " ---> a2f28536b737\n",
      "Step 4/14 : COPY /requirements.txt $APP_HOME/requirements.txt\n",
      " ---> 84b0173f9fe5\n",
      "Step 5/14 : RUN pip install --upgrade pip\n",
      " ---> Running in 1d18252f0a49\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (24.0)\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 1d18252f0a49\n",
      " ---> f7798d90eeec\n",
      "Step 6/14 : RUN pip install --no-cache-dir -r $APP_HOME/requirements.txt\n",
      " ---> Running in c13420294f8f\n",
      "Requirement already satisfied: google-cloud-aiplatform==1.41.0 in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 1)) (1.41.0)\n",
      "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 3)) (2.14.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 4)) (1.23.5)\n",
      "Collecting tf-agents==0.17.0 (from -r /workspace/requirements.txt (line 9))\n",
      "  Downloading tf_agents-0.17.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: tensorflow-datasets in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 11)) (4.9.4)\n",
      "Requirement already satisfied: tensorflow-probability in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 13)) (0.23.0)\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 14)) (2.13.0)\n",
      "Requirement already satisfied: tensorboard-plugin-profile in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 15)) (2.15.1)\n",
      "Collecting tensorboard-plugin-wit (from -r /workspace/requirements.txt (line 16))\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\n",
      "Requirement already satisfied: tensorboard-data-server in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 17)) (0.7.2)\n",
      "Requirement already satisfied: tensorflow-io in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 18)) (0.32.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.41.0->-r /workspace/requirements.txt (line 1)) (1.34.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.41.0->-r /workspace/requirements.txt (line 1)) (1.23.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.41.0->-r /workspace/requirements.txt (line 1)) (3.20.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.41.0->-r /workspace/requirements.txt (line 1)) (23.2)\n",
      "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.41.0->-r /workspace/requirements.txt (line 1)) (3.17.2)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.41.0->-r /workspace/requirements.txt (line 1)) (1.12.1)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.41.0->-r /workspace/requirements.txt (line 1)) (2.0.2)\n",
      "Requirement already satisfied: absl-py>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from tf-agents==0.17.0->-r /workspace/requirements.txt (line 9)) (1.4.0)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in /opt/conda/lib/python3.10/site-packages (from tf-agents==0.17.0->-r /workspace/requirements.txt (line 9)) (2.2.1)\n",
      "Collecting gin-config>=0.4.0 (from tf-agents==0.17.0->-r /workspace/requirements.txt (line 9))\n",
      "  Downloading gin_config-0.5.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gym<=0.23.0,>=0.17.0 (from tf-agents==0.17.0->-r /workspace/requirements.txt (line 9))\n",
      "  Downloading gym-0.23.0.tar.gz (624 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 624.4/624.4 kB 68.2 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from tf-agents==0.17.0->-r /workspace/requirements.txt (line 9)) (10.2.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from tf-agents==0.17.0->-r /workspace/requirements.txt (line 9)) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.10/site-packages (from tf-agents==0.17.0->-r /workspace/requirements.txt (line 9)) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from tf-agents==0.17.0->-r /workspace/requirements.txt (line 9)) (4.5.0)\n",
      "Collecting pygame==2.1.3 (from tf-agents==0.17.0->-r /workspace/requirements.txt (line 9))\n",
      "  Downloading pygame-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
      "Collecting tensorflow-probability (from -r /workspace/requirements.txt (line 13))\n",
      "  Downloading tensorflow_probability-0.20.1-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=2.23.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->-r /workspace/requirements.txt (line 3)) (2.27.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->-r /workspace/requirements.txt (line 3)) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->-r /workspace/requirements.txt (line 3)) (2.7.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->-r /workspace/requirements.txt (line 3)) (2.31.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->-r /workspace/requirements.txt (line 3)) (1.5.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->-r /workspace/requirements.txt (line 11)) (8.1.7)\n",
      "Requirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->-r /workspace/requirements.txt (line 11)) (0.1.8)\n",
      "Requirement already satisfied: etils>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->-r /workspace/requirements.txt (line 11)) (1.6.0)\n",
      "Requirement already satisfied: promise in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->-r /workspace/requirements.txt (line 11)) (2.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->-r /workspace/requirements.txt (line 11)) (5.9.3)\n",
      "Requirement already satisfied: tensorflow-metadata in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->-r /workspace/requirements.txt (line 11)) (0.14.0)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->-r /workspace/requirements.txt (line 11)) (2.4.0)\n",
      "Requirement already satisfied: toml in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->-r /workspace/requirements.txt (line 11)) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->-r /workspace/requirements.txt (line 11)) (4.66.2)\n",
      "Requirement already satisfied: array-record>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->-r /workspace/requirements.txt (line 11)) (0.5.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from tensorflow-probability->-r /workspace/requirements.txt (line 13)) (5.1.1)\n",
      "Requirement already satisfied: gast>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow-probability->-r /workspace/requirements.txt (line 13)) (0.4.0)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard->-r /workspace/requirements.txt (line 14))\n",
      "  Downloading grpcio-1.62.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r /workspace/requirements.txt (line 14)) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r /workspace/requirements.txt (line 14)) (3.5.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r /workspace/requirements.txt (line 14)) (69.0.3)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r /workspace/requirements.txt (line 14)) (2.1.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r /workspace/requirements.txt (line 14)) (0.42.0)\n",
      "Requirement already satisfied: gviz-api>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard-plugin-profile->-r /workspace/requirements.txt (line 15)) (1.10.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.32.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-io->-r /workspace/requirements.txt (line 18)) (0.32.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->-r /workspace/requirements.txt (line 11)) (2024.2.0)\n",
      "Requirement already satisfied: importlib_resources in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->-r /workspace/requirements.txt (line 11)) (6.1.1)\n",
      "Requirement already satisfied: zipp in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->-r /workspace/requirements.txt (line 11)) (3.17.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.41.0->-r /workspace/requirements.txt (line 1)) (1.62.0)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.41.0->-r /workspace/requirements.txt (line 1)) (1.48.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage->-r /workspace/requirements.txt (line 3)) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage->-r /workspace/requirements.txt (line 3)) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage->-r /workspace/requirements.txt (line 3)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->-r /workspace/requirements.txt (line 14)) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.41.0->-r /workspace/requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform==1.41.0->-r /workspace/requirements.txt (line 1)) (0.12.7)\n",
      "Collecting gym-notices>=0.0.4 (from gym<=0.23.0,>=0.17.0->tf-agents==0.17.0->-r /workspace/requirements.txt (line 9))\n",
      "  Downloading gym_notices-0.0.8-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage->-r /workspace/requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage->-r /workspace/requirements.txt (line 3)) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage->-r /workspace/requirements.txt (line 3)) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage->-r /workspace/requirements.txt (line 3)) (2024.2.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.23.3->google-cloud-storage->-r /workspace/requirements.txt (line 3)) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->-r /workspace/requirements.txt (line 14)) (3.2.2)\n",
      "Downloading tf_agents-0.17.0-py3-none-any.whl (1.4 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 220.4 MB/s eta 0:00:00\n",
      "Downloading pygame-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.7 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.7/13.7 MB 236.2 MB/s eta 0:00:00\n",
      "Downloading tensorflow_probability-0.20.1-py2.py3-none-any.whl (6.9 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.9/6.9 MB 231.0 MB/s eta 0:00:00\n",
      "Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.3/781.3 kB 265.7 MB/s eta 0:00:00\n",
      "Downloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.3/61.3 kB 212.1 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.62.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.5/5.5 MB 235.6 MB/s eta 0:00:00\n",
      "Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (pyproject.toml): started\n",
      "  Building wheel for gym (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for gym: filename=gym-0.23.0-py3-none-any.whl size=697629 sha256=0f5e5377f5367031c5e241ab0cd15c84d9ffd2473308ad57e08b79bd16e1ac30\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-9als3ty5/wheels/3d/6f/b4/3991d4fae11d0ecb0754c11cc1b4e7745012850da4efaaf0b1\n",
      "Successfully built gym\n",
      "Installing collected packages: tensorboard-plugin-wit, gym-notices, gin-config, tensorflow-probability, pygame, gym, grpcio, tf-agents\n",
      "  Attempting uninstall: tensorflow-probability\n",
      "    Found existing installation: tensorflow-probability 0.23.0\n",
      "    Uninstalling tensorflow-probability-0.23.0:\n",
      "      Successfully uninstalled tensorflow-probability-0.23.0\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.48.1\n",
      "    Uninstalling grpcio-1.48.1:\n",
      "      Successfully uninstalled grpcio-1.48.1\n",
      "Successfully installed gin-config-0.5.0 grpcio-1.60.1 gym-0.23.0 gym-notices-0.0.8 pygame-2.1.3 tensorboard-plugin-wit-1.8.1 tensorflow-probability-0.20.1 tf-agents-0.17.0\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container c13420294f8f\n",
      " ---> 6b05fbdc2d5c\n",
      "Step 7/14 : RUN pip install cloudml-hypertune\n",
      " ---> Running in 61ad24abeaf5\n",
      "Collecting cloudml-hypertune\n",
      "  Downloading cloudml-hypertune-0.1.0.dev6.tar.gz (3.2 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: cloudml-hypertune\n",
      "  Building wheel for cloudml-hypertune (setup.py): started\n",
      "  Building wheel for cloudml-hypertune (setup.py): finished with status 'done'\n",
      "  Created wheel for cloudml-hypertune: filename=cloudml_hypertune-0.1.0.dev6-py2.py3-none-any.whl size=3973 sha256=d27a69c51df0d5f9dc101c3a45bb8dbdfd108d745ccd477dfc0e3aa7347793c2\n",
      "  Stored in directory: /root/.cache/pip/wheels/c6/2d/bb/9c72de7c488cd8e60172c4920c09e404c490020162205b64ba\n",
      "Successfully built cloudml-hypertune\n",
      "Installing collected packages: cloudml-hypertune\n",
      "Successfully installed cloudml-hypertune-0.1.0.dev6\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 61ad24abeaf5\n",
      " ---> cbbdf8eb5351\n",
      "Step 8/14 : RUN apt update && apt -y install nvtop\n",
      " ---> Running in babbce4cea01\n",
      "\u001b[91m\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
      "\n",
      "\u001b[0mGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
      "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1581 B]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy InRelease [270 kB]\n",
      "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [713 kB]\n",
      "Get:5 https://packages.cloud.google.com/apt gcsfuse-focal InRelease [1225 B]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
      "Get:8 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1874 kB]\n",
      "Get:9 https://packages.cloud.google.com/apt cloud-sdk InRelease [6361 B]\n",
      "Get:10 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [44.6 kB]\n",
      "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1505 kB]\n",
      "Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1073 kB]\n",
      "Get:13 https://packages.cloud.google.com/apt google-fast-socket InRelease [5015 B]\n",
      "Get:14 https://packages.cloud.google.com/apt gcsfuse-focal/main amd64 Packages [19.5 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 Packages [266 kB]\n",
      "Get:16 https://packages.cloud.google.com/apt gcsfuse-focal/main all Packages [750 B]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 Packages [1792 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu jammy/universe amd64 Packages [17.5 MB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu jammy/restricted amd64 Packages [164 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1912 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [50.4 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1786 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1345 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [50.4 kB]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [28.1 kB]\n",
      "Get:26 https://packages.cloud.google.com/apt cloud-sdk/main amd64 Packages [609 kB]\n",
      "Get:27 https://packages.cloud.google.com/apt google-fast-socket/main amd64 Packages [447 B]\n",
      "Fetched 31.3 MB in 2s (14.1 MB/s)\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "24 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "\u001b[91mW: https://packages.cloud.google.com/apt/dists/gcsfuse-focal/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
      "W: https://packages.cloud.google.com/apt/dists/google-fast-socket/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
      "\u001b[0m\u001b[91m\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
      "\u001b[0mReading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following NEW packages will be installed:\n",
      "  nvtop\n",
      "0 upgraded, 1 newly installed, 0 to remove and 24 not upgraded.\n",
      "Need to get 43.9 kB of archives.\n",
      "After this operation, 106 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 nvtop amd64 1.2.2-1 [43.9 kB]\n",
      "\u001b[91mdebconf: unable to initialize frontend: Dialog\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\n",
      "debconf: falling back to frontend: Readline\n",
      "\u001b[0m\u001b[91mdebconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "\u001b[0m\u001b[91mdpkg-preconfigure: unable to re-open stdin: \n",
      "\u001b[0mFetched 43.9 kB in 0s (413 kB/s)\n",
      "Selecting previously unselected package nvtop.\n",
      "(Reading database ... 96151 files and directories currently installed.)\n",
      "Preparing to unpack .../nvtop_1.2.2-1_amd64.deb ...\n",
      "Unpacking nvtop (1.2.2-1) ...\n",
      "Setting up nvtop (1.2.2-1) ...\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "Removing intermediate container babbce4cea01\n",
      " ---> 53d6c60f1de0\n",
      "Step 9/14 : COPY src/per_arm_rl $APP_HOME/src/per_arm_rl\n",
      " ---> 273a7b709309\n",
      "Step 10/14 : COPY src/environments $APP_HOME/src/environments\n",
      " ---> a4e5bb1bfbec\n",
      "Step 11/14 : COPY src/utils $APP_HOME/src/utils\n",
      " ---> f4eb41ebb547\n",
      "Step 12/14 : RUN export PYTHONPATH=${PYTHONPATH}:${APP_HOME}/\n",
      " ---> Running in 280e6e1eda8e\n",
      "Removing intermediate container 280e6e1eda8e\n",
      " ---> b826b740cf9a\n",
      "Step 13/14 : RUN pip freeze | grep wrapt\n",
      " ---> Running in 2e484897e78b\n",
      "wrapt==1.16.0\n",
      "Removing intermediate container 2e484897e78b\n",
      " ---> dd7958ade6fc\n",
      "Step 14/14 : ENTRYPOINT [\"python3\", \"-m\", \"src.per_arm_rl.perarm_task\"]\n",
      " ---> Running in 698279c3c47f\n",
      "Removing intermediate container 698279c3c47f\n",
      " ---> 6a00f186e602\n",
      "Successfully built 6a00f186e602\n",
      "Successfully tagged gcr.io/hybrid-vertex/train-my-perarm-env-v2:latest\n",
      "PUSH\n",
      "Pushing gcr.io/hybrid-vertex/train-my-perarm-env-v2\n",
      "The push refers to repository [gcr.io/hybrid-vertex/train-my-perarm-env-v2]\n",
      "c37b02d3c8d6: Preparing\n",
      "bb7dc4719312: Preparing\n",
      "94e46b8b7273: Preparing\n",
      "89a1ff20e3be: Preparing\n",
      "f06e818dd294: Preparing\n",
      "34419cd66d4d: Preparing\n",
      "4d8577dbb048: Preparing\n",
      "37b5f02c170e: Preparing\n",
      "28adf1d5c034: Preparing\n",
      "b5ca19e26bdc: Preparing\n",
      "8030612bdde9: Preparing\n",
      "13a5115c9f37: Preparing\n",
      "661724fb44c4: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "ee090d856acb: Preparing\n",
      "ef7554269085: Preparing\n",
      "58e06bda5ab7: Preparing\n",
      "32a88c0c4833: Preparing\n",
      "c1abfb4fc86a: Preparing\n",
      "dc482a473419: Preparing\n",
      "491ae2ef64ce: Preparing\n",
      "f87c82d6bfb3: Preparing\n",
      "2154cbb38dd6: Preparing\n",
      "5a8bf20ed53d: Preparing\n",
      "a130c97ec1f6: Preparing\n",
      "a8067568c877: Preparing\n",
      "bcbe227c5bb0: Preparing\n",
      "34419cd66d4d: Waiting\n",
      "b607a0f29009: Preparing\n",
      "4d8577dbb048: Waiting\n",
      "7a2a930f18c2: Preparing\n",
      "37b5f02c170e: Waiting\n",
      "3b4c36edcf06: Preparing\n",
      "28adf1d5c034: Waiting\n",
      "b5ca19e26bdc: Waiting\n",
      "9feca8d2c9fe: Preparing\n",
      "8030612bdde9: Waiting\n",
      "d39adfab0675: Preparing\n",
      "13a5115c9f37: Waiting\n",
      "d0e4a1bc308f: Preparing\n",
      "661724fb44c4: Waiting\n",
      "f87c82d6bfb3: Waiting\n",
      "37444e97c0d5: Preparing\n",
      "5f70bf18a086: Waiting\n",
      "2154cbb38dd6: Waiting\n",
      "e73ebd78f459: Preparing\n",
      "ee090d856acb: Waiting\n",
      "f8ff76844128: Preparing\n",
      "5a8bf20ed53d: Waiting\n",
      "ef7554269085: Waiting\n",
      "b5d339a7988a: Preparing\n",
      "a130c97ec1f6: Waiting\n",
      "58e06bda5ab7: Waiting\n",
      "5f70bf18a086: Preparing\n",
      "9c17bf546789: Preparing\n",
      "a235ef32c2d6: Preparing\n",
      "32a88c0c4833: Waiting\n",
      "383e6312d4f9: Preparing\n",
      "c1abfb4fc86a: Waiting\n",
      "64758552f6fa: Preparing\n",
      "3b4c36edcf06: Waiting\n",
      "dc482a473419: Waiting\n",
      "a8067568c877: Waiting\n",
      "9feca8d2c9fe: Waiting\n",
      "bcbe227c5bb0: Waiting\n",
      "d39adfab0675: Waiting\n",
      "491ae2ef64ce: Waiting\n",
      "d0e4a1bc308f: Waiting\n",
      "b607a0f29009: Waiting\n",
      "23d753990c8d: Preparing\n",
      "7a2a930f18c2: Waiting\n",
      "37444e97c0d5: Waiting\n",
      "345cfa465206: Preparing\n",
      "f8ff76844128: Waiting\n",
      "e73ebd78f459: Waiting\n",
      "dcb0f55f81ad: Preparing\n",
      "b5d339a7988a: Waiting\n",
      "399d155a03b0: Preparing\n",
      "23d753990c8d: Waiting\n",
      "a235ef32c2d6: Waiting\n",
      "bc352a27a0e4: Preparing\n",
      "64758552f6fa: Waiting\n",
      "383e6312d4f9: Waiting\n",
      "498bbcc60d01: Preparing\n",
      "345cfa465206: Waiting\n",
      "399d155a03b0: Waiting\n",
      "c0e21dcee623: Preparing\n",
      "d6b19a46b795: Preparing\n",
      "498bbcc60d01: Waiting\n",
      "dcb0f55f81ad: Waiting\n",
      "e6c05e83c163: Preparing\n",
      "256d88da4185: Preparing\n",
      "d6b19a46b795: Waiting\n",
      "256d88da4185: Waiting\n",
      "e6c05e83c163: Waiting\n",
      "94e46b8b7273: Pushed\n",
      "f06e818dd294: Pushed\n",
      "c37b02d3c8d6: Pushed\n",
      "bb7dc4719312: Pushed\n",
      "28adf1d5c034: Pushed\n",
      "4d8577dbb048: Pushed\n",
      "37b5f02c170e: Pushed\n",
      "b5ca19e26bdc: Layer already exists\n",
      "8030612bdde9: Layer already exists\n",
      "13a5115c9f37: Layer already exists\n",
      "5f70bf18a086: Layer already exists\n",
      "661724fb44c4: Layer already exists\n",
      "ee090d856acb: Layer already exists\n",
      "ef7554269085: Layer already exists\n",
      "58e06bda5ab7: Layer already exists\n",
      "32a88c0c4833: Layer already exists\n",
      "c1abfb4fc86a: Layer already exists\n",
      "dc482a473419: Layer already exists\n",
      "f87c82d6bfb3: Layer already exists\n",
      "5a8bf20ed53d: Layer already exists\n",
      "491ae2ef64ce: Layer already exists\n",
      "2154cbb38dd6: Layer already exists\n",
      "a130c97ec1f6: Layer already exists\n",
      "a8067568c877: Layer already exists\n",
      "bcbe227c5bb0: Layer already exists\n",
      "b607a0f29009: Layer already exists\n",
      "7a2a930f18c2: Layer already exists\n",
      "3b4c36edcf06: Layer already exists\n",
      "d39adfab0675: Layer already exists\n",
      "9feca8d2c9fe: Layer already exists\n",
      "d0e4a1bc308f: Layer already exists\n",
      "e73ebd78f459: Layer already exists\n",
      "37444e97c0d5: Layer already exists\n",
      "f8ff76844128: Layer already exists\n",
      "b5d339a7988a: Layer already exists\n",
      "a235ef32c2d6: Layer already exists\n",
      "9c17bf546789: Layer already exists\n",
      "383e6312d4f9: Layer already exists\n",
      "23d753990c8d: Layer already exists\n",
      "64758552f6fa: Layer already exists\n",
      "345cfa465206: Layer already exists\n",
      "dcb0f55f81ad: Layer already exists\n",
      "399d155a03b0: Layer already exists\n",
      "89a1ff20e3be: Pushed\n",
      "bc352a27a0e4: Layer already exists\n",
      "c0e21dcee623: Layer already exists\n",
      "498bbcc60d01: Layer already exists\n",
      "d6b19a46b795: Layer already exists\n",
      "e6c05e83c163: Layer already exists\n",
      "256d88da4185: Layer already exists\n",
      "34419cd66d4d: Pushed\n",
      "latest: digest: sha256:0b2c6d6009edcde6845496a82cf2b2cf5a6fd3e9ceaef8357016a6ac75d516c4 size: 11215\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                       IMAGES                                                 STATUS\n",
      "46c2d2a0-ef37-4463-90cc-9ad01c0de992  2024-02-28T10:53:50+00:00  4M41S     gs://hybrid-vertex_cloudbuild/source/1709117629.922363-ea1475f271744c0da1a55bac3705e48e.tgz  gcr.io/hybrid-vertex/train-my-perarm-env-v2 (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "! gcloud builds submit --config ./cloudbuild.yaml \\\n",
    "    --substitutions _DOCKERNAME=$DOCKERNAME_01,_IMAGE_URI=$IMAGE_URI_01,_FILE_LOCATION=$FILE_LOCATION \\\n",
    "    --timeout=2h \\\n",
    "    --machine-type=$MACHINE_TYPE \\\n",
    "    --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb4d09e-169d-48ab-9399-d9acf7779d0e",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629eb246-f2fc-48a0-8478-4f9c99dddd0b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## (Optional) Build Image Locally\n",
    "\n",
    "Building images with Cloud Build is best practices\n",
    "* images are centrally stored and better managed for robust CI/CD\n",
    "* building images on local workbench instance can alter notebook image config (base image for notebooks vs train images are different)\n",
    "* if building locally, consider using virutal environments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5278eb39-1dbb-48fd-b872-9cd55643a1ed",
   "metadata": {},
   "source": [
    "Provide a name for your dockerfile and make sure you are authenticated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53874306-777f-459f-9250-4a59dbc283a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gcloud auth configure-docker $REGION-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25faef9c-cb5e-425d-9ee6-7ae8003a95af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy these commands into terminal:\n",
      "\n",
      "virtualenv vertex_env\n",
      "source vertex_env/bin/activate\n"
     ]
    }
   ],
   "source": [
    "print(\"copy these commands into terminal:\\n\")\n",
    "print(f\"virtualenv vertex_env\")\n",
    "print(f\"source vertex_env/bin/activate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "027de7fe-dd2a-4be5-80c4-877f7abe4753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy these commands into terminal:\n",
      "\n",
      "export REMOTE_IMAGE_NAME=us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/local_docker_tfa\n",
      "export DOCKERNAME=Dockerfile_train_my_perarm_env\n",
      "docker build -t $REMOTE_IMAGE_NAME -f ./$DOCKERNAME .\n"
     ]
    }
   ],
   "source": [
    "# # set variables if running in terminal\n",
    "print(\"copy these commands into terminal:\\n\")\n",
    "print(f\"export REMOTE_IMAGE_NAME={REMOTE_IMAGE_NAME}\")\n",
    "print(f\"export DOCKERNAME={DOCKERNAME_01}\")\n",
    "print(f\"docker build -t $REMOTE_IMAGE_NAME -f ./$DOCKERNAME .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a82cbe6-0ed5-478f-a38f-e6dedc114e2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !docker build -t $REMOTE_IMAGE_NAME -f $DOCKERNAME ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6110439-f66a-4d6b-8105-17a08ce9b8da",
   "metadata": {},
   "source": [
    "### Push container to Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54a714cf-053c-4f14-b375-2a42ae2092f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy this command into terminal:\n",
      "\n",
      "docker push $REMOTE_IMAGE_NAME\n"
     ]
    }
   ],
   "source": [
    "# ### push the container to registry\n",
    "\n",
    "print(\"copy this command into terminal:\\n\")\n",
    "print(f\"docker push $REMOTE_IMAGE_NAME\")\n",
    "\n",
    "# !docker push $REMOTE_IMAGE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bc85f6-a86e-48f2-a040-89f35376d57c",
   "metadata": {},
   "source": [
    "### GPU profiling\n",
    "\n",
    "> enter these commands in the Vertex interactive terminal:\n",
    "\n",
    "```bash\n",
    "sudo apt update\n",
    "sudo apt -y install nvtop\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18df8169-e4ed-45fb-9279-85e966bc6f3e",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
