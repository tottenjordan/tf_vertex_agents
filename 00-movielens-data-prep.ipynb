{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bef58d66-b85e-49ca-baa1-eae9d3af08b4",
   "metadata": {},
   "source": [
    "# Preparing off-policy training data for RL\n",
    "\n",
    "> \"Off-policy\" refers to the situation where for a data record, given its observation, the current policy in training might not choose the same action as the one in said data record\n",
    "\n",
    "**References**\n",
    "* [internal code example](https://source.corp.google.com/piper///depot/google3/commerce/delivery/recommendation/shop_rl/python/topk_off_policy_reinforce/dataset_analysis.ipynb)\n",
    "* following generator, ingester code from [JT-example](https://github.com/tottenjordan/tf_vertex_agents/blob/main/src/generator/generator_component.py)\n",
    "* not correct, but different [BanditDev](https://github.com/alex-seto/RecipeBandit/blob/7ff5c0d8930aaf60f576222be42f5cd3181a1e49/scrap/BanditDev.ipynb)\n",
    "* (blog) [RL recommender using Tf-Agent](https://medium.com/@yuchengtsai84/reinforcement-learning-based-recommender-systems-using-tf-agent-and-movielens-dataset-ebbf40b3a1a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86c8c72b-6472-47b5-836d-c924c75859a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5be08889-6644-46ac-bd9b-1ce6c2d533d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "from pprint import pprint\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "851a6ded-cf88-47b6-a31a-b0cfe28b6951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \n",
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61009c45-dbf3-494c-a67f-72d2b9aa9c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35ee9650-ba2e-4737-b087-a663244bac66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93326b48-4526-47c7-a32e-2ca873655f2e",
   "metadata": {},
   "source": [
    "### set vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bb8ac31-9998-447f-94ec-43a8c3ae30ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ID       = hybrid-vertex\n",
      "PROJECT_NUM      = 934903580331\n",
      "VPC_NETWORK_NAME = ucaip-haystack-vpc-network\n",
      "LOCATION         = us-central1\n",
      "REGION           = us-central1\n",
      "BQ_LOCATION      = US\n"
     ]
    }
   ],
   "source": [
    "PREFIX = 'mabv1'\n",
    "\n",
    "# creds, PROJECT_ID = google.auth.default()\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "PROJECT_NUM              = !gcloud projects describe $PROJECT_ID --format=\"value(projectNumber)\"\n",
    "PROJECT_NUM              = PROJECT_NUM[0]\n",
    "\n",
    "VERTEX_SA                = f'{PROJECT_NUM}-compute@developer.gserviceaccount.com'\n",
    "\n",
    "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
    "\n",
    "# locations / regions for cloud resources\n",
    "LOCATION                 = 'us-central1'        \n",
    "REGION                   = LOCATION\n",
    "BQ_LOCATION              = 'US'\n",
    "\n",
    "print(f\"PROJECT_ID       = {PROJECT_ID}\")\n",
    "print(f\"PROJECT_NUM      = {PROJECT_NUM}\")\n",
    "print(f\"VPC_NETWORK_NAME = {VPC_NETWORK_NAME}\")\n",
    "print(f\"LOCATION         = {LOCATION}\")\n",
    "print(f\"REGION           = {REGION}\")\n",
    "print(f\"BQ_LOCATION      = {BQ_LOCATION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74f32527-654e-4060-9e71-d40f8fd5e011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUCKET_NAME       : mabv1-hybrid-vertex-bucket\n",
      "BUCKET_URI        : gs://mabv1-hybrid-vertex-bucket\n",
      "DATA_GCS_PREFIX   : data\n",
      "DATA_PATH         : gs://mabv1-hybrid-vertex-bucket/data\n",
      "VPC_NETWORK_FULL  : projects/934903580331/global/networks/ucaip-haystack-vpc-network\n",
      "MY_BQ_DATASET     : mabv1_hybrid_vertex_bucket\n"
     ]
    }
   ],
   "source": [
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "# Location of the MovieLens 100K dataset's \"u.data\" file.\n",
    "DATA_GCS_PREFIX          = \"data\"\n",
    "DATA_PATH                = f\"{BUCKET_URI}/{DATA_GCS_PREFIX}\"\n",
    "\n",
    "VPC_NETWORK_FULL         = f\"projects/{PROJECT_NUM}/global/networks/{VPC_NETWORK_NAME}\"\n",
    "\n",
    "MY_BQ_DATASET            = BUCKET_NAME.lower().replace(\"-\",\"_\")\n",
    "\n",
    "print(f\"BUCKET_NAME       : {BUCKET_NAME}\")\n",
    "print(f\"BUCKET_URI        : {BUCKET_URI}\")\n",
    "print(f\"DATA_GCS_PREFIX   : {DATA_GCS_PREFIX}\")\n",
    "print(f\"DATA_PATH         : {DATA_PATH}\")\n",
    "print(f\"VPC_NETWORK_FULL  : {VPC_NETWORK_FULL}\")\n",
    "print(f\"MY_BQ_DATASET     : {MY_BQ_DATASET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb1cb961-0cc4-435c-9b7f-5934a2707f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://mabv1-hybrid-vertex-bucket/...\n",
      "ServiceException: 409 A Cloud Storage bucket named 'mabv1-hybrid-vertex-bucket' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n"
     ]
    }
   ],
   "source": [
    "# create bucket\n",
    "! gsutil mb -l $REGION $BUCKET_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60ac9153-79b0-473f-98bf-a59237463ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "# # bigquery client\n",
    "# bqclient = bigquery.Client(\n",
    "#     project=PROJECT_ID,\n",
    "#     # location=LOCATION\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adcc8b0-051b-43b5-8422-7ed9ee48fa4b",
   "metadata": {},
   "source": [
    "## Write TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "056703c7-266c-48ae-9a84-6adea7d51753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([45.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'357'], dtype=object)>,\n",
      " 'movie_title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"One Flew Over the Cuckoo's Nest (1975)\"], dtype=object)>,\n",
      " 'raw_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([46.], dtype=float32)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([879024327])>,\n",
      " 'user_gender': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'138'], dtype=object)>,\n",
      " 'user_occupation_label': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([4])>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'doctor'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>,\n",
      " 'user_zip_code': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'53211'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "\n",
    "for x in ratings.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "31b21f3a-0255-43f8-b11c-a88b87bdf03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "-------\n",
      "value: b'healthcare'\n",
      "type: value: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "-------\n",
      "value_n: [b'healthcare']\n",
      "type: value_n: <class 'numpy.ndarray'>\n",
      "-------\n",
      "value_tl: b'healthcare'\n",
      "type: value_tl: <class 'bytes'>\n",
      "-------\n",
      "value_tl: <generator object <genexpr> at 0x7f1c84623920>\n",
      "type: value_tl: <generator object <genexpr> at 0x7f1c84623d10>\n"
     ]
    }
   ],
   "source": [
    "for x in ratings.batch(1).skip(3).take(1):\n",
    "    # value = x['movie_genres']\n",
    "    # value = x['user_id']\n",
    "    value = x['user_occupation_text']\n",
    "    # value = tf.io.serialize_tensor(value)\n",
    "    print(f\"type: {type(value)}\")\n",
    "    # print(f\"type: {type(value)}\")\n",
    "    # print(f\"type: {type(v) for v in value}\")\n",
    "    print(\"-------\")\n",
    "    print(f\"value: {value[0]}\")\n",
    "    print(f\"type: value: {type(value[0])}\")\n",
    "    print(\"-------\")\n",
    "    value_n = value.numpy() # [0]\n",
    "    print(f\"value_n: {value_n}\")\n",
    "    print(f\"type: value_n: {type(value_n)}\")\n",
    "    print(\"-------\")\n",
    "    value_tl = value.numpy().tolist() # [0]\n",
    "    print(f\"value_tl: {value_tl[0]}\")\n",
    "    print(f\"type: value_tl: {type(value_tl[0])}\")\n",
    "    print(\"-------\")\n",
    "    value_tlv = value.numpy().tolist() # [0]\n",
    "    print(f\"value_tl: {v for value in value_tl[0]}\")\n",
    "    print(f\"type: value_tl: {type(v) for v in value_tl[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "b334b002-0976-4eb2-8563-18080e3466f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'administrator', b'artist', b'doctor', b'educator', b'engineer',\n",
       "       b'entertainment', b'executive', b'healthcare', b'homemaker',\n",
       "       b'lawyer', b'librarian', b'marketing', b'none', b'other',\n",
       "       b'programmer', b'retired', b'salesman', b'scientist', b'student',\n",
       "       b'technician', b'writer'], dtype='|S13')"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_user_occs = ratings.map(lambda x: x[\"user_occupation_text\"])\n",
    "unique_occ_ids = np.unique([x.numpy() for x in unique_user_occs])\n",
    "unique_occ_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e6187fd1-eaf6-4410-b2c4-30f35f628afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <class 'tensorflow.python.framework.ops.EagerTensor'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad05d51-44be-4e80-a948-4969476ea0bc",
   "metadata": {},
   "source": [
    "### Build Examples\n",
    "\n",
    "> **TODO** - consolidate with `data_utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "f92b755c-d62c-423e-b65c-c9918fcf767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"\n",
    "    Get byte features\n",
    "    \"\"\"\n",
    "    # value = tf.io.serialize_tensor(value)\n",
    "    # value = value.numpy()\n",
    "    if type(value) == list:\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "    else:\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[i.numpy() for i in [value]]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"\n",
    "    Get int64 feature\n",
    "    \"\"\"\n",
    "    if type(value) == list:\n",
    "        # return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=[int(v) for v in value]))\n",
    "    else:\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "    \n",
    "def _int64_list_feature(value):\n",
    "    \"\"\"\n",
    "    Get int64 list feature\n",
    "    \"\"\"\n",
    "    value = value.numpy().tolist()[0]\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "    # return tf.train.Feature(int64_list=tf.train.Int64List(value=[int(v) for v in value]))\n",
    "\n",
    "def _string_array(value, shape=1):\n",
    "    \"\"\"\n",
    "    Returns a bytes_list from a string / byte.\n",
    "    \"\"\"\n",
    "    value = value.numpy()[0] # .tolist()[0]\n",
    "    if type(value) == list:\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(v).encode('utf-8') for v in value]))\n",
    "        # return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(v) for v in value]))\n",
    "    else:\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value).encode('utf-8')]))\n",
    "        # return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))\n",
    "\n",
    "def _float_feature(value, shape=1):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    if type(value) == list:\n",
    "        return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "    else:\n",
    "        return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "a1dd70f5-9ac4-43cf-b964-b45187d76db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_example(data) -> tf.train.Example:\n",
    "    \"\"\"\n",
    "    Returns: A `tf.train.Example` object holding the same data as `data_row`.\n",
    "    \"\"\"\n",
    "    feature = {\n",
    "        # user - global context features \n",
    "        \"user_id\": _bytes_feature(data['user_id'])\n",
    "        , \"user_rating\": _float_feature(data['user_rating'])\n",
    "        , \"bucketized_user_age\": _float_feature(data['bucketized_user_age'])\n",
    "        , \"user_occupation_text\": _bytes_feature(data['user_occupation_text'])\n",
    "        # , \"user_occupation_label\": _int64_feature(data['user_occupation_label'])\n",
    "        # , \"user_zip_code\": _string_array(data['user_zip_code'])\n",
    "        # , \"user_gender\": BOOL_TODO(data['user_gender'])\n",
    "        , \"timestamp\": _int64_feature(data['timestamp'])\n",
    "        \n",
    "        # movie - per arm features\n",
    "        , \"movie_id\": _bytes_feature(data['movie_id'])\n",
    "        # , \"movie_title\": _string_array(data['movie_title'])\n",
    "        , \"movie_genres\": _int64_list_feature(data['movie_genres'])\n",
    "    }\n",
    "    example_proto = tf.train.Example(\n",
    "        features=tf.train.Features(feature=feature))\n",
    "    return example_proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "922898ce-22ed-47b6-ae91-599a5f7b4943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tfrecords(tfrecord_file, dataset):\n",
    "    with tf.io.TFRecordWriter(tfrecord_file) as writer:\n",
    "        for data_row in dataset:\n",
    "            example = build_example(data_row)\n",
    "            writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "0ab3e621-6109-4877-85a1-20eaba3e4e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_RECORD_FILE = \"ml-ratings-100k-train.tfrecord\"\n",
    "\n",
    "write_tfrecords(TF_RECORD_FILE, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "64969021-de5f-4fd8-a51d-489242540139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./ml-ratings-100k-train.tfrecord [Content-Type=application/octet-stream]...\n",
      "/ [1 files][ 19.4 MiB/ 19.4 MiB]                                                \n",
      "Operation completed over 1 objects/19.4 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "LOCAL_TF_RECORD = \"./ml-ratings-100k-train.tfrecord\"\n",
    "\n",
    "! gsutil cp $LOCAL_TF_RECORD $DATA_PATH/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "f74b2576-800f-41d3-85a2-2be37a410390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mabv1-hybrid-vertex-bucket/data/ml-ratings-100k-train.tfrecord\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls $DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a150e2-29c1-42e5-b513-85f6b27bafd6",
   "metadata": {},
   "source": [
    "### validate TF Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "afdbc480-8977-4caf-b08f-29a665ef3f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://mabv1-hybrid-vertex-bucket/data/ml-ratings-100k-train.tfrecord']"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "7bde3b62-cf77-4750-ab69-47638cbc7184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "a1cb0935-4de2-4812-a983-414ca17755cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec={'bucketized_user_age': TensorSpec(shape=(), dtype=tf.float32, name=None), 'movie_genres': TensorSpec(shape=(1,), dtype=tf.int64, name=None), 'movie_id': TensorSpec(shape=(), dtype=tf.string, name=None), 'timestamp': TensorSpec(shape=(), dtype=tf.int64, name=None), 'user_id': TensorSpec(shape=(), dtype=tf.string, name=None), 'user_occupation_text': TensorSpec(shape=(), dtype=tf.string, name=None), 'user_rating': TensorSpec(shape=(), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - defined later -fix\n",
    "from src.per_arm_rl import data_utils_v1 as data_utils\n",
    "from src.per_arm_rl import data_config\n",
    "\n",
    "train_dataset = train_dataset.map(data_utils.parse_tfrecord)\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "63c44871-63c2-4e69-b5ba-8df3084976bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([45.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'357'], dtype=object)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([879024327])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'138'], dtype=object)>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'doctor'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>}\n",
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([25.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[4]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'709'], dtype=object)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([875654590])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'92'], dtype=object)>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'entertainment'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "for x in train_dataset.batch(1).take(2):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add6d7f1-aa8a-4459-8d7a-e8f6363edede",
   "metadata": {},
   "source": [
    "## Dataset Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73e451f-865d-4614-a77d-a1ef1dce0714",
   "metadata": {},
   "source": [
    "### unique IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "8b468833-642b-436f-8ddb-692f9221e38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(unique_movie_ids) : 1682\n",
      "unique_movie_ids      : [b'1' b'10']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique movies and users\n",
    "# unique_movie_ids = ratings.map(lambda x: x[\"movie_id\"])\n",
    "unique_movie_ids = train_dataset.map(lambda x: x[\"movie_id\"])\n",
    "\n",
    "unique_movie_ids = np.unique([x.numpy() for x in unique_movie_ids])\n",
    "\n",
    "MOVIELENS_NUM_MOVIES = len(unique_movie_ids)\n",
    "\n",
    "print(f\"len(unique_movie_ids) : {len(unique_movie_ids)}\")\n",
    "print(f\"unique_movie_ids      : {unique_movie_ids[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "889c41d2-c4df-496a-8424-bba6bb3d0aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(unique_occ_ids) : 21\n",
      "unique_occ_ids      : [b'administrator' b'artist']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique movies and users\n",
    "# unique_movie_ids = ratings.map(lambda x: x[\"movie_id\"])\n",
    "unique_occ_ids = train_dataset.map(lambda x: x[\"user_occupation_text\"])\n",
    "\n",
    "unique_occ_ids = np.unique([x.numpy() for x in unique_occ_ids])\n",
    "\n",
    "NUM_OCCS = len(unique_occ_ids)\n",
    "\n",
    "print(f\"len(unique_occ_ids) : {len(unique_occ_ids)}\")\n",
    "print(f\"unique_occ_ids      : {unique_occ_ids[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "089c1bf7-f5ac-4343-8dae-a8f1c908a9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(unique_user_ids) : 943\n",
      "unique_user_ids      : [b'1' b'10']\n"
     ]
    }
   ],
   "source": [
    "# unique_user_ids = ratings.map(lambda x: x[\"user_id\"])\n",
    "unique_user_ids = train_dataset.map(lambda x: x[\"user_id\"])\n",
    "\n",
    "unique_user_ids = np.unique([x.numpy() for x in unique_user_ids])\n",
    "\n",
    "MOVIELENS_NUM_USERS = len(unique_user_ids)\n",
    "\n",
    "print(f\"len(unique_user_ids) : {len(unique_user_ids)}\")\n",
    "print(f\"unique_user_ids      : {unique_user_ids[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "fa73a8f9-4608-4379-afa0-2d48c0a77408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(unique_user_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e507fd5b-c398-41ea-8b5c-7a6b7e4886d2",
   "metadata": {},
   "source": [
    "### lookup dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "f1093810-fe2b-43e4-a481-c879616c4f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def get_dictionary_lookup_by_tf_data_key(key: str) -> Dict:\n",
    "    # tensor = ratings.map(lambda x: x[key])\n",
    "    tensor = train_dataset.map(lambda x: x[key])\n",
    "    unique_elems = set()\n",
    "    for x in tensor:\n",
    "        val = x.numpy()\n",
    "        if type(val) is np.ndarray: # if multi dimesnional only grab first one\n",
    "            val = val[0]\n",
    "        unique_elems.add(val)\n",
    "    \n",
    "    #return a dictionary of keys by integer values for the feature space\n",
    "    return {val: i for i, val in enumerate(unique_elems)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "b17cf48c-e0e2-4d65-9b4b-25d7c50d0502",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_AGE_LOOKUP = get_dictionary_lookup_by_tf_data_key('bucketized_user_age')\n",
    "USER_AGE_DIM = len(USER_AGE_LOOKUP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "905e1b2b-a800-47cd-bd29-dcc364f94aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: 0, 35.0: 1, 45.0: 2, 18.0: 3, 50.0: 4, 56.0: 5, 25.0: 6}"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USER_AGE_LOOKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "188f1142-c814-4f6f-9ae6-9dddeaa1005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_OCC_LOOKUP = get_dictionary_lookup_by_tf_data_key('user_occupation_text')\n",
    "USER_OCC_DIM = len(USER_OCC_LOOKUP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "646339f1-e47f-4e01-a9e2-26a205bce810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'artist': 0,\n",
       " b'student': 1,\n",
       " b'other': 2,\n",
       " b'librarian': 3,\n",
       " b'doctor': 4,\n",
       " b'engineer': 5,\n",
       " b'technician': 6,\n",
       " b'programmer': 7,\n",
       " b'scientist': 8,\n",
       " b'entertainment': 9,\n",
       " b'healthcare': 10,\n",
       " b'none': 11,\n",
       " b'educator': 12,\n",
       " b'administrator': 13,\n",
       " b'salesman': 14,\n",
       " b'retired': 15,\n",
       " b'marketing': 16,\n",
       " b'executive': 17,\n",
       " b'writer': 18,\n",
       " b'lawyer': 19,\n",
       " b'homemaker': 20}"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USER_OCC_LOOKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "3b6aafa8-8550-417a-8a67-ff602d79c8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MOVIE_GEN_LOOKUP = get_dictionary_lookup_by_tf_data_key('movie_genres')\n",
    "MOVIE_GEN_DIM = len(MOVIE_GEN_LOOKUP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "dc30e9d7-345e-4838-adda-bfbdec5eea36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 1,\n",
       " 2: 2,\n",
       " 3: 3,\n",
       " 4: 4,\n",
       " 5: 5,\n",
       " 6: 6,\n",
       " 7: 7,\n",
       " 8: 8,\n",
       " 9: 9,\n",
       " 10: 10,\n",
       " 12: 11,\n",
       " 13: 12,\n",
       " 14: 13,\n",
       " 15: 14,\n",
       " 16: 15,\n",
       " 17: 16,\n",
       " 18: 17,\n",
       " 19: 18}"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MOVIE_GEN_LOOKUP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e68a8e3-c56c-40d8-9544-992e62488b3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### write data config for subsequent notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "1557f99e-9fa4-4fd6-9c1b-96b42f9b353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = f'''\n",
    "USER_AGE_LOOKUP       = {USER_AGE_LOOKUP}\n",
    "USER_AGE_DIM          = {USER_AGE_DIM}\n",
    "\n",
    "USER_OCC_LOOKUP       = {USER_OCC_LOOKUP}\n",
    "USER_OCC_DIM          = {USER_OCC_DIM}\n",
    "\n",
    "MOVIE_GEN_LOOKUP      = {MOVIE_GEN_LOOKUP}\n",
    "MOVIE_GEN_DIM         = {MOVIE_GEN_DIM}\n",
    "\n",
    "MOVIELENS_NUM_MOVIES  = {MOVIELENS_NUM_MOVIES}\n",
    "MOVIELENS_NUM_USERS   = {MOVIELENS_NUM_USERS}\n",
    "'''\n",
    "# TODO - cleanup\n",
    "with open('src/per_arm_rl/data_config.py', 'w') as f:\n",
    "    f.write(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "2f376117-d6fd-42c2-813b-e5d28ed2098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dict = USER_OCC_LOOKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "9c481396-c7a5-4d70-a1c4-fbe285d4ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = f\"\"\"\n",
    "# USER_AGE_LOOKUP       = {USER_AGE_LOOKUP}\n",
    "# USER_AGE_DIM          = {USER_AGE_DIM}\n",
    "\n",
    "# USER_OCC_LOOKUP       = {USER_OCC_LOOKUP}\n",
    "# USER_OCC_DIM          = {USER_OCC_DIM}\n",
    "\n",
    "# MOVIE_GEN_LOOKUP      = {MOVIE_GEN_LOOKUP}\n",
    "# MOVIE_GEN_DIM         = {MOVIE_GEN_DIM}\n",
    "\n",
    "# MOVIELENS_NUM_MOVIES  = {MOVIELENS_NUM_MOVIES}\n",
    "# MOVIELENS_NUM_USERS   = {MOVIELENS_NUM_USERS}\n",
    "# \"\"\"\n",
    "# print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "54addd64-02a2-4e3e-91b3-2c0bf945b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !echo '{config}' | gsutil cp - {BUCKET_URI}/data_stats/notebook_env.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "cfa9c8e5-3be4-4826-bda7-2f358cca0642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil ls $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdd0df2-72cd-4475-90d9-f223de06f393",
   "metadata": {},
   "source": [
    "## Data Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "4d0ec95c-08af-47b6-9e3f-b3b3916b7875",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_DOCKER_PATH_PREFIX = 'src'\n",
    "RL_SUB_DIR = 'per_arm_rl'\n",
    "\n",
    "# ! rm -rf {REPO_DOCKER_PATH_PREFIX}/{RL_SUB_DIR}\n",
    "# ! mkdir -p {REPO_DOCKER_PATH_PREFIX}/{RL_SUB_DIR}\n",
    "# ! touch {REPO_DOCKER_PATH_PREFIX}/{RL_SUB_DIR}/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "51459783-87df-446e-8569-af86cfa7df67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp\n",
    "# USER_AGE_LOOKUP  # dict\n",
    "# USER_OCC_LOOKUP  # dict\n",
    "# MOVIE_GEN_LOOKUP # dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "d045d32f-2444-46ae-847e-aa4b858c2d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/per_arm_rl/data_utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{RL_SUB_DIR}/data_utils.py\n",
    "# Copyright 2021 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#            http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "EMBEDDING_SIZE = 128\n",
    "\n",
    "# ============================================\n",
    "# features\n",
    "# ============================================\n",
    "# DEFAULT_FEATURE_MAP = {\n",
    "#     # user - global context features\n",
    "#     'user_id': tf.io.FixedLenSequenceFeature([], tf.string),\n",
    "#     'user_rating': tf.io.FixedLenSequenceFeature([], tf.float32),\n",
    "#     'bucketized_user_age': tf.io.FixedLenSequenceFeature([], tf.float32),\n",
    "#     'user_occupation_text': tf.io.FixedLenSequenceFeature([], tf.string),\n",
    "#     # 'user_occupation_label': tf.io.FixedLenSequenceFeature([], tf.int64),\n",
    "#     'timestamp': tf.io.FixedLenSequenceFeature([], tf.int64),\n",
    "#     # 'user_zip_code': tf.io.FixedLenSequenceFeature([], tf.string),\n",
    "#     # 'user_gender': tf.io.FixedLenSequenceFeature([], tf.bool),\n",
    "    \n",
    "#     # movie - per arm features\n",
    "#     'movie_id': tf.io.FixedLenSequenceFeature([], tf.string),\n",
    "#     'movie_title': tf.io.FixedLenSequenceFeature([], tf.string),\n",
    "#     'movie_genres': tf.io.FixedLenSequenceFeature([], tf.int64),\n",
    "# }\n",
    "\n",
    "def get_all_features():\n",
    "    \n",
    "    feats = {\n",
    "        # user - global context features\n",
    "        'user_id': tf.io.FixedLenFeature(shape=(), dtype=tf.string),\n",
    "        'user_rating': tf.io.FixedLenFeature(shape=(), dtype=tf.float32),\n",
    "        'bucketized_user_age': tf.io.FixedLenFeature(shape=(), dtype=tf.float32),\n",
    "        'user_occupation_text': tf.io.FixedLenFeature(shape=(), dtype=tf.string),\n",
    "        # 'user_occupation_label': tf.io.FixedLenFeature(shape=(), dtype=tf.int64),\n",
    "        'timestamp': tf.io.FixedLenFeature(shape=(), dtype=tf.int64),\n",
    "        # 'user_zip_code': tf.io.FixedLenFeature(shape=(), dtype=tf.string),\n",
    "        # 'user_gender': tf.io.FixedLenFeature(shape=(), dtype=tf.bool),\n",
    "\n",
    "        # movie - per arm features\n",
    "        'movie_id': tf.io.FixedLenFeature(shape=(), dtype=tf.string),\n",
    "        # 'movie_title': tf.io.FixedLenFeature(shape=(), dtype=tf.string),\n",
    "        'movie_genres': tf.io.FixedLenFeature(shape=(1,), dtype=tf.int64),\n",
    "    }\n",
    "    \n",
    "    return feats \n",
    "\n",
    "# ============================================\n",
    "# tf data parsing functions\n",
    "# ============================================\n",
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\n",
    "\n",
    "def parse_tfrecord(example):\n",
    "    \"\"\"\n",
    "    Reads a serialized example from GCS and converts to tfrecord\n",
    "    \"\"\"\n",
    "    feats = get_all_features()\n",
    "    \n",
    "    # example = tf.io.parse_single_example(\n",
    "    example = tf.io.parse_example(\n",
    "        example,\n",
    "        feats\n",
    "        # features=feats\n",
    "    )\n",
    "    return example\n",
    "\n",
    "# data loading and parsing\n",
    "def full_parse(data):\n",
    "    # used for interleave - takes tensors and returns a tf.dataset\n",
    "    data = tf.data.TFRecordDataset(data)\n",
    "    return data\n",
    "\n",
    "# ============================================\n",
    "# Helper function for TF lookup dictionary\n",
    "# ============================================\n",
    "\n",
    "def get_dictionary_lookup_by_tf_data_key(key, dataset) -> Dict:\n",
    "    tensor = dataset.map(lambda x: x[key])\n",
    "    unique_elems = set()\n",
    "    for x in tensor:\n",
    "        val = x.numpy()\n",
    "        if type(val) is np.ndarray: # if multi dimesnional only grab first one\n",
    "            val = val[0]\n",
    "        unique_elems.add(val)\n",
    "    \n",
    "    #return a dictionary of keys by integer values for the feature space\n",
    "    return {val: i for i, val in enumerate(unique_elems)}\n",
    "\n",
    "# ============================================\n",
    "# load movielens\n",
    "# ============================================\n",
    "def load_movielens_ratings(\n",
    "    ratings_dataset\n",
    "    , num_users: int\n",
    "    , num_movies: int\n",
    "    , user_age_lookup_dict: dict\n",
    "    , user_occ_lookup_dict: dict\n",
    "    , movie_gen_lookup_dict: dict\n",
    "):\n",
    "    \"\"\"\n",
    "    > loads (wide) movielens ratings data \n",
    "    > returns ratings matrix\n",
    "    \"\"\"\n",
    "    # ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "    ratings_matrix = np.zeros([num_users, num_movies])\n",
    "    \n",
    "    local_data = ratings_dataset.map(\n",
    "        lambda x: {\n",
    "            'user_id': x['user_id']\n",
    "            ,'movie_id':  x['movie_id']\n",
    "            ,'user_rating':  x['user_rating']\n",
    "            ,'bucketized_user_age': x['bucketized_user_age']\n",
    "            ,'user_occupation_text': x['user_occupation_text']\n",
    "            ,'movie_genres': x['movie_genres'][0]\n",
    "        }\n",
    "    )\n",
    "    user_age_int = []\n",
    "    user_occ_int = []\n",
    "    mov_gen_int = []\n",
    "    \n",
    "    for row in local_data:\n",
    "        ratings_matrix[\n",
    "            int(row['user_id'].numpy()) - 1\n",
    "            , int(row['movie_id'].numpy()) - 1\n",
    "        ] = float(row['user_rating'].numpy())\n",
    "        \n",
    "        user_age_int.append(\n",
    "            float(user_age_lookup_dict[row['bucketized_user_age'].numpy()]) + .0001\n",
    "        )\n",
    "        user_occ_int.append(\n",
    "            float(user_occ_lookup_dict[row['user_occupation_text'].numpy()]) + .0001\n",
    "        )\n",
    "        mov_gen_int.append(\n",
    "            float(movie_gen_lookup_dict[row['movie_genres'].numpy()]) + .0001\n",
    "        ) \n",
    "    return ratings_matrix, np.array(user_age_int), np.array(user_occ_int), np.array(mov_gen_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1c21b7-1778-486a-9cd8-048fc41df4f1",
   "metadata": {},
   "source": [
    "### validate creating ratings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "38b07ca7-f609-46cf-8234-6ceb4e4c1fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: 0, 35.0: 1, 45.0: 2, 18.0: 3, 50.0: 4, 56.0: 5, 25.0: 6}"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_config.USER_AGE_LOOKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "c5625bfa-c1b8-4fc0-8c91-1f9569ce84ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'artist': 0,\n",
       " b'student': 1,\n",
       " b'other': 2,\n",
       " b'librarian': 3,\n",
       " b'doctor': 4,\n",
       " b'engineer': 5,\n",
       " b'technician': 6,\n",
       " b'programmer': 7,\n",
       " b'scientist': 8,\n",
       " b'entertainment': 9,\n",
       " b'healthcare': 10,\n",
       " b'none': 11,\n",
       " b'educator': 12,\n",
       " b'administrator': 13,\n",
       " b'salesman': 14,\n",
       " b'retired': 15,\n",
       " b'marketing': 16,\n",
       " b'executive': 17,\n",
       " b'writer': 18,\n",
       " b'lawyer': 19,\n",
       " b'homemaker': 20}"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_config.USER_OCC_LOOKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "54b19bdd-1564-4781-b1b9-6a2bef3fab93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 1,\n",
       " 2: 2,\n",
       " 3: 3,\n",
       " 4: 4,\n",
       " 5: 5,\n",
       " 6: 6,\n",
       " 7: 7,\n",
       " 8: 8,\n",
       " 9: 9,\n",
       " 10: 10,\n",
       " 12: 11,\n",
       " 13: 12,\n",
       " 14: 13,\n",
       " 15: 14,\n",
       " 16: 15,\n",
       " 17: 16,\n",
       " 18: 17,\n",
       " 19: 18}"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_config.MOVIE_GEN_LOOKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "be3b5f40-ee4d-411e-8408-041a0add0897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - defined later -fix\n",
    "from src.per_arm_rl import data_utils_v2 as data_utils\n",
    "from src.per_arm_rl import data_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "71943223-d7ec-4502-9831-abb75b988950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://mabv1-hybrid-vertex-bucket/data/ml-ratings-100k-train.tfrecord']"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "b39e138f-9c95-4412-8523-cac404497822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "9fbb331f-08cf-4202-857b-ae285fad9196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec={'bucketized_user_age': TensorSpec(shape=(), dtype=tf.float32, name=None), 'movie_genres': TensorSpec(shape=(1,), dtype=tf.int64, name=None), 'movie_id': TensorSpec(shape=(), dtype=tf.string, name=None), 'timestamp': TensorSpec(shape=(), dtype=tf.int64, name=None), 'user_id': TensorSpec(shape=(), dtype=tf.string, name=None), 'user_occupation_text': TensorSpec(shape=(), dtype=tf.string, name=None), 'user_rating': TensorSpec(shape=(), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(data_utils.parse_tfrecord)\n",
    "\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices(train_files).prefetch(\n",
    "#     tf.data.AUTOTUNE,\n",
    "# )\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "80013497-21c9-48c5-bd39-433de6ebc4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([45.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'357'], dtype=object)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([879024327])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'138'], dtype=object)>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'doctor'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>}\n",
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([25.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[4]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'709'], dtype=object)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([875654590])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'92'], dtype=object)>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'entertainment'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "for x in train_dataset.batch(1).take(2):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "fc9d1512-9318-46dd-999d-f87f9c9d9b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[5., 3., 4., ..., 0., 0., 0.],\n",
       "        [4., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [5., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 5., 0., ..., 0., 0., 0.]]),\n",
       " array([2.0001, 6.0001, 3.0001, ..., 3.0001, 1.0001, 3.0001]),\n",
       " array([ 4.0001,  9.0001,  1.0001, ...,  1.0001, 18.0001,  1.0001]),\n",
       " array([7.00010e+00, 4.00010e+00, 4.00010e+00, ..., 1.00001e+01,\n",
       "        1.00000e-04, 4.00010e+00]))"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # TODO - defined later -fix\n",
    "# from src.per_arm_rl import data_utils_v2 as data_utils\n",
    "# from src.per_arm_rl import data_config\n",
    "\n",
    "test_dataset_load = data_utils.load_movielens_ratings(\n",
    "    ratings_dataset = train_dataset\n",
    "    , num_users = data_config.MOVIELENS_NUM_USERS\n",
    "    , num_movies = data_config.MOVIELENS_NUM_MOVIES\n",
    "    , user_age_lookup_dict = data_config.USER_AGE_LOOKUP\n",
    "    , user_occ_lookup_dict = data_config.USER_OCC_LOOKUP\n",
    "    , movie_gen_lookup_dict = data_config.MOVIE_GEN_LOOKUP\n",
    ")\n",
    "\n",
    "test_dataset_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "f55014ae-fc94-4a1a-a2dd-fde3970b5387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 1682)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5., 3., 4., ..., 0., 0., 0.],\n",
       "       [4., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 5., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_matrix = test_dataset_load[0]\n",
    "print(ratings_matrix.shape)\n",
    "ratings_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27d4393-0017-4180-a9e8-eac13f4ed477",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Vocab Generation - TODO\n",
    "\n",
    "following [this internal example](https://source.corp.google.com/piper///depot/google3/commerce/delivery/recommendation/shop_rl/python/topk_off_policy_reinforce/dataset_analysis.ipynb)\n",
    "* see [data_utils.py](https://source.corp.google.com/piper///depot/google3/commerce/delivery/recommendation/shop_rl/python/topk_off_policy_reinforce/data_utils.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7e5f93-ab46-456c-92d8-2abb677e54e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_ACTION = 'movie_id'\n",
    "FEATURE_REWARD = 'user_rating'\n",
    "\n",
    "def process_example(example_proto):\n",
    "    \"\"\"\n",
    "    Returns a dataset of actions for each example.\n",
    "    \"\"\"\n",
    "    _, sequence_feature = tf.io.parse_single_sequence_example(\n",
    "        example_proto\n",
    "        , sequence_features={\n",
    "            FEATURE_ACTION:\n",
    "                tf.io.FixedLenSequenceFeature([], tf.int64, default_value=None)\n",
    "            , FEATURE_REWARD:\n",
    "                tf.io.FixedLenSequenceFeature([], tf.int64, default_value=None)\n",
    "        }\n",
    "    )\n",
    "    actions = sequence_feature[FEATURE_ACTION]\n",
    "    rewards = sequence_feature[FEATURE_REWARD]\n",
    "    \n",
    "    return actions, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7ade30-87d7-4c76-8036-b855ba8a702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "dataset_files = tf.io.gfile.glob(dataset_path)\n",
    "dataset_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77976790-6a7b-4a53-88d8-3a8828f7b209",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dataset = tf.data.RecordIODataset(dataset_files)\n",
    "example_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9758f6-4b8f-402d-ab93-1c1a84ee0c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dataset = example_dataset.map(\n",
    "    process_example\n",
    "    , num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    ")\n",
    "example_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090f672b-28c0-471a-8161-c25afc168f60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfad9c6b-8585-46aa-ad31-61d65434be76",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_items_to_process = 1000000\n",
    "num_elements = 0\n",
    "sequence_lengths = []\n",
    "actions = []\n",
    "rewards = []\n",
    "\n",
    "start_time = time.time()\n",
    "for elem in example_dataset.as_numpy_iterator():\n",
    "    action, reward = elem\n",
    "    sequence_lengths.append(len(action))\n",
    "    actions.append(action)\n",
    "    rewards.append(reward)\n",
    "    num_elements += 1\n",
    "    if num_elements % 10000 == 0:\n",
    "        print(num_elements)\n",
    "    if num_elements > max_items_to_process:\n",
    "        break\n",
    "\n",
    "print('Num sequences = ', num_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd79f362-cd35-476c-adcf-94375df1300e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6479851a-f53c-4f64-b40f-d8178767c6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function which processes a TF Example and returns a nested tensor containing\n",
    "# the data extracted from the Example proto.\n",
    "ProcessExampleFnType = Callable[[types.Tensor], types.NestedTensor]\n",
    "FilterExampleFnType = Callable[[types.NestedTensor, types.Tensor], types.Tensor]\n",
    "\n",
    "DEFAULT_FEATURE_MAP = {\n",
    "    'user_rating':\n",
    "        tf.io.FixedLenSequenceFeature([], tf.float32),\n",
    "    \n",
    "    # The id of an item. This is what we use as the action. \n",
    "    # movie_id's from previous time steps are also used as\n",
    "    # an observation. The movie_id is unique for each item/movie\n",
    "    'movie_id':\n",
    "        tf.io.FixedLenSequenceFeature([], tf.string),\n",
    "    \n",
    "    # The title\n",
    "    'movie_title':\n",
    "        tf.io.FixedLenSequenceFeature([], tf.string),\n",
    "    \n",
    "    # 'movie_genres':\n",
    "    #     tf.io.FixedLenSequenceFeature([], tf.int64),\n",
    "    \n",
    "    'user_id':\n",
    "        tf.io.FixedLenSequenceFeature([], tf.string),\n",
    "    \n",
    "    # user's occupation - encoded label\n",
    "    'user_occupation_label':\n",
    "        tf.io.FixedLenSequenceFeature([], tf.int64),\n",
    "    \n",
    "    # the timestamp of the ratings, \n",
    "    # represented in seconds since midnight UTC of 01/01/1970\n",
    "    # 'timestamp':\n",
    "    #     tf.io.FixedLenSequenceFeature([], tf.int64),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48101a93-6df3-4b68-9821-5200c62f8c09",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Generate Off Policy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f032d8b0-b70f-44cc-8fea-d6a9de15ce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_simulation_data(\n",
    "    raw_data_path: str\n",
    "    , batch_size: int\n",
    "    , rank_k: int\n",
    "    , num_actions: int\n",
    "    , driver_steps: int\n",
    ") -> replay_buffers.TFUniformReplayBuffer:\n",
    "    \"\"\"\n",
    "    Generates `trajectories.Trajectory` data from the simulation environment.\n",
    "\n",
    "    Constructs a MovieLens simulation environment, and generates a set of\n",
    "    `trajectories.Trajectory` data using a random policy.\n",
    "\n",
    "    Args:\n",
    "      raw_data_path: Path to MovieLens 100K's \"u.data\" file.\n",
    "      batch_size: Batch size of environment generated quantities eg. rewards.\n",
    "      rank_k: Rank for matrix factorization in the MovieLens environment; also\n",
    "        the observation dimension.\n",
    "      num_actions: Number of actions (movie items) to choose from.\n",
    "      driver_steps: Number of steps to run per batch.\n",
    "\n",
    "    Returns:\n",
    "      A replay buffer holding randomly generated`trajectories.Trajectory` data.\n",
    "    \"\"\"\n",
    "    # Create MovieLens simulation environment.\n",
    "    # env = movielens_py_environment.MovieLensPyEnvironment(\n",
    "    #     raw_data_path,\n",
    "    #     rank_k,\n",
    "    #     batch_size,\n",
    "    #     num_movies=num_actions,\n",
    "    #     csv_delimiter=\"\\t\"\n",
    "    # )\n",
    "    # environment = tf_py_environment.TFPyEnvironment(env)\n",
    "    \n",
    "    env = movielens_per_arm_py_environment.MovieLensPerArmPyEnvironment(\n",
    "        data_dir = raw_data_path\n",
    "        , rank_k = rank_k\n",
    "        , batch_size = batch_size\n",
    "        , num_actions = num_actions\n",
    "        , csv_delimiter = \"\\t\"\n",
    "    )\n",
    "\n",
    "    environment = tf_py_environment.TFPyEnvironment(env)\n",
    "\n",
    "    # Define random policy for collecting data.\n",
    "    random_policy = random_tf_policy.RandomTFPolicy(\n",
    "        action_spec=environment.action_spec()\n",
    "        , time_step_spec=environment.time_step_spec()\n",
    "    )\n",
    "\n",
    "    # Use replay buffer and observers to keep track of Trajectory data.\n",
    "    data_spec = random_policy.trajectory_spec\n",
    "    replay_buffer = trainer._get_replay_buffer(\n",
    "        data_spec\n",
    "        , environment.batch_size\n",
    "        , driver_steps\n",
    "        , 1\n",
    "    )\n",
    "    observers = [replay_buffer.add_batch]\n",
    "\n",
    "    # Run driver to apply the random policy in the simulation environment.\n",
    "    driver = dynamic_step_driver.DynamicStepDriver(\n",
    "        env=environment\n",
    "        , policy=random_policy\n",
    "        , num_steps=driver_steps * environment.batch_size\n",
    "        , observers=observers\n",
    "    )\n",
    "    driver.run()\n",
    "\n",
    "    return replay_buffer"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
