{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bef58d66-b85e-49ca-baa1-eae9d3af08b4",
   "metadata": {},
   "source": [
    "# Preparing offline training data for RL\n",
    "\n",
    "**Objectives** of this notebook:\n",
    "1. prepare training datasets from the [MovieLens 100k](https://www.tensorflow.org/datasets/catalog/movielens#movielens100k-movies) (or optionally, [MovieLens 1M](https://www.tensorflow.org/datasets/catalog/movielens#movielens1m-movies)) public dataset\n",
    "2. Write datasets to TF-Records\n",
    "3.  Generate dataset vocabulary and look-up dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0035c271-1aff-48cc-841f-38470a314aaf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load env config\n",
    "\n",
    "* use the prefix from `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5fe16f7-704a-4d31-96e9-8cd2c1cbc87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "VERSION = \"v2\"  # TODO\n",
    "PREFIX = f\"rec-bandits-{VERSION}\"  # TODO\n",
    "\n",
    "print(f\"PREFIX: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d04e4d-afd5-45f4-a5f5-db4126b3f514",
   "metadata": {},
   "source": [
    "**run the next cell to populate env vars**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67fb5c09-bdf4-4a7e-abb9-aae601788a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"cpg-cdp\"\n",
      "PROJECT_NUM              = \"939655404703\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"939655404703-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"rec-bandits-v2\"\n",
      "VERSION                  = \"v2\"\n",
      "\n",
      "BUCKET_NAME              = \"rec-bandits-v2-cpg-cdp-bucket\"\n",
      "BUCKET_URI               = \"gs://rec-bandits-v2-cpg-cdp-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://rec-bandits-v2-cpg-cdp-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "DATA_PATH_KFP_DEMO       = \"gs://rec-bandits-v2-cpg-cdp-bucket/data/kfp_demo_data/u.data\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/939655404703/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_NAME    = \"mvlens_rec_bandits_v2\"\n",
      "BIGQUERY_TABLE_NAME      = \"training_dataset\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-rec-bandits-v2\"\n",
      "\n",
      "DOCKERNAME_01            = \"Dockerfile_train_my_perarm_env\"\n",
      "IMAGE_NAME_01            = \"train-my-perarm-env-v2\"\n",
      "IMAGE_URI_01             = \"gcr.io/cpg-cdp/train-my-perarm-env-v2\"\n",
      "\n",
      "DOCKERNAME_02            = \"Dockerfile_perarm_feats\"\n",
      "IMAGE_NAME_02            = \"train-perarm-feats-v2\"\n",
      "IMAGE_URI_02             = \"gcr.io/cpg-cdp/train-perarm-feats-v2\"\n",
      "\n",
      "DOCKERNAME_03            = \"Dockerfile_ranking_bandit\"\n",
      "IMAGE_NAME_03            = \"train-rank-bandit-v2\"\n",
      "IMAGE_URI_03             = \"gcr.io/cpg-cdp/train-rank-bandit-v2\"\n",
      "\n",
      "DOCKERNAME_04            = \"Dockerfile_train_mab_e2e\"\n",
      "IMAGE_NAME_04            = \"train-mab-e2e-v2\"\n",
      "IMAGE_URI_04             = \"gcr.io/cpg-cdp/train-mab-e2e-v2\"\n",
      "\n",
      "DOCKERNAME_04_pred       = \"Dockerfile_pred_mab_e2e\"\n",
      "IMAGE_NAME_04_pred       = \"pred-mab-e2e-v2\"\n",
      "IMAGE_URI_04_pred        = \"gcr.io/cpg-cdp/pred-mab-e2e-v2\"\n",
      "\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/cpg-cdp/rl-movielens-rec-bandits-v2/local_docker_tfa\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e10356aa-db4d-48e9-974f-caee57a3a29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gsutil ls $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ff6716-afc3-4456-8784-f8f1d4796671",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86c8c72b-6472-47b5-836d-c924c75859a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f19c473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numba\n",
      "  Downloading numba-0.59.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting llvmlite<0.43,>=0.42.0dev0 (from numba)\n",
      "  Downloading llvmlite-0.42.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: numpy<1.27,>=1.22 in /opt/conda/envs/tf_agents/lib/python3.10/site-packages (from numba) (1.26.4)\n",
      "Downloading numba-0.59.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.42.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: llvmlite, numba\n",
      "Successfully installed llvmlite-0.42.0 numba-0.59.0\n"
     ]
    }
   ],
   "source": [
    "! pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5be08889-6644-46ac-bd9b-1ce6c2d533d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from pprint import pprint\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from typing import Dict, List, Optional, Text, Tuple\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# import tensorflow_recommenders as tfrsa\n",
    "\n",
    "# GPU\n",
    "from numba import cuda\n",
    "import gc\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "# this repo\n",
    "from src.per_arm_rl import data_utils as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "851a6ded-cf88-47b6-a31a-b0cfe28b6951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61009c45-dbf3-494c-a67f-72d2b9aa9c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17326c68-5251-486d-9558-57f42b932ca7",
   "metadata": {},
   "source": [
    "### Initialize GCP clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60ac9153-79b0-473f-98bf-a59237463ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad05d51-44be-4e80-a948-4969476ea0bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create `data_utils.py`\n",
    "\n",
    "> this will be used to support data processing throughout the development workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17762dd-50c3-48a1-b061-ed7575373754",
   "metadata": {},
   "source": [
    "# [1] Prepare Movielens dataset\n",
    "\n",
    "* [1.a] - prepare 100k dataset; used in folders `01...` and `02...`\n",
    "* [1.b] - prepare 1M dataset; used in folders `05` (WIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8960a293-b3d9-4911-b573-0c381d57c8e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## [1.a] 100k dataset\n",
    "\n",
    "> download and prepare [MovieLens 100k](https://www.tensorflow.org/datasets/catalog/movielens#movielens100k-movies) public dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0066bc65-42c3-4ab4-9e90-69f389638c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_SHARDS: 5\n",
      "DATA_GCS_PREFIX : data/movielens-100k\n"
     ]
    }
   ],
   "source": [
    "DATA_TAG = \"100k\"\n",
    "\n",
    "RECORD_COUNT = 100_000\n",
    "SHARD_SIZE = 20_000\n",
    "NUM_SHARDS = int(RECORD_COUNT / SHARD_SIZE)\n",
    "print(f\"NUM_SHARDS: {NUM_SHARDS}\")\n",
    "\n",
    "# paths\n",
    "DATA_GCS_PREFIX = f\"data/movielens-{DATA_TAG}\"\n",
    "\n",
    "print(f\"DATA_GCS_PREFIX : {DATA_GCS_PREFIX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a923c9-cecf-4613-a8f4-3e31f74c8353",
   "metadata": {},
   "source": [
    "### load data from Tensorflow Datasets\n",
    "\n",
    "* see [TFDS documentation](https://www.tensorflow.org/datasets/catalog/movielens#movielens100k-ratings) for more details on this dataset, feature descriptions, and other versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51fb0683-4929-4417-be65-d67f21bb643f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 4.70 MiB (download: 4.70 MiB, generated: 32.41 MiB, total: 37.10 MiB) to /home/jwortz_google_com/tensorflow_datasets/movielens/100k-ratings/0.1.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  2.66 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  2.60 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  2.55 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  2.51 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  2.40 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  2.36 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  2.33 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  2.29 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  2.26 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  2.23 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  2.17 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  2.13 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  2.06 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  2.03 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.98 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.94 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.89 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.86 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.81 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.78 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.73 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.71 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.67 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.65 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.63 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.62 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.61 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.60 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.59 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.57 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.56 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.54 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.52 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.51 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.50 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.49 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.47 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.46 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.45 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.44 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.43 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.42 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.41 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.40 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.39 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.38 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.37 url/s]\n",
      "Extraction completed...: 100%|██████████| 23/23 [00:00<00:00, 31.55 file/s]\n",
      "Dl Size...: 100%|██████████| 4/4 [00:00<00:00,  5.46 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.36 url/s]\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset movielens downloaded and prepared to /home/jwortz_google_com/tensorflow_datasets/movielens/100k-ratings/0.1.1. Subsequent calls will reuse this data.\u001b[0m\n",
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([45.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'357'], dtype=object)>,\n",
      " 'movie_title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"One Flew Over the Cuckoo's Nest (1975)\"], dtype=object)>,\n",
      " 'raw_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([46.], dtype=float32)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([879024327])>,\n",
      " 'user_gender': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'138'], dtype=object)>,\n",
      " 'user_occupation_label': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([4])>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'doctor'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>,\n",
      " 'user_zip_code': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'53211'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "ratings = tfds.load(f\"movielens/{DATA_TAG}-ratings\", split=\"train\")\n",
    "\n",
    "for x in ratings.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d73b00ad-af36-4571-a0ec-a9c1f11b4c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing skip: 0 take: 20000\n",
      "writing: ./ml-100k-ratings-train-01-of-05.tfrecord...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copied ml-100k-ratings-train-01-of-05.tfrecord to Cloud Storage\n",
      "\n",
      "writing skip: 20000 take: 20000\n",
      "writing: ./ml-100k-ratings-train-02-of-05.tfrecord...\n",
      "copied ml-100k-ratings-train-02-of-05.tfrecord to Cloud Storage\n",
      "\n",
      "writing skip: 40000 take: 20000\n",
      "writing: ./ml-100k-ratings-train-03-of-05.tfrecord...\n",
      "copied ml-100k-ratings-train-03-of-05.tfrecord to Cloud Storage\n",
      "\n",
      "writing skip: 60000 take: 20000\n",
      "writing: ./ml-100k-ratings-train-04-of-05.tfrecord...\n",
      "copied ml-100k-ratings-train-04-of-05.tfrecord to Cloud Storage\n",
      "\n",
      "writing skip: 80000 take: 20000\n",
      "writing: ./ml-100k-ratings-train-05-of-05.tfrecord...\n",
      "copied ml-100k-ratings-train-05-of-05.tfrecord to Cloud Storage\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bucket = storage_client.bucket(BUCKET_NAME)\n",
    "\n",
    "for i in range(0, NUM_SHARDS):\n",
    "    TF_RECORD_FILE = f\"ml-{DATA_TAG}-ratings-train-{str(i+1).zfill(2)}-of-{str(NUM_SHARDS).zfill(2)}.tfrecord\"\n",
    "    LOCAL_TF_RECORD_FILE = f\"./{TF_RECORD_FILE}\"\n",
    "    take = SHARD_SIZE\n",
    "    skip = take * i\n",
    "\n",
    "    print(f\"writing skip: {skip} take: {take}\")\n",
    "    ds_slice = ratings.skip(skip).take(take)\n",
    "\n",
    "    print(f\"writing: {LOCAL_TF_RECORD_FILE}...\")\n",
    "    data_utils.write_tfrecords(LOCAL_TF_RECORD_FILE, ds_slice, list_wise=False)\n",
    "\n",
    "    DEST_BLOB = f\"{DATA_GCS_PREFIX}/all/{TF_RECORD_FILE}\"\n",
    "    blob = bucket.blob(DEST_BLOB)\n",
    "    blob.upload_from_filename(TF_RECORD_FILE)\n",
    "\n",
    "    print(f\"copied {TF_RECORD_FILE} to Cloud Storage\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23c3c3eb-e02a-406d-b0cc-4789da410406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-100k/all/ml-100k-ratings-train-01-of-05.tfrecord\n",
      "gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-100k/all/ml-100k-ratings-train-02-of-05.tfrecord\n",
      "gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-100k/all/ml-100k-ratings-train-03-of-05.tfrecord\n",
      "gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-100k/all/ml-100k-ratings-train-04-of-05.tfrecord\n",
      "gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-100k/all/ml-100k-ratings-train-05-of-05.tfrecord\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls gs://$BUCKET_NAME/$DATA_GCS_PREFIX/all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592e87fe-2c22-4f4d-9a8d-47d2069c274a",
   "metadata": {},
   "source": [
    "### copy subset to train subfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17bd6922-f263-407c-ba64-8d187e557b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml-100k-ratings-train-01-of-05.tfrecord\n",
      "ml-100k-ratings-train-02-of-05.tfrecord\n",
      "ml-100k-ratings-train-03-of-05.tfrecord\n",
      "ml-100k-ratings-train-04-of-05.tfrecord\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, (NUM_SHARDS)):\n",
    "    TF_RECORD_FILE = f\"ml-{DATA_TAG}-ratings-train-{str(i).zfill(2)}-of-{str(NUM_SHARDS).zfill(2)}.tfrecord\"\n",
    "    print(TF_RECORD_FILE)\n",
    "    \n",
    "    ! gsutil -q cp gs://$BUCKET_NAME/$DATA_GCS_PREFIX/all/$TF_RECORD_FILE gs://$BUCKET_NAME/$DATA_GCS_PREFIX/train/$TF_RECORD_FILE\n",
    "    ! rm ./$TF_RECORD_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5241ff8a-d5be-464e-9672-c7072f6699c4",
   "metadata": {},
   "source": [
    "### copy subset to val subfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d18b53a5-7815-4412-9f21-e220984ce93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml-100k-ratings-train-05-of-05.tfrecord\n"
     ]
    }
   ],
   "source": [
    "for i in range(NUM_SHARDS, (NUM_SHARDS+1)):\n",
    "    TF_RECORD_FILE = f\"ml-{DATA_TAG}-ratings-train-{str(i).zfill(2)}-of-{str(NUM_SHARDS).zfill(2)}.tfrecord\"\n",
    "    print(TF_RECORD_FILE)\n",
    "    \n",
    "    ! gsutil -q cp gs://$BUCKET_NAME/$DATA_GCS_PREFIX/all/$TF_RECORD_FILE gs://$BUCKET_NAME/$DATA_GCS_PREFIX/val/$TF_RECORD_FILE\n",
    "    ! rm ./$TF_RECORD_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4c5043-b557-4967-a28c-334c2ad5815a",
   "metadata": {},
   "source": [
    "### validate TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe3dc3c7-4644-49e0-950a-9befe2a89452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-100k/all/ml-100k-ratings-train-01-of-05.tfrecord',\n",
       " 'gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-100k/all/ml-100k-ratings-train-02-of-05.tfrecord',\n",
       " 'gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-100k/all/ml-100k-ratings-train-03-of-05.tfrecord',\n",
       " 'gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-100k/all/ml-100k-ratings-train-04-of-05.tfrecord',\n",
       " 'gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-100k/all/ml-100k-ratings-train-05-of-05.tfrecord']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files = []\n",
    "for blob in storage_client.list_blobs(\n",
    "    f\"{BUCKET_NAME}\",\n",
    "    prefix=f\"{DATA_GCS_PREFIX}/all/\",\n",
    "    # delimiter='/'\n",
    "):\n",
    "    if \".tfrecord\" in blob.name:\n",
    "        train_files.append(\n",
    "            blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\")\n",
    "        )\n",
    "\n",
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68a1a5ad-a4da-429c-947f-3c25dfd80503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([45.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'357'], dtype=object)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([879024327])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'138'], dtype=object)>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'doctor'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "train_dataset = train_dataset.map(data_utils.parse_tfrecord)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c27a012-0901-4106-8912-b8b67a1c54d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 4., 5.], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the unique movies and users\n",
    "unique_user_ratings = train_dataset.map(lambda x: x[\"user_rating\"])\n",
    "\n",
    "unique_user_ratings = np.unique([x.numpy() for x in unique_user_ratings])\n",
    "\n",
    "unique_user_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32bcfb8-5907-4359-8f2d-0881d4819241",
   "metadata": {},
   "source": [
    "### Generate look-up dicts\n",
    "\n",
    "**TODO** - use more Tensorflow native method for generating vocabs and stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14652643-653d-42fd-975d-20ef94535be1",
   "metadata": {},
   "source": [
    "#### unique movie IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b718823-2da9-4aa2-9f84-462ae31022b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(movie_id_vocab) : 1683\n",
      "movie_id_vocab      : ['[UNK]', '50']\n"
     ]
    }
   ],
   "source": [
    "movie_id_lookup = tf.keras.layers.StringLookup()\n",
    "movie_id_lookup.adapt(train_dataset.map(lambda x: x[\"movie_id\"]))\n",
    "movie_id_vocab = movie_id_lookup.get_vocabulary()\n",
    "\n",
    "MOVIELENS_NUM_MOVIES = len(movie_id_vocab)\n",
    "\n",
    "print(f\"len(movie_id_vocab) : {len(movie_id_vocab)}\")\n",
    "print(f\"movie_id_vocab      : {movie_id_vocab[:2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b8ea22-79f0-4e31-a563-492bf7243d80",
   "metadata": {},
   "source": [
    "#### unique user IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bad45da-a0c3-4456-824d-3e136ba5920d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(unique_user_ids_vocab) : 944\n",
      "unique_user_ids_vocab      : ['[UNK]', '405']\n"
     ]
    }
   ],
   "source": [
    "unique_user_ids_lookup = tf.keras.layers.StringLookup()\n",
    "unique_user_ids_lookup.adapt(train_dataset.map(lambda x: x[\"user_id\"]))\n",
    "unique_user_ids_vocab = unique_user_ids_lookup.get_vocabulary()\n",
    "\n",
    "MOVIELENS_NUM_USERS = len(unique_user_ids_vocab)\n",
    "\n",
    "print(f\"len(unique_user_ids_vocab) : {len(unique_user_ids_vocab)}\")\n",
    "print(f\"unique_user_ids_vocab      : {unique_user_ids_vocab[:2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f72258e-a247-4914-9bf6-7fc7d4c4b3ac",
   "metadata": {},
   "source": [
    "#### unique occupational_text_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55da811e-074d-431f-9678-65678b8775f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(unique_occ_vocab) : 22\n",
      "unique_occ_vocab      : ['[UNK]', 'student']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique movies and users\n",
    "# unique_occ_ids = train_dataset.map(lambda x: x[\"user_occupation_text\"])\n",
    "# unique_occ_ids = np.unique([x.numpy().decode('utf-8') for x in unique_occ_ids])\n",
    "\n",
    "unique_occ_lookup = tf.keras.layers.StringLookup()\n",
    "unique_occ_lookup.adapt(train_dataset.map(lambda x: x[\"user_occupation_text\"]))\n",
    "unique_occ_vocab = unique_occ_lookup.get_vocabulary()\n",
    "\n",
    "NUM_OCCS = len(unique_occ_vocab)\n",
    "\n",
    "print(f\"len(unique_occ_vocab) : {len(unique_occ_vocab)}\")\n",
    "print(f\"unique_occ_vocab      : {unique_occ_vocab[:2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40906865-dc56-459a-b52a-2ceb86ac5d6a",
   "metadata": {},
   "source": [
    "#### unique user_age values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f67ca345-c77d-44bd-a143-95350041b7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(unique_user_age) : 7\n",
      "unique_user_age      : [ 1. 18.]\n"
     ]
    }
   ],
   "source": [
    "unique_user_age = train_dataset.map(lambda x: x[\"bucketized_user_age\"])\n",
    "unique_user_age = np.unique([x.numpy() for x in unique_user_age])\n",
    "\n",
    "print(f\"len(unique_user_age) : {len(unique_user_age)}\")\n",
    "print(f\"unique_user_age      : {unique_user_age[:2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f040189c-546e-4c96-915f-6ed3f568f87b",
   "metadata": {},
   "source": [
    "#### timestamp buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56fe3525-b572-47d6-b453-7bb6cf54a0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp_buckets: [8.74724710e+08 8.74743291e+08 8.74761871e+08]\n"
     ]
    }
   ],
   "source": [
    "max_timestamp = (\n",
    "    ratings.map(lambda x: x[\"timestamp\"])\n",
    "    .reduce(tf.cast(0, tf.int64), tf.maximum)\n",
    "    .numpy()\n",
    "    .max()\n",
    ")\n",
    "min_timestamp = (\n",
    "    ratings.map(lambda x: x[\"timestamp\"])\n",
    "    .reduce(np.int64(1e9), tf.minimum)\n",
    "    .numpy()\n",
    "    .min()\n",
    ")\n",
    "\n",
    "timestamp_buckets = np.linspace(min_timestamp, max_timestamp, num=1000)\n",
    "\n",
    "print(f\"timestamp_buckets: {timestamp_buckets[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2a7777-f465-4f19-ab17-414b9c31c502",
   "metadata": {},
   "source": [
    "#### unique movie genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8932b098-780c-4078-ac63-55aef6dc7c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(unique_movie_genres) : 19\n",
      "unique_movie_genres      : [0 1]\n"
     ]
    }
   ],
   "source": [
    "unique_movie_genres = train_dataset.map(lambda x: x[\"movie_genres\"])\n",
    "unique_movie_genres = np.unique([x.numpy() for x in unique_movie_genres])\n",
    "\n",
    "MOVIELENS_NUM_GENRES = len(unique_movie_genres)\n",
    "\n",
    "print(f\"len(unique_movie_genres) : {len(unique_movie_genres)}\")\n",
    "print(f\"unique_movie_genres      : {unique_movie_genres[:2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda5c23a-1f1d-4ca0-8b15-99989ec5aada",
   "metadata": {},
   "source": [
    "### Write vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7585c4ec-e609-4b22-a978-aa091bccb62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_GCS_PREFIX : data/movielens-100k\n"
     ]
    }
   ],
   "source": [
    "vocab_dict = {\n",
    "    \"movie_id\": movie_id_vocab,\n",
    "    \"user_id\": unique_user_ids_vocab,\n",
    "    \"user_occupation_text\": unique_occ_vocab,\n",
    "    \"movie_genres\": unique_movie_genres,\n",
    "    \"bucketized_user_age\": unique_user_age,\n",
    "    \"max_timestamp\": max_timestamp,\n",
    "    \"min_timestamp\": min_timestamp,\n",
    "    \"timestamp_buckets\": timestamp_buckets,\n",
    "}\n",
    "\n",
    "print(f\"DATA_GCS_PREFIX : {DATA_GCS_PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c4f30e7-1e2d-4786-b020-decc3686d261",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_FILE_NAME = \"vocab_dict_1m.pkl\"\n",
    "filehandler = open(VOCAB_FILE_NAME, \"wb\")\n",
    "pkl.dump(vocab_dict, filehandler)\n",
    "\n",
    "filehandler.close()\n",
    "\n",
    "VOCAB_DEST_BLOB = f\"{DATA_GCS_PREFIX}/vocab_dict.pkl\"\n",
    "\n",
    "blob = bucket.blob(VOCAB_DEST_BLOB)\n",
    "blob.upload_from_filename(VOCAB_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cbff98-4bb2-42c5-a8ca-26d8452113f9",
   "metadata": {},
   "source": [
    "### Create lookup dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "681b7456-5229-4a2d-853b-63ecb04fba46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER_AGE_DIM: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1.0: 0, 35.0: 1, 45.0: 2, 18.0: 3, 50.0: 4, 56.0: 5, 25.0: 6}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USER_AGE_LOOKUP = data_utils.get_dictionary_lookup_by_tf_data_key(\n",
    "    key=\"bucketized_user_age\", dataset=train_dataset\n",
    ")\n",
    "\n",
    "USER_AGE_DIM = len(USER_AGE_LOOKUP)\n",
    "print(f\"USER_AGE_DIM: {USER_AGE_DIM}\")\n",
    "\n",
    "USER_AGE_LOOKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a512474f-cf7f-474c-8fde-847db3089b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER_OCC_DIM: 21\n"
     ]
    }
   ],
   "source": [
    "USER_OCC_LOOKUP = data_utils.get_dictionary_lookup_by_tf_data_key(\n",
    "    key=\"user_occupation_text\", dataset=train_dataset\n",
    ")\n",
    "USER_OCC_DIM = len(USER_OCC_LOOKUP)\n",
    "print(f\"USER_OCC_DIM: {USER_OCC_DIM}\")\n",
    "\n",
    "# USER_OCC_LOOKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39a87e3d-6620-475e-9fa6-4ff592c06fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOVIE_GEN_DIM: 19\n"
     ]
    }
   ],
   "source": [
    "MOVIE_GEN_LOOKUP = data_utils.get_dictionary_lookup_by_tf_data_key(\n",
    "    key=\"movie_genres\", dataset=train_dataset\n",
    ")\n",
    "MOVIE_GEN_DIM = len(MOVIE_GEN_LOOKUP)\n",
    "print(f\"MOVIE_GEN_DIM: {MOVIE_GEN_DIM}\")\n",
    "\n",
    "# MOVIE_GEN_LOOKUP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07ac0c8-4040-4d2b-9776-e32e175ac0de",
   "metadata": {},
   "source": [
    "#### Create `data_config.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d998ca85-9f19-4cf1-894d-c4b5a103bf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = f\"\"\"\n",
    "USER_AGE_LOOKUP       = {USER_AGE_LOOKUP}\n",
    "USER_AGE_DIM          = {USER_AGE_DIM}\n",
    "\n",
    "USER_OCC_LOOKUP       = {USER_OCC_LOOKUP}\n",
    "USER_OCC_DIM          = {USER_OCC_DIM}\n",
    "\n",
    "MOVIE_GEN_LOOKUP      = {MOVIE_GEN_LOOKUP}\n",
    "MOVIE_GEN_DIM         = {MOVIE_GEN_DIM}\n",
    "\n",
    "MOVIELENS_NUM_MOVIES  = {MOVIELENS_NUM_MOVIES}\n",
    "MOVIELENS_NUM_USERS   = {MOVIELENS_NUM_USERS}\n",
    "\"\"\"\n",
    "\n",
    "with open(f\"{REPO_DOCKER_PATH_PREFIX}/{RL_SUB_DIR}/data_config.py\", \"w\") as f:\n",
    "    f.write(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22c70877-c92d-4663-8a37-2480dd827b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.per_arm_rl import data_config  # as data_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b636aaf6-68b5-42df-ba1c-60d012a5663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_config.USER_AGE_LOOKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eac0f3f7-3811-4f21-bdea-18d4349687d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_config.USER_OCC_LOOKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7bc914e-bf75-4c30-993a-9dd75f1e17ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_config.MOVIE_GEN_LOOKUP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6097c593-a40a-48ab-89fa-d2d837f939a5",
   "metadata": {},
   "source": [
    "## [1.b] 1M dataset\n",
    "\n",
    "> download and prepare [MovieLens 1M](https://www.tensorflow.org/datasets/catalog/movielens#movielens1m-movies) public dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2de1352-f640-4208-9681-e1f91fcf5ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_SHARDS: 10\n",
      "DATA_GCS_PREFIX : data/movielens-1m\n"
     ]
    }
   ],
   "source": [
    "DATA_TAG = \"1m\"\n",
    "\n",
    "RECORD_COUNT = 1_000_000\n",
    "SHARD_SIZE = 100_000\n",
    "NUM_SHARDS = int(RECORD_COUNT / SHARD_SIZE)\n",
    "print(f\"NUM_SHARDS: {NUM_SHARDS}\")\n",
    "\n",
    "# paths\n",
    "DATA_GCS_PREFIX = f\"data/movielens-{DATA_TAG}\"\n",
    "\n",
    "print(f\"DATA_GCS_PREFIX : {DATA_GCS_PREFIX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fd55a7-c3a5-4a44-981f-9ed3d22da39b",
   "metadata": {},
   "source": [
    "### load data from Tensorflow Datasets\n",
    "\n",
    "* see [TFDS documentation](https://www.tensorflow.org/datasets/catalog/movielens#movielens100k-ratings) for more details on this dataset, feature descriptions, and other versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b870c306-0bb5-454d-82d4-a1a086480e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 5.64 MiB (download: 5.64 MiB, generated: 308.42 MiB, total: 314.06 MiB) to /home/jwortz_google_com/tensorflow_datasets/movielens/1m-ratings/0.1.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Extraction completed...: 100%|██████████| 4/4 [00:00<00:00,  6.94 file/s]\n",
      "Dl Size...: 100%|██████████| 5/5 [00:00<00:00,  8.61 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.71 url/s]\n",
      "                                                                         \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  2.65 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  2.58 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.93 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.82 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.80 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.78 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.76 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.75 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  1.73 url/s]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset movielens downloaded and prepared to /home/jwortz_google_com/tensorflow_datasets/movielens/1m-ratings/0.1.1. Subsequent calls will reuse this data.\u001b[0m\n",
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([35.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 2), dtype=int64, numpy=array([[0, 7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'3107'], dtype=object)>,\n",
      " 'movie_title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Backdraft (1991)'], dtype=object)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([977432193])>,\n",
      " 'user_gender': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'130'], dtype=object)>,\n",
      " 'user_occupation_label': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([18])>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'technician/engineer'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([5.], dtype=float32)>,\n",
      " 'user_zip_code': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'50021'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "ratings = tfds.load(f\"movielens/{DATA_TAG}-ratings\", split=\"train\")\n",
    "\n",
    "for x in ratings.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2280a5ca-ba11-4d33-b507-1b6a6cf96455",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing skip: 0 take: 100000\n",
      "writing: ./ml-1m-ratings-train-01-of-10.tfrecord...\n",
      "copied ml-1m-ratings-train-01-of-10.tfrecord to Cloud Storage\n",
      "\n",
      "writing skip: 100000 take: 100000\n",
      "writing: ./ml-1m-ratings-train-02-of-10.tfrecord...\n",
      "copied ml-1m-ratings-train-02-of-10.tfrecord to Cloud Storage\n",
      "\n",
      "writing skip: 200000 take: 100000\n",
      "writing: ./ml-1m-ratings-train-03-of-10.tfrecord...\n",
      "copied ml-1m-ratings-train-03-of-10.tfrecord to Cloud Storage\n",
      "\n",
      "writing skip: 300000 take: 100000\n",
      "writing: ./ml-1m-ratings-train-04-of-10.tfrecord...\n",
      "copied ml-1m-ratings-train-04-of-10.tfrecord to Cloud Storage\n",
      "\n",
      "writing skip: 400000 take: 100000\n",
      "writing: ./ml-1m-ratings-train-05-of-10.tfrecord...\n",
      "copied ml-1m-ratings-train-05-of-10.tfrecord to Cloud Storage\n",
      "\n",
      "writing skip: 500000 take: 100000\n",
      "writing: ./ml-1m-ratings-train-06-of-10.tfrecord...\n",
      "copied ml-1m-ratings-train-06-of-10.tfrecord to Cloud Storage\n",
      "\n",
      "writing skip: 600000 take: 100000\n",
      "writing: ./ml-1m-ratings-train-07-of-10.tfrecord...\n",
      "copied ml-1m-ratings-train-07-of-10.tfrecord to Cloud Storage\n",
      "\n",
      "writing skip: 700000 take: 100000\n",
      "writing: ./ml-1m-ratings-train-08-of-10.tfrecord...\n",
      "copied ml-1m-ratings-train-08-of-10.tfrecord to Cloud Storage\n",
      "\n",
      "writing skip: 800000 take: 100000\n",
      "writing: ./ml-1m-ratings-train-09-of-10.tfrecord...\n",
      "copied ml-1m-ratings-train-09-of-10.tfrecord to Cloud Storage\n",
      "\n",
      "writing skip: 900000 take: 100000\n",
      "writing: ./ml-1m-ratings-train-10-of-10.tfrecord...\n",
      "copied ml-1m-ratings-train-10-of-10.tfrecord to Cloud Storage\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bucket = storage_client.bucket(BUCKET_NAME)\n",
    "\n",
    "for i in range(0, NUM_SHARDS):\n",
    "    TF_RECORD_FILE = (\n",
    "        f\"ml-{DATA_TAG}-ratings-train-{str(i+1).zfill(2)}-of-{NUM_SHARDS}.tfrecord\"\n",
    "    )\n",
    "    LOCAL_TF_RECORD_FILE = f\"./{TF_RECORD_FILE}\"\n",
    "    take = SHARD_SIZE\n",
    "    skip = take * i\n",
    "\n",
    "    print(f\"writing skip: {skip} take: {take}\")\n",
    "    ds_slice = ratings.skip(skip).take(take)\n",
    "\n",
    "    print(f\"writing: {LOCAL_TF_RECORD_FILE}...\")\n",
    "    data_utils.write_tfrecords(LOCAL_TF_RECORD_FILE, ds_slice, list_wise=False)\n",
    "\n",
    "    DEST_BLOB = f\"{DATA_GCS_PREFIX}/all/{TF_RECORD_FILE}\"\n",
    "    blob = bucket.blob(DEST_BLOB)\n",
    "    blob.upload_from_filename(TF_RECORD_FILE)\n",
    "\n",
    "    print(f\"copied {TF_RECORD_FILE} to Cloud Storage\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2685679-712a-488f-a95f-cbbdcb441197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-1m/all/ml-1m-ratings-train-01-of-10.tfrecord\n",
      "gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-1m/all/ml-1m-ratings-train-02-of-10.tfrecord\n",
      "gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-1m/all/ml-1m-ratings-train-03-of-10.tfrecord\n",
      "gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-1m/all/ml-1m-ratings-train-04-of-10.tfrecord\n",
      "gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-1m/all/ml-1m-ratings-train-05-of-10.tfrecord\n",
      "gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-1m/all/ml-1m-ratings-train-06-of-10.tfrecord\n",
      "gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-1m/all/ml-1m-ratings-train-07-of-10.tfrecord\n",
      "gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-1m/all/ml-1m-ratings-train-08-of-10.tfrecord\n",
      "gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-1m/all/ml-1m-ratings-train-09-of-10.tfrecord\n",
      "gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-1m/all/ml-1m-ratings-train-10-of-10.tfrecord\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls gs://$BUCKET_NAME/$DATA_GCS_PREFIX/all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7bfffc-c431-4020-9ea2-42525dba22b5",
   "metadata": {},
   "source": [
    "### copy subset to train subfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c3ad4db7-458c-4680-9335-2689b285dd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml-1m-ratings-train-01-of-10.tfrecord\n",
      "ml-1m-ratings-train-02-of-10.tfrecord\n",
      "ml-1m-ratings-train-03-of-10.tfrecord\n",
      "ml-1m-ratings-train-04-of-10.tfrecord\n",
      "ml-1m-ratings-train-05-of-10.tfrecord\n",
      "ml-1m-ratings-train-06-of-10.tfrecord\n",
      "ml-1m-ratings-train-07-of-10.tfrecord\n",
      "ml-1m-ratings-train-08-of-10.tfrecord\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, (NUM_SHARDS-1)):\n",
    "    TF_RECORD_FILE = f\"ml-{DATA_TAG}-ratings-train-{str(i).zfill(2)}-of-{NUM_SHARDS}.tfrecord\"\n",
    "    print(TF_RECORD_FILE)\n",
    "    \n",
    "    ! gsutil -q cp gs://$BUCKET_NAME/$DATA_GCS_PREFIX/all/$TF_RECORD_FILE gs://$BUCKET_NAME/$DATA_GCS_PREFIX/train/$TF_RECORD_FILE\n",
    "    ! rm ./$TF_RECORD_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f10fe84-7589-4f5d-b3e0-3c0d658a164d",
   "metadata": {},
   "source": [
    "### copy subset to val subfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "27577a07-973c-4104-a5d5-7ae07ac6f76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml-1m-ratings-train-09-of-10.tfrecord\n",
      "ml-1m-ratings-train-10-of-10.tfrecord\n"
     ]
    }
   ],
   "source": [
    "for i in range((NUM_SHARDS-1), (NUM_SHARDS+1)):\n",
    "    TF_RECORD_FILE = f\"ml-{DATA_TAG}-ratings-train-{str(i).zfill(2)}-of-{NUM_SHARDS}.tfrecord\"\n",
    "    print(TF_RECORD_FILE)\n",
    "    \n",
    "    ! gsutil -q cp gs://$BUCKET_NAME/$DATA_GCS_PREFIX/all/$TF_RECORD_FILE gs://$BUCKET_NAME/$DATA_GCS_PREFIX/val/$TF_RECORD_FILE\n",
    "    ! rm ./$TF_RECORD_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a150e2-29c1-42e5-b513-85f6b27bafd6",
   "metadata": {},
   "source": [
    "### validate TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "afdbc480-8977-4caf-b08f-29a665ef3f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-1m/all/ml-1m-ratings-train-01-of-10.tfrecord',\n",
       " 'gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-1m/all/ml-1m-ratings-train-02-of-10.tfrecord',\n",
       " 'gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-1m/all/ml-1m-ratings-train-03-of-10.tfrecord',\n",
       " 'gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-1m/all/ml-1m-ratings-train-04-of-10.tfrecord',\n",
       " 'gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-1m/all/ml-1m-ratings-train-05-of-10.tfrecord',\n",
       " 'gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-1m/all/ml-1m-ratings-train-06-of-10.tfrecord',\n",
       " 'gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-1m/all/ml-1m-ratings-train-07-of-10.tfrecord',\n",
       " 'gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-1m/all/ml-1m-ratings-train-08-of-10.tfrecord',\n",
       " 'gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-1m/all/ml-1m-ratings-train-09-of-10.tfrecord',\n",
       " 'gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-1m/all/ml-1m-ratings-train-10-of-10.tfrecord']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files = []\n",
    "for blob in storage_client.list_blobs(\n",
    "    f\"{BUCKET_NAME}\",\n",
    "    prefix=f\"{DATA_GCS_PREFIX}/all/\",\n",
    "    # delimiter='/'\n",
    "):\n",
    "    if \".tfrecord\" in blob.name:\n",
    "        train_files.append(\n",
    "            blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\")\n",
    "        )\n",
    "\n",
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7bde3b62-cf77-4750-ab69-47638cbc7184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a1cb0935-4de2-4812-a983-414ca17755cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([35.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[0]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'3107'], dtype=object)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([977432193])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'130'], dtype=object)>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'technician/engineer'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([5.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(data_utils.parse_tfrecord)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ecfc599-498a-4c9e-9737-ec1cdacdd1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 4., 5.], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the unique movies and users\n",
    "unique_user_ratings = train_dataset.map(lambda x: x[\"user_rating\"])\n",
    "\n",
    "unique_user_ratings = np.unique([x.numpy() for x in unique_user_ratings])\n",
    "\n",
    "unique_user_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add6d7f1-aa8a-4459-8d7a-e8f6363edede",
   "metadata": {},
   "source": [
    "### Generate look-up dicts\n",
    "\n",
    "**TODO** - use more Tensorflow native method for generating vocabs and stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73e451f-865d-4614-a77d-a1ef1dce0714",
   "metadata": {},
   "source": [
    "#### unique movie IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8b468833-642b-436f-8ddb-692f9221e38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(movie_id_vocab) : 3707\n",
      "movie_id_vocab      : ['[UNK]', '2858']\n"
     ]
    }
   ],
   "source": [
    "# # Get the unique movies and users\n",
    "# unique_movie_ids = train_dataset.map(lambda x: x[\"movie_id\"])\n",
    "# unique_movie_ids = np.unique([x.numpy().decode('utf-8') for x in unique_movie_ids])\n",
    "\n",
    "movie_id_lookup = tf.keras.layers.StringLookup()\n",
    "movie_id_lookup.adapt(train_dataset.map(lambda x: x[\"movie_id\"]))\n",
    "movie_id_vocab = movie_id_lookup.get_vocabulary()\n",
    "\n",
    "MOVIELENS_NUM_MOVIES = len(movie_id_vocab)\n",
    "\n",
    "print(f\"len(movie_id_vocab) : {len(movie_id_vocab)}\")\n",
    "print(f\"movie_id_vocab      : {movie_id_vocab[:2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a66d97-faf4-490a-b130-fb583b89503c",
   "metadata": {},
   "source": [
    "#### unique user IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "089c1bf7-f5ac-4343-8dae-a8f1c908a9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_user_ids = train_dataset.map(lambda x: x[\"user_id\"])\n",
    "# unique_user_ids = np.unique([x.numpy().decode('utf-8') for x in unique_user_ids])\n",
    "\n",
    "unique_user_ids_lookup = tf.keras.layers.StringLookup()\n",
    "unique_user_ids_lookup.adapt(train_dataset.map(lambda x: x[\"user_id\"]))\n",
    "unique_user_ids_vocab = unique_user_ids_lookup.get_vocabulary()\n",
    "\n",
    "MOVIELENS_NUM_USERS = len(unique_user_ids_vocab)\n",
    "\n",
    "print(f\"len(unique_user_ids_vocab) : {len(unique_user_ids_vocab)}\")\n",
    "print(f\"unique_user_ids_vocab      : {unique_user_ids_vocab[:2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f6a7d1-e38a-489d-bb93-84a6632ef9d7",
   "metadata": {},
   "source": [
    "#### unique occupational_text values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3efd339-5391-4c86-9274-ae0775348f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(unique_occ_vocab) : 22\n",
      "unique_occ_vocab      : ['[UNK]', 'college/grad student']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique movies and users\n",
    "# unique_occ_ids = train_dataset.map(lambda x: x[\"user_occupation_text\"])\n",
    "# unique_occ_ids = np.unique([x.numpy().decode('utf-8') for x in unique_occ_ids])\n",
    "\n",
    "unique_occ_lookup = tf.keras.layers.StringLookup()\n",
    "unique_occ_lookup.adapt(train_dataset.map(lambda x: x[\"user_occupation_text\"]))\n",
    "unique_occ_vocab = unique_occ_lookup.get_vocabulary()\n",
    "\n",
    "NUM_OCCS = len(unique_occ_vocab)\n",
    "\n",
    "print(f\"len(unique_occ_vocab) : {len(unique_occ_vocab)}\")\n",
    "print(f\"unique_occ_vocab      : {unique_occ_vocab[:2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca63bcf-3b88-4c06-98c9-cde41d8e219b",
   "metadata": {},
   "source": [
    "#### unique user_age values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fde4bf-922a-433e-8825-7baedb472f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(unique_user_age) : 7\n",
      "unique_user_age      : [ 1. 18.]\n"
     ]
    }
   ],
   "source": [
    "unique_user_age = train_dataset.map(lambda x: x[\"bucketized_user_age\"])\n",
    "unique_user_age = np.unique([x.numpy() for x in unique_user_age])\n",
    "\n",
    "print(f\"len(unique_user_age) : {len(unique_user_age)}\")\n",
    "print(f\"unique_user_age      : {unique_user_age[:2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91c914e-166c-4805-8556-5a93baf2aef1",
   "metadata": {},
   "source": [
    "#### timestamp buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f10b141-525c-453f-92ba-cfaddee2deb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp_buckets: [9.56703932e+08 9.56793772e+08 9.56883613e+08]\n"
     ]
    }
   ],
   "source": [
    "max_timestamp = (\n",
    "    ratings.map(lambda x: x[\"timestamp\"])\n",
    "    .reduce(tf.cast(0, tf.int64), tf.maximum)\n",
    "    .numpy()\n",
    "    .max()\n",
    ")\n",
    "min_timestamp = (\n",
    "    ratings.map(lambda x: x[\"timestamp\"])\n",
    "    .reduce(np.int64(1e9), tf.minimum)\n",
    "    .numpy()\n",
    "    .min()\n",
    ")\n",
    "\n",
    "timestamp_buckets = np.linspace(min_timestamp, max_timestamp, num=1000)\n",
    "\n",
    "print(f\"timestamp_buckets: {timestamp_buckets[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b97d642-a432-4c87-8802-5b1687fffcea",
   "metadata": {},
   "source": [
    "#### unique movie genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445b1db9-2db2-44aa-8180-c1fb4c154456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(unique_movie_genres) : 18\n",
      "unique_movie_genres      : [0 1]\n"
     ]
    }
   ],
   "source": [
    "unique_movie_genres = train_dataset.map(lambda x: x[\"movie_genres\"])\n",
    "unique_movie_genres = np.unique([x.numpy() for x in unique_movie_genres])\n",
    "\n",
    "MOVIELENS_NUM_GENRES = len(unique_movie_genres)\n",
    "\n",
    "print(f\"len(unique_movie_genres) : {len(unique_movie_genres)}\")\n",
    "print(f\"unique_movie_genres      : {unique_movie_genres[:2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf54dbd-a253-4858-8e5c-3f9eb41547d8",
   "metadata": {},
   "source": [
    "### Write vocab dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc361a9-11ae-4ced-a830-06458be2f349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB_1M_GCS_PREFIX : data/movielens-1m\n"
     ]
    }
   ],
   "source": [
    "vocab_dict = {\n",
    "    \"movie_id\": movie_id_vocab,\n",
    "    \"user_id\": unique_user_ids_vocab,\n",
    "    \"user_occupation_text\": unique_occ_vocab,\n",
    "    \"movie_genres\": unique_movie_genres,\n",
    "    \"bucketized_user_age\": unique_user_age,\n",
    "    \"max_timestamp\": max_timestamp,\n",
    "    \"min_timestamp\": min_timestamp,\n",
    "    \"timestamp_buckets\": timestamp_buckets,\n",
    "}\n",
    "\n",
    "print(f\"DATA_GCS_PREFIX : {DATA_GCS_PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1cea08-4cfb-42d2-894c-f0531d2622d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_FILE_NAME = \"vocab_dict_1m.pkl\"\n",
    "filehandler = open(VOCAB_FILE_NAME, \"wb\")\n",
    "pkl.dump(vocab_dict, filehandler)\n",
    "\n",
    "filehandler.close()\n",
    "\n",
    "VOCAB_DEST_BLOB = f\"{DATA_GCS_PREFIX}/vocab_dict.pkl\"\n",
    "\n",
    "blob = bucket.blob(VOCAB_DEST_BLOB)\n",
    "blob.upload_from_filename(VOCAB_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e507fd5b-c398-41ea-8b5c-7a6b7e4886d2",
   "metadata": {},
   "source": [
    "### Create lookup dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17cf48c-e0e2-4d65-9b4b-25d7c50d0502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER_AGE_DIM: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1.0: 0, 35.0: 1, 45.0: 2, 18.0: 3, 50.0: 4, 56.0: 5, 25.0: 6}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USER_AGE_LOOKUP = data_utils.get_dictionary_lookup_by_tf_data_key(\n",
    "    key=\"bucketized_user_age\", dataset=train_dataset\n",
    ")\n",
    "\n",
    "USER_AGE_DIM = len(USER_AGE_LOOKUP)\n",
    "print(f\"USER_AGE_DIM: {USER_AGE_DIM}\")\n",
    "\n",
    "USER_AGE_LOOKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188f1142-c814-4f6f-9ae6-9dddeaa1005b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER_OCC_DIM: 21\n"
     ]
    }
   ],
   "source": [
    "USER_OCC_LOOKUP = data_utils.get_dictionary_lookup_by_tf_data_key(\n",
    "    key=\"user_occupation_text\", dataset=train_dataset\n",
    ")\n",
    "USER_OCC_DIM = len(USER_OCC_LOOKUP)\n",
    "print(f\"USER_OCC_DIM: {USER_OCC_DIM}\")\n",
    "\n",
    "# USER_OCC_LOOKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6aafa8-8550-417a-8a67-ff602d79c8c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOVIE_GEN_DIM: 18\n"
     ]
    }
   ],
   "source": [
    "MOVIE_GEN_LOOKUP = data_utils.get_dictionary_lookup_by_tf_data_key(\n",
    "    key=\"movie_genres\", dataset=train_dataset\n",
    ")\n",
    "MOVIE_GEN_DIM = len(MOVIE_GEN_LOOKUP)\n",
    "print(f\"MOVIE_GEN_DIM: {MOVIE_GEN_DIM}\")\n",
    "\n",
    "# MOVIE_GEN_LOOKUP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e68a8e3-c56c-40d8-9544-992e62488b3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Create `data_config_1m.py`\n",
    "\n",
    "> write data config for subsequent notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1557f99e-9fa4-4fd6-9c1b-96b42f9b353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = f\"\"\"\n",
    "USER_AGE_LOOKUP       = {USER_AGE_LOOKUP}\n",
    "USER_AGE_DIM          = {USER_AGE_DIM}\n",
    "\n",
    "USER_OCC_LOOKUP       = {USER_OCC_LOOKUP}\n",
    "USER_OCC_DIM          = {USER_OCC_DIM}\n",
    "\n",
    "MOVIE_GEN_LOOKUP      = {MOVIE_GEN_LOOKUP}\n",
    "MOVIE_GEN_DIM         = {MOVIE_GEN_DIM}\n",
    "\n",
    "MOVIELENS_NUM_MOVIES  = {MOVIELENS_NUM_MOVIES}\n",
    "MOVIELENS_NUM_USERS   = {MOVIELENS_NUM_USERS}\n",
    "\"\"\"\n",
    "\n",
    "with open(f\"{REPO_DOCKER_PATH_PREFIX}/{RL_SUB_DIR}/data_config_1m.py\", \"w\") as f:\n",
    "    f.write(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1c21b7-1778-486a-9cd8-048fc41df4f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [2] Validate Ratings Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4ca765-7c25-43c6-8191-68e06360cb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.per_arm_rl import data_config_1m as data_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b07ca7-f609-46cf-8234-6ceb4e4c1fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: 0, 35.0: 1, 45.0: 2, 18.0: 3, 50.0: 4, 56.0: 5, 25.0: 6}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_config.USER_AGE_LOOKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5625bfa-c1b8-4fc0-8c91-1f9569ce84ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'clerical/admin': 0,\n",
       " b'other/not specified': 1,\n",
       " b'doctor/health care': 2,\n",
       " b'college/grad student': 3,\n",
       " b'writer': 4,\n",
       " b'lawyer': 5,\n",
       " b'tradesman/craftsman': 6,\n",
       " b'scientist': 7,\n",
       " b'farmer': 8,\n",
       " b'technician/engineer': 9,\n",
       " b'programmer': 10,\n",
       " b'unemployed': 11,\n",
       " b'K-12 student': 12,\n",
       " b'executive/managerial': 13,\n",
       " b'sales/marketing': 14,\n",
       " b'self-employed': 15,\n",
       " b'academic/educator': 16,\n",
       " b'retired': 17,\n",
       " b'customer service': 18,\n",
       " b'artist': 19,\n",
       " b'homemaker': 20}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_config.USER_OCC_LOOKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b19bdd-1564-4781-b1b9-6a2bef3fab93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 1,\n",
       " 2: 2,\n",
       " 3: 3,\n",
       " 4: 4,\n",
       " 5: 5,\n",
       " 6: 6,\n",
       " 7: 7,\n",
       " 8: 8,\n",
       " 9: 9,\n",
       " 10: 10,\n",
       " 12: 11,\n",
       " 13: 12,\n",
       " 14: 13,\n",
       " 15: 14,\n",
       " 16: 15,\n",
       " 18: 16,\n",
       " 19: 17}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_config.MOVIE_GEN_LOOKUP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca361ffc-36ea-4cc2-8286-7aa5ee2f3288",
   "metadata": {},
   "source": [
    "## Load movielens rating matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9075e0d2-01a5-49a7-a422-8a66be6afebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec={'user_id': TensorSpec(shape=(), dtype=tf.string, name=None), 'movie_id': TensorSpec(shape=(), dtype=tf.string, name=None), 'user_rating': TensorSpec(shape=(), dtype=tf.float32, name=None), 'bucketized_user_age': TensorSpec(shape=(), dtype=tf.float32, name=None), 'user_occupation_text': TensorSpec(shape=(), dtype=tf.string, name=None), 'movie_genres': TensorSpec(shape=(), dtype=tf.int64, name=None)}>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_data = train_dataset.map(\n",
    "    lambda x: {\n",
    "        \"user_id\": x[\"user_id\"],\n",
    "        \"movie_id\": x[\"movie_id\"],\n",
    "        \"user_rating\": x[\"user_rating\"],\n",
    "        \"bucketized_user_age\": x[\"bucketized_user_age\"],\n",
    "        \"user_occupation_text\": x[\"user_occupation_text\"],\n",
    "        \"movie_genres\": x[\"movie_genres\"][0],\n",
    "    }\n",
    ")\n",
    "local_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfbfb4b-731c-4ff3-80dd-5810bfc26f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_matrix = np.zeros(\n",
    "    [data_config.MOVIELENS_NUM_USERS, data_config.MOVIELENS_NUM_MOVIES]\n",
    ")\n",
    "ratings_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027560e1-db7a-4805-b6de-18a86884c99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_age_int = []\n",
    "user_occ_int = []\n",
    "mov_gen_int = []\n",
    "\n",
    "for row in local_data:\n",
    "    ratings_matrix[\n",
    "        int(row[\"user_id\"].numpy()) - 1, int(row[\"movie_id\"].numpy()) - 1\n",
    "    ] = float(row[\"user_rating\"].numpy())\n",
    "\n",
    "    user_age_int.append(\n",
    "        float(data_config.USER_AGE_LOOKUP[row[\"bucketized_user_age\"].numpy()]) + 0.0001\n",
    "    )\n",
    "    user_occ_int.append(\n",
    "        float(data_config.USER_OCC_LOOKUP[row[\"user_occupation_text\"].numpy()]) + 0.0001\n",
    "    )\n",
    "    mov_gen_int.append(\n",
    "        float(data_config.MOVIE_GEN_LOOKUP[row[\"movie_genres\"].numpy()]) + 0.0001\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a963e007-56bb-4830-9826-b854e80e1bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 3., 4., ..., 0., 0., 0.],\n",
       "       [4., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 5., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457a53f5-ad3a-4559-a70f-a7c3aee6b6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.0001, 6.0001, 3.0001, ..., 3.0001, 1.0001, 3.0001])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(user_age_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddac0e4-18e8-4b1b-ac86-42a608ad471b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.0001,  7.0001, 10.0001, ..., 10.0001,  2.0001, 10.0001])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(user_occ_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aace75-55bc-4538-91be-422b88e5409d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.00010e+00, 4.00010e+00, 4.00010e+00, ..., 1.00001e+01,\n",
       "       1.00000e-04, 4.00010e+00])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(mov_gen_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d313edbf-7e38-4b6c-8b72-7b8e607a70fa",
   "metadata": {},
   "source": [
    "The commands above are executed when calling the `load_movielens_ratings()` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9d1512-9318-46dd-999d-f87f9c9d9b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num outputs: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[5., 3., 4., ..., 0., 0., 0.],\n",
       "        [4., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [5., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 5., 0., ..., 0., 0., 0.]]),\n",
       " array([2.0001, 6.0001, 3.0001, ..., 3.0001, 1.0001, 3.0001]),\n",
       " array([14.0001,  7.0001, 10.0001, ..., 10.0001,  2.0001, 10.0001]),\n",
       " array([7.00010e+00, 4.00010e+00, 4.00010e+00, ..., 1.00001e+01,\n",
       "        1.00000e-04, 4.00010e+00]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_load = data_utils.load_movielens_ratings(\n",
    "    ratings_dataset=train_dataset,\n",
    "    num_users=data_config.MOVIELENS_NUM_USERS,\n",
    "    num_movies=data_config.MOVIELENS_NUM_MOVIES,\n",
    "    user_age_lookup_dict=data_config.USER_AGE_LOOKUP,\n",
    "    user_occ_lookup_dict=data_config.USER_OCC_LOOKUP,\n",
    "    movie_gen_lookup_dict=data_config.MOVIE_GEN_LOOKUP,\n",
    ")\n",
    "\n",
    "print(f\"num outputs: {len(test_dataset_load)}\")\n",
    "\n",
    "test_dataset_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51ae0c6-e5d1-4982-99ac-4a538d6e0315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 1682)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5., 3., 4., ..., 0., 0., 0.],\n",
       "       [4., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 5., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_matrix = test_dataset_load[0]\n",
    "print(ratings_matrix.shape)\n",
    "ratings_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55014ae-fc94-4a1a-a2dd-fde3970b5387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.0001, 6.0001, 3.0001, ..., 3.0001, 1.0001, 3.0001])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_age_int = test_dataset_load[1]\n",
    "print(user_age_int[0])\n",
    "user_age_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6118d665-03c8-4456-aa83-4364a0da4653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.0001 20.0001 10.0001 ... 10.0001 13.0001 10.0001]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 6.0001, 20.0001, 10.0001, ..., 10.0001, 13.0001, 10.0001])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_occ_int = test_dataset_load[2]\n",
    "print(user_occ_int)\n",
    "user_occ_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa20d27-8719-4d60-bc71-75398cf0c298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.00010e+00 4.00010e+00 4.00010e+00 ... 1.00001e+01 1.00000e-04\n",
      " 4.00010e+00]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7.00010e+00, 4.00010e+00, 4.00010e+00, ..., 1.00001e+01,\n",
       "       1.00000e-04, 4.00010e+00])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mov_gen_int = test_dataset_load[3]\n",
    "print(mov_gen_int)\n",
    "mov_gen_int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9370b8-85fb-420d-8812-a01c7f6baa94",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [3] Ranking Data (listwise)\n",
    "\n",
    "> TODO: clean-up / optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8666a2f8-5f7f-41e2-9820-c3aebaf52bc6",
   "metadata": {},
   "source": [
    "**define how many items should be in each example's item list:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3962a8a1-63a4-4149-86fb-bd57b3356ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EXAMPLES_PER_LIST = 5  # 3 | 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25889912-d06e-4274-871b-a11983b77ee5",
   "metadata": {},
   "source": [
    "**write this value to config file for `data_util` functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89edf12-be15-4977-ab9b-cf64848aafe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = f\"\"\"\n",
    "NUM_EXAMPLES_PER_LIST = {NUM_EXAMPLES_PER_LIST}\n",
    "\"\"\"\n",
    "# TODO - cleanup\n",
    "with open(f\"{REPO_DOCKER_PATH_PREFIX}/{RL_SUB_DIR}/utils_config.py\", \"w\") as f:\n",
    "    f.write(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177ca352-a258-4f38-b83e-ade22469e261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.per_arm_rl import utils_config as utils_config\n",
    "\n",
    "utils_config.NUM_EXAMPLES_PER_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be676f8b-8f0a-40a7-813f-ff610c0de51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = shuffled.take(80_000)\n",
    "# val = shuffled.skip(80_000).take(20_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ca0a4e-7fb8-4abf-909b-6edae99bae00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([35.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'898'], dtype=object)>,\n",
      " 'movie_title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Postman, The (1997)'], dtype=object)>,\n",
      " 'raw_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([44.], dtype=float32)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([885409515])>,\n",
      " 'user_gender': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'681'], dtype=object)>,\n",
      " 'user_occupation_label': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([14])>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'marketing'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>,\n",
      " 'user_zip_code': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'97208'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "for x in train.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39d0a02-f38a-4497-9ae5-e0408c316c20",
   "metadata": {},
   "source": [
    "## Create train listwise ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ba907a-5896-4019-897c-883d97e8193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EXAMPLES_PER_LIST = 5  # 3 | 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9557d1-8a83-484b-a0ce-0c9bbf5cad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = f\"\"\"\n",
    "NUM_EXAMPLES_PER_LIST = {NUM_EXAMPLES_PER_LIST}\n",
    "\"\"\"\n",
    "# TODO - cleanup\n",
    "with open(f\"{REPO_DOCKER_PATH_PREFIX}/{RL_SUB_DIR}/utils_config.py\", \"w\") as f:\n",
    "    f.write(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb90fe01-754b-41bb-b3e8-a4cfa3e432be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.per_arm_rl import utils_config as utils_config\n",
    "\n",
    "utils_config.NUM_EXAMPLES_PER_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35020d6c-1f95-4889-a53a-a834e90a41aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We sample 50 lists for each user for the training data. For each list we\n",
    "# sample (3 | 5) movies from the movies the user rated.\n",
    "train_lw = data_utils.create_listwise_ds(\n",
    "    train, num_list_per_user=50, num_examples_per_list=NUM_EXAMPLES_PER_LIST, seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3072352-812f-4694-91a9-dd35ae2de309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_genres': <tf.Tensor: shape=(5,), dtype=int64, numpy=array([4, 7, 7, 2, 7])>,\n",
      " 'movie_id': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'294', b'690', b'1176', b'538', b'310'], dtype=object)>,\n",
      " 'user_id': <tf.Tensor: shape=(), dtype=string, numpy=b'681'>,\n",
      " 'user_rating': <tf.Tensor: shape=(5,), dtype=float32, numpy=array([5., 4., 4., 3., 3.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "for example in train_lw.skip(7).take(1):\n",
    "    pprint(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbd2831-131b-4642-8f90-88a4387cf6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 4., 4., 3., 3.], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[\"user_rating\"].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a66defc-80ec-4de0-8a73-fa53034aa30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47150"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(train_lw))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c0a366-d55c-4ff4-899a-afc4c4e4c42b",
   "metadata": {},
   "source": [
    "### write TF records file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c866a87-a3a3-43eb-8ff4-4ccc00380fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://rec-bandits-v2-hybrid-vertex-bucket/data'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837454ff-2770-4e05-a6dd-1b0709101207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train split\n",
    "TF_RECORD_FILE_lw_train = f\"ml-100k-listwise-{NUM_EXAMPLES_PER_LIST}n-train.tfrecord\"\n",
    "LOCAL_TF_RECORD_lw_train = f\"./{TF_RECORD_FILE_lw_train}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75505dad-4ca8-44ab-9581-81c76d52dd49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_utils.write_tfrecords(LOCAL_TF_RECORD_lw_train, train_lw, list_wise=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc397923-11fd-49ee-b2ff-4776552cd347",
   "metadata": {},
   "source": [
    "#### validate TRAIN TF record file(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49743b94-b06c-416f-b696-f11e784fcdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_genres': <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[ 7,  4,  7,  7, 10]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1, 5), dtype=string, numpy=array([[b'898', b'294', b'258', b'1176', b'682']], dtype=object)>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'681'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[4., 5., 1., 4., 1.]], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "# test TF record local\n",
    "tmp_lw_dataset = tf.data.TFRecordDataset(LOCAL_TF_RECORD_lw_train)\n",
    "tmp_lw_dataset = tmp_lw_dataset.map(data_utils.parse_lw_tfrecord)\n",
    "\n",
    "for x in tmp_lw_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992a5f12-0c15-45e5-82c0-0bccb20cefad",
   "metadata": {},
   "outputs": [],
   "source": [
    "lw_train_prefix = f\"{DATA_GCS_PREFIX}/listwise-{NUM_EXAMPLES_PER_LIST}n-train\"\n",
    "LW_TRAIN_DATA_PATH = f\"{BUCKET_URI}/{lw_train_prefix}\"\n",
    "\n",
    "! gsutil -q cp $LOCAL_TF_RECORD_lw_train $LW_TRAIN_DATA_PATH/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17020338-10aa-4a4d-8da3-535f6f397c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/listwise-5n-train/ml-100k-listwise-5n-train.tfrecord\n"
     ]
    }
   ],
   "source": [
    "# ! gsutil ls $LW_TRAIN_DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b15949-e614-4ecb-abd2-3a21703ccd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_genres': <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[ 7,  4,  7,  7, 10]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1, 5), dtype=string, numpy=array([[b'898', b'294', b'258', b'1176', b'682']], dtype=object)>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'681'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[4., 5., 1., 4., 1.]], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "test_lw_files = []\n",
    "\n",
    "for blob in storage_client.list_blobs(\n",
    "    f\"{BUCKET_NAME}\", prefix=f\"{lw_train_prefix}/\", delimiter=\"/\"\n",
    "):\n",
    "    if \".tfrecord\" in blob.name:\n",
    "        test_lw_files.append(\n",
    "            blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\")\n",
    "        )\n",
    "\n",
    "tmp_lw_dataset = tf.data.TFRecordDataset(test_lw_files)\n",
    "tmp_lw_dataset = tmp_lw_dataset.map(data_utils.parse_lw_tfrecord)\n",
    "\n",
    "for x in tmp_lw_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca0e367-c23a-4d60-bfb5-9a208fb0fde7",
   "metadata": {},
   "source": [
    "## Create val listwise ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921fd852-a329-4c49-956c-042ae6bdd763",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_lw = data_utils.create_listwise_ds(\n",
    "    val, num_list_per_user=1, num_examples_per_list=NUM_EXAMPLES_PER_LIST, seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b08ef32-f3e9-475b-937f-40c44d784a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_genres': <tf.Tensor: shape=(5,), dtype=int64, numpy=array([ 3,  0,  0,  0, 19])>,\n",
      " 'movie_id': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'94', b'245', b'403', b'50', b'470'], dtype=object)>,\n",
      " 'user_id': <tf.Tensor: shape=(), dtype=string, numpy=b'346'>,\n",
      " 'user_rating': <tf.Tensor: shape=(5,), dtype=float32, numpy=array([3., 4., 3., 5., 3.], dtype=float32)>}\n",
      "{'movie_genres': <tf.Tensor: shape=(5,), dtype=int64, numpy=array([7, 0, 0, 2, 7])>,\n",
      " 'movie_id': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'678', b'127', b'343', b'1', b'125'], dtype=object)>,\n",
      " 'user_id': <tf.Tensor: shape=(), dtype=string, numpy=b'602'>,\n",
      " 'user_rating': <tf.Tensor: shape=(5,), dtype=float32, numpy=array([4., 5., 2., 4., 4.], dtype=float32)>}\n",
      "{'movie_genres': <tf.Tensor: shape=(5,), dtype=int64, numpy=array([4, 7, 4, 0, 4])>,\n",
      " 'movie_id': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'168', b'1053', b'26', b'110', b'1048'], dtype=object)>,\n",
      " 'user_id': <tf.Tensor: shape=(), dtype=string, numpy=b'393'>,\n",
      " 'user_rating': <tf.Tensor: shape=(5,), dtype=float32, numpy=array([4., 3., 3., 2., 3.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "for example in val_lw.take(3):\n",
    "    pprint(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb5890e-61dc-4fd8-9375-a4bf7e1342c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "836"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(val_lw))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3017c7bb-0ec1-4685-bca0-c08e4cd0bdf7",
   "metadata": {},
   "source": [
    "### write TF records file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9897b50e-f67d-4f4f-8103-bae419f3976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val split\n",
    "TF_RECORD_FILE_lw_val = f\"ml-100k-listwise-{NUM_EXAMPLES_PER_LIST}n-val.tfrecord\"\n",
    "LOCAL_TF_RECORD_lw_val = f\"./{TF_RECORD_FILE_lw_val}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4bc5df-8dca-479a-85e0-2f21379b564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_utils.write_tfrecords(LOCAL_TF_RECORD_lw_val, val_lw, list_wise=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115ddf56-345d-4bc6-835f-7461b56f14a0",
   "metadata": {},
   "source": [
    "#### validate VAL TF record file(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efbcd84-ae93-4da9-a9de-3d2cd8442492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_genres': <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[ 3,  0,  0,  0, 19]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1, 5), dtype=string, numpy=array([[b'94', b'245', b'403', b'50', b'470']], dtype=object)>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'346'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[3., 4., 3., 5., 3.]], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "# test TF record local\n",
    "tmp_lw_dataset = tf.data.TFRecordDataset(LOCAL_TF_RECORD_lw_val)\n",
    "tmp_lw_dataset = tmp_lw_dataset.map(data_utils.parse_lw_tfrecord)\n",
    "\n",
    "for x in tmp_lw_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d7b22f-e126-468a-9cc1-6189a842027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lw_val_prefix = f\"{DATA_GCS_PREFIX}/listwise-{NUM_EXAMPLES_PER_LIST}n-val\"\n",
    "LW_VAL_DATA_PATH = f\"{BUCKET_URI}/{lw_val_prefix}\"\n",
    "\n",
    "! gsutil -q cp $LOCAL_TF_RECORD_lw_val $LW_VAL_DATA_PATH/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c73ec4-9b52-480d-bab8-df43e45b590f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/listwise-5n-val/ml-100k-listwise-5n-val.tfrecord\n"
     ]
    }
   ],
   "source": [
    "# ! gsutil ls $LW_VAL_DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de7724b-dd51-48c0-b4aa-646818378ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_genres': <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[ 3,  0,  0,  0, 19]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1, 5), dtype=string, numpy=array([[b'94', b'245', b'403', b'50', b'470']], dtype=object)>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'346'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[3., 4., 3., 5., 3.]], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "test_lw_files = []\n",
    "\n",
    "for blob in storage_client.list_blobs(\n",
    "    f\"{BUCKET_NAME}\", prefix=f\"{lw_val_prefix}/\", delimiter=\"/\"\n",
    "):\n",
    "    if \".tfrecord\" in blob.name:\n",
    "        test_lw_files.append(\n",
    "            blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\")\n",
    "        )\n",
    "\n",
    "tmp_lw_dataset = tf.data.TFRecordDataset(test_lw_files)\n",
    "tmp_lw_dataset = tmp_lw_dataset.map(data_utils.parse_lw_tfrecord)\n",
    "\n",
    "for x in tmp_lw_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54154d91-333e-4c13-a11f-4fa1c2340255",
   "metadata": {},
   "source": [
    "### get uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd916482-424b-487f-aaa1-b2f100eed877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1682"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = ratings.map(lambda x: x[\"movie_id\"])\n",
    "unique_movie_ids = np.unique(np.concatenate(list(movies.batch(1000))))\n",
    "\n",
    "len(unique_movie_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742fb9ac-78c9-4175-8e8b-b96eef9d6388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = ratings.map(lambda x: x[\"user_id\"])\n",
    "\n",
    "unique_user_ids = np.unique(np.concatenate(list(users.batch(1000))))\n",
    "\n",
    "len(unique_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b05684-7d78-432b-a429-f079b7adf8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gsutil -m cp -r gs://$BUCKET_NAME/$DATA_GCS_PREFIX/train gs://$BUCKET_NAME/$DATA_GCS_PREFIX/train_v1\n",
    "# ! gsutil -m cp -r gs://$BUCKET_NAME/$DATA_GCS_PREFIX/val gs://$BUCKET_NAME/$DATA_GCS_PREFIX/val_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e727db-1123-4e62-ab21-8d42ab03d603",
   "metadata": {},
   "source": [
    "# Done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb75da56-1c5f-43a6-9e8a-6550b3769ba1",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
