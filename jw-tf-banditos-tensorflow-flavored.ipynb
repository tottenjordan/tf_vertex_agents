{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "525b561f-77f5-4736-927f-19929674b868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tf-agents --user -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba0048de-0245-40d9-9ad0-e85793329ce2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-agents==0.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep tf-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53da2313-9daf-4662-8d9b-93b813d2a4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1112bb5e-0151-418f-9d17-eb17ee191788",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "\n",
    "from tf_agents.bandits.agents import lin_ucb_agent\n",
    "from tf_agents.bandits.environments import stationary_stochastic_per_arm_py_environment as p_a_env\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "import tensorflow_datasets as tfds\n",
    "from pprint import pprint\n",
    "\n",
    "nest = tf.nest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dac1a89-b58b-4d4b-92ba-e70d9ed80a96",
   "metadata": {},
   "source": [
    "### movies data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03eb6ba1-8cae-41f6-b65a-31d18165fe69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[4]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'1681'], dtype=object)>,\n",
      " 'movie_title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'You So Crazy (1994)'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")\n",
    "\n",
    "for x in movies.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9c9413-3aa8-4188-b5a2-b342ef50faf2",
   "metadata": {},
   "source": [
    "### user and ratings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92dbdb4b-8f13-4455-887c-6617ebd80242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([45.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'357'], dtype=object)>,\n",
      " 'movie_title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"One Flew Over the Cuckoo's Nest (1975)\"], dtype=object)>,\n",
      " 'raw_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([46.], dtype=float32)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([879024327])>,\n",
      " 'user_gender': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'138'], dtype=object)>,\n",
      " 'user_occupation_label': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([4])>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'doctor'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>,\n",
      " 'user_zip_code': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'53211'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "\n",
    "for x in ratings.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7941678d-f920-4206-9fea-d8e3e9f15cef",
   "metadata": {},
   "source": [
    "#### Let's make this simple and load up movielens that has features\n",
    "We will only consider for this example\n",
    "1) The movie genere as an Arm feature (we will concatenate multiple genres)\n",
    "2) The user occupation and age bucket labels for the overall context features\n",
    "\n",
    "We need to load the data, get the ratings - light EDA for us to get cardnality of the dataset as well as lookups for the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a4c8c8c-6e55-4140-86e7-701308154762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(unique_movie_ids) : 1682\n",
      "unique_movie_ids      : [b'1' b'10']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique movies and users\n",
    "unique_movie_ids = ratings.map(lambda x: x[\"movie_id\"])\n",
    "unique_movie_ids = np.unique([x.numpy() for x in unique_movie_ids])\n",
    "MOVIELENS_NUM_MOVIES = len(unique_movie_ids)\n",
    "\n",
    "\n",
    "print(f\"len(unique_movie_ids) : {len(unique_movie_ids)}\")\n",
    "print(f\"unique_movie_ids      : {unique_movie_ids[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bc12022-129d-48df-8cb3-7e53dbbbfea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(unique_user_ids) : 943\n",
      "unique_user_ids      : [b'1' b'10']\n"
     ]
    }
   ],
   "source": [
    "unique_user_ids = ratings.map(lambda x: x[\"user_id\"])\n",
    "unique_user_ids = np.unique([x.numpy() for x in unique_user_ids])\n",
    "MOVIELENS_NUM_USERS = len(unique_user_ids)\n",
    "\n",
    "\n",
    "print(f\"len(unique_user_ids) : {len(unique_user_ids)}\")\n",
    "print(f\"unique_user_ids      : {unique_user_ids[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cef8a89-0e97-4d93-819e-db2d4667efa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the unnique set of user buckets and create a lookup table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "174860eb-bfeb-4b02-b4d9-1dfaddc70914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def get_dictionary_lookup_by_tf_data_key(key: str) -> Dict:\n",
    "    tensor = ratings.map(lambda x: x[key])\n",
    "    unique_elems = set()\n",
    "    for x in tensor:\n",
    "        val = x.numpy()\n",
    "        if type(val) is np.ndarray: # if multi dimesnional only grab first one\n",
    "            val = val[0]\n",
    "        unique_elems.add(val)\n",
    "    \n",
    "    #return a dictionary of keys by integer values for the feature space\n",
    "    return {val: i for i, val in enumerate(unique_elems)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8113ded-13f2-460f-a2cd-90f44307f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_age_lookup = get_dictionary_lookup_by_tf_data_key('bucketized_user_age')\n",
    "user_age_dim = len(user_age_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bed813e8-cef5-46e0-a1d5-3f6c37ea34a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: 0, 35.0: 1, 45.0: 2, 18.0: 3, 50.0: 4, 56.0: 5, 25.0: 6}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_age_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ced8d46-9e1d-4d88-9228-cb57005d064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_occ_lookup = get_dictionary_lookup_by_tf_data_key('user_occupation_text')\n",
    "user_occ_dim = len(user_occ_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "820171f0-4784-4c61-b101-d3c9ae78f7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'student': 0,\n",
       " b'librarian': 1,\n",
       " b'executive': 2,\n",
       " b'other': 3,\n",
       " b'marketing': 4,\n",
       " b'artist': 5,\n",
       " b'healthcare': 6,\n",
       " b'programmer': 7,\n",
       " b'engineer': 8,\n",
       " b'homemaker': 9,\n",
       " b'scientist': 10,\n",
       " b'doctor': 11,\n",
       " b'entertainment': 12,\n",
       " b'lawyer': 13,\n",
       " b'administrator': 14,\n",
       " b'none': 15,\n",
       " b'retired': 16,\n",
       " b'writer': 17,\n",
       " b'educator': 18,\n",
       " b'technician': 19,\n",
       " b'salesman': 20}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_occ_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca8fa3dc-1144-4fff-8a03-eacb600d58a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_gen_lookup = get_dictionary_lookup_by_tf_data_key('movie_genres')\n",
    "movie_gen_dim = len(movie_gen_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7adf6f0-6842-4777-8cfe-65953dae96f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 1,\n",
       " 2: 2,\n",
       " 3: 3,\n",
       " 4: 4,\n",
       " 5: 5,\n",
       " 6: 6,\n",
       " 7: 7,\n",
       " 8: 8,\n",
       " 9: 9,\n",
       " 10: 10,\n",
       " 12: 11,\n",
       " 13: 12,\n",
       " 14: 13,\n",
       " 15: 14,\n",
       " 16: 15,\n",
       " 17: 16,\n",
       " 18: 17,\n",
       " 19: 18}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_gen_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b571a4e9-60ef-4e06-98b3-017fec36d36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REFACTOR BELOW\n",
    " #from https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/environments/dataset_utilities.py#L153\n",
    "    \n",
    "# def load_movielens_data(data_file, delimiter=','):\n",
    "#     \"\"\"Loads the movielens data and returns the ratings matrix.\"\"\"\n",
    "#     ratings_matrix = np.zeros([MOVIELENS_NUM_USERS, MOVIELENS_NUM_MOVIES])\n",
    "#     with tf.io.gfile.GFile(data_file, 'r') as infile:\n",
    "#     # The file is a csv with rows containing:\n",
    "#     # user id | item id | rating | timestamp\n",
    "#     reader = csv.reader(infile, delimiter=delimiter)\n",
    "#     for row in reader:\n",
    "#         user_id, item_id, rating, _ = row\n",
    "#         ratings_matrix[int(user_id) - 1, int(item_id) - 1] = float(rating)\n",
    "#     return ratings_matrix\n",
    "\n",
    "\n",
    "\n",
    "def load_movielens_data(ratings_dataset):\n",
    "    # ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "    ratings_matrix = np.zeros([MOVIELENS_NUM_USERS, MOVIELENS_NUM_MOVIES])\n",
    "    local_data = ratings_dataset.map(lambda x: {'user_id': x['user_id']\n",
    "                                                 ,'movie_id':  x['movie_id']\n",
    "                                                 ,'user_rating':  x['user_rating']\n",
    "                                                 ,'bucketized_user_age': x['bucketized_user_age']\n",
    "                                                 ,'user_occupation_text': x['user_occupation_text']\n",
    "                                                 ,'movie_genres': x['movie_genres'][0]\n",
    "                                               }\n",
    "                                                                         )\n",
    "    user_age_int = []\n",
    "    user_occ_int = []\n",
    "    mov_gen_int = []\n",
    "    for row in local_data:\n",
    "        ratings_matrix[int(row['user_id'].numpy()) - 1, int(row['movie_id'].numpy()) - 1] = float(row['user_rating'].numpy())\n",
    "        user_age_int.append(user_age_lookup[row['bucketized_user_age'].numpy()])\n",
    "        user_occ_int.append(user_occ_lookup[row['user_occupation_text'].numpy()])\n",
    "        mov_gen_int.append(movie_gen_lookup[row['movie_genres'].numpy()])\n",
    "    return tf.convert_to_tensor(ratings_matrix, dtype=tf.float32), tf.convert_to_tensor(np.array(user_age_int), dtype=tf.float32), tf.convert_to_tensor(np.array(user_occ_int), dtype=tf.float32), tf.convert_to_tensor(np.array(mov_gen_int), dtype=tf.float32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50806cc4-f345-471f-9622-4201303c8679",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_matrix, user_age_int, user_occ_int, mov_gen_int = load_movielens_data(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "848e948c-8fe2-4c95-9779-3e90d9dcc83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_user_indices_np = np.random.randint(\n",
    "            1000, size=8)\n",
    "sampled_user_indices = tf.convert_to_tensor(sampled_user_indices_np, dtype=tf.int32)\n",
    "sampled_user_indices = np.expand_dims(sampled_user_indices,axis=-1) #expand out to individual indicies to match sizes for slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57fc1fb7-ab98-4b29-a4c6-96a9068e22fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[189],\n",
       "       [188],\n",
       "       [336],\n",
       "       [284],\n",
       "       [ 37],\n",
       "       [364],\n",
       "       [903],\n",
       "       [878]], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_user_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ece6c16-5c0a-47bd-817b-892c6321b4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_user_ages = tf.gather_nd(indices=sampled_user_indices\n",
    "                                         , params=user_age_int\n",
    "                                         , batch_dims=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5837bd49-b761-4c16-8949-1c496a2e3a9e",
   "metadata": {},
   "source": [
    "### Now do the same with the movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "873e11d8-5fcb-4fb0-8c04-c4f502e8b717",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_movie_indices_np = np.array([\n",
    "            random.sample(range(1000), 5)\n",
    "            for _ in range(8)\n",
    "        ])\n",
    "sampled_movie_indices = tf.convert_to_tensor(sampled_movie_indices_np, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6166606-6052-49f5-b437-2d7e65b945e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(40, 1), dtype=int32, numpy=\n",
       "array([[ 71],\n",
       "       [568],\n",
       "       [375],\n",
       "       [664],\n",
       "       [ 51],\n",
       "       [ 26],\n",
       "       [ 19],\n",
       "       [962],\n",
       "       [ 78],\n",
       "       [620],\n",
       "       [447],\n",
       "       [190],\n",
       "       [248],\n",
       "       [747],\n",
       "       [996],\n",
       "       [214],\n",
       "       [812],\n",
       "       [325],\n",
       "       [171],\n",
       "       [775],\n",
       "       [701],\n",
       "       [615],\n",
       "       [106],\n",
       "       [626],\n",
       "       [433],\n",
       "       [934],\n",
       "       [120],\n",
       "       [435],\n",
       "       [745],\n",
       "       [150],\n",
       "       [519],\n",
       "       [191],\n",
       "       [712],\n",
       "       [769],\n",
       "       [195],\n",
       "       [959],\n",
       "       [229],\n",
       "       [841],\n",
       "       [149],\n",
       "       [244]], dtype=int32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# movie_index_vector = tf.reshape(sampled_movie_indices, shape=[-1])\n",
    "movie_index_vector = tf.convert_to_tensor(sampled_movie_indices, dtype=tf.int32)\n",
    "movie_index_vector = tf.expand_dims(tf.reshape(movie_index_vector, shape=[-1]), axis=-1)\n",
    "# flat_genre_list = self._mov_gen_int[movie_index_vector] #shape of 1\n",
    "movie_index_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "095ed609-895d-41f3-abf2-8bca01025cfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100000,), dtype=float32, numpy=array([ 7.,  4.,  4., ..., 10.,  0.,  4.], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mov_gen_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca49efb1-dcaa-4896-9890-2613f76d1d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 5), dtype=float32, numpy=\n",
       "array([[0., 7., 0., 4., 4.],\n",
       "       [5., 1., 4., 4., 0.],\n",
       "       [0., 4., 0., 5., 6.],\n",
       "       [5., 9., 0., 3., 7.],\n",
       "       [0., 4., 0., 0., 0.],\n",
       "       [0., 4., 0., 4., 0.],\n",
       "       [1., 0., 4., 7., 7.],\n",
       "       [7., 0., 7., 4., 7.]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_genre_list = tf.gather_nd(indices=movie_index_vector\n",
    "                               , params=mov_gen_int\n",
    "                               , batch_dims=0) #shape of 1\n",
    "genre_list = tf.reshape(flat_genre_list, shape=(8, 5)) #batch size, action \n",
    "genre_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbf2eb3f-ecb0-4e43-a5e0-47ee4d2ba991",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Tf SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1af6e67e-5061-41a1-a92f-227d09d1b356",
   "metadata": {},
   "outputs": [],
   "source": [
    "s, u, vh = tf.linalg.svd(ratings_matrix, full_matrices=False)\n",
    "\n",
    "rank_k = 4\n",
    "\n",
    "# Keep only the largest singular values.\n",
    "u_hat = u[:, :rank_k]\n",
    "s_hat = s[:rank_k]\n",
    "v_hat = vh[:, :rank_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c460bc8-2856-4098-85aa-731e2bd06b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_movie_features = tf.gather_nd(indices=movie_index_vector, params=v_hat)\n",
    "latent_movie_features_reshaped = tf.reshape(latent_movie_features, shape=(8,5,rank_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e235538e-dcb8-4d4c-b138-9b0cc01f1169",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 5, 4), dtype=float32, numpy=\n",
       "array([[[-3.54306847e-02, -7.64061231e-03,  4.35530171e-02,\n",
       "         -5.17456699e-03],\n",
       "        [-1.56895164e-02,  5.02521824e-03,  1.84637476e-02,\n",
       "          1.48388222e-02],\n",
       "        [-5.39823947e-03,  1.52539869e-03,  1.46353347e-02,\n",
       "         -6.38199737e-03],\n",
       "        [-2.22820733e-02,  1.86000427e-03,  3.33855152e-02,\n",
       "          1.75931305e-02],\n",
       "        [-2.83747204e-02, -3.88095081e-02, -2.86513176e-02,\n",
       "          6.45131571e-03]],\n",
       "\n",
       "       [[-1.49953561e-02,  9.73032881e-03,  2.54759118e-02,\n",
       "          1.57616511e-02],\n",
       "        [-1.53361913e-02,  6.28445530e-03, -4.20554318e-02,\n",
       "          3.02750878e-02],\n",
       "        [-1.40080405e-02, -8.14620592e-03, -1.79557167e-02,\n",
       "          1.65346693e-02],\n",
       "        [-9.39802304e-02, -4.09501093e-03,  5.47075793e-02,\n",
       "         -1.07907050e-03],\n",
       "        [-3.25970771e-03, -4.54645092e-03,  2.55617104e-03,\n",
       "         -8.74069054e-03]],\n",
       "\n",
       "       [[-2.42376067e-02, -1.33329453e-02,  1.02638919e-02,\n",
       "          5.48701361e-03],\n",
       "        [-8.20012465e-02, -6.39235675e-02, -2.88686957e-02,\n",
       "         -1.63813122e-02],\n",
       "        [-2.67098304e-02,  4.51653078e-02,  5.94659429e-03,\n",
       "          5.74956313e-02],\n",
       "        [-4.02593948e-02,  1.08257696e-01, -2.04383992e-02,\n",
       "         -8.18391889e-02],\n",
       "        [-3.66069051e-03, -1.57581863e-03,  1.08288124e-03,\n",
       "         -4.19293530e-04]],\n",
       "\n",
       "       [[-6.11262731e-02, -2.56748367e-02,  3.56145948e-02,\n",
       "         -6.34936616e-02],\n",
       "        [-1.17905801e-02,  9.27518308e-03, -3.42471078e-02,\n",
       "          2.41514631e-02],\n",
       "        [-2.16174182e-02,  7.10349903e-02, -4.05975841e-02,\n",
       "         -7.89383873e-02],\n",
       "        [-1.05070494e-01, -2.27152314e-02,  6.75172582e-02,\n",
       "         -1.22202411e-02],\n",
       "        [-2.47858930e-03, -7.91843457e-04,  2.84375111e-03,\n",
       "         -1.04096076e-02]],\n",
       "\n",
       "       [[-1.42411878e-02, -1.35668917e-02, -1.76050439e-02,\n",
       "          1.14782704e-02],\n",
       "        [-1.89069919e-02, -2.56735906e-02,  1.64263009e-03,\n",
       "         -1.52168686e-05],\n",
       "        [-9.26532969e-03,  1.03518628e-02, -6.62432052e-03,\n",
       "         -6.98595773e-03],\n",
       "        [-2.04188135e-02,  6.02438627e-03,  4.06160206e-02,\n",
       "         -2.12195497e-02],\n",
       "        [-2.08592899e-02, -3.38072777e-02,  4.94674407e-03,\n",
       "         -1.30400080e-02]],\n",
       "\n",
       "       [[-1.02071802e-03,  3.42264259e-03, -5.83081646e-03,\n",
       "          2.10190337e-04],\n",
       "        [-8.44244659e-02,  9.99525413e-02,  5.05658276e-02,\n",
       "          1.00730895e-03],\n",
       "        [-2.88608465e-02, -1.88646074e-02,  1.72401462e-02,\n",
       "          2.64001228e-02],\n",
       "        [-3.71578783e-02,  6.88735396e-03,  5.09940125e-02,\n",
       "          2.02549808e-02],\n",
       "        [-7.23171979e-02,  4.41225767e-02,  1.34132951e-02,\n",
       "          4.84189875e-02]],\n",
       "\n",
       "       [[-3.83183919e-02, -4.12014723e-02, -9.26675647e-03,\n",
       "         -5.83906062e-02],\n",
       "        [-3.58751453e-02, -4.03086171e-02, -3.93306352e-02,\n",
       "          4.11752351e-02],\n",
       "        [-1.68236904e-02,  1.40702082e-02, -1.43590923e-02,\n",
       "          1.15951151e-02],\n",
       "        [-1.76990535e-02, -8.26922618e-03,  3.19246808e-03,\n",
       "          1.18385712e-02],\n",
       "        [-7.45034367e-02, -3.27318385e-02,  2.95344740e-02,\n",
       "         -3.47061940e-02]],\n",
       "\n",
       "       [[-6.20624283e-03, -4.45619132e-03, -1.40060866e-02,\n",
       "          1.94023028e-02],\n",
       "        [-5.33528700e-02, -7.04969279e-03,  7.97389448e-02,\n",
       "         -2.30941307e-02],\n",
       "        [-8.46019201e-03, -9.04807355e-03,  1.91626011e-03,\n",
       "         -2.53593326e-02],\n",
       "        [-3.59267294e-02,  4.21305522e-02, -3.19508091e-02,\n",
       "          9.31441337e-02],\n",
       "        [-2.91930176e-02,  9.15164053e-02, -3.48948278e-02,\n",
       "         -6.81221932e-02]]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_movie_features_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a20a64a-450d-4e60-b3e3-1b38b37c8b2e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 5, 5), dtype=float32, numpy=\n",
       "array([[[-3.54306847e-02, -7.64061231e-03,  4.35530171e-02,\n",
       "         -5.17456699e-03,  0.00000000e+00],\n",
       "        [-1.56895164e-02,  5.02521824e-03,  1.84637476e-02,\n",
       "          1.48388222e-02,  7.00000000e+00],\n",
       "        [-5.39823947e-03,  1.52539869e-03,  1.46353347e-02,\n",
       "         -6.38199737e-03,  0.00000000e+00],\n",
       "        [-2.22820733e-02,  1.86000427e-03,  3.33855152e-02,\n",
       "          1.75931305e-02,  4.00000000e+00],\n",
       "        [-2.83747204e-02, -3.88095081e-02, -2.86513176e-02,\n",
       "          6.45131571e-03,  4.00000000e+00]],\n",
       "\n",
       "       [[-1.49953561e-02,  9.73032881e-03,  2.54759118e-02,\n",
       "          1.57616511e-02,  5.00000000e+00],\n",
       "        [-1.53361913e-02,  6.28445530e-03, -4.20554318e-02,\n",
       "          3.02750878e-02,  1.00000000e+00],\n",
       "        [-1.40080405e-02, -8.14620592e-03, -1.79557167e-02,\n",
       "          1.65346693e-02,  4.00000000e+00],\n",
       "        [-9.39802304e-02, -4.09501093e-03,  5.47075793e-02,\n",
       "         -1.07907050e-03,  4.00000000e+00],\n",
       "        [-3.25970771e-03, -4.54645092e-03,  2.55617104e-03,\n",
       "         -8.74069054e-03,  0.00000000e+00]],\n",
       "\n",
       "       [[-2.42376067e-02, -1.33329453e-02,  1.02638919e-02,\n",
       "          5.48701361e-03,  0.00000000e+00],\n",
       "        [-8.20012465e-02, -6.39235675e-02, -2.88686957e-02,\n",
       "         -1.63813122e-02,  4.00000000e+00],\n",
       "        [-2.67098304e-02,  4.51653078e-02,  5.94659429e-03,\n",
       "          5.74956313e-02,  0.00000000e+00],\n",
       "        [-4.02593948e-02,  1.08257696e-01, -2.04383992e-02,\n",
       "         -8.18391889e-02,  5.00000000e+00],\n",
       "        [-3.66069051e-03, -1.57581863e-03,  1.08288124e-03,\n",
       "         -4.19293530e-04,  6.00000000e+00]],\n",
       "\n",
       "       [[-6.11262731e-02, -2.56748367e-02,  3.56145948e-02,\n",
       "         -6.34936616e-02,  5.00000000e+00],\n",
       "        [-1.17905801e-02,  9.27518308e-03, -3.42471078e-02,\n",
       "          2.41514631e-02,  9.00000000e+00],\n",
       "        [-2.16174182e-02,  7.10349903e-02, -4.05975841e-02,\n",
       "         -7.89383873e-02,  0.00000000e+00],\n",
       "        [-1.05070494e-01, -2.27152314e-02,  6.75172582e-02,\n",
       "         -1.22202411e-02,  3.00000000e+00],\n",
       "        [-2.47858930e-03, -7.91843457e-04,  2.84375111e-03,\n",
       "         -1.04096076e-02,  7.00000000e+00]],\n",
       "\n",
       "       [[-1.42411878e-02, -1.35668917e-02, -1.76050439e-02,\n",
       "          1.14782704e-02,  0.00000000e+00],\n",
       "        [-1.89069919e-02, -2.56735906e-02,  1.64263009e-03,\n",
       "         -1.52168686e-05,  4.00000000e+00],\n",
       "        [-9.26532969e-03,  1.03518628e-02, -6.62432052e-03,\n",
       "         -6.98595773e-03,  0.00000000e+00],\n",
       "        [-2.04188135e-02,  6.02438627e-03,  4.06160206e-02,\n",
       "         -2.12195497e-02,  0.00000000e+00],\n",
       "        [-2.08592899e-02, -3.38072777e-02,  4.94674407e-03,\n",
       "         -1.30400080e-02,  0.00000000e+00]],\n",
       "\n",
       "       [[-1.02071802e-03,  3.42264259e-03, -5.83081646e-03,\n",
       "          2.10190337e-04,  0.00000000e+00],\n",
       "        [-8.44244659e-02,  9.99525413e-02,  5.05658276e-02,\n",
       "          1.00730895e-03,  4.00000000e+00],\n",
       "        [-2.88608465e-02, -1.88646074e-02,  1.72401462e-02,\n",
       "          2.64001228e-02,  0.00000000e+00],\n",
       "        [-3.71578783e-02,  6.88735396e-03,  5.09940125e-02,\n",
       "          2.02549808e-02,  4.00000000e+00],\n",
       "        [-7.23171979e-02,  4.41225767e-02,  1.34132951e-02,\n",
       "          4.84189875e-02,  0.00000000e+00]],\n",
       "\n",
       "       [[-3.83183919e-02, -4.12014723e-02, -9.26675647e-03,\n",
       "         -5.83906062e-02,  1.00000000e+00],\n",
       "        [-3.58751453e-02, -4.03086171e-02, -3.93306352e-02,\n",
       "          4.11752351e-02,  0.00000000e+00],\n",
       "        [-1.68236904e-02,  1.40702082e-02, -1.43590923e-02,\n",
       "          1.15951151e-02,  4.00000000e+00],\n",
       "        [-1.76990535e-02, -8.26922618e-03,  3.19246808e-03,\n",
       "          1.18385712e-02,  7.00000000e+00],\n",
       "        [-7.45034367e-02, -3.27318385e-02,  2.95344740e-02,\n",
       "         -3.47061940e-02,  7.00000000e+00]],\n",
       "\n",
       "       [[-6.20624283e-03, -4.45619132e-03, -1.40060866e-02,\n",
       "          1.94023028e-02,  7.00000000e+00],\n",
       "        [-5.33528700e-02, -7.04969279e-03,  7.97389448e-02,\n",
       "         -2.30941307e-02,  0.00000000e+00],\n",
       "        [-8.46019201e-03, -9.04807355e-03,  1.91626011e-03,\n",
       "         -2.53593326e-02,  7.00000000e+00],\n",
       "        [-3.59267294e-02,  4.21305522e-02, -3.19508091e-02,\n",
       "          9.31441337e-02,  4.00000000e+00],\n",
       "        [-2.91930176e-02,  9.15164053e-02, -3.48948278e-02,\n",
       "         -6.81221932e-02,  7.00000000e+00]]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the values so genre is added to the first axis\n",
    "\n",
    "tf.concat([latent_movie_features_reshaped, tf.expand_dims(genre_list, axis=-1)], axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86a12ac-8b8a-42da-b5c3-7c6bec75413c",
   "metadata": {},
   "source": [
    "## Replicate an agent using the above data\n",
    "\n",
    "https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/environments/movielens_per_arm_py_environment.py\n",
    "\n",
    "Create an arm spec from this utility function\n",
    "https://www.tensorflow.org/agents/api_docs/python/tf_agents/specs/bandit_spec_utils/create_per_arm_observation_spec\n",
    "\n",
    "#### NOT Used but helpful to create an obs spec:\n",
    "\n",
    "```python\n",
    "# Example observation spec from above\n",
    "# There are 20 user occupations and 7 age buckets. This makes our global dimension 27\n",
    "# There are 19 genres, and that will be the arm dimension for this example\n",
    "\n",
    "from tf_agents.specs.bandit_spec_utils import create_per_arm_observation_spec as create_obs_spec\n",
    "create_obs_spec(\n",
    "    global_dim = 1,\n",
    "    per_arm_dim = 2,\n",
    "    max_num_actions = 10,\n",
    "    add_num_actions_feature = False\n",
    ") \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b369486f-47aa-4c9c-9726-ac4f83f0fcc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Class implementation of the per-arm MovieLens Bandit environment.\"\"\"\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import random\n",
    "from typing import Optional, Text\n",
    "import gin\n",
    "import numpy as np\n",
    "\n",
    "from tf_agents.bandits.environments import bandit_py_environment\n",
    "from tf_agents.bandits.environments import dataset_utilities\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "\n",
    "GLOBAL_KEY = bandit_spec_utils.GLOBAL_FEATURE_KEY\n",
    "PER_ARM_KEY = bandit_spec_utils.PER_ARM_FEATURE_KEY\n",
    "\n",
    "\n",
    "# @gin.configurable\n",
    "class MovieLensPerArmPyEnvironment(bandit_py_environment.BanditPyEnvironment):\n",
    "    \"\"\"Implements the per-arm version of the MovieLens Bandit environment.\n",
    "\n",
    "    This environment implements the MovieLens 100K dataset, available at:\n",
    "    https://www.kaggle.com/prajitdatta/movielens-100k-dataset\n",
    "\n",
    "    This dataset contains 100K ratings from 943 users on 1682 items.\n",
    "    This csv list of:\n",
    "    user id | item id | rating | timestamp.\n",
    "    This environment computes a low-rank matrix factorization (using SVD) of the\n",
    "    data matrix `A`, such that: `A ~= U * Sigma * V^T`.\n",
    "\n",
    "    The environment uses the rows of `U` as global (or user) features, and the\n",
    "    rows of `V` as per-arm (or movie) features.\n",
    "\n",
    "    The reward of recommending movie `v` to user `u` is `u * Sigma * v^T`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "               dataset = ratings,\n",
    "               rank_k: int = 2,\n",
    "               batch_size: int = 10,\n",
    "               num_actions: int = 100,\n",
    "               name: Optional[Text] = 'movielens_per_arm'):\n",
    "        \"\"\"Initializes the Per-arm MovieLens Bandit environment.\n",
    "\n",
    "        Args:\n",
    "          data_dir: (string) Directory where the data lies (in text form).\n",
    "          rank_k : (int) Which rank to use in the matrix factorization. This will\n",
    "            also be the feature dimension of both the user and the movie features.\n",
    "          batch_size: (int) Number of observations generated per call.\n",
    "          num_actions: (int) How many movies to choose from per round.\n",
    "          csv_delimiter: (string) The delimiter to use in loading the data csv file.\n",
    "          name: (string) The name of this environment instance.\n",
    "        \"\"\"\n",
    "        self._batch_size = batch_size\n",
    "        self._num_actions = num_actions\n",
    "        self.rank_k = rank_k\n",
    "\n",
    "        # Compute the matrix factorization.\n",
    "        # self._data_matrix = dataset_utilities.load_movielens_data(\n",
    "        #     data_dir, delimiter=csv_delimiter)\n",
    "\n",
    "        self._data_matrix, self._user_age_int, self._user_occ_int, self._mov_gen_int = load_movielens_data(ratings)\n",
    "        self._num_users, self._num_movies = self._data_matrix.shape\n",
    "\n",
    "        # Compute the SVD.\n",
    "        s, u, vh = tf.linalg.svd(self._data_matrix, full_matrices=False)\n",
    "\n",
    "        # Keep only the largest singular values.\n",
    "        self._u_hat = u[:, :rank_k]\n",
    "        self._s_hat = s[:rank_k]\n",
    "        self._v_hat = vh[:, :rank_k]\n",
    "\n",
    "        self._approx_ratings_matrix = tf.matmul(self._u_hat * self._s_hat,\n",
    "                                                tf.transpose(self._v_hat))\n",
    "\n",
    "        self._action_spec = array_spec.BoundedArraySpec(\n",
    "            shape=(),\n",
    "            dtype=np.int32,\n",
    "            minimum=0,\n",
    "            maximum=num_actions - 1,\n",
    "            name='action')\n",
    "        observation_spec = {\n",
    "            GLOBAL_KEY:\n",
    "                array_spec.ArraySpec(shape=[rank_k+2], dtype=np.float32), #creating +space for user age and occupation\n",
    "            PER_ARM_KEY:\n",
    "                array_spec.ArraySpec(\n",
    "                    shape=[num_actions, rank_k+1], dtype=np.float32), #creating +1 space for movie genre\n",
    "        }\n",
    "        self._time_step_spec = ts.time_step_spec(observation_spec)\n",
    "\n",
    "        self._current_user_indices = tf.zeros(batch_size, dtype=np.int32)\n",
    "        self._previous_user_indices = tf.zeros(batch_size, dtype=np.int32)\n",
    "\n",
    "        self._current_movie_indices = tf.zeros([batch_size, num_actions],\n",
    "                                               dtype=np.int32)\n",
    "        self._previous_movie_indices = tf.zeros([batch_size, num_actions],\n",
    "                                                dtype=np.int32)\n",
    "\n",
    "        self._observation = {\n",
    "            GLOBAL_KEY:\n",
    "                tf.zeros([batch_size, rank_k+2], dtype=np.int32), #making space like above for dimensions\n",
    "            PER_ARM_KEY:\n",
    "                tf.zeros([batch_size, num_actions, rank_k+1], dtype=np.int32),\n",
    "        }\n",
    "\n",
    "        super(MovieLensPerArmPyEnvironment, self).__init__(\n",
    "            observation_spec, self._action_spec, name=name)\n",
    "\n",
    "    @property\n",
    "    def batch_size(self):\n",
    "        return self._batch_size\n",
    "\n",
    "    @property\n",
    "    def batched(self):\n",
    "        return True\n",
    "\n",
    "    def _observe(self):\n",
    "        \n",
    "        #user section - random sample users\n",
    "        sampled_user_indices_np = np.random.randint(\n",
    "            self._num_users, size=self._batch_size)\n",
    "        sampled_user_indices_1d = tf.convert_to_tensor(sampled_user_indices_np\n",
    "                                                       , dtype=tf.int32)\n",
    "        #expand dims for gather_nd - need to have indices like this [[1], [2], [5]] vs. [1, 2, 5]\n",
    "        sampled_user_indices = tf.expand_dims(sampled_user_indices_1d\n",
    "                                              , axis=-1)\n",
    "        \n",
    "        #sample feature values - gather_nd gathers the values from the randomly sampled incies\n",
    "        sampled_user_ages = tf.gather_nd(indices=sampled_user_indices\n",
    "                                         , params=self._user_age_int)\n",
    "        sampled_user_occ = tf.gather_nd(indices=sampled_user_indices\n",
    "                                        , params=self._user_occ_int)\n",
    "        latent_user_features = tf.gather_nd(indices=sampled_user_indices\n",
    "                                            , params=self._u_hat)\n",
    "        \n",
    "        #we concatenate these - these are our user/context features. note expand dims is needed to properly concatnate across the 1st dim\n",
    "        combined_user_features = tf.concat([latent_user_features\n",
    "                                                 , tf.expand_dims(sampled_user_ages, axis=-1)\n",
    "                                                 , tf.expand_dims(sampled_user_occ, axis=-1)], axis=1)\n",
    "    \n",
    "        \n",
    "        ###movie section\n",
    "\n",
    "        sampled_movie_indices_np = np.array([\n",
    "            random.sample(range(self._num_movies), self._num_actions)\n",
    "            for _ in range(self._batch_size)\n",
    "        ])\n",
    "        sampled_movie_indices = tf.convert_to_tensor(sampled_movie_indices_np\n",
    "                                                     , dtype=tf.int32)\n",
    "        \n",
    "        \n",
    "        #expand dims for gather_nd - need to have indices like this [[1], [2], [5]] vs. [1, 2, 5]\n",
    "        movie_index_vector = tf.expand_dims(tf.reshape(sampled_movie_indices\n",
    "                                                       , shape=[-1])\n",
    "                                            , axis=-1)\n",
    "        \n",
    "        #movie index vector is flattened across actions now, so this will gather the genre feature values for each sampled action(movie)\n",
    "        flat_genre_list = tf.gather_nd(indices=movie_index_vector\n",
    "                                       , params=self._mov_gen_int) #shape of 1\n",
    "        #adding actions back as a dimesions\n",
    "        reshaped_genre_features = tf.reshape(flat_genre_list\n",
    "                                             , shape = [self._batch_size\n",
    "                                                        , self._num_actions])\n",
    "        #gathering the latent movie features, again flattented at action level\n",
    "        latent_movie_features = tf.gather_nd(indices=movie_index_vector\n",
    "                                             , params=self._v_hat) #shape of 2\n",
    "        #then we reshape the action back in\n",
    "        latent_movie_features_reshaped = tf.reshape(latent_movie_features\n",
    "                                                    , shape=[self._batch_size, self._num_actions, self.rank_k])\n",
    "        #now that the shape is right for the latent features + the movie genre and we have dimensions = batch x action x feature dim (we concatenate at feature dim)\n",
    "        current_movies = tf.concat([latent_movie_features_reshaped\n",
    "                                             , tf.expand_dims(reshaped_genre_features, axis=-1)], axis=2)\n",
    "\n",
    "        #save the indices \n",
    "        self._previous_user_indices = self._current_user_indices\n",
    "        self._current_user_indices = sampled_user_indices\n",
    "        self._previous_movie_indices = self._current_movie_indices\n",
    "        self._current_movie_indices = sampled_movie_indices\n",
    "        \n",
    "\n",
    "        batched_observations = {\n",
    "            GLOBAL_KEY:\n",
    "                combined_user_features,\n",
    "            PER_ARM_KEY:\n",
    "                current_movies,\n",
    "        }\n",
    "        return batched_observations\n",
    "    \n",
    "\n",
    "    def _apply_action(self, action):\n",
    "        action = tf.expand_dims(action, axis=-1)\n",
    "        chosen_arm_indices = tf.gather_nd(indices=action\n",
    "                                          , params=self._current_movie_indices\n",
    "                                          , batch_dims = 1)\n",
    "        chosen_user_moves = tf.concat([self._current_user_indices\n",
    "                                       , tf.expand_dims(chosen_arm_indices, axis=-1)]\n",
    "                                      , axis=1)\n",
    "        return tf.gather_nd(indices=chosen_user_moves, params=self._approx_ratings_matrix)\n",
    "\n",
    "    def _rewards_for_all_actions(self):\n",
    "        broadcasted_user = tf.broadcast_to(self._previous_user_indices\n",
    "                                           , [BATCH_SIZE, NUM_ACTIONS]) #broadcast the user ID across all actions\n",
    "        chosen_user_movies = tf.stack([broadcasted_user      \n",
    "                                       , self._previous_movie_indices]\n",
    "                                      , axis=2)\n",
    "        rewards_matrix = tf.gather_nd(indices=chosen_user_movies\n",
    "                                      , params=self._approx_ratings_matrix)\n",
    "        return rewards_matrix\n",
    "\n",
    "    def compute_optimal_action(self):\n",
    "        optimal_actions = tf.argmax(self._rewards_for_all_actions()\n",
    "                                    , axis=-1)\n",
    "        return tf.cast(optimal_actions\n",
    "                       , dtype=tf.int32) #needs casting\n",
    "\n",
    "    def compute_optimal_reward(self):\n",
    "        return np.max(self._rewards_for_all_actions()\n",
    "                      , axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4188ae1-0859-4053-8a5f-b83c1e8a0c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MovieLensPerArmPyEnvironment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79623a28-4e47-4f0e-86de-b61382b939fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation spec:  {'global': ArraySpec(shape=(4,), dtype=dtype('float32'), name=None), 'per_arm': ArraySpec(shape=(100, 3), dtype=dtype('float32'), name=None)}\n",
      "\n",
      "An observation:  {'global': <tf.Tensor: shape=(10, 4), dtype=float32, numpy=\n",
      "array([[-4.4375014e-02,  3.0617092e-02,  2.0000000e+00,  1.9000000e+01],\n",
      "       [-7.9905227e-02, -9.8162433e-03,  6.0000000e+00,  8.0000000e+00],\n",
      "       [-2.2107666e-02, -3.0238582e-02,  3.0000000e+00,  0.0000000e+00],\n",
      "       [-2.8882496e-02,  3.8735330e-02,  2.0000000e+00,  1.4000000e+01],\n",
      "       [-6.4466796e-03,  1.6925792e-03,  3.0000000e+00,  6.0000000e+00],\n",
      "       [-1.1804277e-02,  5.5616260e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-1.6301041e-02,  3.9134230e-02,  6.0000000e+00,  0.0000000e+00],\n",
      "       [-5.9202615e-02, -2.6512155e-02,  1.0000000e+00,  1.7000000e+01],\n",
      "       [-1.6079381e-02, -1.7002936e-02,  3.0000000e+00,  1.9000000e+01],\n",
      "       [-6.1323754e-02, -5.3644337e-02,  3.0000000e+00,  0.0000000e+00]],\n",
      "      dtype=float32)>, 'per_arm': <tf.Tensor: shape=(10, 100, 3), dtype=float32, numpy=\n",
      "array([[[-3.71398330e-02, -5.45250624e-02,  6.00000000e+00],\n",
      "        [-5.69343893e-03,  1.38706127e-02,  4.00000000e+00],\n",
      "        [-1.70756062e-03, -7.13315560e-04,  7.00000000e+00],\n",
      "        ...,\n",
      "        [-2.46506054e-02,  2.48431484e-03,  0.00000000e+00],\n",
      "        [-8.03837832e-03,  1.61963534e-02,  7.00000000e+00],\n",
      "        [-3.58686550e-04, -1.38625101e-05,  0.00000000e+00]],\n",
      "\n",
      "       [[-8.63099284e-03, -7.36710895e-03,  0.00000000e+00],\n",
      "        [-4.90639172e-03,  5.97865833e-03,  4.00000000e+00],\n",
      "        [-9.95588582e-03, -1.24135474e-03,  7.00000000e+00],\n",
      "        ...,\n",
      "        [-2.34714393e-02,  6.48887455e-03,  0.00000000e+00],\n",
      "        [-9.38327424e-03,  1.92951912e-03,  0.00000000e+00],\n",
      "        [-9.57236698e-05, -2.19102934e-04,  2.00000000e+00]],\n",
      "\n",
      "       [[-5.00098243e-03,  1.16554415e-02,  0.00000000e+00],\n",
      "        [-7.71630630e-02, -2.18568407e-02,  7.00000000e+00],\n",
      "        [-6.96398737e-03,  1.09294560e-02,  4.00000000e+00],\n",
      "        ...,\n",
      "        [-1.36808539e-02, -2.99823377e-02,  9.00000000e+00],\n",
      "        [-1.82385463e-03,  3.00172181e-03,  4.00000000e+00],\n",
      "        [-8.08142649e-04,  1.04071677e-03,  5.00000000e+00]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-2.55949562e-03,  7.92074366e-04,  0.00000000e+00],\n",
      "        [-1.32692643e-02, -4.81557474e-03,  5.00000000e+00],\n",
      "        [-7.62955323e-02, -2.91832462e-02,  7.00000000e+00],\n",
      "        ...,\n",
      "        [-7.18076434e-03,  1.77500714e-02,  0.00000000e+00],\n",
      "        [-3.99637036e-03,  1.01199914e-02,  4.00000000e+00],\n",
      "        [-1.74750146e-02, -3.13596390e-02,  1.00000000e+01]],\n",
      "\n",
      "       [[-9.57236698e-05, -2.19102934e-04,  4.00000000e+00],\n",
      "        [-2.12697331e-02, -4.53331321e-02,  4.00000000e+00],\n",
      "        [-6.64013699e-02, -1.29349316e-02,  7.00000000e+00],\n",
      "        ...,\n",
      "        [-1.87444442e-03,  1.61825423e-03,  2.00000000e+00],\n",
      "        [-2.24196771e-03,  4.56279004e-03,  0.00000000e+00],\n",
      "        [-9.24581941e-03,  4.97230468e-03,  4.00000000e+00]],\n",
      "\n",
      "       [[-2.76963413e-03, -1.19257602e-03,  7.00000000e+00],\n",
      "        [-2.48549832e-03, -1.30199082e-03,  4.00000000e+00],\n",
      "        [-3.25806276e-03,  2.97556235e-05,  0.00000000e+00],\n",
      "        ...,\n",
      "        [-7.80946808e-03,  4.06708149e-03,  4.00000000e+00],\n",
      "        [-4.80923627e-04, -7.65503326e-04,  4.00000000e+00],\n",
      "        [-1.32003520e-02,  1.46715418e-02,  0.00000000e+00]]],\n",
      "      dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "print('observation spec: ', env.observation_spec())\n",
    "print('\\nAn observation: ', env.reset().observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4348dcce-d92e-47c1-af00-ae5181c0184d",
   "metadata": {},
   "source": [
    "### Now that the environment is created, let's optimize\n",
    "\n",
    "Taken from here\n",
    "https://github.com/tensorflow/agents/blob/5e5915b0a3650a15e82e77af6e37f41a6c744689/tf_agents/bandits/agents/examples/v2/train_eval_movielens.py#L84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea63b13a-f613-40f3-8184-68d14e45f3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import os\n",
    "from absl import app\n",
    "from absl import flags\n",
    "\n",
    "import tensorflow as tf  # pylint: disable=g-explicit-tensorflow-version-import\n",
    "from tf_agents.bandits.agents import dropout_thompson_sampling_agent as dropout_ts_agent\n",
    "from tf_agents.bandits.agents import lin_ucb_agent\n",
    "from tf_agents.bandits.agents import linear_thompson_sampling_agent as lin_ts_agent\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent as eps_greedy_agent\n",
    "from tf_agents.bandits.agents.examples.v2 import trainer\n",
    "from tf_agents.bandits.environments import environment_utilities\n",
    "from tf_agents.bandits.environments import movielens_per_arm_py_environment\n",
    "from tf_agents.bandits.environments import movielens_py_environment\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.networks import q_network\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "TRAINING_LOOPS = 20000\n",
    "STEPS_PER_LOOP = 2\n",
    "\n",
    "RANK_K = 20\n",
    "NUM_ACTIONS = 20\n",
    "\n",
    "# LinUCB agent constants.\n",
    "\n",
    "AGENT_ALPHA = 10.0\n",
    "\n",
    "# epsilon Greedy constants.\n",
    "\n",
    "EPSILON = 0.05\n",
    "LAYERS = (50, 50, 50)\n",
    "LR = 0.005\n",
    "\n",
    "# Dropout TS constants.\n",
    "DROPOUT_RATE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1d468cf-446a-49d0-aee1-bff3c401e493",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d32f9df-0159-464f-bf11-c054f98ef0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MovieLensPerArmPyEnvironment(\n",
    "        rank_k=RANK_K,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_actions=NUM_ACTIONS,\n",
    ")\n",
    "environment = tf_py_environment.TFPyEnvironment(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c03aba-3f12-4375-998e-919585c2f9c1",
   "metadata": {},
   "source": [
    "### Note we will be using the reward function with this utility function\n",
    "\n",
    "```python\n",
    "@gin.configurable\n",
    "def compute_optimal_reward_with_movielens_environment(observation, environment):\n",
    "  \"\"\"Helper function for gin configurable Regret metric.\"\"\"\n",
    "  del observation\n",
    "  return tf.py_function(environment.compute_optimal_reward, [], tf.float32)\n",
    "\n",
    "@gin.configurable\n",
    "def compute_optimal_action_with_movielens_environment(observation,\n",
    "                                                      environment,\n",
    "                                                      action_dtype=tf.int32):\n",
    "  \"\"\"Helper function for gin configurable SuboptimalArms metric.\"\"\"\n",
    "  del observation\n",
    "  return tf.py_function(environment.compute_optimal_action, [], action_dtype)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78599527-d82d-4048-a319-2dbf7e878db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_reward_fn = functools.partial(\n",
    "      environment_utilities.compute_optimal_reward_with_movielens_environment,\n",
    "      environment=environment)\n",
    "\n",
    "optimal_action_fn = functools.partial(\n",
    "  environment_utilities.compute_optimal_action_with_movielens_environment,\n",
    "  environment=environment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1d1011-8a9b-4f56-9ee7-9492b1a6f01b",
   "metadata": {},
   "source": [
    "### Below we will try different agents by selecting one of the enumerated types:\n",
    "\n",
    "```python\n",
    "flags.DEFINE_enum(\n",
    "    'agent', 'LinUCB', ['LinUCB', 'LinTS', 'epsGreedy', 'DropoutTS'],\n",
    "    'Which agent to use. Possible values: `LinUCB`, `LinTS`, `epsGreedy`,'\n",
    "    ' `DropoutTS`.')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a6a8c07-e655-49e1-871d-ae5e567c2256",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_TYPE = 'LinUCB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "795f6e5b-e98e-4d85-9935-59deae6ba60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if AGENT_TYPE == 'LinUCB':\n",
    "    agent = lin_ucb_agent.LinearUCBAgent(\n",
    "        time_step_spec=environment.time_step_spec(),\n",
    "        action_spec=environment.action_spec(),\n",
    "        tikhonov_weight=0.001,\n",
    "        alpha=AGENT_ALPHA,\n",
    "        dtype=tf.float32,\n",
    "        accepts_per_arm_features=True)\n",
    "\n",
    "elif AGENT_TYPE == 'LinTS':\n",
    "    agent = lin_ts_agent.LinearThompsonSamplingAgent(\n",
    "        time_step_spec=environment.time_step_spec(),\n",
    "        action_spec=environment.action_spec(),\n",
    "        dtype=tf.float32,\n",
    "        accepts_per_arm_features=True)\n",
    "\n",
    "elif AGENT_TYPE == 'epsGreedy':\n",
    "    network = (\n",
    "      global_and_arm_feature_network\n",
    "      .create_feed_forward_dot_product_network(\n",
    "          environment.time_step_spec().observation,\n",
    "          global_layers=LAYERS,\n",
    "          arm_layers=LAYERS))\n",
    "\n",
    "    agent = eps_greedy_agent.NeuralEpsilonGreedyAgent(\n",
    "        time_step_spec=environment.time_step_spec(),\n",
    "        action_spec=environment.action_spec(),\n",
    "        reward_network=network,\n",
    "        optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=LR),\n",
    "        epsilon=EPSILON,\n",
    "        emit_policy_info='predicted_rewards_mean',\n",
    "        info_fields_to_inherit_from_greedy=['predicted_rewards_mean'])\n",
    "\n",
    "elif AGENT_TYPE == 'DropoutTS':\n",
    "    train_step_counter = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "    def dropout_fn():\n",
    "        return tf.math.maximum(\n",
    "          tf.math.reciprocal_no_nan(1.01 +\n",
    "                                    tf.cast(train_step_counter, tf.float32)),\n",
    "          0.0003)\n",
    "\n",
    "    agent = dropout_ts_agent.DropoutThompsonSamplingAgent(\n",
    "        time_step_spec=environment.time_step_spec(),\n",
    "        action_spec=environment.action_spec(),\n",
    "        dropout_rate=dropout_fn,\n",
    "        network_layers=LAYERS,\n",
    "        optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=LR))\n",
    "\n",
    "regret_metric = tf_bandit_metrics.RegretMetric(optimal_reward_fn)\n",
    "suboptimal_arms_metric = tf_bandit_metrics.SuboptimalArmsMetric(\n",
    "  optimal_action_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4ebbb8-bc40-42a5-bbbd-9438d3ff2e74",
   "metadata": {},
   "source": [
    "### Now train the MAB Agent\n",
    "\n",
    "Create a local checkpoint folder if you already have not\n",
    "!mkdir checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46b033cd-dd23-4e93-a33c-347f7e3915f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a9c912-b2b6-44c7-909a-d431316ce0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TFStepMetric._update_state at 0x7fd6a8170820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TFStepMetric._update_state at 0x7fd6a8170820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TFStepMetric._update_state at 0x7fd6b0018af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TFStepMetric._update_state at 0x7fd6b0018af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation/global, 0/observation/per_arm with unsupported characters which will be renamed to step_type, reward, discount, observation_global, observation_per_arm in the SavedModel.\n",
      "WARNING:absl:`0/step_type` is not a valid tf.function parameter name. Sanitizing to `arg_0_step_type`.\n",
      "WARNING:absl:`0/reward` is not a valid tf.function parameter name. Sanitizing to `arg_0_reward`.\n",
      "WARNING:absl:`0/discount` is not a valid tf.function parameter name. Sanitizing to `arg_0_discount`.\n",
      "WARNING:absl:`0/observation/global` is not a valid tf.function parameter name. Sanitizing to `arg_0_observation_global`.\n",
      "WARNING:absl:`0/observation/per_arm` is not a valid tf.function parameter name. Sanitizing to `arg_0_observation_per_arm`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint/policy_40400/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:497: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: checkpoint/policy_40400/assets\n",
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation/global, 0/observation/per_arm with unsupported characters which will be renamed to step_type, reward, discount, observation_global, observation_per_arm in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint/policy_42000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:497: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: checkpoint/policy_42000/assets\n"
     ]
    }
   ],
   "source": [
    "trainer.train(\n",
    "      root_dir='checkpoint',\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      training_loops=TRAINING_LOOPS,\n",
    "      steps_per_loop=STEPS_PER_LOOP,\n",
    "      additional_metrics=[regret_metric, suboptimal_arms_metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8770ef-2d5a-4bfd-9f2e-6bc18c13aad3",
   "metadata": {},
   "source": [
    "#### Development work below on getting tensors to work for prior movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac23e16-5b76-475e-881a-fe63f810de42",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_mi = env._previous_movie_indices\n",
    "p_ui = env._previous_user_indices\n",
    "\n",
    "p_ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b566c2-d9bb-4b32-92c1-5d2c9fecb907",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "9ce92c1f-513a-4802-b29b-bd16503a4d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 20), dtype=int32, numpy=\n",
       "array([[ 46,  46,  46,  46,  46,  46,  46,  46,  46,  46,  46,  46,  46,\n",
       "         46,  46,  46,  46,  46,  46,  46],\n",
       "       [891, 891, 891, 891, 891, 891, 891, 891, 891, 891, 891, 891, 891,\n",
       "        891, 891, 891, 891, 891, 891, 891],\n",
       "       [274, 274, 274, 274, 274, 274, 274, 274, 274, 274, 274, 274, 274,\n",
       "        274, 274, 274, 274, 274, 274, 274],\n",
       "       [866, 866, 866, 866, 866, 866, 866, 866, 866, 866, 866, 866, 866,\n",
       "        866, 866, 866, 866, 866, 866, 866],\n",
       "       [938, 938, 938, 938, 938, 938, 938, 938, 938, 938, 938, 938, 938,\n",
       "        938, 938, 938, 938, 938, 938, 938],\n",
       "       [ 47,  47,  47,  47,  47,  47,  47,  47,  47,  47,  47,  47,  47,\n",
       "         47,  47,  47,  47,  47,  47,  47],\n",
       "       [117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117,\n",
       "        117, 117, 117, 117, 117, 117, 117],\n",
       "       [385, 385, 385, 385, 385, 385, 385, 385, 385, 385, 385, 385, 385,\n",
       "        385, 385, 385, 385, 385, 385, 385]], dtype=int32)>"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadcasted_user = tf.broadcast_to(p_ui, [BATCH_SIZE, NUM_ACTIONS]) #broadcast the user ID across all actions\n",
    "broadcasted_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "id": "60b89bf4-01aa-4696-ac1e-5218ff7ecef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_user_movies = tf.stack([broadcasted_user      \n",
    "                                       , p_mi]\n",
    "                                      , axis=2)\n",
    "# rewards_matrix = tf.gather_nd(indices=chosen_user_moves\n",
    "#                               , params=self._approx_ratings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "id": "1c81d4f3-f896-4931-b53b-4cb873722857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 20, 2), dtype=int32, numpy=\n",
       "array([[[  46, 1526],\n",
       "        [  46, 1011],\n",
       "        [  46, 1063],\n",
       "        [  46, 1540],\n",
       "        [  46,  115],\n",
       "        [  46,  795],\n",
       "        [  46, 1104],\n",
       "        [  46,  758],\n",
       "        [  46, 1555],\n",
       "        [  46, 1071],\n",
       "        [  46,  782],\n",
       "        [  46, 1499],\n",
       "        [  46,  161],\n",
       "        [  46,  773],\n",
       "        [  46,  864],\n",
       "        [  46, 1589],\n",
       "        [  46,  850],\n",
       "        [  46,  953],\n",
       "        [  46,  152],\n",
       "        [  46, 1401]],\n",
       "\n",
       "       [[ 891,  868],\n",
       "        [ 891,  864],\n",
       "        [ 891, 1510],\n",
       "        [ 891, 1318],\n",
       "        [ 891, 1065],\n",
       "        [ 891, 1532],\n",
       "        [ 891,  803],\n",
       "        [ 891, 1015],\n",
       "        [ 891, 1151],\n",
       "        [ 891,  238],\n",
       "        [ 891, 1073],\n",
       "        [ 891, 1634],\n",
       "        [ 891,  375],\n",
       "        [ 891,  361],\n",
       "        [ 891,  987],\n",
       "        [ 891, 1636],\n",
       "        [ 891,  301],\n",
       "        [ 891,  855],\n",
       "        [ 891,  543],\n",
       "        [ 891,  372]],\n",
       "\n",
       "       [[ 274, 1383],\n",
       "        [ 274,  929],\n",
       "        [ 274,   20],\n",
       "        [ 274,  212],\n",
       "        [ 274,   47],\n",
       "        [ 274, 1541],\n",
       "        [ 274,  826],\n",
       "        [ 274,  610],\n",
       "        [ 274,   11],\n",
       "        [ 274, 1507],\n",
       "        [ 274, 1510],\n",
       "        [ 274,  470],\n",
       "        [ 274, 1337],\n",
       "        [ 274,    6],\n",
       "        [ 274, 1269],\n",
       "        [ 274, 1069],\n",
       "        [ 274, 1260],\n",
       "        [ 274,  137],\n",
       "        [ 274,  607],\n",
       "        [ 274,  105]],\n",
       "\n",
       "       [[ 866,  299],\n",
       "        [ 866,  883],\n",
       "        [ 866,  319],\n",
       "        [ 866, 1289],\n",
       "        [ 866,  109],\n",
       "        [ 866,  508],\n",
       "        [ 866, 1450],\n",
       "        [ 866, 1113],\n",
       "        [ 866, 1303],\n",
       "        [ 866, 1121],\n",
       "        [ 866,  501],\n",
       "        [ 866,  103],\n",
       "        [ 866,  187],\n",
       "        [ 866,  292],\n",
       "        [ 866,  318],\n",
       "        [ 866, 1438],\n",
       "        [ 866,  125],\n",
       "        [ 866,   45],\n",
       "        [ 866,  473],\n",
       "        [ 866,  105]],\n",
       "\n",
       "       [[ 938,  157],\n",
       "        [ 938, 1147],\n",
       "        [ 938, 1531],\n",
       "        [ 938,  582],\n",
       "        [ 938, 1638],\n",
       "        [ 938,  784],\n",
       "        [ 938,   58],\n",
       "        [ 938,  924],\n",
       "        [ 938, 1522],\n",
       "        [ 938,  827],\n",
       "        [ 938,  553],\n",
       "        [ 938, 1414],\n",
       "        [ 938,  669],\n",
       "        [ 938, 1077],\n",
       "        [ 938, 1461],\n",
       "        [ 938, 1186],\n",
       "        [ 938, 1628],\n",
       "        [ 938,  564],\n",
       "        [ 938,  255],\n",
       "        [ 938,  531]],\n",
       "\n",
       "       [[  47, 1085],\n",
       "        [  47, 1564],\n",
       "        [  47, 1190],\n",
       "        [  47,  975],\n",
       "        [  47, 1429],\n",
       "        [  47,  899],\n",
       "        [  47,  850],\n",
       "        [  47,  969],\n",
       "        [  47,  744],\n",
       "        [  47,  267],\n",
       "        [  47, 1483],\n",
       "        [  47, 1009],\n",
       "        [  47, 1232],\n",
       "        [  47, 1231],\n",
       "        [  47,  201],\n",
       "        [  47,  362],\n",
       "        [  47,  137],\n",
       "        [  47, 1453],\n",
       "        [  47,  124],\n",
       "        [  47,   99]],\n",
       "\n",
       "       [[ 117, 1616],\n",
       "        [ 117, 1282],\n",
       "        [ 117, 1465],\n",
       "        [ 117,  317],\n",
       "        [ 117,  304],\n",
       "        [ 117,  488],\n",
       "        [ 117, 1239],\n",
       "        [ 117,   58],\n",
       "        [ 117,  436],\n",
       "        [ 117, 1524],\n",
       "        [ 117,  797],\n",
       "        [ 117,   13],\n",
       "        [ 117,  424],\n",
       "        [ 117,  486],\n",
       "        [ 117,  383],\n",
       "        [ 117, 1422],\n",
       "        [ 117, 1527],\n",
       "        [ 117,  440],\n",
       "        [ 117,  126],\n",
       "        [ 117,  384]],\n",
       "\n",
       "       [[ 385,  997],\n",
       "        [ 385, 1026],\n",
       "        [ 385,  264],\n",
       "        [ 385,  856],\n",
       "        [ 385, 1672],\n",
       "        [ 385,  633],\n",
       "        [ 385, 1181],\n",
       "        [ 385, 1371],\n",
       "        [ 385, 1149],\n",
       "        [ 385, 1420],\n",
       "        [ 385, 1004],\n",
       "        [ 385, 1507],\n",
       "        [ 385,  351],\n",
       "        [ 385,  548],\n",
       "        [ 385, 1593],\n",
       "        [ 385,  543],\n",
       "        [ 385,  129],\n",
       "        [ 385, 1627],\n",
       "        [ 385,  855],\n",
       "        [ 385, 1407]]], dtype=int32)>"
      ]
     },
     "execution_count": 720,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_user_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "id": "f8827af2-8c20-4c91-9ef8-2295466ae990",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_matrix = tf.gather_nd(indices=chosen_user_moves\n",
    "                               , params=env._approx_ratings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "454371d1-0fb1-4fc1-9134-ded60e28231d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 20), dtype=float32, numpy=\n",
       "array([[ 5.83164915e-02, -2.41056252e-02, -1.87867433e-02,\n",
       "         8.62880517e-03,  7.30352163e-01,  2.27192324e-02,\n",
       "         9.38408375e-02,  2.41663065e-02,  1.70041691e-03,\n",
       "         2.13751364e-02, -1.24250874e-01,  9.84792318e-03,\n",
       "         2.39062514e-02, -8.74508824e-03,  1.60256714e-01,\n",
       "         1.60809308e-02,  3.14846598e-02, -4.05272655e-03,\n",
       "         2.32983939e-03, -2.88842362e-04],\n",
       "       [ 4.02831882e-02, -2.68716589e-02, -2.93028913e-02,\n",
       "        -1.04498416e-01,  3.91238064e-01,  2.57909205e-02,\n",
       "         1.31979123e-01,  8.55176270e-01, -8.76861140e-02,\n",
       "         2.17240095e+00, -1.74399465e-01, -8.42698440e-02,\n",
       "         2.27339536e-01,  7.18889013e-02,  5.99470213e-02,\n",
       "        -8.42698440e-02,  5.59053957e-01, -1.64513901e-01,\n",
       "         4.21740830e-01,  7.19132006e-01],\n",
       "       [-3.26522440e-03,  5.83950162e-01,  5.90337574e-01,\n",
       "        -1.97528660e-01, -1.32889107e-01,  4.70319875e-02,\n",
       "         1.00843341e-03, -2.43588313e-01, -7.42941618e-01,\n",
       "         1.42039964e-03, -1.64962523e-02,  4.17560428e-01,\n",
       "        -9.49903764e-03,  1.60817111e+00, -6.65873364e-02,\n",
       "        -2.11061671e-01, -4.89876531e-02,  9.11579356e-02,\n",
       "        -4.52505276e-02, -1.72765199e-02],\n",
       "       [ 2.96649933e+00, -3.49653699e-02, -1.28543213e-01,\n",
       "        -7.46685173e-03, -1.66773811e-01,  9.15089130e-01,\n",
       "         1.28574029e-01, -1.93875372e-01, -4.54362156e-03,\n",
       "        -1.14303567e-02, -4.80291247e-01, -1.19034555e-02,\n",
       "         1.99250805e+00,  1.55724287e-01, -2.14560077e-01,\n",
       "        -5.47546148e-02, -4.76968557e-01,  1.83504462e-01,\n",
       "         2.98087692e+00, -1.17149048e-01],\n",
       "       [-4.32262719e-02,  1.34437028e-02,  1.23249684e-02,\n",
       "         2.49030348e-02,  4.47172076e-02,  1.85773492e-01,\n",
       "        -1.51061729e-01,  4.26690459e-01,  1.40415598e-02,\n",
       "         1.34276643e-01,  1.09405145e-01,  7.41673857e-02,\n",
       "         2.12474316e-02, -4.42879088e-02,  4.60333191e-02,\n",
       "         1.01963300e-02,  3.17644291e-02,  1.44632319e-02,\n",
       "         5.28584570e-02,  7.60797188e-02],\n",
       "       [-1.20592549e-01,  9.28553566e-03,  2.60744430e-02,\n",
       "        -1.94028430e-02,  1.84117928e-02,  2.00583905e-01,\n",
       "         5.83747290e-02,  4.12800461e-02,  4.73383218e-02,\n",
       "         2.03615621e-01, -1.92306321e-02, -2.18644530e-01,\n",
       "        -1.48323756e-02, -3.90500538e-02,  9.81547952e-01,\n",
       "        -6.04415201e-02,  9.47507173e-02, -1.03899809e-02,\n",
       "        -2.74992734e-02,  7.61166871e-01],\n",
       "       [ 3.85109801e-03, -1.52480692e-01, -4.07111868e-02,\n",
       "         1.44494379e+00, -3.20671320e-01,  2.58372694e-01,\n",
       "         4.38143104e-01,  8.58981252e-01,  4.92690504e-02,\n",
       "         3.48529778e-03,  2.68599521e-02, -3.04024667e-01,\n",
       "         7.11008251e-01, -1.97983548e-01, -2.21755311e-01,\n",
       "         5.34348749e-02, -8.69879220e-03,  1.04081571e+00,\n",
       "         2.02502680e+00, -4.02557820e-01],\n",
       "       [ 1.86333638e-02,  1.28141958e-02,  5.36252439e-01,\n",
       "        -2.93079810e-03,  1.11206493e-03, -8.35262537e-02,\n",
       "         1.34695368e-03,  1.33987973e-02,  2.77634282e-02,\n",
       "         3.49692330e-02,  6.76472634e-02, -1.00829508e-02,\n",
       "        -1.57892089e-02, -2.65569314e-02, -5.70061989e-03,\n",
       "         2.50196040e-01,  4.35840115e-02, -1.32476911e-03,\n",
       "        -2.28971690e-02, -6.79057033e-04]], dtype=float32)>"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cd6510-86c4-4507-bc12-25e4ff00bc2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-12.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-12:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
