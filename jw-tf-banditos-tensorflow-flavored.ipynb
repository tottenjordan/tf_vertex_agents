{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "525b561f-77f5-4736-927f-19929674b868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tf-agents --user -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ba0048de-0245-40d9-9ad0-e85793329ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-agents==0.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep tf-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "53da2313-9daf-4662-8d9b-93b813d2a4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "1112bb5e-0151-418f-9d17-eb17ee191788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.bandits.agents import lin_ucb_agent\n",
    "from tf_agents.bandits.environments import stationary_stochastic_per_arm_py_environment as p_a_env\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "import tensorflow_datasets as tfds\n",
    "from pprint import pprint\n",
    "\n",
    "nest = tf.nest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dac1a89-b58b-4d4b-92ba-e70d9ed80a96",
   "metadata": {},
   "source": [
    "### movies data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "03eb6ba1-8cae-41f6-b65a-31d18165fe69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[4]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'1681'], dtype=object)>,\n",
      " 'movie_title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'You So Crazy (1994)'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")\n",
    "\n",
    "for x in movies.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9c9413-3aa8-4188-b5a2-b342ef50faf2",
   "metadata": {},
   "source": [
    "### user and ratings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "92dbdb4b-8f13-4455-887c-6617ebd80242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([45.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'357'], dtype=object)>,\n",
      " 'movie_title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"One Flew Over the Cuckoo's Nest (1975)\"], dtype=object)>,\n",
      " 'raw_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([46.], dtype=float32)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([879024327])>,\n",
      " 'user_gender': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'138'], dtype=object)>,\n",
      " 'user_occupation_label': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([4])>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'doctor'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>,\n",
      " 'user_zip_code': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'53211'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "\n",
    "for x in ratings.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7941678d-f920-4206-9fea-d8e3e9f15cef",
   "metadata": {},
   "source": [
    "#### Let's make this simple and load up movielens that has features\n",
    "We will only consider for this example\n",
    "1) The movie genere as an Arm feature (we will concatenate multiple genres)\n",
    "2) The user occupation and age bucket labels for the overall context features\n",
    "\n",
    "We need to load the data, get the ratings - light EDA for us to get cardnality of the dataset as well as lookups for the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "5a4c8c8c-6e55-4140-86e7-701308154762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(unique_movie_ids) : 1682\n",
      "unique_movie_ids      : [b'1' b'10']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique movies and users\n",
    "unique_movie_ids = ratings.map(lambda x: x[\"movie_id\"])\n",
    "unique_movie_ids = np.unique([x.numpy() for x in unique_movie_ids])\n",
    "MOVIELENS_NUM_MOVIES = len(unique_movie_ids)\n",
    "\n",
    "\n",
    "print(f\"len(unique_movie_ids) : {len(unique_movie_ids)}\")\n",
    "print(f\"unique_movie_ids      : {unique_movie_ids[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "6bc12022-129d-48df-8cb3-7e53dbbbfea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(unique_user_ids) : 943\n",
      "unique_user_ids      : [b'1' b'10']\n"
     ]
    }
   ],
   "source": [
    "unique_user_ids = ratings.map(lambda x: x[\"user_id\"])\n",
    "unique_user_ids = np.unique([x.numpy() for x in unique_user_ids])\n",
    "MOVIELENS_NUM_USERS = len(unique_user_ids)\n",
    "\n",
    "\n",
    "print(f\"len(unique_user_ids) : {len(unique_user_ids)}\")\n",
    "print(f\"unique_user_ids      : {unique_user_ids[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "8cef8a89-0e97-4d93-819e-db2d4667efa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the unnique set of user buckets and create a lookup table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "174860eb-bfeb-4b02-b4d9-1dfaddc70914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def get_dictionary_lookup_by_tf_data_key(key: str) -> Dict:\n",
    "    tensor = ratings.map(lambda x: x[key])\n",
    "    unique_elems = set()\n",
    "    for x in tensor:\n",
    "        val = x.numpy()\n",
    "        if type(val) is np.ndarray: # if multi dimesnional only grab first one\n",
    "            val = val[0]\n",
    "        unique_elems.add(val)\n",
    "    \n",
    "    #return a dictionary of keys by integer values for the feature space\n",
    "    return {val: i for i, val in enumerate(unique_elems)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "e8113ded-13f2-460f-a2cd-90f44307f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_age_lookup = get_dictionary_lookup_by_tf_data_key('bucketized_user_age')\n",
    "user_age_dim = len(user_age_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "bed813e8-cef5-46e0-a1d5-3f6c37ea34a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: 0, 35.0: 1, 45.0: 2, 18.0: 3, 50.0: 4, 56.0: 5, 25.0: 6}"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_age_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "9ced8d46-9e1d-4d88-9228-cb57005d064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_occ_lookup = get_dictionary_lookup_by_tf_data_key('user_occupation_text')\n",
    "user_occ_dim = len(user_occ_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "820171f0-4784-4c61-b101-d3c9ae78f7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'salesman': 0,\n",
       " b'healthcare': 1,\n",
       " b'programmer': 2,\n",
       " b'lawyer': 3,\n",
       " b'marketing': 4,\n",
       " b'technician': 5,\n",
       " b'engineer': 6,\n",
       " b'entertainment': 7,\n",
       " b'student': 8,\n",
       " b'other': 9,\n",
       " b'homemaker': 10,\n",
       " b'retired': 11,\n",
       " b'administrator': 12,\n",
       " b'writer': 13,\n",
       " b'executive': 14,\n",
       " b'librarian': 15,\n",
       " b'scientist': 16,\n",
       " b'educator': 17,\n",
       " b'none': 18,\n",
       " b'artist': 19,\n",
       " b'doctor': 20}"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_occ_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "ca8fa3dc-1144-4fff-8a03-eacb600d58a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_gen_lookup = get_dictionary_lookup_by_tf_data_key('movie_genres')\n",
    "movie_gen_dim = len(movie_gen_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "f7adf6f0-6842-4777-8cfe-65953dae96f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 1,\n",
       " 2: 2,\n",
       " 3: 3,\n",
       " 4: 4,\n",
       " 5: 5,\n",
       " 6: 6,\n",
       " 7: 7,\n",
       " 8: 8,\n",
       " 9: 9,\n",
       " 10: 10,\n",
       " 12: 11,\n",
       " 13: 12,\n",
       " 14: 13,\n",
       " 15: 14,\n",
       " 16: 15,\n",
       " 17: 16,\n",
       " 18: 17,\n",
       " 19: 18}"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_gen_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "b571a4e9-60ef-4e06-98b3-017fec36d36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REFACTOR BELOW\n",
    " #from https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/environments/dataset_utilities.py#L153\n",
    "    \n",
    "# def load_movielens_data(data_file, delimiter=','):\n",
    "#     \"\"\"Loads the movielens data and returns the ratings matrix.\"\"\"\n",
    "#     ratings_matrix = np.zeros([MOVIELENS_NUM_USERS, MOVIELENS_NUM_MOVIES])\n",
    "#     with tf.io.gfile.GFile(data_file, 'r') as infile:\n",
    "#     # The file is a csv with rows containing:\n",
    "#     # user id | item id | rating | timestamp\n",
    "#     reader = csv.reader(infile, delimiter=delimiter)\n",
    "#     for row in reader:\n",
    "#         user_id, item_id, rating, _ = row\n",
    "#         ratings_matrix[int(user_id) - 1, int(item_id) - 1] = float(rating)\n",
    "#     return ratings_matrix\n",
    "\n",
    "\n",
    "\n",
    "def load_movielens_data(ratings_dataset):\n",
    "    # ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "    ratings_matrix = np.zeros([MOVIELENS_NUM_USERS, MOVIELENS_NUM_MOVIES])\n",
    "    local_data = ratings_dataset.map(lambda x: {'user_id': x['user_id']\n",
    "                                                 ,'movie_id':  x['movie_id']\n",
    "                                                 ,'user_rating':  x['user_rating']\n",
    "                                                 ,'bucketized_user_age': x['bucketized_user_age']\n",
    "                                                 ,'user_occupation_text': x['user_occupation_text']\n",
    "                                                 ,'movie_genres': x['movie_genres'][0]\n",
    "                                               }\n",
    "                                                                         )\n",
    "    user_age_int = []\n",
    "    user_occ_int = []\n",
    "    mov_gen_int = []\n",
    "    for row in local_data:\n",
    "        ratings_matrix[int(row['user_id'].numpy()) - 1, int(row['movie_id'].numpy()) - 1] = float(row['user_rating'].numpy())\n",
    "        user_age_int.append(user_age_lookup[row['bucketized_user_age'].numpy()])\n",
    "        user_occ_int.append(user_occ_lookup[row['user_occupation_text'].numpy()])\n",
    "        mov_gen_int.append(movie_gen_lookup[row['movie_genres'].numpy()])\n",
    "    return tf.convert_to_tensor(ratings_matrix, dtype=tf.float32), tf.convert_to_tensor(np.array(user_age_int), dtype=tf.float32), tf.convert_to_tensor(np.array(user_occ_int), dtype=tf.float32), tf.convert_to_tensor(np.array(mov_gen_int), dtype=tf.float32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "50806cc4-f345-471f-9622-4201303c8679",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_matrix, user_age_int, user_occ_int, mov_gen_int = load_movielens_data(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "848e948c-8fe2-4c95-9779-3e90d9dcc83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_user_indices_np = np.random.randint(\n",
    "            1000, size=8)\n",
    "sampled_user_indices = tf.convert_to_tensor(sampled_user_indices_np, dtype=tf.int32)\n",
    "sampled_user_indices = np.expand_dims(sampled_user_indices,axis=-1) #expand out to individual indicies to match sizes for slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "57fc1fb7-ab98-4b29-a4c6-96a9068e22fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[959],\n",
       "       [986],\n",
       "       [489],\n",
       "       [534],\n",
       "       [802],\n",
       "       [395],\n",
       "       [750],\n",
       "       [446]], dtype=int32)"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_user_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "9ece6c16-5c0a-47bd-817b-892c6321b4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_user_ages = tf.gather_nd(indices=sampled_user_indices\n",
    "                                         , params=user_age_int\n",
    "                                         , batch_dims=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5837bd49-b761-4c16-8949-1c496a2e3a9e",
   "metadata": {},
   "source": [
    "### Now do the same with the movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "873e11d8-5fcb-4fb0-8c04-c4f502e8b717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 5), dtype=int32, numpy=\n",
       "array([[281, 227, 331, 570,  93],\n",
       "       [263, 406, 514, 217, 621],\n",
       "       [983, 473, 308, 602,  31],\n",
       "       [ 31, 251, 250,  20, 685],\n",
       "       [744, 456, 195, 947, 526],\n",
       "       [196, 141, 955, 861, 235],\n",
       "       [361, 408, 563, 213, 392],\n",
       "       [776, 393, 782, 622, 287]], dtype=int32)>"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_movie_indices_np = np.array([\n",
    "            random.sample(range(1000), 5)\n",
    "            for _ in range(8)\n",
    "        ])\n",
    "sampled_movie_indices = tf.convert_to_tensor(sampled_movie_indices_np, dtype=tf.int32)\n",
    "sampled_movie_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "d6166606-6052-49f5-b437-2d7e65b945e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(40, 1), dtype=int32, numpy=\n",
       "array([[281],\n",
       "       [227],\n",
       "       [331],\n",
       "       [570],\n",
       "       [ 93],\n",
       "       [263],\n",
       "       [406],\n",
       "       [514],\n",
       "       [217],\n",
       "       [621],\n",
       "       [983],\n",
       "       [473],\n",
       "       [308],\n",
       "       [602],\n",
       "       [ 31],\n",
       "       [ 31],\n",
       "       [251],\n",
       "       [250],\n",
       "       [ 20],\n",
       "       [685],\n",
       "       [744],\n",
       "       [456],\n",
       "       [195],\n",
       "       [947],\n",
       "       [526],\n",
       "       [196],\n",
       "       [141],\n",
       "       [955],\n",
       "       [861],\n",
       "       [235],\n",
       "       [361],\n",
       "       [408],\n",
       "       [563],\n",
       "       [213],\n",
       "       [392],\n",
       "       [776],\n",
       "       [393],\n",
       "       [782],\n",
       "       [622],\n",
       "       [287]], dtype=int32)>"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# movie_index_vector = tf.reshape(sampled_movie_indices, shape=[-1])\n",
    "movie_index_vector = tf.convert_to_tensor(sampled_movie_indices, dtype=tf.int32)\n",
    "movie_index_vector = tf.expand_dims(tf.reshape(movie_index_vector, shape=[-1]), axis=-1)\n",
    "# flat_genre_list = self._mov_gen_int[movie_index_vector] #shape of 1\n",
    "movie_index_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "095ed609-895d-41f3-abf2-8bca01025cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100000,), dtype=float32, numpy=array([ 7.,  4.,  4., ..., 10.,  0.,  4.], dtype=float32)>"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mov_gen_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "ca49efb1-dcaa-4896-9890-2613f76d1d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(40,), dtype=float32, numpy=\n",
       "array([10.,  7.,  0.,  4.,  7.,  3.,  7.,  3.,  1.,  4.,  5.,  2.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  5.,  5.,  0.,  1.,  7.,  2.,  2., 12.,\n",
       "        4.,  2.,  9.,  4.,  7.,  7.,  9.,  0.,  4.,  0.,  0.,  7.,  4.,\n",
       "        4.], dtype=float32)>"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_genre_list = tf.gather_nd(indices=movie_index_vector\n",
    "                               , params=mov_gen_int\n",
    "                               , batch_dims=0) #shape of 1\n",
    "flat_genre_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "dbf2eb3f-ecb0-4e43-a5e0-47ee4d2ba991",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Tf SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "1af6e67e-5061-41a1-a92f-227d09d1b356",
   "metadata": {},
   "outputs": [],
   "source": [
    "s, u, vh = tf.linalg.svd(ratings_matrix, full_matrices=False)\n",
    "\n",
    "rank_k = 4\n",
    "\n",
    "# Keep only the largest singular values.\n",
    "u_hat = u[:, :rank_k]\n",
    "s_hat = s[:rank_k]\n",
    "v_hat = tf.transpose(vh[:rank_k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86a12ac-8b8a-42da-b5c3-7c6bec75413c",
   "metadata": {},
   "source": [
    "## Replicate an agent using the above data\n",
    "\n",
    "https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/environments/movielens_per_arm_py_environment.py\n",
    "\n",
    "Create an arm spec from this utility function\n",
    "https://www.tensorflow.org/agents/api_docs/python/tf_agents/specs/bandit_spec_utils/create_per_arm_observation_spec\n",
    "\n",
    "#### NOT Used but helpful to create an obs spec:\n",
    "\n",
    "```python\n",
    "# Example observation spec from above\n",
    "# There are 20 user occupations and 7 age buckets. This makes our global dimension 27\n",
    "# There are 19 genres, and that will be the arm dimension for this example\n",
    "\n",
    "from tf_agents.specs.bandit_spec_utils import create_per_arm_observation_spec as create_obs_spec\n",
    "create_obs_spec(\n",
    "    global_dim = 1,\n",
    "    per_arm_dim = 2,\n",
    "    max_num_actions = 10,\n",
    "    add_num_actions_feature = False\n",
    ") \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "b369486f-47aa-4c9c-9726-ac4f83f0fcc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Class implementation of the per-arm MovieLens Bandit environment.\"\"\"\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import random\n",
    "from typing import Optional, Text\n",
    "import gin\n",
    "import numpy as np\n",
    "\n",
    "from tf_agents.bandits.environments import bandit_py_environment\n",
    "from tf_agents.bandits.environments import dataset_utilities\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "\n",
    "GLOBAL_KEY = bandit_spec_utils.GLOBAL_FEATURE_KEY\n",
    "PER_ARM_KEY = bandit_spec_utils.PER_ARM_FEATURE_KEY\n",
    "\n",
    "\n",
    "# @gin.configurable\n",
    "class MovieLensPerArmPyEnvironment(bandit_py_environment.BanditPyEnvironment):\n",
    "    \"\"\"Implements the per-arm version of the MovieLens Bandit environment.\n",
    "\n",
    "    This environment implements the MovieLens 100K dataset, available at:\n",
    "    https://www.kaggle.com/prajitdatta/movielens-100k-dataset\n",
    "\n",
    "    This dataset contains 100K ratings from 943 users on 1682 items.\n",
    "    This csv list of:\n",
    "    user id | item id | rating | timestamp.\n",
    "    This environment computes a low-rank matrix factorization (using SVD) of the\n",
    "    data matrix `A`, such that: `A ~= U * Sigma * V^T`.\n",
    "\n",
    "    The environment uses the rows of `U` as global (or user) features, and the\n",
    "    rows of `V` as per-arm (or movie) features.\n",
    "\n",
    "    The reward of recommending movie `v` to user `u` is `u * Sigma * v^T`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "               dataset = ratings,\n",
    "               rank_k: int = 2,\n",
    "               batch_size: int = 10,\n",
    "               num_actions: int = 100,\n",
    "               name: Optional[Text] = 'movielens_per_arm'):\n",
    "        \"\"\"Initializes the Per-arm MovieLens Bandit environment.\n",
    "\n",
    "        Args:\n",
    "          data_dir: (string) Directory where the data lies (in text form).\n",
    "          rank_k : (int) Which rank to use in the matrix factorization. This will\n",
    "            also be the feature dimension of both the user and the movie features.\n",
    "          batch_size: (int) Number of observations generated per call.\n",
    "          num_actions: (int) How many movies to choose from per round.\n",
    "          csv_delimiter: (string) The delimiter to use in loading the data csv file.\n",
    "          name: (string) The name of this environment instance.\n",
    "        \"\"\"\n",
    "        self._batch_size = batch_size\n",
    "        self._num_actions = num_actions\n",
    "        self.rank_k = rank_k\n",
    "\n",
    "        # Compute the matrix factorization.\n",
    "        # self._data_matrix = dataset_utilities.load_movielens_data(\n",
    "        #     data_dir, delimiter=csv_delimiter)\n",
    "\n",
    "        self._data_matrix, self._user_age_int, self._user_occ_int, self._mov_gen_int = load_movielens_data(ratings)\n",
    "        self._num_users, self._num_movies = self._data_matrix.shape\n",
    "\n",
    "        # Compute the SVD.\n",
    "        s, u, vh = tf.linalg.svd(self._data_matrix, full_matrices=False)\n",
    "\n",
    "        # Keep only the largest singular values.\n",
    "        self._u_hat = u[:, :rank_k]#.astype(tf.float32)\n",
    "        self._s_hat = s[:rank_k]#.astype(tf.float32)\n",
    "        self._v_hat = vh[:, :rank_k]#.astype(tf.float32)\n",
    "\n",
    "        self._approx_ratings_matrix = tf.matmul(self._u_hat * self._s_hat,\n",
    "                                                tf.transpose(self._v_hat))\n",
    "\n",
    "        self._action_spec = array_spec.BoundedArraySpec(\n",
    "            shape=(),\n",
    "            dtype=np.int32,\n",
    "            minimum=0,\n",
    "            maximum=num_actions - 1,\n",
    "            name='action')\n",
    "        observation_spec = {\n",
    "            GLOBAL_KEY:\n",
    "                array_spec.ArraySpec(shape=[rank_k+2], dtype=np.float32), #creating +space for user age and occupation\n",
    "            PER_ARM_KEY:\n",
    "                array_spec.ArraySpec(\n",
    "                    shape=[num_actions, rank_k+1], dtype=np.float32), #creating +1 space for movie genre\n",
    "        }\n",
    "        self._time_step_spec = ts.time_step_spec(observation_spec)\n",
    "\n",
    "        self._current_user_indices = tf.zeros(batch_size, dtype=np.int32)\n",
    "        self._previous_user_indices = tf.zeros(batch_size, dtype=np.int32)\n",
    "\n",
    "        self._current_movie_indices = tf.zeros([batch_size, num_actions],\n",
    "                                               dtype=np.int32)\n",
    "        self._previous_movie_indices = tf.zeros([batch_size, num_actions],\n",
    "                                                dtype=np.int32)\n",
    "\n",
    "        self._observation = {\n",
    "            GLOBAL_KEY:\n",
    "                tf.zeros([batch_size, rank_k+2], dtype=np.int32), #making space like above for dimensions\n",
    "            PER_ARM_KEY:\n",
    "                tf.zeros([batch_size, num_actions, rank_k+1], dtype=np.int32),\n",
    "        }\n",
    "\n",
    "        super(MovieLensPerArmPyEnvironment, self).__init__(\n",
    "            observation_spec, self._action_spec, name=name)\n",
    "\n",
    "    @property\n",
    "    def batch_size(self):\n",
    "        return self._batch_size\n",
    "\n",
    "    @property\n",
    "    def batched(self):\n",
    "        return True\n",
    "\n",
    "    def _observe(self):\n",
    "        \n",
    "        #user section - random sample users\n",
    "        sampled_user_indices_np = np.random.randint(\n",
    "            self._num_users, size=self._batch_size)\n",
    "        sampled_user_indices_1d = tf.convert_to_tensor(sampled_user_indices_np, dtype=tf.int32)\n",
    "        sampled_user_indices = tf.expand_dims(sampled_user_indices_1d, axis=-1)\n",
    "        self._previous_user_indices = self._current_user_indices\n",
    "        self._current_user_indices = sampled_user_indices\n",
    "        \n",
    "        #sample feature values\n",
    "        sampled_user_ages = tf.gather_nd(indices=sampled_user_indices, params=self._user_age_int)\n",
    "        sampled_user_occ = tf.gather_nd(indices=sampled_user_indices, params=self._user_occ_int)\n",
    "        latent_user_features = tf.gather_nd(indices=sampled_user_indices, params=self._u_hat)\n",
    "        combined_user_features = tf.concat([latent_user_features\n",
    "                                                 , tf.expand_dims(sampled_user_ages, axis=-1)\n",
    "                                                 , tf.expand_dims(sampled_user_occ, axis=-1)], axis=1)\n",
    "        ###movie section\n",
    "\n",
    "        sampled_movie_indices_np = np.array([\n",
    "            random.sample(range(self._num_movies), self._num_actions)\n",
    "            for _ in range(self._batch_size)\n",
    "        ])\n",
    "        sampled_movie_indices = tf.convert_to_tensor(sampled_movie_indices_np, dtype=tf.int32)\n",
    "        print(sampled_movie_indices)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.movie_index_vector = tf.expand_dims(tf.reshape(sampled_movie_indices, shape=[-1]), axis=-1)\n",
    "        flat_genre_list = tf.gather_nd(indices=self.movie_index_vector, params=self._mov_gen_int) #shape of 1\n",
    "        reshaped_genre_features = tf.reshape(flat_genre_list, shape = [self._batch_size, self._num_actions])\n",
    "        latent_movie_features = tf.gather_nd(indices=movie_index_vector, params=self._v_hat) #shape of 2\n",
    "        # shape[0] = [40,20]\n",
    "        latent_movie_features = tf.reshape(latent_movie_features, shape=[self._batch_size, self._num_actions])\n",
    "        combined_movie_features = tf.concat([latent_movie_features\n",
    "                                             , reshaped_genre_features], axis=1)\n",
    "        current_movies = tf.reshape(combined_movie_features\n",
    "                                    , shape = [self._batch_size, self._num_actions, self.rank_k+1]\n",
    "                                   )\n",
    "\n",
    "        self._previous_movie_indices = self._current_movie_indices\n",
    "        self._current_movie_indices = sampled_movie_indices\n",
    "\n",
    "        batched_observations = {\n",
    "            GLOBAL_KEY:\n",
    "                combined_user_features,\n",
    "            PER_ARM_KEY:\n",
    "                current_movies,\n",
    "        }\n",
    "        return batched_observations\n",
    "\n",
    "    def _apply_action(self, action):\n",
    "        chosen_arm_indices = tf.gather_nd(indices=self._current_movie_indices, params=action)\n",
    "        return self._approx_ratings_matrix[self._current_user_indices,\n",
    "                                           chosen_arm_indices]\n",
    "\n",
    "    def _rewards_for_all_actions(self):\n",
    "        rewards_matrix = self._approx_ratings_matrix[\n",
    "            tf.expand_dims(self._previous_user_indices, axis=-1),\n",
    "            self._previous_movie_indices]\n",
    "        return rewards_matrix\n",
    "\n",
    "    def compute_optimal_action(self):\n",
    "        return np.argmax(self._rewards_for_all_actions(), axis=-1)\n",
    "\n",
    "    def compute_optimal_reward(self):\n",
    "        return np.max(self._rewards_for_all_actions(), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "d4188ae1-0859-4053-8a5f-b83c1e8a0c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = MovieLensPerArmPyEnvironment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "79623a28-4e47-4f0e-86de-b61382b939fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('observation spec: ', env.observation_spec())\n",
    "# print('\\nAn observation: ', env.reset().observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4348dcce-d92e-47c1-af00-ae5181c0184d",
   "metadata": {},
   "source": [
    "### Now that the environment is created, let's optimize\n",
    "\n",
    "Taken from here\n",
    "https://github.com/tensorflow/agents/blob/5e5915b0a3650a15e82e77af6e37f41a6c744689/tf_agents/bandits/agents/examples/v2/train_eval_movielens.py#L84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "ea63b13a-f613-40f3-8184-68d14e45f3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import os\n",
    "from absl import app\n",
    "from absl import flags\n",
    "\n",
    "import tensorflow as tf  # pylint: disable=g-explicit-tensorflow-version-import\n",
    "from tf_agents.bandits.agents import dropout_thompson_sampling_agent as dropout_ts_agent\n",
    "from tf_agents.bandits.agents import lin_ucb_agent\n",
    "from tf_agents.bandits.agents import linear_thompson_sampling_agent as lin_ts_agent\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent as eps_greedy_agent\n",
    "from tf_agents.bandits.agents.examples.v2 import trainer\n",
    "from tf_agents.bandits.environments import environment_utilities\n",
    "from tf_agents.bandits.environments import movielens_per_arm_py_environment\n",
    "from tf_agents.bandits.environments import movielens_py_environment\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.networks import q_network\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "TRAINING_LOOPS = 20000\n",
    "STEPS_PER_LOOP = 2\n",
    "\n",
    "RANK_K = 20\n",
    "NUM_ACTIONS = 20\n",
    "\n",
    "# LinUCB agent constants.\n",
    "\n",
    "AGENT_ALPHA = 10.0\n",
    "\n",
    "# epsilon Greedy constants.\n",
    "\n",
    "EPSILON = 0.05\n",
    "LAYERS = (50, 50, 50)\n",
    "LR = 0.005\n",
    "\n",
    "# Dropout TS constants.\n",
    "DROPOUT_RATE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "f1d468cf-446a-49d0-aee1-bff3c401e493",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "9d32f9df-0159-464f-bf11-c054f98ef0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MovieLensPerArmPyEnvironment(\n",
    "        rank_k=RANK_K,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_actions=NUM_ACTIONS,\n",
    ")\n",
    "environment = tf_py_environment.TFPyEnvironment(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c03aba-3f12-4375-998e-919585c2f9c1",
   "metadata": {},
   "source": [
    "### Note we will be using the reward function with this utility function\n",
    "\n",
    "```python\n",
    "@gin.configurable\n",
    "def compute_optimal_reward_with_movielens_environment(observation, environment):\n",
    "  \"\"\"Helper function for gin configurable Regret metric.\"\"\"\n",
    "  del observation\n",
    "  return tf.py_function(environment.compute_optimal_reward, [], tf.float32)\n",
    "\n",
    "@gin.configurable\n",
    "def compute_optimal_action_with_movielens_environment(observation,\n",
    "                                                      environment,\n",
    "                                                      action_dtype=tf.int32):\n",
    "  \"\"\"Helper function for gin configurable SuboptimalArms metric.\"\"\"\n",
    "  del observation\n",
    "  return tf.py_function(environment.compute_optimal_action, [], action_dtype)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "78599527-d82d-4048-a319-2dbf7e878db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_reward_fn = functools.partial(\n",
    "      environment_utilities.compute_optimal_reward_with_movielens_environment,\n",
    "      environment=environment)\n",
    "\n",
    "optimal_action_fn = functools.partial(\n",
    "  environment_utilities.compute_optimal_action_with_movielens_environment,\n",
    "  environment=environment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1d1011-8a9b-4f56-9ee7-9492b1a6f01b",
   "metadata": {},
   "source": [
    "### Below we will try different agents by selecting one of the enumerated types:\n",
    "\n",
    "```python\n",
    "flags.DEFINE_enum(\n",
    "    'agent', 'LinUCB', ['LinUCB', 'LinTS', 'epsGreedy', 'DropoutTS'],\n",
    "    'Which agent to use. Possible values: `LinUCB`, `LinTS`, `epsGreedy`,'\n",
    "    ' `DropoutTS`.')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "3a6a8c07-e655-49e1-871d-ae5e567c2256",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_TYPE = 'LinUCB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "795f6e5b-e98e-4d85-9935-59deae6ba60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if AGENT_TYPE == 'LinUCB':\n",
    "    agent = lin_ucb_agent.LinearUCBAgent(\n",
    "        time_step_spec=environment.time_step_spec(),\n",
    "        action_spec=environment.action_spec(),\n",
    "        tikhonov_weight=0.001,\n",
    "        alpha=AGENT_ALPHA,\n",
    "        dtype=tf.float32,\n",
    "        accepts_per_arm_features=True)\n",
    "\n",
    "elif AGENT_TYPE == 'LinTS':\n",
    "    agent = lin_ts_agent.LinearThompsonSamplingAgent(\n",
    "        time_step_spec=environment.time_step_spec(),\n",
    "        action_spec=environment.action_spec(),\n",
    "        dtype=tf.float32,\n",
    "        accepts_per_arm_features=True)\n",
    "\n",
    "elif AGENT_TYPE == 'epsGreedy':\n",
    "    network = (\n",
    "      global_and_arm_feature_network\n",
    "      .create_feed_forward_dot_product_network(\n",
    "          environment.time_step_spec().observation,\n",
    "          global_layers=LAYERS,\n",
    "          arm_layers=LAYERS))\n",
    "\n",
    "    agent = eps_greedy_agent.NeuralEpsilonGreedyAgent(\n",
    "        time_step_spec=environment.time_step_spec(),\n",
    "        action_spec=environment.action_spec(),\n",
    "        reward_network=network,\n",
    "        optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=LR),\n",
    "        epsilon=EPSILON,\n",
    "        emit_policy_info='predicted_rewards_mean',\n",
    "        info_fields_to_inherit_from_greedy=['predicted_rewards_mean'])\n",
    "\n",
    "elif AGENT_TYPE == 'DropoutTS':\n",
    "    train_step_counter = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "    def dropout_fn():\n",
    "        return tf.math.maximum(\n",
    "          tf.math.reciprocal_no_nan(1.01 +\n",
    "                                    tf.cast(train_step_counter, tf.float32)),\n",
    "          0.0003)\n",
    "\n",
    "    agent = dropout_ts_agent.DropoutThompsonSamplingAgent(\n",
    "        time_step_spec=environment.time_step_spec(),\n",
    "        action_spec=environment.action_spec(),\n",
    "        dropout_rate=dropout_fn,\n",
    "        network_layers=LAYERS,\n",
    "        optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=LR))\n",
    "\n",
    "regret_metric = tf_bandit_metrics.RegretMetric(optimal_reward_fn)\n",
    "suboptimal_arms_metric = tf_bandit_metrics.SuboptimalArmsMetric(\n",
    "  optimal_action_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4ebbb8-bc40-42a5-bbbd-9438d3ff2e74",
   "metadata": {},
   "source": [
    "### Now train the MAB Agent\n",
    "\n",
    "Create a local checkpoint folder if you already have not\n",
    "!mkdir checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "46b033cd-dd23-4e93-a33c-347f7e3915f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "67a9c912-b2b6-44c7-909a-d431316ce0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 991 1142  200 1605 1215  434  208 1051  233  305  942  941 1086 1586\n",
      "   871 1041 1645  483 1506  180]\n",
      " [ 721  182 1240 1114  866  915  332  208 1434  683 1514  587 1259 1665\n",
      "  1604  426  281 1506 1439  454]\n",
      " [ 518 1350 1420   96  618  134  629 1448  896  829  470  600 1465  836\n",
      "  1559  185 1388 1214 1580 1213]\n",
      " [ 493  919  876  632  735  624  850  617  154 1107  492 1621  662   17\n",
      "   353  717  309  149 1624    4]\n",
      " [ 424  230   17 1135  250 1608 1046 1256  305  529  800  475 1457   83\n",
      "   809  982 1199 1140  147  759]\n",
      " [1016  768 1127 1009 1346 1458  541  333 1289 1430  616 1347 1569 1277\n",
      "  1210  721 1371 1097 1002  562]\n",
      " [  91 1419  412  339  844  365  635  988 1189 1467 1293 1590  967  858\n",
      "   175  483   61    1  244  188]\n",
      " [1282 1271  164 1192  844  737  793  463  964   45 1400  801  196  947\n",
      "   897  152 1174 1156 1007  541]], shape=(8, 20), dtype=int32)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 800 values, but the requested shape has 160 [Op:Reshape]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[402], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m      \u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcheckpoint\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m      \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m      \u001b[49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtraining_loops\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRAINING_LOOPS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_loop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSTEPS_PER_LOOP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m      \u001b[49m\u001b[43madditional_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mregret_metric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuboptimal_arms_metric\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/bandits/agents/examples/v2/trainer.py:268\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(root_dir, agent, environment, training_loops, steps_per_loop, async_steps_per_loop, additional_metrics, get_replay_buffer_fn, get_training_loop_fn, training_data_spec_transformation_fn, save_policy, resume_training_loops)\u001b[0m\n\u001b[1;32m    265\u001b[0m   starting_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(starting_loop, training_loops):\n\u001b[0;32m--> 268\u001b[0m   \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m   checkpoint_manager\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m    270\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m save_policy \u001b[38;5;241m&\u001b[39m (i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/bandits/agents/examples/v2/trainer.py:87\u001b[0m, in \u001b[0;36m_get_training_loop.<locals>.training_loop\u001b[0;34m(train_step, metrics)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a function that runs a single training loop and logs metrics.\"\"\"\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(async_steps_per_loop):\n\u001b[0;32m---> 87\u001b[0m   \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m   _export_metrics_and_summaries(\n\u001b[1;32m     89\u001b[0m       step\u001b[38;5;241m=\u001b[39mtrain_step \u001b[38;5;241m*\u001b[39m async_steps_per_loop \u001b[38;5;241m+\u001b[39m batch_id, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n\u001b[1;32m     90\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mbatch_size\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/drivers/dynamic_step_driver.py:182\u001b[0m, in \u001b[0;36mDynamicStepDriver.run\u001b[0;34m(self, time_step, policy_state, maximum_iterations)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, time_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, policy_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, maximum_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    166\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Takes steps in the environment using the policy while updating observers.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03m    policy_state: Tensor with final step policy state.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtime_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpolicy_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmaximum_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximum_iterations\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/utils/common.py:188\u001b[0m, in \u001b[0;36mfunction_in_tf1.<locals>.maybe_wrap.<locals>.with_check_resource_vars\u001b[0;34m(*fn_args, **fn_kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m check_tf1_allowed()\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_eager_been_enabled():\n\u001b[1;32m    186\u001b[0m   \u001b[38;5;66;03m# We're either in eager mode or in tf.function mode (no in-between); so\u001b[39;00m\n\u001b[1;32m    187\u001b[0m   \u001b[38;5;66;03m# autodep-like behavior is already expected of fn.\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m resource_variables_enabled():\n\u001b[1;32m    190\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(MISSING_RESOURCE_VARIABLES_ERROR)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/drivers/dynamic_step_driver.py:191\u001b[0m, in \u001b[0;36mDynamicStepDriver._run\u001b[0;34m(self, time_step, policy_state, maximum_iterations)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See `run()` docstring for details.\"\"\"\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m time_step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m   time_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_time_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m policy_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    193\u001b[0m   policy_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mget_initial_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mbatch_size)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/environments/tf_environment.py:196\u001b[0m, in \u001b[0;36mTFEnvironment.current_time_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcurrent_time_step\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    186\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the current `TimeStep`.\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m  Returns:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m        corresponding to `observation_spec()`.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_current_time_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/environments/tf_py_environment.py:237\u001b[0m, in \u001b[0;36mTFPyEnvironment._current_time_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute(_current_time_step_py)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent_time_step\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 237\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_isolated_current_time_step_py\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m      \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# No inputs.\u001b[39;49;00m\n\u001b[1;32m    240\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_time_step_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcurrent_time_step_py_func\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_step_from_numpy_function_outputs(outputs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/environments/tf_py_environment.py:234\u001b[0m, in \u001b[0;36mTFPyEnvironment._current_time_step.<locals>._isolated_current_time_step_py\u001b[0;34m()\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_isolated_current_time_step_py\u001b[39m():\n\u001b[0;32m--> 234\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_current_time_step_py\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/environments/tf_py_environment.py:211\u001b[0m, in \u001b[0;36mTFPyEnvironment._execute\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    210\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool:\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mapply(fn, args\u001b[38;5;241m=\u001b[39margs, kwds\u001b[38;5;241m=\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/environments/tf_py_environment.py:230\u001b[0m, in \u001b[0;36mTFPyEnvironment._current_time_step.<locals>._current_time_step_py\u001b[0;34m()\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _check_not_called_concurrently(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock):\n\u001b[1;32m    229\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_step)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/environments/py_environment.py:195\u001b[0m, in \u001b[0;36mPyEnvironment.reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ts\u001b[38;5;241m.\u001b[39mTimeStep:\n\u001b[1;32m    181\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Starts a new sequence and returns the first `TimeStep` of this sequence.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m  Note: Subclasses cannot override this directly. Subclasses implement\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m        corresponding to `observation_spec()`.\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 195\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/bandits/environments/bandit_py_environment.py:64\u001b[0m, in \u001b[0;36mBanditPyEnvironment._reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_reset\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ts\u001b[38;5;241m.\u001b[39mTimeStep:\n\u001b[1;32m     57\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a time step containing an observation.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m  It should not be overridden by Bandit environment implementations.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m    A time step of type FIRST containing an observation.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m ts\u001b[38;5;241m.\u001b[39mrestart(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_observe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[1;32m     65\u001b[0m                     reward_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreward_spec())\n",
      "Cell \u001b[0;32mIn[392], line 152\u001b[0m, in \u001b[0;36mMovieLensPerArmPyEnvironment._observe\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    150\u001b[0m latent_movie_features \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mgather_nd(indices\u001b[38;5;241m=\u001b[39mmovie_index_vector, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_v_hat) \u001b[38;5;66;03m#shape of 2\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# shape[0] = [40,20]\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m latent_movie_features \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_movie_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_actions\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m combined_movie_features \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat([latent_movie_features\n\u001b[1;32m    154\u001b[0m                                      , reshaped_genre_features], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    155\u001b[0m current_movies \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(combined_movie_features\n\u001b[1;32m    156\u001b[0m                             , shape \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrank_k\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    157\u001b[0m                            )\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 800 values, but the requested shape has 160 [Op:Reshape]"
     ]
    }
   ],
   "source": [
    "trainer.train(\n",
    "      root_dir='checkpoint',\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      training_loops=TRAINING_LOOPS,\n",
    "      steps_per_loop=STEPS_PER_LOOP,\n",
    "      additional_metrics=[regret_metric, suboptimal_arms_metric])"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-12.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-12:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
