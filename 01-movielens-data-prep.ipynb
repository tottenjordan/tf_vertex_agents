{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bef58d66-b85e-49ca-baa1-eae9d3af08b4",
   "metadata": {},
   "source": [
    "# Preparing off-policy training data for RL\n",
    "\n",
    "> \"Off-policy\" refers to the situation where for a data record, given its observation, the current policy in training might not choose the same action as the one in said data record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0035c271-1aff-48cc-841f-38470a314aaf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load env config\n",
    "\n",
    "* use the prefix from `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5fe16f7-704a-4d31-96e9-8cd2c1cbc87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = 'mabv1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d04e4d-afd5-45f4-a5f5-db4126b3f514",
   "metadata": {},
   "source": [
    "**run the next cell to populate env vars**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67fb5c09-bdf4-4a7e-abb9-aae601788a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"wortz-project-352116\"\n",
      "PROJECT_NUM              = \"679926387543\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"679926387543-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"mabv1\"\n",
      "VERSION                  = \"v1\"\n",
      "\n",
      "BUCKET_NAME              = \"mabv1-wortz-project-352116-bucket\"\n",
      "BUCKET_URI               = \"gs://mabv1-wortz-project-352116-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://mabv1-wortz-project-352116-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/679926387543/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_ID      = \"wortz-project-352116.movielens_dataset_mabv1\"\n",
      "BIGQUERY_TABLE_ID        = \"wortz-project-352116.movielens_dataset_mabv1.training_dataset\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "REPOSITORY               = \"rl-movielens-mabv1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e10356aa-db4d-48e9-974f-caee57a3a29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mabv1-wortz-project-352116-bucket/config/\n",
      "gs://mabv1-wortz-project-352116-bucket/data/\n",
      "gs://mabv1-wortz-project-352116-bucket/neural-linear-bandits-v1/\n",
      "gs://mabv1-wortz-project-352116-bucket/vocabs/\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ff6716-afc3-4456-8784-f8f1d4796671",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86c8c72b-6472-47b5-836d-c924c75859a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5be08889-6644-46ac-bd9b-1ce6c2d533d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tensorflow/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/envs/tensorflow/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/envs/tensorflow/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/envs/tensorflow/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/envs/tensorflow/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/envs/tensorflow/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "from pprint import pprint\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# GPU\n",
    "from numba import cuda\n",
    "import gc\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "851a6ded-cf88-47b6-a31a-b0cfe28b6951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \n",
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61009c45-dbf3-494c-a67f-72d2b9aa9c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = cuda.get_current_device()\n",
    "# device.reset()\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17326c68-5251-486d-9558-57f42b932ca7",
   "metadata": {},
   "source": [
    "### Initialize GCP clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60ac9153-79b0-473f-98bf-a59237463ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad05d51-44be-4e80-a948-4969476ea0bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create `data_utils.py`\n",
    "\n",
    "> this will be used to support data processing throughout the development workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6d89382-80c2-4740-a65e-2589a36f911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPO_DOCKER_PATH_PREFIX = 'src'\n",
    "# RL_SUB_DIR              = 'per_arm_rl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db4bd3b9-bdf8-4819-aa5c-44a841f4d687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm -rf {REPO_DOCKER_PATH_PREFIX}/{RL_SUB_DIR}\n",
    "# ! mkdir -p {REPO_DOCKER_PATH_PREFIX}/{RL_SUB_DIR}\n",
    "# ! touch {REPO_DOCKER_PATH_PREFIX}/{RL_SUB_DIR}/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d14166e-2f0e-4370-aba1-259b1c60aca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/per_arm_rl/data_utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{RL_SUB_DIR}/data_utils.py\n",
    "# Copyright 2021 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#            http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# ============================================\n",
    "# features\n",
    "# ============================================\n",
    "\n",
    "def get_all_features():\n",
    "    \n",
    "    feats = {\n",
    "        # user - global context features\n",
    "        'user_id': tf.io.FixedLenFeature(shape=(), dtype=tf.string),\n",
    "        'user_rating': tf.io.FixedLenFeature(shape=(), dtype=tf.float32),\n",
    "        'bucketized_user_age': tf.io.FixedLenFeature(shape=(), dtype=tf.float32),\n",
    "        'user_occupation_text': tf.io.FixedLenFeature(shape=(), dtype=tf.string),\n",
    "        'user_occupation_label': tf.io.FixedLenFeature(shape=(), dtype=tf.int64),\n",
    "        'user_zip_code': tf.io.FixedLenFeature(shape=(), dtype=tf.string),\n",
    "        'user_gender': tf.io.FixedLenFeature(shape=(), dtype=tf.string),\n",
    "        'timestamp': tf.io.FixedLenFeature(shape=(), dtype=tf.int64),\n",
    "\n",
    "        # movie - per arm features\n",
    "        'movie_id': tf.io.FixedLenFeature(shape=(), dtype=tf.string),\n",
    "        'movie_title': tf.io.FixedLenFeature(shape=(), dtype=tf.string),\n",
    "        'movie_genres': tf.io.FixedLenFeature(shape=(1,), dtype=tf.int64),\n",
    "    }\n",
    "    \n",
    "    return feats\n",
    "\n",
    "# ================================================\n",
    "# converting features to `tf.train.Example` proto\n",
    "# ================================================\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"\n",
    "    Get byte features\n",
    "    \"\"\"\n",
    "    # value = tf.io.serialize_tensor(value)\n",
    "    # value = value.numpy()\n",
    "    if type(value) == list:\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "    else:\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[i.numpy() for i in [value]]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"\n",
    "    Get int64 feature\n",
    "    \"\"\"\n",
    "    if type(value) == list:\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=[int(v) for v in value]))\n",
    "    else:\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "    \n",
    "def _int64_list_feature(value):\n",
    "    \"\"\"\n",
    "    Get int64 list feature\n",
    "    \"\"\"\n",
    "    value = value.numpy().tolist()[0]\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _simple_string(value):\n",
    "    \"\"\"\n",
    "    Gender Feature - True = Male in the training dataset\n",
    "    \"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value).encode('utf-8')]))\n",
    "\n",
    "def _string_array(value, shape=1):\n",
    "    \"\"\"\n",
    "    Returns a bytes_list from a string / byte.\n",
    "    \"\"\"\n",
    "    value = value.numpy() # .tolist()[0]\n",
    "    # try:\n",
    "    #     value = value.numpy()\n",
    "    # except:\n",
    "    #     pass\n",
    "    if type(value) == list:\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(v) for v in value]))\n",
    "    else:\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value).encode('utf-8')]))\n",
    "\n",
    "def _float_feature(value, shape=1):\n",
    "    \"\"\"\n",
    "    Returns a float_list from a float / double.\n",
    "    \"\"\"\n",
    "    if type(value) == list:\n",
    "        return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "    else:\n",
    "        return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "    \n",
    "\n",
    "def build_example(data) -> tf.train.Example:\n",
    "    \"\"\"\n",
    "    Returns: A `tf.train.Example` object holding the same data as `data_row`.\n",
    "    \"\"\"\n",
    "    feature = {\n",
    "        # user - global context features \n",
    "        \"user_id\": _bytes_feature(data['user_id'])\n",
    "        , \"user_rating\": _float_feature(data['user_rating'])\n",
    "        , \"bucketized_user_age\": _float_feature(data['bucketized_user_age'])\n",
    "        , \"user_occupation_text\": _bytes_feature(data['user_occupation_text'])\n",
    "        , \"user_occupation_label\": _int64_feature(data['user_occupation_label'])\n",
    "        , \"user_zip_code\": _bytes_feature(data['user_zip_code'])\n",
    "        , \"user_gender\": _string_array(data['user_gender'])\n",
    "        , \"timestamp\": _int64_feature(data['timestamp'])\n",
    "        \n",
    "        # movie - per arm features\n",
    "        , \"movie_id\": _bytes_feature(data['movie_id'])\n",
    "        , \"movie_title\": _bytes_feature(data['movie_title'])\n",
    "        , \"movie_genres\": _int64_list_feature(data['movie_genres'])\n",
    "    }\n",
    "    example_proto = tf.train.Example(\n",
    "        features=tf.train.Features(feature=feature)\n",
    "    )\n",
    "    return example_proto\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# tf data parsing functions\n",
    "# ============================================\n",
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\n",
    "\n",
    "def parse_tfrecord(example):\n",
    "    \"\"\"\n",
    "    Reads a serialized example from GCS and converts to tfrecord\n",
    "    \"\"\"\n",
    "    feats = get_all_features()\n",
    "    \n",
    "    example = tf.io.parse_example(\n",
    "        example,\n",
    "        feats\n",
    "        # features=feats\n",
    "    )\n",
    "    return example\n",
    "\n",
    "# data loading and parsing\n",
    "def full_parse(data):\n",
    "    # used for interleave - takes tensors and returns a tf.dataset\n",
    "    data = tf.data.TFRecordDataset(data)\n",
    "    return data\n",
    "\n",
    "# ============================================\n",
    "# TF lookup dictionary\n",
    "# ============================================\n",
    "\n",
    "def get_dictionary_lookup_by_tf_data_key(key, dataset) -> Dict:\n",
    "    tensor = dataset.map(lambda x: x[key])\n",
    "    unique_elems = set()\n",
    "    for x in tensor:\n",
    "        val = x.numpy()\n",
    "        if type(val) is np.ndarray: # if multi dimesnional only grab first one\n",
    "            val = val[0]\n",
    "        unique_elems.add(val)\n",
    "    \n",
    "    #return a dictionary of keys by integer values for the feature space\n",
    "    return {val: i for i, val in enumerate(unique_elems)}\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# TF-Record Writer\n",
    "# ============================================\n",
    "def write_tfrecords(tfrecord_file, dataset):\n",
    "    with tf.io.TFRecordWriter(tfrecord_file) as writer:\n",
    "        for data_row in dataset:\n",
    "            example = build_example(data_row)\n",
    "            writer.write(example.SerializeToString())\n",
    "\n",
    "# ============================================\n",
    "# load movielens\n",
    "# ============================================\n",
    "def load_movielens_ratings(\n",
    "    ratings_dataset\n",
    "    , num_users: int\n",
    "    , num_movies: int\n",
    "    , user_age_lookup_dict: dict\n",
    "    , user_occ_lookup_dict: dict\n",
    "    , movie_gen_lookup_dict: dict\n",
    "):\n",
    "    \"\"\"\n",
    "    > loads (wide) movielens ratings data \n",
    "    > returns ratings matrix\n",
    "    \"\"\"\n",
    "    ratings_matrix = np.zeros([num_users, num_movies])\n",
    "    \n",
    "    local_data = ratings_dataset.map(\n",
    "        lambda x: {\n",
    "            'user_id': x['user_id']\n",
    "            ,'movie_id':  x['movie_id']\n",
    "            ,'user_rating':  x['user_rating']\n",
    "            ,'bucketized_user_age': x['bucketized_user_age']\n",
    "            ,'user_occupation_text': x['user_occupation_text']\n",
    "            ,'movie_genres': x['movie_genres'][0]\n",
    "        }\n",
    "    )\n",
    "    user_age_int = []\n",
    "    user_occ_int = []\n",
    "    mov_gen_int = []\n",
    "    \n",
    "    for row in local_data:\n",
    "        ratings_matrix[\n",
    "            int(row['user_id'].numpy()) - 1\n",
    "            , int(row['movie_id'].numpy()) - 1\n",
    "        ] = float(row['user_rating'].numpy())\n",
    "        \n",
    "        user_age_int.append(\n",
    "            float(user_age_lookup_dict[row['bucketized_user_age'].numpy()]) + .0001\n",
    "        )\n",
    "        user_occ_int.append(\n",
    "            float(user_occ_lookup_dict[row['user_occupation_text'].numpy()]) + .0001\n",
    "        )\n",
    "        mov_gen_int.append(\n",
    "            float(movie_gen_lookup_dict[row['movie_genres'].numpy()]) + .0001\n",
    "        ) \n",
    "    return ratings_matrix, np.array(user_age_int), np.array(user_occ_int), np.array(mov_gen_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17762dd-50c3-48a1-b061-ed7575373754",
   "metadata": {},
   "source": [
    "## Prepare Movielens dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fd55a7-c3a5-4a44-981f-9ed3d22da39b",
   "metadata": {},
   "source": [
    "### load data from Tensorflow Datasets\n",
    "\n",
    "* see [TFDS documentation](https://www.tensorflow.org/datasets/catalog/movielens#movielens100k-ratings) for more details on this dataset, feature descriptions, and other versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b870c306-0bb5-454d-82d4-a1a086480e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([45.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'357'], dtype=object)>,\n",
      " 'movie_title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"One Flew Over the Cuckoo's Nest (1975)\"], dtype=object)>,\n",
      " 'raw_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([46.], dtype=float32)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([879024327])>,\n",
      " 'user_gender': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'138'], dtype=object)>,\n",
      " 'user_occupation_label': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([4])>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'doctor'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>,\n",
      " 'user_zip_code': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'53211'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "\n",
    "for x in ratings.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53de08f1-f581-4437-9d46-89ec79b18f7f",
   "metadata": {},
   "source": [
    "### write dataset to TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "726ea348-c0d3-4fbb-8d4d-1dd37887ae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.per_arm_rl import data_utils # as data_utils\n",
    "\n",
    "TF_RECORD_FILE = \"ml-ratings-100k-full.tfrecord\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2f84536-bcbc-4be6-9701-ee936c51586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_utils.write_tfrecords(TF_RECORD_FILE, ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e784205b-3c94-4aec-b271-e9bef7fdf9ee",
   "metadata": {},
   "source": [
    "### save TF Records to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ee120b0-dc8e-4f17-92bc-2139963d5579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mabv1-wortz-project-352116-bucket/data/ml-ratings-100k-full.tfrecord\n",
      "gs://mabv1-wortz-project-352116-bucket/data/train/\n",
      "gs://mabv1-wortz-project-352116-bucket/data/val/\n"
     ]
    }
   ],
   "source": [
    "LOCAL_TF_RECORD = f\"./{TF_RECORD_FILE}\"\n",
    "\n",
    "! gsutil -q cp $LOCAL_TF_RECORD $DATA_PATH/\n",
    "\n",
    "! gsutil ls $DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e60b6754-623c-47e1-b570-e7a1b42d6987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to train\n",
    "! gsutil -q cp $LOCAL_TF_RECORD $DATA_PATH/train/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a150e2-29c1-42e5-b513-85f6b27bafd6",
   "metadata": {},
   "source": [
    "## validate TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afdbc480-8977-4caf-b08f-29a665ef3f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://mabv1-wortz-project-352116-bucket/data/ml-ratings-100k-full.tfrecord']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7bde3b62-cf77-4750-ab69-47638cbc7184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1cb0935-4de2-4812-a983-414ca17755cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(3,), dtype=float32, numpy=array([45., 25., 18.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(3, 1), dtype=int64, numpy=\n",
      "array([[7],\n",
      "       [4],\n",
      "       [4]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'357', b'709', b'412'], dtype=object)>,\n",
      " 'movie_title': <tf.Tensor: shape=(3,), dtype=string, numpy=\n",
      "array([b\"One Flew Over the Cuckoo's Nest (1975)\",\n",
      "       b'Strictly Ballroom (1992)', b'Very Brady Sequel, A (1996)'],\n",
      "      dtype=object)>,\n",
      " 'timestamp': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([879024327, 875654590, 882075110])>,\n",
      " 'user_gender': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'True', b'True', b'True'], dtype=object)>,\n",
      " 'user_id': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'138', b'92', b'301'], dtype=object)>,\n",
      " 'user_occupation_label': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([ 4,  5, 17])>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'doctor', b'entertainment', b'student'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(3,), dtype=float32, numpy=array([4., 2., 4.], dtype=float32)>,\n",
      " 'user_zip_code': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'53211', b'80525', b'55439'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(data_utils.parse_tfrecord)\n",
    "\n",
    "for x in train_dataset.batch(3).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add6d7f1-aa8a-4459-8d7a-e8f6363edede",
   "metadata": {},
   "source": [
    "## Generate look-up dicts\n",
    "\n",
    "**TODO** - use more Tensorflow native method for generating vocabs and stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73e451f-865d-4614-a77d-a1ef1dce0714",
   "metadata": {},
   "source": [
    "### unique IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b468833-642b-436f-8ddb-692f9221e38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(unique_movie_ids) : 1682\n",
      "unique_movie_ids      : [b'1' b'10']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique movies and users\n",
    "unique_movie_ids = train_dataset.map(lambda x: x[\"movie_id\"])\n",
    "\n",
    "unique_movie_ids = np.unique([x.numpy() for x in unique_movie_ids])\n",
    "\n",
    "MOVIELENS_NUM_MOVIES = len(unique_movie_ids)\n",
    "\n",
    "print(f\"len(unique_movie_ids) : {len(unique_movie_ids)}\")\n",
    "print(f\"unique_movie_ids      : {unique_movie_ids[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "889c41d2-c4df-496a-8424-bba6bb3d0aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(unique_occ_ids) : 21\n",
      "unique_occ_ids      : [b'administrator' b'artist']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique movies and users\n",
    "# unique_movie_ids = ratings.map(lambda x: x[\"movie_id\"])\n",
    "unique_occ_ids = train_dataset.map(lambda x: x[\"user_occupation_text\"])\n",
    "\n",
    "unique_occ_ids = np.unique([x.numpy() for x in unique_occ_ids])\n",
    "\n",
    "NUM_OCCS = len(unique_occ_ids)\n",
    "\n",
    "print(f\"len(unique_occ_ids) : {len(unique_occ_ids)}\")\n",
    "print(f\"unique_occ_ids      : {unique_occ_ids[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "089c1bf7-f5ac-4343-8dae-a8f1c908a9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(unique_user_ids) : 943\n",
      "unique_user_ids      : [b'1' b'10']\n"
     ]
    }
   ],
   "source": [
    "# unique_user_ids = ratings.map(lambda x: x[\"user_id\"])\n",
    "unique_user_ids = train_dataset.map(lambda x: x[\"user_id\"])\n",
    "\n",
    "unique_user_ids = np.unique([x.numpy() for x in unique_user_ids])\n",
    "\n",
    "MOVIELENS_NUM_USERS = len(unique_user_ids)\n",
    "\n",
    "print(f\"len(unique_user_ids) : {len(unique_user_ids)}\")\n",
    "print(f\"unique_user_ids      : {unique_user_ids[:2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e507fd5b-c398-41ea-8b5c-7a6b7e4886d2",
   "metadata": {},
   "source": [
    "### lookup dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b17cf48c-e0e2-4d65-9b4b-25d7c50d0502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER_AGE_DIM: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1.0: 0, 35.0: 1, 45.0: 2, 18.0: 3, 50.0: 4, 56.0: 5, 25.0: 6}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USER_AGE_LOOKUP = data_utils.get_dictionary_lookup_by_tf_data_key(\n",
    "    key = 'bucketized_user_age'\n",
    "    , dataset= train_dataset\n",
    ")\n",
    "\n",
    "USER_AGE_DIM = len(USER_AGE_LOOKUP)\n",
    "print(f\"USER_AGE_DIM: {USER_AGE_DIM}\")\n",
    "\n",
    "USER_AGE_LOOKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "188f1142-c814-4f6f-9ae6-9dddeaa1005b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER_OCC_DIM: 21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{b'homemaker': 0,\n",
       " b'technician': 1,\n",
       " b'engineer': 2,\n",
       " b'administrator': 3,\n",
       " b'writer': 4,\n",
       " b'retired': 5,\n",
       " b'librarian': 6,\n",
       " b'entertainment': 7,\n",
       " b'scientist': 8,\n",
       " b'doctor': 9,\n",
       " b'marketing': 10,\n",
       " b'programmer': 11,\n",
       " b'lawyer': 12,\n",
       " b'educator': 13,\n",
       " b'executive': 14,\n",
       " b'other': 15,\n",
       " b'healthcare': 16,\n",
       " b'salesman': 17,\n",
       " b'artist': 18,\n",
       " b'none': 19,\n",
       " b'student': 20}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USER_OCC_LOOKUP = data_utils.get_dictionary_lookup_by_tf_data_key(\n",
    "    key = 'user_occupation_text'\n",
    "    , dataset= train_dataset\n",
    ")\n",
    "USER_OCC_DIM = len(USER_OCC_LOOKUP)\n",
    "print(f\"USER_OCC_DIM: {USER_OCC_DIM}\")\n",
    "\n",
    "USER_OCC_LOOKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6aafa8-8550-417a-8a67-ff602d79c8c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MOVIE_GEN_LOOKUP = data_utils.get_dictionary_lookup_by_tf_data_key(\n",
    "    key = 'movie_genres'\n",
    "    , dataset= train_dataset\n",
    ")\n",
    "MOVIE_GEN_DIM = len(MOVIE_GEN_LOOKUP)\n",
    "print(f\"MOVIE_GEN_DIM: {MOVIE_GEN_DIM}\")\n",
    "\n",
    "MOVIE_GEN_LOOKUP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e68a8e3-c56c-40d8-9544-992e62488b3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## create `data_config.py`\n",
    "\n",
    "> write data config for subsequent notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1557f99e-9fa4-4fd6-9c1b-96b42f9b353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = f'''\n",
    "USER_AGE_LOOKUP       = {USER_AGE_LOOKUP}\n",
    "USER_AGE_DIM          = {USER_AGE_DIM}\n",
    "\n",
    "USER_OCC_LOOKUP       = {USER_OCC_LOOKUP}\n",
    "USER_OCC_DIM          = {USER_OCC_DIM}\n",
    "\n",
    "MOVIE_GEN_LOOKUP      = {MOVIE_GEN_LOOKUP}\n",
    "MOVIE_GEN_DIM         = {MOVIE_GEN_DIM}\n",
    "\n",
    "MOVIELENS_NUM_MOVIES  = {MOVIELENS_NUM_MOVIES}\n",
    "MOVIELENS_NUM_USERS   = {MOVIELENS_NUM_USERS}\n",
    "'''\n",
    "# TODO - cleanup\n",
    "with open(f'{REPO_DOCKER_PATH_PREFIX}/{RL_SUB_DIR}/data_config.py', 'w') as f:\n",
    "    f.write(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1c21b7-1778-486a-9cd8-048fc41df4f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Validate creating the ratings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60f017a-912e-41ed-a37f-70d923b21f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.per_arm_rl import data_config # as data_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b07ca7-f609-46cf-8234-6ceb4e4c1fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config.USER_AGE_LOOKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5625bfa-c1b8-4fc0-8c91-1f9569ce84ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_config.USER_OCC_LOOKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b19bdd-1564-4781-b1b9-6a2bef3fab93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_config.MOVIE_GEN_LOOKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9d1512-9318-46dd-999d-f87f9c9d9b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_load = data_utils.load_movielens_ratings(\n",
    "    ratings_dataset = train_dataset\n",
    "    , num_users = data_config.MOVIELENS_NUM_USERS\n",
    "    , num_movies = data_config.MOVIELENS_NUM_MOVIES\n",
    "    , user_age_lookup_dict = data_config.USER_AGE_LOOKUP\n",
    "    , user_occ_lookup_dict = data_config.USER_OCC_LOOKUP\n",
    "    , movie_gen_lookup_dict = data_config.MOVIE_GEN_LOOKUP\n",
    ")\n",
    "\n",
    "test_dataset_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55014ae-fc94-4a1a-a2dd-fde3970b5387",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_matrix = test_dataset_load[0]\n",
    "print(ratings_matrix.shape)\n",
    "ratings_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c88f5ea-0d35-430f-82f7-643797d8c861",
   "metadata": {},
   "source": [
    "# Data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4472f001-870d-4075-85c9-1d143b3a2928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.per_arm_rl import data_utils\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720e135e-3397-42bf-bb62-782e962c95a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173fc850-0989-46d5-891e-0b097a8a1701",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in test.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0bae96-18d4-4805-b853-10190b60670f",
   "metadata": {},
   "source": [
    "### write TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25610e02-8902-4be5-b034-13330f1d0d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_RECORD_FILE_train = \"ml-ratings-100k-train.tfrecord\"\n",
    "LOCAL_TF_RECORD_train = f\"./{TF_RECORD_FILE_train}\"\n",
    "\n",
    "TF_RECORD_FILE_val = \"ml-ratings-100k-val.tfrecord\"\n",
    "LOCAL_TF_RECORD_val = f\"./{TF_RECORD_FILE_val}\"\n",
    "\n",
    "TRAIN_DATA_PATH = f\"{DATA_PATH}/train\"\n",
    "VAL_DATA_PATH = f\"{DATA_PATH}/val\"\n",
    "\n",
    "print(f\"TRAIN_DATA_PATH  : {TRAIN_DATA_PATH}\")\n",
    "print(f\"VAL_DATA_PATH    : {VAL_DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8034f48a-fd06-4f76-9f07-ba8142053625",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_utils.write_tfrecords(TF_RECORD_FILE_train, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acec3b8c-f28e-4729-a79e-be89dd746d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_utils.write_tfrecords(TF_RECORD_FILE_val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f8a411-73af-4bbf-8749-aee2727f1e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil -q cp $LOCAL_TF_RECORD_train $TRAIN_DATA_PATH/\n",
    "\n",
    "! gsutil -q cp $LOCAL_TF_RECORD_val $VAL_DATA_PATH/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39772781-5f4d-4374-868f-ec97c11375d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil ls $DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc90ffc-d2fd-4136-872f-9f7d7aa6b3b4",
   "metadata": {},
   "source": [
    "### validate TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429a30d0-91da-4b0b-bac2-0708d981eb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## validate\n",
    "\n",
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/train'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690f448f-7646-4cf6-9ca5-5026f89293d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "\n",
    "train_dataset = train_dataset.map(data_utils.parse_tfrecord)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5185e569-fdcd-43c9-841f-dbbf1af5f03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique movies and users\n",
    "unique_user_ratings = train_dataset.map(lambda x: x[\"user_rating\"])\n",
    "\n",
    "unique_user_ratings = np.unique([x.numpy() for x in unique_user_ratings])\n",
    "\n",
    "unique_user_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a943f450-6352-4c4e-a3c6-73638476ac4b",
   "metadata": {},
   "source": [
    "# EDA - TODO\n",
    "\n",
    "* RLDS dataset utils [guide](https://colab.sandbox.google.com/github/google-research/rlds/blob/main/rlds/examples/rlds_performance.ipynb#scrollTo=nGMkkZI9gGVD)\n",
    "* RLDS [examples](https://colab.sandbox.google.com/github/google-research/rlds/blob/main/rlds/examples/rlds_examples.ipynb#scrollTo=nGMkkZI9gGVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e843ad51-dec1-48f3-9d93-ff0cc73cd11d",
   "metadata": {},
   "source": [
    "### size of dataset\n",
    "\n",
    "> Just so that we know how big is the dataset we play with, lets first compute the number of episodes and steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fc544b-8187-442c-9269-6835a455657c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of dataset\n",
    "episodes = 0\n",
    "steps = 0\n",
    "for episode in dataset:\n",
    "    episodes += 1\n",
    "    steps += episode[rlds.STEPS].cardinality()\n",
    "\n",
    "print(f'Episodes: {episodes}, steps: {steps}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15e955d-c633-4c52-9b38-b46113955d41",
   "metadata": {},
   "source": [
    "### Computing the total reward\n",
    "\n",
    "We will experiment with RL dataset pipeline performance by trying to compute a sum of steps' rewards returned in all episodes of the example dataset. The starting point implementation is a simple Python's double loop over episodes and steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3730a79c-6379-4f39-9898-6bfbacd81d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_return(episode_dataset):\n",
    "  result = 0\n",
    "  for episode in episode_dataset:\n",
    "    for step in episode[rlds.STEPS]:\n",
    "      result += step[rlds.REWARD]\n",
    "  return result\n",
    "\n",
    "benchmark(compute_return, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a0df32-5a3b-4309-804e-562a841abee6",
   "metadata": {},
   "source": [
    "### Prefetching\n",
    " \n",
    "The double loop from the example above is very simple, while execution time is quite significant given the total number of steps in the dataset. One could expect the source of slowness is retrieval of elements from the dataset. If so, prefetching a dataset could help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba3fc06-6e5d-4bc9-a82b-61f56cc3834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_return(episode_dataset):\n",
    "    result = 0\n",
    "    for episode in episode_dataset.prefetch(2):\n",
    "        for step in episode[rlds.STEPS].prefetch(2):\n",
    "            result += step[rlds.REWARD]\n",
    "    return result\n",
    "\n",
    "benchmark(compute_return, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63026cad-9a90-4592-a791-0f566f9b4ac6",
   "metadata": {},
   "source": [
    "Python loop can be replaced with a [tf.data.Dataset.reduce](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#reduce) operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe6f50e-2891-4374-860b-543df7def0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def episode_return_sum(episode):\n",
    "    return episode[rlds.STEPS].reduce(np.float32(0), lambda x, step: step[rlds.REWARD] + x)\n",
    "\n",
    "def compute_return(episode_dataset):\n",
    "    return episode_dataset.reduce(np.float32(0), lambda x, episode: episode_return_sum(episode) + x)\n",
    "\n",
    "benchmark(compute_return, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8deb05-a8d1-413f-9aae-6624e4e19fdf",
   "metadata": {},
   "source": [
    "### Vectorized transformations\n",
    "\n",
    "An example we analyzed so far focused on computing aggregated statistics for a given dataset. Sometimes it is required to perform custom per-step modifications of the dataset instead. For that reason RLDS provides *map_nested_steps* operation that maintains the episodic structure. In this example, we will try to implement a simple transformation ourselves with the use of [tf.data.Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) operators. Lets implement a transformation which changes a given episode dataset into a collection of steps with doubled reward values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55b5c5c-4f9c-4a12-abef-351760fe656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_reward(step):\n",
    "    step[rlds.REWARD] *= 2\n",
    "    return step\n",
    "\n",
    "double_reward_dataset = dataset.flat_map(lambda x: x[rlds.STEPS]).map(lambda step : double_reward(step))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab91bba6-bee3-498b-84eb-2ecb484888e7",
   "metadata": {},
   "source": [
    "Lets now measure the performance of the new dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650322fa-91b6-43aa-a173-0b07fde86590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_return(step_dataset):\n",
    "    return step_dataset.batch(100).reduce(np.float32(0), lambda x, step: tf.math.reduce_sum(step[rlds.REWARD]) + x)\n",
    "\n",
    "benchmark(compute_return, double_reward_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b800ef-2db1-4040-af13-3621c9396dd6",
   "metadata": {},
   "source": [
    "Similarly to the previous examples, the main bottleneck is the per-step call of the *double_reward* function. We can reduce that overhead by first batching multiple steps, then applying vectorized version of the *double_reward* and un-batching the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a21ed58-22f4-4851-b561-41039007b49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_double_reward(steps):\n",
    "    return tf.vectorized_map(double_reward, steps)\n",
    "\n",
    "double_reward_dataset = dataset.flat_map(lambda x: x[rlds.STEPS]).batch(100).map(vectorized_double_reward).unbatch()\n",
    "\n",
    "benchmark(compute_return, double_reward_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24c822e-b652-494d-bbcd-63d9ed6d1353",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31a3a9b-3a56-4eea-a4e2-4e8aa10963e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c27d4393-0017-4180-a9e8-eac13f4ed477",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Vocab Generation - TODO\n",
    "\n",
    "* see [working with preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ed52ec0-6434-4d06-804b-f6cefe4b606f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([45.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'357'], dtype=object)>,\n",
      " 'movie_title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"One Flew Over the Cuckoo's Nest (1975)\"], dtype=object)>,\n",
      " 'raw_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([46.], dtype=float32)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([879024327])>,\n",
      " 'user_gender': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'138'], dtype=object)>,\n",
      " 'user_occupation_label': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([4])>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'doctor'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>,\n",
      " 'user_zip_code': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'53211'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_SIZE = 128\n",
    "\n",
    "for x in ratings.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "83a01e03-2d10-4b12-91e5-a55e4f615315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "str_features  : ['movie_id', 'user_id', 'user_occupation_text']\n",
      "int_features  : ['bucketized_user_age', 'timestamp', 'movie_genres']\n",
      "feature_names : ['movie_id', 'user_id', 'user_occupation_text', 'bucketized_user_age', 'timestamp', 'movie_genres']\n"
     ]
    }
   ],
   "source": [
    "str_features = [\n",
    "    \"movie_id\", \"user_id\", \"user_occupation_text\"\n",
    "    # \"user_zip_code\", \"user_occupation_text\", \"movie_title\"\n",
    "]\n",
    "\n",
    "int_features = [\n",
    "    \"timestamp\", \"movie_genres\", \n",
    "    # \"user_occupation_label\", \"user_gender\"\n",
    "]\n",
    "\n",
    "float_features = [\n",
    "    \"bucketized_user_age\", \"user_rating\",\n",
    "    # \"raw_user_age\"\n",
    "]\n",
    "\n",
    "feature_names = str_features + int_features + float_features\n",
    "\n",
    "print(f\"str_features  : {str_features}\")\n",
    "print(f\"int_features  : {int_features}\")\n",
    "print(f\"float_features  : {float_features}\")\n",
    "print(f\"feature_names : {feature_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6ce5a6-821b-4387-b02b-90be4bb8b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabularies = {}\n",
    "\n",
    "# for feature_name in feature_names:\n",
    "#     vocab = ratings.batch(1_000_000).map(lambda x: x[feature_name])\n",
    "#     vocabularies[feature_name] = np.unique(np.concatenate(list(vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e66b992-2627-44dd-98a7-82252ed1ea6c",
   "metadata": {},
   "source": [
    "### movie title lookup\n",
    "\n",
    "* see [Turning categorical features into embeddings](https://www.tensorflow.org/recommenders/examples/featurization#turning_categorical_features_into_embeddings) for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec011e38-9b57-47b2-8016-5071c29a5faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.preprocessing.string_lookup.StringLookup at 0x7f74c8550eb0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_title_lookup = tf.keras.layers.StringLookup()\n",
    "movie_title_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ecf7275-1870-463c-9f01-4e6e37dd5a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['[UNK]', 'Star Wars (1977)', 'Contact (1997)']\n"
     ]
    }
   ],
   "source": [
    "movie_title_lookup.adapt(ratings.map(lambda x: x[\"movie_title\"]))\n",
    "# movie_title_lookup.adapt(train_dataset.map(lambda x: x[\"movie_title\"]))\n",
    "\n",
    "print(f\"Vocabulary: {movie_title_lookup.get_vocabulary()[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab4c616-00ef-4bf4-bdbe-f345cb3ea7a9",
   "metadata": {},
   "source": [
    "Once we have this we can use the layer to translate raw tokens to embedding ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "26076556-0365-4bde-b7ea-a9ced76a0503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int64, numpy=array([ 1, 58])>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_title_lookup([\"Star Wars (1977)\", \"One Flew Over the Cuckoo's Nest (1975)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c48e79cd-976d-40e4-988c-4aaaee338971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1665"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_title_lookup.vocab_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea62f53f-d6b3-4f10-afd3-ad1d5fa76141",
   "metadata": {},
   "source": [
    "#### define embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8e299684-9508-462e-9dcb-b92444512f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.embedding.Embedding at 0x7f74c8558160>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_title_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=movie_title_lookup.vocab_size(),\n",
    "    output_dim=EMBEDDING_SIZE\n",
    ")\n",
    "\n",
    "movie_title_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9332b9-a664-4143-a8d2-e016c2a270a3",
   "metadata": {},
   "source": [
    "**example embeddings from movie title:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9c9c254f-a266-4273-8508-3f98e6079ac7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 128), dtype=float32, numpy=\n",
       "array([[ 0.02504338, -0.0012939 ,  0.04811487, -0.02999126, -0.0292394 ,\n",
       "         0.01156382,  0.03041414, -0.02798716,  0.00799823,  0.04248938,\n",
       "        -0.04263956, -0.01784793,  0.02749519, -0.00937803, -0.01001156,\n",
       "        -0.0056101 ,  0.03250836, -0.00172166, -0.0108378 , -0.04652712,\n",
       "         0.04713202,  0.00197013, -0.0049839 , -0.01328664, -0.00308267,\n",
       "         0.04895042, -0.04782685,  0.00406177,  0.03135257, -0.02687558,\n",
       "         0.01241463, -0.04897828,  0.01407217, -0.0348866 , -0.0373833 ,\n",
       "        -0.00677862,  0.01129251,  0.00500541,  0.01277152,  0.01554528,\n",
       "        -0.01913993, -0.02839179, -0.00459641,  0.02090592, -0.00293946,\n",
       "         0.02296934, -0.02400823, -0.03008862,  0.04921992, -0.00659008,\n",
       "         0.04569877,  0.02329716,  0.00493069, -0.01955005,  0.02327912,\n",
       "        -0.02437162,  0.04842639, -0.01809146, -0.01159244, -0.02352436,\n",
       "         0.00771639, -0.04491389, -0.02470828,  0.02996274, -0.0112378 ,\n",
       "        -0.03083922, -0.00064022,  0.04087969,  0.01504406,  0.00270113,\n",
       "         0.01802838,  0.01754174, -0.00634649,  0.04517454,  0.0185186 ,\n",
       "        -0.04658556, -0.02517147,  0.00523322,  0.0022864 ,  0.02925104,\n",
       "        -0.0070715 ,  0.04383314,  0.03611768,  0.01369358,  0.02870871,\n",
       "         0.01642777,  0.01856947,  0.04896023, -0.02373786, -0.03556041,\n",
       "         0.04617326, -0.04291807, -0.02217703, -0.03177377, -0.03275541,\n",
       "         0.01175636,  0.04684966, -0.02081529, -0.00733521, -0.03661783,\n",
       "        -0.04097661, -0.03884535, -0.01133027, -0.02896965,  0.04198474,\n",
       "        -0.02239027, -0.01627518,  0.03756322,  0.03668908,  0.02979683,\n",
       "         0.03922964,  0.00652919, -0.03670173,  0.04374054, -0.0030681 ,\n",
       "         0.02150017,  0.03785069, -0.03278086, -0.04837065,  0.02009029,\n",
       "        -0.04482074,  0.03286371, -0.04887689,  0.03774024,  0.0462541 ,\n",
       "        -0.02501148,  0.03095749,  0.04917483]], dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_title_model = tf.keras.Sequential([movie_title_lookup, movie_title_embedding])\n",
    "\n",
    "movie_title_model([\"Star Wars (1977)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c93623-2378-4fb4-8d81-067034136ec9",
   "metadata": {},
   "source": [
    "### movie genres\n",
    "\n",
    "> ragged text layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdbfc70-768a-4c51-ba50-c760271bc2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# genre_text_vectorizer = tf.keras.layers.TextVectorization() - no genre text available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e9109e07-9a82-467b-a16c-54429be4f73d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# genre_lookup = tf.keras.layers.IntegerLookup()\n",
    "# genre_lookup\n",
    "\n",
    "# MOVIE_GEN_DIM = len(MOVIE_GEN_LOOKUP)\n",
    "# genre_text_vectorizer.adapt(ratings.map(lambda x: x[\"movie_genres\"]))\n",
    "# # genre_text_vectorizer.adapt(train_dataset.map(lambda x: x[\"movie_genres\"]))\n",
    "\n",
    "# genre_text_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "08ea1052-4376-4c5c-bb19-13f7237b6f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# genre_text_vectorizer = tf.keras.layers.TextVectorization(\n",
    "#     max_tokens=max_tokens,\n",
    "#     ngrams=ngrams\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "10b49976-7b84-48b3-9e49-c2ece684f842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = np.array([vocab_dict['track_name_pl']]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf75905f-1ceb-484a-84ae-233ec3213938",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# start = time.time()\n",
    "# text_layer = tf.keras.layers.TextVectorization(\n",
    "#     max_tokens=max_tokens,\n",
    "#     ngrams=ngrams\n",
    "# )\n",
    "# text_layer.adapt(train_parsed.map(lambda x: tf.reshape(x[f'{feature_name}'], [-1, MAX_PLAYLIST_LENGTH, 1])))\n",
    "# end = time.time()\n",
    "\n",
    "# logging.info(f'Layer adapt elapsed time: {round((end - start), 2)} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75e91d2-99d8-48c7-a753-d875af572afd",
   "metadata": {},
   "source": [
    "### movie ID (action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b95884-edb8-4509-a634-3808a65a0d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_ACTION = 'movie_id'\n",
    "FEATURE_REWARD = 'user_rating'\n",
    "\n",
    "def process_example(example_proto):\n",
    "    \"\"\"\n",
    "    Returns a dataset of actions for each example.\n",
    "    \"\"\"\n",
    "    _, sequence_feature = tf.io.parse_single_sequence_example(\n",
    "        example_proto,\n",
    "        sequence_features={\n",
    "            FEATURE_ACTION:\n",
    "                # tf.io.FixedLenSequenceFeature([], dtype=tf.int64, default_value=None),\n",
    "                tf.io.FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
    "        })\n",
    "    actions = sequence_feature[FEATURE_ACTION]\n",
    "    return tf.data.Dataset.from_tensor_slices(actions)\n",
    "\n",
    "\n",
    "def generate_vocabulary(\n",
    "    train_data_path, \n",
    "    output_vocabulary_file,\n",
    "    max_items_to_process=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate a vocabulary file for actions.\n",
    "    \"\"\"\n",
    "\n",
    "    dataset_files = tf.io.gfile.glob(train_data_path)\n",
    "\n",
    "    example_dataset = tf.data.RecordIODataset(dataset_files)\n",
    "    action_dataset = example_dataset.interleave(\n",
    "        process_example,\n",
    "        cycle_length=16,\n",
    "        block_length=16,\n",
    "        num_parallel_calls=10,\n",
    "        deterministic=False)\n",
    "\n",
    "    if max_items_to_process:\n",
    "        action_dataset = action_dataset.take(max_items_to_process)\n",
    "\n",
    "    action_lookup_layer = IntegerLookup(mask_value=None, num_oov_indices=0)\n",
    "    action_lookup_layer.adapt(action_dataset)\n",
    "\n",
    "    action_vocabulary = action_lookup_layer.get_vocabulary()\n",
    "\n",
    "    with tf.io.gfile.GFile(output_vocabulary_file, 'w') as output_file:\n",
    "        output_file.write('\\n'.join(str(action) for action in action_vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f572b84e-9a6d-4178-a301-db0884712940",
   "metadata": {},
   "source": [
    "### Generate Vocab - sequences - TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7e5f93-ab46-456c-92d8-2abb677e54e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_ACTION = 'movie_id'\n",
    "FEATURE_REWARD = 'user_rating'\n",
    "\n",
    "def process_example(example_proto):\n",
    "    \"\"\"\n",
    "    Returns a dataset of actions for each example.\n",
    "    \"\"\"\n",
    "    _, sequence_feature = tf.io.parse_single_sequence_example(\n",
    "        example_proto\n",
    "        , sequence_features={\n",
    "            FEATURE_ACTION:\n",
    "                tf.io.FixedLenSequenceFeature([], tf.int64, default_value=None)\n",
    "            , FEATURE_REWARD:\n",
    "                tf.io.FixedLenSequenceFeature([], tf.int64, default_value=None)\n",
    "        }\n",
    "    )\n",
    "    actions = sequence_feature[FEATURE_ACTION]\n",
    "    rewards = sequence_feature[FEATURE_REWARD]\n",
    "    \n",
    "    return actions, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7ade30-87d7-4c76-8036-b855ba8a702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "dataset_files = tf.io.gfile.glob(dataset_path)\n",
    "dataset_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77976790-6a7b-4a53-88d8-3a8828f7b209",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dataset = tf.data.RecordIODataset(dataset_files)\n",
    "example_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9758f6-4b8f-402d-ab93-1c1a84ee0c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dataset = example_dataset.map(\n",
    "    process_example\n",
    "    , num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    ")\n",
    "example_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfad9c6b-8585-46aa-ad31-61d65434be76",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_items_to_process = 1000000\n",
    "num_elements = 0\n",
    "sequence_lengths = []\n",
    "actions = []\n",
    "rewards = []\n",
    "\n",
    "start_time = time.time()\n",
    "for elem in example_dataset.as_numpy_iterator():\n",
    "    action, reward = elem\n",
    "    sequence_lengths.append(len(action))\n",
    "    actions.append(action)\n",
    "    rewards.append(reward)\n",
    "    num_elements += 1\n",
    "    if num_elements % 10000 == 0:\n",
    "        print(num_elements)\n",
    "    if num_elements > max_items_to_process:\n",
    "        break\n",
    "\n",
    "print('Num sequences = ', num_elements)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m109"
  },
  "kernelspec": {
   "display_name": "TensorFlow 2-11 (Local)",
   "language": "python",
   "name": "local-conda-env-tensorflow-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
