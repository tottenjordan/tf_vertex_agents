{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f856e765-53d1-470b-a576-ff7b65b6c086",
   "metadata": {},
   "source": [
    "# Build Custom Images for Training and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b5fa60b-5c6d-4a0b-ab3c-3d5a337df4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efd5cfae-82b5-44cd-a13b-0cd1464b5676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "# PREFIX = 'mabv1'\n",
    "VERSION        = \"v2\"                       # TODO\n",
    "PREFIX         = f'rec-bandits-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e00898b7-70f1-4142-951b-10996caa0d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"rec-bandits-v2\"\n",
      "VERSION                  = \"v2\"\n",
      "\n",
      "BUCKET_NAME              = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_ID      = \"hybrid_vertex.movielens_ds_rec_bandits_v2\"\n",
      "BIGQUERY_TABLE_ID        = \"hybrid_vertex.movielens_ds_rec_bandits_v2.training_dataset\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-rec-bandits-v2\"\n",
      "IMAGE_NAME               = \"train-perarm-feats-v2\"\n",
      "DOCKERNAME               = \"Dockerfile_perarm_feats\"\n",
      "\n",
      "IMAGE_URI_01             = \"gcr.io/hybrid-vertex/train-perarm-feats-v2-01\"\n",
      "IMAGE_URI_02             = \"gcr.io/hybrid-vertex/train-perarm-feats-v2-02\"\n",
      "\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/train-perarm-feats-v2\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ba6e51c-ad9e-4e7a-b1cc-4543829c9bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74ef57c5-9850-46fc-866c-5b1726d5bfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tree src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2669da19-c2a1-4d4b-99d8-e6bede7f544c",
   "metadata": {},
   "source": [
    "## Write cloudbuild YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cb95b7c-ef9d-4a62-a8b4-3d8f0f8755d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile cloudbuild.yaml\n",
    "\n",
    "# steps:\n",
    "# - name: 'gcr.io/cloud-builders/docker'\n",
    "#   args: ['build', '-t', '$_IMAGE_URI', '$_FILE_LOCATION', '-f', '$_FILE_LOCATION/$_DOCKERNAME']\n",
    "# images:\n",
    "# - '$_IMAGE_URI'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623efcf1-d797-4a8e-b92e-86979735be45",
   "metadata": {},
   "source": [
    "# Create custom training container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abf3310e-5cc0-4e5b-a9c7-34a1598a8668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_MAB_IMAGE_NAME : train_hpt_mab_e2e_rec_bandits_v2\n",
      "TRAIN_MAB_IMAGE_URI  : gcr.io/hybrid-vertex/train_hpt_mab_e2e_rec_bandits_v2\n",
      "DOCKERNAME_MAB       : Dockerfile_train_mab_e2e\n"
     ]
    }
   ],
   "source": [
    "TRAIN_MAB_IMAGE_NAME = f\"train_hpt_mab_e2e_{PREFIX}\".replace(\"-\",\"_\")\n",
    "TRAIN_MAB_IMAGE_URI  = f\"gcr.io/hybrid-vertex/{TRAIN_MAB_IMAGE_NAME}\" # :latest\n",
    "DOCKERNAME_MAB       = \"Dockerfile_train_mab_e2e\"\n",
    "\n",
    "print(f\"TRAIN_MAB_IMAGE_NAME : {TRAIN_MAB_IMAGE_NAME}\")\n",
    "print(f\"TRAIN_MAB_IMAGE_URI  : {TRAIN_MAB_IMAGE_URI}\")\n",
    "print(f\"DOCKERNAME_MAB       : {DOCKERNAME_MAB}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc3ecf2-a28a-4770-a00f-d72097d18865",
   "metadata": {},
   "source": [
    "#### Write a Dockerfile\n",
    "\n",
    "- Use the [cloudml-hypertune](https://github.com/GoogleCloudPlatform/cloudml-hypertune) Python package to report training metrics to Vertex AI for hyperparameter tuning.\n",
    "- Use the Google [Cloud Storage client library](https://cloud.google.com/storage/docs/reference/libraries) to read the best hyperparameters learned from a previous hyperarameter tuning job during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82990f30-0f83-4e7e-9f64-c66edecb04bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_profiling : True\n"
     ]
    }
   ],
   "source": [
    "gpu_profiling = True # True | False\n",
    "\n",
    "print(f\"gpu_profiling : {gpu_profiling}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ab93178-0f56-41a6-af2e-fbf42a7e414f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_BASE_IMAGE : gcr.io/deeplearning-platform-release/tf2-gpu.2-13.py310\n",
      "NVTOP_RUN        : RUN apt update && apt -y install nvtop\n",
      "RUN_EXPORT       : RUN export PYTHONPATH=${PYTHONPATH}:${APP_HOME}/\n"
     ]
    }
   ],
   "source": [
    "if gpu_profiling:\n",
    "    # TRAIN_BASE_IMAGE = 'tensorflow/tensorflow:2.13.0-gpu'\n",
    "    TRAIN_BASE_IMAGE = 'gcr.io/deeplearning-platform-release/tf2-gpu.2-13.py310'\n",
    "    NVTOP_RUN = 'RUN apt update && apt -y install nvtop'\n",
    "    # NVTOP_RUN = 'RUN apt-get update && apt-get -y install nvtop'\n",
    "else:\n",
    "    TRAIN_BASE_IMAGE = 'python:3.10'\n",
    "    NVTOP_RUN = None\n",
    "    \n",
    "RUN_EXPORT = \"RUN export PYTHONPATH=${PYTHONPATH}:${APP_HOME}/\"\n",
    "    \n",
    "print(f\"TRAIN_BASE_IMAGE : {TRAIN_BASE_IMAGE}\")\n",
    "print(f\"NVTOP_RUN        : {NVTOP_RUN}\")\n",
    "print(f\"RUN_EXPORT       : {RUN_EXPORT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2065b9fc-44cf-43a9-987e-f9432256b4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Specifies base image and tag.\n",
      "# FROM gcr.io/google-appengine/python\n",
      "FROM gcr.io/deeplearning-platform-release/tf2-gpu.2-13.py310\n",
      "\n",
      "ENV PYTHONUNBUFFERED True\n",
      "WORKDIR /root\n",
      "\n",
      "RUN pip install --upgrade pip\n",
      "\n",
      "RUN pip install cloudml-hypertune==0.1.0.dev6\n",
      "RUN pip install google-cloud-storage==1.39.0\n",
      "RUN pip install tensorflow==2.13.0\n",
      "RUN pip install tensorboard-plugin-profile==2.13.1\n",
      "RUN pip install tf-agents==0.17.0\n",
      "RUN pip install matplotlib==3.8.0\n",
      "RUN pip install urllib3==1.26.6\n",
      "\n",
      "RUN apt update && apt -y install nvtop\n",
      "\n",
      "# Copies training code to the Docker image.\n",
      "COPY src/training /root/src/training\n",
      "\n",
      "RUN export PYTHONPATH=${PYTHONPATH}:${APP_HOME}/\n",
      "\n",
      "# Sets up the entry point to invoke the task.\n",
      "ENTRYPOINT [\"python3\", \"-m\", \"src.training.task\"]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dockerfile = f'''\n",
    "# Specifies base image and tag.\n",
    "# FROM gcr.io/google-appengine/python\n",
    "FROM {TRAIN_BASE_IMAGE}\n",
    "\n",
    "ENV PYTHONUNBUFFERED True\n",
    "WORKDIR /root\n",
    "\n",
    "RUN pip install --upgrade pip\n",
    "\n",
    "RUN pip install cloudml-hypertune==0.1.0.dev6\n",
    "RUN pip install google-cloud-storage==1.39.0\n",
    "RUN pip install tensorflow==2.13.0\n",
    "RUN pip install tensorboard-plugin-profile==2.13.1\n",
    "RUN pip install tf-agents==0.17.0\n",
    "RUN pip install matplotlib==3.8.0\n",
    "RUN pip install urllib3==1.26.6\n",
    "\n",
    "{NVTOP_RUN}\n",
    "\n",
    "# Copies training code to the Docker image.\n",
    "COPY src/training /root/src/training\n",
    "\n",
    "{RUN_EXPORT}\n",
    "\n",
    "# Sets up the entry point to invoke the task.\n",
    "ENTRYPOINT [\"python3\", \"-m\", \"src.training.task\"]\n",
    "'''\n",
    "print(dockerfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1a3126-2119-4493-b58b-1fdf10588baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DOCKERNAME_MAB}', 'w') as f:\n",
    "    f.write(dockerfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0c441a-efc8-4d0f-a81c-6739c7216c96",
   "metadata": {},
   "source": [
    "#### Files that will be included in Cloud Build image\n",
    "* to adjust this see the gcloudignore section at the end of `00-env-setup.ipynb` notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c372af8e-1897-4b38-9d1b-c0c3806f615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile .gcloudignore\n",
    ".gcloudignore\n",
    "/WIP/*\n",
    "*.pkl\n",
    "*.png\n",
    "*.ipynb\n",
    ".git\n",
    ".github\n",
    ".ipynb_checkpoints/*\n",
    "*__pycache__\n",
    "*cpython-37.pyc\n",
    "/imgs/*\n",
    "README.md\n",
    ".gitignore\n",
    ".DS_Store\n",
    "*.tfrecord\n",
    "src/archive/*\n",
    "00-archived/*\n",
    "learning/*\n",
    "*.data-00000-of-00001\n",
    "src/tests/*\n",
    "*.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9e4cc20-2385-41c1-a4ec-15e3294d4f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requirements.txt\n",
      "Dockerfile\n",
      "Dockerfile_train_mab_e2e\n",
      "cloudbuild.yaml\n",
      "src/prediction/prestart.sh\n",
      "src/prediction/main.py\n",
      "src/training/policy_util.py\n",
      "src/training/task.py\n",
      "src/utils/data_config.py\n",
      "hptuning/result.json\n"
     ]
    }
   ],
   "source": [
    "# check eligble files\n",
    "!gcloud meta list-files-for-upload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc04297-ec30-4c9d-a85c-a6ad2a90df05",
   "metadata": {},
   "source": [
    "#### Build the custom container with Cloud Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4bb54f8-1675-46fd-ba41-e9a242059d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOCKERNAME    : Dockerfile_train_mab_e2e\n",
      "IMAGE_URI     : gcr.io/hybrid-vertex/train_hpt_mab_e2e_rec_bandits_v2\n",
      "FILE_LOCATION : .\n",
      "MACHINE_TYPE  : e2-highcpu-32\n"
     ]
    }
   ],
   "source": [
    "# image definitions for training\n",
    "MACHINE_TYPE          ='e2-highcpu-32'\n",
    "FILE_LOCATION         = \".\" # './src'\n",
    "\n",
    "DOCKERNAME            = DOCKERNAME_MAB\n",
    "IMAGE_URI             = TRAIN_MAB_IMAGE_URI\n",
    "\n",
    "print(f\"DOCKERNAME    : {DOCKERNAME}\")\n",
    "print(f\"IMAGE_URI     : {IMAGE_URI}\")\n",
    "print(f\"FILE_LOCATION : {FILE_LOCATION}\")\n",
    "print(f\"MACHINE_TYPE  : {MACHINE_TYPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155db3c9-d8af-40b9-9c12-1b16808e1d0e",
   "metadata": {},
   "source": [
    "### run in notebook terminal to continue in-notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cde514dd-9ab8-4da6-8afb-277ca2b7ff71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcloud builds submit --config ./cloudbuild.yaml --substitutions _DOCKERNAME=Dockerfile_train_mab_e2e,_IMAGE_URI=gcr.io/hybrid-vertex/train_hpt_mab_e2e_rec_bandits_v2,_FILE_LOCATION=. --timeout=2h --machine-type=e2-highcpu-32 --quiet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CLOUD_BUILD_CMD = f'''gcloud builds submit --config ./cloudbuild.yaml \\\n",
    "--substitutions _DOCKERNAME={DOCKERNAME},_IMAGE_URI={IMAGE_URI},_FILE_LOCATION={FILE_LOCATION} \\\n",
    "--timeout=2h \\\n",
    "--machine-type={MACHINE_TYPE} \\\n",
    "--quiet\n",
    "'''\n",
    "print(CLOUD_BUILD_CMD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7bb3db-3abe-4824-8ec4-6acc4736fc70",
   "metadata": {},
   "source": [
    "# Create custom prediction container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9962942d-936b-48af-82e8-f15ffe3c78f6",
   "metadata": {},
   "source": [
    "As with training, create a custom prediction container. This container handles the TF-Agents specific logic that is different from a regular TensorFlow Model. Specifically, it finds the predicted action using a trained policy. The associated source code is in `src/prediction/`.\n",
    "See other options for Vertex AI predictions [here](https://cloud.google.com/vertex-ai/docs/predictions/getting-predictions)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f56566-7c19-4e9c-a1b3-d1d0b7084be6",
   "metadata": {},
   "source": [
    "#### Serve predictions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9368993c-3a6d-484b-a84d-0d92b847b65f",
   "metadata": {},
   "source": [
    "- Use [`tensorflow.saved_model.load`](https://www.tensorflow.org/agents/api_docs/python/tf_agents/policies/PolicySaver#usage), instead of [`tf_agents.policies.policy_loader.load`](https://github.com/tensorflow/agents/blob/r0.8.0/tf_agents/policies/policy_loader.py#L26), to load the trained policy, because the latter produces an object of type [`SavedModelPyTFEagerPolicy`](https://github.com/tensorflow/agents/blob/402b8aa81ca1b578ec1f687725d4ccb4115386d2/tf_agents/policies/py_tf_eager_policy.py#L137) whose `action()` is not compatible for use here.\n",
    "- Note that prediction requests contain only observation data but not reward. This is because: The prediction task is a standalone request that doesn't require prior knowledge of the system state. Meanwhile, end users only know what they observe at the moment. Reward is a piece of information that comes after the action has been made, so the end users would not have knowledge of said reward. In handling prediction requests, you create a [`TimeStep`](https://www.tensorflow.org/agents/api_docs/python/tf_agents/trajectories/TimeStep) object (consisting of `observation`, `reward`, `discount`, `step_type`) using the [`restart()`](https://www.tensorflow.org/agents/api_docs/python/tf_agents/trajectories/restart) function which takes in an `observation`. This function creates the *first* TimeStep in a trajectory of steps, where reward is 0, discount is 1 and step_type is marked as the first timestep. In other words, each prediction request forms the first `TimeStep` in a brand new trajectory.\n",
    "- For the prediction response, avoid using NumPy-typed values; instead, convert them to native Python values using methods such as [`tolist()`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.tolist.html) as opposed to `list()`.\n",
    "- There exists a prestart script in `src/prediction`. FastAPI executes this script before starting up the server. The `PORT` environment variable is set to equal `AIP_HTTP_PORT` in order to run FastAPI on the same port expected by Vertex AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa503212-6dd0-4ba7-aefe-cc1df06959e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED_MAB_IMAGE_NAME : mab_custom_prediction_rec_bandits_v2\n",
      "PRED_MAB_IMAGE_URI  : gcr.io/hybrid-vertex/mab_custom_prediction_rec_bandits_v2\n",
      "DOCKERNAME_MAB_PRED : Dockerfile_predict_mab_e2e\n"
     ]
    }
   ],
   "source": [
    "SERVING_APP_DIR      = \"app\"  # fixed for this example in dockerfile\n",
    "\n",
    "PRED_MAB_IMAGE_NAME = f\"mab_custom_prediction_{PREFIX}\".replace(\"-\",\"_\")\n",
    "PRED_MAB_IMAGE_URI  = f\"gcr.io/hybrid-vertex/{PRED_MAB_IMAGE_NAME}\" # :latest\n",
    "DOCKERNAME_MAB_PRED = \"Dockerfile_predict_mab_e2e\"\n",
    "\n",
    "print(f\"PRED_MAB_IMAGE_NAME : {PRED_MAB_IMAGE_NAME}\")\n",
    "print(f\"PRED_MAB_IMAGE_URI  : {PRED_MAB_IMAGE_URI}\")\n",
    "print(f\"DOCKERNAME_MAB_PRED : {DOCKERNAME_MAB_PRED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e60c29e-ba41-46a4-a214-9e1be2c856b2",
   "metadata": {},
   "source": [
    "## Create local directory for serving application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83505060-ab48-4e8f-992c-77cdfdfee31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %mkdir $SERVING_APP_DIR\n",
    "# %%writefile $SERVING_APP_DIR/..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e0a3767b-c269-4c00-b948-d6470207fc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "numpy\n",
    "six\n",
    "typing-extensions\n",
    "pillow\n",
    "tf-agents==0.17.0\n",
    "tensorflow==2.13.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343bc38e-28f6-441e-8074-3d6d0f52a61c",
   "metadata": {},
   "source": [
    "### Write Dockerfile\n",
    "\n",
    "Note: Note: leave the server directory `app`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48aa83f6-7f16-4b39-9131-5f47345c1612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FROM tiangolo/uvicorn-gunicorn-fastapi:python3.10\n",
      "\n",
      "COPY src/prediction /app\n",
      "COPY requirements.txt /app/requirements.txt\n",
      "\n",
      "RUN pip3 install -r /app/requirements.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dockerfile = f'''\n",
    "FROM tiangolo/uvicorn-gunicorn-fastapi:python3.10\n",
    "\n",
    "COPY src/prediction /app\n",
    "COPY requirements.txt /app/requirements.txt\n",
    "\n",
    "RUN pip3 install -r /app/requirements.txt\n",
    "'''\n",
    "print(dockerfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edfbed81-18f1-4acc-afb2-4d3071b61605",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DOCKERNAME_MAB_PRED}', 'w') as f:\n",
    "    f.write(dockerfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403e1ee6-0a34-4d88-aaa4-f21ed89569b4",
   "metadata": {},
   "source": [
    "### write new YAML\n",
    "\n",
    "> Note: env==ARTIFACT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33c651d7-7b52-4fe8-b8c1-90f2f84088d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOCKERNAME    : Dockerfile_predict_mab_e2e\n",
      "IMAGE_URI     : gcr.io/hybrid-vertex/mab_custom_prediction_rec_bandits_v2\n",
      "FILE_LOCATION : .\n",
      "MACHINE_TYPE  : e2-highcpu-32\n",
      "ARTIFACTS_DIR : gs://rec-bandits-v2-hybrid-vertex-bucket/sxs-rl-rec-bandits-v2/run-20231019-041358/artifacts\n"
     ]
    }
   ],
   "source": [
    "# image definitions for training\n",
    "MACHINE_TYPE            ='e2-highcpu-32'\n",
    "FILE_LOCATION           = \".\" # './src'\n",
    "\n",
    "DOCKERNAME            = DOCKERNAME_MAB_PRED\n",
    "IMAGE_URI             = PRED_MAB_IMAGE_URI\n",
    "\n",
    "# TODO - currently manual from step-by-step notebook\n",
    "ARTIFACTS_DIR = 'gs://rec-bandits-v2-hybrid-vertex-bucket/sxs-rl-rec-bandits-v2/run-20231019-041358/artifacts'\n",
    "\n",
    "print(f\"DOCKERNAME    : {DOCKERNAME}\")\n",
    "print(f\"IMAGE_URI     : {IMAGE_URI}\")\n",
    "print(f\"FILE_LOCATION : {FILE_LOCATION}\")\n",
    "print(f\"MACHINE_TYPE  : {MACHINE_TYPE}\")\n",
    "print(f\"ARTIFACTS_DIR : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab52e3a5-50cb-4467-b46f-c1eb8307fa07",
   "metadata": {},
   "source": [
    "### Write new CloudBuild with `env` variable specified..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "330e7eb5-25ae-4a02-94cb-a5196739f77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "steps:\n",
      "- name: 'gcr.io/cloud-builders/docker'\n",
      "  args: ['build', '-t', '$_IMAGE_URI', '$_FILE_LOCATION', '-f', '$_FILE_LOCATION/$_DOCKERNAME']\n",
      "  env: ['AIP_STORAGE_URI=gs://rec-bandits-v2-hybrid-vertex-bucket/sxs-rl-rec-bandits-v2/run-20231019-041358/artifacts']\n",
      "images:\n",
      "- '$_IMAGE_URI'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CLOUD_BUILD_CONFIG = f'''\n",
    "steps:\n",
    "- name: 'gcr.io/cloud-builders/docker'\n",
    "  args: ['build', '-t', '$_IMAGE_URI', '$_FILE_LOCATION', '-f', '$_FILE_LOCATION/$_DOCKERNAME']\n",
    "  env: ['AIP_STORAGE_URI={ARTIFACTS_DIR}']\n",
    "images:\n",
    "- '$_IMAGE_URI'\n",
    "'''\n",
    "print(CLOUD_BUILD_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dbc70a77-bb34-45f6-b476-dde910ad83eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLOUD_BUILD_YAML = 'cloudbuild.yaml'\n",
    "\n",
    "with open(f'{CLOUD_BUILD_YAML}', 'w') as f:\n",
    "    f.write(CLOUD_BUILD_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7df9f2c-7538-4781-ae58-b3ea296a338f",
   "metadata": {},
   "source": [
    "### run in notebook terminal to contnue in-notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bca2e5f8-9851-430e-af86-a8c265fc7acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcloud builds submit --config ./cloudbuild.yaml --substitutions _DOCKERNAME=Dockerfile_predict_mab_e2e,_IMAGE_URI=gcr.io/hybrid-vertex/mab_custom_prediction_rec_bandits_v2,_FILE_LOCATION=. --timeout=2h --machine-type=e2-highcpu-32 --quiet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CLOUD_BUILD_CMD = f'''gcloud builds submit --config ./{CLOUD_BUILD_YAML} \\\n",
    "--substitutions _DOCKERNAME={DOCKERNAME},_IMAGE_URI={IMAGE_URI},_FILE_LOCATION={FILE_LOCATION} \\\n",
    "--timeout=2h \\\n",
    "--machine-type={MACHINE_TYPE} \\\n",
    "--quiet\n",
    "'''\n",
    "print(CLOUD_BUILD_CMD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f5b1a1-4f75-498d-9f4f-e5ca358996ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gcloud builds submit --config ./cloudbuild.yaml \\\n",
    "#     --substitutions _DOCKERNAME=$DOCKERNAME,_IMAGE_URI=$IMAGE_URI,_FILE_LOCATION=$FILE_LOCATION,_ARTIFACTS_DIR=ARTIFACTS_DIR \\\n",
    "#     --timeout=2h \\\n",
    "#     --machine-type=$MACHINE_TYPE \\\n",
    "#     --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeb7c50-0517-455c-9043-1822d1bf2b78",
   "metadata": {},
   "source": [
    "# archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b1575d-4009-4b14-98b1-2a944119e154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gcloud builds submit --config=gcp/cloudbuild-main.yaml --substitutions=_CLIENT=\"client\",_BRANCH=\"branch\",_TAG=\"tag\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d600fe01-3628-4100-be92-cf1b21bfe83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gcloud builds submit --config=gcp/cloudbuild-main.yaml --substitutions _CLIENT='client',_BRANCH='branch',_TAG='tag' ."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
