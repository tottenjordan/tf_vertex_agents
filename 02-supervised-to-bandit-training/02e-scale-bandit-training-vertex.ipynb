{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4699e32-3938-4c72-9eb7-4fe36bea46a0",
   "metadata": {},
   "source": [
    "# Scaling bandit training with Vertex AI \n",
    "\n",
    "**prerequisites:**\n",
    "* build training image in `04b-build-training-image` noteook\n",
    "\n",
    "**Recommendation**\n",
    "\n",
    "When profiling a train job, we don't need to do a full train. \n",
    "\n",
    "> We just need to get multiple iterations of going through the entire Agent graph (i.e., from data iterator --> agent.train a few times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b47b011f-cc14-44d7-9ccd-4d6fc2aadd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# protobuf==3.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "725d9fa8-ad43-49b4-8bf5-75fda5e337fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiplatform SDK version: 1.33.1\n"
     ]
    }
   ],
   "source": [
    "! python3 -c \"import google.cloud.aiplatform; print('aiplatform SDK version: {}'.format(google.cloud.aiplatform.__version__))\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28447656-866e-4403-92ae-e2b3700a71bb",
   "metadata": {},
   "source": [
    "## setup notebook environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38e75f3e-73b9-4f14-8aff-08d3e4ea849a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/02-supervised-to-bandit-training\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d6546a-ec55-46eb-a2fe-c4e8b6a5ad9d",
   "metadata": {},
   "source": [
    "### Load env config\n",
    "* use the prefix from `00-env-setup` notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c928177-d72f-4715-a149-91c9a0a9f7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "VERSION        = \"v2\"                       # TODO\n",
    "PREFIX         = f'rec-bandits-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "314139a3-e896-4f55-acd7-9daac475e98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"rec-bandits-v2\"\n",
      "VERSION                  = \"v2\"\n",
      "\n",
      "BUCKET_NAME              = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_NAME    = \"mvlens_rec_bandits_v2\"\n",
      "BIGQUERY_TABLE_NAME      = \"training_dataset\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-rec-bandits-v2\"\n",
      "\n",
      "DOCKERNAME_01            = \"Dockerfile_train_my_perarm_env\"\n",
      "IMAGE_NAME_01            = \"train-my-perarm-env-v2\"\n",
      "IMAGE_URI_01             = \"gcr.io/hybrid-vertex/train-my-perarm-env-v2\"\n",
      "\n",
      "DOCKERNAME_02            = \"Dockerfile_perarm_feats\"\n",
      "IMAGE_NAME_02            = \"train-perarm-feats-v2\"\n",
      "IMAGE_URI_02             = \"gcr.io/hybrid-vertex/train-perarm-feats-v2\"\n",
      "\n",
      "DOCKERNAME_03            = \"Dockerfile_ranking_bandit\"\n",
      "IMAGE_NAME_03            = \"train-rank-bandit-v2\"\n",
      "IMAGE_URI_03             = \"gcr.io/hybrid-vertex/train-rank-bandit-v2\"\n",
      "\n",
      "DOCKERNAME_04            = \"Dockerfile_train_bandit_e2e\"\n",
      "IMAGE_NAME_04            = \"train-mab-e2e-v2\"\n",
      "IMAGE_URI_04             = \"gcr.io/hybrid-vertex/train-mab-e2e-v2\"\n",
      "\n",
      "DOCKERNAME_04_pred       = \"Dockerfile_pred_bandit_e2e\"\n",
      "IMAGE_NAME_04_pred       = \"pred-mab-e2e-v2\"\n",
      "IMAGE_URI_04_pred        = \"gcr.io/hybrid-vertex/pred-mab-e2e-v2\"\n",
      "\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/local_docker_tfa\"\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce57c0ef-7e44-4c0b-afb2-adb1021c6e0e",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c9f1333-417a-4d12-b28d-c5183b5b4908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2490c9ee-9a23-4903-a659-228268a31081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# disable INFO and DEBUG logging everywhere\n",
    "import logging\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pickle as pkl\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "786af747-66b9-46ab-aef5-2f3dfe8cc564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src import train_utils\n",
    "from src.data import data_utils as data_utils\n",
    "from src.data import data_config as data_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a53e33e-c682-43db-9de6-240721914a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "vertex_ai.init(project=PROJECT_ID,location=REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd627969-7970-4217-a857-8d5f74a5484c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCS_DATA_PATH: gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/mv_b128_g12_a16/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/mv_b128_g12_a16_v4/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/mv_b128_g12_a16_v5/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/mv_b128_g12_a16_v6/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/train/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/val/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/vocabs/\n"
     ]
    }
   ],
   "source": [
    "EXAMPLE_GEN_GCS_PATH = data_config.EXAMPLE_GEN_GCS_PATH\n",
    "GCS_DATA_PATH = f\"{BUCKET_URI}/{EXAMPLE_GEN_GCS_PATH}\"\n",
    "\n",
    "print(f\"GCS_DATA_PATH: {GCS_DATA_PATH}\")\n",
    "\n",
    "!gsutil ls $GCS_DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ec42ad-e318-4e9c-b1fe-4f875c9e3574",
   "metadata": {},
   "source": [
    "# Vertex Training Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d534c68-7ab2-4e15-bdf4-220aab5a6531",
   "metadata": {},
   "source": [
    "## job compute\n",
    "\n",
    "Set the variable `TRAIN_COMPUTE` to configure the compute resources for the VMs you will use for for training.\n",
    "\n",
    "**Machine Type:**\n",
    "* `n1-standard`: 3.75GB of memory per vCPU.\n",
    "* `n1-highmem`: 6.5GB of memory per vCPU\n",
    "* `n1-highcpu`: 0.9 GB of memory per vCPU\n",
    "* `vCPUs`: number of `[2, 4, 8, 16, 32, 64, 96 ]`\n",
    "\n",
    "**Note:** The following is not supported for training:\n",
    "\n",
    "* `standard`: 2 vCPUs\n",
    "* `highcpu`: 2, 4 and 8 vCPUs\n",
    "\n",
    "> Note: You may also use n2 and e2 machine types for training and deployment, but they do not support GPUs.\n",
    "\n",
    "relevant docs: \n",
    "* [Configure compute resources for training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types) for more details\n",
    "* [Machine series comparison](https://cloud.google.com/compute/docs/machine-resource#machine_type_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0700c7d-4c38-491d-90a5-7cf052753d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCELERATOR: t4\n"
     ]
    }
   ],
   "source": [
    "ACCELERATOR = \"t4\" # str: \"a100\" | \"t4\" | None | l4\n",
    "ACCELERATOR = str(ACCELERATOR)\n",
    "print(f\"ACCELERATOR: {ACCELERATOR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd78debb-2363-4ed6-a8cf-7da7ae44a050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORKER_MACHINE_TYPE            : n1-highmem-16\n",
      "REPLICA_COUNT                  : 1\n",
      "ACCELERATOR_TYPE               : NVIDIA_TESLA_T4\n",
      "PER_MACHINE_ACCELERATOR_COUNT  : 1\n",
      "DISTRIBUTE_STRATEGY            : single\n",
      "REDUCTION_SERVER_COUNT         : 0\n",
      "REDUCTION_SERVER_MACHINE_TYPE  : n1-highcpu-16\n",
      "TF_GPU_THREAD_COUNT            : 4\n"
     ]
    }
   ],
   "source": [
    "if ACCELERATOR == \"a100\":\n",
    "    WORKER_MACHINE_TYPE = 'a2-highgpu-1g'\n",
    "    REPLICA_COUNT = 1\n",
    "    ACCELERATOR_TYPE = 'NVIDIA_TESLA_A100'\n",
    "    PER_MACHINE_ACCELERATOR_COUNT = 1\n",
    "    REDUCTION_SERVER_COUNT = 0                                                      \n",
    "    REDUCTION_SERVER_MACHINE_TYPE = \"n1-highcpu-16\"\n",
    "    DISTRIBUTE_STRATEGY = 'single'\n",
    "elif ACCELERATOR == 't4':\n",
    "    # WORKER_MACHINE_TYPE = 'n1-highcpu-16'\n",
    "    WORKER_MACHINE_TYPE = 'n1-highmem-16'\n",
    "    REPLICA_COUNT = 1\n",
    "    ACCELERATOR_TYPE = 'NVIDIA_TESLA_T4'\n",
    "    PER_MACHINE_ACCELERATOR_COUNT = 1\n",
    "    DISTRIBUTE_STRATEGY = 'single'\n",
    "    REDUCTION_SERVER_COUNT = 0                                                      \n",
    "    REDUCTION_SERVER_MACHINE_TYPE = \"n1-highcpu-16\"\n",
    "elif ACCELERATOR == 'l4':\n",
    "    WORKER_MACHINE_TYPE = \"g2-standard-16\"\n",
    "    REPLICA_COUNT = 1\n",
    "    ACCELERATOR_TYPE = 'NVIDIA_L4'\n",
    "    PER_MACHINE_ACCELERATOR_COUNT = 1\n",
    "    DISTRIBUTE_STRATEGY = 'single'\n",
    "    REDUCTION_SERVER_COUNT = 0                                                      \n",
    "    REDUCTION_SERVER_MACHINE_TYPE = \"n1-highcpu-16\"\n",
    "elif ACCELERATOR == 'tpu':\n",
    "    WORKER_MACHINE_TYPE = \"cloud-tpu\"\n",
    "    REPLICA_COUNT = 1\n",
    "    ACCELERATOR_TYPE = 'TPU_v3'\n",
    "    PER_MACHINE_ACCELERATOR_COUNT = 8 # 8 | +32+ for TPU Pods\n",
    "    DISTRIBUTE_STRATEGY = 'single'\n",
    "    REDUCTION_SERVER_COUNT = 0                                                      \n",
    "    REDUCTION_SERVER_MACHINE_TYPE = None\n",
    "elif ACCELERATOR == \"False\":\n",
    "    WORKER_MACHINE_TYPE = 'n2-highmem-32' # 'n1-highmem-96'n | 'n2-highmem-92'\n",
    "    REPLICA_COUNT = 1\n",
    "    ACCELERATOR_TYPE = None\n",
    "    PER_MACHINE_ACCELERATOR_COUNT = 0\n",
    "    DISTRIBUTE_STRATEGY = 'single'\n",
    "    REDUCTION_SERVER_COUNT = 0                                                      \n",
    "    REDUCTION_SERVER_MACHINE_TYPE = \"n1-highcpu-16\"\n",
    "    \n",
    "TF_GPU_THREAD_COUNT   = '4'      # '1' | '4' | '8'\n",
    "\n",
    "print(f\"WORKER_MACHINE_TYPE            : {WORKER_MACHINE_TYPE}\")\n",
    "print(f\"REPLICA_COUNT                  : {REPLICA_COUNT}\")\n",
    "print(f\"ACCELERATOR_TYPE               : {ACCELERATOR_TYPE}\")\n",
    "print(f\"PER_MACHINE_ACCELERATOR_COUNT  : {PER_MACHINE_ACCELERATOR_COUNT}\")\n",
    "print(f\"DISTRIBUTE_STRATEGY            : {DISTRIBUTE_STRATEGY}\")\n",
    "print(f\"REDUCTION_SERVER_COUNT         : {REDUCTION_SERVER_COUNT}\")\n",
    "print(f\"REDUCTION_SERVER_MACHINE_TYPE  : {REDUCTION_SERVER_MACHINE_TYPE}\")\n",
    "print(f\"TF_GPU_THREAD_COUNT            : {TF_GPU_THREAD_COUNT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb1e4a8-4c1a-47ab-9962-f8ec1eb414bc",
   "metadata": {},
   "source": [
    "## set Vertex AI Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0358f36-d5d7-4752-b2ac-3bccdf54edfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : 02-deep-bandits-v1\n",
      "RUN_NAME          : run-20240313-213741\n",
      "\n",
      "CHECKPT_DIR       : gs://rec-bandits-v2-hybrid-vertex-bucket/02-deep-bandits-v1/chkpoint\n",
      "BASE_OUTPUT_DIR   : gs://rec-bandits-v2-hybrid-vertex-bucket/02-deep-bandits-v1/run-20240313-213741\n",
      "LOG_DIR           : gs://rec-bandits-v2-hybrid-vertex-bucket/02-deep-bandits-v1/run-20240313-213741/logs\n",
      "ROOT_DIR          : gs://rec-bandits-v2-hybrid-vertex-bucket/02-deep-bandits-v1/run-20240313-213741/root\n",
      "ARTIFACTS_DIR     : gs://rec-bandits-v2-hybrid-vertex-bucket/02-deep-bandits-v1/run-20240313-213741/artifacts\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME   = f'02-deep-bandits-v1'\n",
    "\n",
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "CHECKPT_DIR       = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/chkpoint\"\n",
    "BASE_OUTPUT_DIR   = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}\"\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "vertex_ai.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"CHECKPT_DIR       : {CHECKPT_DIR}\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611995c1-d451-4f97-8b87-f89551497590",
   "metadata": {},
   "source": [
    "## Create Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74cf8ac4-6284-452a-af3e-d195cd473840",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_TENSORBOARD = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9aeed88-2bba-4832-abaf-f0f6d9b71e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TB_RESOURCE_NAME: projects/934903580331/locations/us-central1/tensorboards/670583345687560192\n",
      "TB display name: 02-deep-bandits-v1\n"
     ]
    }
   ],
   "source": [
    "if NEW_TENSORBOARD:\n",
    "    # # create new TB instance\n",
    "    TENSORBOARD_DISPLAY_NAME=f\"{EXPERIMENT_NAME}\"\n",
    "    tensorboard = vertex_ai.Tensorboard.create(\n",
    "        display_name=TENSORBOARD_DISPLAY_NAME\n",
    "        , project=PROJECT_ID\n",
    "        , location=REGION\n",
    "    )\n",
    "    TB_RESOURCE_NAME = tensorboard.resource_name\n",
    "else:\n",
    "    # use existing TB instance\n",
    "    # TB_RESOURCE_NAME = 'projects/934903580331/locations/us-central1/tensorboards/XXXXXXX' # TODO\n",
    "    tensorboard = vertex_ai.Tensorboard(\n",
    "        tensorboard_name=TB_RESOURCE_NAME\n",
    "    )\n",
    "print(f\"TB_RESOURCE_NAME: {TB_RESOURCE_NAME}\")\n",
    "print(f\"TB display name: {tensorboard.display_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544b8ed9-69f1-4aec-9dd8-c8995a265bbb",
   "metadata": {},
   "source": [
    "## Set training args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9eae7385-dfff-4e3e-af00-c20fa6a05496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGE_URI_02 : gcr.io/hybrid-vertex/train-perarm-feats-v2\n"
     ]
    }
   ],
   "source": [
    "print(f\"IMAGE_URI_02 : {IMAGE_URI_02}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd13dcc4-ab99-4e7c-9028-a7cd93b77a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB_SUBDIR           : vocabs\n",
      "VOCAB_FILENAME         : vocab_dict.pkl\n",
      "BATCH_SIZE             : 128\n",
      "TRAINING_LOOPS         : 500\n",
      "STEPS_PER_LOOP         : 1\n",
      "ASYNC_STEPS_PER_LOOP   : 1\n",
      "LOG_INTERVAL           : 10\n",
      "RANK_K                 : 10\n",
      "NUM_ACTIONS            : 2\n",
      "PER_ARM                : True\n",
      "AGENT_TYPE             : epsGreedy\n",
      "NETWORK_TYPE           : commontower\n",
      "TIKHONOV_WEIGHT        : 0.001\n",
      "AGENT_ALPHA            : 0.1\n",
      "GLOBAL_DIM             : 64\n",
      "PER_ARM_DIM            : 72\n",
      "SPLIT                  : train\n",
      "RESUME_TRAINING        : None\n",
      "NUM_OOV_BUCKETS        : 1\n",
      "GLOBAL_EMBEDDING_SIZE  : 12\n",
      "MV_EMBEDDING_SIZE      : 16\n",
      "AGENT_ALPHA            : 0.1\n",
      "GLOBAL_LAYERS          : [64, 32, 16]\n",
      "ARM_LAYERS             : [72, 36, 18]\n",
      "COMMON_LAYERS          : [34, 8]\n",
      "LR                     : 0.05\n",
      "CHKPT_INTERVAL         : 1000\n",
      "EVAL_BATCH_SIZE        : 1\n",
      "NUM_EVAL_STEPS         : 2000\n",
      "EPSILON                : 0.01\n",
      "ENCODING_DIM           : 1\n",
      "EPS_PHASE_STEPS        : 1000\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# data config\n",
    "# ================================\n",
    "GLOBAL_DIM             = 64       # 16\n",
    "PER_ARM_DIM            = 72       # 16\n",
    "NUM_OOV_BUCKETS        = 1\n",
    "GLOBAL_EMBEDDING_SIZE  = 12\n",
    "MV_EMBEDDING_SIZE      = 16       # 32\n",
    "SPLIT                  = \"train\"  # TODO - remove\n",
    "RESUME_TRAINING        = None\n",
    "\n",
    "# Set hyperparameters.\n",
    "NUM_EPOCHS           = 5\n",
    "BATCH_SIZE           = 128          # Training and prediction batch size.\n",
    "TRAINING_LOOPS       = 500          # Number of training iterations.\n",
    "STEPS_PER_LOOP       = 1            # Number of driver steps per training iteration.\n",
    "ASYNC_STEPS_PER_LOOP = 1\n",
    "LOG_INTERVAL         = 10\n",
    "LR                   = 0.05\n",
    "\n",
    "CHKPT_INTERVAL       = 1000\n",
    "EVAL_BATCH_SIZE      = 1  \n",
    "NUM_EVAL_STEPS       = 2000 #10000\n",
    "\n",
    "# Set MovieLens simulation environment parameters.\n",
    "RANK_K               = 10      # Rank for matrix factorization in the MovieLens environment; also the observation dimension.\n",
    "NUM_ACTIONS          = 2       # Number of actions (movie items) to choose from.\n",
    "PER_ARM              = True    # Use the non-per-arm version of the MovieLens environment.\n",
    "\n",
    "# ================================\n",
    "# Agent\n",
    "# ================================\n",
    "AGENT_TYPE          = 'epsGreedy' # 'LinUCB' | 'LinTS |, 'epsGreedy' | 'NeuralLinUCB'\n",
    "NETWORK_TYPE        = \"commontower\" # 'commontower' | 'dotproduct'\n",
    "\n",
    "TIKHONOV_WEIGHT     = 0.001   # LinUCB Tikhonov regularization weight.\n",
    "AGENT_ALPHA         = 0.1     # LinUCB exploration parameter that multiplies the confidence intervals.\n",
    "EPSILON             = 0.01\n",
    "ENCODING_DIM        = 1\n",
    "EPS_PHASE_STEPS     = 1000\n",
    "\n",
    "# ================================\n",
    "# network params\n",
    "# ================================\n",
    "# GLOBAL_LAYERS       = [128, 64, 32]\n",
    "# ARM_LAYERS          = [128, 64, 32]\n",
    "# COMMON_LAYERS       = [32, 16, 8]\n",
    "\n",
    "GLOBAL_LAYERS   = [GLOBAL_DIM, int(GLOBAL_DIM/2), int(GLOBAL_DIM/4)]\n",
    "ARM_LAYERS      = [PER_ARM_DIM, int(PER_ARM_DIM/2), int(PER_ARM_DIM/4)]\n",
    "\n",
    "FIRST_COMMON_LAYER = GLOBAL_LAYERS[-1] + ARM_LAYERS[-1]\n",
    "COMMON_LAYERS = [\n",
    "    int(FIRST_COMMON_LAYER),\n",
    "    # int(FIRST_COMMON_LAYER/2),\n",
    "    int(FIRST_COMMON_LAYER/4)\n",
    "]\n",
    "\n",
    "if AGENT_TYPE == 'NeuralLinUCB':\n",
    "    NETWORK_TYPE = 'commontower'\n",
    "    ENCODING_DIM = COMMON_LAYERS[-1]\n",
    "\n",
    "print(f\"VOCAB_SUBDIR           : {VOCAB_SUBDIR}\")\n",
    "print(f\"VOCAB_FILENAME         : {VOCAB_FILENAME}\")\n",
    "print(f\"BATCH_SIZE             : {BATCH_SIZE}\")\n",
    "print(f\"TRAINING_LOOPS         : {TRAINING_LOOPS}\")\n",
    "print(f\"STEPS_PER_LOOP         : {STEPS_PER_LOOP}\")\n",
    "print(f\"ASYNC_STEPS_PER_LOOP   : {ASYNC_STEPS_PER_LOOP}\")\n",
    "print(f\"LOG_INTERVAL           : {LOG_INTERVAL}\")\n",
    "print(f\"RANK_K                 : {RANK_K}\")\n",
    "print(f\"NUM_ACTIONS            : {NUM_ACTIONS}\")\n",
    "print(f\"PER_ARM                : {PER_ARM}\")\n",
    "print(f\"AGENT_TYPE             : {AGENT_TYPE}\")\n",
    "print(f\"NETWORK_TYPE           : {NETWORK_TYPE}\")\n",
    "print(f\"TIKHONOV_WEIGHT        : {TIKHONOV_WEIGHT}\")\n",
    "print(f\"AGENT_ALPHA            : {AGENT_ALPHA}\")\n",
    "print(f\"GLOBAL_DIM             : {GLOBAL_DIM}\")\n",
    "print(f\"PER_ARM_DIM            : {PER_ARM_DIM}\")\n",
    "print(f\"SPLIT                  : {SPLIT}\")\n",
    "print(f\"RESUME_TRAINING        : {RESUME_TRAINING}\")\n",
    "print(f\"NUM_OOV_BUCKETS        : {NUM_OOV_BUCKETS}\")\n",
    "print(f\"GLOBAL_EMBEDDING_SIZE  : {GLOBAL_EMBEDDING_SIZE}\")\n",
    "print(f\"MV_EMBEDDING_SIZE      : {MV_EMBEDDING_SIZE}\")\n",
    "print(f\"AGENT_ALPHA            : {AGENT_ALPHA}\")\n",
    "print(f\"GLOBAL_LAYERS          : {GLOBAL_LAYERS}\")\n",
    "print(f\"ARM_LAYERS             : {ARM_LAYERS}\")\n",
    "print(f\"COMMON_LAYERS          : {COMMON_LAYERS}\")\n",
    "print(f\"LR                     : {LR}\")\n",
    "print(f\"CHKPT_INTERVAL         : {CHKPT_INTERVAL}\")\n",
    "print(f\"EVAL_BATCH_SIZE        : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS         : {NUM_EVAL_STEPS}\")\n",
    "print(f\"EPSILON                : {EPSILON}\")\n",
    "print(f\"ENCODING_DIM           : {ENCODING_DIM}\")\n",
    "print(f\"EPS_PHASE_STEPS        : {EPS_PHASE_STEPS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4411e60-067d-4e29-92ff-12dbbc46726f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'container_spec': {'args': ['--project=hybrid-vertex',\n",
      "                              '--project_number=934903580331',\n",
      "                              '--bucket_name=rec-bandits-v2-hybrid-vertex-bucket',\n",
      "                              '--artifacts_dir=gs://rec-bandits-v2-hybrid-vertex-bucket/02-deep-bandits-v1/run-20240313-213741/artifacts',\n",
      "                              '--chkpoint_dir=gs://rec-bandits-v2-hybrid-vertex-bucket/02-deep-bandits-v1/chkpoint',\n",
      "                              '--log_dir=gs://rec-bandits-v2-hybrid-vertex-bucket/02-deep-bandits-v1/run-20240313-213741/logs',\n",
      "                              '--data_dir_prefix_path=data/movielens/m1m',\n",
      "                              '--vocab_prefix_path=data/movielens/m1m/vocabs',\n",
      "                              '--vocab_filename=vocab_dict.pkl',\n",
      "                              '--distribute=single',\n",
      "                              '--experiment_name=02-deep-bandits-v1',\n",
      "                              '--experiment_run=run-20240313-213741',\n",
      "                              '--agent_type=epsGreedy',\n",
      "                              '--network_type=commontower',\n",
      "                              '--batch_size=128',\n",
      "                              '--eval_batch_size=1',\n",
      "                              '--training_loops=500',\n",
      "                              '--steps_per_loop=1',\n",
      "                              '--num_eval_steps=2000',\n",
      "                              '--rank_k=10',\n",
      "                              '--num_actions=2',\n",
      "                              '--async_steps_per_loop=1',\n",
      "                              '--global_dim=64',\n",
      "                              '--per_arm_dim=72',\n",
      "                              '--split=train',\n",
      "                              '--log_interval=10',\n",
      "                              '--chkpt_interval=1000',\n",
      "                              '--num_oov_buckets=1',\n",
      "                              '--global_emb_size=12',\n",
      "                              '--mv_emb_size=16',\n",
      "                              '--agent_alpha=0.1',\n",
      "                              '--global_layers=[64, 32, 16]',\n",
      "                              '--arm_layers=[72, 36, 18]',\n",
      "                              '--common_layers=[34, 8]',\n",
      "                              '--learning_rate=0.05',\n",
      "                              '--epsilon=0.01',\n",
      "                              '--encoding_dim=1',\n",
      "                              '--eps_phase_steps=1000',\n",
      "                              '--tf_gpu_thread_count=4',\n",
      "                              '--num_epochs=5',\n",
      "                              '--use_gpu',\n",
      "                              '--sum_grads_vars',\n",
      "                              '--debug_summaries'],\n",
      "                     'image_uri': 'gcr.io/hybrid-vertex/train-perarm-feats-v2:latest'},\n",
      "  'machine_spec': {'accelerator_count': 1,\n",
      "                   'accelerator_type': 'NVIDIA_TESLA_T4',\n",
      "                   'machine_type': 'n1-highmem-16'},\n",
      "  'replica_count': 1}]\n"
     ]
    }
   ],
   "source": [
    "WORKER_ARGS = [\n",
    "    f\"--project={PROJECT_ID}\"\n",
    "    , f\"--project_number={PROJECT_NUM}\"\n",
    "    , f\"--bucket_name={BUCKET_NAME}\"\n",
    "    , f\"--artifacts_dir={ARTIFACTS_DIR}\"\n",
    "    # , f\"--root_dir={ROOT_DIR}\"\n",
    "    , f\"--chkpoint_dir={CHECKPT_DIR}\"\n",
    "    , f\"--log_dir={LOG_DIR}\"\n",
    "    , f\"--data_dir_prefix_path={EXAMPLE_GEN_GCS_PATH}\"\n",
    "    , f\"--vocab_prefix_path={EXAMPLE_GEN_GCS_PATH}/{VOCAB_SUBDIR}\"\n",
    "    , f\"--vocab_filename={VOCAB_FILENAME}\"\n",
    "    ### job config\n",
    "    , f\"--distribute={DISTRIBUTE_STRATEGY}\"\n",
    "    , f\"--experiment_name={EXPERIMENT_NAME}\"\n",
    "    , f\"--experiment_run={RUN_NAME}\"\n",
    "    , f\"--agent_type={AGENT_TYPE}\"\n",
    "    , f\"--network_type={NETWORK_TYPE}\"\n",
    "    ### hparams\n",
    "    , f\"--batch_size={BATCH_SIZE}\"\n",
    "    , f\"--eval_batch_size={EVAL_BATCH_SIZE}\"\n",
    "    , f\"--training_loops={TRAINING_LOOPS}\"\n",
    "    , f\"--steps_per_loop={STEPS_PER_LOOP}\"\n",
    "    , f\"--num_eval_steps={NUM_EVAL_STEPS}\"\n",
    "    , f\"--rank_k={RANK_K}\"\n",
    "    , f\"--num_actions={NUM_ACTIONS}\"\n",
    "    , f\"--async_steps_per_loop={ASYNC_STEPS_PER_LOOP}\"\n",
    "    # , f\"--resume_training_loops\"\n",
    "    , f\"--global_dim={GLOBAL_DIM}\"\n",
    "    , f\"--per_arm_dim={PER_ARM_DIM}\"\n",
    "    , f\"--split={SPLIT}\"\n",
    "    , f\"--log_interval={LOG_INTERVAL}\"\n",
    "    , f\"--chkpt_interval={CHKPT_INTERVAL}\"\n",
    "    , f\"--num_oov_buckets={NUM_OOV_BUCKETS}\"\n",
    "    , f\"--global_emb_size={GLOBAL_EMBEDDING_SIZE}\"\n",
    "    , f\"--mv_emb_size={MV_EMBEDDING_SIZE}\"\n",
    "    , f\"--agent_alpha={AGENT_ALPHA}\"\n",
    "    , f\"--global_layers={GLOBAL_LAYERS}\"\n",
    "    , f\"--arm_layers={ARM_LAYERS}\"\n",
    "    , f\"--common_layers={COMMON_LAYERS}\"\n",
    "    , f\"--learning_rate={LR}\"\n",
    "    , f\"--epsilon={EPSILON}\"\n",
    "    , f\"--encoding_dim={ENCODING_DIM}\"\n",
    "    , f\"--eps_phase_steps={EPS_PHASE_STEPS}\"\n",
    "    , f\"--tf_gpu_thread_count={TF_GPU_THREAD_COUNT}\"\n",
    "    , f\"--num_epochs={NUM_EPOCHS}\"\n",
    "    ### accelerators & profiling\n",
    "    , f\"--use_gpu\"\n",
    "    # , f\"--use_tpu\"\n",
    "    # , f\"--profiler\"\n",
    "    , f\"--sum_grads_vars\"\n",
    "    , f\"--debug_summaries\"\n",
    "    # , f\"--cache_train\"\n",
    "    # , f\"--is_testing\"\n",
    "]\n",
    "\n",
    "WORKER_POOL_SPECS = train_utils.prepare_worker_pool_specs(\n",
    "    # image_uri=f\"{REMOTE_IMAGE_NAME}:latest\",\n",
    "    image_uri=f\"{IMAGE_URI_02}:latest\",\n",
    "    args=WORKER_ARGS,\n",
    "    replica_count=REPLICA_COUNT,\n",
    "    machine_type=WORKER_MACHINE_TYPE,\n",
    "    accelerator_count=PER_MACHINE_ACCELERATOR_COUNT,\n",
    "    accelerator_type=ACCELERATOR_TYPE,\n",
    "    reduction_server_count=REDUCTION_SERVER_COUNT,\n",
    "    reduction_server_machine_type=REDUCTION_SERVER_MACHINE_TYPE,\n",
    ")\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(WORKER_POOL_SPECS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e582ba0-71f0-4b9d-a5ff-edb7b43dc046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea381beb-3d3b-4595-bd69-b8aeda060ebf",
   "metadata": {},
   "source": [
    "# Submit trainging job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f42d2a93-7043-4433-8d0f-3c15c704419c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB_NAME: 02-deep-bandits-v1-run-20240313-213741\n"
     ]
    }
   ],
   "source": [
    "vertex_ai.init(\n",
    "    project=PROJECT_ID\n",
    "    , location=REGION\n",
    "    , experiment=EXPERIMENT_NAME\n",
    "    # , staging_bucket=ROOT_DIR\n",
    ")\n",
    "\n",
    "JOB_NAME = f\"{EXPERIMENT_NAME}-{RUN_NAME}\"\n",
    "print(f\"JOB_NAME: {JOB_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd25c64d-de18-439d-96f6-5d8d166f4bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CustomJob\n",
    "my_custom_job = vertex_ai.CustomJob(\n",
    "    display_name=JOB_NAME\n",
    "    , project=PROJECT_ID\n",
    "    , worker_pool_specs=WORKER_POOL_SPECS\n",
    "    , base_output_dir=BASE_OUTPUT_DIR\n",
    "    , staging_bucket=ROOT_DIR\n",
    "    # , location=\"asia-southeast1\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db98ac56-e829-4f47-a21f-95fdc3e21fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_custom_job.run(\n",
    "    tensorboard=TB_RESOURCE_NAME,\n",
    "    service_account=VERTEX_SA,\n",
    "    restart_job_on_worker_restart=False,\n",
    "    enable_web_access=True,\n",
    "    sync=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06cd97c1-9682-4bd8-a1c8-da27593cb4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Name: 02-deep-reward-bandits-run-20240222-215620\n",
      "Job Resource Name: projects/934903580331/locations/us-central1/customJobs/5234690678482534400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Job Name: {my_custom_job.display_name}\")\n",
    "print(f\"Job Resource Name: {my_custom_job.resource_name}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa63c92f-0a19-4184-b7c6-ea96d389712d",
   "metadata": {},
   "source": [
    "### Get link to Vertex AI Experiment console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "98ec7046-1708-40f8-a589-886e96f726de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>experiment_name</th>\n",
       "      <td>02-scale-compare-v5</td>\n",
       "      <td>02-scale-compare-v5</td>\n",
       "      <td>02-scale-compare-v5</td>\n",
       "      <td>02-scale-compare-v5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run_name</th>\n",
       "      <td>run-20231214-174236</td>\n",
       "      <td>run-20231214-172310</td>\n",
       "      <td>run-20231214-171428</td>\n",
       "      <td>run-20231214-165818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run_type</th>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.batch_size</th>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.global_lyrs</th>\n",
       "      <td>[64, 32, 16]</td>\n",
       "      <td>[64, 32, 16]</td>\n",
       "      <td>[64, 32, 16]</td>\n",
       "      <td>[64, 32, 16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.arm_lyrs</th>\n",
       "      <td>[64, 32, 16]</td>\n",
       "      <td>[64, 32, 16]</td>\n",
       "      <td>[64, 32, 16]</td>\n",
       "      <td>[64, 32, 16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.runtime</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.encoding_dim</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.network</th>\n",
       "      <td>commontower</td>\n",
       "      <td>commontower</td>\n",
       "      <td>commontower</td>\n",
       "      <td>commontower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.training_loops</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.agent_type</th>\n",
       "      <td>linear_ucb_agent</td>\n",
       "      <td>linear_thompson_sampling_agent</td>\n",
       "      <td>neural_linucb_agent</td>\n",
       "      <td>NeuralEpsGreedyAgent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.common_lyrs</th>\n",
       "      <td>[16, 8]</td>\n",
       "      <td>[16, 8]</td>\n",
       "      <td>[16, 8]</td>\n",
       "      <td>[16, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric.val_loss</th>\n",
       "      <td>13.81</td>\n",
       "      <td>17.44</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric.train_loss</th>\n",
       "      <td>1.22</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_series_metric.loss</th>\n",
       "      <td>1.219626</td>\n",
       "      <td>1.297771</td>\n",
       "      <td>1.222324</td>\n",
       "      <td>1.286156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            0                               1  \\\n",
       "experiment_name           02-scale-compare-v5             02-scale-compare-v5   \n",
       "run_name                  run-20231214-174236             run-20231214-172310   \n",
       "run_type                 system.ExperimentRun            system.ExperimentRun   \n",
       "state                                COMPLETE                        COMPLETE   \n",
       "param.batch_size                        128.0                           128.0   \n",
       "param.global_lyrs                [64, 32, 16]                    [64, 32, 16]   \n",
       "param.arm_lyrs                   [64, 32, 16]                    [64, 32, 16]   \n",
       "param.runtime                             3.0                             3.0   \n",
       "param.encoding_dim                        1.0                             1.0   \n",
       "param.network                     commontower                     commontower   \n",
       "param.training_loops                    100.0                           100.0   \n",
       "param.agent_type             linear_ucb_agent  linear_thompson_sampling_agent   \n",
       "param.common_lyrs                     [16, 8]                         [16, 8]   \n",
       "metric.val_loss                         13.81                           17.44   \n",
       "metric.train_loss                        1.22                             1.3   \n",
       "time_series_metric.loss              1.219626                        1.297771   \n",
       "\n",
       "                                            2                     3  \n",
       "experiment_name           02-scale-compare-v5   02-scale-compare-v5  \n",
       "run_name                  run-20231214-171428   run-20231214-165818  \n",
       "run_type                 system.ExperimentRun  system.ExperimentRun  \n",
       "state                                COMPLETE              COMPLETE  \n",
       "param.batch_size                        128.0                 128.0  \n",
       "param.global_lyrs                [64, 32, 16]          [64, 32, 16]  \n",
       "param.arm_lyrs                   [64, 32, 16]          [64, 32, 16]  \n",
       "param.runtime                             0.0                   0.0  \n",
       "param.encoding_dim                        8.0                   1.0  \n",
       "param.network                     commontower           commontower  \n",
       "param.training_loops                    100.0                 100.0  \n",
       "param.agent_type          neural_linucb_agent  NeuralEpsGreedyAgent  \n",
       "param.common_lyrs                     [16, 8]               [16, 8]  \n",
       "metric.val_loss                          1.36                  1.35  \n",
       "metric.train_loss                        1.22                  1.29  \n",
       "time_series_metric.loss              1.222324              1.286156  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_df = vertex_ai.get_experiment_df()\n",
    "experiment_df = experiment_df[experiment_df.experiment_name == EXPERIMENT_NAME]\n",
    "experiment_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "021ea34f-05c0-492f-baa5-ce6335d3e62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Open the following link\", experiment_df[\"metric.lineage\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ff7630-5337-474c-9d28-fcdfab74f791",
   "metadata": {},
   "source": [
    "### GPU profiling\n",
    "\n",
    "> once training job begins, enter these commands in the Vertex interactive terminal:\n",
    "\n",
    "```bash\n",
    "sudo apt update\n",
    "sudo apt -y install nvtop\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6514a309-ca15-4ca3-a32d-857adb749d4e",
   "metadata": {},
   "source": [
    "## TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbef7bc-0077-48ce-9be0-85e4cf881523",
   "metadata": {},
   "source": [
    "### in-notebook TensorBoard\n",
    "\n",
    "> if `--profiler`, find `PROFILE` in the drop down:\n",
    "\n",
    "<img src=\"imgs/getting_profiler.png\" \n",
    "     align=\"center\" \n",
    "     width=\"850\"\n",
    "     height=\"850\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae6b0c00-39da-411a-8b96-b151a9c45ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG_DIR: gs://rec-bandits-v2-hybrid-vertex-bucket/02-online-dotp/run-20240221-023400/logs\n",
      "Known TensorBoard instances:\n",
      "  - port 6006: logdir gs://rec-bandits-v2-hybrid-vertex-bucket/02b-deep-bandits-rec-bandits-v2/run-20240214-180454/logs (started 6 days, 9:42:33 ago; pid 3029265)\n"
     ]
    }
   ],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard import notebook\n",
    "\n",
    "print(f\"LOG_DIR: {LOG_DIR}\")\n",
    "\n",
    "notebook.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1763ace-2c4a-4b93-a8b9-4419f5858f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eecde86e-96e4-4389-a59b-97b069b97c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6a694f24747dabba\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6a694f24747dabba\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=$LOG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3bf4ac-5621-425e-b74f-5cbaa738b398",
   "metadata": {},
   "source": [
    "# Making predictions\n",
    "\n",
    "* When a policy is trained, given a new observation request (i.e. a user vector),\n",
    "* the policy will inference (produce) actions, which are the recommended movies.\n",
    "* In TF-Agents, observations are abstracted in a named tuple,\n",
    "\n",
    "```\n",
    "TimeStep(‘step_type’, ‘discount’, ‘reward’, ‘observation’)\n",
    "```\n",
    "\n",
    "> the policy maps time steps to actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7eb70de-3aa9-41ca-8f37-b7fb8b7d931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from src.perarm_features import emb_features as emb_features\n",
    "from src.perarm_features import reward_factory as reward_factory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f653049f-0e5f-4055-99c7-471c5a4a665e",
   "metadata": {},
   "source": [
    "## Load eval dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b81eeef5-2512-4235-ac00-6798f14d6fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/movielens-1m'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_GCS_PREFIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fcbc77f1-1e3f-4803-a3f6-70377a755d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec={'bucketized_user_age': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'movie_genres': TensorSpec(shape=(None, 1), dtype=tf.int64, name=None), 'movie_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'timestamp': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'user_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_occupation_text': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_rating': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPLIT = \"val\"\n",
    "\n",
    "val_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        val_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "        \n",
    "val_dataset = tf.data.TFRecordDataset(val_files)\n",
    "val_dataset = val_dataset.map(data_utils.parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(1)\n",
    "\n",
    "if NUM_EVAL_STEPS > 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)\n",
    "\n",
    "eval_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e1c58e1-c187-486c-a7c6-d497f25c2789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens-1m/val/ml-1m-ratings-train-09-of-10.tfrecord',\n",
       " 'gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens-1m/val/ml-1m-ratings-train-10-of-10.tfrecord',\n",
       " 'gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens-1m/val_v1/ml-1m-ratings-train-7-of-10.tfrecord',\n",
       " 'gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens-1m/val_v1/ml-1m-ratings-train-8-of-10.tfrecord']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bc01ee-2857-4cf9-8369-e49156c906af",
   "metadata": {},
   "source": [
    "### Load vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4fe552cf-817c-49b1-8f4b-01860e0f85d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab...\n",
      "Downloaded vocab from: gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens-1m/vocab_dict.pkl\n",
      "\n",
      "'movie_id'\n",
      "'user_id'\n",
      "'user_occupation_text'\n",
      "'movie_genres'\n",
      "'bucketized_user_age'\n",
      "'max_timestamp'\n",
      "'min_timestamp'\n",
      "'timestamp_buckets'\n"
     ]
    }
   ],
   "source": [
    "EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{DATA_GCS_PREFIX}/{VOCAB_FILENAME}'\n",
    "print(f\"Downloading vocab...\")\n",
    "\n",
    "os.system(f'gsutil -q cp {EXISTING_VOCAB_FILE} .')\n",
    "print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "vocab_dict = pkl.load(filehandler)\n",
    "filehandler.close()\n",
    "\n",
    "for key in vocab_dict.keys():\n",
    "    pprint(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d14f4f2-8304-40e5-b7ed-aad69b424bac",
   "metadata": {},
   "source": [
    "## load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d547058-6982-4588-94a7-62dda9801f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-online-dotp/run-20240221-023400/artifacts/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-online-dotp/run-20240221-023400/artifacts/fingerprint.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-online-dotp/run-20240221-023400/artifacts/policy_specs.pbtxt\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-online-dotp/run-20240221-023400/artifacts/saved_model.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-online-dotp/run-20240221-023400/artifacts/assets/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-online-dotp/run-20240221-023400/artifacts/variables/\n"
     ]
    }
   ],
   "source": [
    "# MODEL_DIR = \"gs://mabv1-hybrid-vertex-bucket/scale-perarm-hpt/run-20230717-211248/model\"\n",
    "\n",
    "!gsutil ls $ARTIFACTS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b70d44d1-2afc-47fa-8c37-dbbea6b286bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f44d9655090>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    ARTIFACTS_DIR, load_specs_from_pbtxt=True\n",
    ")\n",
    "\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff61492-f040-4418-b3df-8a1b05684bce",
   "metadata": {},
   "source": [
    "## call embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f69d531-d286-441a-aff9-d6afd3e30a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GLOBAL_EMBEDDING_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a78f2086-6cd3-4f81-8486-ac8356889e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.perarm_features.emb_features.EmbeddingModel at 0x7f43cc42c1f0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs = emb_features.EmbeddingModel(\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3721854c-59e1-4aeb-a77c-96b2c06c1491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec={'bucketized_user_age': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'movie_genres': TensorSpec(shape=(None, 1), dtype=tf.int64, name=None), 'movie_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'timestamp': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'user_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_occupation_text': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_rating': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06af1cb7-a6a4-48ac-8b42-7d5cd20f51ed",
   "metadata": {},
   "source": [
    "## Run inference with trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1612722-ce10-4766-9b73-cd3ad6ee902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "SKIP_NUM = 10\n",
    "\n",
    "for x in eval_ds.skip(SKIP_NUM).take(INFER_SIZE):\n",
    "    # get feature tensors    \n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "    \n",
    "    # rewards = _get_rewards(x)\n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [EVAL_BATCH_SIZE, PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "404f31fd-a5dc-46a8-bb3d-20a9b23cce10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 64), dtype=float32, numpy=\n",
       "array([[-0.02423429,  0.03569544,  0.00941722,  0.01268059, -0.03076227,\n",
       "         0.03151837, -0.0090163 , -0.02012342,  0.04700836,  0.04948396,\n",
       "         0.0341096 , -0.04149907,  0.00039178,  0.01899574, -0.00683619,\n",
       "        -0.04258578, -0.01099278,  0.02549082,  0.01653793,  0.03991942,\n",
       "         0.04965748, -0.0127555 ,  0.02935164,  0.01087339, -0.01636513,\n",
       "        -0.02368754, -0.03929192,  0.02375125,  0.02551729, -0.03736371,\n",
       "        -0.02413548,  0.03881891, -0.01570874, -0.01364864,  0.03775977,\n",
       "         0.00097629, -0.01052288, -0.01703221, -0.03854374, -0.00365437,\n",
       "         0.04919578, -0.02562262,  0.02056113,  0.01011078, -0.03701179,\n",
       "         0.03339164, -0.0496799 , -0.01876576,  0.04010205,  0.02692163,\n",
       "         0.03405235,  0.02577719, -0.00747878, -0.0301556 ,  0.00328819,\n",
       "        -0.00376345, -0.04580323,  0.00474114, -0.00995062, -0.04982231,\n",
       "        -0.01080923, -0.01271247,  0.00133632,  0.03775134]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_feat_infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee06bbdc-8b88-4860-9e85-1dedd020c9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([25.], dtype=float32)>,\n",
       " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[0]])>,\n",
       " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'2641'], dtype=object)>,\n",
       " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([968355413])>,\n",
       " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'3519'], dtype=object)>,\n",
       " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'sales/marketing'], dtype=object)>,\n",
       " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "185c1ee8-7a3c-42b2-87e0-2b27962b043c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.7975988, 3.6516001], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([ 0.03101024,  0.01031622,  0.04479486, -0.02150822, -0.04589235,\n",
       "       -0.01095872,  0.01401026, -0.01187184, -0.0410215 , -0.01127779,\n",
       "        0.04456648,  0.04855448, -0.01872145, -0.00123424, -0.02530294,\n",
       "        0.00059376, -0.00525342, -0.04443268, -0.04115971,  0.00346   ,\n",
       "        0.00196717,  0.03168103,  0.04312061,  0.04696795, -0.02688395,\n",
       "       -0.00467808,  0.03762523,  0.0239989 , -0.02450874, -0.03839843,\n",
       "        0.0156719 ,  0.00319712, -0.03129433,  0.00797918,  0.04204294,\n",
       "       -0.01635186,  0.04087284, -0.04855653, -0.00927971, -0.00776714,\n",
       "        0.03924856,  0.04905334,  0.00831705, -0.03254086,  0.01044741,\n",
       "        0.04248929, -0.04655696,  0.04360152, -0.04491235, -0.02771148,\n",
       "       -0.02455752,  0.02510467, -0.01346394,  0.0129779 ,  0.01938358,\n",
       "       -0.03857655,  0.02585015, -0.00326873,  0.00068201,  0.00505117,\n",
       "       -0.02473953, -0.0349616 , -0.04758177,  0.00491229], dtype=float32)))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3eb310-b9a4-4a13-ad62-f9b2f7c84a43",
   "metadata": {},
   "source": [
    "# Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11040c4c-2291-4c40-8e62-c9956c9285c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7002c9-69e2-4940-b84f-924984c03a54",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
