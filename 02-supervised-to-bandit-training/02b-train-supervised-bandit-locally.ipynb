{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385307d6-2058-47ec-8da0-57f7ef5c43d6",
   "metadata": {},
   "source": [
    "# Train Bandits with per-arm features\n",
    "\n",
    "**Exploring linear and nonlinear** (e.g., those with neural network-based value functions) bandit methods for recommendations using TF-Agents\n",
    "\n",
    "> Neural linear bandits provide a nice way to leverage the representation power of deep learning and the bandit approach for uncertainty measure and efficient exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1e9956-66cd-4bf4-9b4d-8c2c646f0313",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "\n",
    "In this notebook, we explore the following topics for training contextual bandits with per-arm features:\n",
    "\n",
    "1. Data preparation\n",
    "2. Sampling functions\n",
    "3. TensorSpecs\n",
    "4. Agent, Network, training policy\n",
    "5. Reward function\n",
    "6. Trajectory function\n",
    "7. Train & Eval loops\n",
    "8. Getting predictions -\n",
    "9. Preparing the training application - abstracting all steps above to be used in subsequent notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fd257-b98b-426a-a2cd-024429b014f1",
   "metadata": {},
   "source": [
    "## Load notebook config\n",
    "\n",
    "* use the prefix defined in `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f39c9d08-d118-4013-a47f-88450f49f19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "# PREFIX = 'mabv1'\n",
    "VERSION = \"v2\"  # TODO\n",
    "PREFIX = f\"rec-bandits-{VERSION}\"  # TODO\n",
    "\n",
    "print(f\"PREFIX: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908f6b95-b539-4a9f-a836-840d26ea3b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"cpg-cdp\"\n",
      "PROJECT_NUM              = \"939655404703\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"939655404703-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"rec-bandits-v2\"\n",
      "VERSION                  = \"v2\"\n",
      "\n",
      "BUCKET_NAME              = \"rec-bandits-v2-cpg-cdp-bucket\"\n",
      "BUCKET_URI               = \"gs://rec-bandits-v2-cpg-cdp-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://rec-bandits-v2-cpg-cdp-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "DATA_PATH_KFP_DEMO       = \"gs://rec-bandits-v2-cpg-cdp-bucket/data/kfp_demo_data/u.data\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/939655404703/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_NAME    = \"mvlens_rec_bandits_v2\"\n",
      "BIGQUERY_TABLE_NAME      = \"training_dataset\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-rec-bandits-v2\"\n",
      "\n",
      "DOCKERNAME_01            = \"Dockerfile_train_my_perarm_env\"\n",
      "IMAGE_NAME_01            = \"train-my-perarm-env-v2\"\n",
      "IMAGE_URI_01             = \"gcr.io/cpg-cdp/train-my-perarm-env-v2\"\n",
      "\n",
      "DOCKERNAME_02            = \"Dockerfile_perarm_feats\"\n",
      "IMAGE_NAME_02            = \"train-perarm-feats-v2\"\n",
      "IMAGE_URI_02             = \"gcr.io/cpg-cdp/train-perarm-feats-v2\"\n",
      "\n",
      "DOCKERNAME_03            = \"Dockerfile_ranking_bandit\"\n",
      "IMAGE_NAME_03            = \"train-rank-bandit-v2\"\n",
      "IMAGE_URI_03             = \"gcr.io/cpg-cdp/train-rank-bandit-v2\"\n",
      "\n",
      "DOCKERNAME_04            = \"Dockerfile_train_mab_e2e\"\n",
      "IMAGE_NAME_04            = \"train-mab-e2e-v2\"\n",
      "IMAGE_URI_04             = \"gcr.io/cpg-cdp/train-mab-e2e-v2\"\n",
      "\n",
      "DOCKERNAME_04_pred       = \"Dockerfile_pred_mab_e2e\"\n",
      "IMAGE_NAME_04_pred       = \"pred-mab-e2e-v2\"\n",
      "IMAGE_URI_04_pred        = \"gcr.io/cpg-cdp/pred-mab-e2e-v2\"\n",
      "\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/cpg-cdp/rl-movielens-rec-bandits-v2/local_docker_tfa\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c690a9-e2bd-4759-ba41-4e2469098aee",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d0dfe4-695c-4dd4-9f24-67f7488ce1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c669f1a1-1af7-4efb-ab2d-6bf3b3847991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from collections import defaultdict\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pickle as pkl\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# from tf_agents.agents import TFAgent\n",
    "\n",
    "# from tf_agents.bandits.environments import stationary_stochastic_per_arm_py_environment as p_a_env\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "\n",
    "# from tf_agents.drivers import dynamic_step_driver\n",
    "# from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "# from tf_agents.bandits.agents import lin_ucb_agent\n",
    "# from tf_agents.bandits.agents import linear_thompson_sampling_agent as lin_ts_agent\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent\n",
    "from tf_agents.bandits.agents import neural_linucb_agent\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "from tf_agents.bandits.policies import policy_utilities\n",
    "\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "\n",
    "nest = tf.nest\n",
    "\n",
    "# GPU\n",
    "from numba import cuda\n",
    "import gc\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# this repo\n",
    "from src.per_arm_rl import data_utils\n",
    "from src.per_arm_rl import data_config\n",
    "from src.per_arm_rl import train_utils as train_utils\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29e58dd7-ab2b-419f-9771-bf1e98db758b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4969d3e-1fc0-45db-8a69-aa6b342019de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "274e7f4a-1802-4946-888e-876638f5c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a866b1-85b9-43e6-9546-edfbbf886bce",
   "metadata": {},
   "source": [
    "# [1] Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d4ed28-23d7-4785-b327-e5b543b0edb9",
   "metadata": {},
   "source": [
    "**Overview**\n",
    "* Load train and eval datasets from TFRecords created in the `01-movielens-data-prep.ipynb` notebook\n",
    "* training examples represent historical (previously collected) interaction data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc3fcebe-818b-4767-afdc-cfb65b3b953d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_TAG: movielens-100k\n",
      "gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-100k/vocab_dict.pkl\n",
      "gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-100k/all/\n",
      "gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-100k/train/\n",
      "gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-100k/val/\n"
     ]
    }
   ],
   "source": [
    "DATA_TAG = \"movielens-100k\" # movielens-100k | movielens-1m\n",
    "\n",
    "print(f\"DATA_TAG: {DATA_TAG}\")\n",
    "\n",
    "! gsutil ls $DATA_PATH/$DATA_TAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd5b953-14c0-42ed-a511-77147a1bc0ac",
   "metadata": {},
   "source": [
    "### Read TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d0157c8-a04c-4dbd-b6d9-a1ede97687a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = (\n",
    "    tf.data.experimental.AutoShardPolicy.AUTO\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da0cdac-76af-4608-b70e-be7dbe0584b5",
   "metadata": {},
   "source": [
    "**Train data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c934c06-bf08-4c7f-b0cc-0de04ef3515c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-100k/train/ml-100k-ratings-train-01-of-05.tfrecord',\n",
       " 'gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-100k/train/ml-100k-ratings-train-02-of-05.tfrecord',\n",
       " 'gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-100k/train/ml-100k-ratings-train-03-of-05.tfrecord',\n",
       " 'gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-100k/train/ml-100k-ratings-train-04-of-05.tfrecord']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPLIT = \"train\"  # \"train\" | \"val\"\n",
    "\n",
    "train_files = []\n",
    "for blob in storage_client.list_blobs(\n",
    "    f\"{BUCKET_NAME}\", prefix=f\"{DATA_GCS_PREFIX}/{DATA_TAG}/{SPLIT}\"\n",
    "):\n",
    "    if \".tfrecord\" in blob.name:\n",
    "        train_files.append(\n",
    "            blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\")\n",
    "        )\n",
    "\n",
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7511e4d-bf81-4800-bde7-8b16dec9aeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([45.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'357'], dtype=object)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([879024327])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'138'], dtype=object)>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'doctor'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "train_dataset = train_dataset.map(data_utils.parse_tfrecord)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452750c1-46a0-4ee1-84d4-0c3b227de38f",
   "metadata": {},
   "source": [
    "**Val data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7b5376f-9438-4304-84aa-de09c30f5e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = \"val\"\n",
    "\n",
    "val_files = []\n",
    "for blob in storage_client.list_blobs(\n",
    "    f\"{BUCKET_NAME}\", prefix=f\"{DATA_GCS_PREFIX}/{DATA_TAG}/{SPLIT}\"\n",
    "):\n",
    "    if \".tfrecord\" in blob.name:\n",
    "        val_files.append(\n",
    "            blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\")\n",
    "        )\n",
    "\n",
    "val_dataset = tf.data.TFRecordDataset(val_files)\n",
    "val_dataset = val_dataset.map(\n",
    "    data_utils.parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8959967-522e-41c8-9a1b-050ca8bc191f",
   "metadata": {},
   "source": [
    "### get vocab\n",
    "\n",
    "**TODO:** \n",
    "* streamline vocab calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b9169bc-d6dc-497e-9dff-6ebb175282ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE_VOCABS: False\n"
     ]
    }
   ],
   "source": [
    "GENERATE_VOCABS = False\n",
    "\n",
    "print(f\"GENERATE_VOCABS: {GENERATE_VOCABS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3ccf137-7a72-42e7-aa89-3c81a99cf40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab...\n",
      "Downloaded vocab from: gs://rec-bandits-v2-cpg-cdp-bucket/data/movielens-100k/vocab_dict.pkl\n",
      "\n",
      "'movie_id'\n",
      "'user_id'\n",
      "'user_occupation_text'\n",
      "'movie_genres'\n",
      "'bucketized_user_age'\n",
      "'max_timestamp'\n",
      "'min_timestamp'\n",
      "'timestamp_buckets'\n"
     ]
    }
   ],
   "source": [
    "if not GENERATE_VOCABS:\n",
    "\n",
    "    EXISTING_VOCAB_FILE = (\n",
    "        f\"gs://{BUCKET_NAME}/{DATA_GCS_PREFIX}/{DATA_TAG}/{VOCAB_FILENAME}\"\n",
    "    )\n",
    "    print(f\"Downloading vocab...\")\n",
    "\n",
    "    os.system(f\"gsutil -q cp {EXISTING_VOCAB_FILE} .\")\n",
    "    print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "    filehandler = open(VOCAB_FILENAME, \"rb\")\n",
    "    vocab_dict = pkl.load(filehandler)\n",
    "    filehandler.close()\n",
    "\n",
    "    for key in vocab_dict.keys():\n",
    "        pprint(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfda012c-a2c3-4384-a5a4-54f5c6649006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vocab_dict['user_occupation_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138a295-2b0d-4359-8496-af8552ec8cff",
   "metadata": {},
   "source": [
    "# [2] Preprocessing layers for global and arm features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e28c002-8d3a-4cf4-b69b-de56a6abab90",
   "metadata": {},
   "source": [
    "The pre-processing layers will ultimately feed the two sampling functions described below. These sampling functions will be used to create [trajectories](https://github.com/tensorflow/agents/blob/master/tf_agents/trajectories/trajectory.py#L36) (i.e., the training examples for our model)\n",
    "\n",
    "`global_context_sampling_fn`: \n",
    "* A function that outputs a random 1d array or list of ints or floats\n",
    "* This output is the global context. Its shape and type must be consistent across calls.\n",
    "\n",
    "`arm_context_sampling_fn`: \n",
    "* A function that outputs a random 1 array or list of ints or floats (same type as the output of `global_context_sampling_fn`). * This output is the per-arm context. Its shape must be consistent across calls.\n",
    "\n",
    "See `debug-and-learn-emb-models.ipynb` for more details and debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ea1f7-0621-44b8-b062-1f59b0964d72",
   "metadata": {},
   "source": [
    "## Global & Per-Arm feature embedding models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8d77956-635c-438a-916a-185eec52f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OOV_BUCKETS = 1\n",
    "GLOBAL_EMBEDDING_SIZE = 16\n",
    "MV_EMBEDDING_SIZE = 32  # 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea335991-dcec-40b3-ba0d-a0fdfb9c2ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test emb models\n",
    "for i in range(1):\n",
    "\n",
    "    iterator = iter(train_dataset.batch(1))\n",
    "    data = next(iterator)\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48178fff-491f-4f03-b156-7765d1fa9707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.perarm_features.emb_features.EmbeddingModel at 0x7fdfb357b4c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.perarm_features import emb_features as emb_features\n",
    "\n",
    "embs = emb_features.EmbeddingModel(\n",
    "    vocab_dict=vocab_dict,\n",
    "    num_oov_buckets=NUM_OOV_BUCKETS,\n",
    "    global_emb_size=GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size=MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "903c63c5-2468-4443-bcb8-5ff6d69810dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL_DIM: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 64), dtype=float32, numpy=\n",
       "array([[-0.04040783,  0.00323424, -0.0325067 , -0.02339082, -0.02591138,\n",
       "        -0.00582038,  0.00051423,  0.02850081,  0.02921892,  0.03280478,\n",
       "        -0.04334834,  0.04476548,  0.00042028,  0.02298105,  0.04470021,\n",
       "         0.0409661 ,  0.043471  ,  0.03880138, -0.03529788,  0.0209298 ,\n",
       "         0.04648776,  0.04119961, -0.01086237,  0.01859614,  0.01135383,\n",
       "         0.03575164,  0.01524169, -0.02134654,  0.02933108,  0.02930472,\n",
       "        -0.01740506, -0.00738139, -0.00257968,  0.04791887, -0.03091142,\n",
       "        -0.0272158 ,  0.00949512, -0.03595717, -0.02167158,  0.0194491 ,\n",
       "        -0.03991473, -0.01625888, -0.0089318 , -0.01108078, -0.02905966,\n",
       "         0.01480702,  0.03221602,  0.00562758, -0.04594862, -0.03306388,\n",
       "         0.0158106 ,  0.00373627, -0.03267185, -0.01767505, -0.02392538,\n",
       "         0.0418657 , -0.03824027,  0.0318251 , -0.01654371, -0.02102878,\n",
       "        -0.01022767,  0.00565982, -0.04815487, -0.00379621]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_globals = embs._get_global_context_features(data)\n",
    "\n",
    "GLOBAL_DIM = test_globals.shape[1]\n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"GLOBAL_DIM: {GLOBAL_DIM}\")\n",
    "\n",
    "test_globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebec4863-c614-4248-b680-8e29ec5b730d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER_ARM_DIM: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 64), dtype=float32, numpy=\n",
       "array([[-0.00661731, -0.00010347,  0.04630414, -0.00340879, -0.01470927,\n",
       "         0.04405786, -0.01353196, -0.01737996,  0.00077504, -0.02488402,\n",
       "        -0.02095786,  0.00921997, -0.01816414, -0.00538485, -0.01454825,\n",
       "        -0.01753725, -0.04617741, -0.01645146,  0.00371527,  0.04152009,\n",
       "        -0.03887507, -0.02783879, -0.00088984, -0.03548043,  0.00186222,\n",
       "         0.02013714,  0.02228269,  0.00105719,  0.00913454,  0.00845251,\n",
       "        -0.04510913, -0.02633911, -0.04766407, -0.01645933, -0.03067322,\n",
       "         0.02899047, -0.04540149, -0.02805681, -0.01609742, -0.03164977,\n",
       "        -0.04222547,  0.00096946,  0.04163511,  0.0130874 ,  0.02398742,\n",
       "        -0.00807899,  0.00379167, -0.04610946, -0.03536852, -0.03799437,\n",
       "        -0.01432618, -0.03175496, -0.04258743,  0.00134158,  0.01864547,\n",
       "         0.02785227, -0.02001007,  0.03755783, -0.02954866, -0.01902101,\n",
       "        -0.02484101,  0.01521386, -0.03574275,  0.02899405]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arms = embs._get_per_arm_features(data)\n",
    "\n",
    "PER_ARM_DIM = test_arms.shape[1]\n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"PER_ARM_DIM: {PER_ARM_DIM}\")\n",
    "\n",
    "test_arms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ff9baaf-987d-448d-a981-742a79b581e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE      : 128\n",
      "EVAL_BATCH_SIZE : 1\n",
      "NUM_ACTIONS     : 2\n",
      "GLOBAL_DIM      : 64\n",
      "PER_ARM_DIM     : 64\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "EVAL_BATCH_SIZE = 1\n",
    "\n",
    "NUM_ACTIONS = 2  # this is kinda deceptive -\n",
    "# our approach is to learn by \"flashing\" one movie rating at a time per user context.\n",
    "# The n_actions = show/don't show the movie with one degree of freedom (n-1)\n",
    "\n",
    "\n",
    "print(f\"BATCH_SIZE      : {BATCH_SIZE}\")\n",
    "print(f\"EVAL_BATCH_SIZE : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"NUM_ACTIONS     : {NUM_ACTIONS}\")\n",
    "print(f\"GLOBAL_DIM      : {GLOBAL_DIM}\")\n",
    "print(f\"PER_ARM_DIM     : {PER_ARM_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeb4902-5bb9-4587-8d29-c01d78b006be",
   "metadata": {},
   "source": [
    "# [3] TensorSpecs\n",
    "\n",
    "* say you have a global observation spec of `[17]`. And you have two batch dimensions `[4, 5]`. Then your observation has to have the shape `[4, 5, 17]`\n",
    "* and then if you have arm_obs_spec with shape `[9, 13]`, then the arm obs shape has to be exactly `[4, 5, 9, 13]`\n",
    "* and this has to be true for every single tensor in your tensor nest\n",
    "* the first 2 dims are the outer dims that are the same for all tensors, the rest of the dimensions have to follow the spec for each tensor\n",
    "\n",
    "**TODO:**\n",
    "* explain relationship between Tensor Specs and their Tensor counterparts\n",
    "* highlight the errors, lessons learned, and utility functions to address these"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20eca8d-8c73-4ec8-9d0f-f2b428055ac2",
   "metadata": {},
   "source": [
    "## Implementing MAB with TF-Agents\n",
    "\n",
    "In TF-Agents, the *per-arm features* implementation differs from the *global-only* feature examples in the following aspects:\n",
    "* Reward is modeled not per-arm, but globally.\n",
    "* The arms are permutation invariant: it doesn’t matter which arm is arm 1 or arm 2, only their features.\n",
    "* One can have a different number of arms to choose from in every step (note that unspecified/dynamically changing number of arms will have a problem with XLA compatibility).\n",
    "\n",
    "When implementing per-arm features in TF-Bandits, the following details have to be discussed:\n",
    "* Observation spec and observations,\n",
    "* Action spec and actions,\n",
    "* Implementation of specific policies and agents.\n",
    "\n",
    "\n",
    "**TODO:**\n",
    "* outline the components and highlight their interactions, dependencies on eachother, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f68ebe8-116d-43b3-a6e1-4f5a5c7f4741",
   "metadata": {},
   "source": [
    "### Observation spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9c4746-d01b-4ca4-aa53-ab68da54d37a",
   "metadata": {},
   "source": [
    "**This observation spec allows the user to have a global observation of fixed dimension**, and an unspecified number of *per-arm* features (also of fixed dimension)\n",
    "* The actions output by the policy are still integers as usual, and they indicate which row of the arm-features it has chosen \n",
    "* The action spec must be a single integer value without boundaries:\n",
    "\n",
    "```python\n",
    "global_spec = tensor_spec.TensorSpec([GLOBAL_DIM], tf.float32)\n",
    "per_arm_spec = tensor_spec.TensorSpec([None, PER_ARM_DIM], tf.float32)\n",
    "observation_spec = {'global': global_spec, 'per_arm': per_arm_spec}\n",
    "\n",
    "action_spec = tensor_spec.TensorSpec((), tf.int32)\n",
    "```\n",
    "> Here the only difference compared to the action spec with global features only is that the tensor spec is not bounded, as we don’t know how many arms there will be at any time step\n",
    "\n",
    "**XLA compatibility:**\n",
    "* Since dynamic tensor shapes are not compatible with XLA, the number of arm features (and consequently, number of arms for a step) cannot be dynamic. \n",
    "* One workaround is to fix the maximum number of arms for a problem, then pad the arm features in steps with fewer arms, and use action masking to indicate how many arms are actually active.\n",
    "\n",
    "```python\n",
    "per_arm_spec = tensor_spec.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32)\n",
    "\n",
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=(), dtype=tf.int32, minimum = 0, maximum = NUM_ACTIONS - 1\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36bd3b33-635a-4274-8b9e-7172696ebb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_spec = {\n",
    "    \"global\": tf.TensorSpec([GLOBAL_DIM], tf.float32),\n",
    "    \"per_arm\": tf.TensorSpec(\n",
    "        [NUM_ACTIONS, PER_ARM_DIM], tf.float32\n",
    "    ),  # excluding action dim here\n",
    "}\n",
    "observation_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a2da92-7db2-4f42-94a7-b7bad1c8fc42",
   "metadata": {},
   "source": [
    "### Action spec\n",
    "\n",
    "> The time_step_spec and action_spec are specifications for the input time step and the output action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5af42c7-18d7-480f-a7f3-d7da3f4840eb",
   "metadata": {},
   "source": [
    "```python\n",
    "    if (\n",
    "        not tensor_spec.is_bounded(action_spec)\n",
    "        or not tensor_spec.is_discrete(action_spec)\n",
    "        or action_spec.shape.rank > 1\n",
    "        or action_spec.shape.num_elements() != 1\n",
    "    ):\n",
    "      raise NotImplementedError(\n",
    "          'action_spec must be a BoundedTensorSpec of type int32 and shape (). '\n",
    "          'Found {}.'.format(action_spec)\n",
    "      )\n",
    "```\n",
    "\n",
    "* [src](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_base_policy.py#L97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "549a123c-349a-4103-b39a-4502f47d1e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=[],\n",
    "    dtype=tf.int32,\n",
    "    minimum=tf.constant(0),\n",
    "    maximum=NUM_ACTIONS\n",
    "    - 1,  # n degrees of freedom and will dictate the expected mean reward spec shape\n",
    "    name=\"action_spec\",\n",
    ")\n",
    "\n",
    "action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36ee2635-d4e3-4468-886c-ae9c62e3c80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_num_actions: 2\n",
      "predicted_rewards_mean: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n"
     ]
    }
   ],
   "source": [
    "expected_num_actions = action_spec.maximum - action_spec.minimum + 1\n",
    "print(f\"expected_num_actions: {expected_num_actions}\")\n",
    "\n",
    "predicted_rewards_mean = tensor_spec.TensorSpec([expected_num_actions])\n",
    "print(f\"predicted_rewards_mean: {predicted_rewards_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a51efce-9f1b-42d1-bec4-7b788e3fd7e0",
   "metadata": {},
   "source": [
    "### TimeStep spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95f05860-0fbf-4a5a-8273-9c81761e0ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec = ts.time_step_spec(\n",
    "    observation_spec=observation_spec,\n",
    "    # reward_spec = _reward_spec\n",
    ")\n",
    "time_step_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773b129a-6d19-4b3d-a2e7-e27070f57ac0",
   "metadata": {},
   "source": [
    "### Reward Spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b48e89aa-e010-4bd9-a7e0-ad62dd4c5949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reward': TensorSpec(shape=(128,), dtype=tf.float32, name='reward')}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.specs import array_spec\n",
    "\n",
    "reward_spec = {\n",
    "    \"reward\": array_spec.ArraySpec(shape=[BATCH_SIZE], dtype=np.float32, name=\"reward\")\n",
    "}\n",
    "\n",
    "reward_tensor_spec = train_utils.from_spec(reward_spec)\n",
    "reward_tensor_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9181303-6565-45f5-a293-08d50420a805",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Inspect chosen arm features spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6b526a5-997c-4621-b21c-82c6ca1d6a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90d3e03e-619e-4fa4-b817-f02b4cefd6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(64,), dtype=tf.float32, name=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_arm_features_info = policy_utilities.create_chosen_arm_features_info_spec(\n",
    "    time_step_spec.observation,\n",
    ")\n",
    "chosen_arm_features_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc427092-beb7-4baf-a2e9-b8d10629182c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandit_policy_type = policy_utilities.BanditPolicyType.GREEDY\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a4a2a33-c7d4-4d81-8082-80dfc3596741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandit_policy_type = policy_utilities.create_bandit_policy_type_tensor_spec(shape=[1])\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e7ac02b-18bd-4519-92fe-5541b1a8ddc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_spec = policy_utilities.PerArmPolicyInfo(\n",
    "    predicted_rewards_mean=predicted_rewards_mean,\n",
    "    bandit_policy_type=bandit_policy_type,\n",
    "    chosen_arm_features=chosen_arm_features_info,\n",
    ")\n",
    "info_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21f28b9b-8183-495a-89b6-a01f30ea8637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PerArmPolicyInfo(\n",
    "#     log_probability=(),\n",
    "#     predicted_rewards_mean=TensorSpec(shape=(2,),\n",
    "#                                       dtype=tf.float32, name=None),\n",
    "#     multiobjective_scalarized_predicted_rewards_mean=(),\n",
    "#     predicted_rewards_optimistic=(),\n",
    "#     predicted_rewards_sampled=(),\n",
    "#     bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)),\n",
    "#     chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9c197-ae9b-461d-8956-f078b929ac12",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [4] The Agent\n",
    "\n",
    "**Note** that contextual bandits form a special case of RL, where the actions taken by the agent do not alter the state of the environment \n",
    "\n",
    "> “Contextual” refers to the fact that the agent chooses among a set of actions while having knowledge of the context (environment observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81d6e84-688e-48c5-aea1-77df031348c9",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Agent & Network defined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aadb01-eb5c-4870-ae14-9e66624ba594",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Agent types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d075e8a6-11a9-4346-8725-3653fba4bac4",
   "metadata": {},
   "source": [
    "> `AGENT_TYPE = ['LinUCB', 'LinTS', 'epsGreedy', 'NeuralLinUCB']`\n",
    "\n",
    "1. **LinearUCBAgent**: (`LinUCB`) - An agent implementing the Linear UCB bandit algorithm ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/lin_ucb_agent/LinearUCBAgent))\n",
    "\n",
    "2. **LinearThompsonSamplingAgent**: (`LinTS`) - Implements the Linear Thompson Sampling Agent from the [paper](https://arxiv.org/abs/1209.3352): *Thompson Sampling for Contextual Bandits with Linear Payoffs* ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/linear_thompson_sampling_agent/LinearThompsonSamplingAgent))\n",
    "\n",
    "3. **NeuralEpsilonGreedyAgent**: (`epsGreedy`) - A neural network based epsilon greedy agent ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_epsilon_greedy_agent/NeuralEpsilonGreedyAgent))\n",
    "\n",
    "4. **NeuralLinUCBAgent**: (`NeuralLinUCB`) - An agent implementing the LinUCB algorithm on top of a neural network ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_linucb_agent/NeuralLinUCBAgent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b8e88e-c8ea-4193-a911-0d974ef3b1a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Network types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f547087d-5fad-4521-a584-cb46ce52897d",
   "metadata": {},
   "source": [
    "Which network architecture to use for the `epsGreedy` or `NeuralLinUCB` agents\n",
    "\n",
    "```\n",
    "NETWORK_TYPE = ['commontower', 'dotproduct']\n",
    "```\n",
    "\n",
    "**GlobalAndArmCommonTowerNetwork:** (`commontower`)\n",
    "* This network takes the output of the global and per-arm networks, and leads them through a common network, that in turn outputs reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "> * `COMMON_LAYERS` - Iterable of ints. Specifies the layers of the common tower\n",
    "* The network produced by this function can be used either in `GreedyRewardPredictionPolicy`, or `NeuralLinUCBPolicy`\n",
    "> * In the former case, the network must have `output_dim=1`, it is going to be an instance of `QNetwork`, and used in the policy as a reward prediction network\n",
    "> * In the latter case, the network will be an encoding network with its output consumed by a reward layer or a `LinUCB` method. The specified `output_dim` will be the encoding dimension\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmCommonTowerNetwork)\n",
    "\n",
    "**GlobalAndArmDotProductNetwork:** (`dotproduct`)\n",
    "* This network calculates the **dot product** of the output of the global and per-arm networks and returns them as reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmDotProductNetwork)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3dc270-deb5-4e96-8276-74759a06c318",
   "metadata": {},
   "source": [
    "### Agent config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bbe29263-453d-405e-ac50-fee7f379f335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\n",
      "\n",
      "time_step_spec:  TimeStep(\n",
      "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
      "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n",
      "\n",
      "action_spec:  BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))\n",
      "\n",
      "observation_spec:  {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\"\n",
    ")\n",
    "print(\"\\ntime_step_spec: \", time_step_spec)\n",
    "print(\"\\naction_spec: \", action_spec)\n",
    "print(\"\\nobservation_spec: \", observation_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d817bf2-1fa6-4bae-af90-745fad996b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'common_layers': [16, 8],\n",
      " 'encoding_dim': 1,\n",
      " 'epsilon': 0.01,\n",
      " 'eval_batch_size': 1,\n",
      " 'global_layers': [64, 32, 16],\n",
      " 'learning_rate': 0.05,\n",
      " 'model_type': 'epsGreedy',\n",
      " 'network_type': 'commontower',\n",
      " 'num_actions': 2,\n",
      " 'per_arm_layers': [64, 32, 16]}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Agents\n",
    "# ================================\n",
    "AGENT_TYPE = \"epsGreedy\"  # 'LinUCB' | 'LinTS |, 'epsGreedy' | 'NeuralLinUCB'\n",
    "\n",
    "# Parameters for linear agents (LinUCB and LinTS).\n",
    "AGENT_ALPHA = 0.1\n",
    "\n",
    "# Parameters for neural agents (NeuralEpsGreedy and NeuralLinUCB).\n",
    "EPSILON = 0.01\n",
    "LR = 0.05\n",
    "\n",
    "# Parameters for NeuralLinUCB\n",
    "ENCODING_DIM = 1\n",
    "EPS_PHASE_STEPS = 1000\n",
    "\n",
    "# ================================\n",
    "# Agent's Preprocess Network\n",
    "# ================================\n",
    "GLOBAL_LAYERS = [64, 32, 16]  # beginning should be of size: GLOBAL_DIM\n",
    "ARM_LAYERS = [64, 32, 16]  # beginning should be of size: PER_ARM_DIM\n",
    "COMMON_LAYERS = [16, 8]\n",
    "\n",
    "NETWORK_TYPE = \"commontower\"  # 'commontower' | 'dotproduct'\n",
    "\n",
    "if AGENT_TYPE == \"NeuralLinUCB\":\n",
    "    NETWORK_TYPE = \"commontower\"\n",
    "    ENCODING_DIM = COMMON_LAYERS[-1]\n",
    "\n",
    "\n",
    "HPARAMS = {  # TODO - streamline and consolidate\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"eval_batch_size\": EVAL_BATCH_SIZE,\n",
    "    \"num_actions\": NUM_ACTIONS,\n",
    "    \"model_type\": AGENT_TYPE,\n",
    "    \"network_type\": NETWORK_TYPE,\n",
    "    \"global_layers\": GLOBAL_LAYERS,\n",
    "    \"per_arm_layers\": ARM_LAYERS,\n",
    "    \"common_layers\": COMMON_LAYERS,\n",
    "    \"learning_rate\": LR,\n",
    "    \"epsilon\": EPSILON,\n",
    "    \"encoding_dim\": ENCODING_DIM,\n",
    "}\n",
    "pprint(HPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2bf060bb-9880-40b4-8583-dd7a3f915bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent: NeuralEpsGreedyAgent\n",
      "Network: commontower\n"
     ]
    }
   ],
   "source": [
    "from src.perarm_features import agent_factory as agent_factory\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "    agent_type=AGENT_TYPE,\n",
    "    network_type=NETWORK_TYPE,\n",
    "    time_step_spec=time_step_spec,\n",
    "    action_spec=action_spec,\n",
    "    observation_spec=observation_spec,\n",
    "    global_layers=GLOBAL_LAYERS,\n",
    "    arm_layers=ARM_LAYERS,\n",
    "    common_layers=COMMON_LAYERS,\n",
    "    agent_alpha=AGENT_ALPHA,\n",
    "    learning_rate=LR,\n",
    "    epsilon=EPSILON,\n",
    "    train_step_counter=global_step,\n",
    "    output_dim=ENCODING_DIM,\n",
    "    eps_phase_steps=EPS_PHASE_STEPS,\n",
    "    summarize_grads_and_vars=True,\n",
    "    debug_summaries=True,\n",
    ")\n",
    "\n",
    "agent.initialize()\n",
    "print(f\"agent: {agent.name}\")\n",
    "\n",
    "# if network:\n",
    "#     print(f\"Network: {network}\")\n",
    "\n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {NETWORK_TYPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d77d1-a0b3-4898-adf0-0b32bfaf5bd7",
   "metadata": {},
   "source": [
    "#### Inspect the specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78ca56e7-a386-4bf4-8c2b-3d1665521f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41483f5a-bda6-48a4-9e1c-88d8b4afeea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.time_step_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f205716-f265-4ca8-81a7-4799de8f60a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(Trajectory(\n",
       "{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32)),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None)}),\n",
       " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None)),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.training_data_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d404dae-3cc3-4f81-962b-4641455ca4f2",
   "metadata": {},
   "source": [
    "# [5] Reward function\n",
    "\n",
    "> see `reward_factory.py`\n",
    "\n",
    "* Since we are training a policy with previously collected interaction data, we model the reward function from actual rewards\n",
    "* We will simply pass the `user_rating` (values 0-5) as rewards to the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df9aecd6-d20a-48a7-9ead-4da3bbcfdae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _get_rewards(element):\n",
    "#     \"\"\"Calculates reward for the actions.\"\"\"\n",
    "\n",
    "#     def _calc_reward(x):\n",
    "#         \"\"\"Calculates reward for a single action.\"\"\"\n",
    "#         r0 = lambda: tf.constant(0.0)\n",
    "#         r1 = lambda: tf.constant(1.0)\n",
    "#         r2 = lambda: tf.constant(2.0)\n",
    "#         r3 = lambda: tf.constant(3.0)\n",
    "#         r4 = lambda: tf.constant(4.0)\n",
    "#         r5 = lambda: tf.constant(5.0)\n",
    "#         c1 = tf.equal(x, 1.0)\n",
    "#         c2 = tf.equal(x, 2.0)\n",
    "#         c3 = tf.equal(x, 3.0)\n",
    "#         c4 = tf.equal(x, 4.0)\n",
    "#         c5 = tf.equal(x, 5.0)\n",
    "#         return tf.case(\n",
    "#             [(c1, r1), (c2, r2), (c3, r3),(c4, r4),(c5, r5)],\n",
    "#             default=r0, exclusive=True\n",
    "#         )\n",
    "\n",
    "#     return tf.map_fn(\n",
    "#         fn=_calc_reward,\n",
    "#         elems=element['user_rating'],\n",
    "#         dtype=tf.float32\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac59703a-9a00-4eba-a3b7-45b21b738dd4",
   "metadata": {},
   "source": [
    "# [6] Trajectory function\n",
    "\n",
    "> This function will convert training samples from the TF Records to `trajectories` which the Agent interprets as training records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3c16aa7b-f328-425e-b02e-a3fc7f200859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.perarm_features import reward_factory as reward_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f3605d9f-d239-4871-9a61-6e9b21f9c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _trajectory_fn(element):  # hparams\n",
    "    \"\"\"Converts a dataset element into a trajectory.\"\"\"\n",
    "    # global_features = _get_global_context_features(element)\n",
    "    # arm_features = _get_per_arm_features(element)\n",
    "\n",
    "    global_features = embs._get_global_context_features(element)\n",
    "    arm_features = embs._get_per_arm_features(element)\n",
    "\n",
    "    # Adds a time dimension.\n",
    "    arm_features = train_utils._add_outer_dimension(arm_features)\n",
    "\n",
    "    # obs spec\n",
    "    observation = {\n",
    "        bandit_spec_utils.GLOBAL_FEATURE_KEY: train_utils._add_outer_dimension(\n",
    "            global_features\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    # reward = train_utils._add_outer_dimension(_get_rewards(element))\n",
    "    reward = train_utils._add_outer_dimension(reward_factory._get_rewards(element))\n",
    "\n",
    "    # To emit the predicted rewards in policy_info, we need to create dummy\n",
    "    # rewards to match the definition in TensorSpec for the ones specified in\n",
    "    # emit_policy_info set.\n",
    "    dummy_rewards = tf.zeros([HPARAMS[\"batch_size\"], 1, HPARAMS[\"num_actions\"]])\n",
    "    policy_info = policy_utilities.PerArmPolicyInfo(\n",
    "        chosen_arm_features=arm_features,\n",
    "        # Pass dummy mean rewards here to match the model_spec for emitting\n",
    "        # mean rewards in policy info\n",
    "        predicted_rewards_mean=dummy_rewards,\n",
    "        bandit_policy_type=tf.zeros([HPARAMS[\"batch_size\"], 1, 1], dtype=tf.int32),\n",
    "        # policy_utilities.create_bandit_policy_type_tensor_spec(shape=[1]) # policy_utilities.BanditPolicyType.GREEDY\n",
    "        # tf.zeros([batch_size, 1, 1], dtype=tf.int32)\n",
    "    )\n",
    "\n",
    "    if HPARAMS[\"model_type\"] == \"neural_ucb\":\n",
    "        policy_info = policy_info._replace(predicted_rewards_optimistic=dummy_rewards)\n",
    "\n",
    "    return trajectory.single_step(\n",
    "        observation=observation,\n",
    "        action=tf.zeros_like(\n",
    "            reward, dtype=tf.int32\n",
    "        ),  # Arm features are copied from policy info, put dummy zeros here\n",
    "        policy_info=policy_info,\n",
    "        reward=reward,\n",
    "        discount=tf.zeros_like(reward),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a0989c-5a06-4fd5-a12d-d92dbbe71a76",
   "metadata": {},
   "source": [
    "Inspect the trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "257791d1-c97c-48c0-bc92-f5a4737b6c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in train_dataset.batch(HPARAMS[\"batch_size\"]).take(1):\n",
    "    test_traj = _trajectory_fn(x)\n",
    "\n",
    "# test_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3dace3d1-ce61-48cf-82a4-f701d3fe337c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_traj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d8994e-ce28-4fd9-8e3b-153451d014d9",
   "metadata": {},
   "source": [
    "#### Inspect shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8a0e451f-1ad8-4af2-84d6-ddc5eaac0e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.action.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.action.shape: {test_traj.action.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "52ed1767-12ce-404c-9caf-0974d55ec5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.discount.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.discount.shape: {test_traj.discount.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "033ff16b-0158-477f-835f-99deec636b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.reward.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.reward.shape: {test_traj.reward.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ee5aded7-7f9c-4a88-868c-f6ab58a0e704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.observation.shape: (128, 1, 64)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.observation.shape: {test_traj.observation['global'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcbfc9a-049e-49b9-b2a3-ecb9fd4b9964",
   "metadata": {},
   "source": [
    "# [7] Training the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13adc1ef-b50e-41a3-9b95-c128d0c55a2b",
   "metadata": {},
   "source": [
    "## set Vertex Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e861fb27-df24-4821-8448-cf1346b186f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : 02b-deep-bandits-rec-bandits-v2\n",
      "RUN_NAME          : run-20240311-231807\n",
      "\n",
      "CHECKPT_DIR       : gs://rec-bandits-v2-cpg-cdp-bucket/02b-deep-bandits-rec-bandits-v2/chkpoint\n",
      "BASE_OUTPUT_DIR   : gs://rec-bandits-v2-cpg-cdp-bucket/02b-deep-bandits-rec-bandits-v2/run-20240311-231807\n",
      "LOG_DIR           : gs://rec-bandits-v2-cpg-cdp-bucket/02b-deep-bandits-rec-bandits-v2/run-20240311-231807/logs\n",
      "ROOT_DIR          : gs://rec-bandits-v2-cpg-cdp-bucket/02b-deep-bandits-rec-bandits-v2/run-20240311-231807/root\n",
      "ARTIFACTS_DIR     : gs://rec-bandits-v2-cpg-cdp-bucket/02b-deep-bandits-rec-bandits-v2/run-20240311-231807/artifacts\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME = f\"02b-deep-bandits-{PREFIX}\"\n",
    "\n",
    "# new experiment\n",
    "invoke_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME = f\"run-{invoke_time}\"\n",
    "\n",
    "CHECKPT_DIR = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/chkpoint\"\n",
    "BASE_OUTPUT_DIR = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}\"\n",
    "LOG_DIR = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR = (\n",
    "    f\"{BASE_OUTPUT_DIR}/root\"  # Root directory for writing logs/summaries/checkpoints.\n",
    ")\n",
    "ARTIFACTS_DIR = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "# vertex_ai.init(\n",
    "#     project=PROJECT_ID,\n",
    "#     location=REGION,\n",
    "#     experiment=EXPERIMENT_NAME\n",
    "# )\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"CHECKPT_DIR       : {CHECKPT_DIR}\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de729bad-0bc9-429e-b4cb-7b24bf615aa1",
   "metadata": {},
   "source": [
    "### Create TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d2570564-71f4-4dda-8d8a-59784db67632",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_TENSORBOARD = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db63052a-7eea-4982-964d-1f7ecab0665d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TB_RESOURCE_NAME: projects/939655404703/locations/us-central1/tensorboards/7239646352160849920\n",
      "TB display name: 02b-deep-bandits-rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "if NEW_TENSORBOARD:\n",
    "    # create new TB instance\n",
    "    TENSORBOARD_DISPLAY_NAME = f\"{EXPERIMENT_NAME}\"\n",
    "\n",
    "    tensorboard = aiplatform.Tensorboard.create(\n",
    "        display_name=TENSORBOARD_DISPLAY_NAME, project=PROJECT_ID, location=REGION\n",
    "    )\n",
    "\n",
    "    TB_RESOURCE_NAME = tensorboard.resource_name\n",
    "else:\n",
    "    # use existing TB instance\n",
    "    TB_RESOURCE_NAME = \"projects/939655404703/locations/us-central1/tensorboards/7239646352160849920\"  # TODO\n",
    "    tensorboard = aiplatform.Tensorboard(tensorboard_name=TB_RESOURCE_NAME)\n",
    "\n",
    "print(f\"TB_RESOURCE_NAME: {TB_RESOURCE_NAME}\")\n",
    "print(f\"TB display name: {tensorboard.display_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0a0b708d-990e-468b-a1b1-a8ba8f71d726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Delete Tensorboard\n",
    "# vertex_ai_tb.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9c891d27-d9d1-4e64-8981-1a1ae343c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aiplatform.init(\n",
    "#     project=PROJECT_ID,\n",
    "#     location=REGION,\n",
    "#     experiment=EXPERIMENT_NAME,\n",
    "#     experiment_tensorboard=TB_ID\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b7a5e4-efff-490b-b431-53037a2f4a16",
   "metadata": {},
   "source": [
    "## eval loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba0392e-90c8-4dc8-8df2-6d2af1ade490",
   "metadata": {},
   "source": [
    "> When evaluating an epsilon-greedy bandit, we need to remove those predictions that come from the `uniform_random` policy. We only want the predictions from the `GREEDY` policy, becasue we want to know how the model performs when it is actually used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b3d3c-75f7-46f4-9a1b-6329e419b7f5",
   "metadata": {},
   "source": [
    "## train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "97cfe7c3-4022-47a9-83c2-df0ad8a2abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.metrics import export_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.utils import common\n",
    "\n",
    "# from src.per_arm_rl import train_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bb7ffc-00df-4d46-857b-86c87b78f597",
   "metadata": {},
   "source": [
    "`agent.train(experience=...)`\n",
    "\n",
    "where `experience` is a batch of trajectories data in the form of a Trajectory. \n",
    "* The structure of experience must match that of `self.training_data_spec`. \n",
    "* All tensors in experience must be shaped [batch, time, ...] where time must be equal to self.train_step_length if that property is not None."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94d6d45-c71e-4fe4-9af8-af9a8bda4e4f",
   "metadata": {},
   "source": [
    "### logs & checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "049ee49b-3b1a-4b12-a360-15e759dff7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('metrics: [<tf_agents.metrics.tf_metrics.AverageReturnMetric object at '\n",
      " '0x7fdfb33ff6d0>]')\n",
      "setting checkpoint_manager: gs://rec-bandits-v2-cpg-cdp-bucket/02b-deep-bandits-rec-bandits-v2/chkpoint\n",
      "\n",
      "'saver: <tf_agents.policies.policy_saver.PolicySaver object at 0x7fdfb291fbb0>'\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    f\"{LOG_DIR}\", flush_millis=10 * 1000\n",
    ")\n",
    "# train_summary_writer.set_as_default()\n",
    "\n",
    "# eval_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "#     f\"{LOG_DIR}/eval\", flush_millis=10 * 1000\n",
    "# )\n",
    "# ====================================================\n",
    "# metrics\n",
    "# ====================================================\n",
    "step_metric = tf_metrics.EnvironmentSteps()\n",
    "metrics = [\n",
    "    # tf_metrics.NumberOfEpisodes(),\n",
    "    # tf_metrics.AverageEpisodeLengthMetric(batch_size=HPARAMS['batch_size']),\n",
    "    tf_metrics.AverageReturnMetric(batch_size=HPARAMS[\"batch_size\"])\n",
    "]\n",
    "\n",
    "pprint(f\"metrics: {metrics}\")\n",
    "\n",
    "# ====================================================\n",
    "# get checkpoint manager\n",
    "# ====================================================\n",
    "print(f\"setting checkpoint_manager: {CHECKPT_DIR}\\n\")\n",
    "\n",
    "checkpoint_manager = train_utils.restore_and_get_checkpoint_manager(\n",
    "    root_dir=CHECKPT_DIR, agent=agent, metrics=metrics, step_metric=step_metric\n",
    ")\n",
    "# ====================================================\n",
    "# policy saver\n",
    "# ====================================================\n",
    "saver = policy_saver.PolicySaver(agent.policy, train_step=global_step)\n",
    "pprint(f\"saver: {saver}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d155f1f4-0d95-40a8-a37c-c608a64af803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x7fdfb2218ca0>,\n",
       " 'get_initial_state': <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x7fdfb221bd90>,\n",
       " 'get_train_step': <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x7fdfb2951c30>,\n",
       " 'get_metadata': <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x7fdfb2951b70>}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83683f4b-8a1a-44b9-8d5f-7ee3304c794c",
   "metadata": {},
   "source": [
    "### config\n",
    "\n",
    "* calculate train & val dataset sizes\n",
    "* define logging and chkpt intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f9432613-6583-4828-8a2a-dd939adbc3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_DATA_SIZE : 80000\n",
      "NUM_TRAIN_STEPS : 50\n",
      "EVAL_DATA_SIZE : 1000\n",
      "NUM_EVAL_STEPS : 1000\n",
      "CHKPT_INTERVAL: 50\n",
      "LOG_INTERVAL : 10\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA_SIZE = 80000  # len(list(train_dataset))\n",
    "NUM_TRAIN_STEPS = 50  # TRAIN_DATA_SIZE // HPARAMS['batch_size']\n",
    "\n",
    "EVAL_DATA_SIZE = 1000  # len(list(val_dataset))\n",
    "NUM_EVAL_STEPS = 1000  # EVAL_DATA_SIZE // HPARAMS['eval_batch_size']\n",
    "\n",
    "CHKPT_INTERVAL = NUM_TRAIN_STEPS  # // 5\n",
    "LOG_INTERVAL = 10\n",
    "# EVAL_INTERVAL = NUM_TRAIN_STEPS // 2\n",
    "\n",
    "print(f\"TRAIN_DATA_SIZE : {TRAIN_DATA_SIZE}\")\n",
    "print(f\"NUM_TRAIN_STEPS : {NUM_TRAIN_STEPS}\")\n",
    "print(f\"EVAL_DATA_SIZE : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS : {NUM_EVAL_STEPS}\")\n",
    "print(f\"CHKPT_INTERVAL: {CHKPT_INTERVAL}\")\n",
    "print(f\"LOG_INTERVAL : {LOG_INTERVAL}\")\n",
    "# print(f\"EVAL_INTERVAL : {EVAL_INTERVAL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "379ffc65-4eec-4af1-8fd4-912ef65a9808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec={'bucketized_user_age': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'movie_genres': TensorSpec(shape=(None, 1), dtype=tf.int64, name=None), 'movie_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'timestamp': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'user_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_occupation_text': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_rating': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data\n",
    "train_ds_iterator = iter(train_dataset.batch(HPARAMS[\"batch_size\"]).repeat())\n",
    "\n",
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS[\"eval_batch_size\"])\n",
    "\n",
    "if NUM_EVAL_STEPS > 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)\n",
    "\n",
    "# eval_ds = eval_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "eval_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e498d7e3-d166-4e1d-94a5-f721de58694a",
   "metadata": {},
   "source": [
    "### run train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5dd64d98-7d5b-4474-a567-b42426d630a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.perarm_features import eval_perarm as eval_perarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "da4680f3-693b-4530-8e4d-88bc43036c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating pre-trained Agent...\n",
      "pre-train val_loss     : 15.492388725280762\n",
      "pre-train eval runtime : 0\n",
      "starting train loop...\n",
      "step = 0: train loss = 15.640000343322754\n",
      "step = 10: train loss = 13.640000343322754\n",
      "step = 20: train loss = 4.940000057220459\n",
      "step = 30: train loss = 1.7100000381469727\n",
      "step = 40: train loss = 1.9199999570846558\n",
      "train runtime_mins: 5\n",
      "saved trained policy to: gs://rec-bandits-v2-cpg-cdp-bucket/02b-deep-bandits-rec-bandits-v2/run-20240311-231807/artifacts\n",
      "evaluating trained Agent...\n",
      "post-train val_loss     : 1.4128273725509644\n",
      "post-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "# agent.train = common.function(agent.train)\n",
    "\n",
    "list_o_loss = []\n",
    "\n",
    "# ====================================================\n",
    "# Evaluate the agent's policy once before training\n",
    "# ====================================================\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "pre_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "\n",
    "print(f\"evaluating pre-trained Agent...\")\n",
    "start_time = time.time()\n",
    "\n",
    "pre_val_loss, pre_preds, pre_tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy=pre_policy_tf,\n",
    "    data=eval_ds,\n",
    "    eval_batch_size=HPARAMS[\"eval_batch_size\"],\n",
    "    per_arm_dim=PER_ARM_DIM,\n",
    "    global_dim=GLOBAL_DIM,\n",
    "    vocab_dict=vocab_dict,\n",
    "    num_oov_buckets=NUM_OOV_BUCKETS,\n",
    "    global_emb_size=GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size=MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"pre-train val_loss     : {pre_val_loss}\")\n",
    "print(f\"pre-train eval runtime : {runtime_mins}\")\n",
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "print(f\"starting train loop...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# for i in tqdm(range(NUM_TRAIN_STEPS)):\n",
    "for i in range(NUM_TRAIN_STEPS):\n",
    "\n",
    "    with train_summary_writer.as_default():\n",
    "\n",
    "        data = next(train_ds_iterator)\n",
    "        trajectories = _trajectory_fn(data)\n",
    "\n",
    "        # All tensors in experience must be shaped [batch, time, ...]\n",
    "        step = agent.train_step_counter.numpy()\n",
    "        loss = agent.train(experience=trajectories)\n",
    "        list_o_loss.append(loss.loss.numpy())\n",
    "\n",
    "        train_utils._export_metrics_and_summaries(step=i, metrics=metrics)\n",
    "\n",
    "        # print step loss\n",
    "        if step % LOG_INTERVAL == 0:\n",
    "            print(\n",
    "                \"step = {0}: train loss = {1}\".format(step, round(loss.loss.numpy(), 2))\n",
    "            )\n",
    "\n",
    "        if i > 0 and i % CHKPT_INTERVAL == 0:\n",
    "            saver.save(os.path.join(CHKPOINT_DIR, \"policy_%d\" % step_metric.result()))\n",
    "            print(f\"saved policy to: {CHKPOINT_DIR}\")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"train runtime_mins: {runtime_mins}\")\n",
    "\n",
    "saver.save(ARTIFACTS_DIR)\n",
    "print(f\"saved trained policy to: {ARTIFACTS_DIR}\")\n",
    "\n",
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy=post_policy_tf,\n",
    "    data=eval_ds,\n",
    "    eval_batch_size=HPARAMS[\"eval_batch_size\"],\n",
    "    per_arm_dim=PER_ARM_DIM,\n",
    "    global_dim=GLOBAL_DIM,\n",
    "    vocab_dict=vocab_dict,\n",
    "    num_oov_buckets=NUM_OOV_BUCKETS,\n",
    "    global_emb_size=GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size=MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "17b2b0d2-9795-4367-b57b-c331e94d1000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4128274"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb1ed8-f67b-4e7b-9cbc-70edd50e49ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate train job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff31fe28-2f05-499f-b1cc-505f3c9074e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### train loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "41937f9a-6c28-48d2-bc7c-bfe4372c7cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_o_loss)\n",
    "# plt.ylim([0, 10])\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e947e1-67f4-4205-99af-6921c6e9c896",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "65627011-48eb-4e8e-981e-8b61b0f427c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No known TensorBoard instances running.\n"
     ]
    }
   ],
   "source": [
    "from tensorboard import notebook\n",
    "\n",
    "notebook.list()  # View open TensorBoard instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e0f77a33-0962-4af0-af97-cf05f895cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5d0509cb-0777-4d35-86c6-28c8acbcc793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-fa14766e1d8223fe\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-fa14766e1d8223fe\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=$LOG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc40143-30b1-479f-b9b1-fa4c07b1690e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [8] Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6c94a0-122f-4ba6-acef-5653a3cc7850",
   "metadata": {
    "tags": []
   },
   "source": [
    "## load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b1c382b5-e2e0-45a2-9c5f-ef2c468d0f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02b-deep-bandits-rec-bandits-v2/run-20240220-012721/artifacts\n"
     ]
    }
   ],
   "source": [
    "POLICY_URI = ARTIFACTS_DIR\n",
    "\n",
    "print(POLICY_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "68592d97-1272-4c6d-a4bd-43a6f7fe6c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f53fa5c8b50>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910a06f-678f-4bfa-a132-10b885f871c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## get predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1762c936-3c49-4ec5-a9eb-4df5816dc888",
   "metadata": {},
   "source": [
    "TODO - explain bandit_policy_type()\n",
    "\n",
    "**Dummy arm values?**\n",
    "* We set `chosen_arm_features` to dummy values of all zeros. We need to save dummy chosen arm features to make the returned policy step have the same structure as the policy state spec.\n",
    "* `emit_policy_info = ('predicted_rewards_mean', 'bandit_policy_type')` defines what side information we want to get as part of the policy info when we call policy network \n",
    "* This makes it so that the model always returns the expected rewards even if the model is exploring\n",
    "* This means that the largest predicted rewards may not match the selected action when the model is exploring (i.e. bandit_policy == UNIFORM == 2)\n",
    "\n",
    "**UNIFORM Random policy:**\n",
    "```\n",
    "PolicyStep(action=array(1, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.637535 , 3.5557823], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([2], dtype=int32), chosen_arm_features=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)))\n",
    "```\n",
    "\n",
    "**GREEDY policy:**\n",
    "```\n",
    "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.8278818, 3.607565 ], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([ 0.04054676, -0.04735027,  0.02202327,  0.01276748, -0.01367382,\n",
    "       -0.04838754,  0.00104916, -0.01956806,  0.01028793, -0.00256665,\n",
    "       -0.04376553,  0.03900594,  0.02388967, -0.04016995, -0.04945569,\n",
    "       -0.04539652,  0.04423274, -0.04630332,  0.00390794,  0.03986299,\n",
    "       -0.0398974 ,  0.01655747, -0.0471294 , -0.00690235, -0.03643382,\n",
    "       -0.0437116 ,  0.04757959, -0.00991895,  0.0281055 , -0.04633433,\n",
    "        0.01897702, -0.00824345,  0.03232259, -0.04980658, -0.01144745,\n",
    "        0.01690939,  0.02536928,  0.03384003, -0.01558131,  0.04731432,\n",
    "        0.04579857, -0.03305101,  0.03521084, -0.03915765,  0.04927064,\n",
    "        0.04695194,  0.03792156,  0.040496  ,  0.02574866, -0.00665367,\n",
    "       -0.03839222, -0.01564004, -0.04710373,  0.03557512, -0.01392462,\n",
    "        0.01368621,  0.02792176, -0.01799218,  0.00246101,  0.02263175,\n",
    "        0.0170817 ,  0.01388383, -0.03048695,  0.01198485], dtype=float32)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "567f64e1-8149-4364-b561-1a9d12581b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aff30396-e0fd-4f43-acaa-6af8b20b12cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "SKIP_NUM = 10\n",
    "\n",
    "for x in eval_ds.skip(SKIP_NUM).take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "\n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "\n",
    "    # rewards = _get_rewards(x)\n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "\n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(\n",
    "        arm_feat_infer, [HPARAMS[\"eval_batch_size\"], PER_ARM_DIM]\n",
    "    )  # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "\n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {\"global\": flat_global_infer, \"per_arm\": concat_arm}\n",
    "\n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "\n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "\n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2bcd1e82-168e-4df3-92bd-4cd34ecd3a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': <tf.Tensor: shape=(), dtype=float32, numpy=1.0>,\n",
       " 'observation': {'global': <tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
       "array([ 0.02779352,  0.04742886,  0.02355615,  0.01677612, -0.04737238,\n",
       "       -0.01901716,  0.01761233, -0.04155995,  0.03945054, -0.00218635,\n",
       "       -0.02747568, -0.03064599, -0.02419233,  0.01354703,  0.00276662,\n",
       "       -0.03088561, -0.02358708, -0.01925997,  0.01668281,  0.01619628,\n",
       "       -0.03024041,  0.04508832,  0.01180847,  0.04964615,  0.02468178,\n",
       "       -0.03344651,  0.02837029, -0.01992999,  0.03734589,  0.02021093,\n",
       "        0.01450065,  0.01127721,  0.02448865, -0.03829848, -0.03498596,\n",
       "       -0.02861302,  0.02576459,  0.019645  ,  0.03341906, -0.00870086,\n",
       "        0.02031736,  0.0112232 , -0.02101684,  0.01593829,  0.02075512,\n",
       "        0.03842558,  0.04591126, -0.03623281,  0.02338555, -0.04320271,\n",
       "       -0.03769498, -0.04932744,  0.04543027, -0.00710926,  0.00208537,\n",
       "        0.03181982, -0.03045282, -0.03339195, -0.03440003, -0.03224003,\n",
       "        0.03335618, -0.01782926, -0.04904183, -0.02929014], dtype=float32)>,\n",
       "                 'per_arm': <tf.Tensor: shape=(2, 64), dtype=float32, numpy=\n",
       "array([[ 0.04825566, -0.01752017,  0.0415484 , -0.00862701,  0.01044101,\n",
       "         0.00721148, -0.04244436,  0.0120028 ,  0.04307819, -0.04506242,\n",
       "         0.00343912,  0.0079091 ,  0.02118767,  0.00576416,  0.02339428,\n",
       "         0.04405012,  0.01102309, -0.02903042,  0.02531854,  0.04417062,\n",
       "        -0.01080258,  0.03845933, -0.04908425,  0.04161254,  0.02816439,\n",
       "        -0.0022865 , -0.02073095, -0.01652641, -0.00517582, -0.00159618,\n",
       "        -0.04262435, -0.02481074,  0.04362972,  0.0183673 ,  0.01171549,\n",
       "        -0.04627906,  0.00020222, -0.01763391, -0.03658683, -0.00747542,\n",
       "        -0.03353508, -0.01317211,  0.04145939,  0.03506762,  0.0419515 ,\n",
       "         0.00965525, -0.01907877,  0.01188902,  0.03725764,  0.04915946,\n",
       "        -0.02946698, -0.03984656,  0.00479597,  0.0061129 , -0.01093596,\n",
       "        -0.03224005,  0.00316464, -0.04704098, -0.0349537 ,  0.03063358,\n",
       "        -0.02561888,  0.03843598, -0.04401905,  0.02946681],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ]],\n",
       "      dtype=float32)>},\n",
       " 'reward': <tf.Tensor: shape=(), dtype=float32, numpy=3.0>,\n",
       " 'step_type': <tf.Tensor: shape=(), dtype=int32, numpy=0>})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectory_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e58af9ab-f4da-4857-afe5-6b8de26ed0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([1.2951745, 1.2951745], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([ 0.04825566, -0.01752017,  0.0415484 , -0.00862701,  0.01044101,\n",
       "        0.00721148, -0.04244436,  0.0120028 ,  0.04307819, -0.04506242,\n",
       "        0.00343912,  0.0079091 ,  0.02118767,  0.00576416,  0.02339428,\n",
       "        0.04405012,  0.01102309, -0.02903042,  0.02531854,  0.04417062,\n",
       "       -0.01080258,  0.03845933, -0.04908425,  0.04161254,  0.02816439,\n",
       "       -0.0022865 , -0.02073095, -0.01652641, -0.00517582, -0.00159618,\n",
       "       -0.04262435, -0.02481074,  0.04362972,  0.0183673 ,  0.01171549,\n",
       "       -0.04627906,  0.00020222, -0.01763391, -0.03658683, -0.00747542,\n",
       "       -0.03353508, -0.01317211,  0.04145939,  0.03506762,  0.0419515 ,\n",
       "        0.00965525, -0.01907877,  0.01188902,  0.03725764,  0.04915946,\n",
       "       -0.02946698, -0.03984656,  0.00479597,  0.0061129 , -0.01093596,\n",
       "       -0.03224005,  0.00316464, -0.04704098, -0.0349537 ,  0.03063358,\n",
       "       -0.02561888,  0.03843598, -0.04401905,  0.02946681], dtype=float32)))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6676778c-d191-4b1e-a180-61f068b3b8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([1.2951745, 1.2951745], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([ 0.04825566, -0.01752017,  0.0415484 , -0.00862701,  0.01044101,\n",
      "        0.00721148, -0.04244436,  0.0120028 ,  0.04307819, -0.04506242,\n",
      "        0.00343912,  0.0079091 ,  0.02118767,  0.00576416,  0.02339428,\n",
      "        0.04405012,  0.01102309, -0.02903042,  0.02531854,  0.04417062,\n",
      "       -0.01080258,  0.03845933, -0.04908425,  0.04161254,  0.02816439,\n",
      "       -0.0022865 , -0.02073095, -0.01652641, -0.00517582, -0.00159618,\n",
      "       -0.04262435, -0.02481074,  0.04362972,  0.0183673 ,  0.01171549,\n",
      "       -0.04627906,  0.00020222, -0.01763391, -0.03658683, -0.00747542,\n",
      "       -0.03353508, -0.01317211,  0.04145939,  0.03506762,  0.0419515 ,\n",
      "        0.00965525, -0.01907877,  0.01188902,  0.03725764,  0.04915946,\n",
      "       -0.02946698, -0.03984656,  0.00479597,  0.0061129 , -0.01093596,\n",
      "       -0.03224005,  0.00316464, -0.04704098, -0.0349537 ,  0.03063358,\n",
      "       -0.02561888,  0.03843598, -0.04401905,  0.02946681], dtype=float32)))\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c85a0087-7388-4f03-9278-aace31121233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0, dtype=int32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a8266c7c-3688-46a5-a1c8-a63bb7146128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info.bandit_policy_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9712bc00-7ea0-4003-a3c7-81a0be5bc995",
   "metadata": {},
   "source": [
    "# [9] Prepare training application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f62966-123f-410e-9610-832f20566635",
   "metadata": {},
   "source": [
    "To scale this training in Vertex AI's managed training service, we need to package all our code into a python application\n",
    "\n",
    "* This means, we need to modularize all steps executed up until this point. For example, the training loop we ran above is further parameterized in `train_perarm.py`, which will be called from our `task.py` when we submit the job to Vertex AI\n",
    "* This training package will eventually be used to create a custom training image (more on that in `04b-build-training-image` notebook)\n",
    "* For additional details on preparing the training application for Vertex AI, check out [the documentation](https://cloud.google.com/vertex-ai/docs/training/code-requirements) and [this code example](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage2/get_started_vertex_training.ipynb) (which also has good, related commentary)\n",
    "\n",
    "**The remaining cells will repeat steps executed above**\n",
    "> we are just illustrating / validating that they are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6c3d30-bef4-4ec5-a978-116856a70e7e",
   "metadata": {},
   "source": [
    "### Distribution strategy\n",
    "\n",
    "Use `strategy_utils` to generate a strategy. Under the hood, passing the parameter:\n",
    "\n",
    "* `use_gpu = False` returns `tf.distribute.get_strategy()`, which uses CPU\n",
    "* `use_gpu = True` returns `tf.distribute.MirroredStrategy()`, which uses all GPUs that are visible to TensorFlow on one machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "68140c4d-12ff-4758-89ca-44fd710ca0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.distribute.mirrored_strategy.MirroredStrategy at 0x7f53b83038e0>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.train.utils import strategy_utils\n",
    "\n",
    "use_gpu = True\n",
    "use_tpu = False\n",
    "\n",
    "distribution_strategy = strategy_utils.get_strategy(tpu=use_tpu, use_gpu=use_gpu)\n",
    "distribution_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e80724b1-6525-4986-b832-4af8b49d923c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_REPLICAS = distribution_strategy.num_replicas_in_sync\n",
    "NUM_REPLICAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1129ee41-b43c-4d5a-b656-cdac6b79688c",
   "metadata": {},
   "source": [
    "### Vertex Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ef509680-4d19-4efa-9f01-21039e0d573b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : 02b-deep-bandits-rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "# using same experiment name\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7ad98430-d836-40f1-8e4f-eb46f0c91fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : 02b-deep-bandits-rec-bandits-v2\n",
      "RUN_NAME          : run-20240220-015218\n",
      "\n",
      "CHECKPT_DIR       : gs://rec-bandits-v2-hybrid-vertex-bucket/02b-deep-bandits-rec-bandits-v2/chkpoint\n",
      "BASE_OUTPUT_DIR   : gs://rec-bandits-v2-hybrid-vertex-bucket/02b-deep-bandits-rec-bandits-v2/run-20240220-015218\n",
      "LOG_DIR           : gs://rec-bandits-v2-hybrid-vertex-bucket/02b-deep-bandits-rec-bandits-v2/run-20240220-015218/logs\n",
      "ROOT_DIR          : gs://rec-bandits-v2-hybrid-vertex-bucket/02b-deep-bandits-rec-bandits-v2/run-20240220-015218/root\n",
      "ARTIFACTS_DIR     : gs://rec-bandits-v2-hybrid-vertex-bucket/02b-deep-bandits-rec-bandits-v2/run-20240220-015218/artifacts\n"
     ]
    }
   ],
   "source": [
    "# new experiment\n",
    "invoke_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME = f\"run-{invoke_time}\"\n",
    "\n",
    "CHECKPT_DIR = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/chkpoint\"\n",
    "BASE_OUTPUT_DIR = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}\"\n",
    "LOG_DIR = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR = (\n",
    "    f\"{BASE_OUTPUT_DIR}/root\"  # Root directory for writing logs/summaries/checkpoints.\n",
    ")\n",
    "ARTIFACTS_DIR = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "# aiplatform.init(\n",
    "#     project=PROJECT_ID,\n",
    "#     location=REGION,\n",
    "#     experiment=EXPERIMENT_NAME\n",
    "# )\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"CHECKPT_DIR       : {CHECKPT_DIR}\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83de7c4-f7c7-4290-b44a-9e9194bac882",
   "metadata": {},
   "source": [
    "### Create TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "17576ce0-727d-4297-a52d-f64fb75ca78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TB_RESOURCE_NAME : projects/934903580331/locations/us-central1/tensorboards/4592726039918018560\n",
      "TB display name  : 02b-deep-bandits-rec-bandits-v2-run-20240220-015218\n",
      "TB_ID            : 4592726039918018560\n"
     ]
    }
   ],
   "source": [
    "# # create new TB instance\n",
    "TENSORBOARD_DISPLAY_NAME = f\"{EXPERIMENT_NAME}-{RUN_NAME}\"\n",
    "\n",
    "tensorboard = aiplatform.Tensorboard.create(\n",
    "    display_name=TENSORBOARD_DISPLAY_NAME, project=PROJECT_ID, location=REGION\n",
    ")\n",
    "\n",
    "TB_RESOURCE_NAME = tensorboard.resource_name\n",
    "\n",
    "TB_ID = TB_RESOURCE_NAME.split(\"/\")[-1]\n",
    "\n",
    "print(f\"TB_RESOURCE_NAME : {TB_RESOURCE_NAME}\")\n",
    "print(f\"TB display name  : {tensorboard.display_name}\")\n",
    "print(f\"TB_ID            : {TB_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "71d43cf9-db3f-437e-98ee-3791ac0c5e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME,\n",
    "    experiment_tensorboard=TB_ID,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c2e082-c0f6-4792-a279-e827c48b5895",
   "metadata": {},
   "source": [
    "### trajectory function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "55e21068-a7a5-44c8-a16f-d8c41d976c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HPARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b9ce410e-ac03-48b2-8006-4591b38297a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with distribution_strategy.scope():\n",
    "\n",
    "    embs = emb_features.EmbeddingModel(\n",
    "        vocab_dict=vocab_dict,\n",
    "        num_oov_buckets=NUM_OOV_BUCKETS,\n",
    "        global_emb_size=GLOBAL_EMBEDDING_SIZE,\n",
    "        mv_emb_size=MV_EMBEDDING_SIZE,\n",
    "    )\n",
    "\n",
    "    def _trajectory_fn(element):  # hparams\n",
    "        \"\"\"Converts a dataset element into a trajectory.\"\"\"\n",
    "        # global_features = _get_global_context_features(element)\n",
    "        # arm_features = _get_per_arm_features(element)\n",
    "\n",
    "        global_features = embs._get_global_context_features(element)\n",
    "        arm_features = embs._get_per_arm_features(element)\n",
    "\n",
    "        # Adds a time dimension.\n",
    "        arm_features = train_utils._add_outer_dimension(arm_features)\n",
    "\n",
    "        # obs spec\n",
    "        observation = {\n",
    "            bandit_spec_utils.GLOBAL_FEATURE_KEY: train_utils._add_outer_dimension(\n",
    "                global_features\n",
    "            ),\n",
    "        }\n",
    "\n",
    "        reward = train_utils._add_outer_dimension(reward_factory._get_rewards(element))\n",
    "\n",
    "        # To emit the predicted rewards in policy_info, we need to create dummy\n",
    "        # rewards to match the definition in TensorSpec for the ones specified in\n",
    "        # emit_policy_info set.\n",
    "        dummy_rewards = tf.zeros([HPARAMS[\"batch_size\"], 1, HPARAMS[\"num_actions\"]])\n",
    "        policy_info = policy_utilities.PerArmPolicyInfo(\n",
    "            chosen_arm_features=arm_features,\n",
    "            # Pass dummy mean rewards here to match the model_spec for emitting\n",
    "            # mean rewards in policy info\n",
    "            predicted_rewards_mean=dummy_rewards,\n",
    "            bandit_policy_type=tf.zeros([HPARAMS[\"batch_size\"], 1, 1], dtype=tf.int32),\n",
    "            # policy_utilities.create_bandit_policy_type_tensor_spec(shape=[1])\n",
    "            # policy_utilities.BanditPolicyType.GREEDY\n",
    "            # tf.zeros([batch_size, 1, 1], dtype=tf.int32)\n",
    "        )\n",
    "\n",
    "        if HPARAMS[\"model_type\"] == \"neural_ucb\":\n",
    "            policy_info = policy_info._replace(\n",
    "                predicted_rewards_optimistic=dummy_rewards\n",
    "            )\n",
    "\n",
    "        return trajectory.single_step(\n",
    "            observation=observation,\n",
    "            action=tf.zeros_like(\n",
    "                reward, dtype=tf.int32\n",
    "            ),  # Arm features are copied from policy info, put dummy zeros here\n",
    "            policy_info=policy_info,\n",
    "            reward=reward,\n",
    "            discount=tf.zeros_like(reward),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b759404-b282-4f55-add8-7d795867c99e",
   "metadata": {},
   "source": [
    "### get agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3be40320-a73f-45f7-9fc4-0bd64df0ae5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 128,\n",
       " 'eval_batch_size': 1,\n",
       " 'num_actions': 2,\n",
       " 'model_type': 'epsGreedy',\n",
       " 'network_type': 'commontower',\n",
       " 'global_layers': [64, 32, 16],\n",
       " 'per_arm_layers': [64, 32, 16],\n",
       " 'common_layers': [16, 8],\n",
       " 'learning_rate': 0.05,\n",
       " 'epsilon': 0.01,\n",
       " 'encoding_dim': 1}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HPARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fbdecf78-94c5-4f8c-a6c0-86f2eace4663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: NeuralEpsGreedyAgent\n",
      "Network: commontower\n"
     ]
    }
   ],
   "source": [
    "with distribution_strategy.scope():\n",
    "\n",
    "    global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "    agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "        agent_type=HPARAMS[\"model_type\"],\n",
    "        network_type=HPARAMS[\"network_type\"],\n",
    "        time_step_spec=time_step_spec,\n",
    "        action_spec=action_spec,\n",
    "        observation_spec=observation_spec,\n",
    "        global_layers=HPARAMS[\"global_layers\"],\n",
    "        arm_layers=HPARAMS[\"per_arm_layers\"],\n",
    "        common_layers=HPARAMS[\"common_layers\"],\n",
    "        agent_alpha=AGENT_ALPHA,\n",
    "        learning_rate=HPARAMS[\"learning_rate\"],\n",
    "        epsilon=HPARAMS[\"epsilon\"],\n",
    "        train_step_counter=global_step,\n",
    "        output_dim=HPARAMS[\"encoding_dim\"],\n",
    "        eps_phase_steps=EPS_PHASE_STEPS,\n",
    "        summarize_grads_and_vars=True,\n",
    "        debug_summaries=True,\n",
    "    )\n",
    "\n",
    "    agent.initialize()\n",
    "\n",
    "print(f\"Agent: {agent.name}\")\n",
    "\n",
    "# if network:\n",
    "#     print(f\"Network: {network}\")\n",
    "\n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {NETWORK_TYPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "108ed33c-d8ef-4524-97e9-ced9e01c154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHKPT_INTERVAL    : 200\n",
      "eval_batch_size   : 1\n",
      "EVAL_DATA_SIZE    : 1000\n",
      "NUM_EVAL_STEPS    : 100\n",
      "TOTAL_TRAIN_TAKE  : 10000\n"
     ]
    }
   ],
   "source": [
    "from src.perarm_features import train_perarm as train_perarm\n",
    "\n",
    "# train args\n",
    "TRAINING_LOOPS = 150\n",
    "STEPS_PER_LOOP = 1\n",
    "\n",
    "drop_arm_feature_fn = None\n",
    "ASYNC_STEPS_PER_LOOP = 1\n",
    "\n",
    "LOG_INTERVAL = 10\n",
    "CHKPT_INTERVAL = 200\n",
    "\n",
    "# eval args\n",
    "NUM_EVAL_STEPS = 100\n",
    "\n",
    "TOTAL_TRAIN_TAKE = 10000  # TRAINING_LOOPS * HPARAMS['batch_size']\n",
    "\n",
    "print(f\"CHKPT_INTERVAL    : {CHKPT_INTERVAL}\")\n",
    "print(f\"eval_batch_size   : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"EVAL_DATA_SIZE    : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS    : {NUM_EVAL_STEPS}\")\n",
    "print(f\"TOTAL_TRAIN_TAKE  : {TOTAL_TRAIN_TAKE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f66ff927-9a39-4abf-b247-845f0dc7721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS[\"eval_batch_size\"])\n",
    "\n",
    "if NUM_EVAL_STEPS >= 0:\n",
    "    with distribution_strategy.scope():\n",
    "        eval_ds = eval_ds.take(NUM_EVAL_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "528441f5-64ec-4f09-bd50-b2ae85b553bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "with distribution_strategy.scope():\n",
    "    train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "        f\"{LOG_DIR}\", flush_millis=10 * 1000\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f6c98398-d545-4dcc-a71f-32249b5f0336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distribution_strategy: <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f53b83038e0>\n",
      "train_files: ['gs://rec-bandits-v2-hybrid-vertex-bucket/data/train/ml-ratings-100k-train.tfrecord']\n",
      "Inpsecting agent policy from train_peram file...\n",
      "agent.policy: <tf_agents.policies.epsilon_greedy_policy.EpsilonGreedyPolicy object at 0x7f5398631660>\n",
      "Inpsecting agent policy from train_peram file: Complete\n",
      "setting checkpoint_manager: gs://rec-bandits-v2-hybrid-vertex-bucket/02b-deep-bandits-rec-bandits-v2/chkpoint\n",
      "agent.train_step_counter: 50\n",
      "starting train loop...\n",
      "step = 60: loss = 6.869999885559082\n",
      "step = 70: loss = 2.8299999237060547\n",
      "step = 80: loss = 1.0700000524520874\n",
      "step = 90: loss = 1.559999942779541\n",
      "step = 100: loss = 1.3200000524520874\n",
      "step = 110: loss = 1.2100000381469727\n",
      "step = 120: loss = 1.350000023841858\n",
      "step = 130: loss = 1.2799999713897705\n",
      "step = 140: loss = 1.149999976158142\n",
      "step = 150: loss = 1.5399999618530273\n",
      "step = 160: loss = 1.1299999952316284\n",
      "step = 170: loss = 0.9800000190734863\n",
      "step = 180: loss = 1.340000033378601\n",
      "step = 190: loss = 1.399999976158142\n",
      "step = 200: loss = 1.3899999856948853\n",
      "runtime_mins: 0\n",
      "saved trained policy to: gs://rec-bandits-v2-hybrid-vertex-bucket/02b-deep-bandits-rec-bandits-v2/run-20240220-015218/artifacts\n",
      "saved trained policy to: gs://rec-bandits-v2-hybrid-vertex-bucket/02b-deep-bandits-rec-bandits-v2/chkpoint\n",
      "complete train job in 0 minutes\n"
     ]
    }
   ],
   "source": [
    "# start the timer and training\n",
    "start_time = time.time()\n",
    "\n",
    "metric_results, agent = train_perarm.train_perarm(\n",
    "    agent=agent,\n",
    "    reward_spec=reward_tensor_spec,\n",
    "    epsilon=HPARAMS[\"epsilon\"],\n",
    "    global_dim=GLOBAL_DIM,\n",
    "    per_arm_dim=PER_ARM_DIM,\n",
    "    num_iterations=TRAINING_LOOPS,\n",
    "    steps_per_loop=STEPS_PER_LOOP,\n",
    "    num_eval_steps=NUM_EVAL_STEPS,\n",
    "    # data\n",
    "    batch_size=HPARAMS[\"batch_size\"],\n",
    "    eval_batch_size=HPARAMS[\"eval_batch_size\"],\n",
    "    # functions\n",
    "    _trajectory_fn=_trajectory_fn,\n",
    "    # _run_bandit_eval_fn = _run_bandit_eval,\n",
    "    # train intervals\n",
    "    chkpt_interval=CHKPT_INTERVAL,\n",
    "    log_interval=LOG_INTERVAL,\n",
    "    # dirs\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    data_dir_prefix_path=DATA_GCS_PREFIX,\n",
    "    log_dir=LOG_DIR,\n",
    "    model_dir=ARTIFACTS_DIR,\n",
    "    # root_dir = ROOT_DIR,\n",
    "    chkpoint_dir=CHECKPT_DIR,\n",
    "    async_steps_per_loop=ASYNC_STEPS_PER_LOOP,\n",
    "    resume_training_loops=False,\n",
    "    use_gpu=True,\n",
    "    use_tpu=False,\n",
    "    profiler=False,\n",
    "    global_step=global_step,\n",
    "    total_train_take=TOTAL_TRAIN_TAKE,\n",
    "    train_summary_writer=train_summary_writer,\n",
    "    strategy=distribution_strategy,\n",
    ")\n",
    "\n",
    "# aiplatform.end_upload_tb_log()\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"complete train job in {runtime_mins} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "177aa3ab-05b4-48f9-b434-9335bd9eb54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3885794"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(metric_results)\n",
    "metric_results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ba65417f-54e0-436e-b0d4-93cffb981ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(metric_results)\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61464938-a3e7-4ab0-9149-4a9124199dc1",
   "metadata": {},
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9108f8b6-7aea-48d6-a763-461b30671c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "083c2351-5ac8-4218-9bef-e249777aee97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 31910), started 0:02:36 ago. (Use '!kill 31910' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7add1229f72bd2fe\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7add1229f72bd2fe\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=$LOG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7ba747-00d5-4908-8d0b-334ae9d2c791",
   "metadata": {},
   "source": [
    "#### eval trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c5cf9366-d9cd-4c9d-951a-99a50877a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af82506e-95d7-4a4e-a821-e08512615db7",
   "metadata": {},
   "source": [
    "After training, our `agent.policy` is used as the deployment \"model\" that will generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6c82396a-7822-41fb-830f-1f6eb9c9b213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.epsilon_greedy_policy.EpsilonGreedyPolicy at 0x7fdfb35ad990>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_agent = agent.policy\n",
    "deployment_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f6706224-ef5b-4185-bde4-bccb7c8e7ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating trained Agent...\n",
      "post-train val_loss     : 1.412819743156433\n",
      "post-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(\n",
    "    deployment_agent, use_tf_function=True\n",
    ")\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy=post_policy_tf,\n",
    "    data=eval_ds,\n",
    "    eval_batch_size=HPARAMS[\"eval_batch_size\"],\n",
    "    per_arm_dim=PER_ARM_DIM,\n",
    "    global_dim=GLOBAL_DIM,\n",
    "    vocab_dict=vocab_dict,\n",
    "    num_oov_buckets=NUM_OOV_BUCKETS,\n",
    "    global_emb_size=GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size=MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f899120f-3706-4b72-8f2c-2169221dd66b",
   "metadata": {},
   "source": [
    "## Using Trained Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b0f691-860e-4853-928e-4c7ece714dd0",
   "metadata": {},
   "source": [
    "### load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ea029f73-0638-462a-8f00-54b05c54d69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-cpg-cdp-bucket/02b-deep-bandits-rec-bandits-v2/run-20240311-231807/artifacts\n"
     ]
    }
   ],
   "source": [
    "POLICY_URI = ARTIFACTS_DIR\n",
    "\n",
    "print(POLICY_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "66d1d819-0152-437c-aefc-45ffd34d808a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-cpg-cdp-bucket/02b-deep-bandits-rec-bandits-v2/run-20240311-231807/artifacts/\n",
      "gs://rec-bandits-v2-cpg-cdp-bucket/02b-deep-bandits-rec-bandits-v2/run-20240311-231807/artifacts/fingerprint.pb\n",
      "gs://rec-bandits-v2-cpg-cdp-bucket/02b-deep-bandits-rec-bandits-v2/run-20240311-231807/artifacts/policy_specs.pbtxt\n",
      "gs://rec-bandits-v2-cpg-cdp-bucket/02b-deep-bandits-rec-bandits-v2/run-20240311-231807/artifacts/saved_model.pb\n",
      "gs://rec-bandits-v2-cpg-cdp-bucket/02b-deep-bandits-rec-bandits-v2/run-20240311-231807/artifacts/assets/\n",
      "gs://rec-bandits-v2-cpg-cdp-bucket/02b-deep-bandits-rec-bandits-v2/run-20240311-231807/artifacts/variables/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $POLICY_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6aad948e-e346-4da3-8cb2-747435c8dc4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7fdb7ac91930>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "483f8fa5-cbd1-4e3c-8e62-47f91f42e137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(), dtype=dtype('int32'), name='action_spec', minimum=0, maximum=1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_policy.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8f658891-bc09-49b8-bc58-000a7926df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "SKIP_NUM = 10\n",
    "\n",
    "for x in eval_ds.skip(SKIP_NUM).take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "\n",
    "    # global_feat_infer = _get_global_context_features(x)\n",
    "    # arm_feat_infer = _get_per_arm_features(x)\n",
    "\n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "\n",
    "    # rewards = _get_rewards(x)\n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "\n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(\n",
    "        arm_feat_infer, [HPARAMS[\"eval_batch_size\"], PER_ARM_DIM]\n",
    "    )  # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "\n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {\"global\": flat_global_infer, \"per_arm\": concat_arm}\n",
    "\n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "\n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "\n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "49ce41ed-41b7-404d-9796-1658e7955894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': <tf.Tensor: shape=(), dtype=float32, numpy=1.0>,\n",
       " 'observation': {'global': <tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
       "array([-0.01094439, -0.04472867,  0.04441762, -0.01647949,  0.0046405 ,\n",
       "       -0.0341202 , -0.00361496,  0.01297008,  0.00485959, -0.04329402,\n",
       "        0.00117092,  0.01439926,  0.00258077, -0.00833185,  0.04904598,\n",
       "        0.0231492 , -0.02972592, -0.04913876, -0.04863835,  0.0119725 ,\n",
       "       -0.04825534, -0.04812555,  0.04281879,  0.00417844, -0.01244729,\n",
       "       -0.02764809,  0.01387265, -0.00582903,  0.0076939 ,  0.00452417,\n",
       "       -0.04647021,  0.01315482,  0.0255104 ,  0.02038307,  0.03540963,\n",
       "        0.01305784,  0.04377819,  0.00464763,  0.01088867, -0.00138899,\n",
       "       -0.03713303,  0.0236685 , -0.04468458, -0.01889151, -0.03105135,\n",
       "        0.04988252, -0.02835763, -0.01354552,  0.0120822 , -0.01447343,\n",
       "       -0.02453575, -0.00902694, -0.02304086, -0.03903459, -0.02282771,\n",
       "        0.0230325 ,  0.02977616, -0.01900203, -0.00738142,  0.04088057,\n",
       "        0.02876214,  0.02513001,  0.02952735, -0.03183111], dtype=float32)>,\n",
       "                 'per_arm': <tf.Tensor: shape=(2, 64), dtype=float32, numpy=\n",
       "array([[ 0.00918186,  0.02384375,  0.04797592, -0.00890256, -0.0181128 ,\n",
       "        -0.04927206, -0.02378112, -0.03090107,  0.00080135,  0.04829529,\n",
       "        -0.0016102 , -0.0244432 ,  0.01425691, -0.01663367, -0.00142824,\n",
       "         0.02776904, -0.01568995, -0.04898194, -0.04998182, -0.04850136,\n",
       "         0.01773963,  0.02055668, -0.03397145,  0.00868379,  0.02462664,\n",
       "         0.01785356, -0.00787157, -0.01965995,  0.01175265, -0.00243572,\n",
       "        -0.04387187,  0.02046481, -0.01935185, -0.008849  , -0.04911299,\n",
       "         0.00456656,  0.01211917, -0.04114896, -0.03715159, -0.01096507,\n",
       "        -0.01899434, -0.014622  , -0.01888925,  0.00593976, -0.03362364,\n",
       "        -0.02935783,  0.00072186, -0.01117659, -0.01590793, -0.03558428,\n",
       "         0.04288962, -0.04128543, -0.0233798 ,  0.03086963,  0.00532325,\n",
       "         0.04692933,  0.00861125,  0.03498132,  0.01377172, -0.02723817,\n",
       "        -0.00996158, -0.01893291, -0.01930895,  0.03373501],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ]],\n",
       "      dtype=float32)>},\n",
       " 'reward': <tf.Tensor: shape=(), dtype=float32, numpy=3.0>,\n",
       " 'step_type': <tf.Tensor: shape=(), dtype=int32, numpy=0>})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectory_step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f515fcd0-2228-4f68-9ef9-665ce1fc3fb2",
   "metadata": {},
   "source": [
    "### view prediction response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6af4c297-d2e8-4f7b-bed5-e1da997dfe34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([4.0057983, 4.0057983], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([ 0.00918186,  0.02384375,  0.04797592, -0.00890256, -0.0181128 ,\n",
       "       -0.04927206, -0.02378112, -0.03090107,  0.00080135,  0.04829529,\n",
       "       -0.0016102 , -0.0244432 ,  0.01425691, -0.01663367, -0.00142824,\n",
       "        0.02776904, -0.01568995, -0.04898194, -0.04998182, -0.04850136,\n",
       "        0.01773963,  0.02055668, -0.03397145,  0.00868379,  0.02462664,\n",
       "        0.01785356, -0.00787157, -0.01965995,  0.01175265, -0.00243572,\n",
       "       -0.04387187,  0.02046481, -0.01935185, -0.008849  , -0.04911299,\n",
       "        0.00456656,  0.01211917, -0.04114896, -0.03715159, -0.01096507,\n",
       "       -0.01899434, -0.014622  , -0.01888925,  0.00593976, -0.03362364,\n",
       "       -0.02935783,  0.00072186, -0.01117659, -0.01590793, -0.03558428,\n",
       "        0.04288962, -0.04128543, -0.0233798 ,  0.03086963,  0.00532325,\n",
       "        0.04692933,  0.00861125,  0.03498132,  0.01377172, -0.02723817,\n",
       "       -0.00996158, -0.01893291, -0.01930895,  0.03373501], dtype=float32)))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd58d4b-6749-4177-8342-83ee969408c9",
   "metadata": {},
   "source": [
    "#### chosen action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d49adbbb-f747-4e4c-b82d-df88373c644f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0, dtype=int32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd12013-1d12-4197-8254-cef9138df42c",
   "metadata": {},
   "source": [
    "#### Per Arm Policy Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d6126290-546b-4702-8a1e-91f18adb05c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([4.0057983, 4.0057983], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([ 0.00918186,  0.02384375,  0.04797592, -0.00890256, -0.0181128 ,\n",
       "       -0.04927206, -0.02378112, -0.03090107,  0.00080135,  0.04829529,\n",
       "       -0.0016102 , -0.0244432 ,  0.01425691, -0.01663367, -0.00142824,\n",
       "        0.02776904, -0.01568995, -0.04898194, -0.04998182, -0.04850136,\n",
       "        0.01773963,  0.02055668, -0.03397145,  0.00868379,  0.02462664,\n",
       "        0.01785356, -0.00787157, -0.01965995,  0.01175265, -0.00243572,\n",
       "       -0.04387187,  0.02046481, -0.01935185, -0.008849  , -0.04911299,\n",
       "        0.00456656,  0.01211917, -0.04114896, -0.03715159, -0.01096507,\n",
       "       -0.01899434, -0.014622  , -0.01888925,  0.00593976, -0.03362364,\n",
       "       -0.02935783,  0.00072186, -0.01117659, -0.01590793, -0.03558428,\n",
       "        0.04288962, -0.04128543, -0.0233798 ,  0.03086963,  0.00532325,\n",
       "        0.04692933,  0.00861125,  0.03498132,  0.01377172, -0.02723817,\n",
       "       -0.00996158, -0.01893291, -0.01930895,  0.03373501], dtype=float32))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f66961-ebb5-4ae5-8e6f-ad73114d8353",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
