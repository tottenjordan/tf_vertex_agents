{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34230a4a-7296-429e-b5b0-c8e0674ba2d2",
   "metadata": {},
   "source": [
    "# Building embedding models with preprocess global & per-arm features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9849b480-18f0-457b-bbc8-3d612eec7142",
   "metadata": {},
   "source": [
    "**Use this notebook to better understand how the emb preprocessing functions work:**\n",
    "* the dimensions produced at each step\n",
    "* working with tensors (e.g., concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7eaf96-d4ad-438b-bdb3-73cb0dfd4691",
   "metadata": {},
   "source": [
    "The preproccesing layers will ultimately feed the two sampling functions described below. These sampling functions will be used to create [trajectories](https://github.com/tensorflow/agents/blob/master/tf_agents/trajectories/trajectory.py#L36) (i.e., the training examples for our model)\n",
    "\n",
    "`global_context_sampling_fn`: \n",
    "* A function that outputs a random 1d array or list of ints or floats\n",
    "* This output is the global context. Its shape and type must be consistent across calls.\n",
    "\n",
    "`arm_context_sampling_fn`: \n",
    "* A function that outputs a random 1 array or list of ints or floats (same type as the output of `global_context_sampling_fn`). * This output is the per-arm context. Its shape must be consistent across calls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bd7426-859e-4e05-a7e9-bb587eb1663e",
   "metadata": {},
   "source": [
    "## Notebook config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad051d2a-a5d1-497c-809d-81a4c56e9c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = 'mabv1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6084faff-b86b-4fa7-9ff8-eb8bd5d70575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e3aa84-6c80-4f09-b5aa-be5e792056be",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15348de-9cd7-4e58-876c-60b2b1c006c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from collections import defaultdict\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# TF-agents\n",
    "# from tf_agents.bandits.agents import neural_epsilon_greedy_agent\n",
    "# from tf_agents.bandits.agents import neural_linucb_agent\n",
    "# from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "from tf_agents.bandits.policies import policy_utilities\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04a7472-2826-481d-866b-9ab38fdff807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# this repo\n",
    "from src.per_arm_rl import data_utils\n",
    "from src.per_arm_rl import data_config\n",
    "from src.per_arm_rl import train_utils as train_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9cb358-ef5c-4fcc-878c-8b8d591fd09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bad85ca-1cdb-492b-815b-5c83012e0adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8543b533-3b6d-4f8d-9cf2-726839264a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e38dd98-0598-45d8-b00f-3cee68cc862f",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9ea09c-3dc1-40c6-ad9e-7eae192e3053",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a79a5cb-20f4-41d0-8ac9-18bdb288d1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = \"val\"\n",
    "\n",
    "val_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        val_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "val_dataset = tf.data.TFRecordDataset(val_files)\n",
    "val_dataset = val_dataset.map(data_utils.parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068d466d-0b05-411b-a148-8781d98b6e2a",
   "metadata": {},
   "source": [
    "### get vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7fe132-730c-4f94-aed8-fea69aab9fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{VOCAB_SUBDIR}/{VOCAB_FILENAME}'\n",
    "print(f\"Downloading vocab...\")\n",
    "\n",
    "os.system(f'gsutil -q cp {EXISTING_VOCAB_FILE} .')\n",
    "print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "vocab_dict = pkl.load(filehandler)\n",
    "filehandler.close()\n",
    "\n",
    "for key in vocab_dict.keys():\n",
    "    pprint(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eba727a-e3bb-44f3-a4d4-5ef51aacbbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    \n",
    "    iterator = iter(train_dataset.batch(1))\n",
    "    data = next(iterator)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e424e5c6-e030-405b-a0f0-bf2f1791c07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OOV_BUCKETS        = 1\n",
    "GLOBAL_EMBEDDING_SIZE  = 16\n",
    "MV_EMBEDDING_SIZE      = 32 #32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da71da5-2b50-4861-85f5-646165659098",
   "metadata": {},
   "source": [
    "## global context (user) features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4058ed6c-69b5-4681-ad9b-d69632b12fbd",
   "metadata": {},
   "source": [
    "#### user ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8791d355-bac1-4450-8560-963e44a5e93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_input_layer = tf.keras.Input(\n",
    "    name=\"user_id\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.string\n",
    ")\n",
    "\n",
    "user_id_lookup = tf.keras.layers.StringLookup(\n",
    "    max_tokens=len(vocab_dict['user_id']) + NUM_OOV_BUCKETS,\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    mask_token=None,\n",
    "    vocabulary=vocab_dict['user_id'],\n",
    ")(user_id_input_layer)\n",
    "\n",
    "user_id_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['user_id']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=GLOBAL_EMBEDDING_SIZE\n",
    ")(user_id_lookup)\n",
    "\n",
    "user_id_embedding = tf.reduce_sum(user_id_embedding, axis=-2)\n",
    "\n",
    "# global_inputs.append(user_id_input_layer)\n",
    "# global_features.append(user_id_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb4f9a9-6b13-40e8-882c-a91de6147254",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_id_model = tf.keras.Model(inputs=user_id_input_layer, outputs=user_id_embedding)\n",
    "\n",
    "# for x in train_dataset.batch(1).take(1):\n",
    "#     print(x[\"user_id\"])\n",
    "#     print(test_user_id_model(x[\"user_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2692c5f-8e3c-4b19-b291-d6a27968df05",
   "metadata": {},
   "source": [
    "#### user AGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dbe30e-792b-4046-a3d2-a3f0cfad50b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_age_input_layer = tf.keras.Input(\n",
    "#     name=\"bucketized_user_age\",\n",
    "#     shape=(1,),\n",
    "#     dtype=tf.float32\n",
    "# )\n",
    "\n",
    "# user_age_lookup = tf.keras.layers.IntegerLookup(\n",
    "#     vocabulary=vocab_dict['bucketized_user_age'],\n",
    "#     num_oov_indices=NUM_OOV_BUCKETS,\n",
    "#     oov_value=0,\n",
    "# )(user_age_input_layer)\n",
    "\n",
    "# user_age_embedding = tf.keras.layers.Embedding(\n",
    "#     # Let's use the explicit vocabulary lookup.\n",
    "#     input_dim=len(vocab_dict['bucketized_user_age']) + NUM_OOV_BUCKETS,\n",
    "#     output_dim=GLOBAL_EMBEDDING_SIZE\n",
    "# )(user_age_lookup)\n",
    "\n",
    "# user_age_embedding = tf.reduce_sum(user_age_embedding, axis=-2)\n",
    "\n",
    "# # global_inputs.append(user_age_input_layer)\n",
    "# # global_features.append(user_age_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30558d19-e3ca-4bee-bab2-01a19a104351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_user_age_model = tf.keras.Model(inputs=user_age_input_layer, outputs=user_age_embedding)\n",
    "\n",
    "# # for x in train_dataset.batch(1).take(1):\n",
    "# #     print(x[\"bucketized_user_age\"])\n",
    "# #     print(test_user_age_model(x[\"bucketized_user_age\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065b0610-9a1b-4ddb-abc6-4ebfa8902a77",
   "metadata": {},
   "source": [
    "#### user OCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef0ceba-793e-4ca1-862f-d46819d563ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_occ_input_layer = tf.keras.Input(\n",
    "#     name=\"user_occupation_text\",\n",
    "#     shape=(1,),\n",
    "#     dtype=tf.string\n",
    "# )\n",
    "\n",
    "# user_occ_lookup = tf.keras.layers.StringLookup(\n",
    "#     max_tokens=len(vocab_dict['user_occupation_text']) + NUM_OOV_BUCKETS,\n",
    "#     num_oov_indices=NUM_OOV_BUCKETS,\n",
    "#     mask_token=None,\n",
    "#     vocabulary=vocab_dict['user_occupation_text'],\n",
    "# )(user_occ_input_layer)\n",
    "\n",
    "# user_occ_embedding = tf.keras.layers.Embedding(\n",
    "#     # Let's use the explicit vocabulary lookup.\n",
    "#     input_dim=len(vocab_dict['user_occupation_text']) + NUM_OOV_BUCKETS,\n",
    "#     output_dim=GLOBAL_EMBEDDING_SIZE\n",
    "# )(user_occ_lookup)\n",
    "\n",
    "# user_occ_embedding = tf.reduce_sum(user_occ_embedding, axis=-2)\n",
    "\n",
    "# # global_inputs.append(user_occ_input_layer)\n",
    "# # global_features.append(user_occ_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65d96bb-73e2-469c-a4e9-c084ecfbec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_user_occ_model = tf.keras.Model(inputs=user_occ_input_layer, outputs=user_occ_embedding)\n",
    "\n",
    "# # for x in train_dataset.batch(1).take(1):\n",
    "# #     print(x[\"user_occupation_text\"])\n",
    "# #     print(test_user_occ_model(x[\"user_occupation_text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2fd9da-6845-4d2f-8a1f-2151186ecb4a",
   "metadata": {},
   "source": [
    "#### user Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9755aaa-8008-4ae2-b4c2-588c79998917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_ts_input_layer = tf.keras.Input(\n",
    "#     name=\"timestamp\",\n",
    "#     shape=(1,),\n",
    "#     dtype=tf.int64\n",
    "# )\n",
    "\n",
    "# user_ts_lookup = tf.keras.layers.Discretization(\n",
    "#     vocab_dict['timestamp_buckets'].tolist()\n",
    "# )(user_ts_input_layer)\n",
    "\n",
    "# user_ts_embedding = tf.keras.layers.Embedding(\n",
    "#     # Let's use the explicit vocabulary lookup.\n",
    "#     input_dim=len(vocab_dict['timestamp_buckets'].tolist()) + NUM_OOV_BUCKETS,\n",
    "#     output_dim=GLOBAL_EMBEDDING_SIZE\n",
    "# )(user_ts_lookup)\n",
    "\n",
    "# user_ts_embedding = tf.reduce_sum(user_ts_embedding, axis=-2)\n",
    "\n",
    "# # global_inputs.append(user_ts_input_layer)\n",
    "# # global_features.append(user_ts_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3238783f-6f88-4400-96ac-924a3e831f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_user_ts_model = tf.keras.Model(inputs=user_ts_input_layer, outputs=user_ts_embedding)\n",
    "\n",
    "# # for x in train_dataset.batch(1).take(1):\n",
    "# #     print(x[\"timestamp\"])\n",
    "# #     print(test_user_ts_model(x[\"timestamp\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa494695-d3a1-4917-8e63-26f8c1d21cd8",
   "metadata": {},
   "source": [
    "### define global sampling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc66ef6f-4041-4163-8f81-4676495c8a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _get_global_context_features(x):\n",
    "#     \"\"\"\n",
    "#     This function generates a single global observation vector.\n",
    "#     \"\"\"\n",
    "#     user_id_value = x['user_id']\n",
    "#     user_age_value = x['bucketized_user_age']\n",
    "#     user_occ_value = x['user_occupation_text']\n",
    "#     user_ts_value = x['timestamp']\n",
    "\n",
    "#     _id = test_user_id_model(user_id_value) # input_tensor=tf.Tensor(shape=(4,), dtype=float32)\n",
    "#     _age = test_user_age_model(user_age_value)\n",
    "#     _occ = test_user_occ_model(user_occ_value)\n",
    "#     _ts = test_user_ts_model(user_ts_value)\n",
    "\n",
    "#     # # tmp - insepct numpy() values\n",
    "#     # print(_id.numpy()) #[0])\n",
    "#     # print(_age.numpy()) #[0])\n",
    "#     # print(_occ.numpy()) #[0])\n",
    "#     # print(_ts.numpy()) #[0])\n",
    "\n",
    "#     # to numpy array\n",
    "#     _id = np.array(_id.numpy())\n",
    "#     _age = np.array(_age.numpy())\n",
    "#     _occ = np.array(_occ.numpy())\n",
    "#     _ts = np.array(_ts.numpy())\n",
    "\n",
    "#     concat = np.concatenate(\n",
    "#         [_id, _age, _occ, _ts], axis=-1 # -1\n",
    "#     ).astype(np.float32)\n",
    "\n",
    "#     return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31569c4-db07-4371-91de-38e4b8351185",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_DIM = _get_global_context_features(data).shape[1]\n",
    "print(f\"GLOBAL_DIM: {GLOBAL_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce0d85b-25c3-4d81-a758-7c7aa1d3d699",
   "metadata": {},
   "source": [
    "## arm preprocessing layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607ec63b-cad2-45e1-a143-5a233aad78b4",
   "metadata": {},
   "source": [
    "#### movie ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57d06b8-3a73-4361-a549-0f565ddf46e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mv_id_input_layer = tf.keras.Input(\n",
    "#     name=\"movie_id\",\n",
    "#     shape=(1,),\n",
    "#     dtype=tf.string\n",
    "# )\n",
    "\n",
    "# mv_id_lookup = tf.keras.layers.StringLookup(\n",
    "#     max_tokens=len(vocab_dict['movie_id']) + NUM_OOV_BUCKETS,\n",
    "#     num_oov_indices=NUM_OOV_BUCKETS,\n",
    "#     mask_token=None,\n",
    "#     vocabulary=vocab_dict['movie_id'],\n",
    "# )(mv_id_input_layer)\n",
    "\n",
    "# mv_id_embedding = tf.keras.layers.Embedding(\n",
    "#     # Let's use the explicit vocabulary lookup.\n",
    "#     input_dim=len(vocab_dict['movie_id']) + NUM_OOV_BUCKETS,\n",
    "#     output_dim=MV_EMBEDDING_SIZE\n",
    "# )(mv_id_lookup)\n",
    "\n",
    "# mv_id_embedding = tf.reduce_sum(mv_id_embedding, axis=-2)\n",
    "\n",
    "# # arm_inputs.append(mv_id_input_layer)\n",
    "# # arm_features.append(mv_id_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569185f7-e1ae-40eb-b319-088e2b8b6970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mv_id_model = tf.keras.Model(inputs=mv_id_input_layer, outputs=mv_id_embedding)\n",
    "\n",
    "# # for x in train_dataset.batch(1).take(1):\n",
    "# #     print(x[\"movie_id\"])\n",
    "# #     print(test_mv_id_model(x[\"movie_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ba4f2a-b741-4cca-935c-29735a8c9c65",
   "metadata": {},
   "source": [
    "#### movie genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da86a848-7e68-4950-83c0-eae53deaf24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mv_genre_input_layer = tf.keras.Input(\n",
    "#     name=\"movie_genres\",\n",
    "#     shape=(1,),\n",
    "#     dtype=tf.float32\n",
    "# )\n",
    "\n",
    "# mv_genre_lookup = tf.keras.layers.IntegerLookup(\n",
    "#     vocabulary=vocab_dict['movie_genres'],\n",
    "#     num_oov_indices=NUM_OOV_BUCKETS,\n",
    "#     oov_value=0,\n",
    "# )(mv_genre_input_layer)\n",
    "\n",
    "# mv_genre_embedding = tf.keras.layers.Embedding(\n",
    "#     # Let's use the explicit vocabulary lookup.\n",
    "#     input_dim=len(vocab_dict['movie_genres']) + NUM_OOV_BUCKETS,\n",
    "#     output_dim=MV_EMBEDDING_SIZE\n",
    "# )(mv_genre_lookup)\n",
    "\n",
    "# mv_genre_embedding = tf.reduce_sum(mv_genre_embedding, axis=-2)\n",
    "\n",
    "# # arm_inputs.append(mv_genre_input_layer)\n",
    "# # arm_features.append(mv_genre_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7812a50-7188-4c09-b8b2-9f8a26e414bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mv_gen_model = tf.keras.Model(inputs=mv_genre_input_layer, outputs=mv_genre_embedding)\n",
    "\n",
    "# for x in train_dataset.batch(1).take(1):\n",
    "#     print(x[\"movie_genres\"])\n",
    "#     print(test_mv_gen_model(x[\"movie_genres\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da0b72e-a971-423f-85b4-66319e1c441b",
   "metadata": {},
   "source": [
    "### define sampling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7be4e2e-0862-4db0-963b-afc1e58ee3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _get_per_arm_features(x):\n",
    "#     \"\"\"\n",
    "#     This function generates a single per-arm observation vector\n",
    "#     \"\"\"\n",
    "#     mv_id_value = x['movie_id']\n",
    "#     mv_gen_value = x['movie_genres']\n",
    "\n",
    "#     _mid = test_mv_id_model(mv_id_value)\n",
    "#     _mgen = test_mv_gen_model(mv_gen_value)\n",
    "\n",
    "#     # to numpy array\n",
    "#     _mid = np.array(_mid.numpy())\n",
    "#     _mgen = np.array(_mgen.numpy())\n",
    "\n",
    "\n",
    "#     concat = np.concatenate(\n",
    "#         [_mid, _mgen], axis=-1 # -1\n",
    "#     ).astype(np.float32)\n",
    "#     # concat = tf.concat([_mid, _mgen], axis=-1).astype(np.float32)\n",
    "\n",
    "#     return concat #this is special to this example - there is only one action dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015db37c-1254-4586-9262-020299e91420",
   "metadata": {},
   "outputs": [],
   "source": [
    "PER_ARM_DIM = _get_per_arm_features(data).shape[1] #shape checks out at batchdim, nactions, arm feats\n",
    "print(f\"PER_ARM_DIM: {PER_ARM_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafbcafd-a840-4caf-a1e1-9d4c529161e5",
   "metadata": {},
   "source": [
    "## Global & Per-Arm feature embedding models \n",
    "\n",
    "> all these dimensions should match the class output below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9572d7f9-72b6-447c-ac0d-d9f2f6867ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.perarm_features import emb_features as emb_features\n",
    "\n",
    "embs = emb_features.EmbeddingModel(\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2998a87-0aec-4ca7-a989-ddc07e309065",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_globals = embs._get_global_context_features(data)\n",
    "\n",
    "GLOBAL_DIM = test_globals.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"GLOBAL_DIM: {GLOBAL_DIM}\")\n",
    "\n",
    "test_globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642ff35d-7574-410c-ab3d-daf21e24883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arms = embs._get_per_arm_features(data)\n",
    "\n",
    "PER_ARM_DIM = test_arms.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"PER_ARM_DIM: {PER_ARM_DIM}\")\n",
    "\n",
    "test_arms"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
