{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6f6df3d-0777-4c26-bb69-bbe090ddbe70",
   "metadata": {},
   "source": [
    "# Train Contextual Bandits with simple linear, stationary simulation environment\n",
    "\n",
    "> In this notebook, we'll evaluate the performance of Contextual Bandits in stationary, stochastic environments. These are environments whose statistics (e.g., distribution of rewards) do not change over time\n",
    "\n",
    "* A linear  environment is an environment where the expected reward for each arm `k` is linearly related to the context features `x`\n",
    "* Train and evaluate linear and non-linear (neural) Contextual Bandit algorithms\n",
    "* We'll show that linear-based agents converge faster on such an environment, compared to non-linear agents, becasue the problem is linear (by the reward calculation construction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ac7392-ccb3-4c22-b109-31904f45364f",
   "metadata": {},
   "source": [
    "### Per-arm environment\n",
    "In this example we will use the [StationaryStochasticPerArmPyEnvironment](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/environments/stationary_stochastic_per_arm_py_environment.py) environment to simulate offline training data for training a contextual bandit with **per-arm features**\n",
    "\n",
    "\n",
    "To initialize the per-arm environment, one has to define functions that generate:\n",
    "\n",
    "* *global and per-arm features*: These functions have no input parameters and generate a single (global or per-arm) feature vector when called.\n",
    "\n",
    "* *rewards*: This function takes as parameter the concatenation of a global and a per-arm feature vector, and generates a reward. Basically this is the function that the agent will have to \"guess\". \n",
    "\n",
    "It is worth noting here that in the per-arm case the reward function is identical for every arm. This is a fundamental difference from the classic bandit case, where the agent has to estimate reward functions for each arm independently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4f45fa-b534-499a-a0b5-a29b8b57d701",
   "metadata": {},
   "source": [
    "## Load notebook config\n",
    "\n",
    "* use the prefix defined in `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e198023-ff4e-464c-92ab-aefdef472ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "VERSION        = \"v2\"                       # TODO\n",
    "PREFIX         = f'rec-bandits-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9908f71-9e57-47b8-b6cf-04792e7cea2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"rec-bandits-v2\"\n",
      "VERSION                  = \"v2\"\n",
      "\n",
      "BUCKET_NAME              = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "DATA_PATH_KFP_DEMO       = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data/kfp_demo_data/u.data\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_NAME    = \"mvlens_rec_bandits_v2\"\n",
      "BIGQUERY_TABLE_NAME      = \"training_dataset\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-rec-bandits-v2\"\n",
      "\n",
      "DOCKERNAME_01            = \"Dockerfile_train_my_perarm_env\"\n",
      "IMAGE_NAME_01            = \"train-my-perarm-env-v2\"\n",
      "IMAGE_URI_01             = \"gcr.io/hybrid-vertex/train-my-perarm-env-v2\"\n",
      "\n",
      "DOCKERNAME_02            = \"Dockerfile_perarm_feats\"\n",
      "IMAGE_NAME_02            = \"train-perarm-feats-v2\"\n",
      "IMAGE_URI_02             = \"gcr.io/hybrid-vertex/train-perarm-feats-v2\"\n",
      "\n",
      "DOCKERNAME_03            = \"Dockerfile_ranking_bandit\"\n",
      "IMAGE_NAME_03            = \"train-rank-bandit-v2\"\n",
      "IMAGE_URI_03             = \"gcr.io/hybrid-vertex/train-rank-bandit-v2\"\n",
      "\n",
      "DOCKERNAME_04            = \"Dockerfile_train_mab_e2e\"\n",
      "IMAGE_NAME_04            = \"train-mab-e2e-v2\"\n",
      "IMAGE_URI_04             = \"gcr.io/hybrid-vertex/train-mab-e2e-v2\"\n",
      "\n",
      "DOCKERNAME_04_pred       = \"Dockerfile_pred_mab_e2e\"\n",
      "IMAGE_NAME_04_pred       = \"pred-mab-e2e-v2\"\n",
      "IMAGE_URI_04_pred        = \"gcr.io/hybrid-vertex/pred-mab-e2e-v2\"\n",
      "\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/local_docker_tfa\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28954e08-7a8f-472b-84ee-07ddcc1f627a",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c309527-3f86-426a-ab08-71f170bdf091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "451b6a26-aa56-4c4c-bbea-42c8a613538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from collections import defaultdict\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pickle as pkl\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "# from tf_agents.agents import TFAgent\n",
    "\n",
    "from tf_agents.bandits.environments import stationary_stochastic_per_arm_py_environment as p_a_env\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "from tf_agents.bandits.agents import lin_ucb_agent\n",
    "from tf_agents.bandits.agents import linear_thompson_sampling_agent as lin_ts_agent\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent\n",
    "from tf_agents.bandits.agents import neural_linucb_agent\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "from tf_agents.bandits.policies import policy_utilities\n",
    "\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "\n",
    "from tf_agents.bandits.replay_buffers import bandit_replay_buffer\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.eval import metric_utils\n",
    "# from tf_agents.google.metrics import export_utils\n",
    "from tf_agents.metrics import export_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.policies import policy_saver\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# this repo\n",
    "from src.per_arm_rl import data_utils\n",
    "from src.per_arm_rl import data_config\n",
    "from src.per_arm_rl import train_utils as train_utils\n",
    "from src.per_arm_rl import policy_util\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "623b22ed-3ea4-4c38-ace7-e5a2668a8526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0088156-3897-40cf-81fe-2b31fcfb0f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7adaff25-dece-4ccf-8e42-50762702c569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380b558c-e411-4a1f-9a88-f47a5bd6c69e",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b634a4da-4448-4b0c-aa9d-f7618be93c5e",
   "metadata": {},
   "source": [
    "## Read TF Records (for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "567c7360-e18c-40e1-99c1-be20d51bca74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_TAG: movielens-100k\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens-100k/vocab_dict.pkl\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens-100k/all/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens-100k/train/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens-100k/val/\n"
     ]
    }
   ],
   "source": [
    "DATA_TAG = \"movielens-100k\" # movielens-100k | movielens-1m\n",
    "\n",
    "print(f\"DATA_TAG: {DATA_TAG}\")\n",
    "\n",
    "! gsutil ls $DATA_PATH/$DATA_TAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46484443-2bba-474b-9c2c-226bc8a67357",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31ab8fe2-a423-43de-bec2-753521f7f5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens-100k/train/ml-100k-ratings-train-01-of-05.tfrecord',\n",
       " 'gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens-100k/train/ml-100k-ratings-train-02-of-05.tfrecord',\n",
       " 'gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens-100k/train/ml-100k-ratings-train-03-of-05.tfrecord',\n",
       " 'gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens-100k/train/ml-100k-ratings-train-04-of-05.tfrecord']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPLIT = \"train\" # \"train\" | \"val\"\n",
    "\n",
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{DATA_TAG}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3245e4d3-ef41-4c87-98c5-2c749224623f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([45.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'357'], dtype=object)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([879024327])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'138'], dtype=object)>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'doctor'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "train_dataset = train_dataset.map(data_utils.parse_tfrecord)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aa5ff5-64b9-479d-85e8-495f5d085439",
   "metadata": {},
   "source": [
    "### get vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26d3805b-0e6c-47fd-8961-486e2d828ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE_VOCABS: False\n"
     ]
    }
   ],
   "source": [
    "GENERATE_VOCABS = False\n",
    "\n",
    "print(f\"GENERATE_VOCABS: {GENERATE_VOCABS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1977de25-fabb-47be-a9df-c7dfeee83e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab...\n",
      "Downloaded vocab from: gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens-100k/vocab_dict.pkl\n",
      "\n",
      "'movie_id'\n",
      "'user_id'\n",
      "'user_occupation_text'\n",
      "'movie_genres'\n",
      "'bucketized_user_age'\n",
      "'max_timestamp'\n",
      "'min_timestamp'\n",
      "'timestamp_buckets'\n"
     ]
    }
   ],
   "source": [
    "if not GENERATE_VOCABS:\n",
    "\n",
    "    EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{DATA_GCS_PREFIX}/{DATA_TAG}/{VOCAB_FILENAME}'\n",
    "    print(f\"Downloading vocab...\")\n",
    "    \n",
    "    os.system(f'gsutil -q cp {EXISTING_VOCAB_FILE} .')\n",
    "    print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "    filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "    vocab_dict = pkl.load(filehandler)\n",
    "    filehandler.close()\n",
    "    \n",
    "    for key in vocab_dict.keys():\n",
    "        pprint(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abf9a90-99d2-4ff9-b952-70de43b2e14a",
   "metadata": {},
   "source": [
    "# Global & Per-Arm feature embedding models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c74e2e7-23d4-4652-a54b-b9c335285856",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OOV_BUCKETS        = 1\n",
    "GLOBAL_EMBEDDING_SIZE  = 16\n",
    "MV_EMBEDDING_SIZE      = 32 #32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e51dd01f-918e-484c-a470-15b64aea776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test emb models\n",
    "for i in range(1):\n",
    "    \n",
    "    iterator = iter(train_dataset.batch(1))\n",
    "    data = next(iterator)\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e30c3ecb-cf5a-4822-8b2d-32c1aac898b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.perarm_features.emb_features.EmbeddingModel at 0x7ff2bb052590>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.perarm_features import emb_features as emb_features\n",
    "\n",
    "embs = emb_features.EmbeddingModel(\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05aa3547-8d4a-4c07-99d7-d3eda127e366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL_DIM: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 64), dtype=float32, numpy=\n",
       "array([[-0.0184383 , -0.03894822,  0.00513189,  0.03321711,  0.03478311,\n",
       "        -0.04066921,  0.03618351, -0.00489004, -0.02246409, -0.01614964,\n",
       "        -0.00805875,  0.02650708, -0.04822195,  0.01572521,  0.03252577,\n",
       "        -0.00887423, -0.0120305 , -0.04590234, -0.04578064,  0.00227224,\n",
       "         0.0214457 , -0.0148605 ,  0.02696443,  0.01265207, -0.04214443,\n",
       "        -0.01604214, -0.043206  , -0.04495594,  0.014376  , -0.01676066,\n",
       "         0.00597216, -0.00401383,  0.00072857, -0.02916597,  0.00104284,\n",
       "         0.02768863, -0.03252157,  0.04648724, -0.02414525, -0.02835464,\n",
       "         0.02331436,  0.0498654 ,  0.0087239 , -0.02322137, -0.0423955 ,\n",
       "         0.03037107,  0.02202067, -0.02039803,  0.03746719, -0.00310605,\n",
       "        -0.0202341 , -0.02202946, -0.01585388,  0.02658557, -0.00865828,\n",
       "         0.0245355 , -0.00632703, -0.02612565, -0.02200326, -0.01381309,\n",
       "         0.02327615, -0.00941961,  0.01031157,  0.00667394]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_globals = embs._get_global_context_features(data)\n",
    "\n",
    "GLOBAL_DIM = test_globals.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"GLOBAL_DIM: {GLOBAL_DIM}\")\n",
    "\n",
    "test_globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab464f9c-8c5c-4710-acbf-6026e3f94a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER_ARM_DIM: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 64), dtype=float32, numpy=\n",
       "array([[-0.04602586, -0.03587122,  0.00030255, -0.00592788,  0.02938599,\n",
       "         0.03024001, -0.02551819, -0.01284537, -0.04472363, -0.02767679,\n",
       "         0.04128381, -0.01166994, -0.04724962,  0.03400481,  0.01376344,\n",
       "        -0.04117516, -0.02969636, -0.03938909, -0.00737112, -0.01792452,\n",
       "        -0.02786292, -0.03012486,  0.03586279,  0.04632575, -0.02388661,\n",
       "         0.03555742,  0.04626267,  0.00156311,  0.01962711, -0.04815055,\n",
       "         0.04863915, -0.02275487, -0.01470612, -0.00218835,  0.03149606,\n",
       "        -0.01080934,  0.0319992 ,  0.03259032, -0.02268947,  0.04576692,\n",
       "         0.01431593,  0.02255676,  0.02570519, -0.03895449,  0.02913688,\n",
       "         0.04866644,  0.02898869, -0.03645029, -0.00176028,  0.04871298,\n",
       "         0.02291036,  0.01141062, -0.02997943, -0.03081605, -0.00878236,\n",
       "        -0.01974301,  0.04062701,  0.04069677, -0.00850657,  0.00493377,\n",
       "        -0.02962869,  0.03197886, -0.0202675 , -0.02305681]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arms = embs._get_per_arm_features(data)\n",
    "\n",
    "PER_ARM_DIM = test_arms.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"PER_ARM_DIM: {PER_ARM_DIM}\")\n",
    "\n",
    "test_arms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e448de36-168b-487c-bcaa-91335a07dec9",
   "metadata": {},
   "source": [
    "# Sampling and reward functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f5b1bc-c0a4-4859-80e8-d9627102d24c",
   "metadata": {},
   "source": [
    "The preproccesing layers will ultimately feed the two sampling functions described below. These sampling functions will be used to create [trajectories](https://github.com/tensorflow/agents/blob/master/tf_agents/trajectories/trajectory.py#L36) (i.e., the training examples for our model)\n",
    "\n",
    "`global_context_sampling_fn`: \n",
    "* A function that outputs a random 1d array or list of ints or floats\n",
    "* This output is the global context. Its shape and type must be consistent across calls.\n",
    "\n",
    "`arm_context_sampling_fn`: \n",
    "* A function that outputs a random 1 array or list of ints or floats (same type as the output of `global_context_sampling_fn`). \n",
    "* This output is the per-arm context. Its shape must be consistent across calls.\n",
    "\n",
    "`reward_fn`: function takes the concatenation of a global and a per-arm feature, and outputs a possibly random reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b58bda81-3666-4745-addc-20c2204a650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE      = 128\n",
    "EVAL_BATCH_SIZE = 1\n",
    "NUM_ACTIONS     = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a848199-4867-4e3c-a2a3-dc353ff19b84",
   "metadata": {},
   "source": [
    "## Sampling global context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a69d014a-a912-44c1-8d3f-6e2502a43453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., -1.,  0., -1.,  0.,  0., -1.,  0.,  0.,  0.,  0.,\n",
       "        0., -1., -1., -1.,  0.,  0., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        0., -1., -1., -1.,  0., -1., -1.,  0.,  0., -1., -1.,  0., -1.,\n",
       "       -1.,  0., -1., -1.,  0.,  0.,  0., -1.,  0., -1., -1.,  0.,  0.,\n",
       "        0., -1., -1.,  0., -1., -1.,  0.,  0.,  0., -1.,  0., -1.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def example_global_context_sampling_fn():\n",
    "    # return np.random.randint(0, 10, [2])  # 2-dimensional global features.\n",
    "    return np.random.randint(-1, 1, [GLOBAL_DIM]).astype(np.float32)\n",
    "\n",
    "example_global_context_sampling_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6764bf5d-426b-4048-95a8-a18fa9868983",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_iterator = iter(train_dataset.batch(1).repeat())\n",
    "\n",
    "def global_context_sampling_fn():\n",
    "    \n",
    "    data = next(global_iterator)\n",
    "    \n",
    "    return embs._get_global_context_features(data)[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0ea939e-96c3-4682-a478-08352d928929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (64,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.0184383 , -0.03894822,  0.00513189,  0.03321711,  0.03478311,\n",
       "       -0.04066921,  0.03618351, -0.00489004, -0.02246409, -0.01614964,\n",
       "       -0.00805875,  0.02650708, -0.04822195,  0.01572521,  0.03252577,\n",
       "       -0.00887423, -0.0120305 , -0.04590234, -0.04578064,  0.00227224,\n",
       "        0.0214457 , -0.0148605 ,  0.02696443,  0.01265207, -0.04214443,\n",
       "       -0.01604214, -0.043206  , -0.04495594,  0.014376  , -0.01676066,\n",
       "        0.00597216, -0.00401383,  0.00072857, -0.02916597,  0.00104284,\n",
       "        0.02768863, -0.03252157,  0.04648724, -0.02414525, -0.02835464,\n",
       "        0.02331436,  0.0498654 ,  0.0087239 , -0.02322137, -0.0423955 ,\n",
       "        0.03037107,  0.02202067, -0.02039803,  0.03746719, -0.00310605,\n",
       "       -0.0202341 , -0.02202946, -0.01585388,  0.02658557, -0.00865828,\n",
       "        0.0245355 , -0.00632703, -0.02612565, -0.02200326, -0.01381309,\n",
       "        0.02327615, -0.00941961,  0.01031157,  0.00667394], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_global_sampling = global_context_sampling_fn()\n",
    "print(f\"shape: {test_global_sampling.shape}\")\n",
    "\n",
    "test_global_sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbd1a57-aad1-4929-ae9f-0f2e7ea6c49f",
   "metadata": {},
   "source": [
    "## Sampling arm context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ddfb64e-f139-44ab-a60d-b91f4d13a89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  2.,  1.,  2., -2., -1.,  2.,  2.,  0.,  1., -1.,  2.,\n",
       "        1., -2., -2., -2., -1.,  0.,  1.,  2., -1., -1.,  2., -2.,  0.,\n",
       "       -1., -2., -2.,  1.,  1.,  0., -2.,  1.,  2.,  0.,  1.,  1., -1.,\n",
       "       -1.,  0., -2.,  2.,  0.,  0., -2., -2., -1., -1.,  0., -1.,  1.,\n",
       "        0., -2.,  0., -1.,  0.,  0., -2., -1., -1.,  1.,  2.,  2.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def example_arm_context_sampling_fn():\n",
    "    # return np.random.randint(-3, 4, [3])  # 3-dimensional arm features.\n",
    "    return np.random.randint(-2, 3, [PER_ARM_DIM]).astype(np.float32)\n",
    "\n",
    "example_arm_context_sampling_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "932b3267-78a1-4244-85f6-92726ad132ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "arm_iterator = iter(train_dataset.batch(1).repeat())\n",
    "# arm_iterator = iter(train_dataset.repeat())\n",
    "\n",
    "def arm_context_sampling_fn():\n",
    "    \n",
    "    data = next(arm_iterator)\n",
    "    \n",
    "    return embs._get_per_arm_features(data)[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9a58863-a639-44a1-a53e-d4e299e9ec94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (64,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.04602586, -0.03587122,  0.00030255, -0.00592788,  0.02938599,\n",
       "        0.03024001, -0.02551819, -0.01284537, -0.04472363, -0.02767679,\n",
       "        0.04128381, -0.01166994, -0.04724962,  0.03400481,  0.01376344,\n",
       "       -0.04117516, -0.02969636, -0.03938909, -0.00737112, -0.01792452,\n",
       "       -0.02786292, -0.03012486,  0.03586279,  0.04632575, -0.02388661,\n",
       "        0.03555742,  0.04626267,  0.00156311,  0.01962711, -0.04815055,\n",
       "        0.04863915, -0.02275487, -0.01470612, -0.00218835,  0.03149606,\n",
       "       -0.01080934,  0.0319992 ,  0.03259032, -0.02268947,  0.04576692,\n",
       "        0.01431593,  0.02255676,  0.02570519, -0.03895449,  0.02913688,\n",
       "        0.04866644,  0.02898869, -0.03645029, -0.00176028,  0.04871298,\n",
       "        0.02291036,  0.01141062, -0.02997943, -0.03081605, -0.00878236,\n",
       "       -0.01974301,  0.04062701,  0.04069677, -0.00850657,  0.00493377,\n",
       "       -0.02962869,  0.03197886, -0.0202675 , -0.02305681], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arm_sampling = arm_context_sampling_fn()\n",
    "print(f\"shape: {test_arm_sampling.shape}\")\n",
    "\n",
    "test_arm_sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70ee40b-eb02-47e8-ab8a-00a1ee6c1891",
   "metadata": {},
   "source": [
    "### Reward function \n",
    "\n",
    "> compute the dot product between global user context features and arm context features\n",
    "\n",
    "In this environment, the reward function will take as input the concatenation of the global and arm features generated from the provided sampling functions. See it used in the environment's `_apply_action()` function [here](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/environments/stationary_stochastic_per_arm_py_environment.py#L170C18-L170C28)\n",
    "\n",
    "```python\n",
    "feat_concat = np.concatenate((test_global_sampling, test_arm_sampling))\n",
    "reward = np.dot(feat_concat[:GLOBAL_DIM], feat_concat[PER_ARM_DIM:])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2cc4b52c-b47a-4bae-8c4e-44bfe5cc8280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0184383 , -0.03894822,  0.00513189,  0.03321711,  0.03478311,\n",
       "       -0.04066921,  0.03618351, -0.00489004, -0.02246409, -0.01614964,\n",
       "       -0.00805875,  0.02650708, -0.04822195,  0.01572521,  0.03252577,\n",
       "       -0.00887423, -0.0120305 , -0.04590234, -0.04578064,  0.00227224,\n",
       "        0.0214457 , -0.0148605 ,  0.02696443,  0.01265207, -0.04214443,\n",
       "       -0.01604214, -0.043206  , -0.04495594,  0.014376  , -0.01676066,\n",
       "        0.00597216, -0.00401383,  0.00072857, -0.02916597,  0.00104284,\n",
       "        0.02768863, -0.03252157,  0.04648724, -0.02414525, -0.02835464,\n",
       "        0.02331436,  0.0498654 ,  0.0087239 , -0.02322137, -0.0423955 ,\n",
       "        0.03037107,  0.02202067, -0.02039803,  0.03746719, -0.00310605,\n",
       "       -0.0202341 , -0.02202946, -0.01585388,  0.02658557, -0.00865828,\n",
       "        0.0245355 , -0.00632703, -0.02612565, -0.02200326, -0.01381309,\n",
       "        0.02327615, -0.00941961,  0.01031157,  0.00667394], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_global_sampling #[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e708a42-3edc-4335-adeb-657f207865f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04602586, -0.03587122,  0.00030255, -0.00592788,  0.02938599,\n",
       "        0.03024001, -0.02551819, -0.01284537, -0.04472363, -0.02767679,\n",
       "        0.04128381, -0.01166994, -0.04724962,  0.03400481,  0.01376344,\n",
       "       -0.04117516, -0.02969636, -0.03938909, -0.00737112, -0.01792452,\n",
       "       -0.02786292, -0.03012486,  0.03586279,  0.04632575, -0.02388661,\n",
       "        0.03555742,  0.04626267,  0.00156311,  0.01962711, -0.04815055,\n",
       "        0.04863915, -0.02275487, -0.01470612, -0.00218835,  0.03149606,\n",
       "       -0.01080934,  0.0319992 ,  0.03259032, -0.02268947,  0.04576692,\n",
       "        0.01431593,  0.02255676,  0.02570519, -0.03895449,  0.02913688,\n",
       "        0.04866644,  0.02898869, -0.03645029, -0.00176028,  0.04871298,\n",
       "        0.02291036,  0.01141062, -0.02997943, -0.03081605, -0.00878236,\n",
       "       -0.01974301,  0.04062701,  0.04069677, -0.00850657,  0.00493377,\n",
       "       -0.02962869,  0.03197886, -0.0202675 , -0.02305681], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arm_sampling #[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c65a5e6-24e9-417d-a747-6aed423adc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_PARAM = list(np.random.randint(0, 10, [GLOBAL_DIM + PER_ARM_DIM]))\n",
    "\n",
    "class LinearNormalReward(object):\n",
    "    def __init__(self, theta):\n",
    "        self.theta = theta\n",
    "\n",
    "    def __call__(self, x):\n",
    "        mu = np.dot(x, self.theta)\n",
    "        return np.random.normal(mu, 1)\n",
    "    \n",
    "reward_fn = LinearNormalReward(HIDDEN_PARAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4bb435-caad-487e-afb7-212595b72a83",
   "metadata": {},
   "source": [
    "## Initialize environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7e89c02-e871-4f0a-8781-8107e35ef243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE      : 128\n",
      "EVAL_BATCH_SIZE : 1\n",
      "NUM_ACTIONS     : 20\n",
      "GLOBAL_DIM      : 64\n",
      "PER_ARM_DIM     : 64\n"
     ]
    }
   ],
   "source": [
    "print(f\"BATCH_SIZE      : {BATCH_SIZE}\")\n",
    "print(f\"EVAL_BATCH_SIZE : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"NUM_ACTIONS     : {NUM_ACTIONS}\")\n",
    "print(f\"GLOBAL_DIM      : {GLOBAL_DIM}\")\n",
    "print(f\"PER_ARM_DIM     : {PER_ARM_DIM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ccca2db4-712a-4c0b-8dab-013ae9508553",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_arm_py_env = p_a_env.StationaryStochasticPerArmPyEnvironment(\n",
    "    global_context_sampling_fn=global_context_sampling_fn,\n",
    "    arm_context_sampling_fn=arm_context_sampling_fn,\n",
    "    max_num_actions=NUM_ACTIONS,\n",
    "    reward_fn=reward_fn,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "per_arm_tf_env = tf_py_environment.TFPyEnvironment(per_arm_py_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed2b460f-e696-46c2-b87a-091df2698f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rewards after taking an action:  tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# print('observation spec: ', per_arm_tf_env.observation_spec())\n",
    "# print('\\nAn observation: ', per_arm_tf_env.reset().observation)\n",
    "\n",
    "action = tf.zeros(BATCH_SIZE, dtype=tf.int32)\n",
    "time_step = per_arm_tf_env.step(action)\n",
    "print('\\nRewards after taking an action: ', time_step.reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17aadc6e-7a03-4401-9457-0769ce8d83e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_spec = per_arm_tf_env.observation_spec()\n",
    "# observation_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a421768-8df4-496d-9b79-16138f2c445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step_spec = ts.time_step_spec(observation_spec)\n",
    "# time_step_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b84d293b-835a-4512-99bb-c9c956bf3904",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    dtype=tf.int32, \n",
    "    shape=(), \n",
    "    minimum=0, \n",
    "    maximum=NUM_ACTIONS - 1\n",
    ")\n",
    "# action_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44e3199-8d32-4ca8-ab1d-ae1c246d3597",
   "metadata": {},
   "source": [
    "## Define Agent Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5eac943-be90-4000-a4ab-c01b0849f4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'common_layers': [16, 8],\n",
      " 'epsilon': 0.01,\n",
      " 'eval_batch_size': 1,\n",
      " 'global_layers': [64, 32, 16],\n",
      " 'learning_rate': 0.05,\n",
      " 'model_type': 'NeuralLinUCB',\n",
      " 'network_type': 'commontower',\n",
      " 'num_actions': 20,\n",
      " 'per_arm_layers': [64, 32, 16]}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Agents\n",
    "# ================================\n",
    "AGENT_TYPE      = 'NeuralLinUCB' # 'LinUCB' | 'LinTS |, 'epsGreedy' | 'NeuralLinUCB'\n",
    "\n",
    "# Parameters for linear agents (LinUCB and LinTS).\n",
    "AGENT_ALPHA     = 0.1\n",
    "\n",
    "# Parameters for neural agents (NeuralEpsGreedy and NerualLinUCB).\n",
    "EPSILON         = 0.01\n",
    "LR              = 0.05\n",
    "\n",
    "# Parameters for NeuralLinUCB\n",
    "ENCODING_DIM    = 1\n",
    "EPS_PHASE_STEPS = 1000\n",
    "\n",
    "# ================================\n",
    "# Agent's Preprocess Network\n",
    "# ================================\n",
    "GLOBAL_LAYERS   = [64, 32, 16] # beginning should be of size: GLOBAL_DIM\n",
    "ARM_LAYERS      = [64, 32, 16] # beginning should be of size: PER_ARM_DIM\n",
    "COMMON_LAYERS   = [16, 8]\n",
    "\n",
    "NETWORK_TYPE    = \"dotproduct\" # 'dotproduct' | 'commontower'\n",
    "\n",
    "if AGENT_TYPE == 'NeuralLinUCB':\n",
    "    NETWORK_TYPE = 'commontower'\n",
    "    ENCODING_DIM = COMMON_LAYERS[-1]\n",
    "\n",
    "HPARAMS = {  # TODO - streamline and consolidate\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"eval_batch_size\" : EVAL_BATCH_SIZE,\n",
    "    \"num_actions\": NUM_ACTIONS,\n",
    "    \"model_type\": AGENT_TYPE,\n",
    "    \"network_type\": NETWORK_TYPE,\n",
    "    \"global_layers\": GLOBAL_LAYERS,\n",
    "    \"per_arm_layers\": ARM_LAYERS,\n",
    "    \"common_layers\": COMMON_LAYERS,\n",
    "    \"learning_rate\": LR,\n",
    "    \"epsilon\": EPSILON,\n",
    "}\n",
    "pprint(HPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d45cb370-b6d5-46d3-afc5-238d9ef45656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent: neural_linucb_agent\n",
      "Network: commontower\n"
     ]
    }
   ],
   "source": [
    "from src.perarm_features import agent_factory as agent_factory\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "    agent_type = AGENT_TYPE,\n",
    "    network_type = NETWORK_TYPE,\n",
    "    time_step_spec = time_step_spec,\n",
    "    action_spec = action_spec,\n",
    "    observation_spec=observation_spec,\n",
    "    global_layers = GLOBAL_LAYERS,\n",
    "    arm_layers = ARM_LAYERS,\n",
    "    common_layers = COMMON_LAYERS,\n",
    "    agent_alpha = AGENT_ALPHA,\n",
    "    learning_rate = LR,\n",
    "    epsilon = EPSILON,\n",
    "    train_step_counter = global_step,\n",
    "    output_dim = ENCODING_DIM,\n",
    "    eps_phase_steps = EPS_PHASE_STEPS,\n",
    "    summarize_grads_and_vars = True,\n",
    "    debug_summaries = True\n",
    ")\n",
    "      \n",
    "# agent.initialize()\n",
    "print(f'agent: {agent.name}')\n",
    "\n",
    "# if network:\n",
    "#     print(f\"Network: {network}\")\n",
    "\n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {NETWORK_TYPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6be8938-f35f-4858-895b-1a7f7d13a7cd",
   "metadata": {},
   "source": [
    "### The Flow of Training Data\n",
    "\n",
    "look at the data specification in the agent. The training_data_spec attribute of the agent specifies what elements and structure the training data should have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82761ce9-3392-4253-a3f2-ad2c3d300040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data spec:  Trajectory(\n",
      "{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(19, dtype=int32)),\n",
      " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
      " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None)}),\n",
      " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(20,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None)),\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n"
     ]
    }
   ],
   "source": [
    "print('training data spec: ', agent.training_data_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ce10bdf3-7274-484b-8f36-021b0c5be062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _all_rewards(observation, hidden_param):\n",
    "    \"\"\"Outputs rewards for all actions, given an observation.\"\"\"\n",
    "    hidden_param = tf.cast(hidden_param, dtype=tf.float32)\n",
    "    global_obs = observation[bandit_spec_utils.GLOBAL_FEATURE_KEY]\n",
    "    per_arm_obs = observation[bandit_spec_utils.PER_ARM_FEATURE_KEY]\n",
    "    num_actions = tf.shape(per_arm_obs)[1]\n",
    "    tiled_global = tf.tile(\n",
    "        tf.expand_dims(global_obs, axis=1), [1, num_actions, 1]\n",
    "    )\n",
    "    concatenated = tf.concat([tiled_global, per_arm_obs], axis=-1)\n",
    "    rewards = tf.linalg.matvec(concatenated, hidden_param)\n",
    "    return rewards\n",
    "\n",
    "def optimal_reward(observation):\n",
    "    \"\"\"\n",
    "    Outputs the maximum expected reward \n",
    "    for every element in the batch.\n",
    "    \"\"\"\n",
    "    return tf.reduce_max(_all_rewards(observation, HIDDEN_PARAM), axis=1)\n",
    "\n",
    "regret_metric = tf_bandit_metrics.RegretMetric(optimal_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e9fc119-2cc8-47a1-a7bf-f6a03c95f6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_action(observation, hidden_param):\n",
    "    \n",
    "    return tf.argmax(\n",
    "        _all_rewards(observation, hidden_param), axis=1, output_type=tf.int32\n",
    "    )\n",
    "\n",
    "optimal_action_fn = functools.partial(\n",
    "    optimal_action, hidden_param=HIDDEN_PARAM\n",
    ")\n",
    "\n",
    "suboptimal_arms_metric = tf_bandit_metrics.SuboptimalArmsMetric(\n",
    "    optimal_action_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e951e25-2a2f-4685-a878-432a8836c43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf_agents.bandits.metrics.tf_metrics.RegretMetric at 0x7ff2267f1ea0>,\n",
       " <tf_agents.bandits.metrics.tf_metrics.SuboptimalArmsMetric at 0x7ff2267e3a00>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = [regret_metric, suboptimal_arms_metric]\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ad9c4c-ab48-4158-b172-3dd0ddcfb131",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "302564b4-e1d9-4cba-9b5b-bf9db252723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.per_arm_rl import trainer_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6783f164-c1e0-4e14-8878-0c3a31c227ce",
   "metadata": {},
   "source": [
    "## Vertex AI Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf761d34-69d9-400a-a554-ccec38ab5764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : 02-perarm-stationary-env-rec-bandits-v2\n",
      "RUN_NAME          : run-20240214-171810\n",
      "\n",
      "BASE_OUTPUT_DIR   : gs://rec-bandits-v2-hybrid-vertex-bucket/02-perarm-stationary-env-rec-bandits-v2/run-20240214-171810\n",
      "LOG_DIR           : gs://rec-bandits-v2-hybrid-vertex-bucket/02-perarm-stationary-env-rec-bandits-v2/run-20240214-171810/logs\n",
      "ROOT_DIR          : gs://rec-bandits-v2-hybrid-vertex-bucket/02-perarm-stationary-env-rec-bandits-v2/run-20240214-171810/root\n",
      "ARTIFACTS_DIR     : gs://rec-bandits-v2-hybrid-vertex-bucket/02-perarm-stationary-env-rec-bandits-v2/run-20240214-171810/artifacts\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME   = f'02-perarm-stationary-env-{PREFIX}'\n",
    "\n",
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "# aiplatform.init(\n",
    "#     project=PROJECT_ID,\n",
    "#     location=REGION,\n",
    "#     experiment=EXPERIMENT_NAME\n",
    "# )\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac54af0-d8ab-4bef-b1f3-266e9a15bd6f",
   "metadata": {},
   "source": [
    "### Create TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "598e3eee-e8eb-4082-8160-67edf47ff7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_TENSORBOARD = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "540cd50a-8399-4893-92f4-6b82f2208588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TB_RESOURCE_NAME : projects/934903580331/locations/us-central1/tensorboards/2787486276784226304\n",
      "TB display name  : 02-perarm-stationary-env-rec-bandits-v2\n",
      "TB_ID            : 2787486276784226304\n"
     ]
    }
   ],
   "source": [
    "if NEW_TENSORBOARD:\n",
    "    # create new TB instance\n",
    "    TENSORBOARD_DISPLAY_NAME=f\"{EXPERIMENT_NAME}\"\n",
    "\n",
    "    tensorboard = aiplatform.Tensorboard.create(\n",
    "        display_name=TENSORBOARD_DISPLAY_NAME\n",
    "        , project=PROJECT_ID\n",
    "        , location=REGION\n",
    "    )\n",
    "\n",
    "    TB_RESOURCE_NAME = tensorboard.resource_name\n",
    "else:\n",
    "    # use existing TB instance\n",
    "    # TB_RESOURCE_NAME = 'projects/934903580331/locations/us-central1/tensorboards/XXXXXXX' # TODO\n",
    "    tensorboard = aiplatform.Tensorboard(\n",
    "        tensorboard_name=TB_RESOURCE_NAME\n",
    "    )\n",
    "\n",
    "TB_ID = TB_RESOURCE_NAME.split('/')[-1]\n",
    "\n",
    "print(f\"TB_RESOURCE_NAME : {TB_RESOURCE_NAME}\")\n",
    "print(f\"TB display name  : {tensorboard.display_name}\")\n",
    "print(f\"TB_ID            : {TB_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa3a43c-a19f-4775-a653-3784d9ac5922",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Trainer loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "daa54d53-48cf-4b15-9416-7d820ed77a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME,\n",
    "    # experiment_tensorboard=TB_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4fcb892f-6a71-4c16-9d60-6392f4cf9e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG_INTERVAL: 5\n"
     ]
    }
   ],
   "source": [
    "TRAINING_LOOPS = 50\n",
    "STEPS_PER_LOOP = 1\n",
    "LOG_INTERVAL = TRAINING_LOOPS // 5\n",
    "\n",
    "print(f'LOG_INTERVAL: {LOG_INTERVAL}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5d4bf3c5-139a-4769-a0b8-0f558a68ab03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf_agents.bandits.metrics.tf_metrics.RegretMetric at 0x7ff2267f1ea0>,\n",
       " <tf_agents.bandits.metrics.tf_metrics.SuboptimalArmsMetric at 0x7ff2267e3a00>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f77ad7f4-3ef3-42a0-9da3-3846f7d48730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0: train loss = 4.880000114440918\n",
      "step = 10: train loss = 5.769999980926514\n",
      "step = 20: train loss = 3.009999990463257\n",
      "step = 30: train loss = 1.809999942779541\n",
      "step = 40: train loss = 1.4900000095367432\n",
      "train runtime_mins: 17\n"
     ]
    }
   ],
   "source": [
    "#start the timer and training\n",
    "start_time = time.time()\n",
    "\n",
    "trainer_baseline.train(\n",
    "    # root_dir=LOG_DIR,\n",
    "    artifact_dir=ARTIFACTS_DIR,\n",
    "    log_dir=LOG_DIR,\n",
    "    agent=agent,\n",
    "    environment=per_arm_tf_env,\n",
    "    training_loops=TRAINING_LOOPS,\n",
    "    steps_per_loop=STEPS_PER_LOOP,\n",
    "    additional_metrics=metrics,\n",
    "    save_policy=False,\n",
    "    log_interval=LOG_INTERVAL\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"train runtime_mins: {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92ab2c5-26ea-4028-a965-c8292249511f",
   "metadata": {},
   "source": [
    "## Evaluate trained policy with TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709c217f-cc9f-46f2-b9aa-3664c8484ec4",
   "metadata": {},
   "source": [
    "<img src=\"imgs/linear_ss_env_train.png\" \n",
    "     align=\"center\" \n",
    "     width=\"850\"\n",
    "     height=\"850\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "64c6bf86-417c-467b-adeb-b92d42915e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "78204efa-aec3-422b-b692-1aa4be4a86f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-723ca139c19bee85\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-723ca139c19bee85\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=$LOG_DIR "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e782f2-2beb-439a-85fd-e455f679ac09",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
