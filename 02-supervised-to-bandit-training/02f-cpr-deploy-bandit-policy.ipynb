{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a03307f-546e-485f-bf38-3f8acc0b4196",
   "metadata": {},
   "source": [
    "# Build custom container for Vertex Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "025a45dd-21a9-4110-9ca5-294ae0911feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/02-perarm-features-bandit\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "994fffc8-c58f-4dd0-97c2-7116d8ecda43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "# PREFIX = 'mabv1'\n",
    "VERSION        = \"v2\"                       # TODO\n",
    "PREFIX         = f'rec-bandits-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8cc89ad-d0da-4421-b4fd-b232e733bd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"rec-bandits-v2\"\n",
      "VERSION                  = \"v2\"\n",
      "\n",
      "BUCKET_NAME              = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "DATA_PATH_KFP_DEMO       = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data/kfp_demo_data/u.data\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_NAME    = \"mvlens_rec_bandits_v2\"\n",
      "BIGQUERY_TABLE_NAME      = \"training_dataset\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-rec-bandits-v2\"\n",
      "\n",
      "DOCKERNAME_01            = \"Dockerfile_train_my_perarm_env\"\n",
      "IMAGE_NAME_01            = \"train-my-perarm-env-v2\"\n",
      "IMAGE_URI_01             = \"gcr.io/hybrid-vertex/train-my-perarm-env-v2\"\n",
      "\n",
      "DOCKERNAME_02            = \"Dockerfile_perarm_feats\"\n",
      "IMAGE_NAME_02            = \"train-perarm-feats-v2\"\n",
      "IMAGE_URI_02             = \"gcr.io/hybrid-vertex/train-perarm-feats-v2\"\n",
      "\n",
      "DOCKERNAME_03            = \"Dockerfile_ranking_bandit\"\n",
      "IMAGE_NAME_03            = \"train-rank-bandit-v2\"\n",
      "IMAGE_URI_03             = \"gcr.io/hybrid-vertex/train-rank-bandit-v2\"\n",
      "\n",
      "DOCKERNAME_04            = \"Dockerfile_train_mab_e2e\"\n",
      "IMAGE_NAME_04            = \"train-mab-e2e-v2\"\n",
      "IMAGE_URI_04             = \"gcr.io/hybrid-vertex/train-mab-e2e-v2\"\n",
      "\n",
      "DOCKERNAME_04_pred       = \"Dockerfile_pred_mab_e2e\"\n",
      "IMAGE_NAME_04_pred       = \"pred-mab-e2e-v2\"\n",
      "IMAGE_URI_04_pred        = \"gcr.io/hybrid-vertex/pred-mab-e2e-v2\"\n",
      "\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/local_docker_tfa\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d3ecb2a-f76a-4699-8a80-8e1ffeb86993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOCKERNAME_02_PRED = Dockerfile_predict_mab_02e\n",
      "REPOSITORY         = rl-movielens-rec-bandits-v2\n",
      "IMAGE_NAME_02_PRED = pred-perarm-feats-02e\n",
      "IMAGE_URI_02_PRED  = gcr.io/hybrid-vertex/pred-perarm-feats-02e\n",
      "REMOTE_IMAGE_NAME  = us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/pred-perarm-feats-02e\n"
     ]
    }
   ],
   "source": [
    "# # TODO incorporate to 00-env-setup\n",
    "# DOCKERNAME_02_PRED = 'Dockerfile_predict_mab_02e'\n",
    "# IMAGE_NAME_02_PRED = \"pred-perarm-feats-02e\"\n",
    "# IMAGE_URI_02_PRED  = f\"gcr.io/hybrid-vertex/{IMAGE_NAME_02_PRED}\"\n",
    "# REMOTE_IMAGE_NAME  = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE_NAME_02_PRED}\"\n",
    "\n",
    "# print(f\"DOCKERNAME_02_PRED = {DOCKERNAME_02_PRED}\")\n",
    "# print(f\"REPOSITORY         = {REPOSITORY}\")\n",
    "# print(f\"IMAGE_NAME_02_PRED = {IMAGE_NAME_02_PRED}\")\n",
    "# print(f\"IMAGE_URI_02_PRED  = {IMAGE_URI_02_PRED}\")\n",
    "# print(f\"REMOTE_IMAGE_NAME  = {REMOTE_IMAGE_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d25599-2994-41ac-8bee-e12f83e96561",
   "metadata": {},
   "source": [
    "run this in terminal from root to clear `__pycache__` files..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db2803f-08f5-415c-837c-8d5dccbd0250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find . | grep -E \"(/__pycache__$|\\.pyc$|\\.pyo$)\" | xargs rm -rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4412a2fd-fab3-4ef3-9e77-c5faa82a1380",
   "metadata": {},
   "source": [
    "### Setup credentials\n",
    "\n",
    "Setting up credentials is only required to run the custom serving container locally with GCS paths. Credentials set up is required to execute the `Predictor`'s `load` function, which downloads the model artifacts from Google Cloud Storage.\n",
    "\n",
    "To access Google Cloud Storage in your project, you'll need to set up credentials by using one of the following:\n",
    "\n",
    "1. User account\n",
    "2. Service account\n",
    "\n",
    "You can learn more about each of the above [here](https://cloud.google.com/docs/authentication#principals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0dd40b-c9df-49da-8469-45dfc3449b2e",
   "metadata": {},
   "source": [
    "Option 1: Use Google user credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606a9815-1abb-40e9-8455-27c2d9778baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gcloud auth application-default login\n",
    "# !gcloud auth login\n",
    "\n",
    "# USER_ACCOUNT = \"TODO_USER_GCP_LOGIN\"  # TODO - 00-env-setup\n",
    "\n",
    "# !gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
    "#     --member=user:$USER_ACCOUNT \\\n",
    "#     --role=roles/storage.admin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8140adb4-e859-4a70-8638-90cad1a4715c",
   "metadata": {},
   "source": [
    "Option 2: Use Google Service Account credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac8d414-ce5b-4bd8-bc72-be229e6a8a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gcloud services enable iam.googleapis.com\n",
    "# !gcloud auth login\n",
    "\n",
    "# !gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
    "#     --member=serviceAccount:$VERTEX_SA \\\n",
    "#     --role=roles/storage.admin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17288f10-218b-4c1a-a29e-5dd4c46c4392",
   "metadata": {},
   "source": [
    "Create credentials file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6a9eca-eb1d-4b14-af6c-ba6806f60e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/home/jupyter/tf_vertex_agents/src\"\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c10cabe0-1efa-43cb-a41c-9f430bf654a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREDENTIALS_FILE = \"./credentials.json\"\n",
    "\n",
    "# !gcloud iam service-accounts keys create $CREDENTIALS_FILE \\\n",
    "#     --iam-account=$VERTEX_SA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785f880d-1b3e-4cae-82ba-ff185f923771",
   "metadata": {},
   "source": [
    "### Create Artifact Repository\n",
    "If you don't have an existing artifact repository, create one using the gcloud command below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54f30fbc-3801-4363-a70b-df4ca753e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gcloud artifacts repositories create $REPOSITORY --repository-format=docker --location=$LOCATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309d6d6d-8ca3-44fa-89d6-9ffd10e00ecd",
   "metadata": {},
   "source": [
    "# Custom Prediction Routine (CPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25dbba3-6b5f-434f-967a-b48b32eae0b8",
   "metadata": {},
   "source": [
    "### references"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ee1c9e-8e73-4630-89a3-9993d83ebc52",
   "metadata": {},
   "source": [
    "* [src code](https://github.com/googleapis/python-aiplatform/tree/main/google/cloud/aiplatform/prediction)\n",
    "* [docs](https://cloud.google.com/vertex-ai/docs/predictions/custom-prediction-routines#run_the_container_locally_optional)\n",
    "* code examples\n",
    "  * [SDK_Custom_Predict_and_Handler_SDK_Integration](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/prediction/custom_prediction_routines/SDK_Custom_Predict_and_Handler_SDK_Integration.ipynb)\n",
    "  * [SDK_Custom_Preprocess](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/ef8b70db32813b8a2f128ab5ef1d170aea739e7f/notebooks/community/prediction/custom_prediction_routines/SDK_Custom_Preprocess.ipynb)\n",
    "  \n",
    "**In the built image, user provided files will be copied as follows:**\n",
    "\n",
    "```\n",
    "    container_workdir/\n",
    "    |-- predictor.py\n",
    "    |-- requirements.txt\n",
    "    |-- user_code/\n",
    "    |   |-- utils.py\n",
    "    |   |-- custom_package.tar.gz\n",
    "    |   |-- ...\n",
    "    |-- ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013c1afe-472a-4015-8f32-ed2997517d7b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6f18d9b2-5ed1-4e88-9f00-09db736567b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from pprint import pprint\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ[\"PROJECT_ID\"]=PROJECT_ID\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import storage\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud.aiplatform.utils import prediction_utils\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "# this repo\n",
    "# from per_arm_rl import data_utils as data_utils\n",
    "# # from per_arm_rl import data_config\n",
    "# from per_arm_rl import train_utils as train_utils\n",
    "# from pred import emb_features_pred as emb_features\n",
    "# from perarm_features import reward_factory as reward_factory\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from src.per_arm_rl import data_utils\n",
    "from src.per_arm_rl import data_config\n",
    "from src.per_arm_rl import train_utils as train_utils\n",
    "\n",
    "from src.perarm_features import reward_factory as reward_factory\n",
    "from src.perarm_features import emb_features as emb_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe405f4-795d-41fd-94a4-1ace7901e44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbe1fe5-efca-45fa-8b52-fdd4d08e2608",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec94222f-1d0d-48af-9539-6de0e46d0529",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = storage.Client(project=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e116c56-c1f4-4559-9c8b-6bef421e17f7",
   "metadata": {},
   "source": [
    "## Set vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f08dafa5-2336-47c0-b5b4-5124651fd582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/src\n"
     ]
    }
   ],
   "source": [
    "path=\"/home/jupyter/tf_vertex_agents/src\"\n",
    "os.chdir(path)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f01d08c-416f-4797-92c2-b4aca27f07ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY             = rl-movielens-rec-bandits-v2\n",
      "IMAGE_NAME_02_PRED_CPR = cpr-perarm-bandit-02e\n",
      "IMAGE_URI_02_PRED_CPR  = gcr.io/hybrid-vertex/cpr-perarm-bandit-02e\n",
      "REMOTE_IMAGE_NAME_CPR  = us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/cpr-perarm-bandit-02e\n"
     ]
    }
   ],
   "source": [
    "# DOCKERNAME_02_PRED_CPR = 'Dockerfile_cpr'\n",
    "IMAGE_NAME_02_PRED_CPR = \"cpr-perarm-bandit-02e\"\n",
    "IMAGE_URI_02_PRED_CPR  = f\"gcr.io/hybrid-vertex/{IMAGE_NAME_02_PRED_CPR}\"\n",
    "REMOTE_IMAGE_NAME_CPR  = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE_NAME_02_PRED_CPR}\"\n",
    "\n",
    "print(f\"REPOSITORY             = {REPOSITORY}\")\n",
    "# print(f\"DOCKERNAME_02_PRED_CPR = {DOCKERNAME_02_PRED_CPR}\")\n",
    "print(f\"IMAGE_NAME_02_PRED_CPR = {IMAGE_NAME_02_PRED_CPR}\")\n",
    "print(f\"IMAGE_URI_02_PRED_CPR  = {IMAGE_URI_02_PRED_CPR}\")\n",
    "print(f\"REMOTE_IMAGE_NAME_CPR  = {REMOTE_IMAGE_NAME_CPR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecdf1df-95f9-4352-8ec3-5121f904d9a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## (Optional) Local inference example\n",
    "\n",
    "> Before writting the CPR container, let's make sure we understand the steps we need to replicate in that container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dd2c65-7501-4c12-a3c1-562b0ef52caa",
   "metadata": {},
   "source": [
    "### Create test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "638de305-f0b8-4f09-9c02-10252b00a6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_VOCAB_FILENAME = './vocab_dict.pkl'\n",
    "\n",
    "filehandler = open(f\"{LOCAL_VOCAB_FILENAME}\", 'rb')\n",
    "vocab_dict = pkl.load(filehandler)\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b72edb37-3503-4284-afe0-ee5b5676bc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = \"val\"\n",
    "eval_batch_size = 1\n",
    "NUM_EVAL_STEPS = 20\n",
    "\n",
    "val_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        val_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "val_dataset = tf.data.TFRecordDataset(val_files)\n",
    "val_dataset = val_dataset.map(data_utils.parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1dc1388-8ea4-4544-96dc-d38720a064a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.perarm_features.emb_features.EmbeddingModel at 0x7f57e2c98ca0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_OOV_BUCKETS        = 1\n",
    "GLOBAL_EMBEDDING_SIZE  = 16\n",
    "MV_EMBEDDING_SIZE      = 32 #32\n",
    "\n",
    "embs = emb_features.EmbeddingModel(\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "725574fd-a506-46ee-8f97-5353c25ccdd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f7c635ae890>"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ARTIFACTS_DIR = \"gs://rec-bandits-v2-hybrid-vertex-bucket/02-scale-compare-v2/run-20231115-094131/artifacts\"\n",
    "\n",
    "test_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(ARTIFACTS_DIR, load_specs_from_pbtxt=True)\n",
    "test_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735a3cae-9a16-40b7-8952-5fc848452f66",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Inference (policy action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1291,
   "id": "85896566-5ec9-4471-99d1-9feb69277fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec={'bucketized_user_age': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'movie_genres': TensorSpec(shape=(None, 1), dtype=tf.int64, name=None), 'movie_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'timestamp': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'user_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_occupation_text': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_rating': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 1291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INFER_SIZE      = 1\n",
    "EVAL_BATCH_SIZE = 1\n",
    "NUM_EVAL_STEPS  = 5\n",
    "\n",
    "PER_ARM_DIM     = 64\n",
    "GLOBAL_DIM      = 64\n",
    "\n",
    "eval_ds = val_dataset.batch(EVAL_BATCH_SIZE)\n",
    "eval_ds = eval_ds.take(NUM_EVAL_STEPS)\n",
    "eval_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1292,
   "id": "96d00e61-3650-4d7d-9d8e-4528eef92363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([2.4577115, 2.4577115], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([-2.09365617e-02,  1.48380436e-02,  4.38927449e-02, -1.62509568e-02,\n",
       "        4.12502177e-02, -1.96358319e-02,  1.89190395e-02, -1.97972544e-02,\n",
       "        1.07204206e-02, -2.90853623e-02, -5.21492958e-03, -4.96399291e-02,\n",
       "       -3.84666212e-02,  3.22810523e-02,  6.33295625e-03, -1.96670890e-02,\n",
       "       -1.56960599e-02,  3.25680114e-02,  1.57541893e-02, -3.18676122e-02,\n",
       "       -3.89801636e-02, -2.12526806e-02, -1.22037306e-02,  2.59828456e-02,\n",
       "        4.26850952e-02,  1.31589882e-02, -6.71111420e-03,  1.19521245e-02,\n",
       "       -7.05723837e-03,  1.45995654e-02, -8.55533034e-03, -3.35612185e-02,\n",
       "       -1.97723154e-02,  3.51027399e-03,  1.06675625e-02,  4.03297059e-02,\n",
       "        1.16081722e-02,  4.02562357e-02, -4.45134938e-05, -2.06905603e-03,\n",
       "       -4.74689975e-02,  5.20657375e-03, -6.95258379e-03, -3.94169688e-02,\n",
       "       -1.05543509e-02,  1.81756727e-02,  4.98946197e-02,  4.11993600e-02,\n",
       "       -1.63400881e-02,  3.66704501e-02, -4.86949831e-03, -2.38816738e-02,\n",
       "       -4.28798310e-02,  4.74128164e-02, -3.17555293e-02,  4.62534763e-02,\n",
       "        2.41130628e-02, -1.59375444e-02,  3.35972048e-02, -4.21392322e-02,\n",
       "       -3.32080610e-02, -4.41020019e-02, -4.24106829e-02,  6.56117126e-03],\n",
       "      dtype=float32)))"
      ]
     },
     "execution_count": 1292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "for x in eval_ds.take(INFER_SIZE):\n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "    \n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "    actual_reward = rewards.numpy()[0] # get actual reward\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [EVAL_BATCH_SIZE, PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = test_policy.action(trajectory_step)\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1334372e-c63d-4e91-b7c5-bece91e414d2",
   "metadata": {},
   "source": [
    "For the endpoint, we need the policy action (prediction) to be JSON serializable, so:\n",
    "* for `np.array` convert with `tolist()`\n",
    "* for integer wrap with `int()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1316,
   "id": "af6cd4b2-ae7a-4410-bce1-0e750555f1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandit_policy_type     : 1\n",
      "chosen_arm_features    : [-0.02093656174838543, 0.014838043600320816, 0.043892744928598404, -0.016250956803560257, 0.04125021770596504, -0.01963583193719387, 0.018919039517641068, -0.019797254353761673, 0.010720420628786087, -0.02908536233007908, -0.0052149295806884766, -0.049639929085969925, -0.038466621190309525, 0.0322810523211956, 0.006332956254482269, -0.019667088985443115, -0.01569605991244316, 0.032568011432886124, 0.01575418934226036, -0.0318676121532917, -0.038980163633823395, -0.02125268056988716, -0.012203730642795563, 0.025982845574617386, 0.042685095220804214, 0.013158988207578659, -0.006711114197969437, 0.011952124536037445, -0.00705723837018013, 0.014599565416574478, -0.008555330336093903, -0.03356121852993965, -0.01977231539785862, 0.0035102739930152893, 0.010667562484741211, 0.0403297059237957, 0.011608172208070755, 0.040256235748529434, -4.451349377632141e-05, -0.0020690560340881348, -0.04746899753808975, 0.0052065737545490265, -0.0069525837898254395, -0.03941696882247925, -0.010554350912570953, 0.018175672739744186, 0.04989461973309517, 0.04119936004281044, -0.016340088099241257, 0.03667045012116432, -0.004869498312473297, -0.02388167381286621, -0.04287983104586601, 0.04741281643509865, -0.03175552934408188, 0.04625347629189491, 0.024113062769174576, -0.015937544405460358, 0.033597204834222794, -0.04213923215866089, -0.03320806100964546, -0.04410200193524361, -0.04241068288683891, 0.006561171263456345]\n",
      "predicted_rewards_mean : [2.4577114582061768, 2.4577114582061768]\n",
      "action                 : 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"bandit_policy_type     : {prediction.info.bandit_policy_type[0]}\")\n",
    "print(f\"chosen_arm_features    : {prediction.info.chosen_arm_features.tolist()}\")\n",
    "print(f\"predicted_rewards_mean : {prediction.info.predicted_rewards_mean.tolist()}\")\n",
    "print(f\"action                 : {prediction.action.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ba9020-af08-4022-a307-fd3b8f7b2c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(prediction.info.chosen_arm_features)\n",
    "type(prediction.info.bandit_policy_type.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff0833c-dd65-40ee-9b65-76b637229388",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.info.bandit_policy_type[0]\n",
    "type(prediction.info.bandit_policy_type[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c994b9-cbbc-4792-9da6-f5aca57bf002",
   "metadata": {},
   "source": [
    "So we'll need to post-process the policy action (prediction) to a dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1320,
   "id": "e97ce5df-388a-41f2-aa9f-57f869e9b35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_DICT = {\n",
    "    \"bandit_policy_type\" : int(prediction.info.bandit_policy_type[0]),\n",
    "    \"chosen_arm_features\" : prediction.info.chosen_arm_features.tolist(),\n",
    "    \"predicted_rewards_mean\" : prediction.info.predicted_rewards_mean.tolist(),\n",
    "    \"action\" : int(prediction.action.tolist()),\n",
    "}\n",
    "# NEW_DICT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cac4de7-8198-4b10-aac5-dcda30ff076b",
   "metadata": {},
   "source": [
    "And, the final step of the CPR will be serialized with `json.dumps()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1321,
   "id": "9934faa2-70a2-4c73-b4be-ef5a78836193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"prediction\": {\"bandit_policy_type\": 1, \"chosen_arm_features\": [-0.02093656174838543, 0.014838043600320816, 0.043892744928598404, -0.016250956803560257, 0.04125021770596504, -0.01963583193719387, 0.018919039517641068, -0.019797254353761673, 0.010720420628786087, -0.02908536233007908, -0.0052149295806884766, -0.049639929085969925, -0.038466621190309525, 0.0322810523211956, 0.006332956254482269, -0.019667088985443115, -0.01569605991244316, 0.032568011432886124, 0.01575418934226036, -0.0318676121532917, -0.038980163633823395, -0.02125268056988716, -0.012203730642795563, 0.025982845574617386, 0.042685095220804214, 0.013158988207578659, -0.006711114197969437, 0.011952124536037445, -0.00705723837018013, 0.014599565416574478, -0.008555330336093903, -0.03356121852993965, -0.01977231539785862, 0.0035102739930152893, 0.010667562484741211, 0.0403297059237957, 0.011608172208070755, 0.040256235748529434, -4.451349377632141e-05, -0.0020690560340881348, -0.04746899753808975, 0.0052065737545490265, -0.0069525837898254395, -0.03941696882247925, -0.010554350912570953, 0.018175672739744186, 0.04989461973309517, 0.04119936004281044, -0.016340088099241257, 0.03667045012116432, -0.004869498312473297, -0.02388167381286621, -0.04287983104586601, 0.04741281643509865, -0.03175552934408188, 0.04625347629189491, 0.024113062769174576, -0.015937544405460358, 0.033597204834222794, -0.04213923215866089, -0.03320806100964546, -0.04410200193524361, -0.04241068288683891, 0.006561171263456345], \"predicted_rewards_mean\": [2.4577114582061768, 2.4577114582061768], \"action\": 0}}'"
      ]
     },
     "execution_count": 1321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_instance = json.dumps({\"prediction\": NEW_DICT})\n",
    "json_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "25bcafed-1dc9-451c-be1a-3065ed0a6d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([25.], dtype=float32)>,\n",
       " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[4]])>,\n",
       " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'211'], dtype=object)>,\n",
       " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([874948475])>,\n",
       " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'346'], dtype=object)>,\n",
       " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'other'], dtype=object)>,\n",
       " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>}"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c094c401-8067-47f0-8945-27f06a1b258d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### (optional) execute step-by-step\n",
    "\n",
    "> only needed if wanting to better understand dims/shapes etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "d2b857d6-71a4-4fb9-9e79-c83c3f1a04f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([25.], dtype=float32)>,\n",
       "  'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[4]])>,\n",
       "  'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'211'], dtype=object)>,\n",
       "  'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([874948475])>,\n",
       "  'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'346'], dtype=object)>,\n",
       "  'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'other'], dtype=object)>,\n",
       "  'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>},\n",
       " {'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([25.], dtype=float32)>,\n",
       "  'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[4]])>,\n",
       "  'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'211'], dtype=object)>,\n",
       "  'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([874948475])>,\n",
       "  'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'346'], dtype=object)>,\n",
       "  'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'other'], dtype=object)>,\n",
       "  'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>}]"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_list = [] \n",
    "\n",
    "for i in range(2):\n",
    "    \n",
    "    iterator = iter(val_dataset.batch(1))\n",
    "    data = next(iterator)\n",
    "    data_list.append(data)\n",
    "\n",
    "data\n",
    "# data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "24ca2ef2-f0d4-45f4-9561-b50996762500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_feat_infer = embs._get_global_context_features(data)\n",
    "print(f\"global_feat_infer.shape = {global_feat_infer.shape}\")\n",
    "\n",
    "arm_feat_infer = embs._get_per_arm_features(data)\n",
    "print(f\"arm_feat_infer.shape = {arm_feat_infer.shape}\")\n",
    "\n",
    "rewards = reward_factory._get_rewards(data)\n",
    "print(f\"rewards.numpy()[0] = {rewards.numpy()[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "6ed765f4-591c-4bcc-b37e-555a9334fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_arm = tf.zeros([1, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "# reshape arm features\n",
    "arm_feat_infer = tf.reshape(arm_feat_infer, [EVAL_BATCH_SIZE, PER_ARM_DIM]) # perarm_dim\n",
    "concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "\n",
    "# flatten global\n",
    "flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "# feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "329bf444-8a7e-48ce-9194-dc8f4d163ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "# get trajectory step for prediction\n",
    "def _get_pred_step(feature, reward_np):\n",
    "    \n",
    "    infer_step = ts.TimeStep(\n",
    "        tf.constant(ts.StepType.FIRST, dtype=tf.int32, shape=[],name='step_type'),\n",
    "        tf.constant(reward_np, dtype=tf.float32, shape=[], name='reward'),\n",
    "        tf.constant(1.0, dtype=tf.float32, shape=[], name='discount'),\n",
    "        feature\n",
    "    )\n",
    "    \n",
    "    return infer_step\n",
    "\n",
    "trajectory_step = _get_pred_step(feature, actual_reward)\n",
    "# trajectory_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "76965773-b4af-4e9d-905c-25bbfacad039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([2.4577115, 2.4577115], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([-2.09365617e-02,  1.48380436e-02,  4.38927449e-02, -1.62509568e-02,\n",
       "        4.12502177e-02, -1.96358319e-02,  1.89190395e-02, -1.97972544e-02,\n",
       "        1.07204206e-02, -2.90853623e-02, -5.21492958e-03, -4.96399291e-02,\n",
       "       -3.84666212e-02,  3.22810523e-02,  6.33295625e-03, -1.96670890e-02,\n",
       "       -1.56960599e-02,  3.25680114e-02,  1.57541893e-02, -3.18676122e-02,\n",
       "       -3.89801636e-02, -2.12526806e-02, -1.22037306e-02,  2.59828456e-02,\n",
       "        4.26850952e-02,  1.31589882e-02, -6.71111420e-03,  1.19521245e-02,\n",
       "       -7.05723837e-03,  1.45995654e-02, -8.55533034e-03, -3.35612185e-02,\n",
       "       -1.97723154e-02,  3.51027399e-03,  1.06675625e-02,  4.03297059e-02,\n",
       "        1.16081722e-02,  4.02562357e-02, -4.45134938e-05, -2.06905603e-03,\n",
       "       -4.74689975e-02,  5.20657375e-03, -6.95258379e-03, -3.94169688e-02,\n",
       "       -1.05543509e-02,  1.81756727e-02,  4.98946197e-02,  4.11993600e-02,\n",
       "       -1.63400881e-02,  3.66704501e-02, -4.86949831e-03, -2.38816738e-02,\n",
       "       -4.28798310e-02,  4.74128164e-02, -3.17555293e-02,  4.62534763e-02,\n",
       "        2.41130628e-02, -1.59375444e-02,  3.35972048e-02, -4.21392322e-02,\n",
       "       -3.32080610e-02, -4.41020019e-02, -4.24106829e-02,  6.56117126e-03],\n",
       "      dtype=float32)))"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = test_policy.action(trajectory_step)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8061a6e5-2c6f-44b4-892f-83369eb98c19",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### (optional) understand the pre-processing steps\n",
    "\n",
    "> this will be the global and arm sampling functions from `EmbeddingModel()` class in `src/../emb_features.py`\n",
    "\n",
    "```\n",
    "        self._embs = emb_features.EmbeddingModel(\n",
    "            vocab_dict = vocab_dict,\n",
    "            num_oov_buckets = num_oov_buckets,\n",
    "            global_emb_size = global_embedding_size,\n",
    "            mv_emb_size = mv_embedding_size,\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84847924-3a06-4dd7-b06d-7cd2d3f29576",
   "metadata": {},
   "source": [
    "This is the embbedding representation we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f2f3d7-9858-40d3-a333-1cb41b3861d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in eval_ds:\n",
    "    print(x[\"user_id\"])\n",
    "    print(embs.user_id_model(x[\"user_id\"]))\n",
    "    \n",
    "    break\n",
    "    \n",
    "# embs.user_id_model(tf.constant(TEST_INSTANCE['instances'][0]['user_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45532b2-bb75-4f4c-8e86-b366f501d769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_list[0]['user_id'].numpy()[0]\n",
    "# data_list[0]['user_occupation_text'].numpy()[0]\n",
    "# value_test = data_list[0]['movie_id'].numpy()[0]\n",
    "# type(data_list[0]['movie_id'].numpy()[0])\n",
    "# type(data_list[0]['user_rating'].numpy()[0])\n",
    "# type(data_list[0]['timestamp'].numpy()[0])\n",
    "# type(data_list[0]['movie_genres'].numpy()[0])\n",
    "# data_list[0]['movie_genres'].numpy().tolist()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54b1c45-f611-4ec3-ad36-0431b325f7a6",
   "metadata": {},
   "source": [
    "**sample test instance** (prediction request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e891ca7-a6f3-41aa-a897-51c7462e9ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_INSTANCE = {\n",
    "    \"instances\": [\n",
    "        {\n",
    "            'bucketized_user_age': 25.0,\n",
    "            'movie_genres': [4],\n",
    "            'movie_id': '211',\n",
    "            'timestamp': 874948475,\n",
    "            'user_id': '346',\n",
    "            'user_occupation_text': 'other',\n",
    "            'user_rating': 4.0\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "TEST_INSTANCE['instances']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4c1caf-5629-4777-a2ba-66dd54b388e8",
   "metadata": {},
   "source": [
    "**preprocessing steps to implement in CPR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29472d32-c1cd-40b8-a812-bd0a8079faa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rebuild_ex = {}\n",
    "\n",
    "for x in TEST_INSTANCE['instances']:\n",
    "    rebuild_ex['bucketized_user_age'] = tf.constant([x[\"bucketized_user_age\"]], dtype=tf.float32)\n",
    "    rebuild_ex['movie_genres'] = tf.constant([x[\"movie_genres\"]], dtype=tf.int64)\n",
    "    rebuild_ex['movie_id'] = tf.constant([x[\"movie_id\"]], dtype=tf.string)\n",
    "    rebuild_ex['timestamp'] = tf.constant([x[\"timestamp\"]], dtype=tf.int64)\n",
    "    rebuild_ex['user_id'] = tf.constant([x[\"user_id\"]], dtype=tf.string)\n",
    "    rebuild_ex['user_occupation_text'] = tf.constant([x[\"user_occupation_text\"]], dtype=tf.string)\n",
    "    rebuild_ex['user_rating'] = tf.constant([x[\"user_rating\"]], dtype=tf.float32)\n",
    "    print(embs.user_id_model(rebuild_ex['user_id']))\n",
    "    \n",
    "# rebuild_ex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32373b5d-74cf-4416-bd41-4adebba2c597",
   "metadata": {},
   "source": [
    "**...which will be converted to embeddings like this:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493b9959-41a5-4fe5-8db0-48f51ea73416",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embs.user_id_model(rebuild_ex['user_id']).numpy())\n",
    "print(embs.user_age_model(rebuild_ex['bucketized_user_age']).numpy())\n",
    "print(embs.user_occ_model(rebuild_ex['user_occupation_text']).numpy())\n",
    "print(embs.user_ts_model(rebuild_ex['timestamp']).numpy())\n",
    "print(embs.mv_id_model(rebuild_ex['movie_id']).numpy())\n",
    "print(embs.mv_gen_model(rebuild_ex['movie_genres']).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60ba21f-2a4d-4484-8ab4-5e85c1a7240c",
   "metadata": {},
   "source": [
    "### (optional) understand CPR's model download steps\n",
    "\n",
    "> one of the steps in our CPR will be to download our trained policy with `prediction_utils.download_model_artifacts()`; let's see what that looks like locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27d16d14-d697-4c7a-a9b9-d1647d32ecdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/src\n"
     ]
    }
   ],
   "source": [
    "path=\"/home/jupyter/tf_vertex_agents/src\"\n",
    "os.chdir(path)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1573ec1-f45d-4a34-be21-27647ee79347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing\n",
    "LOCAL_MODEL_ARTIFACTS_DIR = \"local_model_dir\"\n",
    "\n",
    "! rm -rf ./$LOCAL_MODEL_ARTIFACTS_DIR\n",
    "! mkdir ./$LOCAL_MODEL_ARTIFACTS_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40ffc70-3e0e-4039-9a70-450d107ca181",
   "metadata": {},
   "source": [
    "Ultimately we'll need to call `py_tf_eager_policy.SavedModelPyTFEagerPolicy()` in our CPR...\n",
    "\n",
    "We can't just pass the `ARTIFACTS_DIR` because that would result in the CPR container's `model_dir` to look like this:\n",
    "\n",
    "```\n",
    "cpr_model_dir/\n",
    "├── fingerprint.pb\n",
    "├── policy_specs.pbtxt\n",
    "├── saved_model.pb\n",
    "└── variables\n",
    "    ├── variables.data-00000-of-00001\n",
    "    └── variables.index\n",
    "```\n",
    "\n",
    "Instead, we need the CPR container's `model_dir` to have a subdirectory holding these files like:\n",
    "\n",
    "```\n",
    "cpr_model_dir/\n",
    "└── artifacts\n",
    "    ├── fingerprint.pb\n",
    "    ├── policy_specs.pbtxt\n",
    "    ├── saved_model.pb\n",
    "    └── variables\n",
    "        ├── variables.data-00000-of-00001\n",
    "        └── variables.index\n",
    "```\n",
    ".. this is compatible with `py_tf_eager_policy.SavedModelPyTFEagerPolicy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f04d4a4-b399-4048-9799-7a42611d755b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-scale-compare-v2/run-20231115-094131/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-scale-compare-v2/run-20231115-094131/artifacts/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-scale-compare-v2/run-20231115-094131/logs/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-scale-compare-v2/run-20231115-094131/policy-server/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-scale-compare-v2/run-20231115-094131/root/\n"
     ]
    }
   ],
   "source": [
    "BASE_OUTPUT_URI = \"gs://rec-bandits-v2-hybrid-vertex-bucket/02-scale-compare-v2/run-20231115-094131\"\n",
    "\n",
    "ARTIFACTS_DIR = f\"{BASE_OUTPUT_URI}/artifacts\"\n",
    "POLICY_SERVE_DIR_URI = f\"{BASE_OUTPUT_URI}/policy-server\"\n",
    "\n",
    "# !gsutil cp -r $ARTIFACTS_DIR $POLICY_SERVE_DIR_URI/\n",
    "\n",
    "!gsutil ls $BASE_OUTPUT_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcd0141-45dc-402e-b37a-34a80a27bb26",
   "metadata": {},
   "source": [
    "Let's test this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "02ba7f7d-a912-4009-870a-04441f6312b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/src/local_model_dir\n"
     ]
    }
   ],
   "source": [
    "%cd $LOCAL_MODEL_ARTIFACTS_DIR\n",
    "# prediction_utils.download_model_artifacts(POLICY_SERVE_DIR_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aedd89d7-4103-4a6d-bbb4-0fb05a9f88ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifacts/\n"
     ]
    }
   ],
   "source": [
    "!ls -p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a114f95c-492b-46a1-b6a2-0979466b5bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f58a2608790>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for testing\n",
    "deployment_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy('artifacts', load_specs_from_pbtxt=True)\n",
    "deployment_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77ee088-b1fc-4d5c-85fd-d160591d8246",
   "metadata": {},
   "source": [
    "# Create CPR directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88205a5d-3bfe-42cd-9ce3-e9071c7d5110",
   "metadata": {},
   "source": [
    "The CPR directory's structure will be the prediction serving container\n",
    "\n",
    "Becasue we are going to use the `build_cpr_model()` method for `LocalModel()`, it need to resemble:\n",
    "\n",
    "```\n",
    "            container_workdir/\n",
    "            |-- predictor.py\n",
    "            |-- requirements.txt\n",
    "            |-- user_code/\n",
    "            |   |-- utils.py\n",
    "            |   |-- custom_package.tar.gz\n",
    "            |   |-- ...\n",
    "            |-- ...\n",
    "```\n",
    "\n",
    "see `build_cpr_model()` [src](https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform/prediction/local_model.py#L147)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d454d70-b05d-4122-b15f-4e7f8c8c6482",
   "metadata": {},
   "source": [
    "If you skipped the optional CPR model download steps above, load a trained policy here:\n",
    "\n",
    "> TODO: edit the BASE_OUTPUT_DIR to reflect a trained policy in your project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d7f5208f-8e1d-4045-9dd6-83a6abef4e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f58a21e6170>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_OUTPUT_URI = \"gs://rec-bandits-v2-hybrid-vertex-bucket/02-scale-compare-v2/run-20231115-094131\"\n",
    "ARTIFACTS_DIR = f\"{BASE_OUTPUT_URI}/artifacts\"\n",
    "\n",
    "deployment_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(ARTIFACTS_DIR, load_specs_from_pbtxt=True)\n",
    "deployment_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "933ac2c2-5511-4470-9d10-64769b5c2c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/src\n"
     ]
    }
   ],
   "source": [
    "path=\"/home/jupyter/tf_vertex_agents/src\"\n",
    "os.chdir(path)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "73619465-d6ca-4816-9202-6b9e4310a175",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_CPR_DIR = \"cpr_dir\"\n",
    "CPR_SUBDIR = \"user_code\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "65b7a2bb-607d-4024-824c-9bc8de0489ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf ./$LOCAL_CPR_DIR\n",
    "! mkdir ./$LOCAL_CPR_DIR\n",
    "! mkdir ./$LOCAL_CPR_DIR/$CPR_SUBDIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559f7d60-8836-4034-8fe5-040b4505cb4e",
   "metadata": {},
   "source": [
    "## Predictor\n",
    "\n",
    "* Implement a custom `Predictor` that loads in the preprocesor. The preprocessor will then be used at `preprocess` time\n",
    "* Note, the `PredictionHandle`r will be used for prediction request handling, and the following will be executed:\n",
    "\n",
    "> `self._predictor.postprocess(self._predictor.predict(self._predictor.preprocess(prediction_input)))`\n",
    "\n",
    "**references**\n",
    "* predictor_utils - [src](https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform/utils/prediction_utils.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "106768cc-4521-46ac-95c1-c3f55b393822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/src\n"
     ]
    }
   ],
   "source": [
    "os.chdir(path)\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a2bb5a41-7468-4ab6-be4e-f4f58db3199c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_code\n"
     ]
    }
   ],
   "source": [
    "!ls $LOCAL_CPR_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "255b9561-1657-4a5d-9aae-5b1d2094aed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cpr_dir/predictor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $LOCAL_CPR_DIR/predictor.py\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from typing import Dict, Any, Tuple\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "# google cloud\n",
    "from google.cloud.aiplatform.prediction.predictor import Predictor\n",
    "from google.cloud.aiplatform.utils import prediction_utils\n",
    "from google.cloud import storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "import tf_agents\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "# this repo\n",
    "sys.path.extend([f'./{name}' for name in os.listdir(\".\") if os.path.isdir(name)])\n",
    "\n",
    "import data_config as data_config\n",
    "import emb_features_pred as emb_features\n",
    "import reward_factory as reward_factory\n",
    "\n",
    "os.environ[\"PROJECT_ID\"] = data_config.PROJECT_ID\n",
    "\n",
    "# ==================================\n",
    "# get trajectory step for prediction\n",
    "# ==================================\n",
    "def _get_pred_step(feature, reward_np):\n",
    "    \n",
    "    infer_step = ts.TimeStep(\n",
    "        tf.constant(ts.StepType.FIRST, dtype=tf.int32, shape=[],name='step_type'),\n",
    "        tf.constant(reward_np, dtype=tf.float32, shape=[], name='reward'),\n",
    "        tf.constant(1.0, dtype=tf.float32, shape=[], name='discount'),\n",
    "        feature\n",
    "    )\n",
    "    \n",
    "    return infer_step\n",
    "\n",
    "# ==================================\n",
    "# prediction logic\n",
    "# ==================================\n",
    "class BanditPolicyPredictor(Predictor):\n",
    "    \n",
    "    \"\"\"\n",
    "    Interface of the Predictor class for Custom Prediction Routines.\n",
    "    \n",
    "    The Predictor is responsible for the ML logic for processing a prediction request.\n",
    "    \n",
    "    Specifically, the Predictor must define:\n",
    "        (1) How to load all model artifacts used during prediction into memory.\n",
    "        (2) The logic that should be executed at predict time.\n",
    "    \n",
    "    When using the default PredictionHandler, the Predictor will be invoked as follows:\n",
    "    \n",
    "      predictor.postprocess(predictor.predict(predictor.preprocess(prediction_input)))\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self._local_vocab_filename = \"./vocab_dict.pkl\"\n",
    "        self._num_oov_buckets = data_config.NUM_OOV_BUCKETS\n",
    "        self._global_embedding_size = data_config.GLOBAL_EMBEDDING_SIZE\n",
    "        self._mv_embedding_size = data_config.MV_EMBEDDING_SIZE\n",
    "        return\n",
    "        \n",
    "    def load(self, artifacts_uri: str):\n",
    "        \"\"\"\n",
    "        Loads trained policy dir & vocabulary\n",
    "        Args:\n",
    "            artifacts_uri (str):\n",
    "                Required. The value of the environment variable AIP_STORAGE_URI.\n",
    "                has `artifacts/` as a sub directory \n",
    "        \n",
    "        \"\"\"\n",
    "        prediction_utils.download_model_artifacts(artifacts_uri)\n",
    "        \n",
    "        # init deploy policy\n",
    "        self._deployment_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "            'artifacts', load_specs_from_pbtxt=True\n",
    "        )\n",
    "        \n",
    "        # load vocab dict\n",
    "        filehandler = open(f\"{self._local_vocab_filename}\", 'rb')\n",
    "        self._vocab_dict = pkl.load(filehandler)\n",
    "        filehandler.close()\n",
    "        \n",
    "        # only if no custom preprocessor is defined\n",
    "        # self._preprocessor = preprocessor\n",
    "        \n",
    "    def preprocess(self, prediction_input: Dict): # -> Tuple[Dict, float]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            prediction_input (Any):\n",
    "                Required. The prediction input that needs to be preprocessed.\n",
    "        Returns:\n",
    "            The preprocessed prediction input.        \n",
    "        \"\"\"\n",
    "        # inputs = super().preprocess(prediction_input)\n",
    "        \n",
    "        dummy_arm = tf.zeros([1, data_config.PER_ARM_DIM], dtype=tf.float32)\n",
    "        \n",
    "        batch_size = len(prediction_input) #[\"instances\"])\n",
    "        assert batch_size == 1, 'prediction batch_size must be == 1'\n",
    "        \n",
    "        self._embs = emb_features.EmbeddingModel(\n",
    "            vocab_dict = self._vocab_dict,\n",
    "            num_oov_buckets = self._num_oov_buckets,\n",
    "            global_emb_size = self._global_embedding_size,\n",
    "            mv_emb_size = self._mv_embedding_size,\n",
    "        )\n",
    "        \n",
    "        # preprocess example\n",
    "        rebuild_ex = {}\n",
    "\n",
    "        for x in prediction_input: #[\"instances\"]:\n",
    "            rebuild_ex['bucketized_user_age'] = tf.constant([x[\"bucketized_user_age\"]], dtype=tf.float32)\n",
    "            rebuild_ex['movie_genres'] = tf.constant([x[\"movie_genres\"]], dtype=tf.int64)\n",
    "            rebuild_ex['movie_id'] = tf.constant([x[\"movie_id\"]], dtype=tf.string)\n",
    "            rebuild_ex['timestamp'] = tf.constant([x[\"timestamp\"]], dtype=tf.int64)\n",
    "            rebuild_ex['user_id'] = tf.constant([x[\"user_id\"]], dtype=tf.string)\n",
    "            rebuild_ex['user_occupation_text'] = tf.constant([x[\"user_occupation_text\"]], dtype=tf.string)\n",
    "            rebuild_ex['user_rating'] = tf.constant([x[\"user_rating\"]], dtype=tf.float32)\n",
    "        \n",
    "        global_feat_infer = self._embs._get_global_context_features(rebuild_ex)\n",
    "        logging.info(f'global_feat_infer: {global_feat_infer}')          # tmp - debugging\n",
    "        \n",
    "        arm_feat_infer = self._embs._get_per_arm_features(rebuild_ex)    # tmp - debugging\n",
    "        logging.info(f'arm_feat_infer: {arm_feat_infer}')\n",
    "    \n",
    "        rewards = reward_factory._get_rewards(rebuild_ex)\n",
    "        logging.info(f'rewards: {rewards}')                              # tmp - debugging\n",
    "        \n",
    "        actual_reward = rewards.numpy()[0]\n",
    "        logging.info(f'actual_reward: {actual_reward}')                  # tmp - debugging\n",
    "        \n",
    "        arm_feat_infer = tf.reshape(arm_feat_infer, [1, data_config.PER_ARM_DIM])\n",
    "        concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)      # tmp - debugging\n",
    "        \n",
    "        # flatten global\n",
    "        flat_global_infer = tf.reshape(global_feat_infer, [data_config.GLOBAL_DIM])\n",
    "        feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "        logging.info(f'feature: {feature}')                              # tmp - debugging\n",
    "        \n",
    "        trajectory_step = _get_pred_step(feature, actual_reward)\n",
    "        logging.info(f'trajectory_step: {trajectory_step}')\n",
    "        \n",
    "        # prediction = self._deployment_policy.action(trajectory_step)\n",
    "        \n",
    "        return trajectory_step\n",
    "    \n",
    "    def predict(self, instances) -> Dict:\n",
    "        \"\"\"\n",
    "        Performs prediction i.e., policy takes action\n",
    "        \"\"\"\n",
    "        # prediction = self._deployment_policy.action(instances) # trajectory_step\n",
    "        # return {\"predictions\": prediction}\n",
    "        return self._deployment_policy.action(instances)\n",
    "        \n",
    "\n",
    "    def postprocess(self, prediction_results: Any) -> Any:\n",
    "        \"\"\" \n",
    "        Postprocesses the prediction results\n",
    "        \n",
    "        TODO:\n",
    "             Convert predictions to item IDs\n",
    "             \n",
    "        \"\"\"\n",
    "        processed_pred_dict = {\n",
    "            \"bandit_policy_type\" : int(prediction_results.info.bandit_policy_type[0]),\n",
    "            \"chosen_arm_features\" : prediction_results.info.chosen_arm_features.tolist(),\n",
    "            \"predicted_rewards_mean\" : prediction_results.info.predicted_rewards_mean.tolist(),\n",
    "            \"action\" : int(prediction_results.action.tolist()),\n",
    "        }\n",
    "        \n",
    "        return processed_pred_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5a0f3f-88c8-4f58-8b4a-ce4001bc05b2",
   "metadata": {},
   "source": [
    "## Entrypoint / Handler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc388e1-72cd-49e9-b2eb-e74dda59f69c",
   "metadata": {},
   "source": [
    "Custom containers require an **entrypoint** of the image that starts the model server\n",
    "* With Custom Prediction Routines (CPR), you **don't need to write the entrypoint** anymore. Vertex SDK will populate the entrypoint with the custom predictor you provide\n",
    "* However, we *can* implement a custom `handler()` method for the CPR model server, instead of using a pre-built http request handler. \n",
    "  * The `handler()` method handles the extraction of the prediction request from the HTTP request message\n",
    "  * Will also, call the `predictor()` method to pass the extraction instances data for the prediction request\n",
    "  \n",
    "For implementing our own Docker build process, see \"Scenario 4\" in [getting started with cpr](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage6/get_started_with_cpr.ipynb) notebook tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "48271635-b1fe-46e8-bfda-129aa2363423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/src\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ad590206-8653-411a-b20c-4b16a69e545e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cpr_dir/handler.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $LOCAL_CPR_DIR/handler.py\n",
    "\n",
    "import json\n",
    "import logging\n",
    "from fastapi import Response\n",
    "from google.cloud.aiplatform.prediction.handler import PredictionHandler\n",
    "\n",
    "class CprHandler(PredictionHandler):\n",
    "    \"\"\"\n",
    "    Default prediction handler for the pred requests sent to the application\n",
    "    \"\"\"\n",
    "\n",
    "    async def handle(self, request):\n",
    "        \"\"\"Handles a prediction request.\"\"\"\n",
    "        \n",
    "        request_body = await request.body()\n",
    "        logging.info(f'request_body: {request_body}')\n",
    "        \n",
    "        request_body_dict = json.loads(request_body)\n",
    "        logging.info(f'request_body_dict: {request_body_dict}')\n",
    "        \n",
    "        instances=request_body_dict[\"instances\"]\n",
    "        logging.info(f'instances: {instances}')\n",
    "        \n",
    "        prediction_results = self._predictor.postprocess(self._predictor.predict(self._predictor.preprocess(instances)))\n",
    "                                                         \n",
    "        logging.info(f'prediction: {prediction_results}')\n",
    "\n",
    "        return Response(content=json.dumps(prediction_results))\n",
    "        # return {\"predictions\": prediction_results}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd15510-a173-47a0-b4cd-2a9f091f45ae",
   "metadata": {},
   "source": [
    "## CPR package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "53ad9fd6-a891-427b-96d8-f7e8a7b1a022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/src\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3291ce02-feea-43f4-9c9e-a4b42c15544c",
   "metadata": {},
   "source": [
    "### data config\n",
    "\n",
    "> TODO - edit these as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dec13664-6ce0-41c9-9977-af3711f5612f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cpr_dir/user_code/data_config.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $LOCAL_CPR_DIR/$CPR_SUBDIR/data_config.py\n",
    "PROJECT_ID             = \"hybrid-vertex\"\n",
    "REGION                 = \"us-central1\"\n",
    "PREFIX                 = \"rec-bandits-v2\"\n",
    "BUCKET_NAME            = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
    "EXISTING_VOCAB_FILE    = \"gs://rec-bandits-v2-hybrid-vertex-bucket/vocabs/vocab_dict.pkl\"\n",
    "eval_batch_size        = 1\n",
    "PER_ARM_DIM            = 64\n",
    "GLOBAL_DIM             = 64\n",
    "NUM_OOV_BUCKETS        = 1\n",
    "GLOBAL_EMBEDDING_SIZE  = 16\n",
    "MV_EMBEDDING_SIZE      = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1784ba3-46ed-4b3b-ae6b-84ed10f14c1e",
   "metadata": {},
   "source": [
    "### requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4b63686b-f217-4657-9551-fe339053de9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cpr_dir/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile $LOCAL_CPR_DIR/requirements.txt\n",
    "google-cloud-aiplatform[prediction]==1.33.1\n",
    "google-cloud-storage\n",
    "numpy\n",
    "six\n",
    "typing-extensions\n",
    "tensorflow==2.13.1\n",
    "tf-agents==0.17.0\n",
    "urllib3\n",
    "pillow\n",
    "tensorflow-io\n",
    "tensorflow-datasets\n",
    "tensorflow-probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac45b03-b9aa-4113-be47-47e95bc8194a",
   "metadata": {},
   "source": [
    "### copy remaining files to CPR dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b7eb3887-b4ec-4428-ad17-0f619e2676d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp ./perarm_features/reward_factory.py ./$LOCAL_CPR_DIR/$CPR_SUBDIR/reward_factory.py\n",
    "! cp ./perarm_features/emb_features.py ./$LOCAL_CPR_DIR/$CPR_SUBDIR/emb_features_pred.py\n",
    "! cp ./vocab_dict.pkl ./$LOCAL_CPR_DIR/vocab_dict.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a6dd9ab3-ae33-47df-9ec9-43698947e5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mcpr_dir\u001b[00m\n",
      "├── handler.py\n",
      "├── predictor.py\n",
      "├── requirements.txt\n",
      "├── \u001b[01;34muser_code\u001b[00m\n",
      "│   ├── data_config.py\n",
      "│   ├── emb_features_pred.py\n",
      "│   └── reward_factory.py\n",
      "└── vocab_dict.pkl\n",
      "\n",
      "1 directory, 7 files\n"
     ]
    }
   ],
   "source": [
    "!tree $LOCAL_CPR_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6677f422-8a08-4913-96c6-b60a153a9800",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Build and push CPR container to Vertex\n",
    "\n",
    "* `LocalModel` [src](https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform/prediction/local_model.py)\n",
    "\n",
    "**Build container**\n",
    "* To build a custom container, we also need to write an entrypoint of the image that starts the model server. \n",
    "* However, with the Custom Prediction Routine feature, you don't need to write the entrypoint anymore. \n",
    "* Vertex AI SDK will populate the entrypoint with the custom predictor you provide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e9c88a-7cbb-459b-9368-459e533de036",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5fbcc1-e3ba-4015-a0b0-73edb0ad5d8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "**build_cpr_model**\n",
    "```\n",
    "    local_model = LocalModel.build_cpr_model(\n",
    "        \"./user_src_dir\",\n",
    "        \"us-docker.pkg.dev/$PROJECT/$REPOSITORY/$IMAGE_NAME$\",\n",
    "        predictor=$CUSTOM_PREDICTOR_CLASS,\n",
    "        requirements_path=\"./user_src_dir/requirements.txt\",\n",
    "        extra_packages=[\"./user_src_dir/user_code/custom_package.tar.gz\"],\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b0984c-629c-4316-b6cd-2bfa51688d23",
   "metadata": {
    "tags": []
   },
   "source": [
    "```\n",
    "Args:\n",
    "    src_dir (str):\n",
    "        Required. The path to the local directory including all needed files such as\n",
    "        predictor. The whole directory will be copied to the image.\n",
    "    output_image_uri (str):\n",
    "        Required. The image uri of the built image.\n",
    "    predictor (Type[Predictor]):\n",
    "        Optional. The custom predictor class consumed by handler to do prediction.\n",
    "    handler (Type[Handler]):\n",
    "        Required. The handler class to handle requests in the model server.\n",
    "    base_image (str):\n",
    "        Required. The base image used to build the custom images. The base image must\n",
    "        have python and pip installed where the two commands ``python`` and ``pip`` must be\n",
    "        available.\n",
    "    requirements_path (str):\n",
    "        Optional. The path to the local requirements.txt file. This file will be copied\n",
    "        to the image and the needed packages listed in it will be installed.\n",
    "    extra_packages (List[str]):\n",
    "        Optional. The list of user custom dependency packages to install.\n",
    "    no_cache (bool):\n",
    "        Required. Do not use cache when building the image. Using build cache usually\n",
    "        reduces the image building time. See\n",
    "        https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#leverage-build-cache\n",
    "        for more details.\n",
    "        \n",
    "Returns:\n",
    "    local model: Instantiated representation of the local model.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9862847d-cf80-4aa7-afd5-70d20cdc36f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create example prediction instance\n",
    "\n",
    "Create two formats:\n",
    "* json file\n",
    "* serialized dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "60f74502-4afd-470e-868a-37100dcd21f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b5415dd1-cc87-4e54-8db6-0312e68cc1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/src\n"
     ]
    }
   ],
   "source": [
    "path=\"/home/jupyter/tf_vertex_agents/src\"\n",
    "os.chdir(path)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "08dea81b-f893-4c03-a453-8f4791f0b734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"instances\": [{\"bucketized_user_age\": 25.0, \"movie_genres\": [4], \"movie_id\": \"211\", \"timestamp\": 874948475, \"user_id\": \"346\", \"user_occupation_text\": \"other\", \"user_rating\": 4.0}]}'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_INSTANCE = {\n",
    "    \"instances\": [\n",
    "        {\n",
    "            'bucketized_user_age': 25.0,\n",
    "            'movie_genres': [4],\n",
    "            'movie_id': '211',\n",
    "            'timestamp': 874948475,\n",
    "            'user_id': '346',\n",
    "            'user_occupation_text': 'other',\n",
    "            'user_rating': 4.0\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# TEST_INSTANCE['instances']\n",
    "json_instance = json.dumps({\"instances\": TEST_INSTANCE['instances']})\n",
    "json_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c9c6b306-854b-4156-891b-0708910b9dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = \"instances.json\"\n",
    "\n",
    "with open(INPUT_FILE, \"w\") as f:\n",
    "    json_dumps_str = json.dumps(TEST_INSTANCE)\n",
    "    f.write(json_dumps_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b20182-58c6-4782-9af5-090e019f54b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile $INPUT_FILE\n",
    "# {\n",
    "#     \"instances\": [\n",
    "#         'bucketized_user_age': 25.0,\n",
    "#         'movie_genres': [4],\n",
    "#         'movie_id': '211',\n",
    "#         'timestamp': 874948475,\n",
    "#         'user_id': '346',\n",
    "#         'user_occupation_text': 'other',\n",
    "#         'user_rating': 4.0\n",
    "#     ]\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb5d3f6-4d7c-425a-9fa9-f444d0caf6d0",
   "metadata": {},
   "source": [
    "## Local build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a886577c-53dc-4c9a-9504-adc4ccd878e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/src\n"
     ]
    }
   ],
   "source": [
    "# path =\"/home/jupyter/tf_vertex_agents/src\"\n",
    "# os.chdir(path)\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5c7a701f-9d30-42bf-bbf8-c474dac9f0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handler.py  predictor.py  requirements.txt  user_code  vocab_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "!ls $LOCAL_CPR_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b3ebbf40-e33e-45ba-bec9-bc493d421ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLICY_SERVE_DIR_URI   = gs://rec-bandits-v2-hybrid-vertex-bucket/02-scale-compare-v2/run-20231115-094131/policy-server\n",
      "REPOSITORY             = rl-movielens-rec-bandits-v2\n",
      "IMAGE_NAME_02_PRED_CPR = cpr-perarm-bandit-02e\n",
      "IMAGE_URI_02_PRED_CPR  = gcr.io/hybrid-vertex/cpr-perarm-bandit-02e\n",
      "REMOTE_IMAGE_NAME_CPR  = us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/cpr-perarm-bandit-02e\n"
     ]
    }
   ],
   "source": [
    "from google.cloud.aiplatform.prediction import LocalModel\n",
    "from cpr_dir.predictor import BanditPolicyPredictor\n",
    "from cpr_dir.handler import CprHandler\n",
    "\n",
    "POLICY_SERVE_DIR_URI = f\"{BASE_OUTPUT_URI}/policy-server\"\n",
    "\n",
    "print(f\"POLICY_SERVE_DIR_URI   = {POLICY_SERVE_DIR_URI}\")\n",
    "print(f\"REPOSITORY             = {REPOSITORY}\")\n",
    "print(f\"IMAGE_NAME_02_PRED_CPR = {IMAGE_NAME_02_PRED_CPR}\")\n",
    "print(f\"IMAGE_URI_02_PRED_CPR  = {IMAGE_URI_02_PRED_CPR}\")\n",
    "print(f\"REMOTE_IMAGE_NAME_CPR  = {REMOTE_IMAGE_NAME_CPR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1417d964-2ac1-4825-a2b3-9a1bd1ee334b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-scale-compare-v2/run-20231115-094131/policy-server/artifacts/\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls $POLICY_SERVE_DIR_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2b5e1693-24b5-427b-bf30-1cc9636ddf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/subprocess.py:955: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
      "/opt/conda/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
     ]
    }
   ],
   "source": [
    "local_model = LocalModel.build_cpr_model(\n",
    "    src_dir= f\"./{LOCAL_CPR_DIR}\",\n",
    "    # output_image_uri = IMAGE_URI_02_PRED_CPR,\n",
    "    output_image_uri = REMOTE_IMAGE_NAME_CPR,\n",
    "    predictor= BanditPolicyPredictor,\n",
    "    handler= CprHandler,\n",
    "    base_image = 'tiangolo/uvicorn-gunicorn-fastapi:python3.10', # fastapi referenced in Predictor\n",
    "    # base_image = 'tensorflow/tensorflow:2.14.0',\n",
    "    requirements_path=f\"./{LOCAL_CPR_DIR}/requirements.txt\",\n",
    "    no_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b514a0db-a8f1-4214-9b38-efe9c6ec0821",
   "metadata": {},
   "source": [
    "You can check out the serving container spec of the built image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d7a75746-1a63-4809-9ef0-57ebaa40d10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_uri: \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/cpr-perarm-bandit-02e\"\n",
       "predict_route: \"/predict\"\n",
       "health_route: \"/health\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_model.get_serving_container_spec()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fffce15-48ae-4d91-ad39-c7a98b5707c8",
   "metadata": {},
   "source": [
    "Once CPR model built, either (1) test it locally or (2) push image to registry and upload model to Vertex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aea9475-977a-404c-8195-5cf9335fbadc",
   "metadata": {},
   "source": [
    "### (Optional) deploy to local endpoint\n",
    "\n",
    "> **Deploy `LocalModel` to `LocalEndpoint`**\n",
    "\n",
    "This cuts the dev cycle iterations significantly!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b65a0280-0444-4f39-8198-265fd86cf355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/src\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "39d2f076-c44a-4d61-93a9-fbef5e7935ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_endpoint = local_model.deploy_to_local_endpoint(\n",
    "    artifact_uri=f\"{POLICY_SERVE_DIR_URI}\",\n",
    "    credential_path=CREDENTIALS_FILE,\n",
    "    container_ready_timeout=300,\n",
    "    container_ready_check_interval=10\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789143bb-1f26-4792-b1f0-e742d70a05bd",
   "metadata": {},
   "source": [
    "**Call `serve()` to start the conatiner for local traffic** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "faabd41c-9d49-41f0-a696-dd7408b4c2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "health_check     : b'{}'\n",
      "container_status : running\n",
      "container_port   : 8080\n",
      "env_vars         : {}\n",
      "ready_interval   : 10\n"
     ]
    }
   ],
   "source": [
    "local_endpoint.serve()\n",
    "\n",
    "health_check_response = local_endpoint.run_health_check()\n",
    "\n",
    "print(f\"health_check     : {health_check_response.content}\")\n",
    "print(f\"container_status : {local_endpoint.get_container_status()}\")\n",
    "print(f\"container_port   : {local_endpoint.container_port}\")\n",
    "print(f\"env_vars         : {local_endpoint.serving_container_environment_variables}\")\n",
    "print(f\"ready_interval   : {local_endpoint.container_ready_check_interval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e50a5759-50ea-4bde-8ebe-8bb28fedd14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: still don't understand how to use this\n",
    "local_endpoint.print_container_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14432ce-4a85-4751-9f61-cca31d5ee9ce",
   "metadata": {},
   "source": [
    "#### Test locally deployed policy endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "87c3ee0a-f3b2-454d-b14a-31165382a011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_response: b'{\"bandit_policy_type\": 1, \"chosen_arm_features\": [0.022640574723482132, -0.026614343747496605, 0.009350311011075974, -0.009256027638912201, 0.01683845743536949, -0.02970973215997219, -0.004785060882568359, -0.027460742741823196, 0.039387334138154984, 0.03265250846743584, 0.02882300689816475, -0.020852291956543922, -0.004458390176296234, -0.04745906591415405, -0.01072145625948906, 0.04541505500674248, -0.010558567941188812, 0.03181641176342964, -0.03314167261123657, 0.026442501693964005, 0.01832817867398262, 0.012074984610080719, -0.017612121999263763, 0.03968402370810509, 0.04626071825623512, -0.015969157218933105, 0.042623136192560196, 0.0013975389301776886, -0.017309151589870453, 0.018650617450475693, -0.04263586923480034, 0.03596215322613716, 0.047955069690942764, 0.04047132655978203, 0.02982569858431816, -0.01531977578997612, 0.016927648335695267, 0.01658148691058159, 0.03304805979132652, -0.03345393016934395, -0.0012910142540931702, -0.02426820993423462, 0.016876552253961563, -0.025590229779481888, 0.024780478328466415, -0.028814518824219704, -0.0302688367664814, 0.028406117111444473, -0.007304169237613678, 0.017228666692972183, 0.013460788875818253, 0.030434083193540573, -0.0004304535686969757, 0.014961827546358109, -0.010323237627744675, -0.008295737206935883, -0.004164658486843109, -0.02987389639019966, 0.0013648271560668945, -0.025325370952486992, -0.04983177408576012, 0.009227048605680466, -0.03774099424481392, -0.006645273417234421], \"predicted_rewards_mean\": [2.4577114582061768, 2.4577114582061768], \"action\": 0}'\n"
     ]
    }
   ],
   "source": [
    "predict_response = local_endpoint.predict(\n",
    "    request_file=INPUT_FILE,\n",
    "    headers={\"Content-Type\": \"application/json\"},\n",
    ")\n",
    "# print(predict_response, predict_response.content)\n",
    "print(f\"predict_response: {predict_response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97d0be4-9010-4973-9a56-773e258d7486",
   "metadata": {},
   "source": [
    "and to get prediction response as a usable object: `.json()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b52754e8-5958-4183-a401-3cb93702ae6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.022640574723482132, -0.026614343747496605, 0.009350311011075974, -0.009256027638912201, 0.01683845743536949, -0.02970973215997219, -0.004785060882568359, -0.027460742741823196, 0.039387334138154984, 0.03265250846743584, 0.02882300689816475, -0.020852291956543922, -0.004458390176296234, -0.04745906591415405, -0.01072145625948906, 0.04541505500674248, -0.010558567941188812, 0.03181641176342964, -0.03314167261123657, 0.026442501693964005, 0.01832817867398262, 0.012074984610080719, -0.017612121999263763, 0.03968402370810509, 0.04626071825623512, -0.015969157218933105, 0.042623136192560196, 0.0013975389301776886, -0.017309151589870453, 0.018650617450475693, -0.04263586923480034, 0.03596215322613716, 0.047955069690942764, 0.04047132655978203, 0.02982569858431816, -0.01531977578997612, 0.016927648335695267, 0.01658148691058159, 0.03304805979132652, -0.03345393016934395, -0.0012910142540931702, -0.02426820993423462, 0.016876552253961563, -0.025590229779481888, 0.024780478328466415, -0.028814518824219704, -0.0302688367664814, 0.028406117111444473, -0.007304169237613678, 0.017228666692972183, 0.013460788875818253, 0.030434083193540573, -0.0004304535686969757, 0.014961827546358109, -0.010323237627744675, -0.008295737206935883, -0.004164658486843109, -0.02987389639019966, 0.0013648271560668945, -0.025325370952486992, -0.04983177408576012, 0.009227048605680466, -0.03774099424481392, -0.006645273417234421]\n"
     ]
    }
   ],
   "source": [
    "preds = predict_response.json()\n",
    "\n",
    "print(preds['chosen_arm_features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a569cb28-098d-45bc-8a44-691523f1130e",
   "metadata": {},
   "source": [
    "stop local endpoint container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba92506-324a-4b02-b1e8-228c13bc8c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_endpoint.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753357e3-6488-45f4-865f-536dcdd704ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deploy to Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee959f50-789f-4453-966a-54030fb9250d",
   "metadata": {},
   "source": [
    "**Push image to registry**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4fc23089-9550-43ae-8efd-b94c5eed3e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/subprocess.py:955: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
      "/opt/conda/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
     ]
    }
   ],
   "source": [
    "local_model.push_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c3ad87-c6fc-4c2b-a5be-b23ae77969fc",
   "metadata": {},
   "source": [
    "**Upload to Vertex Model Registry**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6d24ebd4-2ae9-42b9-bcf0-efbdfb3cc868",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = \"v5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "45f35fb7-a9cd-4b3c-91e2-c2512e61aefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-scale-compare-v2/run-20231115-094131/policy-server/artifacts/\n"
     ]
    }
   ],
   "source": [
    "# !gsutil ls $ARTIFACTS_DIR\n",
    "!gsutil ls $POLICY_SERVE_DIR_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "661ca0a3-8df7-4d70-8356-ff62d3985966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "display_name    : cpr-bandit-from-local-v5\n",
      "uploaded_policy : <google.cloud.aiplatform.models.Model object at 0x7f58886894b0> \n",
      "resource name: projects/934903580331/locations/us-central1/models/7813171408418111488\n"
     ]
    }
   ],
   "source": [
    "uploaded_policy = vertex_ai.Model.upload(\n",
    "    local_model=local_model,\n",
    "    display_name=f'cpr-bandit-from-local-{VERSION}',\n",
    "    artifact_uri=POLICY_SERVE_DIR_URI,\n",
    "    sync=True,\n",
    ")\n",
    "\n",
    "print(f\"display_name    : {model.display_name}\")\n",
    "print(f\"uploaded_policy : {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c41524d2-24c0-4ef0-9460-da60c18173aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "display_name : endpoint-cpr-bandit-v5\n",
      "endpoint     : <google.cloud.aiplatform.models.Endpoint object at 0x7f580564d7e0> \n",
      "resource name: projects/934903580331/locations/us-central1/endpoints/5168920710407520256\n"
     ]
    }
   ],
   "source": [
    "endpoint = vertex_ai.Endpoint.create(\n",
    "    display_name=f'endpoint-cpr-bandit-{VERSION}',\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION,\n",
    "    sync=True,\n",
    ")\n",
    "\n",
    "print(f\"display_name : {endpoint.display_name}\")\n",
    "print(f\"endpoint     : {endpoint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "aab8fb6c-5f53-473b-a770-287a975f9180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "display_name    : endpoint-cpr-bandit-v5\n",
      "\n",
      "deployed_policy : <google.cloud.aiplatform.models.Endpoint object at 0x7f580564d7e0> \n",
      "resource name: projects/934903580331/locations/us-central1/endpoints/5168920710407520256\n"
     ]
    }
   ],
   "source": [
    "deployed_policy = uploaded_policy.deploy(\n",
    "    endpoint=endpoint,\n",
    "    deployed_model_display_name=f'deployed-cpr-bandit-{VERSION}',\n",
    "    machine_type=\"n1-standard-4\",\n",
    "    min_replica_count=1,\n",
    "    max_replica_count=1,\n",
    "    accelerator_type=None,\n",
    "    accelerator_count=0,\n",
    "    sync=True,\n",
    "    enable_access_logging=True,\n",
    ")\n",
    "\n",
    "print(f\"display_name    : {deployed_model.display_name}\\n\")\n",
    "print(f\"deployed_policy : {deployed_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858364c7-a593-4cf8-8d68-56f484c393c6",
   "metadata": {},
   "source": [
    "### Test deployed policy endpoint\n",
    "\n",
    "*Note*: to have predictions display in response to the gcloud command, the handler should return a response dictionary like:\n",
    "\n",
    "> `{\"predictions\": post_processed_preds}`\n",
    "\n",
    "See [Send an online prediction request](https://cloud.google.com/vertex-ai/docs/predictions/get-online-predictions#predict-request) in docs for more details "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37096a2-bb9f-48e4-9edb-540131bde77a",
   "metadata": {},
   "source": [
    "#### gcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "91361966-9668-4fe3-acd3-c818447272a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-prediction-aiplatform.googleapis.com/]\n",
      "deployedModelId: '9012835351344971776'\n",
      "model: projects/934903580331/locations/us-central1/models/7813171408418111488\n",
      "modelDisplayName: cpr-bandit-from-local-v5\n",
      "modelVersionId: '1'\n"
     ]
    }
   ],
   "source": [
    "ENDPOINT_ID = endpoint.resource_name\n",
    "\n",
    "!gcloud ai endpoints predict $ENDPOINT_ID --region=$REGION --json-request=instances.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "35cd42a9-c058-4aa5-9337-c1bf7db54353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"instances\": [{\"bucketized_user_age\": 25.0, \"movie_genres\": [4], \"movie_id\": \"211\", \"timestamp\": 874948475, \"user_id\": \"346\", \"user_occupation_text\": \"other\", \"user_rating\": 4.0}]}'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# json_dumps_str = json.dumps(TEST_INSTANCE)\n",
    "\n",
    "# json_instance\n",
    "ENCODED_TEST_INSTANCE = json_instance.encode('utf-8')\n",
    "ENCODED_TEST_INSTANCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a98d549-5572-40c3-9fd3-96217a0f7d1f",
   "metadata": {},
   "source": [
    "#### Vertex SDK's raw predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4352b587-72a0-44f7-8097-b59a13f8d0f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bandit_policy_type': 1, 'chosen_arm_features': [0.024603907018899918, 0.022303912788629532, -0.029591917991638184, 0.030105959624052048, 0.015452351421117783, 0.0425909049808979, -0.04958895593881607, 0.0021106116473674774, 0.005578480660915375, -0.047885406762361526, 0.03569388762116432, 0.007767736911773682, -0.028136778622865677, 0.0128319151699543, -0.009761642664670944, -0.02994852140545845, -0.01563861221075058, 0.04413098469376564, 0.00020591169595718384, 0.006635785102844238, -0.0350680947303772, -0.020459115505218506, 0.014313783496618271, 0.0007997974753379822, 0.03674118593335152, -0.007525373250246048, -0.006622813642024994, -0.006104696542024612, -0.040216851979494095, 0.03555159643292427, -0.0321384072303772, 0.02723154053092003, -0.017000533640384674, -0.013260770589113235, 0.009485840797424316, -0.019609510898590088, -0.011272478848695755, -0.037256695330142975, -0.016197729855775833, 0.03783922269940376, 0.03956976160407066, -0.012978147715330124, 0.00630347803235054, 0.04646916314959526, -0.014920331537723541, 0.027975905686616898, -0.041696321219205856, -0.04531940445303917, -0.04963039234280586, -0.02783872000873089, 0.008858632296323776, 0.03666261211037636, 0.04942293092608452, 0.042202237993478775, 0.01247091218829155, 0.03607669845223427, -0.023854507133364677, -0.005360901355743408, -0.0342240110039711, 0.03668424114584923, 0.025492403656244278, -0.02792983129620552, 0.045034777373075485, -0.011539913713932037], 'predicted_rewards_mean': [2.4577114582061768, 2.4577114582061768], 'action': 0}\n"
     ]
    }
   ],
   "source": [
    "response = deployed_model.raw_predict(\n",
    "    body = ENCODED_TEST_INSTANCE,\n",
    "    headers = {'Content-Type':'application/json'}\n",
    ").json()\n",
    "\n",
    "# print(response['chosen_arm_features'])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c02755f4-e2d3-4e16-8553-2cd472326397",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO - jt\n",
    "\n",
    "# response_v2 = deployed_model.predict(\n",
    "#     instances=[[TEST_INSTANCE]], \n",
    "#     use_raw_predict=False\n",
    "# ) #.json()\n",
    "\n",
    "# print(response_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd19b18-ba9c-4df8-95ea-f929f1724829",
   "metadata": {},
   "source": [
    "# Vertex Batch Predictions\n",
    "\n",
    "> TODO: jt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35df514e-074a-46f7-a51a-ff307a1fb5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f58e24-9528-4774-9694-f473cad00cfa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7621cce-2927-4d84-881d-d8875cdf4286",
   "metadata": {},
   "source": [
    "Undeploy model and delete endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b0d1fe98-6588-4e6c-9bc6-fa300ea51b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint.delete(force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f033038-ae3e-45b2-82b0-597151efdec2",
   "metadata": {},
   "source": [
    "Delete policy uploaded to Vertex AI Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3a4b9e4c-d93a-46ef-9a9e-c12344555b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uploaded_policy.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e098affd-3723-438e-a44d-cf2f4c8f8fcf",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
