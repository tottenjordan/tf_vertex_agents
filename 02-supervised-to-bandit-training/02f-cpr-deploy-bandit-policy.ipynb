{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a03307f-546e-485f-bf38-3f8acc0b4196",
   "metadata": {},
   "source": [
    "# Custom Prediction Routine (CPR)\n",
    "\n",
    "> Build custom container for deploying trained policy to Vertex Prediction online endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcb75d2-ed29-467c-9767-708b3be22868",
   "metadata": {},
   "source": [
    "### references"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff022e80-96e3-44f1-8414-09106d7b2d20",
   "metadata": {},
   "source": [
    "* [src code](https://github.com/googleapis/python-aiplatform/tree/main/google/cloud/aiplatform/prediction)\n",
    "* [docs](https://cloud.google.com/vertex-ai/docs/predictions/custom-prediction-routines#run_the_container_locally_optional)\n",
    "* code examples\n",
    "  * [SDK_Custom_Predict_and_Handler_SDK_Integration](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/prediction/custom_prediction_routines/SDK_Custom_Predict_and_Handler_SDK_Integration.ipynb)\n",
    "  * [SDK_Custom_Preprocess](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/ef8b70db32813b8a2f128ab5ef1d170aea739e7f/notebooks/community/prediction/custom_prediction_routines/SDK_Custom_Preprocess.ipynb)\n",
    "  \n",
    "**In the built image, user provided files will be copied as follows:**\n",
    "\n",
    "```\n",
    "    container_workdir/\n",
    "    |-- predictor.py\n",
    "    |-- requirements.txt\n",
    "    |-- user_code/\n",
    "    |   |-- utils.py\n",
    "    |   |-- custom_package.tar.gz\n",
    "    |   |-- ...\n",
    "    |-- ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9302b843-5fbb-4c9f-b61a-5635c33d733b",
   "metadata": {},
   "source": [
    "## Notebook config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4297ff6e-3a25-4ef2-8a74-a1b710c8ead4",
   "metadata": {},
   "source": [
    "**in this notebook** we need to be concious of our current working directory (path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c8d374e-17c3-4512-a6be-73a0a91af5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/src\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "path=\"/home/jupyter/tf_vertex_agents/src\"\n",
    "os.chdir(path)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "025a45dd-21a9-4110-9ca5-294ae0911feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/src\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "994fffc8-c58f-4dd0-97c2-7116d8ecda43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "VERSION        = \"v2\"                       # TODO\n",
    "PREFIX         = f'rec-bandits-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8cc89ad-d0da-4421-b4fd-b232e733bd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"rec-bandits-v2\"\n",
      "VERSION                  = \"v2\"\n",
      "\n",
      "BUCKET_NAME              = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_NAME    = \"mvlens_rec_bandits_v2\"\n",
      "BIGQUERY_TABLE_NAME      = \"training_dataset\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-rec-bandits-v2\"\n",
      "\n",
      "DOCKERNAME_01            = \"Dockerfile_train_my_perarm_env\"\n",
      "IMAGE_NAME_01            = \"train-my-perarm-env-v2\"\n",
      "IMAGE_URI_01             = \"gcr.io/hybrid-vertex/train-my-perarm-env-v2\"\n",
      "\n",
      "DOCKERNAME_02            = \"Dockerfile_perarm_feats\"\n",
      "IMAGE_NAME_02            = \"train-perarm-feats-v2\"\n",
      "IMAGE_URI_02             = \"gcr.io/hybrid-vertex/train-perarm-feats-v2\"\n",
      "\n",
      "DOCKERNAME_03            = \"Dockerfile_ranking_bandit\"\n",
      "IMAGE_NAME_03            = \"train-rank-bandit-v2\"\n",
      "IMAGE_URI_03             = \"gcr.io/hybrid-vertex/train-rank-bandit-v2\"\n",
      "\n",
      "DOCKERNAME_04            = \"Dockerfile_train_bandit_e2e\"\n",
      "IMAGE_NAME_04            = \"train-mab-e2e-v2\"\n",
      "IMAGE_URI_04             = \"gcr.io/hybrid-vertex/train-mab-e2e-v2\"\n",
      "\n",
      "DOCKERNAME_04_pred       = \"Dockerfile_pred_bandit_e2e\"\n",
      "IMAGE_NAME_04_pred       = \"pred-mab-e2e-v2\"\n",
      "IMAGE_URI_04_pred        = \"gcr.io/hybrid-vertex/pred-mab-e2e-v2\"\n",
      "\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/local_docker_tfa\"\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb49f543-210a-4891-8cb1-4e0d6cc41dbf",
   "metadata": {},
   "source": [
    "### Set vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1df4915f-d72c-450b-8cb2-8ad753d8041e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# this repo\n",
    "from src.data import data_utils, data_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7cf564-e687-4e00-87c5-2ed9a47148bd",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c7f00eb-6d69-4bd1-bb38-aeeb7100018e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCS_DATA_PATH: gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/mv_b128_g12_a16/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/mv_b128_g12_a16_v4/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/mv_b128_g12_a16_v5/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/mv_b128_g12_a16_v6/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/train/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/val/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/vocabs/\n"
     ]
    }
   ],
   "source": [
    "EXAMPLE_GEN_GCS_PATH = data_config.EXAMPLE_GEN_GCS_PATH\n",
    "GCS_DATA_PATH = f\"{BUCKET_URI}/{EXAMPLE_GEN_GCS_PATH}\"\n",
    "\n",
    "print(f\"GCS_DATA_PATH: {GCS_DATA_PATH}\")\n",
    "\n",
    "!gsutil ls $GCS_DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4b883d-ce35-4084-a8e7-947e2fbee2c9",
   "metadata": {},
   "source": [
    "#### Custom prediction container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0d688ad-31c8-44ef-afd6-a44cde791744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY             = rl-movielens-rec-bandits-v2\n",
      "IMAGE_NAME_02_PRED_CPR = cpr-perarm-bandit-02e\n",
      "IMAGE_URI_02_PRED_CPR  = gcr.io/hybrid-vertex/cpr-perarm-bandit-02e\n",
      "REMOTE_IMAGE_NAME_CPR  = us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/cpr-perarm-bandit-02e\n"
     ]
    }
   ],
   "source": [
    "IMAGE_NAME_02_PRED_CPR = \"cpr-perarm-bandit-02e\"\n",
    "IMAGE_URI_02_PRED_CPR  = f\"gcr.io/hybrid-vertex/{IMAGE_NAME_02_PRED_CPR}\"\n",
    "REMOTE_IMAGE_NAME_CPR  = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE_NAME_02_PRED_CPR}\"\n",
    "\n",
    "print(f\"REPOSITORY             = {REPOSITORY}\")\n",
    "print(f\"IMAGE_NAME_02_PRED_CPR = {IMAGE_NAME_02_PRED_CPR}\")\n",
    "print(f\"IMAGE_URI_02_PRED_CPR  = {IMAGE_URI_02_PRED_CPR}\")\n",
    "print(f\"REMOTE_IMAGE_NAME_CPR  = {REMOTE_IMAGE_NAME_CPR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b0bc69-9d10-463d-8ddd-03ccba04a035",
   "metadata": {},
   "source": [
    "#### Set `ARTIFACTS_DIR` from previous experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77f7d476-aa76-4127-a103-cb701696014a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_OUTPUT_URI      : gs://rec-bandits-v2-hybrid-vertex-bucket/02-supervised-bandits-v1/run-20240313-192115\n",
      "ARTIFACTS_DIR        : gs://rec-bandits-v2-hybrid-vertex-bucket/02-supervised-bandits-v1/run-20240313-192115/artifacts\n",
      "EXISTING_VOCAB_FILE  : gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/vocabs/vocab_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "# EXPERIMENT_NAME      = \"02-online-1m-v6\"     # TODO - replace with an experiment that has saved policy\n",
    "# RUN_NAME             = \"run-20240220-025133\" # TODO - replace with a run that has saved policy\n",
    "EXPERIMENT_NAME      = \"02-supervised-bandits-v1\"\n",
    "RUN_NAME             = \"run-20240313-192115\"\n",
    "\n",
    "BASE_OUTPUT_URI      = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}\"\n",
    "ARTIFACTS_DIR        = f\"{BASE_OUTPUT_URI}/artifacts\"\n",
    "EXISTING_VOCAB_FILE  = f'gs://{BUCKET_NAME}/{EXAMPLE_GEN_GCS_PATH}/{VOCAB_SUBDIR}/{VOCAB_FILENAME}'\n",
    "\n",
    "print(f\"BASE_OUTPUT_URI      : {BASE_OUTPUT_URI}\")\n",
    "print(f\"ARTIFACTS_DIR        : {ARTIFACTS_DIR}\")\n",
    "print(f\"EXISTING_VOCAB_FILE  : {EXISTING_VOCAB_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d25599-2994-41ac-8bee-e12f83e96561",
   "metadata": {},
   "source": [
    "run this in terminal from root to clear `__pycache__` files..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8db2803f-08f5-415c-837c-8d5dccbd0250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find . | grep -E \"(/__pycache__$|\\.pyc$|\\.pyo$)\" | xargs rm -rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4412a2fd-fab3-4ef3-9e77-c5faa82a1380",
   "metadata": {
    "tags": []
   },
   "source": [
    "### (Optional) Setup credentials\n",
    "\n",
    "Setting up credentials is only required to run the custom serving container locally with GCS paths. Credentials set up is required to execute the `Predictor`'s `load` function, which downloads the model artifacts from Google Cloud Storage.\n",
    "\n",
    "To access Google Cloud Storage in your project, you'll need to set up credentials by using one of the following:\n",
    "\n",
    "1. User account\n",
    "2. Service account\n",
    "\n",
    "You can learn more about each of the above [here](https://cloud.google.com/docs/authentication#principals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0dd40b-c9df-49da-8469-45dfc3449b2e",
   "metadata": {},
   "source": [
    "Option 1: Use Google user credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "606a9815-1abb-40e9-8455-27c2d9778baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gcloud auth application-default login\n",
    "# !gcloud auth login\n",
    "\n",
    "# USER_ACCOUNT = \"TODO_USER_GCP_LOGIN\"  # TODO - 00-env-setup\n",
    "\n",
    "# !gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
    "#     --member=user:$USER_ACCOUNT \\\n",
    "#     --role=roles/storage.admin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8140adb4-e859-4a70-8638-90cad1a4715c",
   "metadata": {},
   "source": [
    "Option 2: Use Google Service Account credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aac8d414-ce5b-4bd8-bc72-be229e6a8a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gcloud services enable iam.googleapis.com\n",
    "# !gcloud auth login\n",
    "\n",
    "# !gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
    "#     --member=serviceAccount:$VERTEX_SA \\\n",
    "#     --role=roles/storage.admin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17288f10-218b-4c1a-a29e-5dd4c46c4392",
   "metadata": {},
   "source": [
    "Create credentials file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c6a9eca-eb1d-4b14-af6c-ba6806f60e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path=\"/home/jupyter/tf_vertex_agents/src\"\n",
    "# os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c10cabe0-1efa-43cb-a41c-9f430bf654a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREDENTIALS_FILE = \"./credentials.json\"\n",
    "\n",
    "# !gcloud iam service-accounts keys create $CREDENTIALS_FILE \\\n",
    "#     --iam-account=$VERTEX_SA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785f880d-1b3e-4cae-82ba-ff185f923771",
   "metadata": {},
   "source": [
    "### (Optional) Create Artifact Repository\n",
    "If you don't have an existing artifact repository, create one using the gcloud command below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54f30fbc-3801-4363-a70b-df4ca753e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gcloud artifacts repositories create $REPOSITORY --repository-format=docker --location=$LOCATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013c1afe-472a-4015-8f32-ed2997517d7b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f18d9b2-5ed1-4e88-9f00-09db736567b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from pprint import pprint\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ[\"PROJECT_ID\"]=PROJECT_ID\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import storage\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud.aiplatform.utils import prediction_utils\n",
    "\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "# this repo\n",
    "sys.path.append(\"..\")\n",
    "from src.utils import reward_factory as reward_factory\n",
    "from src.networks import encoding_network as emb_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbe405f4-795d-41fd-94a4-1ace7901e44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fbe1fe5-efca-45fa-8b52-fdd4d08e2608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b06449f-1eec-46e8-b1d7-939c096206b3",
   "metadata": {},
   "source": [
    "## Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d93e8a66-42eb-4824-842e-a4448ea44faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-supervised-bandits-v1/run-20240313-192115/artifacts/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-supervised-bandits-v1/run-20240313-192115/artifacts/fingerprint.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-supervised-bandits-v1/run-20240313-192115/artifacts/policy_specs.pbtxt\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-supervised-bandits-v1/run-20240313-192115/artifacts/saved_model.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-supervised-bandits-v1/run-20240313-192115/artifacts/assets/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-supervised-bandits-v1/run-20240313-192115/artifacts/variables/\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls $ARTIFACTS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fefd5bf0-c28c-4b9d-b4d2-542d1d78d39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f0e1c143400>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    ARTIFACTS_DIR, \n",
    "    load_specs_from_pbtxt=True\n",
    ")\n",
    "\n",
    "deployment_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77ee088-b1fc-4d5c-85fd-d160591d8246",
   "metadata": {},
   "source": [
    "# Create CPR directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff341715-7174-4d32-9e08-21d357e52f0b",
   "metadata": {},
   "source": [
    "## Structure code for CPR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88205a5d-3bfe-42cd-9ce3-e9071c7d5110",
   "metadata": {},
   "source": [
    "The CPR directory's structure will be the prediction serving container\n",
    "\n",
    "Becasue we are going to use the `build_cpr_model()` method for `LocalModel()`, it need to resemble:\n",
    "\n",
    "```\n",
    "            container_workdir/\n",
    "            |-- predictor.py\n",
    "            |-- requirements.txt\n",
    "            |-- user_code/\n",
    "            |   |-- utils.py\n",
    "            |   |-- custom_package.tar.gz\n",
    "            |   |-- ...\n",
    "            |-- ...\n",
    "```\n",
    "\n",
    "see `build_cpr_model()` [src](https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform/prediction/local_model.py#L147)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df65bdff-138a-46e6-8c22-4f74a5c484bf",
   "metadata": {},
   "source": [
    "### Saving deployment policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dca4fc-113c-4e41-a270-20cd4eefca1c",
   "metadata": {},
   "source": [
    "**Ultimately we'll need to call `py_tf_eager_policy.SavedModelPyTFEagerPolicy()` in our CPR...**\n",
    "\n",
    "We can't just pass the `ARTIFACTS_DIR` because that would result in the CPR container's `model_dir` to look like this:\n",
    "\n",
    "```\n",
    "cpr_model_dir/\n",
    "├── fingerprint.pb\n",
    "├── policy_specs.pbtxt\n",
    "├── saved_model.pb\n",
    "└── variables\n",
    "    ├── variables.data-00000-of-00001\n",
    "    └── variables.index\n",
    "```\n",
    "\n",
    "Instead, we need the CPR container's `model_dir` to have a subdirectory holding these files like:\n",
    "\n",
    "```\n",
    "cpr_model_dir/\n",
    "└── artifacts\n",
    "    ├── fingerprint.pb\n",
    "    ├── policy_specs.pbtxt\n",
    "    ├── saved_model.pb\n",
    "    └── variables\n",
    "        ├── variables.data-00000-of-00001\n",
    "        └── variables.index\n",
    "```\n",
    ".. this is compatible with `py_tf_eager_policy.SavedModelPyTFEagerPolicy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2885cf6-c33e-4f11-b6d2-48d4fb222c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-supervised-bandits-v1/run-20240313-192115/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-supervised-bandits-v1/run-20240313-192115/artifacts/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-supervised-bandits-v1/run-20240313-192115/logs/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-supervised-bandits-v1/run-20240313-192115/policy-server/\n"
     ]
    }
   ],
   "source": [
    "POLICY_SERVE_DIR_URI = f\"{BASE_OUTPUT_URI}/policy-server\"\n",
    "\n",
    "! gsutil -q cp -r $ARTIFACTS_DIR $POLICY_SERVE_DIR_URI/\n",
    "\n",
    "! gsutil ls $BASE_OUTPUT_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d948b0-703d-460b-b259-c92e984374ac",
   "metadata": {},
   "source": [
    "## Create local CPR directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "020173f1-fc02-4978-93be-1b858059ac1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/src\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73619465-d6ca-4816-9202-6b9e4310a175",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_CPR_DIR = \"cpr_dir\"\n",
    "CPR_SUBDIR = \"user_code\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65b7a2bb-607d-4024-824c-9bc8de0489ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf ./$LOCAL_CPR_DIR\n",
    "! mkdir ./$LOCAL_CPR_DIR\n",
    "! mkdir ./$LOCAL_CPR_DIR/$CPR_SUBDIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2bb5a41-7468-4ab6-be4e-f4f58db3199c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_code\n"
     ]
    }
   ],
   "source": [
    "!ls $LOCAL_CPR_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559f7d60-8836-4034-8fe5-040b4505cb4e",
   "metadata": {},
   "source": [
    "## Predictor\n",
    "\n",
    "* Implement a custom `Predictor` that loads in the preprocesor. The preprocessor will then be used at `preprocess` time\n",
    "* Note, the `PredictionHandle`r will be used for prediction request handling, and the following will be executed:\n",
    "\n",
    "> `self._predictor.postprocess(self._predictor.predict(self._predictor.preprocess(prediction_input)))`\n",
    "\n",
    "**references**\n",
    "* predictor_utils - [src](https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform/utils/prediction_utils.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "665d066e-ac3f-4c0d-82eb-e8d0d8933b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/src\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "255b9561-1657-4a5d-9aae-5b1d2094aed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cpr_dir/predictor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $LOCAL_CPR_DIR/predictor.py\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from typing import Dict, Any, Tuple\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "# google cloud\n",
    "from google.cloud.aiplatform.prediction.predictor import Predictor\n",
    "from google.cloud.aiplatform.utils import prediction_utils\n",
    "from google.cloud import storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "import tf_agents\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "# this repo\n",
    "sys.path.extend([f'./{name}' for name in os.listdir(\".\") if os.path.isdir(name)])\n",
    "\n",
    "from user_code import pred_config as pred_config\n",
    "from user_code import emb_features_pred as emb_features\n",
    "from user_code import reward_factory as reward_factory\n",
    "\n",
    "os.environ[\"PROJECT_ID\"] = pred_config.PROJECT_ID\n",
    "\n",
    "# ==================================\n",
    "# get trajectory step for prediction\n",
    "# ==================================\n",
    "def _get_pred_step(feature, reward_np):\n",
    "    \n",
    "    infer_step = ts.TimeStep(\n",
    "        tf.constant(ts.StepType.FIRST, dtype=tf.int32, shape=[],name='step_type'),\n",
    "        tf.constant(reward_np, dtype=tf.float32, shape=[], name='reward'),\n",
    "        tf.constant(1.0, dtype=tf.float32, shape=[], name='discount'),\n",
    "        feature\n",
    "    )\n",
    "    \n",
    "    return infer_step\n",
    "\n",
    "# ==================================\n",
    "# prediction logic\n",
    "# ==================================\n",
    "class BanditPolicyPredictor(Predictor):\n",
    "    \n",
    "    \"\"\"\n",
    "    Interface of the Predictor class for Custom Prediction Routines.\n",
    "    \n",
    "    The Predictor is responsible for the ML logic for processing a prediction request.\n",
    "    \n",
    "    Specifically, the Predictor must define:\n",
    "        (1) How to load all model artifacts used during prediction into memory.\n",
    "        (2) The logic that should be executed at predict time.\n",
    "    \n",
    "    When using the default PredictionHandler, the Predictor will be invoked as follows:\n",
    "    \n",
    "      predictor.postprocess(predictor.predict(predictor.preprocess(prediction_input)))\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self._local_vocab_filename = \"./vocab_dict.pkl\"\n",
    "        self._num_oov_buckets = pred_config.NUM_OOV_BUCKETS\n",
    "        self._global_embedding_size = pred_config.GLOBAL_EMBEDDING_SIZE\n",
    "        self._mv_embedding_size = pred_config.MV_EMBEDDING_SIZE\n",
    "        self.max_genre_length = pred_config.MAX_GENRE_LENGTH\n",
    "        return\n",
    "        \n",
    "    def load(self, artifacts_uri: str):\n",
    "        \"\"\"\n",
    "        Loads trained policy dir & vocabulary\n",
    "        Args:\n",
    "            artifacts_uri (str):\n",
    "                Required. The value of the environment variable AIP_STORAGE_URI.\n",
    "                has `artifacts/` as a sub directory \n",
    "        \n",
    "        \"\"\"\n",
    "        prediction_utils.download_model_artifacts(artifacts_uri)\n",
    "        \n",
    "        # init deploy policy\n",
    "        self._deployment_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "            'artifacts', load_specs_from_pbtxt=True\n",
    "        )\n",
    "        \n",
    "        # load vocab dict\n",
    "        filehandler = open(f\"{self._local_vocab_filename}\", 'rb')\n",
    "        self._vocab_dict = pkl.load(filehandler)\n",
    "        filehandler.close()\n",
    "        \n",
    "        # only if no custom preprocessor is defined\n",
    "        # self._preprocessor = preprocessor\n",
    "        \n",
    "    def preprocess(self, prediction_input: Dict): # -> Tuple[Dict, float]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            prediction_input (Any):\n",
    "                Required. The prediction input that needs to be preprocessed.\n",
    "        Returns:\n",
    "            The preprocessed prediction input.        \n",
    "        \"\"\"\n",
    "        # inputs = super().preprocess(prediction_input)\n",
    "        \n",
    "        dummy_arm = tf.zeros([1, pred_config.PER_ARM_DIM], dtype=tf.float32)\n",
    "        \n",
    "        batch_size = len(prediction_input) #[\"instances\"])\n",
    "        assert batch_size == 1, 'prediction batch_size must be == 1'\n",
    "        \n",
    "        self._embs = emb_features.EmbeddingModel(\n",
    "            vocab_dict = self._vocab_dict,\n",
    "            num_oov_buckets = self._num_oov_buckets,\n",
    "            global_emb_size = self._global_embedding_size,\n",
    "            mv_emb_size = self._mv_embedding_size,\n",
    "            max_genre_length = self.max_genre_length\n",
    "        )\n",
    "        \n",
    "        # preprocess example\n",
    "        rebuild_ex = {}\n",
    "\n",
    "        for x in prediction_input: #[\"instances\"]:\n",
    "            rebuild_ex['target_movie_id'] = tf.constant([x[\"target_movie_id\"]], dtype=tf.string)\n",
    "            rebuild_ex['target_movie_rating'] = tf.constant([x[\"target_movie_rating\"]], dtype=tf.float32)\n",
    "            rebuild_ex['target_rating_timestamp'] = tf.constant([x[\"target_rating_timestamp\"]], dtype=tf.int64)\n",
    "            rebuild_ex['target_movie_genres'] = tf.constant([x[\"target_movie_genres\"]], dtype=tf.string)\n",
    "            rebuild_ex['target_movie_year'] = tf.constant([x[\"target_movie_year\"]], dtype=tf.int64)\n",
    "            rebuild_ex['target_movie_title'] = tf.constant([x[\"target_movie_title\"]], dtype=tf.string)\n",
    "            rebuild_ex['user_id'] = tf.constant([x[\"user_id\"]], dtype=tf.string)\n",
    "            rebuild_ex['user_gender'] = tf.constant([x[\"user_gender\"]], dtype=tf.string)\n",
    "            rebuild_ex['user_age'] = tf.constant([x[\"user_age\"]], dtype=tf.int64)\n",
    "            rebuild_ex['user_occupation_text'] = tf.constant([x[\"user_occupation_text\"]], dtype=tf.string)\n",
    "            rebuild_ex['user_zip_code'] = tf.constant([x[\"user_zip_code\"]], dtype=tf.string)\n",
    "        \n",
    "        global_feat_infer = self._embs._get_global_context_features(rebuild_ex)\n",
    "        logging.info(f'global_feat_infer: {global_feat_infer}')          # tmp - debugging\n",
    "        \n",
    "        arm_feat_infer = self._embs._get_per_arm_features(rebuild_ex)    # tmp - debugging\n",
    "        logging.info(f'arm_feat_infer: {arm_feat_infer}')\n",
    "    \n",
    "        rewards = reward_factory._get_rewards(rebuild_ex)\n",
    "        logging.info(f'rewards: {rewards}')                              # tmp - debugging\n",
    "        \n",
    "        actual_reward = rewards.numpy()[0]\n",
    "        logging.info(f'actual_reward: {actual_reward}')                  # tmp - debugging\n",
    "        \n",
    "        arm_feat_infer = tf.reshape(arm_feat_infer, [1, pred_config.PER_ARM_DIM])\n",
    "        concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)      # tmp - debugging\n",
    "        \n",
    "        # flatten global\n",
    "        flat_global_infer = tf.reshape(global_feat_infer, [pred_config.GLOBAL_DIM])\n",
    "        feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "        logging.info(f'feature: {feature}')                              # tmp - debugging\n",
    "        \n",
    "        trajectory_step = _get_pred_step(feature, actual_reward)\n",
    "        logging.info(f'trajectory_step: {trajectory_step}')\n",
    "        \n",
    "        # prediction = self._deployment_policy.action(trajectory_step)\n",
    "        \n",
    "        return trajectory_step\n",
    "    \n",
    "    def predict(self, instances) -> Dict:\n",
    "        \"\"\"\n",
    "        Performs prediction i.e., policy takes action\n",
    "        \"\"\"\n",
    "        # prediction = self._deployment_policy.action(instances) # trajectory_step\n",
    "        # return {\"predictions\": prediction}\n",
    "        return self._deployment_policy.action(instances)\n",
    "        \n",
    "\n",
    "    def postprocess(self, prediction_results: Any) -> Any:\n",
    "        \"\"\" \n",
    "        Postprocesses the prediction results\n",
    "        \n",
    "        TODO:\n",
    "             Convert predictions to item IDs\n",
    "             \n",
    "        \"\"\"\n",
    "        processed_pred_dict = {\n",
    "            \"bandit_policy_type\" : int(prediction_results.info.bandit_policy_type[0]),\n",
    "            \"chosen_arm_features\" : prediction_results.info.chosen_arm_features.tolist(),\n",
    "            \"predicted_rewards_mean\" : prediction_results.info.predicted_rewards_mean.tolist(),\n",
    "            \"action\" : int(prediction_results.action.tolist()),\n",
    "        }\n",
    "        \n",
    "        return processed_pred_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5a0f3f-88c8-4f58-8b4a-ce4001bc05b2",
   "metadata": {},
   "source": [
    "## Entrypoint / Handler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc388e1-72cd-49e9-b2eb-e74dda59f69c",
   "metadata": {},
   "source": [
    "Custom containers require an **entrypoint** of the image that starts the model server\n",
    "* With Custom Prediction Routines (CPR), you **don't need to write the entrypoint** anymore. Vertex SDK will populate the entrypoint with the custom predictor you provide\n",
    "* However, we *can* implement a custom `handler()` method for the CPR model server, instead of using a pre-built http request handler. \n",
    "  * The `handler()` method handles the extraction of the prediction request from the HTTP request message\n",
    "  * Will also, call the `predictor()` method to pass the extraction instances data for the prediction request\n",
    "  \n",
    "For implementing our own Docker build process, see \"Scenario 4\" in [getting started with cpr](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage6/get_started_with_cpr.ipynb) notebook tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48271635-b1fe-46e8-bfda-129aa2363423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/src\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad590206-8653-411a-b20c-4b16a69e545e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cpr_dir/handler.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $LOCAL_CPR_DIR/handler.py\n",
    "\n",
    "import json\n",
    "import logging\n",
    "from fastapi import Response\n",
    "from google.cloud.aiplatform.prediction.handler import PredictionHandler\n",
    "\n",
    "class CprHandler(PredictionHandler):\n",
    "    \"\"\"\n",
    "    Default prediction handler for the pred requests sent to the application\n",
    "    \"\"\"\n",
    "\n",
    "    async def handle(self, request):\n",
    "        \"\"\"Handles a prediction request.\"\"\"\n",
    "        \n",
    "        request_body = await request.body()\n",
    "        logging.info(f'request_body: {request_body}')\n",
    "        \n",
    "        request_body_dict = json.loads(request_body)\n",
    "        logging.info(f'request_body_dict: {request_body_dict}')\n",
    "        \n",
    "        instances=request_body_dict[\"instances\"]\n",
    "        logging.info(f'instances: {instances}')\n",
    "        \n",
    "        prediction_results = self._predictor.postprocess(\n",
    "            self._predictor.predict(\n",
    "                self._predictor.preprocess(instances)\n",
    "            )\n",
    "        )\n",
    "                                                         \n",
    "        logging.info(f'prediction: {prediction_results}')\n",
    "\n",
    "        return Response(content=json.dumps(prediction_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd15510-a173-47a0-b4cd-2a9f091f45ae",
   "metadata": {},
   "source": [
    "## CPR package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3291ce02-feea-43f4-9c9e-a4b42c15544c",
   "metadata": {},
   "source": [
    "### data config\n",
    "\n",
    "> TODO - edit these as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dec13664-6ce0-41c9-9977-af3711f5612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PER_ARM_DIM           = 64\n",
    "GLOBAL_DIM            = 72\n",
    "NUM_OOV_BUCKETS       = 1\n",
    "GLOBAL_EMBEDDING_SIZE = 12\n",
    "MV_EMBEDDING_SIZE     = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc2464ea-3e36-48a1-917b-b4161c895bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID            = \"hybrid-vertex\"\n",
      "REGION                = \"us-central1\"\n",
      "PREFIX                = \"rec-bandits-v2\"\n",
      "BUCKET_NAME           = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "EXAMPLE_GEN_GCS_PATH  = \"data/movielens/m1m\"\n",
      "PER_ARM_DIM           = 64\n",
      "GLOBAL_DIM            = 72\n",
      "NUM_OOV_BUCKETS       = 1\n",
      "GLOBAL_EMBEDDING_SIZE = 12\n",
      "MV_EMBEDDING_SIZE     = 16\n",
      "MAX_GENRE_LENGTH      = 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_config = f\"\"\"\n",
    "PROJECT_ID            = \"{PROJECT_ID}\"\n",
    "REGION                = \"{REGION}\"\n",
    "PREFIX                = \"{PREFIX}\"\n",
    "BUCKET_NAME           = \"{BUCKET_NAME}\"\n",
    "EXAMPLE_GEN_GCS_PATH  = \"{EXAMPLE_GEN_GCS_PATH}\"\n",
    "PER_ARM_DIM           = {PER_ARM_DIM}\n",
    "GLOBAL_DIM            = {GLOBAL_DIM}\n",
    "NUM_OOV_BUCKETS       = {NUM_OOV_BUCKETS}\n",
    "GLOBAL_EMBEDDING_SIZE = {GLOBAL_EMBEDDING_SIZE}\n",
    "MV_EMBEDDING_SIZE     = {MV_EMBEDDING_SIZE}\n",
    "MAX_GENRE_LENGTH      = {data_config.MAX_GENRE_LENGTH}\n",
    "\"\"\"\n",
    "print(pred_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "087de52b-c233-4d2c-a3dc-62c446e0ae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_PRED_CONFIG_FILE = f\"{LOCAL_CPR_DIR}/{CPR_SUBDIR}/pred_config.py\"\n",
    "\n",
    "with open(LOCAL_PRED_CONFIG_FILE, 'w') as f:\n",
    "    f.write(pred_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1784ba3-46ed-4b3b-ae6b-84ed10f14c1e",
   "metadata": {},
   "source": [
    "### requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3ca8897-3ab2-4e31-86c7-7fc3fa0055ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version    : 2.13.0\n",
      "tf_agents version     : 0.17.0\n",
      "vertex_ai SDK version : 1.33.1\n"
     ]
    }
   ],
   "source": [
    "import tf_agents\n",
    "\n",
    "print(f\"tensorflow version    : {tf.__version__}\")\n",
    "print(f\"tf_agents version     : {tf_agents.__version__}\")\n",
    "print(f\"vertex_ai SDK version : {vertex_ai.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b63686b-f217-4657-9551-fe339053de9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cpr_dir/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile $LOCAL_CPR_DIR/requirements.txt\n",
    "google-cloud-aiplatform[prediction]==1.46.0\n",
    "google-cloud-storage\n",
    "numpy\n",
    "six\n",
    "typing-extensions\n",
    "tensorflow==2.13.0\n",
    "tf-agents==0.17.0\n",
    "urllib3\n",
    "pillow\n",
    "tensorflow-io\n",
    "tensorflow-datasets\n",
    "tensorflow-probability\n",
    "fastapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59ae56cd-34bb-455c-81a5-e91848c78401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/src\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac45b03-b9aa-4113-be47-47e95bc8194a",
   "metadata": {},
   "source": [
    "### copy remaining files to CPR dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b7eb3887-b4ec-4428-ad17-0f619e2676d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/vocabs/vocab_dict.pkl...\n",
      "/ [1 files][205.2 KiB/205.2 KiB]                                                \n",
      "Operation completed over 1 objects/205.2 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "## TODO - fix import issue for two lines below\n",
    "\n",
    "! cp ./utils/reward_factory.py ./$LOCAL_CPR_DIR/$CPR_SUBDIR/reward_factory.py\n",
    "! cp ./networks/encoding_network.py ./$LOCAL_CPR_DIR/$CPR_SUBDIR/emb_features_pred.py\n",
    "! gsutil cp $EXISTING_VOCAB_FILE ./$LOCAL_CPR_DIR/vocab_dict.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a6dd9ab3-ae33-47df-9ec9-43698947e5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mcpr_dir\u001b[00m\n",
      "├── handler.py\n",
      "├── predictor.py\n",
      "├── requirements.txt\n",
      "├── \u001b[01;34muser_code\u001b[00m\n",
      "│   ├── emb_features_pred.py\n",
      "│   ├── pred_config.py\n",
      "│   └── reward_factory.py\n",
      "└── vocab_dict.pkl\n",
      "\n",
      "1 directory, 7 files\n"
     ]
    }
   ],
   "source": [
    "!tree $LOCAL_CPR_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6677f422-8a08-4913-96c6-b60a153a9800",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Build and push CPR container to Vertex\n",
    "\n",
    "* `LocalModel` [src](https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform/prediction/local_model.py)\n",
    "\n",
    "**Build container**\n",
    "* To build a custom container, we also need to write an entrypoint of the image that starts the model server. \n",
    "* However, with the Custom Prediction Routine feature, you don't need to write the entrypoint anymore. \n",
    "* Vertex AI SDK will populate the entrypoint with the custom predictor you provide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e9c88a-7cbb-459b-9368-459e533de036",
   "metadata": {
    "tags": []
   },
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5fbcc1-e3ba-4015-a0b0-73edb0ad5d8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "**build_cpr_model**\n",
    "```\n",
    "    local_model = LocalModel.build_cpr_model(\n",
    "        \"./user_src_dir\",\n",
    "        \"us-docker.pkg.dev/$PROJECT/$REPOSITORY/$IMAGE_NAME$\",\n",
    "        predictor=$CUSTOM_PREDICTOR_CLASS,\n",
    "        requirements_path=\"./user_src_dir/requirements.txt\",\n",
    "        extra_packages=[\"./user_src_dir/user_code/custom_package.tar.gz\"],\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b0984c-629c-4316-b6cd-2bfa51688d23",
   "metadata": {
    "tags": []
   },
   "source": [
    "```\n",
    "Args:\n",
    "    src_dir (str):\n",
    "        Required. The path to the local directory including all needed files such as\n",
    "        predictor. The whole directory will be copied to the image.\n",
    "    output_image_uri (str):\n",
    "        Required. The image uri of the built image.\n",
    "    predictor (Type[Predictor]):\n",
    "        Optional. The custom predictor class consumed by handler to do prediction.\n",
    "    handler (Type[Handler]):\n",
    "        Required. The handler class to handle requests in the model server.\n",
    "    base_image (str):\n",
    "        Required. The base image used to build the custom images. The base image must\n",
    "        have python and pip installed where the two commands ``python`` and ``pip`` must be\n",
    "        available.\n",
    "    requirements_path (str):\n",
    "        Optional. The path to the local requirements.txt file. This file will be copied\n",
    "        to the image and the needed packages listed in it will be installed.\n",
    "    extra_packages (List[str]):\n",
    "        Optional. The list of user custom dependency packages to install.\n",
    "    no_cache (bool):\n",
    "        Required. Do not use cache when building the image. Using build cache usually\n",
    "        reduces the image building time. See\n",
    "        https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#leverage-build-cache\n",
    "        for more details.\n",
    "        \n",
    "Returns:\n",
    "    local model: Instantiated representation of the local model.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9862847d-cf80-4aa7-afd5-70d20cdc36f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create example prediction instance\n",
    "\n",
    "Create two formats:\n",
    "* json file\n",
    "* serialized dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "60f74502-4afd-470e-868a-37100dcd21f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "08dea81b-f893-4c03-a453-8f4791f0b734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"instances\": [\n",
      "        {\n",
      "            \"target_movie_genres\": [\n",
      "                \"Drama\",\n",
      "                \"UNK\",\n",
      "                \"UNK\",\n",
      "                \"UNK\",\n",
      "                \"UNK\",\n",
      "                \"UNK\",\n",
      "                \"UNK\",\n",
      "                \"UNK\",\n",
      "                \"UNK\",\n",
      "                \"UNK\"\n",
      "            ],\n",
      "            \"target_movie_id\": \"1775\",\n",
      "            \"target_movie_rating\": 4.0,\n",
      "            \"target_movie_title\": \"Live Flesh (1997)\",\n",
      "            \"target_movie_year\": 1997,\n",
      "            \"target_rating_timestamp\": 974612615,\n",
      "            \"user_age\": 50,\n",
      "            \"user_gender\": \"M\",\n",
      "            \"user_id\": \"2173\",\n",
      "            \"user_occupation_text\": \"programmer\",\n",
      "            \"user_zip_code\": \"87505\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "TEST_INSTANCE = {\n",
    "    \"instances\": [\n",
    "        {\n",
    "            'target_movie_genres': ['Drama', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK'],\n",
    "            'target_movie_id': '1775',\n",
    "            'target_movie_rating': 4.0,\n",
    "            'target_movie_title': 'Live Flesh (1997)',\n",
    "            'target_movie_year': 1997,\n",
    "            'target_rating_timestamp': 974612615,\n",
    "            'user_age': 50,\n",
    "            'user_gender': 'M',\n",
    "            'user_id': '2173',\n",
    "            'user_occupation_text': 'programmer',\n",
    "            'user_zip_code': '87505',\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "json_instance = json.dumps({\"instances\": TEST_INSTANCE['instances']})\n",
    "\n",
    "print(json.dumps({\"instances\": TEST_INSTANCE['instances']}, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9c6b306-854b-4156-891b-0708910b9dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = \"instances.json\"\n",
    "\n",
    "with open(INPUT_FILE, \"w\") as f:\n",
    "    json_dumps_str = json.dumps(TEST_INSTANCE)\n",
    "    f.write(json_dumps_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb5d3f6-4d7c-425a-9fa9-f444d0caf6d0",
   "metadata": {},
   "source": [
    "## Local build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a886577c-53dc-4c9a-9504-adc4ccd878e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/src\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c7a701f-9d30-42bf-bbf8-c474dac9f0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handler.py  predictor.py  requirements.txt  user_code  vocab_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "!ls $LOCAL_CPR_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b3ebbf40-e33e-45ba-bec9-bc493d421ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLICY_SERVE_DIR_URI   = gs://rec-bandits-v2-hybrid-vertex-bucket/02-supervised-bandits-v1/run-20240313-192115/policy-server\n",
      "REPOSITORY             = rl-movielens-rec-bandits-v2\n",
      "IMAGE_NAME_02_PRED_CPR = cpr-perarm-bandit-02e\n",
      "IMAGE_URI_02_PRED_CPR  = gcr.io/hybrid-vertex/cpr-perarm-bandit-02e\n",
      "REMOTE_IMAGE_NAME_CPR  = us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/cpr-perarm-bandit-02e\n"
     ]
    }
   ],
   "source": [
    "from google.cloud.aiplatform.prediction import LocalModel\n",
    "from cpr_dir.predictor import BanditPolicyPredictor\n",
    "from cpr_dir.handler import CprHandler\n",
    "\n",
    "# POLICY_SERVE_DIR_URI = f\"{BASE_OUTPUT_URI}/policy-server\"\n",
    "\n",
    "print(f\"POLICY_SERVE_DIR_URI   = {POLICY_SERVE_DIR_URI}\")\n",
    "print(f\"REPOSITORY             = {REPOSITORY}\")\n",
    "print(f\"IMAGE_NAME_02_PRED_CPR = {IMAGE_NAME_02_PRED_CPR}\")\n",
    "print(f\"IMAGE_URI_02_PRED_CPR  = {IMAGE_URI_02_PRED_CPR}\")\n",
    "print(f\"REMOTE_IMAGE_NAME_CPR  = {REMOTE_IMAGE_NAME_CPR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4cb74b0d-bfe2-469e-84fe-7997a4f17909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-supervised-bandits-v1/run-20240313-192115/artifacts/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-supervised-bandits-v1/run-20240313-192115/artifacts/fingerprint.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-supervised-bandits-v1/run-20240313-192115/artifacts/policy_specs.pbtxt\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-supervised-bandits-v1/run-20240313-192115/artifacts/saved_model.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-supervised-bandits-v1/run-20240313-192115/artifacts/assets/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-supervised-bandits-v1/run-20240313-192115/artifacts/variables/\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls $ARTIFACTS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2b5e1693-24b5-427b-bf30-1cc9636ddf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model = LocalModel.build_cpr_model(\n",
    "    src_dir= f\"./{LOCAL_CPR_DIR}\",\n",
    "    output_image_uri = REMOTE_IMAGE_NAME_CPR,\n",
    "    predictor= BanditPolicyPredictor,\n",
    "    handler= CprHandler,\n",
    "    base_image = 'tensorflow/tensorflow:2.13.0',\n",
    "    requirements_path=f\"./{LOCAL_CPR_DIR}/requirements.txt\",\n",
    "    no_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b514a0db-a8f1-4214-9b38-efe9c6ec0821",
   "metadata": {},
   "source": [
    "You can check out the serving container spec of the built image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d7a75746-1a63-4809-9ef0-57ebaa40d10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_uri: \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/cpr-perarm-bandit-02e\"\n",
       "predict_route: \"/predict\"\n",
       "health_route: \"/health\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_model.get_serving_container_spec()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fffce15-48ae-4d91-ad39-c7a98b5707c8",
   "metadata": {},
   "source": [
    "Once CPR model built, either (1) test it locally or (2) push image to registry and upload model to Vertex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aea9475-977a-404c-8195-5cf9335fbadc",
   "metadata": {},
   "source": [
    "### (Optional) deploy to local endpoint\n",
    "\n",
    "> **Deploy `LocalModel` to `LocalEndpoint`**\n",
    "\n",
    "This cuts the dev cycle iterations significantly!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b65a0280-0444-4f39-8198-265fd86cf355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/src\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "39d2f076-c44a-4d61-93a9-fbef5e7935ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_endpoint = local_model.deploy_to_local_endpoint(\n",
    "    artifact_uri=f\"{POLICY_SERVE_DIR_URI}\",\n",
    "    credential_path=CREDENTIALS_FILE,\n",
    "    container_ready_timeout=300,\n",
    "    container_ready_check_interval=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789143bb-1f26-4792-b1f0-e742d70a05bd",
   "metadata": {},
   "source": [
    "**Call `serve()` to start the conatiner for local traffic** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "faabd41c-9d49-41f0-a696-dd7408b4c2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "health_check     : b'{}'\n",
      "container_status : running\n",
      "container_port   : 8080\n",
      "env_vars         : {}\n",
      "ready_interval   : 10\n"
     ]
    }
   ],
   "source": [
    "local_endpoint.serve()\n",
    "\n",
    "health_check_response = local_endpoint.run_health_check()\n",
    "\n",
    "print(f\"health_check     : {health_check_response.content}\")\n",
    "print(f\"container_status : {local_endpoint.get_container_status()}\")\n",
    "print(f\"container_port   : {local_endpoint.container_port}\")\n",
    "print(f\"env_vars         : {local_endpoint.serving_container_environment_variables}\")\n",
    "print(f\"ready_interval   : {local_endpoint.container_ready_check_interval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e50a5759-50ea-4bde-8ebe-8bb28fedd14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: still don't understand how to use this\n",
    "local_endpoint.print_container_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14432ce-4a85-4751-9f61-cca31d5ee9ce",
   "metadata": {},
   "source": [
    "#### Test locally deployed policy endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "87c3ee0a-f3b2-454d-b14a-31165382a011",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_response: b'{\"bandit_policy_type\": 1, \"chosen_arm_features\": [-0.0397552028298378, -0.03813551738858223, 0.044915106147527695, 0.02706361934542656, 0.009737588465213776, -0.019834626466035843, 0.04776227846741676, 0.013513337820768356, 0.049553122371435165, 0.017252493649721146, -0.01818246766924858, -0.004529118537902832, 0.021304253488779068, 0.017105866223573685, -0.012950398027896881, -0.020180154591798782, 0.03597677871584892, -0.022177668288350105, 0.02848290465772152, -0.018231380730867386, -0.021156037226319313, 0.0037916938308626413, 0.02093610353767872, -0.039079517126083374, 0.017280887812376022, 0.04565785080194473, 0.035186875611543655, 0.009450845420360565, 0.02285950817167759, 0.001532208058051765, -0.0380002036690712, -0.04490354657173157, 0.008885107934474945, -0.012029051780700684, -0.02177565172314644, 0.038999903947114944, -0.00711219385266304, 0.016311775892972946, -0.04275301843881607, -0.008268356323242188, 0.021482016891241074, -0.032657526433467865, -0.02329789474606514, -0.009759318083524704, 0.027740132063627243, 0.029958251863718033, -0.01707826927304268, -0.024311233311891556, -0.19527733325958252, 0.004302207380533218, -0.001964978873729706, 0.24218016862869263, -0.18778306245803833, -0.09149825572967529, 0.055825766175985336, 0.2161731719970703, -0.16866326332092285, 0.10163599252700806, 0.09541018307209015, -0.051665790379047394, -0.10158169269561768, 0.013957619667053223, -0.042317211627960205, 0.059662945568561554], \"predicted_rewards_mean\": [2.5810296535491943, 2.444391965866089], \"action\": 0}'\n"
     ]
    }
   ],
   "source": [
    "predict_response = local_endpoint.predict(\n",
    "    request_file=INPUT_FILE,\n",
    "    headers={\"Content-Type\": \"application/json\"},\n",
    ")\n",
    "print(f\"predict_response: {predict_response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97d0be4-9010-4973-9a56-773e258d7486",
   "metadata": {},
   "source": [
    "and to get prediction response as a usable object: `.json()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b52754e8-5958-4183-a401-3cb93702ae6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0397552028298378, -0.03813551738858223, 0.044915106147527695, 0.02706361934542656, 0.009737588465213776, -0.019834626466035843, 0.04776227846741676, 0.013513337820768356, 0.049553122371435165, 0.017252493649721146, -0.01818246766924858, -0.004529118537902832, 0.021304253488779068, 0.017105866223573685, -0.012950398027896881, -0.020180154591798782, 0.03597677871584892, -0.022177668288350105, 0.02848290465772152, -0.018231380730867386, -0.021156037226319313, 0.0037916938308626413, 0.02093610353767872, -0.039079517126083374, 0.017280887812376022, 0.04565785080194473, 0.035186875611543655, 0.009450845420360565, 0.02285950817167759, 0.001532208058051765, -0.0380002036690712, -0.04490354657173157, 0.008885107934474945, -0.012029051780700684, -0.02177565172314644, 0.038999903947114944, -0.00711219385266304, 0.016311775892972946, -0.04275301843881607, -0.008268356323242188, 0.021482016891241074, -0.032657526433467865, -0.02329789474606514, -0.009759318083524704, 0.027740132063627243, 0.029958251863718033, -0.01707826927304268, -0.024311233311891556, -0.19527733325958252, 0.004302207380533218, -0.001964978873729706, 0.24218016862869263, -0.18778306245803833, -0.09149825572967529, 0.055825766175985336, 0.2161731719970703, -0.16866326332092285, 0.10163599252700806, 0.09541018307209015, -0.051665790379047394, -0.10158169269561768, 0.013957619667053223, -0.042317211627960205, 0.059662945568561554]\n"
     ]
    }
   ],
   "source": [
    "preds = predict_response.json()\n",
    "\n",
    "print(preds['chosen_arm_features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a569cb28-098d-45bc-8a44-691523f1130e",
   "metadata": {},
   "source": [
    "stop local endpoint container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8ba92506-324a-4b02-b1e8-228c13bc8c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_endpoint.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753357e3-6488-45f4-865f-536dcdd704ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deploy to Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee959f50-789f-4453-966a-54030fb9250d",
   "metadata": {},
   "source": [
    "**Push image to registry**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4fc23089-9550-43ae-8efd-b94c5eed3e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model.push_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c3ad87-c6fc-4c2b-a5be-b23ae77969fc",
   "metadata": {},
   "source": [
    "**Upload to Vertex Model Registry**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d24ebd4-2ae9-42b9-bcf0-efbdfb3cc868",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = \"v3-cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "45f35fb7-a9cd-4b3c-91e2-c2512e61aefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-supervised-bandits-v1/run-20240313-192115/policy-server/artifacts/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $POLICY_SERVE_DIR_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "661ca0a3-8df7-4d70-8356-ff62d3985966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "display_name    : cpr-bandit-v3-cpu\n",
      "uploaded_policy : <google.cloud.aiplatform.models.Model object at 0x7f0cec1b41f0> \n",
      "resource name: projects/934903580331/locations/us-central1/models/3886713131048632320\n"
     ]
    }
   ],
   "source": [
    "uploaded_policy = vertex_ai.Model.upload(\n",
    "    local_model=local_model,\n",
    "    display_name=f'cpr-bandit-{VERSION}',\n",
    "    artifact_uri=POLICY_SERVE_DIR_URI,\n",
    "    sync=True,\n",
    "    serving_container_environment_variables={\n",
    "        \"VERTEX_CPR_MAX_WORKERS\": 4,\n",
    "        \"VERTEX_CPR_WEB_CONCURRENCY\": 4\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"display_name    : {uploaded_policy.display_name}\")\n",
    "print(f\"uploaded_policy : {uploaded_policy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c41524d2-24c0-4ef0-9460-da60c18173aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "display_name : endpoint-cpr-bandit-v3-cpu\n",
      "endpoint     : <google.cloud.aiplatform.models.Endpoint object at 0x7f0cec190940> \n",
      "resource name: projects/934903580331/locations/us-central1/endpoints/7382884129957740544\n"
     ]
    }
   ],
   "source": [
    "endpoint = vertex_ai.Endpoint.create(\n",
    "    display_name=f'endpoint-cpr-bandit-{VERSION}',\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION,\n",
    "    sync=True,\n",
    ")\n",
    "\n",
    "print(f\"display_name : {endpoint.display_name}\")\n",
    "print(f\"endpoint     : {endpoint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aab8fb6c-5f53-473b-a770-287a975f9180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "display_name    : endpoint-cpr-bandit-v3-cpu\n",
      "\n",
      "deployed_policy : <google.cloud.aiplatform.models.Endpoint object at 0x7f0cec190940> \n",
      "resource name: projects/934903580331/locations/us-central1/endpoints/7382884129957740544\n"
     ]
    }
   ],
   "source": [
    "deployed_policy = uploaded_policy.deploy(\n",
    "    endpoint=endpoint,\n",
    "    deployed_model_display_name=f'deployed-cpr-bandit-{VERSION}',\n",
    "    machine_type=\"n1-standard-32\",\n",
    "    min_replica_count=1,\n",
    "    max_replica_count=2,\n",
    "    accelerator_type=None,\n",
    "    accelerator_count=0,\n",
    "    sync=True,\n",
    "    enable_access_logging=True,\n",
    ")\n",
    "\n",
    "print(f\"display_name    : {deployed_policy.display_name}\\n\")\n",
    "print(f\"deployed_policy : {deployed_policy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858364c7-a593-4cf8-8d68-56f484c393c6",
   "metadata": {},
   "source": [
    "### Test deployed policy endpoint\n",
    "\n",
    "*Note*: to have predictions display in response to the gcloud command, the handler should return a response dictionary like:\n",
    "\n",
    "> `{\"predictions\": post_processed_preds}`\n",
    "\n",
    "See [Send an online prediction request](https://cloud.google.com/vertex-ai/docs/predictions/get-online-predictions#predict-request) in docs for more details "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37096a2-bb9f-48e4-9edb-540131bde77a",
   "metadata": {},
   "source": [
    "#### gcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "91361966-9668-4fe3-acd3-c818447272a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-prediction-aiplatform.googleapis.com/]\n",
      "deployedModelId: '6544044718894874624'\n",
      "model: projects/934903580331/locations/us-central1/models/3886713131048632320\n",
      "modelDisplayName: cpr-bandit-v3-cpu\n",
      "modelVersionId: '1'\n"
     ]
    }
   ],
   "source": [
    "ENDPOINT_ID = endpoint.resource_name\n",
    "\n",
    "!gcloud ai endpoints predict $ENDPOINT_ID --region=$REGION --json-request=instances.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "35cd42a9-c058-4aa5-9337-c1bf7db54353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"instances\": [{\"target_movie_genres\": [\"Drama\", \"UNK\", \"UNK\", \"UNK\", \"UNK\", \"UNK\", \"UNK\", \"UNK\", \"UNK\", \"UNK\"], \"target_movie_id\": \"1775\", \"target_movie_rating\": 4.0, \"target_movie_title\": \"Live Flesh (1997)\", \"target_movie_year\": 1997, \"target_rating_timestamp\": 974612615, \"user_age\": 50, \"user_gender\": \"M\", \"user_id\": \"2173\", \"user_occupation_text\": \"programmer\", \"user_zip_code\": \"87505\"}]}'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# json_instance\n",
    "ENCODED_TEST_INSTANCE = json_instance.encode('utf-8')\n",
    "ENCODED_TEST_INSTANCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a98d549-5572-40c3-9fd3-96217a0f7d1f",
   "metadata": {},
   "source": [
    "#### Vertex SDK's raw predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4352b587-72a0-44f7-8097-b59a13f8d0f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bandit_policy_type': 1, 'chosen_arm_features': [-0.03418135643005371, 0.014238927513360977, -0.035376884043216705, -0.030898524448275566, 0.029633570462465286, 0.04977237060666084, 0.002097915858030319, 0.049689147621393204, 0.04013046994805336, -0.03785369545221329, -0.023264408111572266, -0.028406275436282158, 0.016198862344026566, 0.031409528106451035, -0.0464482307434082, -0.019686413928866386, 0.027092022821307182, 0.032301608473062515, -0.0012740996899083257, 0.02169101871550083, -0.039971426129341125, -0.009036685340106487, 0.011448188684880733, -0.03226463869214058, 0.03542361408472061, 0.03470868989825249, -0.029757792130112648, -0.03481779247522354, -0.013962672092020512, -0.015002253465354443, 0.01682540401816368, -0.02901960350573063, 0.033026840537786484, 0.019611980766057968, -0.013973880559206009, 0.008736848831176758, -0.007301889359951019, 0.04800843074917793, -0.03088761679828167, -0.009026013314723969, 0.00881868600845337, -0.008199773728847504, 0.017894532531499863, 0.01791715994477272, -0.0396762378513813, -0.02963576279580593, 0.035386811941862106, 0.003720581531524658, -0.2292807698249817, 0.2270589917898178, 0.09383542835712433, -0.1587696671485901, 0.18486888706684113, 0.019611362367868423, 0.21734678745269775, -0.23881971836090088, -0.19434446096420288, -0.04870682954788208, 0.04046637564897537, 0.243671253323555, 0.001158006489276886, 0.038751065731048584, 0.17340576648712158, -0.17974108457565308], 'predicted_rewards_mean': [2.526940107345581, 2.455695867538452], 'action': 0}\n"
     ]
    }
   ],
   "source": [
    "response = deployed_policy.raw_predict(\n",
    "    body = ENCODED_TEST_INSTANCE,\n",
    "    headers = {'Content-Type':'application/json'}\n",
    ").json()\n",
    "\n",
    "# print(response['chosen_arm_features'])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9e1ec838-8a0f-44bf-b848-aebb8605e741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"projects/934903580331/locations/us-central1/endpoints/7382884129957740544\"\n",
       "display_name: \"endpoint-cpr-bandit-v3-cpu\"\n",
       "deployed_models {\n",
       "  id: \"6544044718894874624\"\n",
       "  model: \"projects/934903580331/locations/us-central1/models/3886713131048632320\"\n",
       "  display_name: \"deployed-cpr-bandit-v3-cpu\"\n",
       "  create_time {\n",
       "    seconds: 1712343516\n",
       "    nanos: 348343000\n",
       "  }\n",
       "  dedicated_resources {\n",
       "    machine_spec {\n",
       "      machine_type: \"n1-standard-32\"\n",
       "    }\n",
       "    min_replica_count: 1\n",
       "    max_replica_count: 2\n",
       "  }\n",
       "  enable_access_logging: true\n",
       "  model_version_id: \"1\"\n",
       "}\n",
       "traffic_split {\n",
       "  key: \"6544044718894874624\"\n",
       "  value: 100\n",
       "}\n",
       "etag: \"AMEw9yPul3Qy_PxnNOAgH550btafWqyXRrF_j0iuHmse0fSKYDvwVZ8QFbcNUp4ee7ID\"\n",
       "create_time {\n",
       "  seconds: 1712343509\n",
       "  nanos: 298718000\n",
       "}\n",
       "update_time {\n",
       "  seconds: 1712343896\n",
       "  nanos: 632132000\n",
       "}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployed_policy.gca_resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3dfdac25-da86-4197-84f5-3225041f073d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/934903580331/locations/us-central1/endpoints/7382884129957740544',\n",
       " 'displayName': 'endpoint-cpr-bandit-v3-cpu',\n",
       " 'deployedModels': [{'id': '6544044718894874624',\n",
       "   'model': 'projects/934903580331/locations/us-central1/models/3886713131048632320',\n",
       "   'displayName': 'deployed-cpr-bandit-v3-cpu',\n",
       "   'createTime': '2024-04-05T18:58:36.348343Z',\n",
       "   'dedicatedResources': {'machineSpec': {'machineType': 'n1-standard-32'},\n",
       "    'minReplicaCount': 1,\n",
       "    'maxReplicaCount': 2},\n",
       "   'enableAccessLogging': True,\n",
       "   'modelVersionId': '1'}],\n",
       " 'trafficSplit': {'6544044718894874624': 100},\n",
       " 'etag': 'AMEw9yPul3Qy_PxnNOAgH550btafWqyXRrF_j0iuHmse0fSKYDvwVZ8QFbcNUp4ee7ID',\n",
       " 'createTime': '2024-04-05T18:58:29.298718Z',\n",
       " 'updateTime': '2024-04-05T19:04:56.632132Z'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployed_policy.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f58e24-9528-4774-9694-f473cad00cfa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6442ef8e-80b8-4dda-806e-2c5928afe877",
   "metadata": {},
   "source": [
    "**in terminal shell, run:**\n",
    "\n",
    "* `docker image ls`\n",
    "* `docker system df`\n",
    "* `docker system prune`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2edc6f-bfb1-479f-8162-b8e552a5331e",
   "metadata": {},
   "source": [
    "If you use the `-f` flag and specify the image's short or long ID, then this command untags and removes all images that match the specified ID.\n",
    "\n",
    "These aliases are equivalent:\n",
    "* `docker image rm`\n",
    "* `docker image remove`\n",
    "* `docker rmi`\n",
    "\n",
    "> `docker rmi gcr.io/hybrid-vertex/pred-perarm-feats-02e:latest`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7621cce-2927-4d84-881d-d8875cdf4286",
   "metadata": {},
   "source": [
    "Undeploy model and delete endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b0d1fe98-6588-4e6c-9bc6-fa300ea51b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint.delete(force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f033038-ae3e-45b2-82b0-597151efdec2",
   "metadata": {},
   "source": [
    "Delete policy uploaded to Vertex AI Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3a4b9e4c-d93a-46ef-9a9e-c12344555b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uploaded_policy.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e098affd-3723-438e-a44d-cf2f4c8f8fcf",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
