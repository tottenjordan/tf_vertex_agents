{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a03307f-546e-485f-bf38-3f8acc0b4196",
   "metadata": {},
   "source": [
    "# Custom Prediction Routine (CPR)\n",
    "\n",
    "> Build custom container for deploying trained policy to Vertex Prediction online endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcb75d2-ed29-467c-9767-708b3be22868",
   "metadata": {},
   "source": [
    "### references"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff022e80-96e3-44f1-8414-09106d7b2d20",
   "metadata": {},
   "source": [
    "* [src code](https://github.com/googleapis/python-aiplatform/tree/main/google/cloud/aiplatform/prediction)\n",
    "* [docs](https://cloud.google.com/vertex-ai/docs/predictions/custom-prediction-routines#run_the_container_locally_optional)\n",
    "* code examples\n",
    "  * [SDK_Custom_Predict_and_Handler_SDK_Integration](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/prediction/custom_prediction_routines/SDK_Custom_Predict_and_Handler_SDK_Integration.ipynb)\n",
    "  * [SDK_Custom_Preprocess](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/ef8b70db32813b8a2f128ab5ef1d170aea739e7f/notebooks/community/prediction/custom_prediction_routines/SDK_Custom_Preprocess.ipynb)\n",
    "  \n",
    "**In the built image, user provided files will be copied as follows:**\n",
    "\n",
    "```\n",
    "    container_workdir/\n",
    "    |-- predictor.py\n",
    "    |-- requirements.txt\n",
    "    |-- user_code/\n",
    "    |   |-- utils.py\n",
    "    |   |-- custom_package.tar.gz\n",
    "    |   |-- ...\n",
    "    |-- ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9302b843-5fbb-4c9f-b61a-5635c33d733b",
   "metadata": {},
   "source": [
    "## Notebook config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c8d374e-17c3-4512-a6be-73a0a91af5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/src\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "path=\"/home/jupyter/tf_vertex_agents/src\"\n",
    "os.chdir(path)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "025a45dd-21a9-4110-9ca5-294ae0911feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/src\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "994fffc8-c58f-4dd0-97c2-7116d8ecda43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "# PREFIX = 'mabv1'\n",
    "VERSION        = \"v2\"                       # TODO\n",
    "PREFIX         = f'rec-bandits-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8cc89ad-d0da-4421-b4fd-b232e733bd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"rec-bandits-v2\"\n",
      "VERSION                  = \"v2\"\n",
      "\n",
      "BUCKET_NAME              = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "DATA_PATH_KFP_DEMO       = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data/kfp_demo_data/u.data\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_NAME    = \"mvlens_rec_bandits_v2\"\n",
      "BIGQUERY_TABLE_NAME      = \"training_dataset\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-rec-bandits-v2\"\n",
      "\n",
      "DOCKERNAME_01            = \"Dockerfile_train_my_perarm_env\"\n",
      "IMAGE_NAME_01            = \"train-my-perarm-env-v2\"\n",
      "IMAGE_URI_01             = \"gcr.io/hybrid-vertex/train-my-perarm-env-v2\"\n",
      "\n",
      "DOCKERNAME_02            = \"Dockerfile_perarm_feats\"\n",
      "IMAGE_NAME_02            = \"train-perarm-feats-v2\"\n",
      "IMAGE_URI_02             = \"gcr.io/hybrid-vertex/train-perarm-feats-v2\"\n",
      "\n",
      "DOCKERNAME_03            = \"Dockerfile_ranking_bandit\"\n",
      "IMAGE_NAME_03            = \"train-rank-bandit-v2\"\n",
      "IMAGE_URI_03             = \"gcr.io/hybrid-vertex/train-rank-bandit-v2\"\n",
      "\n",
      "DOCKERNAME_04            = \"Dockerfile_train_mab_e2e\"\n",
      "IMAGE_NAME_04            = \"train-mab-e2e-v2\"\n",
      "IMAGE_URI_04             = \"gcr.io/hybrid-vertex/train-mab-e2e-v2\"\n",
      "\n",
      "DOCKERNAME_04_pred       = \"Dockerfile_pred_mab_e2e\"\n",
      "IMAGE_NAME_04_pred       = \"pred-mab-e2e-v2\"\n",
      "IMAGE_URI_04_pred        = \"gcr.io/hybrid-vertex/pred-mab-e2e-v2\"\n",
      "\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/local_docker_tfa\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb49f543-210a-4891-8cb1-4e0d6cc41dbf",
   "metadata": {},
   "source": [
    "### Set vars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7cf564-e687-4e00-87c5-2ed9a47148bd",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c7f00eb-6d69-4bd1-bb38-aeeb7100018e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_TAG: movielens-1m\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens-1m/vocab_dict.pkl\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens-1m/all/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens-1m/all_v2/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens-1m/full/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens-1m/full_v2/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens-1m/train/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens-1m/train_v1/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens-1m/val/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens-1m/val_v1/\n"
     ]
    }
   ],
   "source": [
    "DATA_TAG = \"movielens-1m\" # movielens-100k | movielens-1m\n",
    "\n",
    "print(f\"DATA_TAG: {DATA_TAG}\")\n",
    "\n",
    "! gsutil ls $DATA_PATH/$DATA_TAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4b883d-ce35-4084-a8e7-947e2fbee2c9",
   "metadata": {},
   "source": [
    "#### Custom prediction container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d688ad-31c8-44ef-afd6-a44cde791744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY             = rl-movielens-rec-bandits-v2\n",
      "IMAGE_NAME_02_PRED_CPR = cpr-perarm-bandit-02e\n",
      "IMAGE_URI_02_PRED_CPR  = gcr.io/hybrid-vertex/cpr-perarm-bandit-02e\n",
      "REMOTE_IMAGE_NAME_CPR  = us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/cpr-perarm-bandit-02e\n"
     ]
    }
   ],
   "source": [
    "IMAGE_NAME_02_PRED_CPR = \"cpr-perarm-bandit-02e\"\n",
    "IMAGE_URI_02_PRED_CPR  = f\"gcr.io/hybrid-vertex/{IMAGE_NAME_02_PRED_CPR}\"\n",
    "REMOTE_IMAGE_NAME_CPR  = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE_NAME_02_PRED_CPR}\"\n",
    "\n",
    "print(f\"REPOSITORY             = {REPOSITORY}\")\n",
    "print(f\"IMAGE_NAME_02_PRED_CPR = {IMAGE_NAME_02_PRED_CPR}\")\n",
    "print(f\"IMAGE_URI_02_PRED_CPR  = {IMAGE_URI_02_PRED_CPR}\")\n",
    "print(f\"REMOTE_IMAGE_NAME_CPR  = {REMOTE_IMAGE_NAME_CPR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b0bc69-9d10-463d-8ddd-03ccba04a035",
   "metadata": {},
   "source": [
    "#### Set `ARTIFACTS_DIR` from previous experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77f7d476-aa76-4127-a103-cb701696014a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_OUTPUT_URI      : gs://rec-bandits-v2-hybrid-vertex-bucket/02-online-1m-v6/run-20240220-025133\n",
      "ARTIFACTS_DIR        : gs://rec-bandits-v2-hybrid-vertex-bucket/02-online-1m-v6/run-20240220-025133/artifacts\n",
      "EXISTING_VOCAB_FILE  : gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens-1m/vocab_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "# EXPERIMENT_NAME     = \"02-scale-compare-v2\" # TODO\n",
    "# EXPERIMENT_NAME     = \"run-20231115-094131\" # TODO\n",
    "EXPERIMENT_NAME      = \"02-online-1m-v6\" # TODO\n",
    "RUN_NAME             = \"run-20240220-025133\" # TODO\n",
    "\n",
    "BASE_OUTPUT_URI      = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}\"\n",
    "ARTIFACTS_DIR        = f\"{BASE_OUTPUT_URI}/artifacts\"\n",
    "EXISTING_VOCAB_FILE  = f'gs://{BUCKET_NAME}/{DATA_GCS_PREFIX}/{DATA_TAG}/{VOCAB_FILENAME}'\n",
    "\n",
    "print(f\"BASE_OUTPUT_URI      : {BASE_OUTPUT_URI}\")\n",
    "print(f\"ARTIFACTS_DIR        : {ARTIFACTS_DIR}\")\n",
    "print(f\"EXISTING_VOCAB_FILE  : {EXISTING_VOCAB_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d25599-2994-41ac-8bee-e12f83e96561",
   "metadata": {},
   "source": [
    "run this in terminal from root to clear `__pycache__` files..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8db2803f-08f5-415c-837c-8d5dccbd0250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find . | grep -E \"(/__pycache__$|\\.pyc$|\\.pyo$)\" | xargs rm -rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4412a2fd-fab3-4ef3-9e77-c5faa82a1380",
   "metadata": {
    "tags": []
   },
   "source": [
    "### (Optional) Setup credentials\n",
    "\n",
    "Setting up credentials is only required to run the custom serving container locally with GCS paths. Credentials set up is required to execute the `Predictor`'s `load` function, which downloads the model artifacts from Google Cloud Storage.\n",
    "\n",
    "To access Google Cloud Storage in your project, you'll need to set up credentials by using one of the following:\n",
    "\n",
    "1. User account\n",
    "2. Service account\n",
    "\n",
    "You can learn more about each of the above [here](https://cloud.google.com/docs/authentication#principals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0dd40b-c9df-49da-8469-45dfc3449b2e",
   "metadata": {},
   "source": [
    "Option 1: Use Google user credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "606a9815-1abb-40e9-8455-27c2d9778baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gcloud auth application-default login\n",
    "# !gcloud auth login\n",
    "\n",
    "# USER_ACCOUNT = \"TODO_USER_GCP_LOGIN\"  # TODO - 00-env-setup\n",
    "\n",
    "# !gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
    "#     --member=user:$USER_ACCOUNT \\\n",
    "#     --role=roles/storage.admin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8140adb4-e859-4a70-8638-90cad1a4715c",
   "metadata": {},
   "source": [
    "Option 2: Use Google Service Account credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aac8d414-ce5b-4bd8-bc72-be229e6a8a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gcloud services enable iam.googleapis.com\n",
    "# !gcloud auth login\n",
    "\n",
    "# !gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
    "#     --member=serviceAccount:$VERTEX_SA \\\n",
    "#     --role=roles/storage.admin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17288f10-218b-4c1a-a29e-5dd4c46c4392",
   "metadata": {},
   "source": [
    "Create credentials file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c6a9eca-eb1d-4b14-af6c-ba6806f60e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path=\"/home/jupyter/tf_vertex_agents/src\"\n",
    "# os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c10cabe0-1efa-43cb-a41c-9f430bf654a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREDENTIALS_FILE = \"./credentials.json\"\n",
    "\n",
    "# !gcloud iam service-accounts keys create $CREDENTIALS_FILE \\\n",
    "#     --iam-account=$VERTEX_SA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785f880d-1b3e-4cae-82ba-ff185f923771",
   "metadata": {},
   "source": [
    "### (Optional) Create Artifact Repository\n",
    "If you don't have an existing artifact repository, create one using the gcloud command below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54f30fbc-3801-4363-a70b-df4ca753e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gcloud artifacts repositories create $REPOSITORY --repository-format=docker --location=$LOCATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013c1afe-472a-4015-8f32-ed2997517d7b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f18d9b2-5ed1-4e88-9f00-09db736567b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from pprint import pprint\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ[\"PROJECT_ID\"]=PROJECT_ID\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import storage\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud.aiplatform.utils import prediction_utils\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "# this repo\n",
    "sys.path.append(\"..\")\n",
    "# from src.per_arm_rl import data_utils\n",
    "# from src.per_arm_rl import data_config\n",
    "# from src.per_arm_rl import train_utils as train_utils\n",
    "from src.perarm_features import reward_factory as reward_factory\n",
    "from src.perarm_features import emb_features as emb_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbe405f4-795d-41fd-94a4-1ace7901e44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fbe1fe5-efca-45fa-8b52-fdd4d08e2608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec94222f-1d0d-48af-9539-6de0e46d0529",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = storage.Client(project=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b06449f-1eec-46e8-b1d7-939c096206b3",
   "metadata": {},
   "source": [
    "## Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d93e8a66-42eb-4824-842e-a4448ea44faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-online-1m-v6/run-20240220-025133/artifacts/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-online-1m-v6/run-20240220-025133/artifacts/fingerprint.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-online-1m-v6/run-20240220-025133/artifacts/policy_specs.pbtxt\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-online-1m-v6/run-20240220-025133/artifacts/saved_model.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-online-1m-v6/run-20240220-025133/artifacts/assets/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-online-1m-v6/run-20240220-025133/artifacts/variables/\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls $ARTIFACTS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fefd5bf0-c28c-4b9d-b4d2-542d1d78d39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f67d52e1c60>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    ARTIFACTS_DIR, \n",
    "    load_specs_from_pbtxt=True\n",
    ")\n",
    "\n",
    "deployment_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77ee088-b1fc-4d5c-85fd-d160591d8246",
   "metadata": {},
   "source": [
    "# Create CPR directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff341715-7174-4d32-9e08-21d357e52f0b",
   "metadata": {},
   "source": [
    "## Structure code for CPR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88205a5d-3bfe-42cd-9ce3-e9071c7d5110",
   "metadata": {},
   "source": [
    "The CPR directory's structure will be the prediction serving container\n",
    "\n",
    "Becasue we are going to use the `build_cpr_model()` method for `LocalModel()`, it need to resemble:\n",
    "\n",
    "```\n",
    "            container_workdir/\n",
    "            |-- predictor.py\n",
    "            |-- requirements.txt\n",
    "            |-- user_code/\n",
    "            |   |-- utils.py\n",
    "            |   |-- custom_package.tar.gz\n",
    "            |   |-- ...\n",
    "            |-- ...\n",
    "```\n",
    "\n",
    "see `build_cpr_model()` [src](https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform/prediction/local_model.py#L147)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df65bdff-138a-46e6-8c22-4f74a5c484bf",
   "metadata": {},
   "source": [
    "### Saving deployment policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dca4fc-113c-4e41-a270-20cd4eefca1c",
   "metadata": {},
   "source": [
    "**Ultimately we'll need to call `py_tf_eager_policy.SavedModelPyTFEagerPolicy()` in our CPR...**\n",
    "\n",
    "We can't just pass the `ARTIFACTS_DIR` because that would result in the CPR container's `model_dir` to look like this:\n",
    "\n",
    "```\n",
    "cpr_model_dir/\n",
    "├── fingerprint.pb\n",
    "├── policy_specs.pbtxt\n",
    "├── saved_model.pb\n",
    "└── variables\n",
    "    ├── variables.data-00000-of-00001\n",
    "    └── variables.index\n",
    "```\n",
    "\n",
    "Instead, we need the CPR container's `model_dir` to have a subdirectory holding these files like:\n",
    "\n",
    "```\n",
    "cpr_model_dir/\n",
    "└── artifacts\n",
    "    ├── fingerprint.pb\n",
    "    ├── policy_specs.pbtxt\n",
    "    ├── saved_model.pb\n",
    "    └── variables\n",
    "        ├── variables.data-00000-of-00001\n",
    "        └── variables.index\n",
    "```\n",
    ".. this is compatible with `py_tf_eager_policy.SavedModelPyTFEagerPolicy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2885cf6-c33e-4f11-b6d2-48d4fb222c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-online-1m-v6/run-20240220-025133/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-online-1m-v6/run-20240220-025133/artifacts/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-online-1m-v6/run-20240220-025133/logs/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-online-1m-v6/run-20240220-025133/policy-server/\n"
     ]
    }
   ],
   "source": [
    "POLICY_SERVE_DIR_URI = f\"{BASE_OUTPUT_URI}/policy-server\"\n",
    "\n",
    "! gsutil -q cp -r $ARTIFACTS_DIR $POLICY_SERVE_DIR_URI/\n",
    "\n",
    "! gsutil ls $BASE_OUTPUT_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d948b0-703d-460b-b259-c92e984374ac",
   "metadata": {},
   "source": [
    "## Create local CPR directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "933ac2c2-5511-4470-9d10-64769b5c2c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/src\n"
     ]
    }
   ],
   "source": [
    "path=\"/home/jupyter/tf_vertex_agents/src\"\n",
    "os.chdir(path)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73619465-d6ca-4816-9202-6b9e4310a175",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_CPR_DIR = \"cpr_dir\"\n",
    "CPR_SUBDIR = \"user_code\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65b7a2bb-607d-4024-824c-9bc8de0489ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf ./$LOCAL_CPR_DIR\n",
    "! mkdir ./$LOCAL_CPR_DIR\n",
    "! mkdir ./$LOCAL_CPR_DIR/$CPR_SUBDIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2bb5a41-7468-4ab6-be4e-f4f58db3199c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_code\n"
     ]
    }
   ],
   "source": [
    "!ls $LOCAL_CPR_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559f7d60-8836-4034-8fe5-040b4505cb4e",
   "metadata": {},
   "source": [
    "## Predictor\n",
    "\n",
    "* Implement a custom `Predictor` that loads in the preprocesor. The preprocessor will then be used at `preprocess` time\n",
    "* Note, the `PredictionHandle`r will be used for prediction request handling, and the following will be executed:\n",
    "\n",
    "> `self._predictor.postprocess(self._predictor.predict(self._predictor.preprocess(prediction_input)))`\n",
    "\n",
    "**references**\n",
    "* predictor_utils - [src](https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform/utils/prediction_utils.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "665d066e-ac3f-4c0d-82eb-e8d0d8933b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/src\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "255b9561-1657-4a5d-9aae-5b1d2094aed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cpr_dir/predictor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $LOCAL_CPR_DIR/predictor.py\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from typing import Dict, Any, Tuple\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "# google cloud\n",
    "from google.cloud.aiplatform.prediction.predictor import Predictor\n",
    "from google.cloud.aiplatform.utils import prediction_utils\n",
    "from google.cloud import storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "import tf_agents\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "# this repo\n",
    "sys.path.extend([f'./{name}' for name in os.listdir(\".\") if os.path.isdir(name)])\n",
    "\n",
    "from user_code import pred_config as pred_config\n",
    "from user_code import emb_features_pred as emb_features\n",
    "from user_code import reward_factory as reward_factory\n",
    "\n",
    "os.environ[\"PROJECT_ID\"] = pred_config.PROJECT_ID\n",
    "\n",
    "# ==================================\n",
    "# get trajectory step for prediction\n",
    "# ==================================\n",
    "def _get_pred_step(feature, reward_np):\n",
    "    \n",
    "    infer_step = ts.TimeStep(\n",
    "        tf.constant(ts.StepType.FIRST, dtype=tf.int32, shape=[],name='step_type'),\n",
    "        tf.constant(reward_np, dtype=tf.float32, shape=[], name='reward'),\n",
    "        tf.constant(1.0, dtype=tf.float32, shape=[], name='discount'),\n",
    "        feature\n",
    "    )\n",
    "    \n",
    "    return infer_step\n",
    "\n",
    "# ==================================\n",
    "# prediction logic\n",
    "# ==================================\n",
    "class BanditPolicyPredictor(Predictor):\n",
    "    \n",
    "    \"\"\"\n",
    "    Interface of the Predictor class for Custom Prediction Routines.\n",
    "    \n",
    "    The Predictor is responsible for the ML logic for processing a prediction request.\n",
    "    \n",
    "    Specifically, the Predictor must define:\n",
    "        (1) How to load all model artifacts used during prediction into memory.\n",
    "        (2) The logic that should be executed at predict time.\n",
    "    \n",
    "    When using the default PredictionHandler, the Predictor will be invoked as follows:\n",
    "    \n",
    "      predictor.postprocess(predictor.predict(predictor.preprocess(prediction_input)))\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self._local_vocab_filename = \"./vocab_dict.pkl\"\n",
    "        self._num_oov_buckets = pred_config.NUM_OOV_BUCKETS\n",
    "        self._global_embedding_size = pred_config.GLOBAL_EMBEDDING_SIZE\n",
    "        self._mv_embedding_size = pred_config.MV_EMBEDDING_SIZE\n",
    "        return\n",
    "        \n",
    "    def load(self, artifacts_uri: str):\n",
    "        \"\"\"\n",
    "        Loads trained policy dir & vocabulary\n",
    "        Args:\n",
    "            artifacts_uri (str):\n",
    "                Required. The value of the environment variable AIP_STORAGE_URI.\n",
    "                has `artifacts/` as a sub directory \n",
    "        \n",
    "        \"\"\"\n",
    "        prediction_utils.download_model_artifacts(artifacts_uri)\n",
    "        \n",
    "        # init deploy policy\n",
    "        self._deployment_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "            'artifacts', load_specs_from_pbtxt=True\n",
    "        )\n",
    "        \n",
    "        # load vocab dict\n",
    "        filehandler = open(f\"{self._local_vocab_filename}\", 'rb')\n",
    "        self._vocab_dict = pkl.load(filehandler)\n",
    "        filehandler.close()\n",
    "        \n",
    "        # only if no custom preprocessor is defined\n",
    "        # self._preprocessor = preprocessor\n",
    "        \n",
    "    def preprocess(self, prediction_input: Dict): # -> Tuple[Dict, float]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            prediction_input (Any):\n",
    "                Required. The prediction input that needs to be preprocessed.\n",
    "        Returns:\n",
    "            The preprocessed prediction input.        \n",
    "        \"\"\"\n",
    "        # inputs = super().preprocess(prediction_input)\n",
    "        \n",
    "        dummy_arm = tf.zeros([1, pred_config.PER_ARM_DIM], dtype=tf.float32)\n",
    "        \n",
    "        batch_size = len(prediction_input) #[\"instances\"])\n",
    "        assert batch_size == 1, 'prediction batch_size must be == 1'\n",
    "        \n",
    "        self._embs = emb_features.EmbeddingModel(\n",
    "            vocab_dict = self._vocab_dict,\n",
    "            num_oov_buckets = self._num_oov_buckets,\n",
    "            global_emb_size = self._global_embedding_size,\n",
    "            mv_emb_size = self._mv_embedding_size,\n",
    "        )\n",
    "        \n",
    "        # preprocess example\n",
    "        rebuild_ex = {}\n",
    "\n",
    "        for x in prediction_input: #[\"instances\"]:\n",
    "            rebuild_ex['bucketized_user_age'] = tf.constant([x[\"bucketized_user_age\"]], dtype=tf.float32)\n",
    "            rebuild_ex['movie_genres'] = tf.constant([x[\"movie_genres\"]], dtype=tf.int64)\n",
    "            rebuild_ex['movie_id'] = tf.constant([x[\"movie_id\"]], dtype=tf.string)\n",
    "            rebuild_ex['timestamp'] = tf.constant([x[\"timestamp\"]], dtype=tf.int64)\n",
    "            rebuild_ex['user_id'] = tf.constant([x[\"user_id\"]], dtype=tf.string)\n",
    "            rebuild_ex['user_occupation_text'] = tf.constant([x[\"user_occupation_text\"]], dtype=tf.string)\n",
    "            rebuild_ex['user_rating'] = tf.constant([x[\"user_rating\"]], dtype=tf.float32)\n",
    "        \n",
    "        global_feat_infer = self._embs._get_global_context_features(rebuild_ex)\n",
    "        logging.info(f'global_feat_infer: {global_feat_infer}')          # tmp - debugging\n",
    "        \n",
    "        arm_feat_infer = self._embs._get_per_arm_features(rebuild_ex)    # tmp - debugging\n",
    "        logging.info(f'arm_feat_infer: {arm_feat_infer}')\n",
    "    \n",
    "        rewards = reward_factory._get_rewards(rebuild_ex)\n",
    "        logging.info(f'rewards: {rewards}')                              # tmp - debugging\n",
    "        \n",
    "        actual_reward = rewards.numpy()[0]\n",
    "        logging.info(f'actual_reward: {actual_reward}')                  # tmp - debugging\n",
    "        \n",
    "        arm_feat_infer = tf.reshape(arm_feat_infer, [1, pred_config.PER_ARM_DIM])\n",
    "        concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)      # tmp - debugging\n",
    "        \n",
    "        # flatten global\n",
    "        flat_global_infer = tf.reshape(global_feat_infer, [pred_config.GLOBAL_DIM])\n",
    "        feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "        logging.info(f'feature: {feature}')                              # tmp - debugging\n",
    "        \n",
    "        trajectory_step = _get_pred_step(feature, actual_reward)\n",
    "        logging.info(f'trajectory_step: {trajectory_step}')\n",
    "        \n",
    "        # prediction = self._deployment_policy.action(trajectory_step)\n",
    "        \n",
    "        return trajectory_step\n",
    "    \n",
    "    def predict(self, instances) -> Dict:\n",
    "        \"\"\"\n",
    "        Performs prediction i.e., policy takes action\n",
    "        \"\"\"\n",
    "        # prediction = self._deployment_policy.action(instances) # trajectory_step\n",
    "        # return {\"predictions\": prediction}\n",
    "        return self._deployment_policy.action(instances)\n",
    "        \n",
    "\n",
    "    def postprocess(self, prediction_results: Any) -> Any:\n",
    "        \"\"\" \n",
    "        Postprocesses the prediction results\n",
    "        \n",
    "        TODO:\n",
    "             Convert predictions to item IDs\n",
    "             \n",
    "        \"\"\"\n",
    "        processed_pred_dict = {\n",
    "            \"bandit_policy_type\" : int(prediction_results.info.bandit_policy_type[0]),\n",
    "            \"chosen_arm_features\" : prediction_results.info.chosen_arm_features.tolist(),\n",
    "            \"predicted_rewards_mean\" : prediction_results.info.predicted_rewards_mean.tolist(),\n",
    "            \"action\" : int(prediction_results.action.tolist()),\n",
    "        }\n",
    "        \n",
    "        return processed_pred_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5a0f3f-88c8-4f58-8b4a-ce4001bc05b2",
   "metadata": {},
   "source": [
    "## Entrypoint / Handler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc388e1-72cd-49e9-b2eb-e74dda59f69c",
   "metadata": {},
   "source": [
    "Custom containers require an **entrypoint** of the image that starts the model server\n",
    "* With Custom Prediction Routines (CPR), you **don't need to write the entrypoint** anymore. Vertex SDK will populate the entrypoint with the custom predictor you provide\n",
    "* However, we *can* implement a custom `handler()` method for the CPR model server, instead of using a pre-built http request handler. \n",
    "  * The `handler()` method handles the extraction of the prediction request from the HTTP request message\n",
    "  * Will also, call the `predictor()` method to pass the extraction instances data for the prediction request\n",
    "  \n",
    "For implementing our own Docker build process, see \"Scenario 4\" in [getting started with cpr](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage6/get_started_with_cpr.ipynb) notebook tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48271635-b1fe-46e8-bfda-129aa2363423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/src\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad590206-8653-411a-b20c-4b16a69e545e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cpr_dir/handler.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $LOCAL_CPR_DIR/handler.py\n",
    "\n",
    "import json\n",
    "import logging\n",
    "from fastapi import Response\n",
    "from google.cloud.aiplatform.prediction.handler import PredictionHandler\n",
    "\n",
    "class CprHandler(PredictionHandler):\n",
    "    \"\"\"\n",
    "    Default prediction handler for the pred requests sent to the application\n",
    "    \"\"\"\n",
    "\n",
    "    async def handle(self, request):\n",
    "        \"\"\"Handles a prediction request.\"\"\"\n",
    "        \n",
    "        request_body = await request.body()\n",
    "        logging.info(f'request_body: {request_body}')\n",
    "        \n",
    "        request_body_dict = json.loads(request_body)\n",
    "        logging.info(f'request_body_dict: {request_body_dict}')\n",
    "        \n",
    "        instances=request_body_dict[\"instances\"]\n",
    "        logging.info(f'instances: {instances}')\n",
    "        \n",
    "        prediction_results = self._predictor.postprocess(\n",
    "            self._predictor.predict(\n",
    "                self._predictor.preprocess(instances)\n",
    "            )\n",
    "        )\n",
    "                                                         \n",
    "        logging.info(f'prediction: {prediction_results}')\n",
    "\n",
    "        return Response(content=json.dumps(prediction_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd15510-a173-47a0-b4cd-2a9f091f45ae",
   "metadata": {},
   "source": [
    "## CPR package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3291ce02-feea-43f4-9c9e-a4b42c15544c",
   "metadata": {},
   "source": [
    "### data config\n",
    "\n",
    "> TODO - edit these as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dec13664-6ce0-41c9-9977-af3711f5612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PER_ARM_DIM           = 64\n",
    "GLOBAL_DIM            = 64\n",
    "NUM_OOV_BUCKETS       = 1\n",
    "GLOBAL_EMBEDDING_SIZE = 16\n",
    "MV_EMBEDDING_SIZE     = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc2464ea-3e36-48a1-917b-b4161c895bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID            = \"hybrid-vertex\"\n",
      "REGION                = \"us-central1\"\n",
      "PREFIX                = \"rec-bandits-v2\"\n",
      "BUCKET_NAME           = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "DATA_TAG              = \"movielens-1m\"\n",
      "PER_ARM_DIM           = 64\n",
      "GLOBAL_DIM            = 64\n",
      "NUM_OOV_BUCKETS       = 1\n",
      "GLOBAL_EMBEDDING_SIZE = 16\n",
      "MV_EMBEDDING_SIZE     = 32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_config = f\"\"\"\n",
    "PROJECT_ID            = \"{PROJECT_ID}\"\n",
    "REGION                = \"{REGION}\"\n",
    "PREFIX                = \"{PREFIX}\"\n",
    "BUCKET_NAME           = \"{BUCKET_NAME}\"\n",
    "DATA_TAG              = \"{DATA_TAG}\"\n",
    "PER_ARM_DIM           = {PER_ARM_DIM}\n",
    "GLOBAL_DIM            = {GLOBAL_DIM}\n",
    "NUM_OOV_BUCKETS       = {NUM_OOV_BUCKETS}\n",
    "GLOBAL_EMBEDDING_SIZE = {GLOBAL_EMBEDDING_SIZE}\n",
    "MV_EMBEDDING_SIZE     = {MV_EMBEDDING_SIZE}\n",
    "\"\"\"\n",
    "print(pred_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "087de52b-c233-4d2c-a3dc-62c446e0ae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_PRED_CONFIG_FILE = f\"{LOCAL_CPR_DIR}/{CPR_SUBDIR}/pred_config.py\"\n",
    "\n",
    "with open(LOCAL_PRED_CONFIG_FILE, 'w') as f:\n",
    "    f.write(pred_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1784ba3-46ed-4b3b-ae6b-84ed10f14c1e",
   "metadata": {},
   "source": [
    "### requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3ca8897-3ab2-4e31-86c7-7fc3fa0055ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version    : 2.13.0\n",
      "tf_agents version     : 0.17.0\n",
      "vertex_ai SDK version : 1.33.1\n"
     ]
    }
   ],
   "source": [
    "import tf_agents\n",
    "\n",
    "print(f\"tensorflow version    : {tf.__version__}\")\n",
    "print(f\"tf_agents version     : {tf_agents.__version__}\")\n",
    "print(f\"vertex_ai SDK version : {vertex_ai.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b63686b-f217-4657-9551-fe339053de9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cpr_dir/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile $LOCAL_CPR_DIR/requirements.txt\n",
    "google-cloud-aiplatform[prediction]==1.41.0\n",
    "google-cloud-storage\n",
    "numpy\n",
    "six\n",
    "typing-extensions\n",
    "tensorflow==2.13.1\n",
    "tf-agents==0.17.0\n",
    "urllib3\n",
    "pillow\n",
    "tensorflow-io\n",
    "tensorflow-datasets\n",
    "tensorflow-probability\n",
    "fastapi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac45b03-b9aa-4113-be47-47e95bc8194a",
   "metadata": {},
   "source": [
    "### copy remaining files to CPR dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7eb3887-b4ec-4428-ad17-0f619e2676d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens-1m/vocab_dict.pkl...\n",
      "/ [1 files][525.5 KiB/525.5 KiB]                                                \n",
      "Operation completed over 1 objects/525.5 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "! cp ./perarm_features/reward_factory.py ./$LOCAL_CPR_DIR/$CPR_SUBDIR/reward_factory.py\n",
    "! cp ./perarm_features/emb_features.py ./$LOCAL_CPR_DIR/$CPR_SUBDIR/emb_features_pred.py\n",
    "! gsutil cp $EXISTING_VOCAB_FILE ./$LOCAL_CPR_DIR/vocab_dict.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6dd9ab3-ae33-47df-9ec9-43698947e5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mcpr_dir\u001b[00m\n",
      "├── handler.py\n",
      "├── predictor.py\n",
      "├── requirements.txt\n",
      "├── \u001b[01;34muser_code\u001b[00m\n",
      "│   ├── emb_features_pred.py\n",
      "│   ├── pred_config.py\n",
      "│   └── reward_factory.py\n",
      "└── vocab_dict.pkl\n",
      "\n",
      "1 directory, 7 files\n"
     ]
    }
   ],
   "source": [
    "!tree $LOCAL_CPR_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6677f422-8a08-4913-96c6-b60a153a9800",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Build and push CPR container to Vertex\n",
    "\n",
    "* `LocalModel` [src](https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform/prediction/local_model.py)\n",
    "\n",
    "**Build container**\n",
    "* To build a custom container, we also need to write an entrypoint of the image that starts the model server. \n",
    "* However, with the Custom Prediction Routine feature, you don't need to write the entrypoint anymore. \n",
    "* Vertex AI SDK will populate the entrypoint with the custom predictor you provide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e9c88a-7cbb-459b-9368-459e533de036",
   "metadata": {
    "tags": []
   },
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5fbcc1-e3ba-4015-a0b0-73edb0ad5d8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "**build_cpr_model**\n",
    "```\n",
    "    local_model = LocalModel.build_cpr_model(\n",
    "        \"./user_src_dir\",\n",
    "        \"us-docker.pkg.dev/$PROJECT/$REPOSITORY/$IMAGE_NAME$\",\n",
    "        predictor=$CUSTOM_PREDICTOR_CLASS,\n",
    "        requirements_path=\"./user_src_dir/requirements.txt\",\n",
    "        extra_packages=[\"./user_src_dir/user_code/custom_package.tar.gz\"],\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b0984c-629c-4316-b6cd-2bfa51688d23",
   "metadata": {
    "tags": []
   },
   "source": [
    "```\n",
    "Args:\n",
    "    src_dir (str):\n",
    "        Required. The path to the local directory including all needed files such as\n",
    "        predictor. The whole directory will be copied to the image.\n",
    "    output_image_uri (str):\n",
    "        Required. The image uri of the built image.\n",
    "    predictor (Type[Predictor]):\n",
    "        Optional. The custom predictor class consumed by handler to do prediction.\n",
    "    handler (Type[Handler]):\n",
    "        Required. The handler class to handle requests in the model server.\n",
    "    base_image (str):\n",
    "        Required. The base image used to build the custom images. The base image must\n",
    "        have python and pip installed where the two commands ``python`` and ``pip`` must be\n",
    "        available.\n",
    "    requirements_path (str):\n",
    "        Optional. The path to the local requirements.txt file. This file will be copied\n",
    "        to the image and the needed packages listed in it will be installed.\n",
    "    extra_packages (List[str]):\n",
    "        Optional. The list of user custom dependency packages to install.\n",
    "    no_cache (bool):\n",
    "        Required. Do not use cache when building the image. Using build cache usually\n",
    "        reduces the image building time. See\n",
    "        https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#leverage-build-cache\n",
    "        for more details.\n",
    "        \n",
    "Returns:\n",
    "    local model: Instantiated representation of the local model.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9862847d-cf80-4aa7-afd5-70d20cdc36f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create example prediction instance\n",
    "\n",
    "Create two formats:\n",
    "* json file\n",
    "* serialized dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60f74502-4afd-470e-868a-37100dcd21f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5415dd1-cc87-4e54-8db6-0312e68cc1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/src\n"
     ]
    }
   ],
   "source": [
    "path=\"/home/jupyter/tf_vertex_agents/src\"\n",
    "os.chdir(path)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08dea81b-f893-4c03-a453-8f4791f0b734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"instances\": [\n",
      "        {\n",
      "            \"bucketized_user_age\": 25.0,\n",
      "            \"movie_genres\": [\n",
      "                4\n",
      "            ],\n",
      "            \"movie_id\": \"211\",\n",
      "            \"timestamp\": 874948475,\n",
      "            \"user_id\": \"346\",\n",
      "            \"user_occupation_text\": \"other\",\n",
      "            \"user_rating\": 4.0\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "TEST_INSTANCE = {\n",
    "    \"instances\": [\n",
    "        {\n",
    "            'bucketized_user_age': 25.0,\n",
    "            'movie_genres': [4],\n",
    "            'movie_id': '211',\n",
    "            'timestamp': 874948475,\n",
    "            'user_id': '346',\n",
    "            'user_occupation_text': 'other',\n",
    "            'user_rating': 4.0\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "json_instance = json.dumps({\"instances\": TEST_INSTANCE['instances']})\n",
    "\n",
    "print(json.dumps({\"instances\": TEST_INSTANCE['instances']}, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9c6b306-854b-4156-891b-0708910b9dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = \"instances.json\"\n",
    "\n",
    "with open(INPUT_FILE, \"w\") as f:\n",
    "    json_dumps_str = json.dumps(TEST_INSTANCE)\n",
    "    f.write(json_dumps_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb5d3f6-4d7c-425a-9fa9-f444d0caf6d0",
   "metadata": {},
   "source": [
    "## Local build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a886577c-53dc-4c9a-9504-adc4ccd878e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/src\n"
     ]
    }
   ],
   "source": [
    "# path =\"/home/jupyter/tf_vertex_agents/src\"\n",
    "# os.chdir(path)\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5c7a701f-9d30-42bf-bbf8-c474dac9f0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handler.py  predictor.py  requirements.txt  user_code  vocab_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "!ls $LOCAL_CPR_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b3ebbf40-e33e-45ba-bec9-bc493d421ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLICY_SERVE_DIR_URI   = gs://rec-bandits-v2-hybrid-vertex-bucket/02-online-1m-v6/run-20240220-025133/policy-server\n",
      "REPOSITORY             = rl-movielens-rec-bandits-v2\n",
      "IMAGE_NAME_02_PRED_CPR = cpr-perarm-bandit-02e\n",
      "IMAGE_URI_02_PRED_CPR  = gcr.io/hybrid-vertex/cpr-perarm-bandit-02e\n",
      "REMOTE_IMAGE_NAME_CPR  = us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/cpr-perarm-bandit-02e\n"
     ]
    }
   ],
   "source": [
    "from google.cloud.aiplatform.prediction import LocalModel\n",
    "from cpr_dir.predictor import BanditPolicyPredictor\n",
    "from cpr_dir.handler import CprHandler\n",
    "\n",
    "# POLICY_SERVE_DIR_URI = f\"{BASE_OUTPUT_URI}/policy-server\"\n",
    "\n",
    "print(f\"POLICY_SERVE_DIR_URI   = {POLICY_SERVE_DIR_URI}\")\n",
    "print(f\"REPOSITORY             = {REPOSITORY}\")\n",
    "print(f\"IMAGE_NAME_02_PRED_CPR = {IMAGE_NAME_02_PRED_CPR}\")\n",
    "print(f\"IMAGE_URI_02_PRED_CPR  = {IMAGE_URI_02_PRED_CPR}\")\n",
    "print(f\"REMOTE_IMAGE_NAME_CPR  = {REMOTE_IMAGE_NAME_CPR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4cb74b0d-bfe2-469e-84fe-7997a4f17909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-online-1m-v6/run-20240220-025133/artifacts/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-online-1m-v6/run-20240220-025133/artifacts/fingerprint.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-online-1m-v6/run-20240220-025133/artifacts/policy_specs.pbtxt\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-online-1m-v6/run-20240220-025133/artifacts/saved_model.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-online-1m-v6/run-20240220-025133/artifacts/assets/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-online-1m-v6/run-20240220-025133/artifacts/variables/\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls $ARTIFACTS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b5e1693-24b5-427b-bf30-1cc9636ddf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/subprocess.py:955: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
      "/opt/conda/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
     ]
    }
   ],
   "source": [
    "local_model = LocalModel.build_cpr_model(\n",
    "    src_dir= f\"./{LOCAL_CPR_DIR}\",\n",
    "    output_image_uri = REMOTE_IMAGE_NAME_CPR,\n",
    "    predictor= BanditPolicyPredictor,\n",
    "    handler= CprHandler,\n",
    "    # base_image = 'tiangolo/uvicorn-gunicorn-fastapi:python3.10', # fastapi referenced in Predictor\n",
    "    base_image = 'tensorflow/tensorflow:2.14.0',\n",
    "    requirements_path=f\"./{LOCAL_CPR_DIR}/requirements.txt\",\n",
    "    no_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b514a0db-a8f1-4214-9b38-efe9c6ec0821",
   "metadata": {},
   "source": [
    "You can check out the serving container spec of the built image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d7a75746-1a63-4809-9ef0-57ebaa40d10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_uri: \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/cpr-perarm-bandit-02e\"\n",
       "predict_route: \"/predict\"\n",
       "health_route: \"/health\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_model.get_serving_container_spec()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fffce15-48ae-4d91-ad39-c7a98b5707c8",
   "metadata": {},
   "source": [
    "Once CPR model built, either (1) test it locally or (2) push image to registry and upload model to Vertex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aea9475-977a-404c-8195-5cf9335fbadc",
   "metadata": {},
   "source": [
    "### (Optional) deploy to local endpoint\n",
    "\n",
    "> **Deploy `LocalModel` to `LocalEndpoint`**\n",
    "\n",
    "This cuts the dev cycle iterations significantly!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b65a0280-0444-4f39-8198-265fd86cf355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/src\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "39d2f076-c44a-4d61-93a9-fbef5e7935ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_endpoint = local_model.deploy_to_local_endpoint(\n",
    "    artifact_uri=f\"{POLICY_SERVE_DIR_URI}\",\n",
    "    credential_path=CREDENTIALS_FILE,\n",
    "    container_ready_timeout=300,\n",
    "    container_ready_check_interval=10\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789143bb-1f26-4792-b1f0-e742d70a05bd",
   "metadata": {},
   "source": [
    "**Call `serve()` to start the conatiner for local traffic** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "faabd41c-9d49-41f0-a696-dd7408b4c2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "health_check     : b'{}'\n",
      "container_status : running\n",
      "container_port   : 8080\n",
      "env_vars         : {}\n",
      "ready_interval   : 10\n"
     ]
    }
   ],
   "source": [
    "local_endpoint.serve()\n",
    "\n",
    "health_check_response = local_endpoint.run_health_check()\n",
    "\n",
    "print(f\"health_check     : {health_check_response.content}\")\n",
    "print(f\"container_status : {local_endpoint.get_container_status()}\")\n",
    "print(f\"container_port   : {local_endpoint.container_port}\")\n",
    "print(f\"env_vars         : {local_endpoint.serving_container_environment_variables}\")\n",
    "print(f\"ready_interval   : {local_endpoint.container_ready_check_interval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e50a5759-50ea-4bde-8ebe-8bb28fedd14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: still don't understand how to use this\n",
    "local_endpoint.print_container_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14432ce-4a85-4751-9f61-cca31d5ee9ce",
   "metadata": {},
   "source": [
    "#### Test locally deployed policy endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "87c3ee0a-f3b2-454d-b14a-31165382a011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_response: b'{\"bandit_policy_type\": 1, \"chosen_arm_features\": [0.024590615183115005, -0.00033376365900039673, -0.03397611528635025, 0.04492168501019478, -0.033947668969631195, 0.03606318309903145, 0.025834273546934128, -0.03723832219839096, 0.019868027418851852, 0.02900315448641777, 0.00570303201675415, -0.021642232313752174, 0.02098197117447853, -0.009108174592256546, -0.04313721880316734, -0.013914097100496292, 0.01598529890179634, -0.022642744705080986, 0.00047028064727783203, -0.025703513994812965, 0.025680188089609146, -0.0006519779562950134, -0.010534681379795074, -0.0050194151699543, -0.011823724955320358, -0.04261663183569908, 0.04181345924735069, -0.0022050142288208008, 0.003776051104068756, 0.012430153787136078, 0.022539202123880386, -0.011918164789676666, 0.04904935136437416, 0.04570366069674492, 0.002466190606355667, -0.0466778390109539, 0.025574151426553726, -0.013656318187713623, -0.04398539289832115, 0.0373685248196125, 0.0038287751376628876, 0.02021322026848793, 0.029208216816186905, -0.012430977076292038, -0.012124467641115189, -0.011590622365474701, -0.03287925571203232, -0.029714107513427734, -0.015558145940303802, -0.03421800211071968, 0.03434126451611519, 0.033421460539102554, 0.04076157882809639, -0.020752429962158203, 0.030656997114419937, 0.00040264055132865906, 0.01530316099524498, 0.0208643339574337, 0.02004697546362877, 0.03484325483441353, 0.03315216675400734, 0.022516075521707535, 0.005508244037628174, 0.04199213907122612], \"predicted_rewards_mean\": [3.5834827423095703, 3.5834827423095703], \"action\": 0}'\n"
     ]
    }
   ],
   "source": [
    "predict_response = local_endpoint.predict(\n",
    "    request_file=INPUT_FILE,\n",
    "    headers={\"Content-Type\": \"application/json\"},\n",
    ")\n",
    "print(f\"predict_response: {predict_response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97d0be4-9010-4973-9a56-773e258d7486",
   "metadata": {},
   "source": [
    "and to get prediction response as a usable object: `.json()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b52754e8-5958-4183-a401-3cb93702ae6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.024590615183115005, -0.00033376365900039673, -0.03397611528635025, 0.04492168501019478, -0.033947668969631195, 0.03606318309903145, 0.025834273546934128, -0.03723832219839096, 0.019868027418851852, 0.02900315448641777, 0.00570303201675415, -0.021642232313752174, 0.02098197117447853, -0.009108174592256546, -0.04313721880316734, -0.013914097100496292, 0.01598529890179634, -0.022642744705080986, 0.00047028064727783203, -0.025703513994812965, 0.025680188089609146, -0.0006519779562950134, -0.010534681379795074, -0.0050194151699543, -0.011823724955320358, -0.04261663183569908, 0.04181345924735069, -0.0022050142288208008, 0.003776051104068756, 0.012430153787136078, 0.022539202123880386, -0.011918164789676666, 0.04904935136437416, 0.04570366069674492, 0.002466190606355667, -0.0466778390109539, 0.025574151426553726, -0.013656318187713623, -0.04398539289832115, 0.0373685248196125, 0.0038287751376628876, 0.02021322026848793, 0.029208216816186905, -0.012430977076292038, -0.012124467641115189, -0.011590622365474701, -0.03287925571203232, -0.029714107513427734, -0.015558145940303802, -0.03421800211071968, 0.03434126451611519, 0.033421460539102554, 0.04076157882809639, -0.020752429962158203, 0.030656997114419937, 0.00040264055132865906, 0.01530316099524498, 0.0208643339574337, 0.02004697546362877, 0.03484325483441353, 0.03315216675400734, 0.022516075521707535, 0.005508244037628174, 0.04199213907122612]\n"
     ]
    }
   ],
   "source": [
    "preds = predict_response.json()\n",
    "\n",
    "print(preds['chosen_arm_features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a569cb28-098d-45bc-8a44-691523f1130e",
   "metadata": {},
   "source": [
    "stop local endpoint container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8ba92506-324a-4b02-b1e8-228c13bc8c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_endpoint.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753357e3-6488-45f4-865f-536dcdd704ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deploy to Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee959f50-789f-4453-966a-54030fb9250d",
   "metadata": {},
   "source": [
    "**Push image to registry**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4fc23089-9550-43ae-8efd-b94c5eed3e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/subprocess.py:955: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
      "/opt/conda/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
     ]
    }
   ],
   "source": [
    "local_model.push_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c3ad87-c6fc-4c2b-a5be-b23ae77969fc",
   "metadata": {},
   "source": [
    "**Upload to Vertex Model Registry**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6d24ebd4-2ae9-42b9-bcf0-efbdfb3cc868",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = \"v1-cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "45f35fb7-a9cd-4b3c-91e2-c2512e61aefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02-online-1m-v6/run-20240220-025133/policy-server/artifacts/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $POLICY_SERVE_DIR_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "661ca0a3-8df7-4d70-8356-ff62d3985966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "display_name    : cpr-bandit-from-local-v1-cpu\n",
      "uploaded_policy : <google.cloud.aiplatform.models.Model object at 0x7f6614143a00> \n",
      "resource name: projects/934903580331/locations/us-central1/models/1712139715563487232\n"
     ]
    }
   ],
   "source": [
    "uploaded_policy = vertex_ai.Model.upload(\n",
    "    local_model=local_model,\n",
    "    display_name=f'cpr-bandit-from-local-{VERSION}',\n",
    "    artifact_uri=POLICY_SERVE_DIR_URI,\n",
    "    sync=True,\n",
    ")\n",
    "\n",
    "print(f\"display_name    : {uploaded_policy.display_name}\")\n",
    "print(f\"uploaded_policy : {uploaded_policy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c41524d2-24c0-4ef0-9460-da60c18173aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "display_name : endpoint-cpr-bandit-v1-cpu\n",
      "endpoint     : <google.cloud.aiplatform.models.Endpoint object at 0x7f666c33d7b0> \n",
      "resource name: projects/934903580331/locations/us-central1/endpoints/1089125640940027904\n"
     ]
    }
   ],
   "source": [
    "endpoint = vertex_ai.Endpoint.create(\n",
    "    display_name=f'endpoint-cpr-bandit-{VERSION}',\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION,\n",
    "    sync=True,\n",
    ")\n",
    "\n",
    "print(f\"display_name : {endpoint.display_name}\")\n",
    "print(f\"endpoint     : {endpoint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aab8fb6c-5f53-473b-a770-287a975f9180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "display_name    : endpoint-cpr-bandit-v1-cpu\n",
      "\n",
      "deployed_policy : <google.cloud.aiplatform.models.Endpoint object at 0x7f666c33d7b0> \n",
      "resource name: projects/934903580331/locations/us-central1/endpoints/1089125640940027904\n"
     ]
    }
   ],
   "source": [
    "deployed_policy = uploaded_policy.deploy(\n",
    "    endpoint=endpoint,\n",
    "    deployed_model_display_name=f'deployed-cpr-bandit-{VERSION}',\n",
    "    machine_type=\"n1-standard-4\",\n",
    "    min_replica_count=1,\n",
    "    max_replica_count=1,\n",
    "    accelerator_type=None,\n",
    "    accelerator_count=0,\n",
    "    sync=True,\n",
    "    enable_access_logging=True,\n",
    ")\n",
    "\n",
    "print(f\"display_name    : {deployed_policy.display_name}\\n\")\n",
    "print(f\"deployed_policy : {deployed_policy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858364c7-a593-4cf8-8d68-56f484c393c6",
   "metadata": {},
   "source": [
    "### Test deployed policy endpoint\n",
    "\n",
    "*Note*: to have predictions display in response to the gcloud command, the handler should return a response dictionary like:\n",
    "\n",
    "> `{\"predictions\": post_processed_preds}`\n",
    "\n",
    "See [Send an online prediction request](https://cloud.google.com/vertex-ai/docs/predictions/get-online-predictions#predict-request) in docs for more details "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37096a2-bb9f-48e4-9edb-540131bde77a",
   "metadata": {},
   "source": [
    "#### gcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "91361966-9668-4fe3-acd3-c818447272a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-prediction-aiplatform.googleapis.com/]\n",
      "deployedModelId: '18284878369914880'\n",
      "model: projects/934903580331/locations/us-central1/models/1712139715563487232\n",
      "modelDisplayName: cpr-bandit-from-local-v1-cpu\n",
      "modelVersionId: '1'\n"
     ]
    }
   ],
   "source": [
    "ENDPOINT_ID = endpoint.resource_name\n",
    "\n",
    "!gcloud ai endpoints predict $ENDPOINT_ID --region=$REGION --json-request=instances.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "35cd42a9-c058-4aa5-9337-c1bf7db54353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"instances\": [{\"bucketized_user_age\": 25.0, \"movie_genres\": [4], \"movie_id\": \"211\", \"timestamp\": 874948475, \"user_id\": \"346\", \"user_occupation_text\": \"other\", \"user_rating\": 4.0}]}'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# json_dumps_str = json.dumps(TEST_INSTANCE)\n",
    "\n",
    "# json_instance\n",
    "ENCODED_TEST_INSTANCE = json_instance.encode('utf-8')\n",
    "ENCODED_TEST_INSTANCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a98d549-5572-40c3-9fd3-96217a0f7d1f",
   "metadata": {},
   "source": [
    "#### Vertex SDK's raw predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4352b587-72a0-44f7-8097-b59a13f8d0f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bandit_policy_type': 1, 'chosen_arm_features': [0.012386918067932129, -0.015644621104002, -0.009408485144376755, -0.031144320964813232, 0.049573127180337906, -0.00806887075304985, -0.04555115848779678, 0.004090465605258942, 0.003566741943359375, -0.025310445576906204, -0.03044682741165161, -0.04963138327002525, 0.0037688501179218292, -0.0129280686378479, -0.04948903247714043, 0.0015893355011940002, -0.040560126304626465, 0.01589367166161537, -0.044217027723789215, -0.0026133060455322266, 0.043408479541540146, 0.048723507672548294, -0.02227889373898506, 0.0333329476416111, -0.0036832578480243683, 0.037600401788949966, -0.013880264014005661, 0.0008616447448730469, -0.01647765561938286, -0.0027528293430805206, -0.007353566586971283, 0.029232848435640335, 0.008020617067813873, 0.031404364854097366, 0.04713099077343941, -0.02941749058663845, -0.04171924665570259, 0.034284066408872604, 0.013429012149572372, 0.047239791601896286, -0.023427022621035576, 0.021618355065584183, -0.01982797496020794, 0.01043921709060669, 0.043291520327329636, -0.0007582679390907288, -0.048004936426877975, 0.012345470488071442, -0.0053817033767700195, -0.021520305424928665, -0.048733603209257126, 0.022649873048067093, -0.0038850903511047363, -0.004932809621095657, -0.02803562954068184, 0.044663358479738235, -0.006840705871582031, -0.022370148450136185, 0.04128119722008705, 0.03171208128333092, 0.025735054165124893, -0.019917070865631104, -0.044333625584840775, -0.03978998586535454], 'predicted_rewards_mean': [3.5834827423095703, 3.5834827423095703], 'action': 0}\n"
     ]
    }
   ],
   "source": [
    "response = deployed_policy.raw_predict(\n",
    "    body = ENCODED_TEST_INSTANCE,\n",
    "    headers = {'Content-Type':'application/json'}\n",
    ").json()\n",
    "\n",
    "# print(response['chosen_arm_features'])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f58e24-9528-4774-9694-f473cad00cfa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6442ef8e-80b8-4dda-806e-2c5928afe877",
   "metadata": {},
   "source": [
    "**in terminal shell, run:**\n",
    "\n",
    "* `docker image ls`\n",
    "* `docker system df`\n",
    "* `docker system prune`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2edc6f-bfb1-479f-8162-b8e552a5331e",
   "metadata": {},
   "source": [
    "If you use the `-f` flag and specify the image's short or long ID, then this command untags and removes all images that match the specified ID.\n",
    "\n",
    "These aliases are equivalent:\n",
    "* `docker image rm`\n",
    "* `docker image remove`\n",
    "* `docker rmi`\n",
    "\n",
    "> `docker rmi gcr.io/hybrid-vertex/pred-perarm-feats-02e:latest`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7621cce-2927-4d84-881d-d8875cdf4286",
   "metadata": {},
   "source": [
    "Undeploy model and delete endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b0d1fe98-6588-4e6c-9bc6-fa300ea51b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint.delete(force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f033038-ae3e-45b2-82b0-597151efdec2",
   "metadata": {},
   "source": [
    "Delete policy uploaded to Vertex AI Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3a4b9e4c-d93a-46ef-9a9e-c12344555b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uploaded_policy.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e098affd-3723-438e-a44d-cf2f4c8f8fcf",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
