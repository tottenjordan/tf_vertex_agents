{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385307d6-2058-47ec-8da0-57f7ef5c43d6",
   "metadata": {},
   "source": [
    "# Train Bandits with per-arm features\n",
    "\n",
    "**Exploring linear and nonlinear** (e.g., those with neural network-based value functions) bandit methods for recommendations using TF-Agents\n",
    "\n",
    "> Neural linear bandits provide a nice way to leverage the representation power of deep learning and the bandit approach for uncertainty measure and efficient exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1e9956-66cd-4bf4-9b4d-8c2c646f0313",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "\n",
    "In this notebook, we explore the following topics for training contextual bandits with per-arm features:\n",
    "\n",
    "1. Data preperation\n",
    "2. Sampling functions\n",
    "3. TensorSpecs\n",
    "4. Agent, Network, training policy\n",
    "5. Reward function\n",
    "6. Trajectory function\n",
    "7. Train & Eval loops\n",
    "8. Getting predictions -\n",
    "9. Preparing the training application - abstracting all steps above to be used in subsequent notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fd257-b98b-426a-a2cd-024429b014f1",
   "metadata": {},
   "source": [
    "## Load notebook config\n",
    "\n",
    "* use the prefix defined in `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd4881e2-b395-4a5b-be7d-e4e6b39a433e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install tensorflow-probability==0.23.0 --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f39c9d08-d118-4013-a47f-88450f49f19e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "VERSION        = \"v2\"                       # TODO\n",
    "PREFIX         = f'rec-bandits-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "908f6b95-b539-4a9f-a836-840d26ea3b09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"rec-bandits-v2\"\n",
      "VERSION                  = \"v2\"\n",
      "\n",
      "BUCKET_NAME              = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_NAME    = \"mvlens_rec_bandits_v2\"\n",
      "BIGQUERY_TABLE_NAME      = \"training_dataset\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-rec-bandits-v2\"\n",
      "\n",
      "DOCKERNAME_01            = \"Dockerfile_train_my_perarm_env\"\n",
      "IMAGE_NAME_01            = \"train-my-perarm-env-v2\"\n",
      "IMAGE_URI_01             = \"gcr.io/hybrid-vertex/train-my-perarm-env-v2\"\n",
      "\n",
      "DOCKERNAME_02            = \"Dockerfile_perarm_feats\"\n",
      "IMAGE_NAME_02            = \"train-perarm-feats-v2\"\n",
      "IMAGE_URI_02             = \"gcr.io/hybrid-vertex/train-perarm-feats-v2\"\n",
      "\n",
      "DOCKERNAME_03            = \"Dockerfile_ranking_bandit\"\n",
      "IMAGE_NAME_03            = \"train-rank-bandit-v2\"\n",
      "IMAGE_URI_03             = \"gcr.io/hybrid-vertex/train-rank-bandit-v2\"\n",
      "\n",
      "DOCKERNAME_04            = \"Dockerfile_train_bandit_e2e\"\n",
      "IMAGE_NAME_04            = \"train-mab-e2e-v2\"\n",
      "IMAGE_URI_04             = \"gcr.io/hybrid-vertex/train-mab-e2e-v2\"\n",
      "\n",
      "DOCKERNAME_04_pred       = \"Dockerfile_pred_bandit_e2e\"\n",
      "IMAGE_NAME_04_pred       = \"pred-mab-e2e-v2\"\n",
      "IMAGE_URI_04_pred        = \"gcr.io/hybrid-vertex/pred-mab-e2e-v2\"\n",
      "\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/local_docker_tfa\"\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c690a9-e2bd-4759-ba41-4e2469098aee",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4d0dfe4-695c-4dd4-9f24-67f7488ce1a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c669f1a1-1af7-4efb-ab2d-6bf3b3847991",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import functools\n",
    "import collections\n",
    "import pickle as pkl\n",
    "from pprint import pprint\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# tf-agents\n",
    "from tf_agents.utils import common\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.metrics import export_utils\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.bandits.policies import policy_utilities\n",
    "from tf_agents.bandits.agents import neural_linucb_agent\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# this repo\n",
    "from src.utils import train_utils, reward_factory\n",
    "from src.data import data_utils, data_config\n",
    "from src.trainer import eval_perarm as eval_perarm, train_perarm\n",
    "from src.agents import agent_factory as agent_factory\n",
    "from src.networks import encoding_network as emb_features\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29e58dd7-ab2b-419f-9771-bf1e98db758b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4969d3e-1fc0-45db-8a69-aa6b342019de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "121b9260-cc9f-4abc-8285-365d22b38cf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "print(f\"device: {device.name.decode()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "274e7f4a-1802-4946-888e-876638f5c677",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a866b1-85b9-43e6-9546-edfbbf886bce",
   "metadata": {},
   "source": [
    "# [1] Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d4ed28-23d7-4785-b327-e5b543b0edb9",
   "metadata": {},
   "source": [
    "**Overview**\n",
    "* Load train and eval datasets from TFRecords created in the `01-movielens-data-prep.ipynb` notebook\n",
    "* training examples represent historical (previously collected) interaction data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc3fcebe-818b-4767-afdc-cfb65b3b953d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCS_DATA_PATH: gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/action-embeddings/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/mv_b128_g12_a16/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/mv_b128_g12_a16_v4/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/mv_b128_g12_a16_v5/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/mv_b128_g12_a16_v6/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/mv_b128_g12_a16_v7/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/train/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/val/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/vocabs/\n"
     ]
    }
   ],
   "source": [
    "EXAMPLE_GEN_GCS_PATH = data_config.EXAMPLE_GEN_GCS_PATH\n",
    "GCS_DATA_PATH = f\"{BUCKET_URI}/{EXAMPLE_GEN_GCS_PATH}\"\n",
    "\n",
    "print(f\"GCS_DATA_PATH: {GCS_DATA_PATH}\")\n",
    "\n",
    "!gsutil ls $GCS_DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd5b953-14c0-42ed-a511-77147a1bc0ac",
   "metadata": {},
   "source": [
    "### Read TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d0157c8-a04c-4dbd-b6d9-a1ede97687a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da0cdac-76af-4608-b70e-be7dbe0584b5",
   "metadata": {},
   "source": [
    "**Train data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c934c06-bf08-4c7f-b0cc-0de04ef3515c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/train/ml-1m-gen-001-of-008.tfrecord',\n",
       " 'gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/train/ml-1m-gen-002-of-008.tfrecord',\n",
       " 'gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/train/ml-1m-gen-003-of-008.tfrecord']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPLIT = \"train\" # \"train\" | \"val\"\n",
    "\n",
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{EXAMPLE_GEN_GCS_PATH}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "train_files = train_files[:3]\n",
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7511e4d-bf81-4800-bde7-8b16dec9aeb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target_movie_genres': <tf.Tensor: shape=(1, 10), dtype=string, numpy=\n",
      "array([[b'Drama', b'UNK', b'UNK', b'UNK', b'UNK', b'UNK', b'UNK', b'UNK',\n",
      "        b'UNK', b'UNK']], dtype=object)>,\n",
      " 'target_movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'1775'], dtype=object)>,\n",
      " 'target_movie_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>,\n",
      " 'target_movie_title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Live Flesh (1997)'], dtype=object)>,\n",
      " 'target_movie_year': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1997])>,\n",
      " 'target_rating_timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([974612615])>,\n",
      " 'user_age': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([50])>,\n",
      " 'user_gender': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'M'], dtype=object)>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'2173'], dtype=object)>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'programmer'], dtype=object)>,\n",
      " 'user_zip_code': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'87505'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "train_dataset = train_dataset.map(data_utils._parse_function)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452750c1-46a0-4ee1-84d4-0c3b227de38f",
   "metadata": {},
   "source": [
    "**Val data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7b5376f-9438-4304-84aa-de09c30f5e0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SPLIT = \"val\"\n",
    "\n",
    "val_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{EXAMPLE_GEN_GCS_PATH}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        val_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "val_dataset = tf.data.TFRecordDataset(val_files)\n",
    "val_dataset = val_dataset.map(data_utils._parse_function, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8959967-522e-41c8-9a1b-050ca8bc191f",
   "metadata": {},
   "source": [
    "### get vocab\n",
    "\n",
    "**TODO:** \n",
    "* streamline vocab calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3ccf137-7a72-42e7-aa89-3c81a99cf40a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab...\n",
      "Downloaded vocab from: gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/vocabs/vocab_dict.pkl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{EXAMPLE_GEN_GCS_PATH}/vocabs/{VOCAB_FILENAME}'\n",
    "print(f\"Downloading vocab...\")\n",
    "\n",
    "os.system(f'gsutil -q cp {EXISTING_VOCAB_FILE} .')\n",
    "print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "vocab_dict = pkl.load(filehandler)\n",
    "filehandler.close()\n",
    "\n",
    "# for key in vocab_dict.keys():\n",
    "#     pprint(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfda012c-a2c3-4384-a5a4-54f5c6649006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vocab_dict['user_occupation_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138a295-2b0d-4359-8496-af8552ec8cff",
   "metadata": {},
   "source": [
    "# [2] Preprocessing layers for global and arm features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e28c002-8d3a-4cf4-b69b-de56a6abab90",
   "metadata": {},
   "source": [
    "The preproccesing layers will ultimately feed the two sampling functions described below. These sampling functions will be used to create [trajectories](https://github.com/tensorflow/agents/blob/master/tf_agents/trajectories/trajectory.py#L36) (i.e., the training examples for our model)\n",
    "\n",
    "`global_context_sampling_fn`: \n",
    "* A function that outputs a random 1d array or list of ints or floats\n",
    "* This output is the global context. Its shape and type must be consistent across calls.\n",
    "\n",
    "`arm_context_sampling_fn`: \n",
    "* A function that outputs a random 1 array or list of ints or floats (same type as the output of `global_context_sampling_fn`). * This output is the per-arm context. Its shape must be consistent across calls.\n",
    "\n",
    "See `debug-and-learn-emb-models.ipynb` for more details and debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ea1f7-0621-44b8-b062-1f59b0964d72",
   "metadata": {},
   "source": [
    "## Global & Per-Arm feature embedding models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550a1063-15d4-472e-b5a7-d92dcdea3c0f",
   "metadata": {},
   "source": [
    "**get expected dimensions**\n",
    "\n",
    "**common layers**\n",
    "* layer sizes for the final tower\n",
    "* The network that takes as input the concatenation of \n",
    "  the outputs of the global and the arm networks\n",
    "*  hidden layers ideally divisible by 8, e.g., [16, 32, 64, 128, 256, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8d77956-635c-438a-916a-185eec52f9c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPECTED_GLOBAL_DIM: 72\n",
      "EXPECTED_PER_ARM_DIM: 64\n",
      "EXPECTED_GLOBAL_LAYERS      : [72, 36, 18]\n",
      "EXPECTED_ARM_LAYERS         : [64, 32, 16]\n",
      "EXPECTED_COMMON_LAYERS      : [34, 17, 8]\n"
     ]
    }
   ],
   "source": [
    "NUM_OOV_BUCKETS        = 1\n",
    "GLOBAL_EMBEDDING_SIZE  = 12\n",
    "MV_EMBEDDING_SIZE      = 16\n",
    "\n",
    "NUM_GLOBAL_FEATURES = len(data_utils.USER_FEATURE_NAMES)     # 6\n",
    "NUM_ARM_FEATURES    = len(data_utils.MOVIE_FEATURE_NAMES)    # 5\n",
    "EXPECTED_GLOBAL_DIM  = GLOBAL_EMBEDDING_SIZE * NUM_GLOBAL_FEATURES\n",
    "EXPECTED_PER_ARM_DIM = MV_EMBEDDING_SIZE * NUM_ARM_FEATURES\n",
    "print(f\"EXPECTED_GLOBAL_DIM: {EXPECTED_GLOBAL_DIM}\")\n",
    "print(f\"EXPECTED_PER_ARM_DIM: {EXPECTED_PER_ARM_DIM}\")\n",
    "\n",
    "EXPECTED_GLOBAL_LAYERS   = [\n",
    "    EXPECTED_GLOBAL_DIM, \n",
    "    int(EXPECTED_GLOBAL_DIM/2), \n",
    "    int(EXPECTED_GLOBAL_DIM/4)\n",
    "]\n",
    "EXPECTED_ARM_LAYERS      = [\n",
    "    EXPECTED_PER_ARM_DIM, \n",
    "    int(EXPECTED_PER_ARM_DIM/2), \n",
    "    int(EXPECTED_PER_ARM_DIM/4)\n",
    "]\n",
    "EXPECTED_FIRST_COMMON_LAYER = EXPECTED_GLOBAL_LAYERS[-1] + EXPECTED_ARM_LAYERS[-1]\n",
    "EXPECTED_COMMON_LAYERS = [\n",
    "    int(EXPECTED_FIRST_COMMON_LAYER), \n",
    "    int(EXPECTED_FIRST_COMMON_LAYER/2), \n",
    "    int(EXPECTED_FIRST_COMMON_LAYER/4)\n",
    "]\n",
    "print(f\"EXPECTED_GLOBAL_LAYERS      : {EXPECTED_GLOBAL_LAYERS}\")\n",
    "print(f\"EXPECTED_ARM_LAYERS         : {EXPECTED_ARM_LAYERS}\")\n",
    "print(f\"EXPECTED_COMMON_LAYERS      : {EXPECTED_COMMON_LAYERS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea335991-dcec-40b3-ba0d-a0fdfb9c2ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test emb models\n",
    "for i in range(1):\n",
    "    \n",
    "    iterator = iter(train_dataset.batch(1))\n",
    "    data = next(iterator)\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48178fff-491f-4f03-b156-7765d1fa9707",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.networks.encoding_network.EmbeddingModel at 0x7f9b195b7640>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs = emb_features.EmbeddingModel(\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    "    max_genre_length = data_config.MAX_GENRE_LENGTH\n",
    ")\n",
    "\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "903c63c5-2468-4443-bcb8-5ff6d69810dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL_DIM: 72\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 72), dtype=float32, numpy=\n",
       "array([[ 0.0178544 , -0.04419141,  0.02163377, -0.00887176, -0.03954706,\n",
       "         0.03609543,  0.02029798, -0.01625859,  0.00386403,  0.0054809 ,\n",
       "        -0.04379515,  0.02219352, -0.04257007, -0.02383138,  0.00264021,\n",
       "        -0.03605119,  0.04029793,  0.04355988, -0.03599702,  0.01188514,\n",
       "        -0.04961718, -0.00096133,  0.03160795,  0.03040297,  0.03739203,\n",
       "         0.02217231,  0.03605786,  0.0174781 ,  0.01698938,  0.0216865 ,\n",
       "         0.02281306,  0.02627483, -0.01341261,  0.02398754,  0.04585947,\n",
       "         0.03653132,  0.0284594 , -0.00695268, -0.03307855,  0.04234859,\n",
       "        -0.02164789,  0.04894276, -0.04441763, -0.00425138,  0.0421542 ,\n",
       "         0.034336  , -0.01787672,  0.01420433,  0.04353007, -0.03925301,\n",
       "         0.03886368, -0.02812861, -0.03355094, -0.00078724, -0.01509041,\n",
       "         0.04979872,  0.02596125,  0.0046113 , -0.03379095,  0.03238029,\n",
       "         0.00034983, -0.01073961,  0.00483686,  0.01486007, -0.01945845,\n",
       "        -0.01512548,  0.00573098, -0.0257884 ,  0.025655  ,  0.00408605,\n",
       "        -0.00112281,  0.02410544]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_globals = embs._get_global_context_features(data)\n",
    "\n",
    "GLOBAL_DIM = test_globals.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"GLOBAL_DIM: {GLOBAL_DIM}\")\n",
    "\n",
    "test_globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebec4863-c614-4248-b680-8e29ec5b730d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER_ARM_DIM: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 64), dtype=float32, numpy=\n",
       "array([[ 0.04590951, -0.02604198, -0.04487407, -0.01363887,  0.01023418,\n",
       "        -0.04678574,  0.01822323,  0.02710411,  0.01241046,  0.04016737,\n",
       "         0.0148306 ,  0.02363174, -0.00109003,  0.01622068, -0.01870066,\n",
       "         0.03941271,  0.00287239, -0.00324784, -0.01248026, -0.04444889,\n",
       "         0.02234783, -0.03040076, -0.01996803,  0.03677713, -0.01691733,\n",
       "         0.04072145,  0.00237372, -0.00411195,  0.03068035, -0.03112201,\n",
       "         0.0234942 , -0.02073882, -0.0005726 , -0.04336821,  0.04020414,\n",
       "        -0.03919156,  0.02583276,  0.04420779,  0.03216577, -0.04103842,\n",
       "        -0.00069793, -0.03388319,  0.04793603,  0.02580443,  0.04223592,\n",
       "        -0.0084434 ,  0.04141908,  0.03130119,  0.23685998,  0.12202843,\n",
       "        -0.00134032,  0.20490767,  0.03176546, -0.12185246, -0.04843527,\n",
       "         0.16393812, -0.13167489, -0.07810008,  0.06425792,  0.14722323,\n",
       "        -0.04930984, -0.16240579, -0.16146965, -0.00471205]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arms = embs._get_per_arm_features(data)\n",
    "\n",
    "PER_ARM_DIM = test_arms.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"PER_ARM_DIM: {PER_ARM_DIM}\")\n",
    "\n",
    "test_arms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeb4902-5bb9-4587-8d29-c01d78b006be",
   "metadata": {},
   "source": [
    "# [3] TensorSpecs\n",
    "\n",
    "* say you have a global observation spec of `[17]`. And you have two batch dimensions `[4, 5]`. Then your observation has to have the shape `[4, 5, 17]`\n",
    "* and then if you have arm_obs_spec with shape `[9, 13]`, then the arm obs shape has to be exactly `[4, 5, 9, 13]`\n",
    "* and this has to be true for every single tensor in your tensor nest\n",
    "* the first 2 dims are the outer dims that are the same for all tensors, the rest of the dimensions have to follow the spec for each tensor\n",
    "\n",
    "**TODO:**\n",
    "* explain relationship between Tensor Specs and their Tensor counterparts\n",
    "* highlight the errors, lessons learned, and utility functions to address these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ff9baaf-987d-448d-a981-742a79b581e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE      : 128\n",
      "EVAL_BATCH_SIZE : 1\n",
      "NUM_ACTIONS     : 2\n",
      "GLOBAL_DIM      : 72\n",
      "PER_ARM_DIM     : 64\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE      = 128\n",
    "EVAL_BATCH_SIZE = 1\n",
    "\n",
    "NUM_ACTIONS     = 2 #this is kinda deceptive - \n",
    "#our approach is to learn by \"flashing\" one movie rating at a time per user context. \n",
    "#The n_actions = show/don't show the movie with one degree of freedom (n-1)\n",
    "\n",
    "\n",
    "print(f\"BATCH_SIZE      : {BATCH_SIZE}\")\n",
    "print(f\"EVAL_BATCH_SIZE : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"NUM_ACTIONS     : {NUM_ACTIONS}\")\n",
    "print(f\"GLOBAL_DIM      : {GLOBAL_DIM}\")\n",
    "print(f\"PER_ARM_DIM     : {PER_ARM_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20eca8d-8c73-4ec8-9d0f-f2b428055ac2",
   "metadata": {},
   "source": [
    "## Implementing MAB with TF-Agents\n",
    "\n",
    "In TF-Agents, the *per-arm features* implementation differs from the *global-only* feature examples in the following aspects:\n",
    "* Reward is modeled not per-arm, but globally.\n",
    "* The arms are permutation invariant: it doesn’t matter which arm is arm 1 or arm 2, only their features.\n",
    "* One can have a different number of arms to choose from in every step (note that unspecified/dynamically changing number of arms will have a problem with XLA compatibility).\n",
    "\n",
    "When implementing per-arm features in TF-Bandits, the following details have to be discussed:\n",
    "* Observation spec and observations,\n",
    "* Action spec and actions,\n",
    "* Implementation of specific policies and agents.\n",
    "\n",
    "\n",
    "**TODO:**\n",
    "* outline the components and highlight their interactions, dependencies on eachother, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f68ebe8-116d-43b3-a6e1-4f5a5c7f4741",
   "metadata": {},
   "source": [
    "### Observation spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9c4746-d01b-4ca4-aa53-ab68da54d37a",
   "metadata": {},
   "source": [
    "**This observation spec allows the user to have a global observation of fixed dimension**, and an unspecified number of *per-arm* features (also of fixed dimension)\n",
    "* The actions output by the policy are still integers as usual, and they indicate which row of the arm-features it has chosen \n",
    "* The action spec must be a single integer value without boundaries:\n",
    "\n",
    "```python\n",
    "global_spec = tensor_spec.TensorSpec([GLOBAL_DIM], tf.float32)\n",
    "per_arm_spec = tensor_spec.TensorSpec([None, PER_ARM_DIM], tf.float32)\n",
    "observation_spec = {'global': global_spec, 'per_arm': per_arm_spec}\n",
    "\n",
    "action_spec = tensor_spec.TensorSpec((), tf.int32)\n",
    "```\n",
    "> Here the only difference compared to the action spec with global features only is that the tensor spec is not bounded, as we don’t know how many arms there will be at any time step\n",
    "\n",
    "**XLA compatibility:**\n",
    "* Since dynamic tensor shapes are not compatible with XLA, the number of arm features (and consequently, number of arms for a step) cannot be dynamic. \n",
    "* One workaround is to fix the maximum number of arms for a problem, then pad the arm features in steps with fewer arms, and use action masking to indicate how many arms are actually active.\n",
    "\n",
    "```python\n",
    "per_arm_spec = tensor_spec.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32)\n",
    "\n",
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=(), dtype=tf.int32, minimum = 0, maximum = NUM_ACTIONS - 1\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36bd3b33-635a-4274-8b9e-7172696ebb2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(72,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_spec = {\n",
    "    'global': tf.TensorSpec([GLOBAL_DIM], tf.float32),\n",
    "    'per_arm': tf.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32) #excluding action dim here\n",
    "}\n",
    "observation_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a2da92-7db2-4f42-94a7-b7bad1c8fc42",
   "metadata": {},
   "source": [
    "### Action spec\n",
    "\n",
    "> The time_step_spec and action_spec are specifications for the input time step and the output action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5af42c7-18d7-480f-a7f3-d7da3f4840eb",
   "metadata": {},
   "source": [
    "```python\n",
    "    if (\n",
    "        not tensor_spec.is_bounded(action_spec)\n",
    "        or not tensor_spec.is_discrete(action_spec)\n",
    "        or action_spec.shape.rank > 1\n",
    "        or action_spec.shape.num_elements() != 1\n",
    "    ):\n",
    "      raise NotImplementedError(\n",
    "          'action_spec must be a BoundedTensorSpec of type int32 and shape (). '\n",
    "          'Found {}.'.format(action_spec)\n",
    "      )\n",
    "```\n",
    "\n",
    "* [src](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_base_policy.py#L97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "549a123c-349a-4103-b39a-4502f47d1e85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=[], \n",
    "    dtype=tf.int32,\n",
    "    minimum=tf.constant(0),            \n",
    "    maximum=NUM_ACTIONS-1, # n degrees of freedom and will dictate the expected mean reward spec shape\n",
    "    name=\"action_spec\"\n",
    ")\n",
    "\n",
    "action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36ee2635-d4e3-4468-886c-ae9c62e3c80d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_num_actions: 2\n",
      "predicted_rewards_mean: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n"
     ]
    }
   ],
   "source": [
    "expected_num_actions = action_spec.maximum - action_spec.minimum + 1\n",
    "print(f\"expected_num_actions: {expected_num_actions}\")\n",
    "\n",
    "predicted_rewards_mean = tensor_spec.TensorSpec([expected_num_actions])\n",
    "print(f\"predicted_rewards_mean: {predicted_rewards_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a51efce-9f1b-42d1-bec4-7b788e3fd7e0",
   "metadata": {},
   "source": [
    "### TimeStep spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95f05860-0fbf-4a5a-8273-9c81761e0ea5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'global': TensorSpec(shape=(72,), dtype=tf.float32, name=None),\n",
       "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec = ts.time_step_spec(\n",
    "    observation_spec = observation_spec, \n",
    "    # reward_spec = _reward_spec\n",
    ")\n",
    "time_step_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773b129a-6d19-4b3d-a2e7-e27070f57ac0",
   "metadata": {},
   "source": [
    "### Reward Spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b48e89aa-e010-4bd9-a7e0-ad62dd4c5949",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reward': TensorSpec(shape=(128,), dtype=tf.float32, name='reward')}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.specs import array_spec\n",
    "\n",
    "reward_spec = {\n",
    "    \"reward\": array_spec.ArraySpec(shape=[BATCH_SIZE], dtype=np.float32, name=\"reward\")\n",
    "}\n",
    "\n",
    "reward_tensor_spec = train_utils.from_spec(reward_spec)\n",
    "reward_tensor_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9181303-6565-45f5-a293-08d50420a805",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Inspect chosen arm features spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6b526a5-997c-4621-b21c-82c6ca1d6a70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(72,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90d3e03e-619e-4fa4-b817-f02b4cefd6b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(64,), dtype=tf.float32, name=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_arm_features_info = (\n",
    "  policy_utilities.create_chosen_arm_features_info_spec(\n",
    "      time_step_spec.observation,\n",
    "  )\n",
    ")\n",
    "chosen_arm_features_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc427092-beb7-4baf-a2e9-b8d10629182c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandit_policy_type = (\n",
    "    policy_utilities.BanditPolicyType.GREEDY\n",
    ")\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a4a2a33-c7d4-4d81-8082-80dfc3596741",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandit_policy_type = (\n",
    "    policy_utilities.create_bandit_policy_type_tensor_spec(shape=[1])\n",
    ")\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e7ac02b-18bd-4519-92fe-5541b1a8ddc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_spec = policy_utilities.PerArmPolicyInfo(\n",
    "  predicted_rewards_mean=predicted_rewards_mean,\n",
    "  bandit_policy_type=bandit_policy_type,\n",
    "  chosen_arm_features=chosen_arm_features_info,\n",
    ")\n",
    "info_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9c197-ae9b-461d-8956-f078b929ac12",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [4] The Agent\n",
    "\n",
    "**Note** that contextual bandits form a special case of RL, where the actions taken by the agent do not alter the state of the environment \n",
    "\n",
    "> “Contextual” refers to the fact that the agent chooses among a set of actions while having knowledge of the context (environment observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81d6e84-688e-48c5-aea1-77df031348c9",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Agent & Network defined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aadb01-eb5c-4870-ae14-9e66624ba594",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Agent types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d075e8a6-11a9-4346-8725-3653fba4bac4",
   "metadata": {},
   "source": [
    "> `AGENT_TYPE = ['LinUCB', 'LinTS', 'epsGreedy', 'NeuralLinUCB']`\n",
    "\n",
    "1. **LinearUCBAgent**: (`LinUCB`) - An agent implementing the Linear UCB bandit algorithm ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/lin_ucb_agent/LinearUCBAgent))\n",
    "\n",
    "2. **LinearThompsonSamplingAgent**: (`LinTS`) - Implements the Linear Thompson Sampling Agent from the [paper](https://arxiv.org/abs/1209.3352): *Thompson Sampling for Contextual Bandits with Linear Payoffs* ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/linear_thompson_sampling_agent/LinearThompsonSamplingAgent))\n",
    "\n",
    "3. **NeuralEpsilonGreedyAgent**: (`epsGreedy`) - A neural network based epsilon greedy agent ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_epsilon_greedy_agent/NeuralEpsilonGreedyAgent))\n",
    "\n",
    "4. **NeuralLinUCBAgent**: (`NeuralLinUCB`) - An agent implementing the LinUCB algorithm on top of a neural network ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_linucb_agent/NeuralLinUCBAgent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b8e88e-c8ea-4193-a911-0d974ef3b1a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Network types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f547087d-5fad-4521-a584-cb46ce52897d",
   "metadata": {},
   "source": [
    "Which network architecture to use for the `epsGreedy` or `NeuralLinUCB` agents\n",
    "\n",
    "```\n",
    "NETWORK_TYPE = ['commontower', 'dotproduct']\n",
    "```\n",
    "\n",
    "**GlobalAndArmCommonTowerNetwork:** (`commontower`)\n",
    "* This network takes the output of the global and per-arm networks, and leads them through a common network, that in turn outputs reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "> * `COMMON_LAYERS` - Iterable of ints. Specifies the layers of the common tower\n",
    "* The network produced by this function can be used either in `GreedyRewardPredictionPolicy`, or `NeuralLinUCBPolicy`\n",
    "> * In the former case, the network must have `output_dim=1`, it is going to be an instance of `QNetwork`, and used in the policy as a reward prediction network\n",
    "> * In the latter case, the network will be an encoding network with its output consumed by a reward layer or a `LinUCB` method. The specified `output_dim` will be the encoding dimension\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmCommonTowerNetwork)\n",
    "\n",
    "**GlobalAndArmDotProductNetwork:** (`dotproduct`)\n",
    "* This network calculates the **dot product** of the output of the global and per-arm networks and returns them as reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmDotProductNetwork)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3dc270-deb5-4e96-8276-74759a06c318",
   "metadata": {},
   "source": [
    "### Agent config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bbe29263-453d-405e-ac50-fee7f379f335",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\n",
      "\n",
      "time_step_spec:  TimeStep(\n",
      "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'observation': {'global': TensorSpec(shape=(72,), dtype=tf.float32, name=None),\n",
      "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n",
      "\n",
      "action_spec:  BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))\n",
      "\n",
      "observation_spec:  {'global': TensorSpec(shape=(72,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\")\n",
    "print(\"\\ntime_step_spec: \", time_step_spec)\n",
    "print(\"\\naction_spec: \", action_spec)\n",
    "print(\"\\nobservation_spec: \", observation_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d817bf2-1fa6-4bae-af90-745fad996b96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'common_layers': [34, 8],\n",
      " 'encoding_dim': 1,\n",
      " 'epsilon': 0.01,\n",
      " 'eval_batch_size': 1,\n",
      " 'global_layers': [72, 36, 18],\n",
      " 'learning_rate': 0.05,\n",
      " 'model_type': 'epsGreedy',\n",
      " 'network_type': 'commontower',\n",
      " 'num_actions': 2,\n",
      " 'per_arm_layers': [64, 32, 16]}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Agents\n",
    "# ================================\n",
    "AGENT_TYPE      = 'epsGreedy' # 'LinUCB' | 'LinTS |, 'epsGreedy' | 'NeuralLinUCB'\n",
    "\n",
    "# Parameters for linear agents (LinUCB and LinTS).\n",
    "AGENT_ALPHA     = 0.1\n",
    "\n",
    "# Parameters for neural agents (NeuralEpsGreedy and NerualLinUCB).\n",
    "EPSILON         = 0.01\n",
    "LR              = 0.05\n",
    "\n",
    "# Parameters for NeuralLinUCB\n",
    "ENCODING_DIM    = 1\n",
    "EPS_PHASE_STEPS = 1000\n",
    "\n",
    "# ================================\n",
    "# Agent's Preprocess Network\n",
    "# ================================\n",
    " # beginning should be of size: GLOBAL_DIM\n",
    "GLOBAL_LAYERS   = [GLOBAL_DIM, int(GLOBAL_DIM/2), int(GLOBAL_DIM/4)]\n",
    "\n",
    "# beginning should be of size: PER_ARM_DIM\n",
    "ARM_LAYERS      = [PER_ARM_DIM, int(PER_ARM_DIM/2), int(PER_ARM_DIM/4)]\n",
    "\n",
    "# ================================\n",
    "# common layers\n",
    "# ================================\n",
    "\"\"\"\n",
    "> layer sizes for the final tower\n",
    "> The network that takes as input the concatenation of \n",
    "  the outputs of the global and the arm networks\n",
    "> hidden layers ideally divisible by 8, e.g., [16, 32, 64, 128, 256, 512]\n",
    "\"\"\"\n",
    "FIRST_COMMON_LAYER = GLOBAL_LAYERS[-1] + ARM_LAYERS[-1] # min(GLOBAL_LAYERS[-1], ARM_LAYERS[-1])\n",
    "\n",
    "COMMON_LAYERS = [\n",
    "    int(FIRST_COMMON_LAYER),\n",
    "    # int(FIRST_COMMON_LAYER/2),\n",
    "    int(FIRST_COMMON_LAYER/4)\n",
    "]\n",
    "\n",
    "NETWORK_TYPE    = \"commontower\" # 'commontower' | 'dotproduct'\n",
    "\n",
    "if AGENT_TYPE == 'NeuralLinUCB':\n",
    "    NETWORK_TYPE = 'commontower'\n",
    "    ENCODING_DIM = COMMON_LAYERS[-1]\n",
    "    \n",
    "if NETWORK_TYPE == 'dotproduct':\n",
    "    assert GLOBAL_LAYERS[0] == ARM_LAYERS[0]\n",
    "\n",
    "\n",
    "HPARAMS = {  # TODO - streamline and consolidate\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"eval_batch_size\" : EVAL_BATCH_SIZE,\n",
    "    \"num_actions\": NUM_ACTIONS,\n",
    "    \"model_type\": AGENT_TYPE,\n",
    "    \"network_type\": NETWORK_TYPE,\n",
    "    \"global_layers\": GLOBAL_LAYERS,\n",
    "    \"per_arm_layers\": ARM_LAYERS,\n",
    "    \"common_layers\": COMMON_LAYERS,\n",
    "    \"learning_rate\": LR,\n",
    "    \"epsilon\": EPSILON,\n",
    "    \"encoding_dim\": ENCODING_DIM\n",
    "}\n",
    "pprint(HPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2bf060bb-9880-40b4-8583-dd7a3f915bc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent: NeuralEpsGreedyAgent\n",
      "Network: commontower\n"
     ]
    }
   ],
   "source": [
    "# from src.perarm_features import agent_factory as agent_factory\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "    agent_type = AGENT_TYPE,\n",
    "    network_type = NETWORK_TYPE,\n",
    "    time_step_spec = time_step_spec,\n",
    "    action_spec = action_spec,\n",
    "    observation_spec=observation_spec,\n",
    "    global_layers = GLOBAL_LAYERS,\n",
    "    arm_layers = ARM_LAYERS,\n",
    "    common_layers = COMMON_LAYERS,\n",
    "    agent_alpha = AGENT_ALPHA,\n",
    "    learning_rate = LR,\n",
    "    epsilon = EPSILON,\n",
    "    train_step_counter = global_step,\n",
    "    output_dim = ENCODING_DIM,\n",
    "    eps_phase_steps = EPS_PHASE_STEPS,\n",
    "    summarize_grads_and_vars = True,\n",
    "    debug_summaries = True\n",
    ")\n",
    "      \n",
    "agent.initialize()\n",
    "print(f'agent: {agent.name}')\n",
    "\n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {NETWORK_TYPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d77d1-a0b3-4898-adf0-0b32bfaf5bd7",
   "metadata": {},
   "source": [
    "#### Inspect the specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78ca56e7-a386-4bf4-8c2b-3d1665521f53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41483f5a-bda6-48a4-9e1c-88d8b4afeea9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(72,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.time_step_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f205716-f265-4ca8-81a7-4799de8f60a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(Trajectory(\n",
       "{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32)),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(72,), dtype=tf.float32, name=None)}),\n",
       " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None)),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.training_data_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d404dae-3cc3-4f81-962b-4641455ca4f2",
   "metadata": {},
   "source": [
    "# [5] Reward function\n",
    "\n",
    "> see `reward_factory.py`\n",
    "\n",
    "* Since we are training a policy with previously collected interaction data, we model the reward function from actual rewards\n",
    "* We will simply pass the `user_rating` (values 0-5) as rewards to the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df9aecd6-d20a-48a7-9ead-4da3bbcfdae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _get_rewards(element):\n",
    "    \"\"\"Calculates reward for the actions.\"\"\"\n",
    "\n",
    "    def _calc_reward(x):\n",
    "        \"\"\"\n",
    "        Calculates reward for a single action.\n",
    "        \"\"\"\n",
    "        r0 = lambda: tf.constant(0.0)\n",
    "        r1 = lambda: tf.constant(1.0)\n",
    "        r2 = lambda: tf.constant(2.0)\n",
    "        r3 = lambda: tf.constant(3.0)\n",
    "        r4 = lambda: tf.constant(4.0)\n",
    "        r5 = lambda: tf.constant(5.0)\n",
    "        \n",
    "        c1 = tf.equal(x, 1.0)\n",
    "        c2 = tf.equal(x, 2.0)\n",
    "        c3 = tf.equal(x, 3.0)\n",
    "        c4 = tf.equal(x, 4.0)\n",
    "        c5 = tf.equal(x, 5.0)\n",
    "        return tf.case(\n",
    "            [(c1, r1), (c2, r2), (c3, r3),(c4, r4),(c5, r5)], \n",
    "            default=r0, exclusive=True\n",
    "        )\n",
    "\n",
    "    return tf.map_fn(\n",
    "        fn=_calc_reward, \n",
    "        # elems=element['user_rating'],\n",
    "        elems=element[data_utils.TARGET_FEATURE_NAME],\n",
    "        dtype=tf.float32\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac59703a-9a00-4eba-a3b7-45b21b738dd4",
   "metadata": {},
   "source": [
    "# [6] Trajectory function\n",
    "\n",
    "> This function will convert training samples from the TF Records to `trajectories` which the Agent interprets as training records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f3605d9f-d239-4871-9a61-6e9b21f9c2a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _trajectory_fn(element): # hparams\n",
    "    \n",
    "    \"\"\"Converts a dataset element into a trajectory.\"\"\"\n",
    "    global_features = embs._get_global_context_features(element)\n",
    "    arm_features = embs._get_per_arm_features(element)\n",
    "\n",
    "    # Adds a time dimension.\n",
    "    arm_features = train_utils._add_outer_dimension(arm_features)\n",
    "\n",
    "    # obs spec\n",
    "    observation = {\n",
    "        bandit_spec_utils.GLOBAL_FEATURE_KEY:\n",
    "            train_utils._add_outer_dimension(global_features),\n",
    "    }\n",
    "\n",
    "    reward = train_utils._add_outer_dimension(_get_rewards(element))\n",
    "\n",
    "    # To emit the predicted rewards in policy_info, we need to create dummy\n",
    "    # rewards to match the definition in TensorSpec for the ones specified in\n",
    "    # emit_policy_info set.\n",
    "    dummy_rewards = tf.zeros([HPARAMS['batch_size'], 1, HPARAMS['num_actions']])\n",
    "    policy_info = policy_utilities.PerArmPolicyInfo(\n",
    "        chosen_arm_features=arm_features,\n",
    "        # Pass dummy mean rewards here to match the model_spec for emitting\n",
    "        # mean rewards in policy info\n",
    "        predicted_rewards_mean=dummy_rewards,\n",
    "        bandit_policy_type=tf.zeros([HPARAMS['batch_size'], 1, 1], dtype=tf.int32)\n",
    "    )\n",
    "    \n",
    "    if HPARAMS['model_type'] == 'neural_ucb':\n",
    "        policy_info = policy_info._replace(\n",
    "            predicted_rewards_optimistic=dummy_rewards\n",
    "        )\n",
    "        \n",
    "    return trajectory.single_step(\n",
    "        observation=observation,\n",
    "        action=tf.zeros_like(\n",
    "            reward, dtype=tf.int32\n",
    "        ),  # Arm features are copied from policy info, put dummy zeros here\n",
    "        policy_info=policy_info,\n",
    "        reward=reward,\n",
    "        discount=tf.zeros_like(reward)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a0989c-5a06-4fd5-a12d-d92dbbe71a76",
   "metadata": {},
   "source": [
    "Inspect the trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "257791d1-c97c-48c0-bc92-f5a4737b6c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.action.shape      : (128, 1)\n",
      "test_traj.discount.shape    : (128, 1)\n",
      "test_traj.reward.shape      : (128, 1)\n",
      "test_traj.observation.shape : (128, 1, 72)\n"
     ]
    }
   ],
   "source": [
    "for x in train_dataset.batch(HPARAMS['batch_size']).take(1):\n",
    "    test_traj = _trajectory_fn(x)\n",
    "    \n",
    "print(f\"test_traj.action.shape      : {test_traj.action.shape}\") \n",
    "print(f\"test_traj.discount.shape    : {test_traj.discount.shape}\")\n",
    "print(f\"test_traj.reward.shape      : {test_traj.reward.shape}\")\n",
    "print(f\"test_traj.observation.shape : {test_traj.observation['global'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3dace3d1-ce61-48cf-82a4-f701d3fe337c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_traj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcbfc9a-049e-49b9-b2a3-ecb9fd4b9964",
   "metadata": {},
   "source": [
    "# [7] Training the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13adc1ef-b50e-41a3-9b95-c128d0c55a2b",
   "metadata": {},
   "source": [
    "## set Vertex Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "180c03a0-b6b1-4ef0-ae5e-90c04159b584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VERSION=\"v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e861fb27-df24-4821-8448-cf1346b186f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : 02a-superfly-bandit-v2\n",
      "RUN_NAME          : run-20241126-111452\n",
      "\n",
      "CHECKPT_DIR       : gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/chkpoint\n",
      "BASE_OUTPUT_DIR   : gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/run-20241126-111452\n",
      "LOG_DIR           : gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/run-20241126-111452/logs\n",
      "ROOT_DIR          : gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/run-20241126-111452/root\n",
      "ARTIFACTS_DIR     : gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/run-20241126-111452/artifacts\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME   = f'02a-superfly-bandit-{VERSION}'\n",
    "\n",
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "CHECKPT_DIR       = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/chkpoint\"\n",
    "BASE_OUTPUT_DIR   = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}\"\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"CHECKPT_DIR       : {CHECKPT_DIR}\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de729bad-0bc9-429e-b4cb-7b24bf615aa1",
   "metadata": {},
   "source": [
    "### Create TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d2570564-71f4-4dda-8d8a-59784db67632",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NEW_TENSORBOARD = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "db63052a-7eea-4982-964d-1f7ecab0665d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if NEW_TENSORBOARD:\n",
    "#     # create new TB instance\n",
    "#     TENSORBOARD_DISPLAY_NAME=f\"{EXPERIMENT_NAME}\"\n",
    "\n",
    "#     tensorboard = aiplatform.Tensorboard.create(\n",
    "#         display_name=TENSORBOARD_DISPLAY_NAME\n",
    "#         , project=PROJECT_ID\n",
    "#         , location=REGION\n",
    "#     )\n",
    "\n",
    "#     TB_RESOURCE_NAME = tensorboard.resource_name\n",
    "# else:\n",
    "#     # use existing TB instance\n",
    "#     # TB_RESOURCE_NAME = f'projects/{PROJECT_NUM}/locations/{LOCATION}/tensorboards/XXXXXX_TODO_XXXXX'\n",
    "#     tensorboard = aiplatform.Tensorboard(\n",
    "#         tensorboard_name=TB_RESOURCE_NAME\n",
    "#     )\n",
    "\n",
    "# print(f\"TB_RESOURCE_NAME: {TB_RESOURCE_NAME}\")\n",
    "# print(f\"TB display name: {tensorboard.display_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a0b708d-990e-468b-a1b1-a8ba8f71d726",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Delete Tensorboard\n",
    "# vertex_ai_tb.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9c891d27-d9d1-4e64-8981-1a1ae343c858",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# aiplatform.init(\n",
    "#     project=PROJECT_ID,\n",
    "#     location=REGION,\n",
    "#     experiment=EXPERIMENT_NAME,\n",
    "#     experiment_tensorboard=TB_ID\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b7a5e4-efff-490b-b431-53037a2f4a16",
   "metadata": {},
   "source": [
    "## eval loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba0392e-90c8-4dc8-8df2-6d2af1ade490",
   "metadata": {},
   "source": [
    "> When evaluating an epsilon-greedy bandit, we need to remove those predictions that come from the `uniform_random` policy. We only want the predictions from the `GREEDY` policy, becasue we want to know how the model performs when it is actually used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b3d3c-75f7-46f4-9a1b-6329e419b7f5",
   "metadata": {},
   "source": [
    "## train loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bb7ffc-00df-4d46-857b-86c87b78f597",
   "metadata": {},
   "source": [
    "`agent.train(experience=...)`\n",
    "\n",
    "where `experience` is a batch of trajectories data in the form of a Trajectory. \n",
    "* The structure of experience must match that of `self.training_data_spec`. \n",
    "* All tensors in experience must be shaped [batch, time, ...] where time must be equal to self.train_step_length if that property is not None."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94d6d45-c71e-4fe4-9af8-af9a8bda4e4f",
   "metadata": {},
   "source": [
    "### logs & checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "049ee49b-3b1a-4b12-a360-15e759dff7ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('metrics: [<tf_agents.metrics.tf_metrics.AverageReturnMetric object at '\n",
      " '0x7f9a8114bfa0>]')\n",
      "setting checkpoint_manager: gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/chkpoint\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'action': <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x7f9a81015960>,\n",
       " 'get_initial_state': <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x7f9a810178e0>,\n",
       " 'get_train_step': <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x7f9a81016920>,\n",
       " 'get_metadata': <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x7f9a810169e0>}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    f\"{LOG_DIR}\", flush_millis=10 * 1000\n",
    ")\n",
    "# ====================================================\n",
    "# metrics\n",
    "# ====================================================\n",
    "step_metric = tf_metrics.EnvironmentSteps()\n",
    "metrics = [\n",
    "    # tf_metrics.NumberOfEpisodes(),\n",
    "    # tf_metrics.AverageEpisodeLengthMetric(batch_size=HPARAMS['batch_size']),\n",
    "    tf_metrics.AverageReturnMetric(batch_size=HPARAMS['batch_size'])\n",
    "]\n",
    "\n",
    "pprint(f\"metrics: {metrics}\")\n",
    "\n",
    "# ====================================================\n",
    "# get checkpoint manager\n",
    "# ====================================================\n",
    "print(f\"setting checkpoint_manager: {CHECKPT_DIR}\\n\")\n",
    "\n",
    "checkpoint_manager = train_utils.restore_and_get_checkpoint_manager(\n",
    "    root_dir=CHECKPT_DIR, \n",
    "    agent=agent, \n",
    "    metrics=metrics, \n",
    "    step_metric=step_metric\n",
    ")\n",
    "# ====================================================\n",
    "# policy saver\n",
    "# ====================================================\n",
    "saver = policy_saver.PolicySaver(\n",
    "    agent.policy, \n",
    "    train_step=global_step\n",
    ")\n",
    "saver.signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83683f4b-8a1a-44b9-8d5f-7ee3304c794c",
   "metadata": {},
   "source": [
    "### config\n",
    "\n",
    "* calculate train & val dataset sizes\n",
    "* define logging and chkpt intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f9432613-6583-4828-8a2a-dd939adbc3c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_TRAIN_STEPS : 50\n",
      "NUM_EVAL_STEPS  : 1000\n",
      "CHKPT_INTERVAL  : 50\n",
      "LOG_INTERVAL    : 10\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAIN_STEPS = 50\n",
    "NUM_EVAL_STEPS  = 1_000\n",
    "CHKPT_INTERVAL  = NUM_TRAIN_STEPS # // 5\n",
    "LOG_INTERVAL    = 10\n",
    "\n",
    "print(f\"NUM_TRAIN_STEPS : {NUM_TRAIN_STEPS}\")\n",
    "print(f\"NUM_EVAL_STEPS  : {NUM_EVAL_STEPS}\")\n",
    "print(f\"CHKPT_INTERVAL  : {CHKPT_INTERVAL}\")\n",
    "print(f\"LOG_INTERVAL    : {LOG_INTERVAL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "379ffc65-4eec-4af1-8fd4-912ef65a9808",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train data\n",
    "train_ds_iterator = iter(train_dataset.batch(HPARAMS['batch_size']).repeat())\n",
    "\n",
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS[\"eval_batch_size\"])\n",
    "\n",
    "if NUM_EVAL_STEPS > 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)\n",
    "\n",
    "# eval_ds = eval_ds.prefetch(tf.data.AUTOTUNE)\n",
    "# eval_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e498d7e3-d166-4e1d-94a5-f721de58694a",
   "metadata": {},
   "source": [
    "### run train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da4680f3-693b-4530-8e4d-88bc43036c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating pre-trained Agent...\n",
      "pre-train val_loss     : 15.022668838500977\n",
      "pre-train eval runtime : 0\n",
      "starting train loop...\n",
      "step = 0: train loss = 16.030000686645508\n",
      "step = 10: train loss = 14.6899995803833\n",
      "step = 20: train loss = 12.880000114440918\n",
      "step = 30: train loss = 9.850000381469727\n",
      "step = 40: train loss = 7.809999942779541\n",
      "train runtime_mins: 4\n",
      "saved to checkpoint_manager: gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/chkpoint\n",
      "saved trained policy to: gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/run-20241126-111452/artifacts\n",
      "evaluating trained Agent...\n",
      "post-train val_loss     : 5.392337799072266\n",
      "post-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "# agent.train = common.function(agent.train)\n",
    "\n",
    "list_o_loss = []\n",
    "\n",
    "# ====================================================\n",
    "# Evaluate the agent's policy once before training\n",
    "# ====================================================\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "pre_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "\n",
    "print(f\"evaluating pre-trained Agent...\")\n",
    "start_time = time.time()\n",
    "\n",
    "pre_val_loss, pre_preds, pre_tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = pre_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"pre-train val_loss     : {pre_val_loss}\")\n",
    "print(f\"pre-train eval runtime : {runtime_mins}\")\n",
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "print(f\"starting train loop...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(NUM_TRAIN_STEPS):\n",
    "    \n",
    "    with train_summary_writer.as_default():\n",
    "\n",
    "        data = next(train_ds_iterator)\n",
    "        trajectories = _trajectory_fn(data)\n",
    "\n",
    "        # All tensors in experience must be shaped [batch, time, ...] \n",
    "        step = agent.train_step_counter.numpy()\n",
    "        loss = agent.train(experience=trajectories)\n",
    "        list_o_loss.append(loss.loss.numpy())\n",
    "\n",
    "        train_utils._export_metrics_and_summaries(\n",
    "            step=i, \n",
    "            metrics=metrics\n",
    "        )\n",
    "\n",
    "        # print step loss\n",
    "        if step % LOG_INTERVAL == 0:\n",
    "            print(\n",
    "                'step = {0}: train loss = {1}'.format(\n",
    "                    step, round(loss.loss.numpy(), 2)\n",
    "                )\n",
    "            )\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"train runtime_mins: {runtime_mins}\")\n",
    "checkpoint_manager.save(global_step)\n",
    "print(f\"saved to checkpoint_manager: {CHECKPT_DIR}\")\n",
    "saver.save(ARTIFACTS_DIR)\n",
    "print(f\"saved trained policy to: {ARTIFACTS_DIR}\")\n",
    "\n",
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = post_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6008a6fa-748f-4d1e-8d01-c9c4d1b93ce3",
   "metadata": {},
   "source": [
    "#### Inspect Saver and Checkpointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6b0bd92b-6170-4eca-b387-15dca4310dd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/run-20241126-111452/artifacts/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/run-20241126-111452/artifacts/fingerprint.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/run-20241126-111452/artifacts/policy_specs.pbtxt\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/run-20241126-111452/artifacts/saved_model.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/run-20241126-111452/artifacts/assets/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/run-20241126-111452/artifacts/variables/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $ARTIFACTS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6bb79cc5-4dd9-4cfb-aed6-b33037a535fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/chkpoint/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/chkpoint/checkpoint\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/chkpoint/ckpt-50.data-00000-of-00001\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/chkpoint/ckpt-50.index\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $CHECKPT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb1ed8-f67b-4e7b-9cbc-70edd50e49ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate train job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "41937f9a-6c28-48d2-bc7c-bfe4372c7cd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_o_loss)\n",
    "# plt.ylim([0, 10])\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e947e1-67f4-4205-99af-6921c6e9c896",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "65627011-48eb-4e8e-981e-8b61b0f427c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorboard import notebook\n",
    "# notebook.list() # View open TensorBoard instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e0f77a33-0962-4af0-af97-cf05f895cbf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # %load_ext tensorboard\n",
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5d0509cb-0777-4d35-86c6-28c8acbcc793",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %tensorboard --logdir=$LOG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc40143-30b1-479f-b9b1-fa4c07b1690e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [8] Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6c94a0-122f-4ba6-acef-5653a3cc7850",
   "metadata": {
    "tags": []
   },
   "source": [
    "## load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b1c382b5-e2e0-45a2-9c5f-ef2c468d0f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/run-20241126-111452/artifacts\n"
     ]
    }
   ],
   "source": [
    "POLICY_URI = ARTIFACTS_DIR\n",
    "\n",
    "print(POLICY_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "68592d97-1272-4c6d-a4bd-43a6f7fe6c1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f94bc66ca90>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910a06f-678f-4bfa-a132-10b885f871c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## get predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1762c936-3c49-4ec5-a9eb-4df5816dc888",
   "metadata": {},
   "source": [
    "TODO - explain bandit_policy_type()\n",
    "\n",
    "**Dummy arm values?**\n",
    "* We set `chosen_arm_features` to dummy values of all zeros. We need to save dummy chosen arm features to make the returned policy step have the same structure as the policy state spec.\n",
    "* `emit_policy_info = ('predicted_rewards_mean', 'bandit_policy_type')` defines what side information we want to get as part of the policy info when we call policy network \n",
    "* This makes it so that the model always returns the expected rewards even if the model is exploring\n",
    "* This means that the largest predicted rewards may not match the selected action when the model is exploring (i.e. bandit_policy == UNIFORM == 2)\n",
    "\n",
    "**UNIFORM Random policy:**\n",
    "```\n",
    "PolicyStep(action=array(1, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.637535 , 3.5557823], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([2], dtype=int32), chosen_arm_features=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)))\n",
    "```\n",
    "\n",
    "**GREEDY policy:**\n",
    "```\n",
    "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.8278818, 3.607565 ], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([ 0.04054676, -0.04735027,  0.02202327,  0.01276748, -0.01367382,\n",
    "       -0.04838754,  0.00104916, -0.01956806,  0.01028793, -0.00256665,\n",
    "       -0.04376553,  0.03900594,  0.02388967, -0.04016995, -0.04945569,\n",
    "       -0.04539652,  0.04423274, -0.04630332,  0.00390794,  0.03986299,\n",
    "       -0.0398974 ,  0.01655747, -0.0471294 , -0.00690235, -0.03643382,\n",
    "       -0.0437116 ,  0.04757959, -0.00991895,  0.0281055 , -0.04633433,\n",
    "        0.01897702, -0.00824345,  0.03232259, -0.04980658, -0.01144745,\n",
    "        0.01690939,  0.02536928,  0.03384003, -0.01558131,  0.04731432,\n",
    "        0.04579857, -0.03305101,  0.03521084, -0.03915765,  0.04927064,\n",
    "        0.04695194,  0.03792156,  0.040496  ,  0.02574866, -0.00665367,\n",
    "       -0.03839222, -0.01564004, -0.04710373,  0.03557512, -0.01392462,\n",
    "        0.01368621,  0.02792176, -0.01799218,  0.00246101,  0.02263175,\n",
    "        0.0170817 ,  0.01388383, -0.03048695,  0.01198485], dtype=float32)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "567f64e1-8149-4364-b561-1a9d12581b35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# eval_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aff30396-e0fd-4f43-acaa-6af8b20b12cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "SKIP_NUM = 10\n",
    "\n",
    "for x in eval_ds.skip(SKIP_NUM).take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    \n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "    \n",
    "    rewards = _get_rewards(x)\n",
    "    # rewards = reward_factory._get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2bcd1e82-168e-4df3-92bd-4cd34ecd3a94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': <tf.Tensor: shape=(), dtype=float32, numpy=1.0>,\n",
       " 'observation': {'global': <tf.Tensor: shape=(72,), dtype=float32, numpy=\n",
       "array([ 0.01129039,  0.03749099, -0.03180032, -0.01817255, -0.0176999 ,\n",
       "       -0.01351507, -0.01508808,  0.04469122,  0.02707199,  0.00789779,\n",
       "        0.04111029,  0.04264548, -0.01217401,  0.04800345, -0.02508198,\n",
       "       -0.02559271,  0.04327368, -0.01395888, -0.02054362, -0.01462566,\n",
       "        0.03889402,  0.00959548, -0.01155854,  0.00396474,  0.03125955,\n",
       "       -0.04992391,  0.02444819, -0.04372856, -0.00934452,  0.01675539,\n",
       "        0.02335129,  0.02154723, -0.03603622,  0.02849502, -0.04114772,\n",
       "       -0.04593766,  0.0284594 , -0.00695268, -0.03307855,  0.04234859,\n",
       "       -0.02164789,  0.04894276, -0.04441763, -0.00425138,  0.0421542 ,\n",
       "        0.034336  , -0.01787672,  0.01420433,  0.04353007, -0.03925301,\n",
       "        0.03886368, -0.02812861, -0.03355094, -0.00078724, -0.01509041,\n",
       "        0.04979872,  0.02596125,  0.0046113 , -0.03379095,  0.03238029,\n",
       "       -0.00436066,  0.00982936, -0.0420226 ,  0.03732229,  0.00199336,\n",
       "       -0.0292324 , -0.03960808, -0.00069617, -0.01689496, -0.01669176,\n",
       "        0.02310525, -0.01053197], dtype=float32)>,\n",
       "                 'per_arm': <tf.Tensor: shape=(2, 64), dtype=float32, numpy=\n",
       "array([[-0.00972738,  0.02502752, -0.03793858, -0.01111926,  0.0191216 ,\n",
       "         0.00019491, -0.03382985, -0.02035629, -0.02704687,  0.04002326,\n",
       "         0.00639906, -0.02867543,  0.00491301, -0.0001898 ,  0.04085878,\n",
       "        -0.0185643 ,  0.00287239, -0.00324784, -0.01248026, -0.04444889,\n",
       "         0.02234783, -0.03040076, -0.01996803,  0.03677713, -0.01691733,\n",
       "         0.04072145,  0.00237372, -0.00411195,  0.03068035, -0.03112201,\n",
       "         0.0234942 , -0.02073882,  0.0303377 ,  0.01860411,  0.03589633,\n",
       "        -0.04600185,  0.04484267,  0.00460251,  0.03521072, -0.02974161,\n",
       "         0.04901147,  0.03825816, -0.04736679, -0.0040251 ,  0.04317143,\n",
       "        -0.00695745, -0.01981356,  0.03289971,  0.14211598,  0.07321705,\n",
       "        -0.00080419,  0.12294461,  0.01905927, -0.07311147, -0.02906116,\n",
       "         0.09836288, -0.07900493, -0.04686005,  0.03855475,  0.08833393,\n",
       "        -0.02958591, -0.09744347, -0.09688179, -0.00282723],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ]],\n",
       "      dtype=float32)>},\n",
       " 'reward': <tf.Tensor: shape=(), dtype=float32, numpy=3.0>,\n",
       " 'step_type': <tf.Tensor: shape=(), dtype=int32, numpy=0>})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectory_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e58af9ab-f4da-4857-afe5-6b8de26ed0b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([1.486441, 1.486441], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([-0.00972738,  0.02502752, -0.03793858, -0.01111926,  0.0191216 ,\n",
       "        0.00019491, -0.03382985, -0.02035629, -0.02704687,  0.04002326,\n",
       "        0.00639906, -0.02867543,  0.00491301, -0.0001898 ,  0.04085878,\n",
       "       -0.0185643 ,  0.00287239, -0.00324784, -0.01248026, -0.04444889,\n",
       "        0.02234783, -0.03040076, -0.01996803,  0.03677713, -0.01691733,\n",
       "        0.04072145,  0.00237372, -0.00411195,  0.03068035, -0.03112201,\n",
       "        0.0234942 , -0.02073882,  0.0303377 ,  0.01860411,  0.03589633,\n",
       "       -0.04600185,  0.04484267,  0.00460251,  0.03521072, -0.02974161,\n",
       "        0.04901147,  0.03825816, -0.04736679, -0.0040251 ,  0.04317143,\n",
       "       -0.00695745, -0.01981356,  0.03289971,  0.14211598,  0.07321705,\n",
       "       -0.00080419,  0.12294461,  0.01905927, -0.07311147, -0.02906116,\n",
       "        0.09836288, -0.07900493, -0.04686005,  0.03855475,  0.08833393,\n",
       "       -0.02958591, -0.09744347, -0.09688179, -0.00282723], dtype=float32)))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ec286d78-dd56-455d-90f8-4ffa88f3ac50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.486441, 1.486441], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info.predicted_rewards_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c85a0087-7388-4f03-9278-aace31121233",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0, dtype=int32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a8266c7c-3688-46a5-a1c8-a63bb7146128",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info.bandit_policy_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9712bc00-7ea0-4003-a3c7-81a0be5bc995",
   "metadata": {},
   "source": [
    "# [9] Prepare training application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f62966-123f-410e-9610-832f20566635",
   "metadata": {},
   "source": [
    "To scale this training in Vertex AI's managed training service, we need to package all our code into a python application\n",
    "\n",
    "* This means, we need to modularize all steps executed up until this point. For example, the training loop we ran above is further parameterized in `train_perarm.py`, which will be called from our `task.py` when we submit the job to Vertex AI\n",
    "* This training package will eventually be used to create a custom training image (more on that in `04b-build-training-image` notebook)\n",
    "* For additional details on preparing the training application for Vertex AI, check out [the documentation](https://cloud.google.com/vertex-ai/docs/training/code-requirements) and [this code example](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage2/get_started_vertex_training.ipynb) (which also has good, related commentary)\n",
    "\n",
    "**The remaining cells will repeat steps executed above**\n",
    "> we are just illustrating / validating that they are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6c3d30-bef4-4ec5-a978-116856a70e7e",
   "metadata": {},
   "source": [
    "### Distribution strategy\n",
    "\n",
    "Use `strategy_utils` to generate a strategy. Under the hood, passing the parameter:\n",
    "\n",
    "* `use_gpu = False` returns `tf.distribute.get_strategy()`, which uses CPU\n",
    "* `use_gpu = True` returns `tf.distribute.MirroredStrategy()`, which uses all GPUs that are visible to TensorFlow on one machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "68140c4d-12ff-4758-89ca-44fd710ca0c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.distribute.mirrored_strategy.MirroredStrategy at 0x7f945059bc10>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.train.utils import strategy_utils\n",
    "\n",
    "use_gpu = True\n",
    "use_tpu = False\n",
    "\n",
    "distribution_strategy = strategy_utils.get_strategy(tpu=use_tpu, use_gpu=use_gpu)\n",
    "distribution_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e80724b1-6525-4986-b832-4af8b49d923c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_REPLICAS = distribution_strategy.num_replicas_in_sync\n",
    "NUM_REPLICAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1129ee41-b43c-4d5a-b656-cdac6b79688c",
   "metadata": {},
   "source": [
    "### Vertex Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ef509680-4d19-4efa-9f01-21039e0d573b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : 02a-superfly-bandit-v2\n"
     ]
    }
   ],
   "source": [
    "# using same experiment name \n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7ad98430-d836-40f1-8e4f-eb46f0c91fd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : 02a-superfly-bandit-v2\n",
      "RUN_NAME          : run-20241126-112255\n",
      "\n",
      "CHECKPT_DIR       : gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/chkpoint\n",
      "BASE_OUTPUT_DIR   : gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/run-20241126-112255\n",
      "LOG_DIR           : gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/run-20241126-112255/logs\n",
      "ROOT_DIR          : gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/run-20241126-112255/root\n",
      "ARTIFACTS_DIR     : gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/run-20241126-112255/artifacts\n"
     ]
    }
   ],
   "source": [
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "CHECKPT_DIR       = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/chkpoint\"\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "# aiplatform.init(\n",
    "#     project=PROJECT_ID,\n",
    "#     location=REGION,\n",
    "#     experiment=EXPERIMENT_NAME\n",
    "# )\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"CHECKPT_DIR       : {CHECKPT_DIR}\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83de7c4-f7c7-4290-b44a-9e9194bac882",
   "metadata": {},
   "source": [
    "### Create TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "17576ce0-727d-4297-a52d-f64fb75ca78f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # # create new TB instance\n",
    "# TENSORBOARD_DISPLAY_NAME=f\"{EXPERIMENT_NAME}-{RUN_NAME}\"\n",
    "\n",
    "# tensorboard = aiplatform.Tensorboard.create(\n",
    "#     display_name=TENSORBOARD_DISPLAY_NAME\n",
    "#     , project=PROJECT_ID\n",
    "#     , location=REGION\n",
    "# )\n",
    "\n",
    "# TB_RESOURCE_NAME = tensorboard.resource_name\n",
    "\n",
    "# TB_ID = TB_RESOURCE_NAME.split('/')[-1]\n",
    "\n",
    "# print(f\"TB_RESOURCE_NAME : {TB_RESOURCE_NAME}\")\n",
    "# print(f\"TB display name  : {tensorboard.display_name}\")\n",
    "# print(f\"TB_ID            : {TB_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "71d43cf9-db3f-437e-98ee-3791ac0c5e3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    # experiment=EXPERIMENT_NAME,\n",
    "    # experiment_tensorboard=TB_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c2e082-c0f6-4792-a279-e827c48b5895",
   "metadata": {},
   "source": [
    "### trajectory function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b9ce410e-ac03-48b2-8006-4591b38297a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with distribution_strategy.scope():\n",
    "\n",
    "    embs = emb_features.EmbeddingModel(\n",
    "        vocab_dict = vocab_dict,\n",
    "        num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "        global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "        mv_emb_size = MV_EMBEDDING_SIZE,\n",
    "        max_genre_length = data_config.MAX_GENRE_LENGTH\n",
    "    )\n",
    "\n",
    "    def _trajectory_fn(element): # hparams\n",
    "        \"\"\"\n",
    "        Converts a dataset element into a trajectory\n",
    "        \"\"\"\n",
    "        global_features = embs._get_global_context_features(element)\n",
    "        arm_features = embs._get_per_arm_features(element)\n",
    "\n",
    "        # Adds a time dimension.\n",
    "        arm_features = train_utils._add_outer_dimension(arm_features)\n",
    "\n",
    "        # obs spec\n",
    "        observation = {\n",
    "            bandit_spec_utils.GLOBAL_FEATURE_KEY:\n",
    "                train_utils._add_outer_dimension(global_features),\n",
    "        }\n",
    "\n",
    "        # reward = train_utils._add_outer_dimension(reward_factory._get_binary_rewards(element))\n",
    "        reward = train_utils._add_outer_dimension(reward_factory._get_rewards(element))\n",
    "\n",
    "        # To emit the predicted rewards in policy_info, we need to create dummy\n",
    "        # rewards to match the definition in TensorSpec for the ones specified in\n",
    "        # emit_policy_info set.\n",
    "        dummy_rewards = tf.zeros([HPARAMS['batch_size'], 1, HPARAMS['num_actions']])\n",
    "        policy_info = policy_utilities.PerArmPolicyInfo(\n",
    "            chosen_arm_features=arm_features,\n",
    "            # Pass dummy mean rewards here to match the model_spec for emitting\n",
    "            # mean rewards in policy info\n",
    "            predicted_rewards_mean=dummy_rewards,\n",
    "            bandit_policy_type=tf.zeros([HPARAMS['batch_size'], 1, 1], dtype=tf.int32)\n",
    "        )\n",
    "\n",
    "        if HPARAMS['model_type'] == 'neural_ucb':\n",
    "            policy_info = policy_info._replace(\n",
    "                predicted_rewards_optimistic=dummy_rewards\n",
    "            )\n",
    "\n",
    "        return trajectory.single_step(\n",
    "            observation=observation,\n",
    "            action=tf.zeros_like(\n",
    "                reward, \n",
    "                dtype=tf.int32\n",
    "            ),\n",
    "            policy_info=policy_info,\n",
    "            reward=reward,\n",
    "            discount=tf.zeros_like(reward)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b759404-b282-4f55-add8-7d795867c99e",
   "metadata": {},
   "source": [
    "### get agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3be40320-a73f-45f7-9fc4-0bd64df0ae5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 128,\n",
       " 'eval_batch_size': 1,\n",
       " 'num_actions': 2,\n",
       " 'model_type': 'epsGreedy',\n",
       " 'network_type': 'commontower',\n",
       " 'global_layers': [72, 36, 18],\n",
       " 'per_arm_layers': [64, 32, 16],\n",
       " 'common_layers': [34, 8],\n",
       " 'learning_rate': 0.05,\n",
       " 'epsilon': 0.01,\n",
       " 'encoding_dim': 1}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HPARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fbdecf78-94c5-4f8c-a6c0-86f2eace4663",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: NeuralEpsGreedyAgent\n",
      "Network: commontower\n"
     ]
    }
   ],
   "source": [
    "with distribution_strategy.scope():\n",
    "\n",
    "    global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "    agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "        agent_type = HPARAMS['model_type'],\n",
    "        network_type = HPARAMS['network_type'],\n",
    "        time_step_spec = time_step_spec,\n",
    "        action_spec = action_spec,\n",
    "        observation_spec=observation_spec,\n",
    "        global_layers = HPARAMS['global_layers'],\n",
    "        arm_layers = HPARAMS['per_arm_layers'],\n",
    "        common_layers = HPARAMS['common_layers'],\n",
    "        agent_alpha = AGENT_ALPHA,\n",
    "        learning_rate = HPARAMS['learning_rate'],\n",
    "        epsilon = HPARAMS['epsilon'],\n",
    "        train_step_counter = global_step,\n",
    "        output_dim = HPARAMS['encoding_dim'],\n",
    "        eps_phase_steps = EPS_PHASE_STEPS,\n",
    "        summarize_grads_and_vars = False,\n",
    "        debug_summaries = True\n",
    "    )\n",
    "\n",
    "    agent.initialize()\n",
    "\n",
    "print(f\"Agent: {agent.name}\")\n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {NETWORK_TYPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "108ed33c-d8ef-4524-97e9-ced9e01c154b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHKPT_INTERVAL  : 200\n",
      "eval_batch_size : 1\n",
      "NUM_EVAL_STEPS  : 100\n"
     ]
    }
   ],
   "source": [
    "IS_TESTING = True\n",
    "\n",
    "# train args\n",
    "NUM_EPOCHS          = 2\n",
    "TRAINING_LOOPS      = 100\n",
    "STEPS_PER_LOOP      = 1\n",
    "drop_arm_feature_fn = None\n",
    "\n",
    "LOG_INTERVAL        = 10\n",
    "CHKPT_INTERVAL      = 200\n",
    "NUM_EVAL_STEPS      = 100\n",
    "\n",
    "print(f\"CHKPT_INTERVAL  : {CHKPT_INTERVAL}\")\n",
    "print(f\"eval_batch_size : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS  : {NUM_EVAL_STEPS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f66ff927-9a39-4abf-b247-845f0dc7721f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS['eval_batch_size'])\n",
    "\n",
    "if NUM_EVAL_STEPS >= 0:\n",
    "    with distribution_strategy.scope():\n",
    "        eval_ds = eval_ds.take(NUM_EVAL_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "528441f5-64ec-4f09-bd50-b2ae85b553bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "with distribution_strategy.scope():\n",
    "    train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "        f\"{LOG_DIR}\", flush_millis=10 * 1000\n",
    "    )\n",
    "    train_summary_writer.set_as_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f6c98398-d545-4dcc-a71f-32249b5f0336",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distribution_strategy: <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f945059bc10>\n",
      "number of train_files: 3\n",
      "Inpsecting agent policy from train_peram file...\n",
      "agent.policy: <tf_agents.policies.epsilon_greedy_policy.EpsilonGreedyPolicy object at 0x7f94504929e0>\n",
      "Inpsecting agent policy from train_peram file: Complete\n",
      "setting checkpoint_manager: gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/chkpoint\n",
      "agent.train_step_counter: 50\n",
      "starting train loop...\n",
      "epoch: 1\n",
      "step = 60: loss = 4.519999980926514\n",
      "step = 70: loss = 3.9000000953674316\n",
      "step = 80: loss = 2.759999990463257\n",
      "step = 90: loss = 2.119999885559082\n",
      "step = 100: loss = 1.9700000286102295\n",
      "step = 110: loss = 1.5199999809265137\n",
      "step = 120: loss = 1.6699999570846558\n",
      "step = 130: loss = 1.440000057220459\n",
      "step = 140: loss = 1.25\n",
      "step = 150: loss = 1.399999976158142\n",
      "epoch: 2\n",
      "step = 160: loss = 1.1299999952316284\n",
      "step = 170: loss = 1.440000057220459\n",
      "step = 180: loss = 1.1399999856948853\n",
      "step = 190: loss = 1.0099999904632568\n",
      "step = 200: loss = 1.4299999475479126\n",
      "step = 210: loss = 1.2100000381469727\n",
      "step = 220: loss = 1.2699999809265137\n",
      "step = 230: loss = 1.3200000524520874\n",
      "step = 240: loss = 1.3300000429153442\n",
      "step = 250: loss = 1.399999976158142\n",
      "runtime_mins: 0\n",
      "saved trained policy to: gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/run-20241126-112255/artifacts\n",
      "saved to checkpoint_manager: gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/chkpoint\n",
      "complete train job in 0 minutes\n"
     ]
    }
   ],
   "source": [
    "#start the timer and training\n",
    "start_time = time.time()\n",
    "\n",
    "metric_results, agent = train_perarm.train_perarm(\n",
    "    agent = agent,\n",
    "    reward_spec = reward_tensor_spec,\n",
    "    epsilon = HPARAMS['epsilon'],\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    num_epochs = NUM_EPOCHS,\n",
    "    num_iterations = TRAINING_LOOPS,\n",
    "    steps_per_loop = STEPS_PER_LOOP,\n",
    "    global_step = global_step,\n",
    "    train_summary_writer = train_summary_writer,\n",
    "    strategy = distribution_strategy,\n",
    "    # data\n",
    "    batch_size = HPARAMS['batch_size'],\n",
    "    # functions\n",
    "    _trajectory_fn = _trajectory_fn,\n",
    "    # train intervals\n",
    "    chkpt_interval = CHKPT_INTERVAL,\n",
    "    log_interval = LOG_INTERVAL,\n",
    "    # dirs\n",
    "    bucket_name = BUCKET_NAME,\n",
    "    data_dir_prefix_path = f\"{EXAMPLE_GEN_GCS_PATH}\",\n",
    "    log_dir = LOG_DIR,\n",
    "    model_dir = ARTIFACTS_DIR,\n",
    "    chkpoint_dir = CHECKPT_DIR,\n",
    "    use_gpu = True,\n",
    "    use_tpu = False,\n",
    "    profiler = False,\n",
    "    is_testing = IS_TESTING,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"complete train job in {runtime_mins} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "177aa3ab-05b4-48f9-b434-9335bd9eb54d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3976177"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(metric_results)\n",
    "metric_results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ba65417f-54e0-436e-b0d4-93cffb981ae6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(metric_results)\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61464938-a3e7-4ab0-9149-4a9124199dc1",
   "metadata": {},
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9108f8b6-7aea-48d6-a763-461b30671c21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # %load_ext tensorboard\n",
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "083c2351-5ac8-4218-9bef-e249777aee97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %tensorboard --logdir=$LOG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7ba747-00d5-4908-8d0b-334ae9d2c791",
   "metadata": {},
   "source": [
    "#### eval trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c5cf9366-d9cd-4c9d-951a-99a50877a374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af82506e-95d7-4a4e-a821-e08512615db7",
   "metadata": {},
   "source": [
    "After training, our `agent.policy` is used as the deployment \"model\" that will generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6c82396a-7822-41fb-830f-1f6eb9c9b213",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.epsilon_greedy_policy.EpsilonGreedyPolicy at 0x7f94504929e0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_agent = agent.policy\n",
    "deployment_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f6706224-ef5b-4185-bde4-bccb7c8e7ccc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating trained Agent...\n",
      "post-train val_loss     : 1.2774502038955688\n",
      "post-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(deployment_agent, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = post_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f899120f-3706-4b72-8f2c-2169221dd66b",
   "metadata": {},
   "source": [
    "## Using Trained Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b0f691-860e-4853-928e-4c7ece714dd0",
   "metadata": {},
   "source": [
    "### load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ea029f73-0638-462a-8f00-54b05c54d69b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/run-20241126-112255/artifacts\n"
     ]
    }
   ],
   "source": [
    "POLICY_URI = ARTIFACTS_DIR\n",
    "\n",
    "print(POLICY_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "66d1d819-0152-437c-aefc-45ffd34d808a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/run-20241126-112255/artifacts/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/run-20241126-112255/artifacts/fingerprint.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/run-20241126-112255/artifacts/policy_specs.pbtxt\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/run-20241126-112255/artifacts/saved_model.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/run-20241126-112255/artifacts/assets/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-superfly-bandit-v2/run-20241126-112255/artifacts/variables/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $POLICY_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6aad948e-e346-4da3-8cb2-747435c8dc4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f94503ed1e0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "483f8fa5-cbd1-4e3c-8e62-47f91f42e137",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(), dtype=dtype('int32'), name='action_spec', minimum=0, maximum=1)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_policy.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8f658891-bc09-49b8-bc58-000a7926df28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "SKIP_NUM = 10\n",
    "\n",
    "for x in eval_ds.skip(SKIP_NUM).take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    \n",
    "    # global_feat_infer = _get_global_context_features(x)\n",
    "    # arm_feat_infer = _get_per_arm_features(x)\n",
    "    \n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "    \n",
    "    # rewards = _get_rewards(x)\n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "49ce41ed-41b7-404d-9796-1658e7955894",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': <tf.Tensor: shape=(), dtype=float32, numpy=1.0>,\n",
       " 'observation': {'global': <tf.Tensor: shape=(72,), dtype=float32, numpy=\n",
       "array([-0.00538361,  0.00447739,  0.04942648,  0.03591767,  0.00931233,\n",
       "        0.02108629, -0.04305942, -0.00392396,  0.04840577,  0.03431318,\n",
       "        0.0255559 , -0.02742267,  0.04062105,  0.04895863, -0.01312735,\n",
       "        0.04471897, -0.01480586, -0.03796353,  0.01384299, -0.03076298,\n",
       "       -0.02944547, -0.02978922,  0.04957206,  0.00246198, -0.0081513 ,\n",
       "        0.00277939,  0.04076641, -0.03918875, -0.04565778,  0.03440491,\n",
       "       -0.02607255, -0.04191235,  0.02618906, -0.02087877,  0.01018996,\n",
       "       -0.02191182, -0.0144453 , -0.03191795, -0.02902844, -0.02068773,\n",
       "       -0.02811318,  0.0008903 , -0.01872082, -0.03359433,  0.01133414,\n",
       "       -0.03173732,  0.04541408, -0.03813523, -0.01412927,  0.03659237,\n",
       "       -0.00641279, -0.00417291, -0.00584519, -0.03944383, -0.03986212,\n",
       "       -0.01232792, -0.01055049, -0.0196521 , -0.03116201,  0.04036707,\n",
       "        0.04662788, -0.00724137,  0.0393529 , -0.01924014, -0.00435849,\n",
       "       -0.03546519, -0.04325556,  0.01899565,  0.03625965, -0.01881355,\n",
       "        0.01012565,  0.00473077], dtype=float32)>,\n",
       "                 'per_arm': <tf.Tensor: shape=(2, 64), dtype=float32, numpy=\n",
       "array([[-0.01207782, -0.03164081, -0.0313274 ,  0.02340678,  0.0225823 ,\n",
       "         0.02541426,  0.03392345, -0.0227659 , -0.04601965,  0.00166409,\n",
       "        -0.00096167,  0.01407405, -0.00044758, -0.02387581, -0.01450387,\n",
       "        -0.00408467, -0.02115578,  0.02963001,  0.04767457,  0.01824208,\n",
       "        -0.02070843, -0.03245039,  0.04143092, -0.02818679,  0.04846076,\n",
       "        -0.0328464 ,  0.03828836,  0.04121409, -0.00500689, -0.02125076,\n",
       "         0.00216123,  0.00123165,  0.01302527,  0.04182294,  0.01450776,\n",
       "         0.04486063, -0.048182  , -0.01883265,  0.02330278, -0.02645388,\n",
       "         0.01591787, -0.03296734,  0.01028142, -0.04503173,  0.03503683,\n",
       "         0.00966709,  0.04619633, -0.00961082, -0.00878381, -0.04821321,\n",
       "        -0.12448872,  0.10201892,  0.01977074, -0.10400999,  0.01961252,\n",
       "        -0.05901968, -0.09936652,  0.1010755 , -0.13575812,  0.0286476 ,\n",
       "        -0.05501604,  0.06147376, -0.00917501,  0.13131276],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ]],\n",
       "      dtype=float32)>},\n",
       " 'reward': <tf.Tensor: shape=(), dtype=float32, numpy=3.0>,\n",
       " 'step_type': <tf.Tensor: shape=(), dtype=int32, numpy=0>})"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectory_step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f515fcd0-2228-4f68-9ef9-665ce1fc3fb2",
   "metadata": {},
   "source": [
    "### view prediction response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6af4c297-d2e8-4f7b-bed5-e1da997dfe34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.5640433, 3.5640433], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([-0.01207782, -0.03164081, -0.0313274 ,  0.02340678,  0.0225823 ,\n",
       "        0.02541426,  0.03392345, -0.0227659 , -0.04601965,  0.00166409,\n",
       "       -0.00096167,  0.01407405, -0.00044758, -0.02387581, -0.01450387,\n",
       "       -0.00408467, -0.02115578,  0.02963001,  0.04767457,  0.01824208,\n",
       "       -0.02070843, -0.03245039,  0.04143092, -0.02818679,  0.04846076,\n",
       "       -0.0328464 ,  0.03828836,  0.04121409, -0.00500689, -0.02125076,\n",
       "        0.00216123,  0.00123165,  0.01302527,  0.04182294,  0.01450776,\n",
       "        0.04486063, -0.048182  , -0.01883265,  0.02330278, -0.02645388,\n",
       "        0.01591787, -0.03296734,  0.01028142, -0.04503173,  0.03503683,\n",
       "        0.00966709,  0.04619633, -0.00961082, -0.00878381, -0.04821321,\n",
       "       -0.12448872,  0.10201892,  0.01977074, -0.10400999,  0.01961252,\n",
       "       -0.05901968, -0.09936652,  0.1010755 , -0.13575812,  0.0286476 ,\n",
       "       -0.05501604,  0.06147376, -0.00917501,  0.13131276], dtype=float32)))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd58d4b-6749-4177-8342-83ee969408c9",
   "metadata": {},
   "source": [
    "#### chosen action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d49adbbb-f747-4e4c-b82d-df88373c644f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0, dtype=int32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd12013-1d12-4197-8254-cef9138df42c",
   "metadata": {},
   "source": [
    "#### Per Arm Policy Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d6126290-546b-4702-8a1e-91f18adb05c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.5640433, 3.5640433], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([-0.01207782, -0.03164081, -0.0313274 ,  0.02340678,  0.0225823 ,\n",
       "        0.02541426,  0.03392345, -0.0227659 , -0.04601965,  0.00166409,\n",
       "       -0.00096167,  0.01407405, -0.00044758, -0.02387581, -0.01450387,\n",
       "       -0.00408467, -0.02115578,  0.02963001,  0.04767457,  0.01824208,\n",
       "       -0.02070843, -0.03245039,  0.04143092, -0.02818679,  0.04846076,\n",
       "       -0.0328464 ,  0.03828836,  0.04121409, -0.00500689, -0.02125076,\n",
       "        0.00216123,  0.00123165,  0.01302527,  0.04182294,  0.01450776,\n",
       "        0.04486063, -0.048182  , -0.01883265,  0.02330278, -0.02645388,\n",
       "        0.01591787, -0.03296734,  0.01028142, -0.04503173,  0.03503683,\n",
       "        0.00966709,  0.04619633, -0.00961082, -0.00878381, -0.04821321,\n",
       "       -0.12448872,  0.10201892,  0.01977074, -0.10400999,  0.01961252,\n",
       "       -0.05901968, -0.09936652,  0.1010755 , -0.13575812,  0.0286476 ,\n",
       "       -0.05501604,  0.06147376, -0.00917501,  0.13131276], dtype=float32))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f66961-ebb5-4ae5-8e6f-ad73114d8353",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
