{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385307d6-2058-47ec-8da0-57f7ef5c43d6",
   "metadata": {},
   "source": [
    "# Train Bandits with per-arm features\n",
    "\n",
    "**Exploring linear and nonlinear** (e.g., those with neural network-based value functions) bandit methods for recommendations using TF-Agents\n",
    "\n",
    "> Neural linear bandits provide a nice way to leverage the representation power of deep learning and the bandit approach for uncertainty measure and efficient exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1e9956-66cd-4bf4-9b4d-8c2c646f0313",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e77101d-7014-4b1d-9f7a-ecc158513b96",
   "metadata": {},
   "source": [
    "In this notebook, we explore the following topics for training contextual bandits with per-arm features:\n",
    "\n",
    "1. Data preperation\n",
    "2. Sampling functions\n",
    "3. TensorSpecs\n",
    "4. Agent, Network, training policy\n",
    "5. Reward function\n",
    "6. Trajectory function\n",
    "7. Train & Eval loops\n",
    "8. Getting predictions -\n",
    "9. Preparing the training application - abstracting all steps above to be used in subsequent notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc51191-d773-46cd-adc7-ef5ab92e5ffb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Per-arm features in TF-Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00d46b5-ea07-4447-84e6-0f023f77f5b4",
   "metadata": {},
   "source": [
    "In TF-Agents, the *per-arm features* implementation differs from the *global-only* feature examples in the following aspects:\n",
    "* Reward is modeled not per-arm, but globally.\n",
    "* The arms are permutation invariant: it doesn’t matter which arm is arm 1 or arm 2, only their features.\n",
    "* One can have a different number of arms to choose from in every step (note that unspecified/dynamically changing number of arms will have a problem with XLA compatibility).\n",
    "\n",
    "When implementing per-arm features in TF-Bandits, the following details have to be discussed:\n",
    "* Observation spec and observations,\n",
    "* Action spec and actions,\n",
    "* Implementation of specific policies and agents.\n",
    "\n",
    "\n",
    "**TODO:**\n",
    "* outline the components and highlight their interactions, dependencies on eachother, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fd257-b98b-426a-a2cd-024429b014f1",
   "metadata": {},
   "source": [
    "## Load notebook config\n",
    "\n",
    "* use the prefix defined in `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f39c9d08-d118-4013-a47f-88450f49f19e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "VERSION        = \"v2\"                       # TODO\n",
    "PREFIX         = f'rec-bandits-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908f6b95-b539-4a9f-a836-840d26ea3b09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"rec-bandits-v2\"\n",
      "VERSION                  = \"v2\"\n",
      "\n",
      "BUCKET_NAME              = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_NAME    = \"mvlens_rec_bandits_v2\"\n",
      "BIGQUERY_TABLE_NAME      = \"training_dataset\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-rec-bandits-v2\"\n",
      "\n",
      "DOCKERNAME_01            = \"Dockerfile_train_my_perarm_env\"\n",
      "IMAGE_NAME_01            = \"train-my-perarm-env-v2\"\n",
      "IMAGE_URI_01             = \"gcr.io/hybrid-vertex/train-my-perarm-env-v2\"\n",
      "\n",
      "DOCKERNAME_02            = \"Dockerfile_perarm_feats\"\n",
      "IMAGE_NAME_02            = \"train-perarm-feats-v2\"\n",
      "IMAGE_URI_02             = \"gcr.io/hybrid-vertex/train-perarm-feats-v2\"\n",
      "\n",
      "DOCKERNAME_03            = \"Dockerfile_ranking_bandit\"\n",
      "IMAGE_NAME_03            = \"train-rank-bandit-v2\"\n",
      "IMAGE_URI_03             = \"gcr.io/hybrid-vertex/train-rank-bandit-v2\"\n",
      "\n",
      "DOCKERNAME_04            = \"Dockerfile_train_bandit_e2e\"\n",
      "IMAGE_NAME_04            = \"train-mab-e2e-v2\"\n",
      "IMAGE_URI_04             = \"gcr.io/hybrid-vertex/train-mab-e2e-v2\"\n",
      "\n",
      "DOCKERNAME_04_pred       = \"Dockerfile_pred_bandit_e2e\"\n",
      "IMAGE_NAME_04_pred       = \"pred-mab-e2e-v2\"\n",
      "IMAGE_URI_04_pred        = \"gcr.io/hybrid-vertex/pred-mab-e2e-v2\"\n",
      "\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/local_docker_tfa\"\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c690a9-e2bd-4759-ba41-4e2469098aee",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d0dfe4-695c-4dd4-9f24-67f7488ce1a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_GPU_ALLOCATOR'] ='cuda_malloc_async'\n",
    "os.environ['TF_GPU_THREAD_MODE'] = 'gpu_private'\n",
    "os.environ['TF_GPU_THREAD_COUNT'] = '1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c669f1a1-1af7-4efb-ab2d-6bf3b3847991",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import functools\n",
    "import collections\n",
    "import pickle as pkl\n",
    "from pprint import pprint\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# tf-agents\n",
    "from tf_agents.utils import common\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.metrics import export_utils\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.bandits.policies import policy_utilities\n",
    "from tf_agents.bandits.agents import neural_linucb_agent\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# this repo\n",
    "from src.utils import train_utils, reward_factory\n",
    "from src.data import data_utils, data_config\n",
    "from src.trainer import eval_perarm as eval_perarm, train_perarm\n",
    "from src.agents import agent_factory as agent_factory\n",
    "from src.networks import encoding_network as emb_features\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4969d3e-1fc0-45db-8a69-aa6b342019de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: Tesla T4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "print(f\"device: {device.name.decode()}\")\n",
    "\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "274e7f4a-1802-4946-888e-876638f5c677",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a866b1-85b9-43e6-9546-edfbbf886bce",
   "metadata": {},
   "source": [
    "# [1] Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d4ed28-23d7-4785-b327-e5b543b0edb9",
   "metadata": {},
   "source": [
    "**Overview**\n",
    "* Load train and eval datasets from TFRecords created in the `01-movielens-data-prep.ipynb` notebook\n",
    "* training examples represent historical (previously collected) interaction data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc3fcebe-818b-4767-afdc-cfb65b3b953d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCS_DATA_PATH: gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m\n"
     ]
    }
   ],
   "source": [
    "EXAMPLE_GEN_GCS_PATH = data_config.EXAMPLE_GEN_GCS_PATH\n",
    "GCS_DATA_PATH = f\"{BUCKET_URI}/{EXAMPLE_GEN_GCS_PATH}\"\n",
    "\n",
    "print(f\"GCS_DATA_PATH: {GCS_DATA_PATH}\")\n",
    "\n",
    "# !gsutil ls $GCS_DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd5b953-14c0-42ed-a511-77147a1bc0ac",
   "metadata": {},
   "source": [
    "### Read TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d0157c8-a04c-4dbd-b6d9-a1ede97687a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da0cdac-76af-4608-b70e-be7dbe0584b5",
   "metadata": {},
   "source": [
    "**Train data**\n",
    "\n",
    "tf example\n",
    "\n",
    "```python\n",
    "{\n",
    "    'target_movie_genres': <tf.Tensor: shape=(1, 10), dtype=string, numpy= array([[b'Drama', b'UNK', b'UNK', b'UNK', b'UNK', b'UNK', b'UNK', b'UNK', b'UNK', b'UNK']], dtype=object)>,\n",
    "    'target_movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'1775'], dtype=object)>,\n",
    "    'target_movie_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>,\n",
    "    'target_movie_title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Live Flesh (1997)'], dtype=object)>,\n",
    "    'target_movie_year': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1997])>,\n",
    "    'target_rating_timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([974612615])>,\n",
    "    'user_age': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([50])>,\n",
    "    'user_gender': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'M'], dtype=object)>,\n",
    "    'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'2173'], dtype=object)>,\n",
    "    'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'programmer'], dtype=object)>,\n",
    "    'user_zip_code': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'87505'], dtype=object)>\n",
    "}\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c934c06-bf08-4c7f-b0cc-0de04ef3515c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SPLIT = \"train\"\n",
    "\n",
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{EXAMPLE_GEN_GCS_PATH}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "train_files = train_files[:5]\n",
    "\n",
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "train_dataset = train_dataset.map(data_utils._parse_function)\n",
    "\n",
    "# for x in train_dataset.batch(1).take(1):\n",
    "#     pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452750c1-46a0-4ee1-84d4-0c3b227de38f",
   "metadata": {},
   "source": [
    "**Val data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7b5376f-9438-4304-84aa-de09c30f5e0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/val/ml-1m-gen-001-of-003.tfrecord',\n",
       " 'gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/val/ml-1m-gen-002-of-003.tfrecord',\n",
       " 'gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/val/ml-1m-gen-003-of-003.tfrecord']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPLIT = \"val\"\n",
    "\n",
    "val_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{EXAMPLE_GEN_GCS_PATH}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        val_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "val_files\n",
    "# val_dataset = tf.data.TFRecordDataset(val_files)\n",
    "# val_dataset = val_dataset.map(data_utils._parse_function, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8959967-522e-41c8-9a1b-050ca8bc191f",
   "metadata": {},
   "source": [
    "### get vocab\n",
    "\n",
    "**TODO:** \n",
    "* streamline vocab calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3ccf137-7a72-42e7-aa89-3c81a99cf40a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab...\n",
      "Downloaded vocab from: gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/vocabs/vocab_dict.pkl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{EXAMPLE_GEN_GCS_PATH}/vocabs/{VOCAB_FILENAME}'\n",
    "print(f\"Downloading vocab...\")\n",
    "\n",
    "os.system(f'gsutil -q cp {EXISTING_VOCAB_FILE} .')\n",
    "print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "vocab_dict = pkl.load(filehandler)\n",
    "filehandler.close()\n",
    "\n",
    "# for key in vocab_dict.keys():\n",
    "#     pprint(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138a295-2b0d-4359-8496-af8552ec8cff",
   "metadata": {},
   "source": [
    "# [2] Preprocessing layers for global and arm features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e28c002-8d3a-4cf4-b69b-de56a6abab90",
   "metadata": {},
   "source": [
    "The preproccesing layers will ultimately feed the two sampling functions described below. These sampling functions will be used to create [trajectories](https://github.com/tensorflow/agents/blob/master/tf_agents/trajectories/trajectory.py#L36) (i.e., the training examples for our model)\n",
    "\n",
    "`global_context_sampling_fn`: \n",
    "* A function that outputs a random 1d array or list of ints or floats\n",
    "* This output is the global context. Its shape and type must be consistent across calls.\n",
    "\n",
    "`arm_context_sampling_fn`: \n",
    "* A function that outputs a random 1 array or list of ints or floats (same type as the output of `global_context_sampling_fn`). * This output is the per-arm context. Its shape must be consistent across calls.\n",
    "\n",
    "See `debug-and-learn-emb-models.ipynb` for more details and debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ea1f7-0621-44b8-b062-1f59b0964d72",
   "metadata": {},
   "source": [
    "## Global & Per-Arm feature embedding models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550a1063-15d4-472e-b5a7-d92dcdea3c0f",
   "metadata": {},
   "source": [
    "**get expected dimensions**\n",
    "\n",
    "**common layers**\n",
    "* layer sizes for the final tower\n",
    "* The network that takes as input the concatenation of \n",
    "  the outputs of the global and the arm networks\n",
    "*  hidden layers ideally divisible by 8, e.g., [16, 32, 64, 128, 256, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8d77956-635c-438a-916a-185eec52f9c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPECTED_GLOBAL_DIM: 72\n",
      "EXPECTED_PER_ARM_DIM: 64\n",
      "EXPECTED_GLOBAL_LAYERS      : [72, 36, 18]\n",
      "EXPECTED_ARM_LAYERS         : [64, 32, 16]\n",
      "EXPECTED_COMMON_LAYERS      : [34, 17, 8]\n"
     ]
    }
   ],
   "source": [
    "NUM_OOV_BUCKETS        = 1\n",
    "GLOBAL_EMBEDDING_SIZE  = 12\n",
    "MV_EMBEDDING_SIZE      = 16\n",
    "\n",
    "NUM_GLOBAL_FEATURES = len(data_utils.USER_FEATURE_NAMES)\n",
    "NUM_ARM_FEATURES    = len(data_utils.MOVIE_FEATURE_NAMES)\n",
    "\n",
    "EXPECTED_GLOBAL_DIM  = GLOBAL_EMBEDDING_SIZE * NUM_GLOBAL_FEATURES\n",
    "EXPECTED_PER_ARM_DIM = MV_EMBEDDING_SIZE * NUM_ARM_FEATURES\n",
    "print(f\"EXPECTED_GLOBAL_DIM: {EXPECTED_GLOBAL_DIM}\")\n",
    "print(f\"EXPECTED_PER_ARM_DIM: {EXPECTED_PER_ARM_DIM}\")\n",
    "\n",
    "EXPECTED_GLOBAL_LAYERS   = [\n",
    "    EXPECTED_GLOBAL_DIM, \n",
    "    int(EXPECTED_GLOBAL_DIM/2), \n",
    "    int(EXPECTED_GLOBAL_DIM/4)\n",
    "]\n",
    "EXPECTED_ARM_LAYERS      = [\n",
    "    EXPECTED_PER_ARM_DIM, \n",
    "    int(EXPECTED_PER_ARM_DIM/2), \n",
    "    int(EXPECTED_PER_ARM_DIM/4)\n",
    "]\n",
    "EXPECTED_FIRST_COMMON_LAYER = EXPECTED_GLOBAL_LAYERS[-1] + EXPECTED_ARM_LAYERS[-1]\n",
    "EXPECTED_COMMON_LAYERS = [\n",
    "    int(EXPECTED_FIRST_COMMON_LAYER), \n",
    "    int(EXPECTED_FIRST_COMMON_LAYER/2), \n",
    "    int(EXPECTED_FIRST_COMMON_LAYER/4)\n",
    "]\n",
    "print(f\"EXPECTED_GLOBAL_LAYERS      : {EXPECTED_GLOBAL_LAYERS}\")\n",
    "print(f\"EXPECTED_ARM_LAYERS         : {EXPECTED_ARM_LAYERS}\")\n",
    "print(f\"EXPECTED_COMMON_LAYERS      : {EXPECTED_COMMON_LAYERS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea335991-dcec-40b3-ba0d-a0fdfb9c2ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test emb models\n",
    "for i in range(1):\n",
    "    \n",
    "    iterator = iter(train_dataset.batch(1))\n",
    "    data = next(iterator)\n",
    "\n",
    "del iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48178fff-491f-4f03-b156-7765d1fa9707",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.networks.encoding_network.EmbeddingModel at 0x7f97a99740d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs = emb_features.EmbeddingModel(\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    "    max_genre_length = data_config.MAX_GENRE_LENGTH\n",
    ")\n",
    "\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "903c63c5-2468-4443-bcb8-5ff6d69810dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL_DIM: 72\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 72), dtype=float32, numpy=\n",
       "array([[ 0.0069826 ,  0.03065955,  0.01049351, -0.01218629,  0.02665737,\n",
       "         0.04960923,  0.03306135,  0.00095851, -0.0084366 ,  0.00120091,\n",
       "        -0.01793635,  0.01086356,  0.00807315, -0.01629288,  0.010896  ,\n",
       "         0.02065433, -0.02469853, -0.04128011,  0.04595056,  0.04052837,\n",
       "         0.0033137 ,  0.00658653, -0.01219565,  0.0446209 ,  0.01600316,\n",
       "         0.04670178,  0.04060948,  0.04057236,  0.02646592,  0.04101631,\n",
       "         0.00259695, -0.04790501,  0.03033283, -0.01827732, -0.02054741,\n",
       "        -0.01148578, -0.03696977, -0.04736035,  0.03973882,  0.01464732,\n",
       "        -0.04674872, -0.04359777,  0.01684796, -0.01724502, -0.01035795,\n",
       "         0.04537386,  0.03879004, -0.04044508, -0.04943304,  0.0469308 ,\n",
       "         0.02647572, -0.0132942 ,  0.00209051,  0.0437024 ,  0.0042304 ,\n",
       "        -0.04750459,  0.03952603,  0.01891147, -0.00696827,  0.00310028,\n",
       "         0.04663733,  0.02246128, -0.00207583, -0.00980072, -0.0018989 ,\n",
       "        -0.0193848 , -0.0247088 , -0.0322293 , -0.02596726, -0.01131264,\n",
       "        -0.03270828, -0.00216649]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_globals = embs._get_global_context_features(data)\n",
    "\n",
    "GLOBAL_DIM = test_globals.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"GLOBAL_DIM: {GLOBAL_DIM}\")\n",
    "\n",
    "test_globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebec4863-c614-4248-b680-8e29ec5b730d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER_ARM_DIM: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 64), dtype=float32, numpy=\n",
       "array([[ 1.39449947e-02,  1.36779062e-02,  3.12077999e-03,\n",
       "         1.75842680e-02,  1.14239752e-04,  7.63963908e-04,\n",
       "        -2.04827916e-02, -4.22689319e-02,  3.08053382e-02,\n",
       "         3.84588726e-02,  4.81002443e-02, -3.90453935e-02,\n",
       "        -4.18667793e-02, -2.23834645e-02,  3.08406614e-02,\n",
       "         3.54906209e-02, -4.75951284e-03, -1.29815713e-02,\n",
       "         3.91244553e-02, -1.21539719e-02, -1.35800354e-02,\n",
       "        -2.26184968e-02,  1.80386193e-02, -1.46738440e-03,\n",
       "         3.70568521e-02,  4.75392006e-02, -3.18372399e-02,\n",
       "         2.37102546e-02,  1.40780471e-02, -3.49355713e-02,\n",
       "         4.67159487e-02,  2.14806907e-02, -1.07951701e-01,\n",
       "         2.26606891e-01,  1.88006893e-01, -1.62788153e-01,\n",
       "         3.78237292e-02,  1.68139949e-01,  4.09193709e-02,\n",
       "        -1.99330971e-02, -1.86482370e-01,  1.13743484e-01,\n",
       "        -4.81014885e-02,  1.42596826e-01,  2.53000297e-02,\n",
       "        -6.91986680e-02,  2.01352850e-01, -9.59427953e-02,\n",
       "         3.05313058e-02,  2.31417511e-02, -2.43165810e-02,\n",
       "         1.27901481e-02, -5.30672842e-04, -1.73209328e-02,\n",
       "         4.26807860e-03, -1.99542660e-02, -1.17676314e-02,\n",
       "         4.72449772e-02,  4.16579992e-02,  2.63639204e-02,\n",
       "        -3.65391858e-02,  1.02735462e-03, -1.51819149e-02,\n",
       "        -3.45663279e-02]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arms = embs._get_per_arm_features(data)\n",
    "\n",
    "PER_ARM_DIM = test_arms.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"PER_ARM_DIM: {PER_ARM_DIM}\")\n",
    "\n",
    "test_arms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeb4902-5bb9-4587-8d29-c01d78b006be",
   "metadata": {},
   "source": [
    "# [3] TensorSpecs\n",
    "\n",
    "* say you have a global observation spec of `[17]`. And you have two batch dimensions `[4, 5]`. Then your observation has to have the shape `[4, 5, 17]`\n",
    "* and then if you have arm_obs_spec with shape `[9, 13]`, then the arm obs shape has to be exactly `[4, 5, 9, 13]`\n",
    "* and this has to be true for every single tensor in your tensor nest\n",
    "* the first 2 dims are the outer dims that are the same for all tensors, the rest of the dimensions have to follow the spec for each tensor\n",
    "\n",
    "**TODO:**\n",
    "* explain relationship between Tensor Specs and their Tensor counterparts\n",
    "* highlight the errors, lessons learned, and utility functions to address these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ff9baaf-987d-448d-a981-742a79b581e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE      : 128\n",
      "EVAL_BATCH_SIZE : 1\n",
      "NUM_ACTIONS     : 2\n",
      "GLOBAL_DIM      : 72\n",
      "PER_ARM_DIM     : 64\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE      = 128\n",
    "EVAL_BATCH_SIZE = 1\n",
    "\n",
    "NUM_ACTIONS     = 2\n",
    "\"\"\"\n",
    "This `NUM_ACTIONS` is kinda deceptive: \n",
    "  Our approach is to learn by \"flashing\" one movie rating at a time per user context. \n",
    "  The n_actions = show/don't show the movie with one degree of freedom (n-1)\n",
    "\"\"\"\n",
    "\n",
    "print(f\"BATCH_SIZE      : {BATCH_SIZE}\")\n",
    "print(f\"EVAL_BATCH_SIZE : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"NUM_ACTIONS     : {NUM_ACTIONS}\")\n",
    "print(f\"GLOBAL_DIM      : {GLOBAL_DIM}\")\n",
    "print(f\"PER_ARM_DIM     : {PER_ARM_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f68ebe8-116d-43b3-a6e1-4f5a5c7f4741",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Observation spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9c4746-d01b-4ca4-aa53-ab68da54d37a",
   "metadata": {},
   "source": [
    "**This observation spec allows the user to have a global observation of fixed dimension**, and an unspecified number of *per-arm* features (also of fixed dimension)\n",
    "* The actions output by the policy are still integers as usual, and they indicate which row of the arm-features it has chosen \n",
    "* The action spec must be a single integer value without boundaries:\n",
    "\n",
    "```python\n",
    "global_spec = tensor_spec.TensorSpec([GLOBAL_DIM], tf.float32)\n",
    "per_arm_spec = tensor_spec.TensorSpec([None, PER_ARM_DIM], tf.float32)\n",
    "observation_spec = {'global': global_spec, 'per_arm': per_arm_spec}\n",
    "\n",
    "action_spec = tensor_spec.TensorSpec((), tf.int32)\n",
    "```\n",
    "> Here the only difference compared to the action spec with global features only is that the tensor spec is not bounded, as we don’t know how many arms there will be at any time step\n",
    "\n",
    "**XLA compatibility:**\n",
    "* Since dynamic tensor shapes are not compatible with XLA, the number of arm features (and consequently, number of arms for a step) cannot be dynamic. \n",
    "* One workaround is to fix the maximum number of arms for a problem, then pad the arm features in steps with fewer arms, and use action masking to indicate how many arms are actually active.\n",
    "\n",
    "```python\n",
    "per_arm_spec = tensor_spec.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32)\n",
    "\n",
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=(), dtype=tf.int32, minimum = 0, maximum = NUM_ACTIONS - 1\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36bd3b33-635a-4274-8b9e-7172696ebb2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(72,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_spec = {\n",
    "    'global': tf.TensorSpec([GLOBAL_DIM], tf.float32),\n",
    "    'per_arm': tf.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32) #excluding action dim here\n",
    "}\n",
    "observation_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a2da92-7db2-4f42-94a7-b7bad1c8fc42",
   "metadata": {},
   "source": [
    "### Action spec\n",
    "\n",
    "> The time_step_spec and action_spec are specifications for the input time step and the output action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5af42c7-18d7-480f-a7f3-d7da3f4840eb",
   "metadata": {},
   "source": [
    "```python\n",
    "    if (\n",
    "        not tensor_spec.is_bounded(action_spec)\n",
    "        or not tensor_spec.is_discrete(action_spec)\n",
    "        or action_spec.shape.rank > 1\n",
    "        or action_spec.shape.num_elements() != 1\n",
    "    ):\n",
    "      raise NotImplementedError(\n",
    "          'action_spec must be a BoundedTensorSpec of type int32 and shape (). '\n",
    "          'Found {}.'.format(action_spec)\n",
    "      )\n",
    "```\n",
    "\n",
    "* [src](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_base_policy.py#L97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "549a123c-349a-4103-b39a-4502f47d1e85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=[], \n",
    "    dtype=tf.int32,\n",
    "    minimum=tf.constant(0),            \n",
    "    maximum=NUM_ACTIONS-1, # n degrees of freedom and will dictate the expected mean reward spec shape\n",
    "    name=\"action_spec\"\n",
    ")\n",
    "\n",
    "action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36ee2635-d4e3-4468-886c-ae9c62e3c80d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_num_actions: 2\n",
      "predicted_rewards_mean: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n"
     ]
    }
   ],
   "source": [
    "expected_num_actions = action_spec.maximum - action_spec.minimum + 1\n",
    "print(f\"expected_num_actions: {expected_num_actions}\")\n",
    "\n",
    "predicted_rewards_mean = tensor_spec.TensorSpec([expected_num_actions])\n",
    "print(f\"predicted_rewards_mean: {predicted_rewards_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a51efce-9f1b-42d1-bec4-7b788e3fd7e0",
   "metadata": {},
   "source": [
    "### TimeStep spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95f05860-0fbf-4a5a-8273-9c81761e0ea5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'global': TensorSpec(shape=(72,), dtype=tf.float32, name=None),\n",
       "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec = ts.time_step_spec(\n",
    "    observation_spec = observation_spec, \n",
    "    # reward_spec = _reward_spec\n",
    ")\n",
    "time_step_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773b129a-6d19-4b3d-a2e7-e27070f57ac0",
   "metadata": {},
   "source": [
    "### Reward Spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b48e89aa-e010-4bd9-a7e0-ad62dd4c5949",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reward': TensorSpec(shape=(128,), dtype=tf.float32, name='reward')}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.specs import array_spec\n",
    "\n",
    "reward_spec = {\n",
    "    \"reward\": array_spec.ArraySpec(shape=[BATCH_SIZE], dtype=np.float32, name=\"reward\")\n",
    "}\n",
    "\n",
    "reward_tensor_spec = train_utils.from_spec(reward_spec)\n",
    "reward_tensor_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9181303-6565-45f5-a293-08d50420a805",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Inspect chosen arm features spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6b526a5-997c-4621-b21c-82c6ca1d6a70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(72,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90d3e03e-619e-4fa4-b817-f02b4cefd6b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(64,), dtype=tf.float32, name=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_arm_features_info = (\n",
    "  policy_utilities.create_chosen_arm_features_info_spec(\n",
    "      time_step_spec.observation,\n",
    "  )\n",
    ")\n",
    "chosen_arm_features_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc427092-beb7-4baf-a2e9-b8d10629182c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandit_policy_type = (\n",
    "    policy_utilities.BanditPolicyType.GREEDY\n",
    ")\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a4a2a33-c7d4-4d81-8082-80dfc3596741",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandit_policy_type = (\n",
    "    policy_utilities.create_bandit_policy_type_tensor_spec(shape=[1])\n",
    ")\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e7ac02b-18bd-4519-92fe-5541b1a8ddc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_spec = policy_utilities.PerArmPolicyInfo(\n",
    "  predicted_rewards_mean=predicted_rewards_mean,\n",
    "  bandit_policy_type=bandit_policy_type,\n",
    "  chosen_arm_features=chosen_arm_features_info,\n",
    ")\n",
    "info_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9c197-ae9b-461d-8956-f078b929ac12",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [4] The Agent\n",
    "\n",
    "**Note** that contextual bandits form a special case of RL, where the actions taken by the agent do not alter the state of the environment \n",
    "\n",
    "> “Contextual” refers to the fact that the agent chooses among a set of actions while having knowledge of the context (environment observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81d6e84-688e-48c5-aea1-77df031348c9",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Agent & Network defined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aadb01-eb5c-4870-ae14-9e66624ba594",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Agent types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d075e8a6-11a9-4346-8725-3653fba4bac4",
   "metadata": {},
   "source": [
    "> `AGENT_TYPE = ['LinUCB', 'LinTS', 'epsGreedy', 'NeuralLinUCB']`\n",
    "\n",
    "1. **LinearUCBAgent**: (`LinUCB`) - An agent implementing the Linear UCB bandit algorithm ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/lin_ucb_agent/LinearUCBAgent))\n",
    "\n",
    "2. **LinearThompsonSamplingAgent**: (`LinTS`) - Implements the Linear Thompson Sampling Agent from the [paper](https://arxiv.org/abs/1209.3352): *Thompson Sampling for Contextual Bandits with Linear Payoffs* ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/linear_thompson_sampling_agent/LinearThompsonSamplingAgent))\n",
    "\n",
    "3. **NeuralEpsilonGreedyAgent**: (`epsGreedy`) - A neural network based epsilon greedy agent ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_epsilon_greedy_agent/NeuralEpsilonGreedyAgent))\n",
    "\n",
    "4. **NeuralLinUCBAgent**: (`NeuralLinUCB`) - An agent implementing the LinUCB algorithm on top of a neural network ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_linucb_agent/NeuralLinUCBAgent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b8e88e-c8ea-4193-a911-0d974ef3b1a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Network types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f547087d-5fad-4521-a584-cb46ce52897d",
   "metadata": {},
   "source": [
    "Which network architecture to use for the `epsGreedy` or `NeuralLinUCB` agents\n",
    "\n",
    "```\n",
    "NETWORK_TYPE = ['commontower', 'dotproduct']\n",
    "```\n",
    "\n",
    "**GlobalAndArmCommonTowerNetwork:** (`commontower`)\n",
    "* This network takes the output of the global and per-arm networks, and leads them through a common network, that in turn outputs reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "> * `COMMON_LAYERS` - Iterable of ints. Specifies the layers of the common tower\n",
    "* The network produced by this function can be used either in `GreedyRewardPredictionPolicy`, or `NeuralLinUCBPolicy`\n",
    "> * In the former case, the network must have `output_dim=1`, it is going to be an instance of `QNetwork`, and used in the policy as a reward prediction network\n",
    "> * In the latter case, the network will be an encoding network with its output consumed by a reward layer or a `LinUCB` method. The specified `output_dim` will be the encoding dimension\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmCommonTowerNetwork)\n",
    "\n",
    "**GlobalAndArmDotProductNetwork:** (`dotproduct`)\n",
    "* This network calculates the **dot product** of the output of the global and per-arm networks and returns them as reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmDotProductNetwork)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3dc270-deb5-4e96-8276-74759a06c318",
   "metadata": {},
   "source": [
    "### Agent config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bbe29263-453d-405e-ac50-fee7f379f335",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\n",
      "\n",
      "time_step_spec:\n",
      "  TimeStep(\n",
      "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'observation': {'global': TensorSpec(shape=(72,), dtype=tf.float32, name=None),\n",
      "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n",
      "\n",
      "action_spec:\n",
      "  BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))\n",
      "\n",
      "observation_spec:\n",
      "  {'global': TensorSpec(shape=(72,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\")\n",
    "print(\"\\ntime_step_spec:\\n \", time_step_spec)\n",
    "print(\"\\naction_spec:\\n \", action_spec)\n",
    "print(\"\\nobservation_spec:\\n \", observation_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d817bf2-1fa6-4bae-af90-745fad996b96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arm_emb_size': 16,\n",
      " 'batch_size': 128,\n",
      " 'common_layers': [34, 8],\n",
      " 'encoding_dim': 8,\n",
      " 'epsilon': 0.01,\n",
      " 'eval_batch_size': 1,\n",
      " 'global_dim': 72,\n",
      " 'global_emb_size': 12,\n",
      " 'global_layers': [72, 36, 18],\n",
      " 'learning_rate': 0.05,\n",
      " 'model_type': 'NeuralLinUCB',\n",
      " 'network_type': 'commontower',\n",
      " 'num_actions': 2,\n",
      " 'num_oov_buckets': 1,\n",
      " 'per_arm_dim': 64,\n",
      " 'per_arm_layers': [64, 32, 16]}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Agents\n",
    "# ================================\n",
    "AGENT_TYPE      = 'NeuralLinUCB' # 'LinUCB' | 'LinTS |, 'epsGreedy' | 'NeuralLinUCB'\n",
    "\n",
    "# Parameters for linear agents (LinUCB and LinTS).\n",
    "AGENT_ALPHA     = 0.1\n",
    "\n",
    "# Parameters for neural agents (NeuralEpsGreedy and NerualLinUCB).\n",
    "EPSILON         = 0.01\n",
    "LR              = 0.05\n",
    "\n",
    "# Parameters for NeuralLinUCB\n",
    "ENCODING_DIM    = 1\n",
    "EPS_PHASE_STEPS = 1000\n",
    "\n",
    "# ================================\n",
    "# Agent's Preprocess Network\n",
    "# ================================\n",
    " # beginning should be of size: GLOBAL_DIM\n",
    "GLOBAL_LAYERS   = [GLOBAL_DIM, int(GLOBAL_DIM/2), int(GLOBAL_DIM/4)]\n",
    "\n",
    "# beginning should be of size: PER_ARM_DIM\n",
    "ARM_LAYERS      = [PER_ARM_DIM, int(PER_ARM_DIM/2), int(PER_ARM_DIM/4)]\n",
    "\n",
    "# ================================\n",
    "# common layers\n",
    "# ================================\n",
    "\"\"\"\n",
    "> layer sizes for the final tower\n",
    "> The network that takes as input the concatenation of \n",
    "  the outputs of the global and the arm networks\n",
    "> hidden layers ideally divisible by 8, e.g., [16, 32, 64, 128, 256, 512]\n",
    "\"\"\"\n",
    "FIRST_COMMON_LAYER = GLOBAL_LAYERS[-1] + ARM_LAYERS[-1] # min(GLOBAL_LAYERS[-1], ARM_LAYERS[-1])\n",
    "\n",
    "COMMON_LAYERS = [\n",
    "    int(FIRST_COMMON_LAYER),\n",
    "    # int(FIRST_COMMON_LAYER/2),\n",
    "    int(FIRST_COMMON_LAYER/4)\n",
    "]\n",
    "\n",
    "NETWORK_TYPE    = \"commontower\" # 'commontower' | 'dotproduct'\n",
    "\n",
    "if AGENT_TYPE == 'NeuralLinUCB':\n",
    "    NETWORK_TYPE = 'commontower'\n",
    "    ENCODING_DIM = COMMON_LAYERS[-1]\n",
    "    \n",
    "if NETWORK_TYPE == 'dotproduct':\n",
    "    assert GLOBAL_LAYERS[0] == ARM_LAYERS[0]\n",
    "\n",
    "\n",
    "HPARAMS = {  # TODO - streamline and consolidate\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"eval_batch_size\" : EVAL_BATCH_SIZE,\n",
    "    \"num_actions\": NUM_ACTIONS,\n",
    "    \"global_emb_size\": GLOBAL_EMBEDDING_SIZE,\n",
    "    \"arm_emb_size\": MV_EMBEDDING_SIZE,\n",
    "    \"global_dim\": GLOBAL_DIM,\n",
    "    \"per_arm_dim\": PER_ARM_DIM,\n",
    "    \"global_layers\": GLOBAL_LAYERS,\n",
    "    \"per_arm_layers\": ARM_LAYERS,\n",
    "    \"common_layers\": COMMON_LAYERS,\n",
    "    \"learning_rate\": LR,\n",
    "    \"epsilon\": EPSILON,\n",
    "    \"encoding_dim\": ENCODING_DIM,\n",
    "    \"num_oov_buckets\": NUM_OOV_BUCKETS,\n",
    "    \"model_type\": AGENT_TYPE,\n",
    "    \"network_type\": NETWORK_TYPE,\n",
    "}\n",
    "pprint(HPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2bf060bb-9880-40b4-8583-dd7a3f915bc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent: neural_linucb_agent\n",
      "Network: commontower\n"
     ]
    }
   ],
   "source": [
    "# from src.perarm_features import agent_factory as agent_factory\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "    agent_type = AGENT_TYPE,\n",
    "    network_type = NETWORK_TYPE,\n",
    "    time_step_spec = time_step_spec,\n",
    "    action_spec = action_spec,\n",
    "    observation_spec=observation_spec,\n",
    "    global_layers = GLOBAL_LAYERS,\n",
    "    arm_layers = ARM_LAYERS,\n",
    "    common_layers = COMMON_LAYERS,\n",
    "    agent_alpha = AGENT_ALPHA,\n",
    "    learning_rate = LR,\n",
    "    epsilon = EPSILON,\n",
    "    train_step_counter = global_step,\n",
    "    output_dim = ENCODING_DIM,\n",
    "    eps_phase_steps = EPS_PHASE_STEPS,\n",
    "    summarize_grads_and_vars = False,\n",
    "    debug_summaries = True\n",
    ")\n",
    "      \n",
    "agent.initialize()\n",
    "print(f'agent: {agent.name}')\n",
    "\n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {NETWORK_TYPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d77d1-a0b3-4898-adf0-0b32bfaf5bd7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Inspect the specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78ca56e7-a386-4bf4-8c2b-3d1665521f53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41483f5a-bda6-48a4-9e1c-88d8b4afeea9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(72,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.time_step_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f205716-f265-4ca8-81a7-4799de8f60a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(Trajectory(\n",
       "{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32)),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(72,), dtype=tf.float32, name=None)}),\n",
       " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=TensorSpec(shape=(2,), dtype=tf.float32, name=None), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None)),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.training_data_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d404dae-3cc3-4f81-962b-4641455ca4f2",
   "metadata": {},
   "source": [
    "# [5] Reward function\n",
    "\n",
    "> see `reward_factory.py`\n",
    "\n",
    "* Since we are training a policy with previously collected interaction data, we model the reward function from actual rewards\n",
    "* We will simply pass the `user_rating` (values 0-5) as rewards to the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df9aecd6-d20a-48a7-9ead-4da3bbcfdae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def _get_rewards(element):\n",
    "#     \"\"\"Calculates reward for the actions.\"\"\"\n",
    "\n",
    "#     def _calc_reward(x):\n",
    "#         \"\"\"\n",
    "#         Calculates reward for a single action.\n",
    "#         \"\"\"\n",
    "#         r0 = lambda: tf.constant(0.0)\n",
    "#         r1 = lambda: tf.constant(1.0)\n",
    "#         r2 = lambda: tf.constant(2.0)\n",
    "#         r3 = lambda: tf.constant(3.0)\n",
    "#         r4 = lambda: tf.constant(4.0)\n",
    "#         r5 = lambda: tf.constant(5.0)\n",
    "        \n",
    "#         c1 = tf.equal(x, 1.0)\n",
    "#         c2 = tf.equal(x, 2.0)\n",
    "#         c3 = tf.equal(x, 3.0)\n",
    "#         c4 = tf.equal(x, 4.0)\n",
    "#         c5 = tf.equal(x, 5.0)\n",
    "#         return tf.case(\n",
    "#             [(c1, r1), (c2, r2), (c3, r3),(c4, r4),(c5, r5)], \n",
    "#             default=r0, exclusive=True\n",
    "#         )\n",
    "\n",
    "#     return tf.map_fn(\n",
    "#         fn=_calc_reward, \n",
    "#         # elems=element['user_rating'],\n",
    "#         elems=element[data_utils.TARGET_FEATURE_NAME],\n",
    "#         dtype=tf.float32\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac59703a-9a00-4eba-a3b7-45b21b738dd4",
   "metadata": {},
   "source": [
    "# [6] Trajectory function\n",
    "\n",
    "> This function will convert training samples from the TF Records to `trajectories` which the Agent interprets as training records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3605d9f-d239-4871-9a61-6e9b21f9c2a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _trajectory_fn(element): # hparams\n",
    "    \n",
    "    \"\"\"Converts a dataset element into a trajectory.\"\"\"\n",
    "    global_features = embs._get_global_context_features(element)\n",
    "    arm_features = embs._get_per_arm_features(element)\n",
    "\n",
    "    # Adds a time dimension.\n",
    "    arm_features = train_utils._add_outer_dimension(arm_features)\n",
    "\n",
    "    # obs spec\n",
    "    observation = {\n",
    "        bandit_spec_utils.GLOBAL_FEATURE_KEY:\n",
    "            train_utils._add_outer_dimension(global_features),\n",
    "    }\n",
    "\n",
    "    reward = train_utils._add_outer_dimension(reward_factory._get_rewards(element))\n",
    "\n",
    "    # To emit the predicted rewards in policy_info, we need to create dummy\n",
    "    # rewards to match the definition in TensorSpec for the ones specified in\n",
    "    # emit_policy_info set.\n",
    "    dummy_rewards = tf.zeros([HPARAMS['batch_size'], 1, HPARAMS['num_actions']])\n",
    "    policy_info = policy_utilities.PerArmPolicyInfo(\n",
    "        chosen_arm_features=arm_features,\n",
    "        # Pass dummy mean rewards here to match the model_spec for emitting\n",
    "        # mean rewards in policy info\n",
    "        predicted_rewards_mean=dummy_rewards,\n",
    "        bandit_policy_type=tf.zeros([HPARAMS['batch_size'], 1, 1], dtype=tf.int32)\n",
    "    )\n",
    "    \n",
    "    if HPARAMS['model_type'] == 'NeuralLinUCB':\n",
    "        policy_info = policy_info._replace(\n",
    "            predicted_rewards_optimistic=dummy_rewards\n",
    "        )\n",
    "        \n",
    "    return trajectory.single_step(\n",
    "        observation=observation,\n",
    "        action=tf.zeros_like(\n",
    "            reward, dtype=tf.int32\n",
    "        ),  # Arm features are copied from policy info, put dummy zeros here\n",
    "        policy_info=policy_info,\n",
    "        reward=reward,\n",
    "        discount=tf.zeros_like(reward)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a0989c-5a06-4fd5-a12d-d92dbbe71a76",
   "metadata": {},
   "source": [
    "Inspect the trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "257791d1-c97c-48c0-bc92-f5a4737b6c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.action.shape      : (128, 1)\n",
      "test_traj.discount.shape    : (128, 1)\n",
      "test_traj.reward.shape      : (128, 1)\n",
      "test_traj.observation.shape : (128, 1, 72)\n"
     ]
    }
   ],
   "source": [
    "for x in train_dataset.batch(HPARAMS['batch_size']).take(2):\n",
    "    test_traj = _trajectory_fn(x)\n",
    "    \n",
    "print(f\"test_traj.action.shape      : {test_traj.action.shape}\") \n",
    "print(f\"test_traj.discount.shape    : {test_traj.discount.shape}\")\n",
    "print(f\"test_traj.reward.shape      : {test_traj.reward.shape}\")\n",
    "print(f\"test_traj.observation.shape : {test_traj.observation['global'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3dace3d1-ce61-48cf-82a4-f701d3fe337c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_traj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5490435-779f-40b3-80ae-5f2646c7cdb8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tmp debugging - START\n",
    "\n",
    "see [src](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/agents/examples/v2/trainer.py#L107C7-L107C44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da5dfcfe-2c35-4926-b910-c68c35a6508a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_expected_shape(experience, num_steps):\n",
    "  \"\"\"Sets expected shape.\"\"\"\n",
    "\n",
    "  def set_time_dim(input_tensor, steps):\n",
    "    tensor_shape = input_tensor.shape.as_list()\n",
    "    if len(tensor_shape) < 2:\n",
    "      raise ValueError(\n",
    "          'input_tensor is expected to be of rank-2, but found otherwise: '\n",
    "          f'input_tensor={input_tensor}, tensor_shape={tensor_shape}'\n",
    "      )\n",
    "    tensor_shape[1] = steps\n",
    "    input_tensor.set_shape(tensor_shape)\n",
    "\n",
    "  tf.nest.map_structure(lambda t: set_time_dim(t, num_steps), experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "323e240b-08e3-4c85-9d2a-f5b95fdbd472",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "STEPS_TEST = 1\n",
    "\n",
    "testy = set_expected_shape(\n",
    "    experience=test_traj, \n",
    "    num_steps=STEPS_TEST\n",
    ")\n",
    "\n",
    "testy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374a350c-7a32-4b11-9f3b-4e1019eaf01a",
   "metadata": {},
   "source": [
    "#### tmp debugging - END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcbfc9a-049e-49b9-b2a3-ecb9fd4b9964",
   "metadata": {},
   "source": [
    "# [7] Training the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13adc1ef-b50e-41a3-9b95-c128d0c55a2b",
   "metadata": {},
   "source": [
    "## set Vertex Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "180c03a0-b6b1-4ef0-ae5e-90c04159b584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EXP_VERSION=\"v15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e861fb27-df24-4821-8448-cf1346b186f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : 02a-perarm-bandit-v15\n",
      "RUN_NAME          : run-20241209-183419\n",
      "\n",
      "CHECKPT_DIR       : gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v15/chkpoint\n",
      "BASE_OUTPUT_DIR   : gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v15/run-20241209-183419\n",
      "LOG_DIR           : gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v15/run-20241209-183419/logs\n",
      "ROOT_DIR          : gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v15/run-20241209-183419/root\n",
      "ARTIFACTS_DIR     : gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v15/run-20241209-183419/artifacts\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME   = f'02a-perarm-bandit-{EXP_VERSION}'\n",
    "\n",
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "CHECKPT_DIR       = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/chkpoint\"\n",
    "BASE_OUTPUT_DIR   = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}\"\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"CHECKPT_DIR       : {CHECKPT_DIR}\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b3d3c-75f7-46f4-9a1b-6329e419b7f5",
   "metadata": {},
   "source": [
    "## train loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bb7ffc-00df-4d46-857b-86c87b78f597",
   "metadata": {},
   "source": [
    "`agent.train(experience=...)`\n",
    "\n",
    "where `experience` is a batch of trajectories data in the form of a Trajectory. \n",
    "* The structure of experience must match that of `self.training_data_spec`. \n",
    "* All tensors in experience must be shaped [batch, time, ...] where time must be equal to self.train_step_length if that property is not None.\n",
    "\n",
    "**eval loop**\n",
    "\n",
    "> When evaluating an epsilon-greedy bandit, we need to remove those predictions that come from the `uniform_random` policy. We only want the predictions from the `GREEDY` policy, becasue we want to know how the model performs when it is actually used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94d6d45-c71e-4fe4-9af8-af9a8bda4e4f",
   "metadata": {},
   "source": [
    "### logs & checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "049ee49b-3b1a-4b12-a360-15e759dff7ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics: [<tf_agents.metrics.tf_metrics.AverageReturnMetric object at 0x7f96b03ca0e0>]\n",
      "setting checkpoint_manager: gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v15/chkpoint\n",
      "\n",
      "train step : 0\n",
      "\n",
      "saver signatures:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'action': <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x7f96b03fb970>,\n",
       " 'get_initial_state': <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x7f96b03fa8f0>,\n",
       " 'get_train_step': <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x7f96b03fa830>,\n",
       " 'get_metadata': <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x7f96b03f8160>}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    f\"{LOG_DIR}\", flush_millis=10 * 1000\n",
    ")\n",
    "\n",
    "train_summary_writer.set_as_default()\n",
    "# ====================================================\n",
    "# metrics\n",
    "# ====================================================\n",
    "step_metric = tf_metrics.EnvironmentSteps()\n",
    "metrics = [\n",
    "    # tf_metrics.NumberOfEpisodes(),\n",
    "    # tf_metrics.AverageEpisodeLengthMetric(batch_size=HPARAMS['batch_size']),\n",
    "    tf_metrics.AverageReturnMetric(batch_size=HPARAMS['batch_size'])\n",
    "]\n",
    "\n",
    "print(f\"metrics: {metrics}\")\n",
    "\n",
    "# ====================================================\n",
    "# get checkpoint manager\n",
    "# ====================================================\n",
    "print(f\"setting checkpoint_manager: {CHECKPT_DIR}\\n\")\n",
    "\n",
    "checkpoint_manager = train_utils.restore_and_get_checkpoint_manager(\n",
    "    root_dir=CHECKPT_DIR, \n",
    "    agent=agent, \n",
    "    metrics=metrics, \n",
    "    step_metric=step_metric\n",
    ")\n",
    "print(f\"train step : {agent.train_step_counter.numpy()}\")\n",
    "# ====================================================\n",
    "# policy saver\n",
    "# ====================================================\n",
    "saver = policy_saver.PolicySaver(\n",
    "    agent.policy, \n",
    "    train_step=global_step\n",
    ")\n",
    "print(f\"\\nsaver signatures:\")\n",
    "saver.signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83683f4b-8a1a-44b9-8d5f-7ee3304c794c",
   "metadata": {},
   "source": [
    "### config\n",
    "\n",
    "* calculate train & val dataset sizes\n",
    "* define logging and chkpt intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9432613-6583-4828-8a2a-dd939adbc3c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_TRAIN_STEPS : 50\n",
      "NUM_EVAL_STEPS  : 1000\n",
      "CHKPT_INTERVAL  : 50\n",
      "LOG_INTERVAL    : 10\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAIN_STEPS = 50\n",
    "NUM_EVAL_STEPS  = 1_000\n",
    "CHKPT_INTERVAL  = NUM_TRAIN_STEPS # // 5\n",
    "LOG_INTERVAL    = 10\n",
    "\n",
    "print(f\"NUM_TRAIN_STEPS : {NUM_TRAIN_STEPS}\")\n",
    "print(f\"NUM_EVAL_STEPS  : {NUM_EVAL_STEPS}\")\n",
    "print(f\"CHKPT_INTERVAL  : {CHKPT_INTERVAL}\")\n",
    "print(f\"LOG_INTERVAL    : {LOG_INTERVAL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "379ffc65-4eec-4af1-8fd4-912ef65a9808",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embs = emb_features.EmbeddingModel(\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = HPARAMS[\"num_oov_buckets\"],\n",
    "    global_emb_size = HPARAMS[\"global_emb_size\"],\n",
    "    mv_emb_size = HPARAMS[\"arm_emb_size\"],\n",
    "    max_genre_length = data_config.MAX_GENRE_LENGTH\n",
    ")\n",
    "\n",
    "process_example_fn = functools.partial(\n",
    "    train_utils.example_proto_to_trajectory,\n",
    ")\n",
    "process_trajectory_fn = functools.partial(\n",
    "    train_utils._trajectory_fn,\n",
    "    hparams=HPARAMS,\n",
    "    embs=embs\n",
    ")\n",
    "\n",
    "train_dataset = train_utils.create_tfrecord_ds(\n",
    "    tf.io.gfile.glob(train_files),\n",
    "    # num_shards = 10,\n",
    "    process_example_fn=process_example_fn,\n",
    "    process_trajectory_fn=process_trajectory_fn,\n",
    "    batch_size=HPARAMS['batch_size'],\n",
    "    repeat = True,\n",
    "    drop_remainder = False\n",
    ")\n",
    "train_dataset_iterator = iter(train_dataset)\n",
    "\n",
    "eval_ds = tf.data.TFRecordDataset(val_files)\n",
    "eval_ds = eval_ds.map(\n",
    "    data_utils._parse_function, \n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ").batch(HPARAMS[\"eval_batch_size\"])\n",
    "\n",
    "if NUM_EVAL_STEPS > 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e498d7e3-d166-4e1d-94a5-f721de58694a",
   "metadata": {},
   "source": [
    "### run train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "da4680f3-693b-4530-8e4d-88bc43036c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating pre-trained Agent...\n",
      "pre-train val_loss     : 13.573118209838867\n",
      "pre-train eval runtime : 0\n",
      "starting train loop...\n",
      "step = 0: train loss = 13.609999656677246\n",
      "step = 10: train loss = 15.34000015258789\n",
      "step = 20: train loss = 14.510000228881836\n",
      "step = 30: train loss = 12.210000038146973\n",
      "step = 40: train loss = 4.190000057220459\n",
      "train runtime_mins: 0\n",
      "saved to checkpoint_manager: gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v15/chkpoint\n",
      "saved trained policy to: gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v15/run-20241209-183419/artifacts\n",
      "evaluating trained Agent...\n",
      "post-train val_loss     : 3.00793719291687\n",
      "post-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "# agent.train = common.function(agent.train)\n",
    "\n",
    "list_o_loss = []\n",
    "\n",
    "# ====================================================\n",
    "# Evaluate the agent's policy once before training\n",
    "# ====================================================\n",
    "pre_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "\n",
    "print(f\"evaluating pre-trained Agent...\")\n",
    "start_time = time.time()\n",
    "\n",
    "pre_val_loss, pre_preds, pre_tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = pre_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    embs = embs,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"pre-train val_loss     : {pre_val_loss}\")\n",
    "print(f\"pre-train eval runtime : {runtime_mins}\")\n",
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "print(f\"starting train loop...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(NUM_TRAIN_STEPS):\n",
    "    \n",
    "    trajectories = next(train_dataset_iterator)\n",
    "\n",
    "    # All tensors in experience must be shaped [batch, time, ...] \n",
    "    step = agent.train_step_counter.numpy()\n",
    "    loss = agent.train(experience=trajectories)\n",
    "    list_o_loss.append(loss.loss.numpy())\n",
    "\n",
    "    train_utils._export_metrics_and_summaries(\n",
    "        step=i, \n",
    "        metrics=metrics\n",
    "    )\n",
    "\n",
    "    # print step loss\n",
    "    if step % LOG_INTERVAL == 0:\n",
    "        print(\n",
    "            'step = {0}: train loss = {1}'.format(\n",
    "                step, round(loss.loss.numpy(), 2)\n",
    "            )\n",
    "        )\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"train runtime_mins: {runtime_mins}\")\n",
    "checkpoint_manager.save(global_step)\n",
    "print(f\"saved to checkpoint_manager: {CHECKPT_DIR}\")\n",
    "saver.save(ARTIFACTS_DIR)\n",
    "print(f\"saved trained policy to: {ARTIFACTS_DIR}\")\n",
    "\n",
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = post_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    embs = embs,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6008a6fa-748f-4d1e-8d01-c9c4d1b93ce3",
   "metadata": {},
   "source": [
    "#### Inspect Saver and Checkpointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b0bd92b-6170-4eca-b387-15dca4310dd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v15/run-20241209-183419/artifacts/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v15/run-20241209-183419/artifacts/fingerprint.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v15/run-20241209-183419/artifacts/policy_specs.pbtxt\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v15/run-20241209-183419/artifacts/saved_model.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v15/run-20241209-183419/artifacts/assets/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v15/run-20241209-183419/artifacts/variables/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $ARTIFACTS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6bb79cc5-4dd9-4cfb-aed6-b33037a535fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v15/chkpoint/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v15/chkpoint/checkpoint\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v15/chkpoint/ckpt-50.data-00000-of-00001\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v15/chkpoint/ckpt-50.index\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $CHECKPT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb1ed8-f67b-4e7b-9cbc-70edd50e49ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate train job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "41937f9a-6c28-48d2-bc7c-bfe4372c7cd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAGdCAYAAAD0e7I1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA90ElEQVR4nO3de3xU1b3///fMJDO5Tm6QGwREUC4iSEFjxFoUBMF6OdJz1NJKezzyqyfYKh4v9Nt66znF2v5ai1JtT/uT9vuTarVH+UpbKgLGWgERpXJRBAwGgSRASCbXSTKzv38kszMDSUgml8meeT0fj3lksveeyZoNmjdrfdZaNsMwDAEAAEQpe6QbAAAAMJAIOwAAIKoRdgAAQFQj7AAAgKhG2AEAAFGNsAMAAKIaYQcAAEQ1wg4AAIhqcZFuwFDg9/t19OhRpaamymazRbo5AACgBwzDUG1trfLz82W3d91/Q9iRdPToURUUFES6GQAAIAyHDx/WyJEjuzxP2JGUmpoqqe1mud3uCLcGAAD0hMfjUUFBgfl7vCuEHckcunK73YQdAAAs5mwlKBQoAwCAqEbYAQAAUY2wAwAAohphBwAARDXCDgAAiGqEHQAAENUIOwAAIKoRdgAAQFQj7AAAgKhG2AEAAFGNsAMAAKIaYQcAAEQ1wk6UMAxDv33nkN4vOxXppgAAMKQQdqLE7iMePfx/9uh7r+yOdFMAABhSCDtRorqxWZJU09gS4ZYAADC0EHaiRHOrX5Lkbf8KAADaEHaiRCDsNLf6ItwSAACGFsJOlGj2+UO+AgCANoSdKOE1e3YIOwAABCPsRIlAyPEbUiu9OwAAmAg7USK4R4ehLAAAOhB2okRwwPG2EHYAAAgg7ESJ4IBDzw4AAB0iGnZWrFihiy++WKmpqcrOztaNN96offv2hVwza9Ys2Wy2kMe3vvWtkGvKysp07bXXKikpSdnZ2brvvvvU2to6mB8l4pp9HVPOKVIGAKBDXCR/eElJiYqLi3XxxRertbVV3/3udzV37lzt3btXycnJ5nV33HGHHnvsMfP7pKQk87nP59O1116r3NxcvfPOOzp27Jhuu+02xcfH64c//OGgfp5ICg44LCwIAECHiIad9evXh3y/evVqZWdna8eOHbriiivM40lJScrNze30PV5//XXt3btXb7zxhnJycnTRRRfpBz/4gR544AE98sgjcjqdA/oZhoqQAmXCDgAApiFVs1NTUyNJyszMDDn+/PPPa9iwYZo8ebKWL1+uhoYG89yWLVt04YUXKicnxzw2b948eTwe7dmzp9Of4/V65fF4Qh5WF1ynQ80OAAAdItqzE8zv9+vuu+/WzJkzNXnyZPP4V7/6VY0ePVr5+fn68MMP9cADD2jfvn36n//5H0lSeXl5SNCRZH5fXl7e6c9asWKFHn300QH6JJERPHTlbWHLCAAAAoZM2CkuLtbu3bv19ttvhxxfsmSJ+fzCCy9UXl6eZs+erYMHD2rs2LFh/azly5dr2bJl5vcej0cFBQXhNXyIYJ0dAAA6NySGsZYuXap169Zp8+bNGjlyZLfXFhYWSpIOHDggScrNzVVFRUXINYHvu6rzcblccrvdIQ+ro2YHAIDORTTsGIahpUuX6pVXXtGmTZs0ZsyYs75m586dkqS8vDxJUlFRkXbt2qXKykrzmg0bNsjtdmvSpEkD0u6hKKRmh7ADAIAposNYxcXFWrNmjdauXavU1FSzxiYtLU2JiYk6ePCg1qxZowULFigrK0sffvih7rnnHl1xxRWaMmWKJGnu3LmaNGmSvv71r+uJJ55QeXm5vve976m4uFgulyuSH29QMYwFAEDnItqz88wzz6impkazZs1SXl6e+XjxxRclSU6nU2+88Ybmzp2rCRMm6N5779XChQv12muvme/hcDi0bt06ORwOFRUV6Wtf+5puu+22kHV5YgHr7AAA0LmI9uwYhtHt+YKCApWUlJz1fUaPHq0///nP/dUsSwrZG4uwAwCAaUgUKKPvKFAGAKBzhJ0oQdgBAKBzhJ0o4SXsAADQKcJOlAjdLoIVlAEACCDsRAmGsQAA6BxhJ0ow9RwAgM4RdqIEKygDANA5wk4U8PkN+fwdaxYRdgAA6EDYiQKnhxsv20UAAGAi7ESB08MOPTsAAHQg7EQB72lTzQk7AAB0IOxEgTOGsVpZZwcAgADCThRgGAsAgK4RdqJA82kFyad/DwBALCPsRAF6dgAA6BphJwoQdgAA6BphJwoQdgAA6BphJwoEFhGMs9skUbMDAEAwwk4UCPTkpCbESZK8LYQdAAACCDtRIBB2UgJhh54dAABMhJ0oYIYdV7z5vWEY3b0EAICYQdiJAoEancAwliS1+Ag7AABIhJ2oYNbsuDrCDkXKAAC0IexEgUDYSQ4OO0w/BwBAEmEnKgR6cRLi7eb0czYDBQCgDWEnCnjbe3GccXY549r+SOnZAQCgDWEnCgSCjdPhkIuwAwBACMJOFGjupGfHS9gBAEASYScqNPva6nNChrGYjQUAgCTCTlQI9Oy44uxyOhjGAgAgGGEnCnTU7NjljHNIYhgLAIAAwk4UCAxZMRsLAIAzEXaiQHCBsothLAAAQhB2ooA3aBjLFR8oUGZRQQAAJMJOVAiZek7PDgAAIQg7UYCaHQAAukbYiQIsKggAQNcIO1HAXGfH0TGMRdgBAKANYScKMIwFAEDXCDtRIGTqefuigmwXAQBAG8JOFOisZoeeHQAA2hB2ooA3ZLsIwg4AAMEIO1EgdBgrUKDMooIAAEiEHcszDCO0QJlFBQEACEHYsbjgQmRXnKNjGIsCZQAAJBF2LC+4B8cVNIxFzw4AAG0IOxYXHGqCC5RZVBAAgDaEHYsLDFfF2W2y223MxgIA4DSEHYsLnoklie0iAAA4DWHH4s4IO/TsAAAQgrBjccELCkpiNhYAAKch7Fhc8Bo7kjr2xqJnBwAASYQdyzt9GIup5wAAhCLsWFwzw1gAAHQromFnxYoVuvjii5Wamqrs7GzdeOON2rdvX8g1TU1NKi4uVlZWllJSUrRw4UJVVFSEXFNWVqZrr71WSUlJys7O1n333afW1tbB/CgREwg7rtNnY7WwNxYAAFKEw05JSYmKi4u1detWbdiwQS0tLZo7d67q6+vNa+655x699tpreumll1RSUqKjR4/qpptuMs/7fD5de+21am5u1jvvvKPf/va3Wr16tR566KFIfKRBd3rNDj07AACEiovkD1+/fn3I96tXr1Z2drZ27NihK664QjU1NfrNb36jNWvW6KqrrpIkPffcc5o4caK2bt2qSy+9VK+//rr27t2rN954Qzk5Obrooov0gx/8QA888IAeeeQROZ3OSHy0QdPV1PMWnyG/35DdbotY2wAAGAqGVM1OTU2NJCkzM1OStGPHDrW0tGjOnDnmNRMmTNCoUaO0ZcsWSdKWLVt04YUXKicnx7xm3rx58ng82rNnT6c/x+v1yuPxhDys6vSancBwlkTvDgAA0hAKO36/X3fffbdmzpypyZMnS5LKy8vldDqVnp4ecm1OTo7Ky8vNa4KDTuB84FxnVqxYobS0NPNRUFDQz59m8Hi7GMaSCDsAAEhDKOwUFxdr9+7deuGFFwb8Zy1fvlw1NTXm4/DhwwP+MwdKxzBW2/o6gR6e4HMAAMSyiNbsBCxdulTr1q3TW2+9pZEjR5rHc3Nz1dzcrOrq6pDenYqKCuXm5prXvPvuuyHvF5itFbjmdC6XSy6Xq58/RWScPoxls9nkdNjV7POzPxYAAIpwz45hGFq6dKleeeUVbdq0SWPGjAk5P336dMXHx2vjxo3msX379qmsrExFRUWSpKKiIu3atUuVlZXmNRs2bJDb7dakSZMG54NE0OkFysHP6dkBACDCPTvFxcVas2aN1q5dq9TUVLPGJi0tTYmJiUpLS9Ptt9+uZcuWKTMzU263W3fddZeKiop06aWXSpLmzp2rSZMm6etf/7qeeOIJlZeX63vf+56Ki4ujpvemO82+tvV0XKeHHS9hBwAAKcJh55lnnpEkzZo1K+T4c889p2984xuSpJ/97Gey2+1auHChvF6v5s2bp1/84hfmtQ6HQ+vWrdOdd96poqIiJScna/HixXrssccG62NEVGc9O2wZAQBAh4iGHcMwznpNQkKCVq1apVWrVnV5zejRo/XnP/+5P5tmGafX7EjBCwuyijIAAENmNhbCc/oKylLQlhH07AAAQNixOm83BcqEHQAACDuW1+0wFmEHAADCjtV1OvXcQdgBACCAsGNxndXsuOLbVlMm7AAAQNixvECgcXXWs8PeWAAAEHasrrOaHdbZAQCgA2HH4jqdek7YAQDARNixuO4KlL2tLCoIAABhx+KYeg4AQPcIOxbX2aKCgZodLwXKAAAQdqyOmh0AALpH2LG4TqeeE3YAADARdiyuo2bHYR4j7AAA0IGwY3Hseg4AQPcIOxbm8xvy+Q1JnRco07MDAABhx9KCw0ynBcrMxgIAgLBjZSFhJ2S7CDYCBQAggLBjYV5fxwrJ8Q6b+ZwCZQAAOhB2LCx4qwibLSjsOFhUEACAAMKOhZlr7DhC/xgDPTveFvbGAgCAsGNhnU07D/6eAmUAAAg7ltbZjufB31OzAwAAYcfSugo7rLMDAEAHwo6FdWwV0UXYYRgLAADCjpV5u6rZcbDODgAAAYQdC+tsx3MpaDYWYQcAAMKOlZ2tQDl47ywAAGIVYcfCOsKOI+R4cPhhKAsAEOsIOxZmrrPTRYGyRNgBAICwY2GBFZJPr9mJs9sU2D0ieP8sAABiEWHHwrpaQdlms5m9PfTsAABiHWHHwrpaZ0diRhYAAAGEHQvrajaWxCrKAAAEEHYsrKtFBSUxjAUAQDvCjoV127MT376KMltGAABiHGHHwrqt2aFnBwAASYQdS+uuZ8dJzQ4AAJIIO5YWGKI6fZ0dKXg2FuvsAABiG2HHwrrt2XEw9RwAAImwY2k9WWeHYSwAQKwj7FhYVysoS0Hr7DAbCwAQ4wg7FualQBkAgLMi7FgYw1gAAJwdYcfCerJdBAXKAIBYR9ixsO5qdlhUEACANoQdCwsEme7W2aFAGQAQ6wg7FtZRs+M445wrzhFyDQAAsYqwY2HdDmNRswMAgCTCjqWxNxYAAGdH2LGwnm0Xwd5YAIDYRtixKMMwOoaxWGcHAIAuEXYsKniWVbfDWMzGAgDEOMKORQX32HQ29dxFzw4AAJIiHHbeeustXXfddcrPz5fNZtOrr74acv4b3/iGbDZbyOOaa64JuaaqqkqLFi2S2+1Wenq6br/9dtXV1Q3ip4iM4BDT2TAWYQcAgDYRDTv19fWaOnWqVq1a1eU111xzjY4dO2Y+fv/734ecX7Rokfbs2aMNGzZo3bp1euutt7RkyZKBbnrEBYan4uw22e22M84zjAUAQJu4SP7w+fPna/78+d1e43K5lJub2+m5jz76SOvXr9f27ds1Y8YMSdJTTz2lBQsW6Cc/+Yny8/P7vc1DRXczsaSOhQa9LYQdAEBsG/I1O2+++aays7M1fvx43XnnnTp58qR5bsuWLUpPTzeDjiTNmTNHdrtd27Zt6/I9vV6vPB5PyMNqzhp26NkBAEDSEA8711xzjX73u99p48aN+tGPfqSSkhLNnz9fPl/b2jHl5eXKzs4OeU1cXJwyMzNVXl7e5fuuWLFCaWlp5qOgoGBAP8dA8LZ2Pe1cYuo5AAABER3GOptbbrnFfH7hhRdqypQpGjt2rN58803Nnj077Pddvny5li1bZn7v8XgsF3i62ypC6ihQZrsIAECsG9I9O6c799xzNWzYMB04cECSlJubq8rKypBrWltbVVVV1WWdj9RWB+R2u0MeVtPjYSxWUAYAxDhLhZ3PP/9cJ0+eVF5eniSpqKhI1dXV2rFjh3nNpk2b5Pf7VVhYGKlmDormsw1jOajZAQBAivAwVl1dndlLI0mlpaXauXOnMjMzlZmZqUcffVQLFy5Ubm6uDh48qPvvv1/jxo3TvHnzJEkTJ07UNddcozvuuEPPPvusWlpatHTpUt1yyy1RPRNL6gg7nS0oGHy8udUvwzBks505PR0AgFgQ0Z6d9957T9OmTdO0adMkScuWLdO0adP00EMPyeFw6MMPP9T111+v888/X7fffrumT5+uv/3tb3K5XOZ7PP/885owYYJmz56tBQsW6PLLL9evfvWrSH2kQXO2mp3Acb8htfqNQWsXAABDTUR7dmbNmiXD6PoX8V//+tezvkdmZqbWrFnTn82yhJ7W7ASuje9iuAsAgGjHb0CL6mnNTvC1AADEIsKORXnPMowV57DL0b6NBEXKAIBYRtixqI5hLEeX15gzsujZAQDEMMKORZ1tGEvq6PVhYUEAQCwj7FjU2QqUg895WVgQABDDCDsW1dy+P1hX6+xIDGMBACARdiyrJz07LjYDBQCAsGNVZ1tBWQraH4vZWACAGBZW2Pntb3+rP/3pT+b3999/v9LT03XZZZfps88+67fGoWvmCsrdFCjTswMAQJhh54c//KESExMlSVu2bNGqVav0xBNPaNiwYbrnnnv6tYHonLcXBcqEHQBALAtru4jDhw9r3LhxkqRXX31VCxcu1JIlSzRz5kzNmjWrP9uHLvRuNhZhBwAQu8Lq2UlJSdHJkyclSa+//rquvvpqSVJCQoIaGxv7r3XoUo/CDrOxAAAIr2fn6quv1r/9279p2rRp+uSTT7RgwQJJ0p49e3TOOef0Z/vQhZ7U7Jg9OxQoAwBiWFg9O6tWrVJRUZGOHz+uP/7xj8rKypIk7dixQ7feemu/NhCd69nUc0fItQAAxKKwenbS09P19NNPn3H80Ucf7XOD0DO9mnpO2AEAxLCwenbWr1+vt99+2/x+1apVuuiii/TVr35Vp06d6rfGoWvNZ9n1PPgcYQcAEMvCCjv33XefPB6PJGnXrl269957tWDBApWWlmrZsmX92kB0rmMj0LPves7eWACAWBbWMFZpaakmTZokSfrjH/+oL3/5y/rhD3+o999/3yxWxsBiuwgAAHomrJ4dp9OphoYGSdIbb7yhuXPnSpIyMzPNHh8MrF4tKshsLABADAurZ+fyyy/XsmXLNHPmTL377rt68cUXJUmffPKJRo4c2a8NROfMsMN2EQAAdCusnp2nn35acXFxevnll/XMM89oxIgRkqS//OUvuuaaa/q1gehcc3sdDgXKAAB0L6yenVGjRmndunVnHP/Zz37W5wahZwJDU91OPXewqCAAAGGFHUny+Xx69dVX9dFHH0mSLrjgAl1//fVydDM7CP2nZ3tjtf1ZeFsIOwCA2BVW2Dlw4IAWLFigI0eOaPz48ZKkFStWqKCgQH/60580duzYfm0kQrX6/PIbbc97sl0EBcoAgFgWVs3Ot7/9bY0dO1aHDx/W+++/r/fff19lZWUaM2aMvv3tb/d3G3Ga4PDSs5od1tkBAMSusHp2SkpKtHXrVmVmZprHsrKy9Pjjj2vmzJn91jh0LrjgmHV2AADoXlg9Oy6XS7W1tWccr6urk9Pp7HOj0L1AeLHZpDi7rcvrGMYCACDMsPPlL39ZS5Ys0bZt22QYhgzD0NatW/Wtb31L119/fX+3EacJXmPHZus67Lgc9OwAABBW2Fm5cqXGjh2roqIiJSQkKCEhQZdddpnGjRunJ598sp+biNP1ZBPQ4PNewg4AIIaFVbOTnp6utWvX6sCBA+bU84kTJ2rcuHH92jh0LtBT090aOxKLCgIAIPUi7JxtN/PNmzebz3/605+G3yKcVXMPtoqQCDsAAEi9CDsffPBBj67rroYE/aOnw1iu9kUFCTsAgFjW47AT3HODyOrJ6snB59kuAgAQy8IqUEZk9TjsBM3GMgxjwNsFAMBQRNixIG8va3Yk1toBAMQuwo4F9bxmJyjsULcDAIhRhB0L6hjG6n6H+eCeH8IOACBWEXYsqKdTz+12m+IdbbPjGMYCAMQqwo4FBXYxP9uiglJokTIAALGIsGNBPa3ZCb6GsAMAiFWEHQvq6TCWxP5YAAAQdiyop+vsBF9D2AEAxCrCjgV5ezOMRc0OACDGEXYsqDc9O+b+WMzGAgDEKMKOBYVTs0PPDgAgVhF2LCicmh3CDgAgVhF2LCgwJNWTdXZcZoGyb0DbBADAUEXYsaBe9exQoAwAiHGEHQsKq2aHAmUAQIwi7FgQKygDANBzhB0L8vZq6jmLCgIAYhthx4KYeg4AQM8RdiyodwXKLCoIAIhtEQ07b731lq677jrl5+fLZrPp1VdfDTlvGIYeeugh5eXlKTExUXPmzNH+/ftDrqmqqtKiRYvkdruVnp6u22+/XXV1dYP4KQZfx9Rzx1mvNffGaiHsAABiU0TDTn19vaZOnapVq1Z1ev6JJ57QypUr9eyzz2rbtm1KTk7WvHnz1NTUZF6zaNEi7dmzRxs2bNC6dev01ltvacmSJYP1ESIirEUFfayzAwCITXGR/OHz58/X/PnzOz1nGIaefPJJfe9739MNN9wgSfrd736nnJwcvfrqq7rlllv00Ucfaf369dq+fbtmzJghSXrqqae0YMEC/eQnP1F+fv6gfZbBFAg7vVlUkJodAECsGrI1O6WlpSovL9ecOXPMY2lpaSosLNSWLVskSVu2bFF6eroZdCRpzpw5stvt2rZt26C3ebD0Zuo5YQcAEOsi2rPTnfLycklSTk5OyPGcnBzzXHl5ubKzs0POx8XFKTMz07ymM16vV16v1/ze4/H0V7MHBYsKAgDQc0O2Z2cgrVixQmlpaeajoKAg0k3qFbaLAACg54Zs2MnNzZUkVVRUhByvqKgwz+Xm5qqysjLkfGtrq6qqqsxrOrN8+XLV1NSYj8OHD/dz6weOYRhhraDMooIAgFg1ZMPOmDFjlJubq40bN5rHPB6Ptm3bpqKiIklSUVGRqqurtWPHDvOaTZs2ye/3q7CwsMv3drlccrvdIQ+rCB6OIuwAAHB2Ea3Zqaur04EDB8zvS0tLtXPnTmVmZmrUqFG6++679Z//+Z8677zzNGbMGH3/+99Xfn6+brzxRknSxIkTdc011+iOO+7Qs88+q5aWFi1dulS33HJL1M/EknpYs8MwFgAgxkU07Lz33nu68sorze+XLVsmSVq8eLFWr16t+++/X/X19VqyZImqq6t1+eWXa/369UpISDBf8/zzz2vp0qWaPXu27Ha7Fi5cqJUrVw76ZxksvQ07rnjHGa8DACCWRDTszJo1S4ZhdHneZrPpscce02OPPdblNZmZmVqzZs1ANG9ICgxjxTtsstttZ73e7NlhNhYAIEYN2ZoddK43084lNgIFAICwYzG9mXYudSwq6G1luwgAQGwi7FiMt5dhh54dAECsI+xYTG/W2JGYjQUAAGHHYnpbs+OKp0AZABDbCDsW01Gz4+jR9YFQ1OIz5Pd3PfMNAIBoRdixmN4WKAdfR+8OACAWEXYsJhBYXL2cei6xZQQAIDYRdiym1z07QaGIImUAQCwi7FhMYL2cnoYdm83GKsoAgJhG2LGY3s7GkjoWFqRnBwAQiwg7FtPbRQWDryXsAABiEWHHYnq7qGDwtYQdAEAsIuxYTG8LlIOvZX8sAEAsIuxYTDg1O2wZAQCIZYQdiwkEFlc4PTvMxgIAxCDCjsWEU7PDbCwAQCwj7FhMWMNYhB0AQAwj7FhMeAXKjpDXAgAQSwg7FuMNZ+q5IzAbi7ADAIg9hB2LCadnp6Nmh6nnAIDYQ9ixmD7V7DAbCwAQgwg7FtO3nh3CDgAg9hB2LCbQOxPOOjuEHQBALCLsWExYs7EcLCoIAIhdhB2L6ajZcfT4NeYKyi2EHQBA7CHsWEyfdj2nZwcAEIMIOxbTl13PqdkBAMQiwo7FeMOYeu5iBWUAQAwj7FhMYGFAenYAAOgZwo7FhDP13OWgZgcAELsIOxbTl5odL9tFAABiEGHHQlp9fvmNtudhbRfBMBYAIAYRdiwkeBgqnEUFCTsAgFhE2LGQ4LAS3jAWYQcAEHsIOxYSCDs2mxRnt/X4dS4WFQQAxDDCjoUEemZccXbZbD0PO9TsAABiGWHHQsytInpRnCwRdgAAsY2wYyEd0857vgmo1DGMRc0OACAWEXYspLm19wsKSh07pNOzAwCIRYQdCwlnx/Pg6ylQBgDEIsKOhTSHsQmo1NET5PMb8gVWJQQAIEYQdiwknK0iTr+eoSwAQKwh7FiIl7ADAECvEXYsJNyp53F2mwLL8rAZKAAg1hB2LCTcYSybzWYGJKafAwBiDWHHQsINO8GvYUYWACDWEHYspLl9CCqcsOOKY60dAEBsIuxYSKBXxtXLmh0paDNQwg4AIMYQdiyEYSwAAHqPsGMhfQo7gQLlFsIOACC2EHYsxBvm1HMpuGeHqecAgNhC2LGQfhnGomYHABBjCDsW0pewEyhQZp0dAECsGdJh55FHHpHNZgt5TJgwwTzf1NSk4uJiZWVlKSUlRQsXLlRFRUUEWzyw6NkBAKD3hnTYkaQLLrhAx44dMx9vv/22ee6ee+7Ra6+9ppdeekklJSU6evSobrrppgi2dmCFu11E8GuYjQUAiDVxkW7A2cTFxSk3N/eM4zU1NfrNb36jNWvW6KqrrpIkPffcc5o4caK2bt2qSy+9dLCbOuACvTKuPvTsMBsLABBrhnzPzv79+5Wfn69zzz1XixYtUllZmSRpx44damlp0Zw5c8xrJ0yYoFGjRmnLli3dvqfX65XH4wl5WAHr7AAA0HtDOuwUFhZq9erVWr9+vZ555hmVlpbqi1/8ompra1VeXi6n06n09PSQ1+Tk5Ki8vLzb912xYoXS0tLMR0FBwQB+iv5jDmP1oUCZmh0AQKwZ0sNY8+fPN59PmTJFhYWFGj16tP7whz8oMTEx7Pddvny5li1bZn7v8XgsEXgCM6mcDkevX8veWACAWDWke3ZOl56ervPPP18HDhxQbm6umpubVV1dHXJNRUVFpzU+wVwul9xud8jDChjGAgCg9ywVdurq6nTw4EHl5eVp+vTpio+P18aNG83z+/btU1lZmYqKiiLYyoHTH9tF0LMDAIg1Q3oY6z/+4z903XXXafTo0Tp69KgefvhhORwO3XrrrUpLS9Ptt9+uZcuWKTMzU263W3fddZeKioqiciaWJHlb27Z66Mt2EYH3AAAgVgzpsPP555/r1ltv1cmTJzV8+HBdfvnl2rp1q4YPHy5J+tnPfia73a6FCxfK6/Vq3rx5+sUvfhHhVg+cvhQoO1lBGQAQo4Z02HnhhRe6PZ+QkKBVq1Zp1apVg9SiyOrTOjsMYwEAYpSlanZiXZ/2xoon7AAAYhNhx0LMsMN2EQAA9Bhhx0L6o2aHnh0AQKwh7FiE32+oxWdI6tsKyhQoAwBiDWHHIoKHn+jZAQCg5wg7FhESdsKq2WG7CABAbCLsWERwSAkn7JizsShQBgDEGMKORQTCTrzDJrvd1uvXs84OACBWEXYsoi/TziVWUAYAxC7CjkX0Zdp58OvYGwsAEGsIOxbRl9WTJYaxAACxi7BjEd4+hp3AOjvNPr8Mw+i3dgEAMNQRdiyiv2p2DENq9RN2AACxg7BjER01O46wXu8Keh1DWQCAWELYsYg+1+wEvY6wAwCIJYQdiwgEFFeYw1gOu02O9vV5mH4OAIglhB2LaPa1TRkPt2dHYkYWACA2EXYswuzZ6UvYMWdksdYOACB2EHYsoq81O8GvZRgLABBLCDsW0dd1dqSgtXYIOwCAGELYsQhz6nmYBcpS0DAWYQcAEEMIOxbRL8NYDoaxAACxh7BjEf0RdhjGAgDEIsKORfRngXJgSAwAgFhA2LGIQEAJd1FBiZodAEBsIuxYRP8MYzlC3gsAgFhA2LGIfi1QZhgLABBDCDsW4WXqOQAAYSHsWERHz44j7PfoWEGZ7SIAALGDsGMR/Tobi54dAEAMIexYRH/W7BB2AACxhLBjEf2xXYQrnrADAIg9hB2LCAQUV1+mnjtYVBAAEHsIOxZBzQ4AAOEh7FiEOYzVD2GHjUABALGEsGMRZs9OX9bZoUAZABCDCDsW4e2XYSxHyHsBABAL4iLdAPRMc/tCgH3bGys6C5Sr6ptV8kmlNn98XJW1TbqoIEOF52ZqxugMpSbER6xd9d5WlZ6ol91m0/k5KYrrQ69cd7ytPpXXNOlIdaOO13o1PMWlsdkpyk51yWaz9fh9Gppb9dExj3Yf8WjP0Ro1NPuU405QrjtBOWltX3PdCcp2u5QQH/7ilgAw2Ag7FtEfU887CpSHzgrKLT6/9pXXymG3aURGotw9CCd+v6E9Rz3avK9Sm/dVaufhahlGx/mtn1bp2ZKDstukC/LTVDgmU4XnZuniczKUnuTs9D19fkOnGpp1os6rk3XNOtXQLFecQ6kJcUpNiJM7IV7uhHilJMTJYe8IEIZh6ERdsw4er9OByrbHweN1OlhZp6M1TeZ1ifEOXTgiTdNGpeuignRNG5Wh3LSEHn3WE3VeHatp0rGaRh2pbtLR6kbzcaS6SSfqvJ2+NjUhTmOHp2hcdtsj8LwgI1H1Xp/2HK3R7qM1Zrj59ER9yH3sTkZSvHLcCcpLS9DIjCSNzEgM+pqozGRnl0HL5zd0ss6rCo9XFZ4mVdQ26WRds+IddqUkxMndfs9TXPHm/U91nXnvo4VhGKrztireYSdEAgOEsDOAntq4X3XeVuWnJyovLUH56YnKT09URlJ8r/7FLfXP1POhMBvrVH2z3i87pR2ftT3+8Xm1mlo62pOaEKcR6W2/MPPTEzUiPVEjMtq+Hqtp0uaPK/XmJ8d1vDb0F/zEPLeuHD9co7OS9N6hU9pWWqWyqgbtOlKjXUdq9Ou3S2WzSeNzUjV1ZLrqm1t1sq5ZJ+vbwk1VQ3OPf9EnOx1KbQ8+x2u9qmls6fLarGSnmlv9qvW26t1DVXr3UJV5Li8toT34pGtUZpIqPF4drWlUeU2TjlU36WhNoyo8TWrxnb1hCfF25acnaniKSxWeJpVVNai2qVU7D1dr5+HqkGvjHbYu3zPH7dLk/DRdkO+WOzFelbVeldc0qdzTpApPk8prmuRt9etUQ4tONbTo4/LaTt8nMd5hBp9hKS6damhWZW1buDle65W/h/f6dKmuOKUnxyszyan0JKcykuLbvzqVkdz23GGzqbqxWdUNLappbFF1Q9vz6sYW1TS0qLqxWQ3e0wK/7cynNptNdpvksNtkt9lCvrY9bzuXGO9QotOhJGeckpyO9kfb82RXnBLjHfK2+lXd0BaiTzW0tcN83tisFp+heIdN0woydOnYLBWdm6Vpo9IJP0A/IewMoD++/7kOnWw443hCvF35aYlmCBqfm6qvXTq6y/+xtfr85i+HoT4by+835G31q7HFp6YWn2oaW7Tr8xq991mVdnx2SgeP15/xGnf7v9hPNbSotqlVH5fXdvlLNCDZ6dDl5w3TleOzNWt8dkgvyc0Xj5IkHatp1LulVdr6aZXeLT2pg8fru31vm03KSHIqK7ntl6fX51dtU1ubaptazFBW3+xTfbNP8nS8riAjqb33JNnsRRk7PEUZyU75/YY+PVGn98vagscHZdXaV+5p760p1192l3f7We02KTs1QXnpCWYAzA8Kz50F6KYWnw6drNfByvq2Hqf23qZPT9SZn2NUZpImj3DrgvZwc0F+moanurpti2EYqmlsUXl78DlW06TPTzXo81ON7Y8GVXi8amzxaX9lnfZX1nX5mYanupTjTlB2aoKGpzrV4jPM+13nbTXve21Tq/l3ttbbqlpvqw5XNXbbTitq8RlmIF65cb+ccXZNH5WhorFZKhqbpakj0/v03z8Qywg7A+ibM8fo0Ml681/pR9uHHJpa/Pr0RL0+PdHxi39/RZ1+9JUpnb5PcI1Nn2p2+nE21p8+PKZf/e1TeRpb1NTiU2OLT43Nvh4FqXOHJ2vG6AxNb3+cOyxFdrtN9d5WHa1u1OfVjTpyKjBM0/b8SHWjUlxx+tL5w3XlhGzNOCdDrrNsipqXlqgbLhqhGy4aIUk6XuvV9kNV2ldeK3divIalODUsxaWsFKeykl3KSIrvtq6muTU4/LT9Is5IdmrMsORu/wVut9s0LjtV47JT9S8zCiS11fPsOlLT1vNSVq1yT5Ny3e2BJi1RuWkJyk9PUF5aorJTXb2u90mId2hCrlsTct0hx/1+Q0drGpWaEK+0xN7XM9lsNqW396qc/t4B3lafjlU3meHneK1XmSlO5aQmKMedoBy3S1kprl4NSQXufXV7T82p+raekWqzh6TjmGFIaUnxSk+MV3p7z09a4HmiU+lJ8Up2xZk9OMGdTEZQ957faPveZxjy+Q35/ep43v7V5zfU1OJTQ7NPDc2t7V/bntd7O4654hxKT4oP7Ylqf9523KkKT5O2fHpSWw6e1JZPT+p4rbft+09PShvaessKz83U1wpH66oJ2bJH4ZAeMFBshtHTzvvo5fF4lJaWppqaGrndnf8PvL8EikmPttdelJ6o19ObD0iSfn/HpSoam3XGa6obmnXRYxskSQf+a37Yha7vHarSV57dotFZSSq578qwP8Ov//ap/vNPH531OqfDrkSnQ+NzU9uCzagMfWF0hjKTO6+bAdDGMAwdPF6vLZ+e1Nb28FNV32yeHzMsWd+ceY6+Mn2kkpz8mxWxq6e/v/mvZJC54hwanZWs0VnJ5rFTDc16fluZvvvKLv3lO188o5cg0BNjt6lPM3oCPSHh9uz4/YYeX/+xfvXWp5Kkb1x2jq6dkqeEOIcSnW3FlQnxDiW2f43GYlJgMNhsNrOw/OuXjpbfb+iTylq98sERrdlWptIT9Xpo7R795K/7dGvhKH3jsnOUl5YY6WYDQxZhZwh4YP4EvfFRhUpP1OupTft137wJIef7Y42d4NeHE3ZafH7d//KHeuWDI5Kk5fMnaMkV5/a60BpA79ntNk3IdWv5fLe+fdV5ennH53ru76U6dLJBvyz5VL/5W6kWXJin2y8fo6kF6ZFuLjDkUO02BLgT4vXo9ZMlSb8s+VQfHfOEnO+PaedS+GGn3tuq23/7nl754Igcdpv+33+eqv/nS2MJOkAEJLvitPiyc7Tx3ln679tm6NJzM9XqN/R//nFUN6z6u/752Xf0j9Nm4AGxjrAzRFwzOVfzLshRq9/Qg/+zS76gubkdm4D2bRpqOLOxTtZ59dX/3qq3PjmuxHiHfr14hhZOH9mndgDoO4fdpqsn5eiFJUVad9fluukLIxTvsGn7oVO66Zl39OQbn6hlgBcQNdoLtYGhjrAzhDx2w2SluuL0j8PV+t2WQ+bx/lhjRwraG8vnV0/q0g9XNegrz27RPz6vUUZSvNbcUagrx2f3qQ0A+t/kEWn66b9cpL8/cJWun5ovn9/Qk2/s11eeeUcHj3c+/b+vdh6u1pyflqhoxUa9ua9yQH4G0F8IO0NIjjtBD8xvq9f58V/36Uh121oi/bHj+emv//7a3frN26V6Y2+F9lfUqqkldJG1vUc9uumZd1R6ol4j0hP18p2XadqojD79fAADK9udoJW3TtPKW6fJnRCnf3xeo2tX/k2/23KoR//A6Qmf39DTm/Zr4TPv6ODxelXWevWN57brv/60l02GMWRRoDzEfPWSUVq784i2Hzql77+6W79ZPKNfdjyX2hbiS0+KV3VDi/7/rWUh52w2KdedoNFZSSrISNL63eWq9bZqQm6qfvuvlyjHffatDQAMDddPzdfF52To/pc/1N/2n9BDa/dow94K/fgrU3u0TUlXDlc1aNkfdmr7oVOSpGun5Ckr2anfbflM//23Um39tEorb52mMcOSz/JOA6epxadmn1/JzujcXqQ/1DS26N3SKhWNzVKKKzZiAOvsaHDX2emJA5W1WvDzt9Xs8+upW6cpxRWnb67ergtHpOm1uy7v03sfrmrQOwdP6NDJBpWdbNChk/UqO9mgWm/rGdcWjsnUr26bEdbicwAiz+839L+3fqYf/vkjeVv9SkuM1w9unKzrp+b3+r1e/eCIvv/qbtV6W5XiitNjN1ygf5o2QjabTRv2Vui+l/+h6oYWJTsd+sGNk3XTFwantq/F59fOw9X6+4ET+vuBE/qgrFqt7XVEyU6HUhLilOJqf5jP45WZHK9RmUkqyEzSqMwkjchIPOtCpVZ3os6r/+/tUv3vLZ+p1tuqYSkuLbv6fP3LjJEDtlHxQOvp72/CjoZe2JGkJ9/4RE++sV/DUpy6b954PfDHXZo+OkN/vPOyfv9ZhmGoqr5Zn1V1BKDUhHgtKhzF3jxAFDhQWadlf9ipDz+vkSRdNzVfd101TucOSz7rL7maxhY9tHa31u48KkmaPjpDT958kQoyk0KuO1bTqLtf2KltpW37v/3TtBH6wY2T+73nwDAM7auo1dv728LNu6VVbdu39FGgdzsQfkZlJikvLUGpCXFKdrU9UgJfnXFKdjksExCO1TTqlyWf6oXtZeZ2MQnxdvP5+JxUfffaifrS+cMj2cywEHZ6YSiGHW+rT9eufFsHKuuU43apwuNV0blZ+v2SSyPdNAAW1OLz6+lNB/T05gPmDCpXnF0T8tzte6O17Y82ITfV/EfOu6VVuufFnTpS3SiH3aZvX3Weiq8c2+UveZ/f0C82H9CTG/fL5zc0OitJT906TVNGpvep7Z6mFr2577g2flShvx84oRN1zSHnM5Liddm4YZo5dphmjstSjjtB9d6OPdbqvK2qa2pVfXOrud3LiTqvyqoadLiqQWVVDWoIIzC54uxyJ8br/JwUTR6RpgtHpGnKiHQVZCYOiaU5Dp2o17MlB/XH9z83N/+dMjJNxVeO06zxw/X81jL9fON+czPjK84frv+1YKLG56ZGstm9QtjphaEYdiRp+6Eq/fOzW8zvv3T+cP32Xy+JYIsAWN3Ow9X60V8+1j8+r+70F7zDbtPY4ckqyEjS5n2V8httm8Y+ectF+kIPJym8d6hK33mhLSTF2W26e855mjMpR2OGJfd4qOhYTaPe2Fuh1/dWaOunJ81f1lLbPmGXjMnUzHFZmjlumCbmuvu0V1igd7usPfh8fqpRZScbdMzTpHpvqxmcGpp9qvO2nrUQOy0xXpNHuDV5RJom57eFoFGZSYO2n9nH5R79YvNBrfvwqLmJdOGYTC29apwuHzcsJIhVNzTrqU0H9Lsth9TiM2S3tW2mvOzq88+6MfBQEHNhZ9WqVfrxj3+s8vJyTZ06VU899ZQuuaRnwWCohh1J+l+v7NLz29qKia+elKP/vm1GhFsEIBr4/YYOnazXnqOe9keN9h716GR9aK/JP08fqYevv6DXw1E1DS168H8+1F92l5vHHHabxgxL1vk5KTo/J1Xjc1J1Xk6qzslKksNu0ycVddqwt1yv760wh9wCxg5P1tWTcjVr/HBNG5Ue0fqaFp/fDEBV9c3ae9SjXUdqtPtIjT46VhuyeXOAM86ugoxEjc5K1qjMJI3OCjySNbIX9UKGYehkfbO5wfSx6kYdq2nS0ZomlbdvOB2YyStJV44fruIrx2nGOZndvu+hE/X60fqPzT+vZKdDd84aq2mjMuRpbJGnqUWextb2ry3yNLWaxxOdcRqVmWgO/wWGAlMTBr7eM6bCzosvvqjbbrtNzz77rAoLC/Xkk0/qpZde0r59+5SdffZ1YYZy2PE0tejqn5aowuPVtVPytOqrX4h0kwBEKcMwVOHxau+xGu0rr9MF+W5d0Yc6DsMw9NKOz/Xi9sP6pLy204kQUttM0/SkeFXWes1jNpv0hVEZunpSjq6elKOxw1PCbsdgam7165OKWu0+UtMRgMpru+0Nstmk/LREpbji5DMM+f1G21fDkN/fNjwYOF7bg54lm01aMDlP/37lWF2Qn9ar9r9bWqX/+tNe/eO0sBmOjKTQIvCvF43u9z3cYirsFBYW6uKLL9bTTz8tSfL7/SooKNBdd92lBx988KyvH8phR5JKPjmue17cqQfnT9C/zCiIdHMAoNcMw1C5p0n7ymu1v6JOn1TU6pOKWu2vrDOH05xxdl0+bpjmTsrR7Ik5lhhG6Qmf39DR6kZ9drJBn1W1zYBte96gz07W97peyGaThqe4lJeeqPy0BOWmJSg/LVF56QnKS0vU6KwkDUsJ/97527cf+c3bpWpu9cudGCd3QrzcifFyJ8S1f41XWmK8UhPiVNvUag4BBuqgTu8hlKSN936p30NrzISd5uZmJSUl6eWXX9aNN95oHl+8eLGqq6u1du3aM17j9Xrl9Xb8C8Lj8aigoGDIhh2p7X8UQ6HgDQD6k99v6Ej7UMwF+W4lx8i6LwGGYehEXbPKqurV1OKX3WaTw26Twy7ZbTbz+8DXJKdDOe6EPi8yO9DqvK1m8Xfg63cXTOz3Gb49DTuW/1t14sQJ+Xw+5eTkhBzPycnRxx9/3OlrVqxYoUcffXQwmtdvCDoAopHdblNB+1BHLLLZbBqe6oqaXqyAFFecJua5NTFvaHQgDO1oOECWL1+umpoa83H48OFINwkAAAwQy/fsDBs2TA6HQxUVFSHHKyoqlJub2+lrXC6XXK7oStEAAKBzlu/ZcTqdmj59ujZu3Gge8/v92rhxo4qKiiLYMgAAMBRYvmdHkpYtW6bFixdrxowZuuSSS/Tkk0+qvr5e3/zmNyPdNAAAEGFREXZuvvlmHT9+XA899JDKy8t10UUXaf369WcULQMAgNhj+ann/WGor7MDAADO1NPf35av2QEAAOgOYQcAAEQ1wg4AAIhqhB0AABDVCDsAACCqEXYAAEBUI+wAAICoFhWLCvZVYKkhj8cT4ZYAAICeCvzePtuSgYQdSbW1tZKkgoKCCLcEAAD0Vm1trdLS0ro8zwrKats49OjRo0pNTZXNZuu39/V4PCooKNDhw4dZmXkQcL8HF/d7cHG/Bxf3e3CFe78Nw1Btba3y8/Nlt3ddmUPPjiS73a6RI0cO2Pu73W7+YxlE3O/Bxf0eXNzvwcX9Hlzh3O/uenQCKFAGAABRjbADAACiGmFnALlcLj388MNyuVyRbkpM4H4PLu734OJ+Dy7u9+Aa6PtNgTIAAIhq9OwAAICoRtgBAABRjbADAACiGmEHAABENcLOAFq1apXOOeccJSQkqLCwUO+++26kmxQV3nrrLV133XXKz8+XzWbTq6++GnLeMAw99NBDysvLU2JioubMmaP9+/dHprEWt2LFCl188cVKTU1Vdna2brzxRu3bty/kmqamJhUXFysrK0spKSlauHChKioqItRi63vmmWc0ZcoUc3G1oqIi/eUvfzHPc78HzuOPPy6bzaa7777bPMb97l+PPPKIbDZbyGPChAnm+YG634SdAfLiiy9q2bJlevjhh/X+++9r6tSpmjdvniorKyPdNMurr6/X1KlTtWrVqk7PP/HEE1q5cqWeffZZbdu2TcnJyZo3b56ampoGuaXWV1JSouLiYm3dulUbNmxQS0uL5s6dq/r6evOae+65R6+99ppeeukllZSU6OjRo7rpppsi2GprGzlypB5//HHt2LFD7733nq666irdcMMN2rNnjyTu90DZvn27fvnLX2rKlCkhx7nf/e+CCy7QsWPHzMfbb79tnhuw+21gQFxyySVGcXGx+b3P5zPy8/ONFStWRLBV0UeS8corr5jf+/1+Izc31/jxj39sHquurjZcLpfx+9//PgItjC6VlZWGJKOkpMQwjLZ7Gx8fb7z00kvmNR999JEhydiyZUukmhl1MjIyjF//+tfc7wFSW1trnHfeecaGDRuML33pS8Z3vvMdwzD4+z0QHn74YWPq1KmdnhvI+03PzgBobm7Wjh07NGfOHPOY3W7XnDlztGXLlgi2LPqVlpaqvLw85N6npaWpsLCQe98PampqJEmZmZmSpB07dqilpSXkfk+YMEGjRo3ifvcDn8+nF154QfX19SoqKuJ+D5Di4mJde+21IfdV4u/3QNm/f7/y8/N17rnnatGiRSorK5M0sPebjUAHwIkTJ+Tz+ZSTkxNyPCcnRx9//HGEWhUbysvLJanTex84h/D4/X7dfffdmjlzpiZPniyp7X47nU6lp6eHXMv97ptdu3apqKhITU1NSklJ0SuvvKJJkyZp586d3O9+9sILL+j999/X9u3bzzjH3+/+V1hYqNWrV2v8+PE6duyYHn30UX3xi1/U7t27B/R+E3YA9EhxcbF2794dMr6OgTF+/Hjt3LlTNTU1evnll7V48WKVlJREullR5/Dhw/rOd76jDRs2KCEhIdLNiQnz5883n0+ZMkWFhYUaPXq0/vCHPygxMXHAfi7DWANg2LBhcjgcZ1SQV1RUKDc3N0Ktig2B+8u9719Lly7VunXrtHnzZo0cOdI8npubq+bmZlVXV4dcz/3uG6fTqXHjxmn69OlasWKFpk6dqp///Ofc7362Y8cOVVZW6gtf+ILi4uIUFxenkpISrVy5UnFxccrJyeF+D7D09HSdf/75OnDgwID+/SbsDACn06np06dr48aN5jG/36+NGzeqqKgogi2LfmPGjFFubm7Ivfd4PNq2bRv3PgyGYWjp0qV65ZVXtGnTJo0ZMybk/PTp0xUfHx9yv/ft26eysjLudz/y+/3yer3c7342e/Zs7dq1Szt37jQfM2bM0KJFi8zn3O+BVVdXp4MHDyovL29g/373qbwZXXrhhRcMl8tlrF692ti7d6+xZMkSIz093SgvL4900yyvtrbW+OCDD4wPPvjAkGT89Kc/NT744APjs88+MwzDMB5//HEjPT3dWLt2rfHhhx8aN9xwgzFmzBijsbExwi23njvvvNNIS0sz3nzzTePYsWPmo6GhwbzmW9/6ljFq1Chj06ZNxnvvvWcUFRUZRUVFEWy1tT344INGSUmJUVpaanz44YfGgw8+aNhsNuP11183DIP7PdCCZ2MZBve7v917773Gm2++aZSWlhp///vfjTlz5hjDhg0zKisrDcMYuPtN2BlATz31lDFq1CjD6XQal1xyibF169ZINykqbN682ZB0xmPx4sWGYbRNP//+979v5OTkGC6Xy5g9e7axb9++yDbaojq7z5KM5557zrymsbHR+Pd//3cjIyPDSEpKMv7pn/7JOHbsWOQabXH/+q//aowePdpwOp3G8OHDjdmzZ5tBxzC43wPt9LDD/e5fN998s5GXl2c4nU5jxIgRxs0332wcOHDAPD9Q99tmGIbRt74hAACAoYuaHQAAENUIOwAAIKoRdgAAQFQj7AAAgKhG2AEAAFGNsAMAAKIaYQcAAEQ1wg4AAIhqhB0AABDVCDsAACCqEXYAAEBUI+wAAICo9n8B/RH1KVQjPqYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_o_loss)\n",
    "# plt.ylim([0, 10])\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e947e1-67f4-4205-99af-6921c6e9c896",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65627011-48eb-4e8e-981e-8b61b0f427c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorboard import notebook\n",
    "# notebook.list() # View open TensorBoard instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e0f77a33-0962-4af0-af97-cf05f895cbf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fcc3decd-8017-4617-b295-d49640ce3d2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %tensorboard --logdir=$LOG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc40143-30b1-479f-b9b1-fa4c07b1690e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [8] Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6c94a0-122f-4ba6-acef-5653a3cc7850",
   "metadata": {
    "tags": []
   },
   "source": [
    "## load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b1c382b5-e2e0-45a2-9c5f-ef2c468d0f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v15/run-20241209-183419/artifacts\n"
     ]
    }
   ],
   "source": [
    "POLICY_URI = ARTIFACTS_DIR\n",
    "\n",
    "print(POLICY_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "68592d97-1272-4c6d-a4bd-43a6f7fe6c1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f962c63a380>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910a06f-678f-4bfa-a132-10b885f871c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## get predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1762c936-3c49-4ec5-a9eb-4df5816dc888",
   "metadata": {},
   "source": [
    "TODO - explain bandit_policy_type()\n",
    "\n",
    "**Dummy arm values?**\n",
    "* We set `chosen_arm_features` to dummy values of all zeros. We need to save dummy chosen arm features to make the returned policy step have the same structure as the policy state spec.\n",
    "* `emit_policy_info = ('predicted_rewards_mean', 'bandit_policy_type')` defines what side information we want to get as part of the policy info when we call policy network \n",
    "* This makes it so that the model always returns the expected rewards even if the model is exploring\n",
    "* This means that the largest predicted rewards may not match the selected action when the model is exploring (i.e. bandit_policy == UNIFORM == 2)\n",
    "\n",
    "**UNIFORM Random policy:**\n",
    "```\n",
    "PolicyStep(action=array(1, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.637535 , 3.5557823], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([2], dtype=int32), chosen_arm_features=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)))\n",
    "```\n",
    "\n",
    "**GREEDY policy:**\n",
    "```\n",
    "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.8278818, 3.607565 ], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([ 0.04054676, -0.04735027,  0.02202327,  0.01276748, -0.01367382,\n",
    "       -0.04838754,  0.00104916, -0.01956806,  0.01028793, -0.00256665,\n",
    "       -0.04376553,  0.03900594,  0.02388967, -0.04016995, -0.04945569,\n",
    "       -0.04539652,  0.04423274, -0.04630332,  0.00390794,  0.03986299,\n",
    "       -0.0398974 ,  0.01655747, -0.0471294 , -0.00690235, -0.03643382,\n",
    "       -0.0437116 ,  0.04757959, -0.00991895,  0.0281055 , -0.04633433,\n",
    "        0.01897702, -0.00824345,  0.03232259, -0.04980658, -0.01144745,\n",
    "        0.01690939,  0.02536928,  0.03384003, -0.01558131,  0.04731432,\n",
    "        0.04579857, -0.03305101,  0.03521084, -0.03915765,  0.04927064,\n",
    "        0.04695194,  0.03792156,  0.040496  ,  0.02574866, -0.00665367,\n",
    "       -0.03839222, -0.01564004, -0.04710373,  0.03557512, -0.01392462,\n",
    "        0.01368621,  0.02792176, -0.01799218,  0.00246101,  0.02263175,\n",
    "        0.0170817 ,  0.01388383, -0.03048695,  0.01198485], dtype=float32)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aff30396-e0fd-4f43-acaa-6af8b20b12cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "SKIP_NUM = 10\n",
    "\n",
    "for x in eval_ds.skip(SKIP_NUM).take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    \n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "    \n",
    "    # rewards = _get_rewards(x)\n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2bcd1e82-168e-4df3-92bd-4cd34ecd3a94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': <tf.Tensor: shape=(), dtype=float32, numpy=1.0>,\n",
       " 'observation': {'global': <tf.Tensor: shape=(72,), dtype=float32, numpy=\n",
       "array([-0.02266808,  0.03374651,  0.01344511, -0.04072883,  0.00333109,\n",
       "       -0.03854891,  0.02258417,  0.02261107, -0.03201053,  0.01069438,\n",
       "        0.00984267,  0.02959475,  0.01783261, -0.0233057 , -0.04796777,\n",
       "       -0.04069347, -0.04347043, -0.02588516,  0.01958538,  0.04014254,\n",
       "       -0.03883126, -0.01179407,  0.04639982, -0.04120154, -0.00310273,\n",
       "        0.00322305, -0.025387  , -0.00844039,  0.01892832, -0.04562571,\n",
       "       -0.02220386, -0.01355764, -0.03174492,  0.00758722, -0.00478777,\n",
       "        0.03007371, -0.03097217,  0.02430639, -0.03765398, -0.0210402 ,\n",
       "        0.00979852, -0.00566171, -0.03486073, -0.02477167, -0.01221125,\n",
       "       -0.03168996, -0.00628415, -0.04342208,  0.00872253,  0.01548855,\n",
       "        0.04987988, -0.01089209, -0.01382544,  0.03478048,  0.04539231,\n",
       "        0.03530445, -0.01755105,  0.03770969, -0.02651383, -0.00238528,\n",
       "        0.04153426,  0.0021206 , -0.01055909,  0.04546957, -0.0426662 ,\n",
       "       -0.0236995 ,  0.01541403, -0.01012019,  0.01503308, -0.01948508,\n",
       "        0.00911264, -0.0457615 ], dtype=float32)>,\n",
       "                 'per_arm': <tf.Tensor: shape=(2, 64), dtype=float32, numpy=\n",
       "array([[ 0.04678645, -0.04986302,  0.00039756, -0.0063717 ,  0.00338418,\n",
       "        -0.03862878,  0.01571499, -0.02118614,  0.03065653, -0.04441894,\n",
       "        -0.00453939, -0.03180676,  0.00370729,  0.042188  , -0.00185664,\n",
       "         0.02103868,  0.02073762, -0.02669345, -0.00526383,  0.0392246 ,\n",
       "         0.01063422, -0.01547053, -0.03193083, -0.03199725,  0.03343971,\n",
       "         0.00957556, -0.02217044, -0.04335929, -0.04697284,  0.00454235,\n",
       "         0.02986431,  0.02157892,  0.14006421, -0.05837856, -0.09898996,\n",
       "        -0.08678105,  0.01023198, -0.10343557, -0.07030103,  0.05126235,\n",
       "        -0.05444595, -0.00858568,  0.14279081, -0.03253373, -0.10341844,\n",
       "        -0.09779982,  0.1412717 ,  0.08593705,  0.02505516, -0.02445642,\n",
       "        -0.02608733,  0.01787025,  0.00794103, -0.02179296, -0.01954065,\n",
       "        -0.0122567 ,  0.03608974, -0.02604431,  0.04553938, -0.00937469,\n",
       "         0.0118037 , -0.00419128,  0.01161989,  0.04335671],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ]],\n",
       "      dtype=float32)>},\n",
       " 'reward': <tf.Tensor: shape=(), dtype=float32, numpy=3.0>,\n",
       " 'step_type': <tf.Tensor: shape=(), dtype=int32, numpy=0>})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectory_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e58af9ab-f4da-4857-afe5-6b8de26ed0b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([2.2755818, 2.1761792], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=array([2.2755818, 2.1761792], dtype=float32), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=array([ 0.04678645, -0.04986302,  0.00039756, -0.0063717 ,  0.00338418,\n",
       "       -0.03862878,  0.01571499, -0.02118614,  0.03065653, -0.04441894,\n",
       "       -0.00453939, -0.03180676,  0.00370729,  0.042188  , -0.00185664,\n",
       "        0.02103868,  0.02073762, -0.02669345, -0.00526383,  0.0392246 ,\n",
       "        0.01063422, -0.01547053, -0.03193083, -0.03199725,  0.03343971,\n",
       "        0.00957556, -0.02217044, -0.04335929, -0.04697284,  0.00454235,\n",
       "        0.02986431,  0.02157892,  0.14006421, -0.05837856, -0.09898996,\n",
       "       -0.08678105,  0.01023198, -0.10343557, -0.07030103,  0.05126235,\n",
       "       -0.05444595, -0.00858568,  0.14279081, -0.03253373, -0.10341844,\n",
       "       -0.09779982,  0.1412717 ,  0.08593705,  0.02505516, -0.02445642,\n",
       "       -0.02608733,  0.01787025,  0.00794103, -0.02179296, -0.01954065,\n",
       "       -0.0122567 ,  0.03608974, -0.02604431,  0.04553938, -0.00937469,\n",
       "        0.0118037 , -0.00419128,  0.01161989,  0.04335671], dtype=float32)))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ec286d78-dd56-455d-90f8-4ffa88f3ac50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.2755818, 2.1761792], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info.predicted_rewards_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c85a0087-7388-4f03-9278-aace31121233",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0, dtype=int32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a8266c7c-3688-46a5-a1c8-a63bb7146128",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info.bandit_policy_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9712bc00-7ea0-4003-a3c7-81a0be5bc995",
   "metadata": {},
   "source": [
    "# [9] Prepare training application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f62966-123f-410e-9610-832f20566635",
   "metadata": {},
   "source": [
    "To scale this training in Vertex AI's managed training service, we need to package all our code into a python application\n",
    "\n",
    "* This means, we need to modularize all steps executed up until this point. For example, the training loop we ran above is further parameterized in `train_perarm.py`, which will be called from our `task.py` when we submit the job to Vertex AI\n",
    "* This training package will eventually be used to create a custom training image (more on that in `04b-build-training-image` notebook)\n",
    "* For additional details on preparing the training application for Vertex AI, check out [the documentation](https://cloud.google.com/vertex-ai/docs/training/code-requirements) and [this code example](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage2/get_started_vertex_training.ipynb) (which also has good, related commentary)\n",
    "\n",
    "**The remaining cells will repeat steps executed above**\n",
    "> we are just illustrating / validating that they are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6c3d30-bef4-4ec5-a978-116856a70e7e",
   "metadata": {},
   "source": [
    "### Distribution strategy\n",
    "\n",
    "Use `strategy_utils` to generate a strategy. Under the hood, passing the parameter:\n",
    "\n",
    "* `use_gpu = False` returns `tf.distribute.get_strategy()`, which uses CPU\n",
    "* `use_gpu = True` returns `tf.distribute.MirroredStrategy()`, which uses all GPUs that are visible to TensorFlow on one machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "68140c4d-12ff-4758-89ca-44fd710ca0c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.train.utils import strategy_utils\n",
    "\n",
    "use_gpu = True\n",
    "use_tpu = False\n",
    "\n",
    "distribution_strategy = strategy_utils.get_strategy(tpu=use_tpu, use_gpu=use_gpu)\n",
    "\n",
    "NUM_REPLICAS = distribution_strategy.num_replicas_in_sync\n",
    "NUM_REPLICAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1129ee41-b43c-4d5a-b656-cdac6b79688c",
   "metadata": {},
   "source": [
    "### Vertex Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ef509680-4d19-4efa-9f01-21039e0d573b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : 02a-perarm-bandit-v15\n"
     ]
    }
   ],
   "source": [
    "# using same experiment name \n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7ad98430-d836-40f1-8e4f-eb46f0c91fd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : 02a-perarm-bandit-v15\n",
      "RUN_NAME          : run-20241209-183658\n",
      "\n",
      "CHECKPT_DIR       : gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v15/chkpoint\n",
      "BASE_OUTPUT_DIR   : gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v15/run-20241209-183658\n",
      "LOG_DIR           : gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v15/run-20241209-183658/logs\n",
      "ROOT_DIR          : gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v15/run-20241209-183658/root\n",
      "ARTIFACTS_DIR     : gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v15/run-20241209-183658/artifacts\n"
     ]
    }
   ],
   "source": [
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "CHECKPT_DIR       = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/chkpoint\"\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"CHECKPT_DIR       : {CHECKPT_DIR}\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "71d43cf9-db3f-437e-98ee-3791ac0c5e3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    # experiment=EXPERIMENT_NAME,\n",
    "    # experiment_tensorboard=TB_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b759404-b282-4f55-add8-7d795867c99e",
   "metadata": {},
   "source": [
    "### get agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3be40320-a73f-45f7-9fc4-0bd64df0ae5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 128,\n",
       " 'eval_batch_size': 1,\n",
       " 'num_actions': 2,\n",
       " 'global_emb_size': 12,\n",
       " 'arm_emb_size': 16,\n",
       " 'global_dim': 72,\n",
       " 'per_arm_dim': 64,\n",
       " 'global_layers': [72, 36, 18],\n",
       " 'per_arm_layers': [64, 32, 16],\n",
       " 'common_layers': [34, 8],\n",
       " 'learning_rate': 0.05,\n",
       " 'epsilon': 0.01,\n",
       " 'encoding_dim': 8,\n",
       " 'num_oov_buckets': 1,\n",
       " 'model_type': 'NeuralLinUCB',\n",
       " 'network_type': 'commontower'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HPARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "108ed33c-d8ef-4524-97e9-ced9e01c154b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHKPT_INTERVAL  : 200\n",
      "eval_batch_size : 1\n",
      "NUM_EVAL_STEPS  : 100\n"
     ]
    }
   ],
   "source": [
    "IS_TESTING = True\n",
    "\n",
    "# train args\n",
    "NUM_EPOCHS          = 2\n",
    "TRAINING_LOOPS      = 100\n",
    "STEPS_PER_LOOP      = 1\n",
    "drop_arm_feature_fn = None\n",
    "\n",
    "LOG_INTERVAL        = 10\n",
    "CHKPT_INTERVAL      = 200\n",
    "NUM_EVAL_STEPS      = 100\n",
    "\n",
    "print(f\"CHKPT_INTERVAL  : {CHKPT_INTERVAL}\")\n",
    "print(f\"eval_batch_size : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS  : {NUM_EVAL_STEPS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f66ff927-9a39-4abf-b247-845f0dc7721f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_ds = tf.data.TFRecordDataset(val_files)\n",
    "eval_ds = eval_ds.map(\n",
    "    data_utils._parse_function, \n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ").batch(HPARAMS[\"eval_batch_size\"])\n",
    "\n",
    "if NUM_EVAL_STEPS > 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "528441f5-64ec-4f09-bd50-b2ae85b553bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    f\"{LOG_DIR}\", flush_millis=10 * 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f6c98398-d545-4dcc-a71f-32249b5f0336",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distribution_strategy: <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f972524d300>\n",
      "Inpsecting agent policy from train_peram file...\n",
      "agent.policy: <tf_agents.bandits.policies.neural_linucb_policy.NeuralLinUCBPolicy object at 0x7f96b04f5180>\n",
      "setting checkpoint_manager: gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v15/chkpoint\n",
      "agent.train_step_counter: 50\n",
      "starting train loop...\n",
      "\n",
      "starting epoch: 1\n",
      "step = 50: loss = 2.059999942779541\n",
      "step = 60: loss = 1.9700000286102295\n",
      "step = 70: loss = 1.4199999570846558\n",
      "step = 80: loss = 1.4600000381469727\n",
      "step = 90: loss = 1.2000000476837158\n",
      "step = 100: loss = 1.2899999618530273\n",
      "step = 110: loss = 1.2799999713897705\n",
      "step = 120: loss = 1.2599999904632568\n",
      "step = 130: loss = 1.2999999523162842\n",
      "step = 140: loss = 1.1399999856948853\n",
      "epoch_mins: 0\n",
      "\n",
      "7.145 steps/sec\n",
      "\n",
      "starting epoch: 2\n",
      "step = 150: loss = 1.0499999523162842\n",
      "step = 160: loss = 1.0399999618530273\n",
      "step = 170: loss = 1.2300000190734863\n",
      "step = 180: loss = 1.3799999952316284\n",
      "step = 190: loss = 1.2300000190734863\n",
      "step = 200: loss = 1.2699999809265137\n",
      "step = 210: loss = 1.2699999809265137\n",
      "step = 220: loss = 1.4700000286102295\n",
      "step = 230: loss = 1.440000057220459\n",
      "step = 240: loss = 1.1100000143051147\n",
      "epoch_mins: 0\n",
      "\n",
      "7.713 steps/sec\n",
      "runtime_mins: 0\n",
      "saved trained policy to: gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v15/run-20241209-183658/artifacts\n",
      "saved to checkpoint_manager: gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v15/chkpoint\n",
      "complete train job in 0 minutes\n"
     ]
    }
   ],
   "source": [
    "#start the timer and training\n",
    "start_time = time.time()\n",
    "\n",
    "# TODO: clean up\n",
    "metric_results, agent = train_perarm.train_perarm(\n",
    "    agent = agent,\n",
    "    embs = embs,\n",
    "    hparams = HPARAMS,\n",
    "    train_files = train_files,\n",
    "    reward_spec = reward_tensor_spec,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    num_epochs = NUM_EPOCHS,\n",
    "    num_iterations = TRAINING_LOOPS,\n",
    "    steps_per_loop = STEPS_PER_LOOP,\n",
    "    global_step = global_step,\n",
    "    train_summary_writer = train_summary_writer,\n",
    "    strategy = distribution_strategy,\n",
    "    chkpt_interval = CHKPT_INTERVAL,\n",
    "    log_interval = LOG_INTERVAL,\n",
    "    log_dir = LOG_DIR,\n",
    "    model_dir = ARTIFACTS_DIR,\n",
    "    chkpoint_dir = CHECKPT_DIR,\n",
    "    use_gpu = True,\n",
    "    use_tpu = False,\n",
    "    profiler = False,\n",
    "    use_tf_functions = True,\n",
    "    # is_testing = IS_TESTING,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"complete train job in {runtime_mins} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "177aa3ab-05b4-48f9-b434-9335bd9eb54d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2174019"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(metric_results)\n",
    "metric_results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ba65417f-54e0-436e-b0d4-93cffb981ae6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(metric_results)\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61464938-a3e7-4ab0-9149-4a9124199dc1",
   "metadata": {},
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9108f8b6-7aea-48d6-a763-461b30671c21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # %load_ext tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "083c2351-5ac8-4218-9bef-e249777aee97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %tensorboard --logdir=$LOG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7ba747-00d5-4908-8d0b-334ae9d2c791",
   "metadata": {},
   "source": [
    "#### eval trained policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af82506e-95d7-4a4e-a821-e08512615db7",
   "metadata": {},
   "source": [
    "After training, our `agent.policy` is used as the deployment \"model\" that will generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6c82396a-7822-41fb-830f-1f6eb9c9b213",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.bandits.policies.neural_linucb_policy.NeuralLinUCBPolicy at 0x7f99d01f1120>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_agent = agent.policy\n",
    "deployment_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f6706224-ef5b-4185-bde4-bccb7c8e7ccc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating trained Agent...\n",
      "post-train val_loss     : 2.3358964920043945\n",
      "post-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(deployment_agent, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = post_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    embs = embs,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f899120f-3706-4b72-8f2c-2169221dd66b",
   "metadata": {},
   "source": [
    "## Using Trained Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b0f691-860e-4853-928e-4c7ece714dd0",
   "metadata": {},
   "source": [
    "### load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ea029f73-0638-462a-8f00-54b05c54d69b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v4/run-20241205-221416/artifacts\n"
     ]
    }
   ],
   "source": [
    "POLICY_URI = ARTIFACTS_DIR\n",
    "\n",
    "print(POLICY_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "66d1d819-0152-437c-aefc-45ffd34d808a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v4/run-20241205-221416/artifacts/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v4/run-20241205-221416/artifacts/fingerprint.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v4/run-20241205-221416/artifacts/policy_specs.pbtxt\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v4/run-20241205-221416/artifacts/saved_model.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v4/run-20241205-221416/artifacts/assets/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/02a-perarm-bandit-v4/run-20241205-221416/artifacts/variables/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $POLICY_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6aad948e-e346-4da3-8cb2-747435c8dc4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f9a39fcae00>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "483f8fa5-cbd1-4e3c-8e62-47f91f42e137",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(), dtype=dtype('int32'), name='action', minimum=0, maximum=1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_policy.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8f658891-bc09-49b8-bc58-000a7926df28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "SKIP_NUM = 10\n",
    "\n",
    "for x in eval_ds.skip(SKIP_NUM).take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    \n",
    "    # global_feat_infer = _get_global_context_features(x)\n",
    "    # arm_feat_infer = _get_per_arm_features(x)\n",
    "    \n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "    \n",
    "    # rewards = _get_rewards(x)\n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "49ce41ed-41b7-404d-9796-1658e7955894",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': <tf.Tensor: shape=(), dtype=float32, numpy=1.0>,\n",
       " 'observation': {'global': <tf.Tensor: shape=(72,), dtype=float32, numpy=\n",
       "array([-0.0099626 , -0.00394415,  0.0197092 ,  0.04250233,  0.00916795,\n",
       "        0.01527121, -0.02332963,  0.00985807, -0.04315094,  0.01647432,\n",
       "       -0.03412988, -0.00587546, -0.02147988, -0.04369628, -0.02493261,\n",
       "        0.00909295, -0.02660922, -0.02011522, -0.00223094, -0.03941519,\n",
       "        0.01177158,  0.0064461 ,  0.03732795, -0.03752469,  0.02025969,\n",
       "        0.00383257, -0.0082325 , -0.02108042, -0.02714737,  0.02911887,\n",
       "       -0.02518604, -0.00977173, -0.03069023, -0.03852297,  0.00844917,\n",
       "        0.04871459, -0.03267304,  0.00152943,  0.04560282,  0.03741708,\n",
       "       -0.04212917, -0.04051284,  0.04321044,  0.01029409,  0.02462873,\n",
       "       -0.00252813,  0.04009459,  0.04178102, -0.03472944, -0.0116804 ,\n",
       "       -0.0213201 ,  0.04594301,  0.04685979, -0.01410444, -0.03354567,\n",
       "       -0.02353553,  0.03010169,  0.01883814, -0.0320617 ,  0.03663448,\n",
       "        0.04131671,  0.04976361, -0.02244846, -0.0043745 ,  0.03951984,\n",
       "        0.04145856,  0.02603433, -0.04243596, -0.00947043,  0.01181472,\n",
       "       -0.03668901,  0.04640496], dtype=float32)>,\n",
       "                 'per_arm': <tf.Tensor: shape=(2, 64), dtype=float32, numpy=\n",
       "array([[-0.00051674,  0.01867915, -0.02930391,  0.03801186,  0.04534866,\n",
       "        -0.02285298,  0.03548386,  0.02481313,  0.04383267, -0.02538759,\n",
       "         0.04284595, -0.03305705, -0.02714789, -0.04774402, -0.02002913,\n",
       "         0.02649121, -0.02652257,  0.02551811, -0.0148774 , -0.04432839,\n",
       "        -0.00508779,  0.00899891,  0.0362381 , -0.02512401,  0.0362133 ,\n",
       "         0.01282996,  0.01314238, -0.00894414,  0.01908514, -0.01679073,\n",
       "         0.00367063, -0.009486  ,  0.0852033 ,  0.0015633 ,  0.02030128,\n",
       "        -0.1251823 , -0.04537314,  0.12187943, -0.02500877, -0.09922382,\n",
       "         0.11031017,  0.13187413, -0.10083769,  0.09931462,  0.07289018,\n",
       "        -0.05859296,  0.14690402,  0.08254956,  0.02213715, -0.03855956,\n",
       "         0.031966  ,  0.02905133, -0.00494854, -0.02763722, -0.00502845,\n",
       "        -0.01325263, -0.03824131, -0.04149419,  0.02147027, -0.03892509,\n",
       "         0.0386116 , -0.0261461 , -0.02841913, -0.03562253],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ]],\n",
       "      dtype=float32)>},\n",
       " 'reward': <tf.Tensor: shape=(), dtype=float32, numpy=3.0>,\n",
       " 'step_type': <tf.Tensor: shape=(), dtype=int32, numpy=0>})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectory_step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f515fcd0-2228-4f68-9ef9-665ce1fc3fb2",
   "metadata": {},
   "source": [
    "### view prediction response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6af4c297-d2e8-4f7b-bed5-e1da997dfe34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([2.1573486, 1.8796222], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=array([2.1573486, 1.8796222], dtype=float32), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=array([-0.00051674,  0.01867915, -0.02930391,  0.03801186,  0.04534866,\n",
       "       -0.02285298,  0.03548386,  0.02481313,  0.04383267, -0.02538759,\n",
       "        0.04284595, -0.03305705, -0.02714789, -0.04774402, -0.02002913,\n",
       "        0.02649121, -0.02652257,  0.02551811, -0.0148774 , -0.04432839,\n",
       "       -0.00508779,  0.00899891,  0.0362381 , -0.02512401,  0.0362133 ,\n",
       "        0.01282996,  0.01314238, -0.00894414,  0.01908514, -0.01679073,\n",
       "        0.00367063, -0.009486  ,  0.0852033 ,  0.0015633 ,  0.02030128,\n",
       "       -0.1251823 , -0.04537314,  0.12187943, -0.02500877, -0.09922382,\n",
       "        0.11031017,  0.13187413, -0.10083769,  0.09931462,  0.07289018,\n",
       "       -0.05859296,  0.14690402,  0.08254956,  0.02213715, -0.03855956,\n",
       "        0.031966  ,  0.02905133, -0.00494854, -0.02763722, -0.00502845,\n",
       "       -0.01325263, -0.03824131, -0.04149419,  0.02147027, -0.03892509,\n",
       "        0.0386116 , -0.0261461 , -0.02841913, -0.03562253], dtype=float32)))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd58d4b-6749-4177-8342-83ee969408c9",
   "metadata": {},
   "source": [
    "#### chosen action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d49adbbb-f747-4e4c-b82d-df88373c644f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0, dtype=int32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd12013-1d12-4197-8254-cef9138df42c",
   "metadata": {},
   "source": [
    "#### Per Arm Policy Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d6126290-546b-4702-8a1e-91f18adb05c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([2.1573486, 1.8796222], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=array([2.1573486, 1.8796222], dtype=float32), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=array([-0.00051674,  0.01867915, -0.02930391,  0.03801186,  0.04534866,\n",
       "       -0.02285298,  0.03548386,  0.02481313,  0.04383267, -0.02538759,\n",
       "        0.04284595, -0.03305705, -0.02714789, -0.04774402, -0.02002913,\n",
       "        0.02649121, -0.02652257,  0.02551811, -0.0148774 , -0.04432839,\n",
       "       -0.00508779,  0.00899891,  0.0362381 , -0.02512401,  0.0362133 ,\n",
       "        0.01282996,  0.01314238, -0.00894414,  0.01908514, -0.01679073,\n",
       "        0.00367063, -0.009486  ,  0.0852033 ,  0.0015633 ,  0.02030128,\n",
       "       -0.1251823 , -0.04537314,  0.12187943, -0.02500877, -0.09922382,\n",
       "        0.11031017,  0.13187413, -0.10083769,  0.09931462,  0.07289018,\n",
       "       -0.05859296,  0.14690402,  0.08254956,  0.02213715, -0.03855956,\n",
       "        0.031966  ,  0.02905133, -0.00494854, -0.02763722, -0.00502845,\n",
       "       -0.01325263, -0.03824131, -0.04149419,  0.02147027, -0.03892509,\n",
       "        0.0386116 , -0.0261461 , -0.02841913, -0.03562253], dtype=float32))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f66961-ebb5-4ae5-8e6f-ad73114d8353",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
