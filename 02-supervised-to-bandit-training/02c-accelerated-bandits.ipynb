{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e406936-2fb6-4a23-a6dd-e51977dc5ee2",
   "metadata": {},
   "source": [
    "# Using GPUs & TPUs with TF-Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5219324-2f52-41a5-b36a-03958f224caf",
   "metadata": {},
   "source": [
    "### Profile in-notebook training\n",
    "\n",
    "> Note: this notebook will only be useful if you have an accelerator (GPU or TPU) attached to the instance.\n",
    "\n",
    "#### Goals\n",
    "\n",
    "* Use the [TensorBoard Profiler](https://www.tensorflow.org/guide/profiler) to profile the RL training job, and compare this to other ML training jobs\n",
    "* Visualize information such as operation statistics on different devices, tracing, etc. \n",
    "* Discuss these performance characteristics with respect to decisions in the code base (e.g., the structure of the Agent class), the use of TF helpers like `@tf.function`, and the order of operations in the input data pipeline\n",
    "\n",
    "**Why?**\n",
    "* Accelerators like GPUs and TPUs are certainly advantageous, but they are also the most expensive component(s) of a training job\n",
    "* Before scaling to a full training job, it's best to make sure we are fully utilizing the chosen device(s), and doing this in-notebook can quickly help uncover any red flags \n",
    "\n",
    "We'll mainly look to address any bottlenecks in the input pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965670ad-987d-401e-aeca-f0492a52dbea",
   "metadata": {},
   "source": [
    "## Load notebook config\n",
    "\n",
    "* use the prefix defined in `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09b8d292-a86a-4c1c-9b22-244b0d28dc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "VERSION        = \"v2\"                       # TODO\n",
    "PREFIX         = f'rec-bandits-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c137c648-e01c-4288-900c-608bd1f7bdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"rec-bandits-v2\"\n",
      "VERSION                  = \"v2\"\n",
      "\n",
      "BUCKET_NAME              = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_NAME    = \"mvlens_rec_bandits_v2\"\n",
      "BIGQUERY_TABLE_NAME      = \"training_dataset\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-rec-bandits-v2\"\n",
      "\n",
      "DOCKERNAME_01            = \"Dockerfile_train_my_perarm_env\"\n",
      "IMAGE_NAME_01            = \"train-my-perarm-env-v2\"\n",
      "IMAGE_URI_01             = \"gcr.io/hybrid-vertex/train-my-perarm-env-v2\"\n",
      "\n",
      "DOCKERNAME_02            = \"Dockerfile_perarm_feats\"\n",
      "IMAGE_NAME_02            = \"train-perarm-feats-v2\"\n",
      "IMAGE_URI_02             = \"gcr.io/hybrid-vertex/train-perarm-feats-v2\"\n",
      "\n",
      "DOCKERNAME_03            = \"Dockerfile_ranking_bandit\"\n",
      "IMAGE_NAME_03            = \"train-rank-bandit-v2\"\n",
      "IMAGE_URI_03             = \"gcr.io/hybrid-vertex/train-rank-bandit-v2\"\n",
      "\n",
      "DOCKERNAME_04            = \"Dockerfile_train_bandit_e2e\"\n",
      "IMAGE_NAME_04            = \"train-mab-e2e-v2\"\n",
      "IMAGE_URI_04             = \"gcr.io/hybrid-vertex/train-mab-e2e-v2\"\n",
      "\n",
      "DOCKERNAME_04_pred       = \"Dockerfile_pred_bandit_e2e\"\n",
      "IMAGE_NAME_04_pred       = \"pred-mab-e2e-v2\"\n",
      "IMAGE_URI_04_pred        = \"gcr.io/hybrid-vertex/pred-mab-e2e-v2\"\n",
      "\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/local_docker_tfa\"\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd20dda8-6c27-4690-9981-59c251dc602b",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39c34db9-39cf-4abe-b2c5-ade744338620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wrapt\n",
    "\n",
    "wrapt.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e043029b-7540-49e2-a646-9e0e4f60ad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37bc712f-c7d9-442a-ad92-9d865fa4faab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from collections import defaultdict\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pickle as pkl\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud import storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.metrics import tf_metrics\n",
    "\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent\n",
    "from tf_agents.bandits.agents import neural_linucb_agent\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.bandits.policies import policy_utilities\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.specs import array_spec\n",
    "\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.train.utils import spec_utils\n",
    "from tf_agents.train.utils import strategy_utils\n",
    "from tf_agents.train.utils import train_utils as tfa_train_utils\n",
    "from tf_agents.utils import common\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# this repo\n",
    "from src import train_utils as train_utils\n",
    "from src import reward_factory as reward_factory\n",
    "from src.data import data_utils as data_utils\n",
    "from src.data import data_config as data_config\n",
    "from src.trainer import train_perarm as train_perarm\n",
    "from src.networks import encoding_network as emb_features\n",
    "from src.agents import agent_factory as agent_factory\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03eb0137-aff7-43f3-929b-03568d4cf287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2522f6a-3826-4509-bd9b-f878c74ca8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "865d4b19-a078-44d3-b0bd-f407a16f6a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "vertex_ai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8857b7-1f7b-4bbf-8637-1bbff7ab8af1",
   "metadata": {},
   "source": [
    "## Specify dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb00b2dc-cef0-42d2-8e8f-82289f874bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCS_DATA_PATH: gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/mv_b128_g12_a16/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/mv_b128_g12_a16_v4/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/mv_b128_g12_a16_v5/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/train/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/val/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/vocabs/\n"
     ]
    }
   ],
   "source": [
    "EXAMPLE_GEN_GCS_PATH = data_config.EXAMPLE_GEN_GCS_PATH\n",
    "GCS_DATA_PATH = f\"{BUCKET_URI}/{EXAMPLE_GEN_GCS_PATH}\"\n",
    "\n",
    "print(f\"GCS_DATA_PATH: {GCS_DATA_PATH}\")\n",
    "\n",
    "!gsutil ls $GCS_DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e75a40f-00ca-4bf9-93f8-063a1056ba48",
   "metadata": {},
   "source": [
    "### Generate Vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa227f5c-364b-4488-b65f-617a3a80cf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab...\n",
      "Downloaded vocab from: gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/vocabs/vocab_dict.pkl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{EXAMPLE_GEN_GCS_PATH}/vocabs/{VOCAB_FILENAME}'\n",
    "print(f\"Downloading vocab...\")\n",
    "\n",
    "os.system(f'gsutil -q cp {EXISTING_VOCAB_FILE} .')\n",
    "print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "vocab_dict = pkl.load(filehandler)\n",
    "filehandler.close()\n",
    "\n",
    "# for key in vocab_dict.keys():\n",
    "#     pprint(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef26da66-7284-4b5e-82cd-f261400726aa",
   "metadata": {},
   "source": [
    "### train config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e71482f-b262-46f7-9bd2-c492b7df5189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_OOV_BUCKETS        : 1\n",
      "GLOBAL_EMBEDDING_SIZE  : 12\n",
      "MV_EMBEDDING_SIZE      : 16\n",
      "EXPECTED_GLOBAL_DIM    : 72\n",
      "EXPECTED_PER_ARM_DIM   : 64\n",
      "EXPECTED_GLOBAL_LAYERS : [72, 36, 18]\n",
      "EXPECTED_ARM_LAYERS    : [64, 32, 16]\n",
      "EXPECTED_COMMON_LAYERS : [34, 8]\n"
     ]
    }
   ],
   "source": [
    "NUM_OOV_BUCKETS       = 1\n",
    "GLOBAL_EMBEDDING_SIZE = 12\n",
    "MV_EMBEDDING_SIZE     = 16 #32\n",
    "\n",
    "NUM_GLOBAL_FEATURES   = len(data_utils.USER_FEATURE_NAMES)     # 6\n",
    "NUM_ARM_FEATURES      = len(data_utils.MOVIE_FEATURE_NAMES)    # 5\n",
    "\n",
    "EXPECTED_GLOBAL_DIM   = GLOBAL_EMBEDDING_SIZE * NUM_GLOBAL_FEATURES\n",
    "EXPECTED_PER_ARM_DIM  = MV_EMBEDDING_SIZE * NUM_ARM_FEATURES\n",
    "\n",
    "EXPECTED_GLOBAL_LAYERS   = [\n",
    "    EXPECTED_GLOBAL_DIM,\n",
    "    int(EXPECTED_GLOBAL_DIM/2),\n",
    "    int(EXPECTED_GLOBAL_DIM/4)\n",
    "]\n",
    "EXPECTED_ARM_LAYERS      = [\n",
    "    EXPECTED_PER_ARM_DIM,\n",
    "    int(EXPECTED_PER_ARM_DIM/2),\n",
    "    int(EXPECTED_PER_ARM_DIM/4)\n",
    "]\n",
    "EXPECTED_FIRST_COMMON_LAYER = EXPECTED_GLOBAL_LAYERS[-1] + EXPECTED_ARM_LAYERS[-1]\n",
    "EXPECTED_COMMON_LAYERS = [\n",
    "    int(EXPECTED_FIRST_COMMON_LAYER),\n",
    "    # int(EXPECTED_FIRST_COMMON_LAYER/2),\n",
    "    int(EXPECTED_FIRST_COMMON_LAYER/4)\n",
    "]\n",
    "\n",
    "print(f\"NUM_OOV_BUCKETS        : {NUM_OOV_BUCKETS}\")\n",
    "print(f\"GLOBAL_EMBEDDING_SIZE  : {GLOBAL_EMBEDDING_SIZE}\")\n",
    "print(f\"MV_EMBEDDING_SIZE      : {MV_EMBEDDING_SIZE}\")\n",
    "print(f\"EXPECTED_GLOBAL_DIM    : {EXPECTED_GLOBAL_DIM}\")\n",
    "print(f\"EXPECTED_PER_ARM_DIM   : {EXPECTED_PER_ARM_DIM}\")\n",
    "print(f\"EXPECTED_GLOBAL_LAYERS : {EXPECTED_GLOBAL_LAYERS}\")\n",
    "print(f\"EXPECTED_ARM_LAYERS    : {EXPECTED_ARM_LAYERS}\")\n",
    "print(f\"EXPECTED_COMMON_LAYERS : {EXPECTED_COMMON_LAYERS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0e134ff-f712-462c-aeab-55a6e3517c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE      : 128\n",
      "EVAL_BATCH_SIZE : 1\n",
      "NUM_ACTIONS     : 2\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE             = 128\n",
    "EVAL_BATCH_SIZE        = 1\n",
    "NUM_ACTIONS            = 2 \n",
    "#this is kinda deceptive - \n",
    "#our approach is to learn by \"flashing\" one movie rating at a time per user context. \n",
    "#The n_actions = show/don't show the movie with one degree of freedom (n-1)\n",
    "\n",
    "print(f\"BATCH_SIZE      : {BATCH_SIZE}\")\n",
    "print(f\"EVAL_BATCH_SIZE : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"NUM_ACTIONS     : {NUM_ACTIONS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99e98fb-9f15-4220-a00a-9b501929d672",
   "metadata": {},
   "source": [
    "#### confirm GLOBAL and PER_ARM DIMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d691a77f-3c1f-4d0d-8527-e2a4a27f9f7f",
   "metadata": {},
   "source": [
    "**we only need a subset of data for profiling!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e947733-3785-48e0-ab99-690090df58e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = \"train\" # \"train\" | \"val\"\n",
    "\n",
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{EXAMPLE_GEN_GCS_PATH}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "train_files = train_files[:3]\n",
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "train_dataset = train_dataset.map(data_utils._parse_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09f19f54-30e0-4e28-b49a-8e716e210bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target_movie_genres': <tf.Tensor: shape=(1, 10), dtype=string, numpy=\n",
       " array([[b'Drama', b'UNK', b'UNK', b'UNK', b'UNK', b'UNK', b'UNK', b'UNK',\n",
       "         b'UNK', b'UNK']], dtype=object)>,\n",
       " 'target_movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'1775'], dtype=object)>,\n",
       " 'target_movie_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>,\n",
       " 'target_movie_title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Live Flesh (1997)'], dtype=object)>,\n",
       " 'target_movie_year': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1997])>,\n",
       " 'target_rating_timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([974612615])>,\n",
       " 'user_age': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([50])>,\n",
       " 'user_gender': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'M'], dtype=object)>,\n",
       " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'2173'], dtype=object)>,\n",
       " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'programmer'], dtype=object)>,\n",
       " 'user_zip_code': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'87505'], dtype=object)>}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    \n",
    "    iterator = iter(train_dataset.batch(1))\n",
    "    data = next(iterator)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "165119f6-8f93-4188-a027-64dd0323f2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.networks.encoding_network.EmbeddingModel at 0x7f0ed5efb670>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs = emb_features.EmbeddingModel(\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    "    max_genre_length = data_config.MAX_GENRE_LENGTH\n",
    ")\n",
    "\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c93478fd-8ec0-4cb6-bcdf-54cd434a43a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL_DIM: 72\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 72), dtype=float32, numpy=\n",
       "array([[-0.00220969, -0.01018505,  0.03136306, -0.03691041,  0.0088677 ,\n",
       "        -0.01294257,  0.02216968,  0.03370644, -0.04281315, -0.04963579,\n",
       "        -0.00932394, -0.03629516, -0.01433527,  0.04646407, -0.01049136,\n",
       "         0.03159623,  0.00824474,  0.02213852, -0.04088575,  0.04068065,\n",
       "        -0.04546126, -0.04512074, -0.04038326, -0.00164672,  0.04483819,\n",
       "        -0.02248036,  0.00616931,  0.02903417, -0.0345687 ,  0.00898182,\n",
       "        -0.02653583, -0.03184617, -0.01271646, -0.02575951, -0.02175512,\n",
       "        -0.02507622, -0.02845078,  0.02747995, -0.02340014,  0.00135168,\n",
       "         0.00598501, -0.03019683,  0.01175339, -0.03679283, -0.01561902,\n",
       "         0.0294814 ,  0.04204804,  0.03707682, -0.01908903, -0.02194713,\n",
       "        -0.02616794,  0.02912897,  0.01162267,  0.01644954,  0.01413251,\n",
       "        -0.04123377, -0.00247125, -0.04864487, -0.04342648,  0.02916935,\n",
       "         0.02900752, -0.00703911,  0.03902322,  0.0445024 , -0.02140472,\n",
       "         0.03572497,  0.04844503, -0.00204841, -0.04785203,  0.03163309,\n",
       "         0.01563904, -0.04808187]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_globals = embs._get_global_context_features(data)\n",
    "\n",
    "GLOBAL_DIM = test_globals.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"GLOBAL_DIM: {GLOBAL_DIM}\")\n",
    "\n",
    "test_globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a47b5c29-ecdf-458f-8068-5279e0fee08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER_ARM_DIM: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 64), dtype=float32, numpy=\n",
       "array([[-0.00312338,  0.00774918,  0.00215518, -0.03376938, -0.01384886,\n",
       "        -0.00552088, -0.02043545, -0.0337787 , -0.04608624,  0.02826986,\n",
       "        -0.03434776, -0.03464084,  0.00946363, -0.02597234, -0.04594671,\n",
       "        -0.01866   ,  0.0047385 , -0.03076395, -0.04440791,  0.03802906,\n",
       "        -0.03064857,  0.03217075,  0.01391791,  0.02225424,  0.00942134,\n",
       "        -0.01371497, -0.00309979, -0.02641685, -0.027082  ,  0.03396977,\n",
       "         0.0128768 , -0.00965741,  0.04813839, -0.04599638,  0.04745925,\n",
       "        -0.03878559,  0.03860198, -0.03012933, -0.02489975,  0.00726052,\n",
       "        -0.03632771,  0.03394934,  0.02678188, -0.00469298, -0.02702544,\n",
       "        -0.00903589, -0.04123338,  0.03622668,  0.21292283, -0.12284189,\n",
       "        -0.03208231,  0.24443881, -0.06082946,  0.12944238, -0.2139914 ,\n",
       "         0.22663778, -0.06235003,  0.08919692,  0.23596717,  0.24711834,\n",
       "        -0.03020471,  0.16739988,  0.23102047, -0.09080356]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arms = embs._get_per_arm_features(data)\n",
    "\n",
    "PER_ARM_DIM = test_arms.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"PER_ARM_DIM: {PER_ARM_DIM}\")\n",
    "\n",
    "test_arms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d59ad1-e850-4bb3-ae4a-94efcbb89c9b",
   "metadata": {},
   "source": [
    "### TensorSpecs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc226a9-c5db-4d1e-a879-4e23248cb17a",
   "metadata": {},
   "source": [
    "#### Observation Spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f03d7f8d-a168-4e47-92f1-5242fc723599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(72,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_spec = {\n",
    "    'global': tf.TensorSpec([GLOBAL_DIM], tf.float32),\n",
    "    'per_arm': tf.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32) #excluding action dim here\n",
    "}\n",
    "observation_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db4eae7-e7a5-4f72-bd69-e88681e9438e",
   "metadata": {},
   "source": [
    "#### Action Spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b927e6a2-d01c-4e9b-866f-9afaba5bb795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=[], \n",
    "    dtype=tf.int32,\n",
    "    minimum=tf.constant(0),            \n",
    "    maximum=NUM_ACTIONS-1, # n degrees of freedom and will dictate the expected mean reward spec shape\n",
    "    # name=\"action_spec\"\n",
    ")\n",
    "\n",
    "action_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa475f6d-b204-4efc-9df7-65293109f830",
   "metadata": {},
   "source": [
    "#### TimeStep Spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd146ddd-0bf6-47c8-baf9-a81633909211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'global': TensorSpec(shape=(72,), dtype=tf.float32, name=None),\n",
       "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec = ts.time_step_spec(\n",
    "    observation_spec = observation_spec, \n",
    "    # reward_spec = _reward_spec\n",
    ")\n",
    "time_step_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff14eae-f17b-461b-800d-3b6de70a73ba",
   "metadata": {},
   "source": [
    "#### Reward Spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf73029c-7919-4852-ac86-030f7ccd2b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.specs import array_spec\n",
    "\n",
    "reward_spec = {\n",
    "    \"reward\": array_spec.ArraySpec(shape=[BATCH_SIZE], dtype=np.float32, name=\"reward\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fc31d36-ec40-4260-a00a-02d3bb1c192e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reward': TensorSpec(shape=(128,), dtype=tf.float32, name='reward')}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_tensor_spec = train_utils.from_spec(reward_spec)\n",
    "reward_tensor_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f73646-b69e-4f1a-960b-055602fd36fa",
   "metadata": {},
   "source": [
    "## Distribution strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226a2cd7-5484-4db2-b7ac-a57a61a452f5",
   "metadata": {},
   "source": [
    "Use `strategy_utils` to generate a strategy. Under the hood, passing the parameter:\n",
    "\n",
    "* `use_gpu = False` returns `tf.distribute.get_strategy()`, which uses CPU\n",
    "* `use_gpu = True` returns `tf.distribute.MirroredStrategy()`, which uses all GPUs that are visible to TensorFlow on one machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2aedc5c8-788e-443b-994b-3c4021a273a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.distribute.mirrored_strategy.MirroredStrategy at 0x7f0e17b83160>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_gpu = True\n",
    "use_tpu = False\n",
    "\n",
    "distribution_strategy = strategy_utils.get_strategy(tpu=use_tpu, use_gpu=use_gpu)\n",
    "distribution_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "781e1b7d-396b-48df-8657-71c8daf4e6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_REPLICAS = distribution_strategy.num_replicas_in_sync\n",
    "NUM_REPLICAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86791ffd-ae3c-4558-8a08-335abb242a9c",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d8ff74e-fcdd-4523-838d-68e399bbb39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'common_layers': [34, 8],\n",
      " 'epsilon': 0.01,\n",
      " 'eval_batch_size': 1,\n",
      " 'global_layers': [72, 36, 18],\n",
      " 'learning_rate': 0.05,\n",
      " 'model_type': 'epsGreedy',\n",
      " 'network_type': 'commontower',\n",
      " 'num_actions': 2,\n",
      " 'num_eval_steps': 10000,\n",
      " 'per_arm_layers': [64, 32, 16]}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Agents\n",
    "# ================================\n",
    "AGENT_TYPE      = 'epsGreedy' # 'LinUCB' | 'LinTS |, 'epsGreedy' | 'NeuralLinUCB'\n",
    "\n",
    "# Parameters for linear agents (LinUCB and LinTS).\n",
    "AGENT_ALPHA     = 0.1\n",
    "\n",
    "# Parameters for neural agents (NeuralEpsGreedy and NerualLinUCB).\n",
    "EPSILON         = 0.01\n",
    "LR              = 0.05\n",
    "\n",
    "# Parameters for NeuralLinUCB\n",
    "ENCODING_DIM    = 1\n",
    "EPS_PHASE_STEPS = 1000\n",
    "NUM_EVAL_STEPS  = 10000\n",
    "\n",
    "# ==================================\n",
    "# Agent's Preprocess Network layers\n",
    "# ==================================\n",
    "NETWORK_TYPE       = \"commontower\" # 'dotproduct' | 'dotproduct'\n",
    "\n",
    "GLOBAL_LAYERS      = [GLOBAL_DIM, int(GLOBAL_DIM/2), int(GLOBAL_DIM/4)]\n",
    "ARM_LAYERS         = [PER_ARM_DIM, int(PER_ARM_DIM/2), int(PER_ARM_DIM/4)]\n",
    "FIRST_COMMON_LAYER = GLOBAL_LAYERS[-1] + ARM_LAYERS[-1] # min(GLOBAL_LAYERS[-1], ARM_LAYERS[-1])\n",
    "\n",
    "COMMON_LAYERS = [\n",
    "    int(FIRST_COMMON_LAYER), \n",
    "    # int(FIRST_COMMON_LAYER/2),\n",
    "    int(FIRST_COMMON_LAYER/4)\n",
    "]\n",
    "\n",
    "if AGENT_TYPE == 'NeuralLinUCB':\n",
    "    NETWORK_TYPE = 'commontower'\n",
    "    ENCODING_DIM = COMMON_LAYERS[-1]\n",
    "    \n",
    "if NETWORK_TYPE == 'dotproduct':\n",
    "    assert GLOBAL_LAYERS[0] == ARM_LAYERS[0]\n",
    "\n",
    "HPARAMS = {\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"eval_batch_size\" : EVAL_BATCH_SIZE,\n",
    "    \"num_actions\": NUM_ACTIONS,\n",
    "    \"model_type\": AGENT_TYPE,\n",
    "    \"network_type\": NETWORK_TYPE,\n",
    "    \"global_layers\": GLOBAL_LAYERS,\n",
    "    \"per_arm_layers\": ARM_LAYERS,\n",
    "    \"common_layers\": COMMON_LAYERS,\n",
    "    \"learning_rate\": LR,\n",
    "    \"epsilon\": EPSILON,\n",
    "    \"num_eval_steps\": NUM_EVAL_STEPS,\n",
    "}\n",
    "pprint(HPARAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c27bf4-7d1d-485c-9644-4c0d60d77a83",
   "metadata": {},
   "source": [
    "### trajectory function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5338c598-1c22-409b-8f67-b4a906d579ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with distribution_strategy.scope():\n",
    "    \n",
    "    embs = emb_features.EmbeddingModel(\n",
    "        vocab_dict = vocab_dict,\n",
    "        num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "        global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "        mv_emb_size = MV_EMBEDDING_SIZE,\n",
    "        max_genre_length = data_config.MAX_GENRE_LENGTH\n",
    "    )\n",
    "    \n",
    "    def _trajectory_fn(element): # hparams\n",
    "    \n",
    "        \"\"\"Converts a dataset element into a trajectory.\"\"\"\n",
    "        global_features = embs._get_global_context_features(element)\n",
    "        arm_features = embs._get_per_arm_features(element)\n",
    "\n",
    "        # Adds a time dimension.\n",
    "        arm_features = train_utils._add_outer_dimension(arm_features)\n",
    "\n",
    "        # obs spec\n",
    "        observation = {\n",
    "            bandit_spec_utils.GLOBAL_FEATURE_KEY:\n",
    "                train_utils._add_outer_dimension(global_features),\n",
    "        }\n",
    "\n",
    "        reward = train_utils._add_outer_dimension(reward_factory._get_rewards(element))\n",
    "\n",
    "        # To emit the predicted rewards in policy_info, we need to create dummy\n",
    "        # rewards to match the definition in TensorSpec for the ones specified in\n",
    "        # emit_policy_info set.\n",
    "        dummy_rewards = tf.zeros([HPARAMS['batch_size'], 1, HPARAMS['num_actions']])\n",
    "        policy_info = policy_utilities.PerArmPolicyInfo(\n",
    "            chosen_arm_features=arm_features,\n",
    "            # Pass dummy mean rewards here to match the model_spec for emitting\n",
    "            # mean rewards in policy info\n",
    "            predicted_rewards_mean=dummy_rewards,\n",
    "            bandit_policy_type=tf.zeros([HPARAMS['batch_size'], 1, 1], dtype=tf.int32)\n",
    "            # policy_utilities.create_bandit_policy_type_tensor_spec(shape=[1]) \n",
    "            # policy_utilities.BanditPolicyType.GREEDY\n",
    "            # tf.zeros([batch_size, 1, 1], dtype=tf.int32)\n",
    "        )\n",
    "\n",
    "        if HPARAMS['model_type'] == 'neural_ucb':\n",
    "            policy_info = policy_info._replace(\n",
    "                predicted_rewards_optimistic=dummy_rewards\n",
    "            )\n",
    "\n",
    "        return trajectory.single_step(\n",
    "            observation=observation,\n",
    "            action=tf.zeros_like(\n",
    "                reward, \n",
    "                dtype=tf.int32\n",
    "            ),  # Arm features are copied from policy info, put dummy zeros here\n",
    "            policy_info=policy_info,\n",
    "            reward=reward,\n",
    "            discount=tf.zeros_like(reward)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df6c2218-ebef-4bb6-822c-9a67ee9b8f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"test_traj_v1.action.shape: {test_traj_v1.action.shape}\")\n",
    "# print(f\"test_traj_v1.discount.shape: {test_traj_v1.discount.shape}\") \n",
    "# print(f\"test_traj_v1.observation.shape: {test_traj_v1.observation['global'].shape}\") \n",
    "# print(f\"test_traj_v1.reward.shape: {test_traj_v1.reward.shape}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a634d31-306f-445c-8d34-e431ee5839a2",
   "metadata": {},
   "source": [
    "## Create Agent\n",
    "\n",
    "> Note: writting distributions and historgrams of gradients and variables will negatively impact training performance\n",
    "\n",
    "* set `summarize_grads_and_vars = False` for best training performance\n",
    "* keep `debug_summaries = True` to track training metrics (e.g., loss / regret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5cd7b0e8-93aa-4846-b532-7b62dee81f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: NeuralEpsGreedyAgent\n",
      "NETWORK_TYPE: commontower\n"
     ]
    }
   ],
   "source": [
    "with distribution_strategy.scope():\n",
    "    \n",
    "    global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "    \n",
    "    agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "        agent_type = AGENT_TYPE,\n",
    "        network_type = NETWORK_TYPE,\n",
    "        time_step_spec = time_step_spec,\n",
    "        action_spec = action_spec,\n",
    "        observation_spec=observation_spec,\n",
    "        global_layers = GLOBAL_LAYERS,\n",
    "        arm_layers = ARM_LAYERS,\n",
    "        common_layers = COMMON_LAYERS,\n",
    "        agent_alpha = AGENT_ALPHA,\n",
    "        learning_rate = LR,\n",
    "        epsilon = EPSILON,\n",
    "        train_step_counter = global_step,\n",
    "        output_dim = ENCODING_DIM,\n",
    "        eps_phase_steps = EPS_PHASE_STEPS,\n",
    "        summarize_grads_and_vars = False,\n",
    "        debug_summaries = True\n",
    "    )\n",
    "    \n",
    "    agent.initialize()\n",
    "\n",
    "print(f\"Agent: {agent.name}\")\n",
    "\n",
    "if NETWORK_TYPE:\n",
    "    print(f\"NETWORK_TYPE: {NETWORK_TYPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3719520d-4eaa-4739-b0c3-b1e521afa234",
   "metadata": {},
   "source": [
    "### GPU stuff\n",
    "\n",
    "* `TF_GPU_THREAD_MODE=gpu_private` ensures that GPU kernels are launched from their own dedicated threads, and don't get queued behind tf.data work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91c4c959-03a0-46d1-b02c-09153820b192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "TF_GPU_THREAD_COUNT   = '1'      # '1' | '4' | '8'\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['TF_GPU_THREAD_MODE']='gpu_private'\n",
    "os.environ['TF_GPU_THREAD_COUNT']=f\"{TF_GPU_THREAD_COUNT}\"\n",
    "os.environ['TF_GPU_ALLOCATOR']='cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293aef61-3336-4041-befa-27cadbd756fa",
   "metadata": {},
   "source": [
    "## Vertex Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6037dde7-e446-40b3-8c9d-5913b6139147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : 02-acc-bandit-v1\n",
      "RUN_NAME          : run-20240313-201026\n",
      "\n",
      "CHECKPT_DIR       : gs://rec-bandits-v2-hybrid-vertex-bucket/02-acc-bandit-v1/chkpoint\n",
      "BASE_OUTPUT_DIR   : gs://rec-bandits-v2-hybrid-vertex-bucket/02-acc-bandit-v1/run-20240313-201026\n",
      "LOG_DIR           : gs://rec-bandits-v2-hybrid-vertex-bucket/02-acc-bandit-v1/run-20240313-201026/logs\n",
      "ROOT_DIR          : gs://rec-bandits-v2-hybrid-vertex-bucket/02-acc-bandit-v1/run-20240313-201026/root\n",
      "ARTIFACTS_DIR     : gs://rec-bandits-v2-hybrid-vertex-bucket/02-acc-bandit-v1/run-20240313-201026/artifacts\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME   = f'02-acc-bandit-v1' # customize as needed\n",
    "\n",
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "CHECKPT_DIR       = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/chkpoint\"\n",
    "BASE_OUTPUT_DIR   = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}\"\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "vertex_ai.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"CHECKPT_DIR       : {CHECKPT_DIR}\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fd56f4-1cf0-4224-9135-7f0fbe30bc44",
   "metadata": {},
   "source": [
    "### TB Summary writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "033135a5-0fd2-421a-a172-5a15e1e28dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "with distribution_strategy.scope():\n",
    "    train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "        f\"{LOG_DIR}\", flush_millis=10 * 1000\n",
    "    )\n",
    "\n",
    "    train_summary_writer.set_as_default()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2b102e-35c9-4ff3-8ae0-6b15103c27de",
   "metadata": {},
   "source": [
    "## Train loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e68792ed-9b90-47aa-80d8-d190c4580079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_EPOCHS           : 1\n",
      "NUM_ITER_STEPS       : 50\n",
      "STEPS_PER_LOOP       : 1\n",
      "LOG_INTERVAL         : 10\n",
      "CHKPT_INTERVAL       : 1000\n",
      "NUM_EVAL_STEPS       : 100\n",
      "ASYNC_STEPS_PER_LOOP : 1\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS           = 1\n",
    "NUM_ITER_STEPS       = 50\n",
    "STEPS_PER_LOOP       = 1\n",
    "LOG_INTERVAL         = 10\n",
    "CHKPT_INTERVAL       = 1000\n",
    "NUM_EVAL_STEPS       = 100\n",
    "ASYNC_STEPS_PER_LOOP = 1\n",
    "\n",
    "print(f\"NUM_EPOCHS           : {NUM_EPOCHS}\")\n",
    "print(f\"NUM_ITER_STEPS       : {NUM_ITER_STEPS}\")\n",
    "print(f\"STEPS_PER_LOOP       : {STEPS_PER_LOOP}\")\n",
    "print(f\"LOG_INTERVAL         : {LOG_INTERVAL}\")\n",
    "print(f\"CHKPT_INTERVAL       : {CHKPT_INTERVAL}\")\n",
    "print(f\"NUM_EVAL_STEPS       : {NUM_EVAL_STEPS}\")\n",
    "print(f\"ASYNC_STEPS_PER_LOOP : {ASYNC_STEPS_PER_LOOP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef52a68d-d601-4d64-8365-9df5998fae86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6400"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOTAL_TRAIN_TAKE = NUM_ITER_STEPS * HPARAMS['batch_size']\n",
    "TOTAL_TRAIN_TAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c56c7092-b4cb-420c-9b7c-6f1410a740de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distribution_strategy: <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f0e17b83160>\n",
      "number of train_files: 2\n",
      "Inpsecting agent policy from train_peram file...\n",
      "agent.policy: <tf_agents.policies.epsilon_greedy_policy.EpsilonGreedyPolicy object at 0x7f0e177b5a20>\n",
      "Inpsecting agent policy from train_peram file: Complete\n",
      "setting checkpoint_manager: gs://rec-bandits-v2-hybrid-vertex-bucket/02-acc-bandit-v1/chkpoint\n",
      "agent.train_step_counter: 0\n",
      "starting train loop...\n",
      "epoch: 1\n",
      "step = 10: loss = 14.050000190734863\n",
      "step = 20: loss = 2.1700000762939453\n",
      "step = 30: loss = 3.440000057220459\n",
      "step = 40: loss = 1.340000033378601\n",
      "step = 50: loss = 1.1200000047683716\n",
      "runtime_mins: 0\n",
      "saved trained policy to: gs://rec-bandits-v2-hybrid-vertex-bucket/02-acc-bandit-v1/run-20240313-201026/artifacts\n",
      "saved trained policy to: gs://rec-bandits-v2-hybrid-vertex-bucket/02-acc-bandit-v1/chkpoint\n",
      "complete train job in 0 minutes\n"
     ]
    }
   ],
   "source": [
    "#start the timer and training\n",
    "start_time = time.time()\n",
    "\n",
    "# tf.profiler.experimental.start(LOG_DIR, options=profiler_options)\n",
    "metric_results, agent = train_perarm.train_perarm(\n",
    "    agent = agent,\n",
    "    reward_spec = reward_tensor_spec,\n",
    "    epsilon = HPARAMS['epsilon'],\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    num_epochs = NUM_EPOCHS,\n",
    "    num_iterations = NUM_ITER_STEPS,\n",
    "    steps_per_loop = STEPS_PER_LOOP,\n",
    "    num_eval_steps = NUM_EVAL_STEPS,\n",
    "    # data\n",
    "    batch_size = HPARAMS['batch_size'],\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    # functions\n",
    "    _trajectory_fn = _trajectory_fn,\n",
    "    # _run_bandit_eval_fn = _run_bandit_eval,\n",
    "    # train intervals\n",
    "    chkpt_interval = CHKPT_INTERVAL,\n",
    "    log_interval = LOG_INTERVAL,\n",
    "    # dirs\n",
    "    bucket_name = BUCKET_NAME,\n",
    "    data_dir_prefix_path = f\"{EXAMPLE_GEN_GCS_PATH}\",\n",
    "    log_dir = LOG_DIR,\n",
    "    model_dir = ARTIFACTS_DIR,\n",
    "    # root_dir = ROOT_DIR,\n",
    "    chkpoint_dir = CHECKPT_DIR,\n",
    "    async_steps_per_loop = ASYNC_STEPS_PER_LOOP,\n",
    "    resume_training_loops = False,\n",
    "    use_gpu = True,\n",
    "    use_tpu = False,\n",
    "    profiler = True,\n",
    "    global_step = global_step,\n",
    "    total_train_take = TOTAL_TRAIN_TAKE, # TODO - remove?\n",
    "    train_summary_writer = train_summary_writer,\n",
    "    # additional_metrics = metrics,\n",
    "    cache_train_data = False,\n",
    "    strategy = distribution_strategy,\n",
    "    # saver=saver,\n",
    ")\n",
    "# tf.profiler.experimental.stop()\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"complete train job in {runtime_mins} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2e4260-97e3-4ad4-a429-6745f887769b",
   "metadata": {},
   "source": [
    "## Evaluate Train job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "26b0aaf4-3f62-47a3-8cd7-fc729b4128e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1207393"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(metric_results)\n",
    "metric_results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd21d3b0-b922-446f-991b-488149e66938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(metric_results)\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f923259-8cca-4a7b-9e4e-8ec9b543f34a",
   "metadata": {},
   "source": [
    "### GPU profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ba9a3a-bb07-4619-88f0-34cb08fbdad1",
   "metadata": {},
   "source": [
    "#### Load TensorBoard\n",
    "\n",
    "> on the right-hand side, find `PROFILE` in the drop down:\n",
    "\n",
    "<img src=\"imgs/getting_profiler.png\" \n",
    "     align=\"center\" \n",
    "     width=\"850\"\n",
    "     height=\"850\"/>\n",
    "     \n",
    "<!-- tf_vertex_agents/imgs/getting_profiler.png -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1b61b02-8ca0-4d1c-9bf8-4914715611d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://rec-bandits-v2-hybrid-vertex-bucket/02-acc-bandit-v1/run-20240313-201026/logs'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOG_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f03fe778-ebf1-4237-a269-d70639b4f984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known TensorBoard instances:\n",
      "  - port 6006: logdir gs://rec-bandits-v2-hybrid-vertex-bucket/02-big-local-bandits-rec-bandits-v2/run-20240301-042649/logs (started 12 days, 15:36:58 ago; pid 3837675)\n",
      "  - port 6006: logdir gs://rec-bandits-v2-hybrid-vertex-bucket/02x-new-data-loading-v3/run-20240307-012852/logs (started 6 days, 18:43:20 ago; pid 1590886)\n",
      "  - port 6006: logdir gs://rec-bandits-v2-hybrid-vertex-bucket/02b-deep-bandits-rec-bandits-v2/run-20240214-180454/logs (started 28 days, 1:52:50 ago; pid 3029265)\n"
     ]
    }
   ],
   "source": [
    "from tensorboard import notebook\n",
    "notebook.list() # View open TensorBoard instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ae8de567-c152-4deb-99dc-54ed840c9e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e9ba7b2d-3ee7-478a-b634-c809a895103d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-83563ffebcdc71bb\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-83563ffebcdc71bb\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=$LOG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d8a19f-c56e-4176-b29f-b62c1a3979e8",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
