{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385307d6-2058-47ec-8da0-57f7ef5c43d6",
   "metadata": {},
   "source": [
    "# Contextual Multi Armed Bandits with âœ¨Generativeâœ¨ Reward Functions\n",
    "\n",
    "Inspiration from this idea - somewhat of a LLM distillation method:\n",
    "https://arxiv.org/abs/2303.00001\n",
    "\n",
    "Also, for furture work - consider this approach (ReST) \n",
    "\n",
    "https://arxiv.org/abs/2308.08998\n",
    "\n",
    "We will be using LLMs to \"Grow\" the data and reward function, then we will improve using ratings from the user, fine tune LLM and repeat\n",
    "\n",
    "<img src=\"../imgs/rest-method.png\" alt=\"ReST approach for RL\" width=\"400\"/>\n",
    "\n",
    "\n",
    "\n",
    "### Reward Design with Language Models\n",
    "##### Minae Kwon, Sang Michael Xie, Kalesha Bullard, Dorsa Sadigh\n",
    "`Reward design in reinforcement learning (RL) is challenging since specifying human notions of desired behavior may be difficult via reward functions or require many expert demonstrations. Can we instead cheaply design rewards using a natural language interface? This paper explores how to simplify reward design by prompting a large language model (LLM) such as GPT-3 as a proxy reward function, where the user provides a textual prompt containing a few examples (few-shot) or a description (zero-shot) of the desired behavior. Our approach leverages this proxy reward function in an RL framework. Specifically, users specify a prompt once at the beginning of training. During training, the LLM evaluates an RL agent's behavior against the desired behavior described by the prompt and outputs a corresponding reward signal. The RL agent then uses this reward to update its behavior. We evaluate whether our approach can train agents aligned with user objectives in the Ultimatum Game, matrix games, and the DealOrNoDeal negotiation task. In all three tasks, we show that RL agents trained with our framework are well-aligned with the user's objectives and outperform RL agents trained with reward functions learned via supervised learning`\n",
    "\n",
    "In this we will use PALM Text Bison. We will do the following\n",
    "\n",
    "1. Generate \"trajectory\" training examples where we have a batch of n users, shown a randomly selected batch of n_actions movies\n",
    "2. Take the raw textual data of those features and format a prompt asking text bison to rate the movie (float) on a 0-5 rating scale\n",
    "3. These rewards are then used as we generte the reward and update the trajectory\n",
    "4. Either generate the rest of these examples online (suggested for scale), or generate as-you-train\n",
    "5. Create a deep network for an epsilon-greed multi-armed bandit agent to explore/exlpoit the rewards generated by text-bison\n",
    "\n",
    "\n",
    "Future ideas\n",
    "\n",
    "- When tempurature is set to high and/or token count is extended, it can be interesting to see it rationalize the ratings. \n",
    "\n",
    "- Mapreduce multiple prompts with...\n",
    "\n",
    "- Mixture-of-experts approach\n",
    "\n",
    "\n",
    "# Train Bandits with per-arm features\n",
    "\n",
    "**Exploring linear and nonlinear** (e.g., those with neural network-based value functions) bandit methods for recommendations using TF-Agents\n",
    "\n",
    "> Neural linear bandits provide a nice way to leverage the representation power of deep learning and the bandit approach for uncertainty measure and efficient exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fd257-b98b-426a-a2cd-024429b014f1",
   "metadata": {},
   "source": [
    "## Load notebook config\n",
    "\n",
    "* use the prefix defined in `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f39c9d08-d118-4013-a47f-88450f49f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = 'mabv1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908f6b95-b539-4a9f-a836-840d26ea3b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"wortz-project-352116\"\n",
      "PROJECT_NUM              = \"679926387543\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"679926387543-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"mabv1\"\n",
      "VERSION                  = \"v1\"\n",
      "\n",
      "BUCKET_NAME              = \"mabv1-wortz-project-352116-bucket\"\n",
      "BUCKET_URI               = \"gs://mabv1-wortz-project-352116-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://mabv1-wortz-project-352116-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/679926387543/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_ID      = \"wortz-project-352116.movielens_dataset_mabv1\"\n",
      "BIGQUERY_TABLE_ID        = \"wortz-project-352116.movielens_dataset_mabv1.training_dataset\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "REPOSITORY               = \"rl-movielens-mabv1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c690a9-e2bd-4759-ba41-4e2469098aee",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d0dfe4-695c-4dd4-9f24-67f7488ce1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c669f1a1-1af7-4efb-ab2d-6bf3b3847991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tensorflow/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/envs/tensorflow/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/envs/tensorflow/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/envs/tensorflow/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/envs/tensorflow/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/envs/tensorflow/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n",
      "2023-09-01 16:20:35.509213: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "from collections import defaultdict\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pickle as pkl\n",
    "# import torch\n",
    "# from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "#we set mem growth so we only use what gpu is needed - to make room for torch/LLaMA\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \n",
    "gpus\n",
    "\n",
    "# from tf_agents.agents import TFAgent\n",
    "\n",
    "# from tf_agents.bandits.environments import stationary_stochastic_per_arm_py_environment as p_a_env\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "# from tf_agents.drivers import dynamic_step_driver\n",
    "# from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "# from tf_agents.bandits.agents import lin_ucb_agent\n",
    "# from tf_agents.bandits.agents import linear_thompson_sampling_agent as lin_ts_agent\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent\n",
    "from tf_agents.bandits.agents import neural_linucb_agent\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "from tf_agents.bandits.policies import policy_utilities\n",
    "\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# this repo\n",
    "from src.per_arm_rl import data_utils\n",
    "from src.per_arm_rl import data_config\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29e58dd7-ab2b-419f-9771-bf1e98db758b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4969d3e-1fc0-45db-8a69-aa6b342019de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = cuda.get_current_device()\n",
    "# device.reset()\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "274e7f4a-1802-4946-888e-876638f5c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a866b1-85b9-43e6-9546-edfbbf886bce",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd5b953-14c0-42ed-a511-77147a1bc0ac",
   "metadata": {},
   "source": [
    "### Read TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d0157c8-a04c-4dbd-b6d9-a1ede97687a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c934c06-bf08-4c7f-b0cc-0de04ef3515c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://mabv1-wortz-project-352116-bucket/data/train/ml-ratings-100k-train.tfrecord']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPLIT = \"train\" # \"train\" | \"val\"\n",
    "\n",
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7511e4d-bf81-4800-bde7-8b16dec9aeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([35.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'898'], dtype=object)>,\n",
      " 'movie_title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Postman, The (1997)'], dtype=object)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([885409515])>,\n",
      " 'user_gender': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'False'], dtype=object)>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'681'], dtype=object)>,\n",
      " 'user_occupation_label': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([14])>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'marketing'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>,\n",
      " 'user_zip_code': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'97208'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "train_dataset = train_dataset.map(data_utils.parse_tfrecord)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8959967-522e-41c8-9a1b-050ca8bc191f",
   "metadata": {},
   "source": [
    "### get vocab\n",
    "\n",
    "**TODO:** \n",
    "* streamline vocab calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b9169bc-d6dc-497e-9dff-6ebb175282ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE_VOCABS: False\n"
     ]
    }
   ],
   "source": [
    "GENERATE_VOCABS = False\n",
    "print(f\"GENERATE_VOCABS: {GENERATE_VOCABS}\")\n",
    "\n",
    "VOCAB_SUBDIR   = \"vocabs\"\n",
    "VOCAB_FILENAME = \"vocab_dict.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3ccf137-7a72-42e7-aa89-3c81a99cf40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab...\n",
      "Downloaded vocab from: gs://mabv1-wortz-project-352116-bucket/vocabs/vocab_dict.pkl\n",
      "\n",
      "'movie_id'\n",
      "'user_id'\n",
      "'user_occupation_text'\n",
      "'movie_genres'\n",
      "'bucketized_user_age'\n",
      "'max_timestamp'\n",
      "'min_timestamp'\n",
      "'timestamp_buckets'\n"
     ]
    }
   ],
   "source": [
    "if not GENERATE_VOCABS:\n",
    "\n",
    "    EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{VOCAB_SUBDIR}/{VOCAB_FILENAME}'\n",
    "    print(f\"Downloading vocab...\")\n",
    "    \n",
    "    os.system(f'gsutil -q cp {EXISTING_VOCAB_FILE} .')\n",
    "    print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "    filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "    vocab_dict = pkl.load(filehandler)\n",
    "    filehandler.close()\n",
    "    \n",
    "    for key in vocab_dict.keys():\n",
    "        pprint(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccaef62-882a-46ff-a1b1-3837e69fdf74",
   "metadata": {},
   "source": [
    "## helper functions\n",
    "\n",
    "**TODO:**\n",
    "* modularize in a train_utils or similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cba2bb14-bf94-466b-b60f-8c7d96c7aab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_outer_dimension(x):\n",
    "    \"\"\"Adds an extra outer dimension.\"\"\"\n",
    "    if isinstance(x, dict):\n",
    "        for key, value in x.items():\n",
    "            x[key] = tf.expand_dims(value, 1)\n",
    "        return x\n",
    "    return tf.expand_dims(x, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b941063b-ad48-4817-aef0-9afa8a444632",
   "metadata": {},
   "source": [
    "# Multi-Armed Bandits with Per-Arm Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28770b8d-836b-448d-8dd1-203d76fc6d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "\n",
    "nest = tf.nest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138a295-2b0d-4359-8496-af8552ec8cff",
   "metadata": {},
   "source": [
    "## Preprocessing layers for global and arm features\n",
    "\n",
    "The preproccesing layers will ultimately feed the two functions described below, both of which will ultimately feed the `Environment`\n",
    "\n",
    "`global_context_sampling_fn`: \n",
    "* A function that outputs a random 1d array or list of ints or floats\n",
    "* This output is the global context. Its shape and type must be consistent across calls.\n",
    "\n",
    "`arm_context_sampling_fn`: \n",
    "* A function that outputs a random 1 array or list of ints or floats (same type as the output of `global_context_sampling_fn`). * This output is the per-arm context. Its shape must be consistent across calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8d77956-635c-438a-916a-185eec52f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OOV_BUCKETS        = 1\n",
    "GLOBAL_EMBEDDING_SIZE  = 8\n",
    "MV_EMBEDDING_SIZE      = 8 #32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6142e63e-0a20-4d51-997c-7a4733517f7e",
   "metadata": {},
   "source": [
    "### global context (user) features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195acd92-06b6-42e4-bef7-798fd09da856",
   "metadata": {},
   "source": [
    "#### user ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c28e887b-421a-4603-8899-87071056783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_input_layer = tf.keras.Input(\n",
    "    name=\"user_id\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.string\n",
    ")\n",
    "\n",
    "user_id_lookup = tf.keras.layers.StringLookup(\n",
    "    max_tokens=len(vocab_dict['user_id']) + NUM_OOV_BUCKETS,\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    mask_token=None,\n",
    "    vocabulary=vocab_dict['user_id'],\n",
    ")(user_id_input_layer)\n",
    "\n",
    "user_id_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['user_id']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=GLOBAL_EMBEDDING_SIZE\n",
    ")(user_id_lookup)\n",
    "\n",
    "user_id_embedding = tf.reduce_sum(user_id_embedding, axis=-2)\n",
    "\n",
    "# global_inputs.append(user_id_input_layer)\n",
    "# global_features.append(user_id_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d6a0fe7-26cb-4c62-a3ef-17f98e6ccddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'681'], shape=(1,), dtype=string)\n",
      "tf.Tensor(\n",
      "[[ 0.0222747  -0.04024553 -0.02816417 -0.00610999  0.03753108 -0.01307023\n",
      "   0.03419149 -0.00834148]], shape=(1, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_user_id_model = tf.keras.Model(inputs=user_id_input_layer, outputs=user_id_embedding)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(x[\"user_id\"])\n",
    "    print(test_user_id_model(x[\"user_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352d2227-92ec-4386-926f-df2fdb9434ec",
   "metadata": {},
   "source": [
    "#### user AGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70785bf0-5ece-4875-ab72-06d9c45ea9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_age_input_layer = tf.keras.Input(\n",
    "    name=\"bucketized_user_age\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "user_age_lookup = tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=vocab_dict['bucketized_user_age'],\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    oov_value=0,\n",
    ")(user_age_input_layer)\n",
    "\n",
    "user_age_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['bucketized_user_age']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=GLOBAL_EMBEDDING_SIZE\n",
    ")(user_age_lookup)\n",
    "\n",
    "user_age_embedding = tf.reduce_sum(user_age_embedding, axis=-2)\n",
    "\n",
    "# global_inputs.append(user_age_input_layer)\n",
    "# global_features.append(user_age_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e01622a-9418-4ca7-8925-9b0ebef8940e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([35.], shape=(1,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.00625925  0.00503098 -0.03977219 -0.00739773  0.00397869 -0.04399686\n",
      "   0.04580864  0.02182123]], shape=(1, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_user_age_model = tf.keras.Model(inputs=user_age_input_layer, outputs=user_age_embedding)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(x[\"bucketized_user_age\"])\n",
    "    print(test_user_age_model(x[\"bucketized_user_age\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997ffaa8-ca92-4851-b7e3-bb06fba8958b",
   "metadata": {},
   "source": [
    "#### user OCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03e7344d-71fb-423a-89dd-f1abeb270e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_occ_input_layer = tf.keras.Input(\n",
    "    name=\"user_occupation_text\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.string\n",
    ")\n",
    "\n",
    "user_occ_lookup = tf.keras.layers.StringLookup(\n",
    "    max_tokens=len(vocab_dict['user_occupation_text']) + NUM_OOV_BUCKETS,\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    mask_token=None,\n",
    "    vocabulary=vocab_dict['user_occupation_text'],\n",
    ")(user_occ_input_layer)\n",
    "\n",
    "user_occ_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['user_occupation_text']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=GLOBAL_EMBEDDING_SIZE\n",
    ")(user_occ_lookup)\n",
    "\n",
    "user_occ_embedding = tf.reduce_sum(user_occ_embedding, axis=-2)\n",
    "\n",
    "# global_inputs.append(user_occ_input_layer)\n",
    "# global_features.append(user_occ_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39cbbc31-ca43-4f8f-a804-a4b830e99d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'marketing'], shape=(1,), dtype=string)\n",
      "tf.Tensor(\n",
      "[[-0.00013451 -0.04046185  0.04273459  0.02683686  0.02432786  0.00318767\n",
      "   0.00342501  0.00742046]], shape=(1, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_user_occ_model = tf.keras.Model(inputs=user_occ_input_layer, outputs=user_occ_embedding)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(x[\"user_occupation_text\"])\n",
    "    print(test_user_occ_model(x[\"user_occupation_text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee0098-a48a-4de6-88bf-6219ce8c0533",
   "metadata": {},
   "source": [
    "#### user Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61a4e01a-e742-4c68-93a9-aa66eb9a5e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ts_input_layer = tf.keras.Input(\n",
    "    name=\"timestamp\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.int64\n",
    ")\n",
    "\n",
    "user_ts_lookup = tf.keras.layers.Discretization(\n",
    "    vocab_dict['timestamp_buckets'].tolist()\n",
    ")(user_ts_input_layer)\n",
    "\n",
    "user_ts_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['timestamp_buckets'].tolist()) + NUM_OOV_BUCKETS,\n",
    "    output_dim=GLOBAL_EMBEDDING_SIZE\n",
    ")(user_ts_lookup)\n",
    "\n",
    "user_ts_embedding = tf.reduce_sum(user_ts_embedding, axis=-2)\n",
    "\n",
    "# global_inputs.append(user_ts_input_layer)\n",
    "# global_features.append(user_ts_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db99f90b-57f8-45e6-9f28-871658e17358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([885409515], shape=(1,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[-0.02567811 -0.0261851  -0.04417054 -0.02518065 -0.01297184 -0.0447331\n",
      "  -0.00047165  0.03007802]], shape=(1, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_user_ts_model = tf.keras.Model(inputs=user_ts_input_layer, outputs=user_ts_embedding)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(x[\"timestamp\"])\n",
    "    print(test_user_ts_model(x[\"timestamp\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc734ea-cb5e-4c6b-8b94-2a8853220178",
   "metadata": {},
   "source": [
    "#### define global sampling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff58c380-8b53-4dfa-b5b4-d36853638ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_global_context_features(x):\n",
    "    \"\"\"\n",
    "    This function generates a single global observation vector.\n",
    "    \"\"\"\n",
    "    user_id_value = x['user_id']\n",
    "    user_age_value = x['bucketized_user_age']\n",
    "    user_occ_value = x['user_occupation_text']\n",
    "    user_ts_value = x['timestamp']\n",
    "\n",
    "    _id = test_user_id_model(user_id_value) # input_tensor=tf.Tensor(shape=(4,), dtype=float32)\n",
    "    _age = test_user_age_model(user_age_value)\n",
    "    _occ = test_user_occ_model(user_occ_value)\n",
    "    _ts = test_user_ts_model(user_ts_value)\n",
    "\n",
    "    # # tmp - insepct numpy() values\n",
    "    # print(_id.numpy()) #[0])\n",
    "    # print(_age.numpy()) #[0])\n",
    "    # print(_occ.numpy()) #[0])\n",
    "    # print(_ts.numpy()) #[0])\n",
    "\n",
    "    # to numpy array\n",
    "    _id = np.array(_id.numpy())\n",
    "    _age = np.array(_age.numpy())\n",
    "    _occ = np.array(_occ.numpy())\n",
    "    _ts = np.array(_ts.numpy())\n",
    "\n",
    "    concat = np.concatenate(\n",
    "        [_id, _age, _occ, _ts], axis=-1 # -1\n",
    "    ).astype(np.float32)\n",
    "    \n",
    "    user_info = [\n",
    "                user_age_value.numpy(),\n",
    "                user_occ_value.numpy(),\n",
    "                user_ts_value.numpy(),\n",
    "                x['user_zip_code'].numpy(),\n",
    "                x['user_gender'].numpy(),\n",
    "                x['movie_title'].numpy(),\n",
    "                x['user_rating'].numpy()\n",
    "                ]\n",
    "\n",
    "    return concat, user_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d583b8f8-df19-4bfc-a963-81874d41523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1):\n",
    "    \n",
    "    iterator = iter(train_dataset.batch(5))\n",
    "    data = next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d693e5b-ab19-438c-b8eb-3be677e4c621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bucketized_user_age': <tf.Tensor: shape=(5,), dtype=float32, numpy=array([35., 18., 56., 45., 35.], dtype=float32)>,\n",
       " 'movie_genres': <tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n",
       " array([[7],\n",
       "        [4],\n",
       "        [9],\n",
       "        [4],\n",
       "        [7]])>,\n",
       " 'movie_id': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'898', b'367', b'484', b'494', b'58'], dtype=object)>,\n",
       " 'movie_title': <tf.Tensor: shape=(5,), dtype=string, numpy=\n",
       " array([b'Postman, The (1997)', b'Clueless (1995)',\n",
       "        b'Maltese Falcon, The (1941)', b'His Girl Friday (1940)',\n",
       "        b'Quiz Show (1994)'], dtype=object)>,\n",
       " 'timestamp': <tf.Tensor: shape=(5,), dtype=int64, numpy=array([885409515, 883388887, 891249586, 878044851, 880130613])>,\n",
       " 'user_gender': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'False', b'True', b'True', b'True', b'False'], dtype=object)>,\n",
       " 'user_id': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'681', b'442', b'932', b'506', b'18'], dtype=object)>,\n",
       " 'user_occupation_label': <tf.Tensor: shape=(5,), dtype=int64, numpy=array([14, 17,  0, 12, 11])>,\n",
       " 'user_occupation_text': <tf.Tensor: shape=(5,), dtype=string, numpy=\n",
       " array([b'marketing', b'student', b'educator', b'programmer', b'other'],\n",
       "       dtype=object)>,\n",
       " 'user_rating': <tf.Tensor: shape=(5,), dtype=float32, numpy=array([4., 2., 5., 5., 4.], dtype=float32)>,\n",
       " 'user_zip_code': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'97208', b'85282', b'06437', b'03869', b'37212'], dtype=object)>}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "557c2d7a-bac0-405b-904c-f05731abb8a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.0222747 , -0.04024553, -0.02816417, -0.00610999,  0.03753108,\n",
       "         -0.01307023,  0.03419149, -0.00834148,  0.00625925,  0.00503098,\n",
       "         -0.03977219, -0.00739773,  0.00397869, -0.04399686,  0.04580864,\n",
       "          0.02182123, -0.00013451, -0.04046185,  0.04273459,  0.02683686,\n",
       "          0.02432786,  0.00318767,  0.00342501,  0.00742046, -0.02567811,\n",
       "         -0.0261851 , -0.04417054, -0.02518065, -0.01297184, -0.0447331 ,\n",
       "         -0.00047165,  0.03007802],\n",
       "        [-0.03849454, -0.00388619, -0.04379085, -0.03172394,  0.04972928,\n",
       "          0.03447331, -0.04639668,  0.04477853, -0.04978393, -0.02123757,\n",
       "          0.00317239,  0.04357268, -0.04147827, -0.01549976, -0.03962313,\n",
       "          0.00662384, -0.00918381,  0.03768696,  0.01015248, -0.04925722,\n",
       "         -0.02517108,  0.00444397,  0.04442063,  0.00485962,  0.03263776,\n",
       "          0.03254581, -0.0481041 ,  0.0362358 , -0.00173527,  0.02334699,\n",
       "         -0.02328423, -0.02389137],\n",
       "        [ 0.02788906,  0.04696986,  0.04553347, -0.02982874,  0.0262934 ,\n",
       "          0.01946694, -0.02218052,  0.02441663,  0.04599238, -0.00843105,\n",
       "         -0.01581782,  0.01017773, -0.03486373, -0.03254323,  0.0047368 ,\n",
       "         -0.00438721, -0.04710764,  0.01967475, -0.03024196, -0.0146898 ,\n",
       "          0.03802731,  0.00942241,  0.002106  ,  0.03846319, -0.00731099,\n",
       "          0.03411937, -0.03958926,  0.01413387,  0.00841372, -0.00285868,\n",
       "         -0.02570605, -0.04062656],\n",
       "        [ 0.02416607,  0.01080065, -0.01472713, -0.04528918, -0.02433894,\n",
       "          0.03246259,  0.0128575 , -0.02838374, -0.0082135 , -0.01649446,\n",
       "          0.01245258,  0.01728931,  0.01937446,  0.03201133,  0.01987359,\n",
       "         -0.0357787 , -0.03425475,  0.04157751,  0.01161908, -0.02250468,\n",
       "         -0.04802287, -0.02884971,  0.0266974 , -0.03485183,  0.00782865,\n",
       "         -0.01500238,  0.03857309,  0.04400683, -0.00753771, -0.02681321,\n",
       "          0.03600473,  0.03835502],\n",
       "        [ 0.01235709,  0.01260439,  0.00848315, -0.00766486,  0.02781053,\n",
       "          0.03173185,  0.03143248, -0.00149362,  0.00625925,  0.00503098,\n",
       "         -0.03977219, -0.00739773,  0.00397869, -0.04399686,  0.04580864,\n",
       "          0.02182123, -0.01240908,  0.03627677,  0.02982371,  0.02759118,\n",
       "         -0.01823311,  0.02118133,  0.03090164, -0.02683461,  0.01379111,\n",
       "         -0.04854506, -0.0102464 ,  0.02923039, -0.03533461, -0.04767268,\n",
       "          0.01049038, -0.02487001]], dtype=float32),\n",
       " [array([35., 18., 56., 45., 35.], dtype=float32),\n",
       "  array([b'marketing', b'student', b'educator', b'programmer', b'other'],\n",
       "        dtype=object),\n",
       "  array([885409515, 883388887, 891249586, 878044851, 880130613]),\n",
       "  array([b'97208', b'85282', b'06437', b'03869', b'37212'], dtype=object),\n",
       "  array([b'False', b'True', b'True', b'True', b'False'], dtype=object),\n",
       "  array([b'Postman, The (1997)', b'Clueless (1995)',\n",
       "         b'Maltese Falcon, The (1941)', b'His Girl Friday (1940)',\n",
       "         b'Quiz Show (1994)'], dtype=object),\n",
       "  array([4., 2., 5., 5., 4.], dtype=float32)])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_get_global_context_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c9f64a0-a713-49bc-9043-d6e9598ecc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #check how this works with batches - new JW\n",
    "\n",
    "# batch_elem = train_dataset.batch(4)\n",
    "# _get_global_context_features(batch_elem)\n",
    "_get_global_context_features(data)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bba133ab-bf12-4b3b-926d-6d1dba940837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0222747 , -0.04024553, -0.02816417, -0.00610999,  0.03753108,\n",
       "        -0.01307023,  0.03419149, -0.00834148,  0.00625925,  0.00503098,\n",
       "        -0.03977219, -0.00739773,  0.00397869, -0.04399686,  0.04580864,\n",
       "         0.02182123, -0.00013451, -0.04046185,  0.04273459,  0.02683686,\n",
       "         0.02432786,  0.00318767,  0.00342501,  0.00742046, -0.02567811,\n",
       "        -0.0261851 , -0.04417054, -0.02518065, -0.01297184, -0.0447331 ,\n",
       "        -0.00047165,  0.03007802]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in train_dataset.batch(1).take(1):\n",
    "    test_globals = _get_global_context_features(x)[0]\n",
    "\n",
    "\n",
    "test_globals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249fa771-35d7-4d04-ab68-2b70911bac17",
   "metadata": {},
   "source": [
    "### arm preprocessing layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534b3bf1-a2ea-4bfb-8c77-efa057f4e391",
   "metadata": {},
   "source": [
    "#### movie ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa53cbe9-2616-4da4-90dc-dc5616258af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_id_input_layer = tf.keras.Input(\n",
    "    name=\"movie_id\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.string\n",
    ")\n",
    "\n",
    "mv_id_lookup = tf.keras.layers.StringLookup(\n",
    "    max_tokens=len(vocab_dict['movie_id']) + NUM_OOV_BUCKETS,\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    mask_token=None,\n",
    "    vocabulary=vocab_dict['movie_id'],\n",
    ")(mv_id_input_layer)\n",
    "\n",
    "mv_id_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['movie_id']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=MV_EMBEDDING_SIZE\n",
    ")(mv_id_lookup)\n",
    "\n",
    "mv_id_embedding = tf.reduce_sum(mv_id_embedding, axis=-2)\n",
    "\n",
    "# arm_inputs.append(mv_id_input_layer)\n",
    "# arm_features.append(mv_id_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9bd19f09-a12e-4a21-a1a1-5ec5bc116559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'898'], shape=(1,), dtype=string)\n",
      "tf.Tensor(\n",
      "[[ 0.02795508  0.02742118 -0.03743098  0.0256545  -0.02196083 -0.04865908\n",
      "  -0.04759594  0.00712175]], shape=(1, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_mv_id_model = tf.keras.Model(inputs=mv_id_input_layer, outputs=mv_id_embedding)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(x[\"movie_id\"])\n",
    "    print(test_mv_id_model(x[\"movie_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4a0e97-c477-4042-b9c0-fcb0f428de0d",
   "metadata": {},
   "source": [
    "#### movie genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f04a0091-d7b0-4f90-ba7c-3eb41dd0b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_genre_input_layer = tf.keras.Input(\n",
    "    name=\"movie_genres\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "mv_genre_lookup = tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=vocab_dict['movie_genres'],\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    oov_value=0,\n",
    ")(mv_genre_input_layer)\n",
    "\n",
    "mv_genre_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['movie_genres']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=MV_EMBEDDING_SIZE\n",
    ")(mv_genre_lookup)\n",
    "\n",
    "mv_genre_embedding = tf.reduce_sum(mv_genre_embedding, axis=-2)\n",
    "\n",
    "# arm_inputs.append(mv_genre_input_layer)\n",
    "# arm_features.append(mv_genre_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51701f0a-9b3e-461c-a9d9-a0c146e310ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[7]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([b'898'], shape=(1,), dtype=string)\n",
      "tf.Tensor(\n",
      "[[-0.01914558  0.01559823  0.02645048 -0.03492063 -0.01787568 -0.01115205\n",
      "  -0.03905399 -0.0137578 ]], shape=(1, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_mv_gen_model = tf.keras.Model(inputs=mv_genre_input_layer, outputs=mv_genre_embedding)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(x[\"movie_genres\"])\n",
    "    print(x[\"movie_id\"])\n",
    "    print(test_mv_gen_model(x[\"movie_genres\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b41cc9-63f5-4559-a943-1288be9c0892",
   "metadata": {},
   "source": [
    "#### define sampling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8727904e-e9b6-4005-8cf3-9da461ca88b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_per_arm_features(x):\n",
    "    \"\"\"\n",
    "    This function generates a single per-arm observation vector\n",
    "    \"\"\"\n",
    "    mv_id_value = x['movie_id']\n",
    "    mv_gen_value = x['movie_genres']\n",
    "\n",
    "    _mid = test_mv_id_model(mv_id_value)\n",
    "    _mgen = test_mv_gen_model(mv_gen_value)\n",
    "\n",
    "    # to numpy array\n",
    "    _mid = np.array(_mid.numpy())\n",
    "    _mgen = np.array(_mgen.numpy())\n",
    "\n",
    "    # print(_mid)\n",
    "    # print(_mgen)\n",
    "\n",
    "    concat = np.concatenate(\n",
    "        [_mid, _mgen], axis=-1 # -1\n",
    "    ).astype(np.float32)\n",
    "    # concat = tf.concat([_mid, _mgen], axis=-1).astype(np.float32)\n",
    "\n",
    "    return concat #this is special to this example - there is only one action dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78d3c6bb-e525-4408-b321-34ac9684f881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 16)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_get_per_arm_features(data).shape #shape checks out at batchdim, nactions, arm feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ff5764-25de-4f4c-ada3-3a417bdf22b5",
   "metadata": {},
   "source": [
    "### Create a moive lookup Table ðŸ†•\n",
    "\n",
    "This will be used in our trajectories to randomly select a movie. Using the produced embeddings, we will also have a reward function for each combination by taking the inner product via `tf_agents.bandits.networks.global_and_arm_feature_network.create_feed_forward_dot_product_network` [link](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/create_feed_forward_dot_product_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "770c3473-622f-44eb-b512-e96c4b08a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_lookup_table = {'id': [],\n",
    "                      'movie_features': [],\n",
    "                      'movie_title': [],\n",
    "                      'movie_genres': []\n",
    "                     }\n",
    "    \n",
    "iterator = iter(train_dataset.batch(1000))\n",
    "for data in iterator:\n",
    "    _get_per_arm_features(data)\n",
    "    movie_lookup_table['id'].extend(data['movie_id'].numpy())\n",
    "    movie_lookup_table['movie_title'].extend(data['movie_title'].numpy())\n",
    "    movie_lookup_table['movie_genres'].extend(data['movie_genres'].numpy())\n",
    "    movie_lookup_table['movie_features'].extend(_get_per_arm_features(data))\n",
    "    \n",
    "#fix string ids to integers for random lookup later\n",
    "movie_lookup_table['id'] = [int(x) for x in movie_lookup_table['id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66eed76c-79c2-415e-8dd9-e4ee85b5e769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "movie_lookup_table = pd.DataFrame(movie_lookup_table)\n",
    "movie_lookup_table.set_index(['id'])\n",
    "\n",
    "unique_table = movie_lookup_table.groupby(['id'])[['movie_features', 'movie_title', 'movie_genres']].first().reset_index() #resetting index to get consecutive counts from min-max (no gaps)\n",
    "# unique_table = unique_table['movie_features']\n",
    "MAX_ARM_ID = len(unique_table)-1\n",
    "MIN_ARM_ID = 0\n",
    "\n",
    "# unique_table\n",
    "# print(f\"Max movie id is: {MAX_ARM_ID} \\nMin movie id is: {MIN_ARM_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8184ea44-5ae0-4986-922b-57ee76cc4783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02649529, -0.03420674, -0.04305322,  0.02177155,  0.04776726,\n",
       "        0.02963425,  0.00585616, -0.01380833, -0.00424419,  0.04877299,\n",
       "       -0.04945192, -0.02433741, -0.04732733,  0.00761474, -0.04203337,\n",
       "       -0.01626902], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_table.iloc[2,:]['movie_features'] #example of getting a ra movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6284375d-410c-4cd5-be8b-3889d39f98b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n",
       " array([[-0.02264047,  0.0325843 ,  0.03405342,  0.02320329,  0.025595  ,\n",
       "          0.02264572,  0.02576734,  0.00051186, -0.01914558,  0.01559823,\n",
       "          0.02645048, -0.03492063, -0.01787568, -0.01115205, -0.03905399,\n",
       "         -0.0137578 ]], dtype=float32)>,\n",
       " [b'Sling Blade (1996)', array([7])])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_random_arm_features(movie_id):\n",
    "    movie_info = unique_table.iloc[movie_id]\n",
    "    tensor = tf.constant(movie_info['movie_features'], dtype=tf.float32)\n",
    "    return tf.reshape(tensor, [1, tensor.shape[0]]), [movie_info['movie_title'],\n",
    "                                                     movie_info['movie_genres']]\n",
    "\n",
    "get_random_arm_features(222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56f020a5-9ac8-46b7-b4b5-257a5cd03398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_set_of_arm_features(n_actions):\n",
    "    random_arm_ids = list(np.random.randint(MIN_ARM_ID, MAX_ARM_ID, n_actions))\n",
    "    features = [get_random_arm_features(x) for x in random_arm_ids]\n",
    "    just_features = [x[0] for x in features]\n",
    "    movie_info = [x[1] for x in features]\n",
    "    return tf.concat(just_features, axis=0), movie_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a334c538-6dab-4db3-9593-8621d5ef060c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 16), dtype=float32, numpy=\n",
       "array([[-0.04323196,  0.0118971 ,  0.01546026, -0.01377887,  0.03118242,\n",
       "        -0.03389366, -0.02528167,  0.01101557, -0.00424419,  0.04877299,\n",
       "        -0.04945192, -0.02433741, -0.04732733,  0.00761474, -0.04203337,\n",
       "        -0.01626902],\n",
       "       [-0.03638207,  0.00766601,  0.04009726, -0.01203433,  0.02385687,\n",
       "        -0.02072497, -0.00188099, -0.01579259,  0.034511  ,  0.00811634,\n",
       "         0.001149  ,  0.02581637,  0.01430186,  0.0456696 ,  0.01507476,\n",
       "        -0.02697303]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_set_of_arm_features(n_actions=2)[0] #NEW - there's a tuple returned with the movies we will use for PALM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "865c8d9e-aa65-4cb6-b632-b805b103ffc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 16), dtype=float32, numpy=\n",
       "array([[-0.02811556, -0.03427996, -0.02301004, -0.01505543, -0.0271075 ,\n",
       "         0.0207031 , -0.04075557, -0.041522  , -0.01914558,  0.01559823,\n",
       "         0.02645048, -0.03492063, -0.01787568, -0.01115205, -0.03905399,\n",
       "        -0.0137578 ],\n",
       "       [ 0.01543451, -0.03711804, -0.01076535, -0.03060374,  0.04467111,\n",
       "         0.03554627, -0.0047795 ,  0.02643493,  0.01006199,  0.02088055,\n",
       "        -0.03473585, -0.03171374, -0.04916475, -0.03865167,  0.01279688,\n",
       "        -0.02928859]], dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# goal of this is to randomly select n_action movies for each global context \n",
    "\n",
    "global_context_fts, gc_sf = _get_global_context_features(data)\n",
    "bs = global_context_fts.shape[0] #get the first batch dimension\n",
    "arm_fts, ar_sf = get_random_set_of_arm_features(n_actions=2)\n",
    "arm_fts\n",
    "# for _ in range(bs-1):\n",
    "# # get_random_set_of_arm_features(n_actions=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a52c9f62-04f9-4f50-912c-d2f75b5f6986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([35., 18., 56., 45., 35., 25., 25., 35.], dtype=float32), array([b'marketing', b'student', b'educator', b'programmer', b'other',\n",
      "       b'programmer', b'other', b'executive'], dtype=object), array([885409515, 883388887, 891249586, 878044851, 880130613, 892778202,\n",
      "       879959212, 877131685]), array([b'97208', b'85282', b'06437', b'03869', b'37212', b'55414',\n",
      "       b'06405', b'L1V3W'], dtype=object), array([b'False', b'True', b'True', b'True', b'False', b'True', b'False',\n",
      "       b'True'], dtype=object), array([b'Postman, The (1997)', b'Clueless (1995)',\n",
      "       b'Maltese Falcon, The (1941)', b'His Girl Friday (1940)',\n",
      "       b'Quiz Show (1994)', b\"Carlito's Way (1993)\",\n",
      "       b'Primal Fear (1996)', b'Aladdin (1992)'], dtype=object), array([4., 2., 5., 5., 4., 4., 5., 4.], dtype=float32)] [[b'Squeeze (1996)', array([7])], [b'Three Lives and Only One Death (1996)', array([4])], [b'Last of the Mohicans, The (1992)', array([0])], [b'East of Eden (1955)', array([7])], [b'Flirt (1995)', array([7])]]\n"
     ]
    }
   ],
   "source": [
    "### Look at the raw input features to format a good prompt for ranking movies\n",
    "NUM_ACTIONS = 5\n",
    "batch_size = 8\n",
    "iterator = iter(train_dataset.batch(batch_size))\n",
    "data = next(iterator)\n",
    "\n",
    "_, user_info = _get_global_context_features(data) #new - user info passes on the raw user features for prompting with PALM\n",
    "###NEW - we are getting the arm features here\n",
    "_, movie_info = get_random_set_of_arm_features(n_actions=NUM_ACTIONS)\n",
    "\n",
    "print(user_info, movie_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f331390-f23b-4f41-a218-2a9211fba9c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wed Jan 21 19:05:15 1998'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "dt = datetime.utcfromtimestamp(885409515)\n",
    "dt.ctime()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c610713-7e65-4ff5-8d9f-bfabf81d6c82",
   "metadata": {},
   "source": [
    "## Quick inspection of movie info\n",
    "Here's an example of `N_ACTIONS` randomly selected movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce9675e3-1a41-4533-b9fa-7fd02bba84c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[b'Squeeze (1996)', array([7])],\n",
       " [b'Three Lives and Only One Death (1996)', array([4])],\n",
       " [b'Last of the Mohicans, The (1992)', array([0])],\n",
       " [b'East of Eden (1955)', array([7])],\n",
       " [b'Flirt (1995)', array([7])]]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf81d87-00c0-40f6-ae0e-0fa9a1e7aa7a",
   "metadata": {},
   "source": [
    "##### Feature formats info reference\n",
    "\n",
    "[BUCKETIZED AGE](https://www.tensorflow.org/datasets/catalog/movielens)\n",
    "\n",
    "\n",
    "[GENRE_LIST](https://files.grouplens.org/datasets/movielens/ml-10m-README.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a804c78a-40b3-4b4c-85ff-b8810e93192d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You are looking to watch a movie and need to review each movie based on user '\n",
      " 'demographics \\n'\n",
      " 'Here are some info on this the user: \\n'\n",
      " 'the user is age is 35-44, n\\n'\n",
      " 'and lives in zipcode 97208\\n'\n",
      " \"the user's occupation is marketing \\n\"\n",
      " 'the user previously reviewed Postman, The (1997), \\n'\n",
      " 'giving it a 4 out five star review during Wed Jan 21 19:05:15 1998\\n'\n",
      " '    \\n'\n",
      " 'Please rate these movies below using using \\n'\n",
      " '5 - highly recomended movie\\n'\n",
      " '4 - somewhat recommend movie\\n'\n",
      " '3 - maybe watch movie\\n'\n",
      " '2 - not a good movie\\n'\n",
      " '1 - really bad movie\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '1. Squeeze (1996), Drama\\n'\n",
      " '2. Three Lives and Only One Death (1996), Comedy\\n'\n",
      " '3. Last of the Mohicans, The (1992), Action\\n'\n",
      " '4. East of Eden (1955), Drama\\n'\n",
      " '5. Flirt (1995), Drama\\n'\n",
      " ' please rate the 5 movies\\n'\n",
      " ' ensure you return the ratings as a python list of just the ratings for 5 '\n",
      " 'movies')\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "age_text_lookup = {\n",
    "'1': \"Under 18\",\n",
    "'18': \"18-24\",\n",
    "'25': \"25-34\",\n",
    "'35': \"35-44\",\n",
    "'45': \"45-49\",\n",
    "'50': \"50-55\",\n",
    "'56': \"56+\"\n",
    "}\n",
    "\n",
    "genre_list = [\n",
    "    \"Action\",\n",
    "    \"Adventure\",\n",
    "    \"Animation\",\n",
    "    \"Children's\",\n",
    "    \"Comedy\",\n",
    "    \"Crime\",\n",
    "    \"Documentary\",\n",
    "    \"Drama\",\n",
    "    \"Fantasy\",\n",
    "    \"Film-Noir\",\n",
    "    \"Horror\",\n",
    "    \"Musical\",\n",
    "    \"Mystery\",\n",
    "    \"Romance\",\n",
    "    \"Sci-Fi\",\n",
    "    \"Thriller\",\n",
    "    \"War\",\n",
    "    \"Western\",\n",
    "] #use this to lookup genres\n",
    "\n",
    "def gender_movielens_translator(elem):\n",
    "    if elem==\"True\":\n",
    "        return \"male\" \n",
    "    else:\n",
    "        return \"non-male\"\n",
    "\n",
    "rating_scale = '''\n",
    "5 - highly recomended movie\n",
    "4 - somewhat recommend movie\n",
    "3 - maybe watch movie\n",
    "2 - not a good movie\n",
    "1 - really bad movie\n",
    "'''\n",
    "\n",
    "age, occ, time, zipcode, gender, ex_movie, ex_movie_rating = user_info[0], user_info[1], user_info[2], user_info[3], user_info[4], user_info[5], user_info[6]\n",
    "\n",
    "prompts = []\n",
    "for i in range(len(age)):\n",
    "    formatted_datetime = datetime.utcfromtimestamp(time[i]).ctime()\n",
    "    gender = gender_movielens_translator(gender[i])\n",
    "    prompt = f\"\"\"You are looking to watch a movie and need to review each movie based on user demographics \n",
    "Here are some info on this the user: \n",
    "the user is age is {age_text_lookup[str(int(age[i]))]}, {gender[i]}\n",
    "and lives in zipcode {zipcode[i].decode(\"utf-8\")}\n",
    "the user's occupation is {occ[i].decode(\"utf-8\")} \n",
    "the user previously reviewed {ex_movie[i].decode(\"utf-8\")}, \n",
    "giving it a {int(ex_movie_rating[i])} out five star review during {formatted_datetime}\n",
    "    \n",
    "Please rate these movies below using using {rating_scale}\n",
    "\"\"\"\n",
    "    \n",
    "    for j, movie in enumerate(movie_info):\n",
    "        try:\n",
    "            genre = genre_list[movie[1][0]]\n",
    "        except:\n",
    "            genre = 'NA'\n",
    "        prompt += f\"\\n{j+1}. {movie[0].decode('utf-8')}, {genre}\"\n",
    "        total_movies = j+1\n",
    "    prompt += f\"\\n please rate the {total_movies} movies\"\n",
    "    prompt += f\"\\n ensure you return the ratings as a python list of just the ratings for {total_movies} movies\"\n",
    "        \n",
    "    ## next add in the movie selections\n",
    "    prompts.append(prompt)\n",
    "pprint(prompts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a03c7f6d-9825-4923-b984-376e4ddd16b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[b'Squeeze (1996)', array([7])],\n",
       " [b'Three Lives and Only One Death (1996)', array([4])],\n",
       " [b'Last of the Mohicans, The (1992)', array([0])],\n",
       " [b'East of Eden (1955)', array([7])],\n",
       " [b'Flirt (1995)', array([7])]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb050b77-ede5-4745-a166-6ade8e401c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "def RL_prompt(user_info, movie_info):\n",
    "    \n",
    "    age, occ, time, zipcode, gender, ex_movie, ex_movie_rating = user_info[0], user_info[1], user_info[2], user_info[3], user_info[4], user_info[5], user_info[6]\n",
    "\n",
    "    prompts = []\n",
    "    for i in range(len(age)):\n",
    "        formatted_datetime = datetime.utcfromtimestamp(time[i]).ctime()\n",
    "        gender = gender_movielens_translator(gender[i])\n",
    "        prompt = f\"\"\"CONTEXT: Pretend you are looking to watch a movie and need to review each movie on your user profile \n",
    "USER PROFILE: \n",
    "your age is {age_text_lookup[str(int(age[i]))]}, {gender[i]}\n",
    "and lives you live in zipcode {zipcode[i].decode(\"utf-8\")}\n",
    "your occupation is {occ[i].decode(\"utf-8\")} \n",
    "plus you previously reviewed {ex_movie[i].decode(\"utf-8\")}, \n",
    "giving it a {int(ex_movie_rating[i])} out 5.0 star review during {formatted_datetime}\n",
    "\n",
    "Review these movies using this scale: {rating_scale}\n",
    "Here are the movies to you need to rate: \"\"\"\n",
    "        for j, movie in enumerate(movie_info):\n",
    "            try:\n",
    "                genre = genre_list[movie[1][0]]\n",
    "            except:\n",
    "                genre = 'NA'\n",
    "            prompt += f\"\\n{j+1}. {movie[0].decode('utf-8')}, {genre}\"\n",
    "        # prompt += textwrap.dedent(f\"\\n Please rate these movies below using using this scale: {rating_scale}\")\n",
    "        # prompt += f\"Q: return the ratings of these movies like so: 3.5, 4, ... for each movie:\" #llm recency bias\n",
    "        prompts.append(prompt)\n",
    "    return prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "697199de-e949-4533-affb-a8c96563c55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('CONTEXT: Pretend you are looking to watch a movie and need to review each '\n",
      " 'movie on your user profile \\n'\n",
      " 'USER PROFILE: \\n'\n",
      " 'your age is 35-44, n\\n'\n",
      " 'and lives you live in zipcode 97208\\n'\n",
      " 'your occupation is marketing \\n'\n",
      " 'plus you previously reviewed Postman, The (1997), \\n'\n",
      " 'giving it a 4 out 5.0 star review during Wed Jan 21 19:05:15 1998\\n'\n",
      " '\\n'\n",
      " 'Review these movies using this scale: \\n'\n",
      " '5 - highly recomended movie\\n'\n",
      " '4 - somewhat recommend movie\\n'\n",
      " '3 - maybe watch movie\\n'\n",
      " '2 - not a good movie\\n'\n",
      " '1 - really bad movie\\n'\n",
      " '\\n'\n",
      " 'Here are the movies to you need to rate: \\n'\n",
      " '1. Squeeze (1996), Drama\\n'\n",
      " '2. Three Lives and Only One Death (1996), Comedy\\n'\n",
      " '3. Last of the Mohicans, The (1992), Action\\n'\n",
      " '4. East of Eden (1955), Drama\\n'\n",
      " '5. Flirt (1995), Drama')\n"
     ]
    }
   ],
   "source": [
    "prompts = RL_prompt(user_info, movie_info)\n",
    "\n",
    "len(prompts)\n",
    "pprint(prompts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3458f058-6346-4636-97db-f8fa02e89984",
   "metadata": {},
   "source": [
    "## Adding in reward function with PALM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "871773c9-2d21-4065-aceb-cf599980c0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-cloud-aiplatform protobuf --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a1526b43-e69e-4d35-9145-05d0c2aaee18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from Model:  I am an AI assistant incapable of experiencing emotions in the same way humans might. \n",
      "\n",
      "I am, however, functioning as intended and am able to help you with a variety of writing-based tasks. \n",
      "\n",
      "Is there anything I can assist you with today?\n"
     ]
    }
   ],
   "source": [
    "import vertexai\n",
    "from vertexai.language_models import TextGenerationModel\n",
    "\n",
    "vertexai.init(project=\"wortz-project-352116\", location=\"us-central1\")\n",
    "parameters = {\n",
    "    \"temperature\": 0.0,\n",
    "    \"max_output_tokens\": 500,\n",
    "    \"top_p\": 0.8,\n",
    "    \"top_k\": 40\n",
    "}\n",
    "llm = TextGenerationModel.from_pretrained(\"text-bison\")\n",
    "response = llm.predict(\n",
    "    prompt = \"Hello, how are you today?\",\n",
    ")\n",
    "print(f\"Response from Model: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2d4b74fc-90a9-45af-a2c0-a023bcfdf50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a rate limiter function\n",
    "import time\n",
    "\n",
    "def wait(secs):\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            time.sleep(secs)\n",
    "            return func(*args, **kwargs)\n",
    "        return wrapper\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5966a267-bb83-4ad5-93dc-cc569620c3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@wait(1)\n",
    "def palm_rate_limited(prompt, *args, **kwargs):\n",
    "    return llm.predict(prompt, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9d27fa6e-89bd-4dbd-a91a-6731eb744b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Hello! How can I help you?"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palm_rate_limited(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b7223dca-5b0a-42a4-bea8-857e14649535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.2 ms, sys: 2.12 ms, total: 13.3 ms\n",
      "Wall time: 7.72 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 3, 2, 4, 5, 3'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### PALM test prompt!\n",
    "\n",
    "rating = llm.predict(prompts[0], **parameters)\n",
    "extraction_prompt = \"extract the ratings in order in a simple comma seperated list:\"\n",
    "ratings = llm.predict(f\"{rating.text} {extraction_prompt}\", **parameters)\n",
    "ratings.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b4911b38-0cec-4f9f-874b-b37040e7f678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_call(prompts):\n",
    "    ratings_list = []\n",
    "    for prompt in prompts:\n",
    "        rating = palm_rate_limited(prompt, **parameters)\n",
    "        extraction_prompt = \"extract the numeric-only ratings a comma seperated list:\"\n",
    "        ratings = palm_rate_limited(f\"given the output {rating.text}, {extraction_prompt}\", **parameters)\n",
    "        ratings_list.append(ratings.text)\n",
    "    return ratings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "39574548-f50e-437f-a2af-fddc565e23fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 5\n"
     ]
    }
   ],
   "source": [
    "#now try to put it together by getting ratings for a batch with multiple arms\n",
    "\n",
    "print(batch_size, NUM_ACTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a267366d-6f6e-4b28-a4da-85dc4b3538c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unvalidated_llm_response = llm_call(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d0e6b0b2-f0ba-46bb-a7d9-1648e6a099ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 3, 2, 4, 5, 3',\n",
       " ' 3, 2, 4, 5, 3',\n",
       " ' 3, 2, 4, 5, 3',\n",
       " ' 3, 4, 5, 5, 3',\n",
       " ' 3, 4, 5, 5, 3',\n",
       " ' 3, 4, 5, 5, 3',\n",
       " ' 3, 4, 5, 5, 3',\n",
       " ' 3, 2, 5, 4, 3']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unvalidated_llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "56487957-39af-43e6-bc52-9bae34bfc6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def validate_llm_response(llm_response, n_actions):\n",
    "    \"this formats the text lists into a list of floats and also\"\n",
    "    \"TODO - handles when LLM has poor output\"\n",
    "    float_rating_list = []\n",
    "    for resp in llm_response:\n",
    "        str_elem = [y for y in resp.split(',')]\n",
    "        if len(str_elem) != n_actions:\n",
    "            float_elem = list(np.ones(n_actions)*3) #default rating of all threes if we can't figure it out TODO\n",
    "        else:\n",
    "            try: \n",
    "                float_elem = [float(x) for x in str_elem] #ensure we can convert the values to a float\n",
    "            except:\n",
    "                float_elem = list(np.ones(n_actions)*3)\n",
    "        float_rating_list.append(float_elem)\n",
    "    # re_clean_list = [[re.findall(r'\\d+', y) for y in x] for x in str_list]\n",
    "    return float_rating_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9e656d8f-63f2-4855-bdae-711b933ed9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3.0, 2.0, 4.0, 5.0, 3.0],\n",
       " [3.0, 2.0, 4.0, 5.0, 3.0],\n",
       " [3.0, 2.0, 4.0, 5.0, 3.0],\n",
       " [3.0, 4.0, 5.0, 5.0, 3.0],\n",
       " [3.0, 4.0, 5.0, 5.0, 3.0],\n",
       " [3.0, 4.0, 5.0, 5.0, 3.0],\n",
       " [3.0, 4.0, 5.0, 5.0, 3.0],\n",
       " [3.0, 2.0, 5.0, 4.0, 3.0]]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_rewards = validate_llm_response(unvalidated_llm_response, NUM_ACTIONS)\n",
    "llm_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3e01ba-8d4f-4d18-b07e-e4183dddd48e",
   "metadata": {},
   "source": [
    "## Finally, put it together into the LLM reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3a08075a-4cae-45d1-b0fc-cb6418cd338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_reward(user_info, movie_info, num_actions):\n",
    "    prompts = RL_prompt(user_info, movie_info)\n",
    "    unvalidated_llm_response = llm_call(prompts)\n",
    "    return validate_llm_response(unvalidated_llm_response, num_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "03de09e2-5ce4-4158-8185-e7635e6be7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Look at the raw input features to format a good prompt for ranking movies\n",
    "# NUM_ACTIONS = 5\n",
    "# batch_size = 8\n",
    "# iterator = iter(train_dataset.batch(batch_size))\n",
    "# test_steps = 3\n",
    "# for _ in range(3):\n",
    "#     data = next(iterator)\n",
    "\n",
    "#     _, user_info = _get_global_context_features(data) #new - user info passes on the raw user features for prompting with PALM\n",
    "#     ###NEW - we are getting the arm features here\n",
    "#     _, movie_info = get_random_set_of_arm_features(n_actions=NUM_ACTIONS)\n",
    "\n",
    "\n",
    "#     llm_reward(user_info, movie_info, NUM_ACTIONS) #batch size by n_actions/arms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "65c1db42-81ab-46a6-b4a5-9f44d76ca4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add one more validation - we will add a null tie in case of bad formatting TODO\n",
    "### should make sure we have the correct shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac6836c-67b7-4fd4-917a-24ddad708edd",
   "metadata": {},
   "source": [
    "# TF-Agents implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1877c79c-b6c8-4048-b1ce-05f011e8d69e",
   "metadata": {},
   "source": [
    "In TF-Agents, the *per-arm features* implementation differs from the *global-only* feature examples in the following aspects:\n",
    "* Reward is modeled not per-arm, but globally.\n",
    "* The arms are permutation invariant: it doesnâ€™t matter which arm is arm 1 or arm 2, only their features.\n",
    "* One can have a different number of arms to choose from in every step (note that unspecified/dynamically changing number of arms will have a problem with XLA compatibility).\n",
    "\n",
    "When implementing per-arm features in TF-Bandits, the following details have to be discussed:\n",
    "* Observation spec and observations,\n",
    "* Action spec and actions,\n",
    "* Implementation of specific policies and agents.\n",
    "\n",
    "\n",
    "**TODO:**\n",
    "* outline the components and highlight their interactions, dependencies on eachother, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7ff9baaf-987d-448d-a981-742a79b581e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE  : 8\n",
      "NUM_ACTIONS : 5\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE  = 8\n",
    "NUM_ACTIONS = 5 \n",
    "\n",
    "# GLOBAL_EMBEDDING_SIZE  = 16\n",
    "# MV_EMBEDDING_SIZE      = 32 #32\n",
    "\n",
    "GLOBAL_DIM = GLOBAL_EMBEDDING_SIZE * 4 # 4 global features in this example\n",
    "PER_ARM_DIM = MV_EMBEDDING_SIZE * 2 # 2 movie features\n",
    "\n",
    "print(f\"BATCH_SIZE  : {BATCH_SIZE}\")\n",
    "print(f\"NUM_ACTIONS : {NUM_ACTIONS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeb4902-5bb9-4587-8d29-c01d78b006be",
   "metadata": {},
   "source": [
    "## Tensor Specs\n",
    "\n",
    "**TODO:**\n",
    "* explain relationship between Tensor Specs and their Tensor counterparts\n",
    "* highlight the errors, lessons learned, and utility functions to address these"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f68ebe8-116d-43b3-a6e1-4f5a5c7f4741",
   "metadata": {},
   "source": [
    "### Observation spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9c4746-d01b-4ca4-aa53-ab68da54d37a",
   "metadata": {},
   "source": [
    "**This observation spec allows the user to have a global observation of fixed dimension**, and an unspecified number of *per-arm* features (also of fixed dimension)\n",
    "* The actions output by the policy are still integers as usual, and they indicate which row of the arm-features it has chosen \n",
    "* The action spec must be a single integer value without boundaries:\n",
    "\n",
    "```python\n",
    "global_spec = tensor_spec.TensorSpec([GLOBAL_DIM], tf.float32)\n",
    "per_arm_spec = tensor_spec.TensorSpec([None, PER_ARM_DIM], tf.float32)\n",
    "observation_spec = {'global': global_spec, 'per_arm': per_arm_spec}\n",
    "\n",
    "action_spec = tensor_spec.TensorSpec((), tf.int32)\n",
    "```\n",
    "> Here the only difference compared to the action spec with global features only is that the tensor spec is not bounded, as we donâ€™t know how many arms there will be at any time step\n",
    "\n",
    "**XLA compatibility:**\n",
    "* Since dynamic tensor shapes are not compatible with XLA, the number of arm features (and consequently, number of arms for a step) cannot be dynamic. \n",
    "* One workaround is to fix the maximum number of arms for a problem, then pad the arm features in steps with fewer arms, and use action masking to indicate how many arms are actually active.\n",
    "\n",
    "```python\n",
    "per_arm_spec = tensor_spec.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32)\n",
    "\n",
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=(), dtype=tf.int32, minimum = 0, maximum = NUM_ACTIONS - 1\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "36bd3b33-635a-4274-8b9e-7172696ebb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(32,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(5, 16), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_spec = {\n",
    "    'global': tf.TensorSpec([GLOBAL_DIM], tf.float32),\n",
    "    'per_arm': tf.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32) #excluding action dim here\n",
    "}\n",
    "observation_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a2da92-7db2-4f42-94a7-b7bad1c8fc42",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Action spec\n",
    "\n",
    "> The time_step_spec and action_spec are specifications for the input time step and the output action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5af42c7-18d7-480f-a7f3-d7da3f4840eb",
   "metadata": {},
   "source": [
    "```python\n",
    "    if (\n",
    "        not tensor_spec.is_bounded(action_spec)\n",
    "        or not tensor_spec.is_discrete(action_spec)\n",
    "        or action_spec.shape.rank > 1\n",
    "        or action_spec.shape.num_elements() != 1\n",
    "    ):\n",
    "      raise NotImplementedError(\n",
    "          'action_spec must be a BoundedTensorSpec of type int32 and shape (). '\n",
    "          'Found {}.'.format(action_spec)\n",
    "      )\n",
    "```\n",
    "\n",
    "* [src](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_base_policy.py#L97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "549a123c-349a-4103-b39a-4502f47d1e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(4, dtype=int32))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=[], \n",
    "    dtype=tf.int32,\n",
    "    minimum=tf.constant(0),            \n",
    "    maximum=NUM_ACTIONS-1, #n degrees of freedom and will dictate the expected mean reward spec shape\n",
    "    name=\"action_spec\"\n",
    ")\n",
    "\n",
    "action_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a51efce-9f1b-42d1-bec4-7b788e3fd7e0",
   "metadata": {},
   "source": [
    "### TimeStep spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "95f05860-0fbf-4a5a-8273-9c81761e0ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'global': TensorSpec(shape=(32,), dtype=tf.float32, name=None),\n",
       "                 'per_arm': TensorSpec(shape=(5, 16), dtype=tf.float32, name=None)},\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec = ts.time_step_spec(observation_spec)#, reward_spec=tf.TensorSpec([1, NUM_ACTIONS]))\n",
    "time_step_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9c197-ae9b-461d-8956-f078b929ac12",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The Agent\n",
    "\n",
    "**Note** that contextual bandits form a special case of RL, where the actions taken by the agent do not alter the state of the environment \n",
    "\n",
    "> â€œContextualâ€ refers to the fact that the agent chooses among a set of actions while having knowledge of the context (environment observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aadb01-eb5c-4870-ae14-9e66624ba594",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Agent types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d075e8a6-11a9-4346-8725-3653fba4bac4",
   "metadata": {},
   "source": [
    "**Possible Agent Types:**\n",
    "\n",
    "```\n",
    "AGENT_TYPE = ['LinUCB', 'LinTS', 'epsGreedy', 'NeuralLinUCB']\n",
    "```\n",
    "\n",
    "**LinearUCBAgent:** (`LinUCB`)\n",
    "* An agent implementing the Linear UCB bandit algorithm\n",
    "* (whitepaper) [A contextual bandit approach to personalized news recommendation](https://arxiv.org/abs/1003.0146)\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/lin_ucb_agent/LinearUCBAgent)\n",
    "\n",
    "**LinearThompsonSamplingAgent:** (`LinTS`)\n",
    "* Implements the Linear Thompson Sampling Agent from the paper: [Thompson Sampling for Contextual Bandits with Linear Payoffs](https://arxiv.org/abs/1209.3352)\n",
    "* the agent maintains two parameters `weight_covariances` and `parameter_estimators`, and updates them based on experience.\n",
    "* The inverse of the weight covariance parameters are updated with the outer product of the observations using the Woodbury inverse matrix update, while the parameter estimators are updated by the reward-weighted observation vectors for every action\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/linear_thompson_sampling_agent/LinearThompsonSamplingAgent)\n",
    "\n",
    "**NeuralEpsilonGreedyAgent:** (`epsGreedy`) \n",
    "* A neural network based epsilon greedy agent\n",
    "* This agent receives a neural network that it trains to predict rewards\n",
    "* The action is chosen greedily with respect to the prediction with probability `1 - epsilon`, and uniformly randomly with probability epsilon\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_epsilon_greedy_agent/NeuralEpsilonGreedyAgent)\n",
    "\n",
    "**NeuralLinUCBAgent:** (`NeuralLinUCB`)\n",
    "* An agent implementing the LinUCB algorithm on top of a neural network\n",
    "* `ENCODING_DIM` is the output dimension of the encoding network \n",
    "> * This output will be used by either a linear reward layer and epsilon greedy exploration, or by a LinUCB logic, depending on the number of training steps executed so far\n",
    "* `EPS_PHASE_STEPS` is the number training steps to run for training the encoding network before switching to `LinUCB`\n",
    "> * If negative, the encoding network is assumed to be already trained\n",
    "> * If the number of steps is less than or equal to `EPS_PHASE_STEPS`, `epsilon greedy` is used, otherwise `LinUCB`\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_linucb_agent/NeuralLinUCBAgent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b8e88e-c8ea-4193-a911-0d974ef3b1a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### network types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f547087d-5fad-4521-a584-cb46ce52897d",
   "metadata": {},
   "source": [
    "Which network architecture to use for the `epsGreedy` or `NeuralLinUCB` agents\n",
    "\n",
    "```\n",
    "NETWORK_TYPE = ['commontower', 'dotproduct']\n",
    "```\n",
    "\n",
    "**GlobalAndArmCommonTowerNetwork:** (`commontower`)\n",
    "* This network takes the output of the global and per-arm networks, and leads them through a common network, that in turn outputs reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "> * `COMMON_LAYERS` - Iterable of ints. Specifies the layers of the common tower\n",
    "* The network produced by this function can be used either in `GreedyRewardPredictionPolicy`, or `NeuralLinUCBPolicy`\n",
    "> * In the former case, the network must have `output_dim=1`, it is going to be an instance of `QNetwork`, and used in the policy as a reward prediction network\n",
    "> * In the latter case, the network will be an encoding network with its output consumed by a reward layer or a `LinUCB` method. The specified `output_dim` will be the encoding dimension\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmCommonTowerNetwork)\n",
    "\n",
    "**GlobalAndArmDotProductNetwork:** (`dotproduct`)\n",
    "* This network calculates the **dot product** of the output of the global and per-arm networks and returns them as reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmDotProductNetwork)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3dc270-deb5-4e96-8276-74759a06c318",
   "metadata": {},
   "source": [
    "### define agent and network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6d817bf2-1fa6-4bae-af90-745fad996b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 8,\n",
      " 'common_layers': [100],\n",
      " 'epsilon': 0.2,\n",
      " 'global_layers': [50, 50, 50],\n",
      " 'learning_rate': 0.005,\n",
      " 'model_type': 'epsGreedy',\n",
      " 'network_type': 'dotproduct',\n",
      " 'num_actions': 5,\n",
      " 'per_arm_layers': [50, 50, 50]}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Agents\n",
    "# ================================\n",
    "AGENT_TYPE      = 'epsGreedy' # 'LinUCB' | 'LinTS |, 'epsGreedy' | 'NeuralLinUCB'\n",
    "\n",
    "# Parameters for linear agents (LinUCB and LinTS).\n",
    "AGENT_ALPHA     = 0.1\n",
    "\n",
    "# Parameters for neural agents (NeuralEpsGreedy and NerualLinUCB).\n",
    "EPSILON         = 0.20\n",
    "LR              = 0.005\n",
    "\n",
    "# Parameters for NeuralLinUCB\n",
    "ENCODING_DIM    = 1\n",
    "EPS_PHASE_STEPS = 1000\n",
    "\n",
    "# ================================\n",
    "# Agent's Preprocess Network\n",
    "# ================================\n",
    "NETWORK_TYPE    = \"dotproduct\" # 'commontower' | 'dotproduct'\n",
    "\n",
    "if AGENT_TYPE == 'NeuralLinUCB':\n",
    "    NETWORK_TYPE = 'commontower'\n",
    "    \n",
    "\n",
    "GLOBAL_LAYERS   = [50, 50, 50]\n",
    "ARM_LAYERS      = [50, 50, 50]\n",
    "COMMON_LAYERS   = [100]\n",
    "\n",
    "observation_and_action_constraint_splitter = None\n",
    "\n",
    "HPARAMS = {  # TODO - streamline and consolidate\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"num_actions\": NUM_ACTIONS,\n",
    "    \"model_type\": AGENT_TYPE,\n",
    "    \"network_type\": NETWORK_TYPE,\n",
    "    \"global_layers\": GLOBAL_LAYERS,\n",
    "    \"per_arm_layers\": ARM_LAYERS,\n",
    "    \"common_layers\": COMMON_LAYERS,\n",
    "    \"learning_rate\": LR,\n",
    "    \"epsilon\": EPSILON,\n",
    "}\n",
    "pprint(HPARAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db165067-6e9d-4b79-b675-bae69ec98c10",
   "metadata": {},
   "source": [
    "### Agent Factory\n",
    "\n",
    "**TODO:**\n",
    "* consolidate agent, network, and hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e7c79df4-f975-49fc-b598-d6fd2f6be125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\n",
      "\n",
      "time_step_spec:  TimeStep(\n",
      "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'observation': {'global': TensorSpec(shape=(32,), dtype=tf.float32, name=None),\n",
      "                 'per_arm': TensorSpec(shape=(5, 16), dtype=tf.float32, name=None)},\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n",
      "\n",
      "action_spec:  BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(4, dtype=int32))\n",
      "\n",
      "observation_spec:  {'global': TensorSpec(shape=(32,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(5, 16), dtype=tf.float32, name=None)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\")\n",
    "print(\"\\ntime_step_spec: \", time_step_spec)\n",
    "print(\"\\naction_spec: \", action_spec)\n",
    "print(\"\\nobservation_spec: \", observation_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6cb60f0b-90b7-49ab-9c41-046ea00ab750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: OffpolicyNeuralEpsGreedyAgent\n",
      "\n",
      "Network: GlobalAndArmDotProductNetwork\n"
     ]
    }
   ],
   "source": [
    "# from tf_agents.bandits.policies import policy_utilities\n",
    "# from tf_agents.bandits.agents import greedy_reward_prediction_agent\n",
    "\n",
    "network = None\n",
    "observation_and_action_constraint_splitter = None\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "if AGENT_TYPE == 'LinUCB':\n",
    "    agent = lin_ucb_agent.LinearUCBAgent(\n",
    "        time_step_spec=time_step_spec,\n",
    "        action_spec=action_spec,\n",
    "        alpha=AGENT_ALPHA,\n",
    "        accepts_per_arm_features=True,\n",
    "        dtype=tf.float32,\n",
    "    )\n",
    "elif AGENT_TYPE == 'LinTS':\n",
    "    agent = lin_ts_agent.LinearThompsonSamplingAgent(\n",
    "        time_step_spec=time_step_spec,\n",
    "        action_spec=action_spec,\n",
    "        alpha=AGENT_ALPHA,\n",
    "        observation_and_action_constraint_splitter=(\n",
    "            observation_and_action_constraint_splitter\n",
    "        ),\n",
    "        accepts_per_arm_features=True,\n",
    "        dtype=tf.float32,\n",
    "    )\n",
    "elif AGENT_TYPE == 'epsGreedy':\n",
    "    # obs_spec = per_arm_tf_env.observation_spec()\n",
    "    if NETWORK_TYPE == 'commontower':\n",
    "        network = global_and_arm_feature_network.create_feed_forward_common_tower_network(\n",
    "            observation_spec = observation_spec, \n",
    "            global_layers = GLOBAL_LAYERS, \n",
    "            arm_layers = ARM_LAYERS, \n",
    "            common_layers = COMMON_LAYERS,\n",
    "            # output_dim = 1\n",
    "        )\n",
    "    elif NETWORK_TYPE == 'dotproduct':\n",
    "        network = global_and_arm_feature_network.create_feed_forward_dot_product_network(\n",
    "            observation_spec = observation_spec, \n",
    "            global_layers = GLOBAL_LAYERS, \n",
    "            arm_layers = ARM_LAYERS\n",
    "        )\n",
    "    agent = neural_epsilon_greedy_agent.NeuralEpsilonGreedyAgent(\n",
    "        time_step_spec=time_step_spec,\n",
    "        action_spec=action_spec,\n",
    "        reward_network=network,\n",
    "        optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=HPARAMS['learning_rate']),\n",
    "        epsilon=HPARAMS['epsilon'],\n",
    "        observation_and_action_constraint_splitter=(\n",
    "            observation_and_action_constraint_splitter\n",
    "        ),\n",
    "        accepts_per_arm_features=True,\n",
    "        emit_policy_info = ('predicted_rewards_mean', 'bandit_policy_type',),\n",
    "        train_step_counter=global_step,\n",
    "        info_fields_to_inherit_from_greedy=('predicted_rewards_mean',),\n",
    "        name='OffpolicyNeuralEpsGreedyAgent'\n",
    "    )\n",
    "\n",
    "elif AGENT_TYPE == 'NeuralLinUCB':\n",
    "    # obs_spec = per_arm_tf_env.observation_spec()\n",
    "    network = (\n",
    "        global_and_arm_feature_network.create_feed_forward_common_tower_network(\n",
    "            observation_spec = observation_spec, \n",
    "            global_layers = GLOBAL_LAYERS, \n",
    "            arm_layers = ARM_LAYERS, \n",
    "            common_layers = COMMON_LAYERS,\n",
    "            output_dim = ENCODING_DIM\n",
    "        )\n",
    "    )\n",
    "    agent = neural_linucb_agent.NeuralLinUCBAgent(\n",
    "        time_step_spec=per_arm_tf_env.time_step_spec(),\n",
    "        action_spec=per_arm_tf_env.action_spec(),\n",
    "        encoding_network=network,\n",
    "        encoding_network_num_train_steps=EPS_PHASE_STEPS,\n",
    "        encoding_dim=ENCODING_DIM,\n",
    "        optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=LR),\n",
    "        alpha=1.0,\n",
    "        gamma=1.0,\n",
    "        epsilon_greedy=EPSILON,\n",
    "        accepts_per_arm_features=True,\n",
    "        debug_summaries=True,\n",
    "        summarize_grads_and_vars=True,\n",
    "        emit_policy_info=policy_utilities.InfoFields.PREDICTED_REWARDS_MEAN,\n",
    "    )\n",
    "    \n",
    "agent.initialize() # TODO - does this go here?\n",
    "    \n",
    "print(f\"Agent: {agent.name}\\n\")\n",
    "if network:\n",
    "    print(f\"Network: {network.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac59703a-9a00-4eba-a3b7-45b21b738dd4",
   "metadata": {},
   "source": [
    "## Trajectory function\n",
    "\n",
    "**parking lot**\n",
    "* does trajectory fn need concept of `dummy_chosen_arm_features`, similar to [this](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_base_policy.py#L297)\n",
    "\n",
    "```python\n",
    "      dummy_chosen_arm_features = tf.nest.map_structure(\n",
    "          lambda obs: tf.zeros_like(obs[:, 0, ...]),\n",
    "          time_step.observation[bandit_spec_utils.PER_ARM_FEATURE_KEY],\n",
    "      )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bcb31c7b-f03e-4d9f-a0f8-2f8ad8318d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "\n",
    "def _trajectory_fn(element, batch_size): # hparams\n",
    "        \n",
    "    \"\"\"Converts a dataset element into a trajectory.\"\"\"\n",
    "    global_features, user_info = _get_global_context_features(element) #new - user info passes on the raw user features for prompting with PALM\n",
    "    ###NEW - we are getting the arm features here\n",
    "    arm_features, movie_info = get_random_set_of_arm_features(n_actions=NUM_ACTIONS)\n",
    "    # arm_features = get_random_set_of_arm_features(n_actions=NUM_ACTIONS)\n",
    "    \n",
    "    #get the dot product reward of the feed-forward network\n",
    "    reward = llm_reward(user_info, movie_info, NUM_ACTIONS)\n",
    "    \n",
    "    reward = tf.constant(reward, tf.float32)\n",
    "    \n",
    "    #chose an arm\n",
    "    best_arm_ids = tf.argmax(reward, axis=1)\n",
    "    # best_arm_ids = tf.cast(best_arm_ids, dtype=tf.int32)\n",
    "    max_rewards = tf.math.reduce_max(reward, axis=1)\n",
    "    max_rewards = _add_outer_dimension(max_rewards) # add time dim\n",
    "    chosen_arm_feats = tf.gather(arm_features, best_arm_ids) # [batch_size, arm_features]\n",
    "    \n",
    "    chosen_arm_feats = _add_outer_dimension(chosen_arm_feats)\n",
    "    # Adds a time dimension.\n",
    "    # arm_features = _add_outer_dimension(arm_features)\n",
    "\n",
    "    # obs spec\n",
    "    observation = {\n",
    "        bandit_spec_utils.GLOBAL_FEATURE_KEY:\n",
    "            _add_outer_dimension(global_features), #timedim bloat\n",
    "        # bandit_spec_utils.PER_ARM_FEATURE_KEY:\n",
    "        #     _add_outer_dimension(arm_features)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    reward = _add_outer_dimension(reward)\n",
    "    \n",
    "    ###TODO - not sure if this should actually go in the action for trajectory\n",
    "    # best_arm_ids =  _add_outer_dimension(best_arm_ids)\n",
    "    \n",
    "    dummy_rewards = tf.zeros([batch_size, 1, NUM_ACTIONS])\n",
    "\n",
    "    \n",
    "    policy_info = policy_utilities.PerArmPolicyInfo(\n",
    "        chosen_arm_features=chosen_arm_feats,\n",
    "        # Pass dummy mean rewards here to match the model_spec for emitting\n",
    "        # mean rewards in policy info\n",
    "        predicted_rewards_mean=reward,\n",
    "        bandit_policy_type=tf.zeros([batch_size, 1, 1], dtype=tf.int32)\n",
    "    )\n",
    "    \n",
    "    if HPARAMS['model_type'] == 'neural_ucb':\n",
    "        policy_info = policy_info._replace(\n",
    "            predicted_rewards_optimistic=dummy_rewards\n",
    "        )\n",
    "        \n",
    "    return trajectory.single_step(\n",
    "        observation=observation,\n",
    "        action=tf.zeros_like(\n",
    "            max_rewards, dtype=tf.int32\n",
    "        ),  # Arm features are copied from policy info, put dummy zeros here\n",
    "        policy_info=policy_info,\n",
    "        reward=max_rewards,\n",
    "        discount=tf.zeros_like(max_rewards)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b3d3c-75f7-46f4-9a1b-6329e419b7f5",
   "metadata": {},
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bb7ffc-00df-4d46-857b-86c87b78f597",
   "metadata": {},
   "source": [
    "`agent.train(experience=...)`\n",
    "\n",
    "where `experience` is a batch of trajectories data in the form of a Trajectory. \n",
    "* The structure of experience must match that of `self.training_data_spec`. \n",
    "* All tensors in experience must be shaped [batch, time, ...] where time must be equal to self.train_step_length if that property is not None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4cf53ca1-f827-424f-adf4-0edaf863da42",
   "metadata": {},
   "outputs": [],
   "source": [
    "##todo - create a function that selects the best movie features along with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6332c741-cdff-4956-831f-fb68417fa52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 5)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE, NUM_ACTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9b4bf964-1028-4bb5-bf1d-939caac7904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.metrics import export_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "\n",
    "LOG_DIR = '.'\n",
    "agent.initialize() # TODO - does this go here?\n",
    "\n",
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "logging.info(f\" log_dir: {LOG_DIR}\")\n",
    "\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    LOG_DIR, flush_millis=10 * 1000\n",
    ")\n",
    "train_summary_writer.set_as_default()\n",
    "\n",
    "# ====================================================\n",
    "# metrics\n",
    "# ====================================================\n",
    "step_metric = tf_metrics.EnvironmentSteps()\n",
    "metrics = [\n",
    "    tf_metrics.NumberOfEpisodes(),\n",
    "    tf_metrics.AverageEpisodeLengthMetric(batch_size=HPARAMS['batch_size']),\n",
    "    tf_metrics.AverageReturnMetric(batch_size=HPARAMS['batch_size'])\n",
    "]\n",
    "# if additional_metrics:\n",
    "#     metrics += additional_metrics\n",
    "    \n",
    "metric_results = defaultdict(list)\n",
    "\n",
    "def _export_metrics_and_summaries(step, metrics):\n",
    "    \"\"\"Exports metrics and tf summaries.\"\"\"\n",
    "    metric_utils.log_metrics(metrics)\n",
    "    export_utils.export_metrics(step=step, metrics=metrics)\n",
    "    for metric in metrics:\n",
    "        metric.tf_summaries(train_step=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b15e87-8971-4721-8edc-50d3f4695ee6",
   "metadata": {},
   "source": [
    "## Generate the training trajectories to disk\n",
    "So we don't have to sync call the llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "18f674f3-faf3-4c93-8f66-c8e7b76dae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to save\n",
    "import pickle\n",
    "\n",
    "# os.mkdir('trajectories')\n",
    "\n",
    "def save_trajectories(trajectory, filename):\n",
    "    # Open a file for writing\n",
    "    with open(f\"{filename}.p\", \"wb\") as f:\n",
    "        # Write the dictionary to the file\n",
    "        pickle.dump(trajectory, f)\n",
    "\n",
    "    # Close the file\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "66007340-a77b-4fa4-8276-a9fbd0d79fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import collections\n",
    "# from tf_agents.utils import common\n",
    "# from tf_agents.eval import metric_utils\n",
    "# from tf_agents.policies import policy_saver\n",
    "# import time\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# ARTIFACTS_DIR = '.'\n",
    "# CHKPOINT_DIR = '.'\n",
    "\n",
    "# NUM_EPOCHS = 1\n",
    "# # NUM_ITERATION_PER_LOOP = NUM_ITER_STEPS\n",
    "# log_interval = 10\n",
    "\n",
    "# # global_step = tf.compat.v1.train.get_global_step()\n",
    "\n",
    "# # (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "# # agent.train = common.function(agent.train)\n",
    "\n",
    "# # Reset the train step\n",
    "# # agent.train_step_counter.assign(0)\n",
    "\n",
    "# train_step_counter = tf.compat.v1.train.get_or_create_global_step()\n",
    "# saver = policy_saver.PolicySaver(\n",
    "#     agent.policy, \n",
    "#     train_step=train_step_counter\n",
    "# )\n",
    "# starting_loop = 0\n",
    "\n",
    "# # train_loss = collections.defaultdict(list)\n",
    "# list_o_loss = []\n",
    "\n",
    "# print(f\"starting train loop...\")\n",
    "# start_time = time.time()\n",
    "\n",
    "# iterator = iter(train_dataset.batch(BATCH_SIZE))\n",
    "\n",
    "# for data in tqdm(iterator):\n",
    "\n",
    "\n",
    "#     trajectories = _trajectory_fn(data, BATCH_SIZE)\n",
    "#     # save_trajectories(trajectories, f'/home/jupyter/mab-bucket/trajectories/{str(starting_loop)}') #using gcsfuse for now\n",
    "#     # starting_loop += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4bfcb9d7-b24a-4526-ae2a-727ba0c55a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting train loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [01:05<1:48:19, 65.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0: loss = 22.940000534057617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 20/100 [19:44<1:16:18, 57.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 20: loss = 2.2100000381469727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|â–ˆâ–ˆ        | 21/100 [20:45<1:16:53, 58.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved policy to: .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [29:43<1:08:36, 58.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 30: loss = 1.190000057220459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [30:48<1:09:42, 60.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved policy to: .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [39:42<59:17, 59.29s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 40: loss = 0.8999999761581421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [40:44<58:52, 59.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved policy to: .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [49:49<50:02, 60.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 50: loss = 0.5400000214576721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [50:52<49:47, 60.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved policy to: .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [59:53<40:42, 61.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 60: loss = 0.3199999928474426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [1:00:55<39:51, 61.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved policy to: .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [1:10:17<29:33, 59.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 70: loss = 1.3799999952316284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [1:11:26<30:01, 62.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved policy to: .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [1:20:35<20:02, 60.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 80: loss = 1.0199999809265137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [1:21:36<19:06, 60.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved policy to: .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [1:30:52<10:30, 63.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 90: loss = 0.9900000095367432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [1:31:57<09:30, 63.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved policy to: .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [1:41:02<00:00, 60.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved trained policy to: .\n",
      "runtime_mins: 101\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from tf_agents.utils import common\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.policies import policy_saver\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "ARTIFACTS_DIR = '.'\n",
    "CHKPOINT_DIR = '.'\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "# NUM_ITERATION_PER_LOOP = NUM_ITER_STEPS\n",
    "log_interval = 10\n",
    "\n",
    "# global_step = tf.compat.v1.train.get_global_step()\n",
    "\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "# agent.train = common.function(agent.train)\n",
    "\n",
    "# Reset the train step\n",
    "# agent.train_step_counter.assign(0)\n",
    "\n",
    "train_step_counter = tf.compat.v1.train.get_or_create_global_step()\n",
    "saver = policy_saver.PolicySaver(\n",
    "    agent.policy, \n",
    "    train_step=train_step_counter\n",
    ")\n",
    "starting_loop = 0\n",
    "\n",
    "# train_loss = collections.defaultdict(list)\n",
    "list_o_loss = []\n",
    "\n",
    "print(f\"starting train loop...\")\n",
    "start_time = time.time()\n",
    "\n",
    "iterator = iter(train_dataset.batch(BATCH_SIZE))\n",
    "\n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "\n",
    "    # iterator = iter(train_dataset.batch(HPARAMS['batch_size']))\n",
    "    data = next(iterator)\n",
    "    # print(f\"print data: {data}\")\n",
    "\n",
    "    trajectories = _trajectory_fn(data, BATCH_SIZE)\n",
    "    # print(f\"print trajectories: {trajectories}\")\n",
    "\n",
    "    # All tensors in experience must be shaped [batch, time, ...] \n",
    "    step = agent.train_step_counter.numpy()\n",
    "    loss = agent.train(experience=trajectories)\n",
    "    list_o_loss.append(loss.loss.numpy())\n",
    "\n",
    "    _export_metrics_and_summaries(\n",
    "        step=epoch, \n",
    "        metrics=metrics\n",
    "    )\n",
    "    \n",
    "    # print \n",
    "    if log_interval and step % log_interval == 0:\n",
    "        print(\n",
    "            'step = {0}: loss = {1}'.format(\n",
    "                step, round(loss.loss.numpy(), 2)\n",
    "            )\n",
    "        )\n",
    "        # print(f\"trajectories: {trajectories}\")\n",
    "        \n",
    "    if epoch > 0 and epoch % log_interval == 0:\n",
    "        saver.save(os.path.join(CHKPOINT_DIR, 'policy_%d' % step_metric.result()))\n",
    "        print(f\"saved policy to: {CHKPOINT_DIR}\")\n",
    "        \n",
    "saver.save(ARTIFACTS_DIR)\n",
    "print(f\"saved trained policy to: {ARTIFACTS_DIR}\")\n",
    "    \n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"runtime_mins: {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313f23f1-6870-48fb-97fd-1bda065edffc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualize the agent's loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a4c4dc23-83fe-465b-aff6-c786a0866408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_o_loss)\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3138762-d440-4495-bd66-435978fb446a",
   "metadata": {},
   "source": [
    "## We now have a policy that learned from home-grown rating data using PALM!\n",
    "\n",
    "Now we can use the trained policy network to offer up the best arms from the policy (e.g. highest rated movie) or offer up a random arm based on epsilon random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d27159ad-d226-4c6a-9210-2301e0c98579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f1e0877bcd0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "POLICY_URI='.'\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "460efbb7-e381-4a01-8046-452718a411af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(), dtype=dtype('int32'), name='action_spec', minimum=0, maximum=4)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_policy.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "443da21b-f2da-4fb4-972e-3383608c9a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_step(\n",
    "    feature, \n",
    "    reward_np\n",
    "):\n",
    "    \n",
    "    infer_step = ts.TimeStep(\n",
    "        tf.constant(\n",
    "            ts.StepType.FIRST, \n",
    "            dtype=tf.int32, \n",
    "            shape=[],\n",
    "            name='step_type'\n",
    "        ),\n",
    "        tf.constant(\n",
    "            reward_np, dtype=tf.float32, shape=[], name='reward'\n",
    "        ),\n",
    "        tf.constant(\n",
    "            1.0, dtype=tf.float32, shape=[], name='discount'\n",
    "        ),\n",
    "        feature\n",
    "    )\n",
    "    \n",
    "    return infer_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2bd445b9-c99a-4c5e-b15d-3233abf8a767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(4, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([5.393278 , 4.6270595, 4.6910663, 5.060456 , 4.645522 ],\n",
       "      dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([2], dtype=int32), chosen_arm_features=array([-0.0055027 ,  0.02529171,  0.03858012, -0.00722548,  0.00300199,\n",
       "        0.03463811, -0.03863857,  0.04823556, -0.01914558,  0.01559823,\n",
       "        0.02645048, -0.03492063, -0.01787568, -0.01115205, -0.03905399,\n",
       "       -0.0137578 ], dtype=float32)))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SKIP_NUM = 10\n",
    "INFER_SIZE = 1\n",
    "\n",
    "# iterator = iter(train_dataset.skip(SKIP_NUM).batch(INFER_SIZE))\n",
    "data = next(iterator)\n",
    "\n",
    "global_feat_infer, user_side_info = _get_global_context_features(data) #new - user info passes on the raw user features for prompting with PALM\n",
    "###NEW - we are getting the arm features here\n",
    "arm_feat_infer, movie_side_info = get_random_set_of_arm_features(n_actions=NUM_ACTIONS)\n",
    "\n",
    "# print(user_info, movie_info)\n",
    "\n",
    "# rewards = _get_rewards(x)\n",
    "rewards = reward = llm_reward(user_side_info, movie_side_info, NUM_ACTIONS)\n",
    "\n",
    "feature = {'global': global_feat_infer, 'per_arm': arm_feat_infer}\n",
    "\n",
    "# rewards = [[4.0, 3.0, 3.0, 2.0, 3.0]] #documentation\n",
    "\n",
    "feature = {'global': tf.squeeze(global_feat_infer), 'per_arm': tf.squeeze(arm_feat_infer)}\n",
    "\n",
    "trajectory_step = get_eval_step(feature, np.array(0))\n",
    "trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6044a365-d14b-432f-b837-9336732402f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exploration vs Exploitation \n",
    "\n",
    "```python\n",
    "PolicyStep(action=array(4, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([5.393278 , 4.6270595, 4.6910663, 5.060456 , 4.645522 ],\n",
    "      dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([2], dtype=int32), chosen_arm_features=array([-0.0055027 ,  0.02529171,  0.03858012, -0.00722548,  0.00300199,\n",
    "        0.03463811, -0.03863857,  0.04823556, -0.01914558,  0.01559823,\n",
    "        0.02645048, -0.03492063, -0.01787568, -0.01115205, -0.03905399,\n",
    "       -0.0137578 ], dtype=float32)))\n",
    "```\n",
    "\n",
    "Note `bandit_policy_type=array([2], dtype=int32)` - this is when the uniform disgtribution \"dice\" roll was less than epsilon (0.2 in this case). The random arm pull was the first movie as represented by:\n",
    "\n",
    "`action=array(4, dtype=int32)`\n",
    "\n",
    "Note the network is sayin the 5th suggested movie has one of the lowest predicted rewards mean (4.64) vs the \"best\" predicted reward of 5.39 for the first movie. \n",
    "\n",
    "```\n",
    "[[b'Metro (1997)', array([0])],\n",
    " [b\"'Til There Was You (1997)\", array([7])],\n",
    " [b'Murder in the First (1995)', array([7])],\n",
    " [b'U Turn (1997)', array([0])],\n",
    " [b'Powder (1995)', array([7])]]\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb46991-2d10-4539-80c8-8ad124ac80f0",
   "metadata": {},
   "source": [
    "### End! This is where the refine stage picks up and real-user feedback is gathered to train fine tune the LLM and begin the process again. "
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m110"
  },
  "kernelspec": {
   "display_name": "TensorFlow 2-11 (Local)",
   "language": "python",
   "name": "local-conda-env-tensorflow-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
