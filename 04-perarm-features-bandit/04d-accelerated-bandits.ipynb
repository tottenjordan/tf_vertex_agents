{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e406936-2fb6-4a23-a6dd-e51977dc5ee2",
   "metadata": {},
   "source": [
    "# Using GPUs & TPUs with TF-Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965670ad-987d-401e-aeca-f0492a52dbea",
   "metadata": {},
   "source": [
    "## Load notebook config\n",
    "\n",
    "* use the prefix defined in `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09b8d292-a86a-4c1c-9b22-244b0d28dc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = 'mabv1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c137c648-e01c-4288-900c-608bd1f7bdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"mabv1\"\n",
      "VERSION                  = \"v1\"\n",
      "\n",
      "BUCKET_NAME              = \"mabv1-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://mabv1-hybrid-vertex-bucket/data\"\n",
      "BUCKET_URI               = \"gs://mabv1-hybrid-vertex-bucket\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_ID      = \"hybrid-vertex.movielens_dataset_mabv1\"\n",
      "BIGQUERY_TABLE_ID        = \"hybrid-vertex.movielens_dataset_mabv1.training_dataset\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd20dda8-6c27-4690-9981-59c251dc602b",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc94ebe3-7952-4ed2-8b3d-e1764cb60c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37bc712f-c7d9-442a-ad92-9d865fa4faab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from collections import defaultdict\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pickle as pkl\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud import storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.metrics import tf_metrics\n",
    "\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent\n",
    "from tf_agents.bandits.agents import neural_linucb_agent\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.bandits.policies import policy_utilities\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.policies import policy_saver\n",
    "\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.train.utils import spec_utils\n",
    "from tf_agents.train.utils import strategy_utils\n",
    "from tf_agents.train.utils import train_utils\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# this repo\n",
    "from src.per_arm_rl import data_utils\n",
    "from src.per_arm_rl import data_config\n",
    "from src.per_arm_rl import train_utils as train_utils\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f884f232-2c14-43a9-b90e-ec80b25736d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.perarm_features import agent_factory as agent_factory\n",
    "from src.perarm_features import reward_factory as reward_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03eb0137-aff7-43f3-929b-03568d4cf287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2522f6a-3826-4509-bd9b-f878c74ca8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "865d4b19-a078-44d3-b0bd-f407a16f6a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "vertex_ai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e75a40f-00ca-4bf9-93f8-063a1056ba48",
   "metadata": {},
   "source": [
    "### Generate Vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "960f5c54-cee3-4563-ba77-4062265a6447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE_VOCABS: False\n"
     ]
    }
   ],
   "source": [
    "GENERATE_VOCABS = False\n",
    "print(f\"GENERATE_VOCABS: {GENERATE_VOCABS}\")\n",
    "\n",
    "VOCAB_SUBDIR   = \"vocabs\"\n",
    "VOCAB_FILENAME = \"vocab_dict.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa227f5c-364b-4488-b65f-617a3a80cf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab...\n",
      "Downloaded vocab from: gs://mabv1-hybrid-vertex-bucket/vocabs/vocab_dict.pkl\n",
      "\n",
      "'movie_id'\n",
      "'user_id'\n",
      "'user_occupation_text'\n",
      "'movie_genres'\n",
      "'bucketized_user_age'\n",
      "'max_timestamp'\n",
      "'min_timestamp'\n",
      "'timestamp_buckets'\n"
     ]
    }
   ],
   "source": [
    "if not GENERATE_VOCABS:\n",
    "\n",
    "    EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{VOCAB_SUBDIR}/{VOCAB_FILENAME}'\n",
    "    print(f\"Downloading vocab...\")\n",
    "    \n",
    "    os.system(f'gsutil -q cp {EXISTING_VOCAB_FILE} .')\n",
    "    print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "    filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "    VOCAB_DICT = pkl.load(filehandler)\n",
    "    filehandler.close()\n",
    "    \n",
    "    for key in VOCAB_DICT.keys():\n",
    "        pprint(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef26da66-7284-4b5e-82cd-f261400726aa",
   "metadata": {},
   "source": [
    "### train config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e71482f-b262-46f7-9bd2-c492b7df5189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_OOV_BUCKETS        : 1\n",
      "GLOBAL_EMBEDDING_SIZE  : 16\n",
      "MV_EMBEDDING_SIZE      : 32\n",
      "GLOBAL_DIM             : 64\n",
      "PER_ARM_DIM            : 64\n",
      "BATCH_SIZE             : 128\n",
      "EVAL_BATCH_SIZE        : 1\n",
      "NUM_ACTIONS            : 2\n"
     ]
    }
   ],
   "source": [
    "NUM_OOV_BUCKETS        = 1\n",
    "GLOBAL_EMBEDDING_SIZE  = 16\n",
    "MV_EMBEDDING_SIZE      = 32 #32\n",
    "\n",
    "GLOBAL_DIM             = 64\n",
    "PER_ARM_DIM            = 64\n",
    "\n",
    "BATCH_SIZE             = 128\n",
    "EVAL_BATCH_SIZE        = 1\n",
    "NUM_ACTIONS            = 2 \n",
    "#this is kinda deceptive - \n",
    "#our approach is to learn by \"flashing\" one movie rating at a time per user context. \n",
    "#The n_actions = show/don't show the movie with one degree of freedom (n-1)\n",
    "\n",
    "print(f\"NUM_OOV_BUCKETS        : {NUM_OOV_BUCKETS}\")\n",
    "print(f\"GLOBAL_EMBEDDING_SIZE  : {GLOBAL_EMBEDDING_SIZE}\")\n",
    "print(f\"MV_EMBEDDING_SIZE      : {MV_EMBEDDING_SIZE}\")\n",
    "print(f\"GLOBAL_DIM             : {GLOBAL_DIM}\")\n",
    "print(f\"PER_ARM_DIM            : {PER_ARM_DIM}\")\n",
    "print(f\"BATCH_SIZE             : {BATCH_SIZE}\")\n",
    "print(f\"EVAL_BATCH_SIZE        : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"NUM_ACTIONS            : {NUM_ACTIONS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0fc38cb-ab46-4b53-a38e-1b853d86a0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# get global_context_sampling_fn\n",
    "# ====================================================\n",
    "def _get_global_context_features(x):\n",
    "    \"\"\"\n",
    "    This function generates a single global observation vector.\n",
    "    \"\"\"\n",
    "    user_id_model = agent_factory.get_user_id_emb_model(\n",
    "        vocab_dict=VOCAB_DICT, \n",
    "        num_oov_buckets=NUM_OOV_BUCKETS, \n",
    "        global_emb_size=GLOBAL_EMBEDDING_SIZE\n",
    "    )\n",
    "    user_age_model = agent_factory.get_user_age_emb_model(\n",
    "        vocab_dict=VOCAB_DICT, \n",
    "        num_oov_buckets=NUM_OOV_BUCKETS, \n",
    "        global_emb_size=GLOBAL_EMBEDDING_SIZE\n",
    "    )\n",
    "    user_occ_model = agent_factory.get_user_occ_emb_model(\n",
    "        vocab_dict=VOCAB_DICT, \n",
    "        num_oov_buckets=NUM_OOV_BUCKETS, \n",
    "        global_emb_size=GLOBAL_EMBEDDING_SIZE\n",
    "    )\n",
    "    user_ts_model = agent_factory.get_ts_emb_model(\n",
    "        vocab_dict=VOCAB_DICT, \n",
    "        num_oov_buckets=NUM_OOV_BUCKETS, \n",
    "        global_emb_size=GLOBAL_EMBEDDING_SIZE\n",
    "    )\n",
    "\n",
    "    # for x in train_dataset.batch(1).take(1):\n",
    "    user_id_value = x['user_id']\n",
    "    user_age_value = x['bucketized_user_age']\n",
    "    user_occ_value = x['user_occupation_text']\n",
    "    user_ts_value = x['timestamp']\n",
    "\n",
    "    _id = user_id_model(user_id_value)\n",
    "    _age = user_age_model(user_age_value)\n",
    "    _occ = user_occ_model(user_occ_value)\n",
    "    _ts = user_ts_model(user_ts_value)\n",
    "\n",
    "    # to numpy array\n",
    "    _id = np.array(_id.numpy())\n",
    "    _age = np.array(_age.numpy())\n",
    "    _occ = np.array(_occ.numpy())\n",
    "    _ts = np.array(_ts.numpy())\n",
    "\n",
    "    concat = np.concatenate(\n",
    "        [_id, _age, _occ, _ts], axis=-1\n",
    "    ).astype(np.float32)\n",
    "\n",
    "    return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d79cc451-b926-454d-84c2-b0542fdde62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# get per_arm_context_sampling_fn\n",
    "# ====================================================\n",
    "def _get_per_arm_features(x):\n",
    "    \"\"\"\n",
    "    This function generates a single per-arm observation vector\n",
    "    \"\"\"\n",
    "\n",
    "    mvid_model = agent_factory.get_mv_id_emb_model(\n",
    "        vocab_dict=VOCAB_DICT, \n",
    "        num_oov_buckets=NUM_OOV_BUCKETS, \n",
    "        mv_emb_size=MV_EMBEDDING_SIZE\n",
    "    )\n",
    "\n",
    "    mvgen_model = agent_factory.get_mv_gen_emb_model(\n",
    "        vocab_dict=VOCAB_DICT, \n",
    "        num_oov_buckets=NUM_OOV_BUCKETS, \n",
    "        mv_emb_size=MV_EMBEDDING_SIZE\n",
    "    )\n",
    "\n",
    "    # for x in train_dataset.batch(1).take(1):\n",
    "    mv_id_value = x['movie_id']\n",
    "    mv_gen_value = x['movie_genres'] #[0]\n",
    "\n",
    "    _mid = mvid_model(mv_id_value)\n",
    "    _mgen = mvgen_model(mv_gen_value)\n",
    "\n",
    "    # to numpy array\n",
    "    _mid = np.array(_mid.numpy())\n",
    "    _mgen = np.array(_mgen.numpy())\n",
    "\n",
    "    concat = np.concatenate(\n",
    "        [_mid, _mgen], axis=-1\n",
    "    ).astype(np.float32)\n",
    "\n",
    "    return concat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d59ad1-e850-4bb3-ae4a-94efcbb89c9b",
   "metadata": {},
   "source": [
    "### TensorSpecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f03d7f8d-a168-4e47-92f1-5242fc723599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_spec = {\n",
    "    'global': tf.TensorSpec([GLOBAL_DIM], tf.float32),\n",
    "    'per_arm': tf.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32) #excluding action dim here\n",
    "}\n",
    "observation_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b927e6a2-d01c-4e9b-866f-9afaba5bb795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=[], \n",
    "    dtype=tf.int32,\n",
    "    minimum=tf.constant(0),            \n",
    "    maximum=NUM_ACTIONS-1, # n degrees of freedom and will dictate the expected mean reward spec shape\n",
    "    name=\"action_spec\"\n",
    ")\n",
    "\n",
    "action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd146ddd-0bf6-47c8-baf9-a81633909211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec = ts.time_step_spec(\n",
    "    observation_spec = observation_spec, \n",
    "    # reward_spec = _reward_spec\n",
    ")\n",
    "time_step_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f73646-b69e-4f1a-960b-055602fd36fa",
   "metadata": {},
   "source": [
    "## Distribution strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226a2cd7-5484-4db2-b7ac-a57a61a452f5",
   "metadata": {},
   "source": [
    "Use `strategy_utils` to generate a strategy. Under the hood, passing the parameter:\n",
    "\n",
    "* `use_gpu = False` returns `tf.distribute.get_strategy()`, which uses CPU\n",
    "* `use_gpu = True` returns `tf.distribute.MirroredStrategy()`, which uses all GPUs that are visible to TensorFlow on one machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecc864c3-4937-45c6-9a9c-a46a42f6c2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_IN_NOTEBOOK = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2aedc5c8-788e-443b-994b-3c4021a273a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.distribute.mirrored_strategy.MirroredStrategy at 0x7f82cfd10b20>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_gpu = True\n",
    "use_tpu = False\n",
    "\n",
    "distribution_strategy = strategy_utils.get_strategy(tpu=use_tpu, use_gpu=use_gpu)\n",
    "distribution_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afc5e2da-e5f0-4056-9e07-4797834ddfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution_strategy = tf.distribute.MirroredStrategy()\n",
    "# distribution_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ccdd846-9373-402d-a9d3-7c9fe90b5dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution_strategy.cluster_resolver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ff56f57-7dfa-45fd-9c65-dcfe62b0c1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.distribute.get_strategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86791ffd-ae3c-4558-8a08-335abb242a9c",
   "metadata": {},
   "source": [
    "### Agent Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d8ff74e-fcdd-4523-838d-68e399bbb39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'common_layers': [16, 8],\n",
      " 'epsilon': 0.01,\n",
      " 'eval_batch_size': 1,\n",
      " 'global_layers': [64, 32, 16],\n",
      " 'learning_rate': 0.05,\n",
      " 'model_type': 'epsGreedy',\n",
      " 'network_type': 'commontower',\n",
      " 'num_actions': 2,\n",
      " 'num_eval_steps': 10000,\n",
      " 'per_arm_layers': [64, 32, 16]}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Agents\n",
    "# ================================\n",
    "AGENT_TYPE      = 'epsGreedy' # 'LinUCB' | 'LinTS |, 'epsGreedy' | 'NeuralLinUCB'\n",
    "\n",
    "# Parameters for linear agents (LinUCB and LinTS).\n",
    "AGENT_ALPHA     = 0.1\n",
    "\n",
    "# Parameters for neural agents (NeuralEpsGreedy and NerualLinUCB).\n",
    "EPSILON         = 0.01\n",
    "LR              = 0.05\n",
    "\n",
    "# Parameters for NeuralLinUCB\n",
    "ENCODING_DIM    = 1\n",
    "EPS_PHASE_STEPS = 1000\n",
    "\n",
    "NUM_EVAL_STEPS = 10000\n",
    "\n",
    "# ================================\n",
    "# Agent's Preprocess Network\n",
    "# ================================\n",
    "NETWORK_TYPE    = \"commontower\" # 'commontower' | 'dotproduct'\n",
    "\n",
    "if AGENT_TYPE == 'NeuralLinUCB':\n",
    "    NETWORK_TYPE = 'commontower'\n",
    "    \n",
    "GLOBAL_LAYERS   = [64, 32, 16]\n",
    "ARM_LAYERS      = [64, 32, 16]\n",
    "COMMON_LAYERS   = [16, 8]\n",
    "\n",
    "HPARAMS = {  # TODO - streamline and consolidate\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"eval_batch_size\" : EVAL_BATCH_SIZE,\n",
    "    \"num_actions\": NUM_ACTIONS,\n",
    "    \"model_type\": AGENT_TYPE,\n",
    "    \"network_type\": NETWORK_TYPE,\n",
    "    \"global_layers\": GLOBAL_LAYERS,\n",
    "    \"per_arm_layers\": ARM_LAYERS,\n",
    "    \"common_layers\": COMMON_LAYERS,\n",
    "    \"learning_rate\": LR,\n",
    "    \"epsilon\": EPSILON,\n",
    "    \"num_eval_steps\": NUM_EVAL_STEPS,\n",
    "}\n",
    "pprint(HPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c91c23cb-62cc-403a-9802-de3e887f8f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: OffpolicyNeuralEpsGreedyAgent\n",
      "Network: global_and_arm_common_tower_network\n"
     ]
    }
   ],
   "source": [
    "with distribution_strategy.scope():\n",
    "    \n",
    "    global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "    agent, network = agent_factory._get_agent(\n",
    "        agent_type=AGENT_TYPE, \n",
    "        network_type=NETWORK_TYPE, \n",
    "        time_step_spec=time_step_spec, \n",
    "        action_spec=action_spec, \n",
    "        observation_spec=observation_spec,\n",
    "        global_step = global_step,\n",
    "        global_layers = GLOBAL_LAYERS,\n",
    "        arm_layers = ARM_LAYERS,\n",
    "        common_layers = COMMON_LAYERS,\n",
    "        agent_alpha = AGENT_ALPHA,\n",
    "        learning_rate = LR,\n",
    "        epsilon = EPSILON,\n",
    "        encoding_dim = ENCODING_DIM,\n",
    "        eps_phase_steps = EPS_PHASE_STEPS,\n",
    "    )\n",
    "    \n",
    "agent.initialize()\n",
    "\n",
    "print(f\"Agent: {agent.name}\")\n",
    "\n",
    "if network:\n",
    "    print(f\"Network: {network}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5338c598-1c22-409b-8f67-b4a906d579ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _trajectory_fn(element): # hparams\n",
    "    \n",
    "    \"\"\"Converts a dataset element into a trajectory.\"\"\"\n",
    "    global_features = _get_global_context_features(element)\n",
    "    arm_features = _get_per_arm_features(element)\n",
    "    \n",
    "    # Adds a time dimension.\n",
    "    arm_features = train_utils._add_outer_dimension(arm_features)\n",
    "\n",
    "    # obs spec\n",
    "    observation = {\n",
    "        bandit_spec_utils.GLOBAL_FEATURE_KEY:\n",
    "            train_utils._add_outer_dimension(global_features),\n",
    "    }\n",
    "\n",
    "    reward = train_utils._add_outer_dimension(reward_factory._get_rewards(element))\n",
    "\n",
    "    # To emit the predicted rewards in policy_info, we need to create dummy\n",
    "    # rewards to match the definition in TensorSpec for the ones specified in\n",
    "    # emit_policy_info set.\n",
    "    dummy_rewards = tf.zeros([HPARAMS['batch_size'], 1, HPARAMS['num_actions']])\n",
    "    policy_info = policy_utilities.PerArmPolicyInfo(\n",
    "        chosen_arm_features=arm_features,\n",
    "        # Pass dummy mean rewards here to match the model_spec for emitting\n",
    "        # mean rewards in policy info\n",
    "        predicted_rewards_mean=dummy_rewards,\n",
    "        bandit_policy_type=policy_utilities.BanditPolicyType.GREEDY\n",
    "    )\n",
    "    \n",
    "    if HPARAMS['model_type'] == 'neural_ucb':\n",
    "        policy_info = policy_info._replace(\n",
    "            predicted_rewards_optimistic=dummy_rewards\n",
    "        )\n",
    "        \n",
    "    return trajectory.single_step(\n",
    "        observation=observation,\n",
    "        action=tf.zeros_like(\n",
    "            reward, dtype=tf.int32\n",
    "        ),  # Arm features are copied from policy info, put dummy zeros here\n",
    "        policy_info=policy_info,\n",
    "        reward=reward,\n",
    "        discount=tf.zeros_like(reward)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a495555e-432f-4e37-8071-57ca41b0de96",
   "metadata": {},
   "source": [
    "### Vertex Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c7e5d67-72cd-48f3-aa63-534b11fdca47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set experiment in `train_perarm` script section below...\n"
     ]
    }
   ],
   "source": [
    "if RUN_IN_NOTEBOOK:\n",
    "    \n",
    "    EXPERIMENT_NAME   = f'acc-paf-v2'\n",
    "\n",
    "    # new experiment\n",
    "    invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "    BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "    LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "    ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "    ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "    vertex_ai.init(\n",
    "        project=PROJECT_ID,\n",
    "        location=REGION,\n",
    "        experiment=EXPERIMENT_NAME\n",
    "    )\n",
    "\n",
    "    print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "    print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "    print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "    print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "    print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "    print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")\n",
    "    \n",
    "else:\n",
    "    print(\"set experiment in `train_perarm` script section below...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf54b29d-4beb-403b-a558-88e2ee0c9288",
   "metadata": {},
   "source": [
    "### Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a07fbf44-d79a-4a18-a071-9446b30cf9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac2ac9d0-59e5-4e42-835e-22fe756e679a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset defined in `train_perarm` script\n"
     ]
    }
   ],
   "source": [
    "if RUN_IN_NOTEBOOK:\n",
    "    \n",
    "    train_files = []\n",
    "    for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/train'):\n",
    "        if '.tfrecord' in blob.name:\n",
    "            train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "    print(train_files)\n",
    "\n",
    "    train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "    train_dataset = train_dataset.map(data_utils.parse_tfrecord)\n",
    "\n",
    "    train_dataset = train_dataset.cache()\n",
    "    train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # train_ds_iterator = iter(train_dataset)\n",
    "    train_ds_iterator = iter(train_dataset.batch(HPARAMS['batch_size']))\n",
    "\n",
    "    print(f\"train_ds_iterator: {train_ds_iterator}\")\n",
    "    \n",
    "else:\n",
    "    print(\"train dataset defined in `train_perarm` script\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ecda2ad3-054e-420b-b8a2-686a69066c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1):\n",
    "    \n",
    "#     # iterator = iter(train_dataset.batch(1))\n",
    "#     data = next(train_ds_iterator)\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b471ec86-c033-489a-812d-79227c6624fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval dataset defined in `train_perarm` script\n"
     ]
    }
   ],
   "source": [
    "if RUN_IN_NOTEBOOK:\n",
    "    \n",
    "    val_files = []\n",
    "    for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/val'):\n",
    "        if '.tfrecord' in blob.name:\n",
    "            val_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "    val_dataset = tf.data.TFRecordDataset(val_files)\n",
    "\n",
    "    # val_dataset.repeat().batch(HPARAMS['eval_batch_size'])\n",
    "\n",
    "    val_dataset = val_dataset.map(data_utils.parse_tfrecord) #, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    # eval_ds = val_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    eval_ds = val_dataset.batch(HPARAMS[\"eval_batch_size\"])\n",
    "\n",
    "    # train_ds_iterator = iter(dist_train_ds)\n",
    "    if HPARAMS['num_eval_steps'] > 0:\n",
    "        eval_ds = eval_ds.take(HPARAMS['num_eval_steps'])\n",
    "\n",
    "    eval_ds = eval_ds.cache()\n",
    "\n",
    "    print(f\"eval_ds: {eval_ds}\")\n",
    "    \n",
    "else:\n",
    "    print(\"eval dataset defined in `train_perarm` script\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e43841a9-9c4b-4d47-b586-eca40a614825",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_IN_NOTEBOOK:\n",
    "    # ====================================================\n",
    "    # TB summary writer\n",
    "    # ====================================================\n",
    "    with distribution_strategy.scope():\n",
    "        train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "            f\"{LOG_DIR}/train\", flush_millis=10 * 1000\n",
    "        )\n",
    "\n",
    "        train_summary_writer.set_as_default()\n",
    "        \n",
    "else:\n",
    "    print(\"set summary writer below...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62864779-26cd-4667-83c2-f1dce552ab02",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a37abe7f-706c-49dc-b7fc-3d111cdfba78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics defined in `train_perarm` script\n"
     ]
    }
   ],
   "source": [
    "if RUN_IN_NOTEBOOK:\n",
    "    # ====================================================\n",
    "    # metrics\n",
    "    # ====================================================\n",
    "    step_metric = tf_metrics.EnvironmentSteps()\n",
    "    metrics = [\n",
    "        # tf_metrics.NumberOfEpisodes(),\n",
    "        # tf_metrics.AverageEpisodeLengthMetric(batch_size=batch_size),\n",
    "        tf_metrics.AverageReturnMetric(batch_size=HPARAMS['batch_size'])\n",
    "    ]\n",
    "    pprint(f\"metrics: {metrics}\")\n",
    "    \n",
    "else:\n",
    "    print(\"metrics defined in `train_perarm` script\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec30da87-4f62-4189-b2a0-35380b91ee8e",
   "metadata": {},
   "source": [
    "### Policy Saver & Chkpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f60e00d-5edf-42c4-b4ad-98bf5b105121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chkpt and saver defined in `train_perarm` script\n"
     ]
    }
   ],
   "source": [
    "if RUN_IN_NOTEBOOK:\n",
    "    \n",
    "    # ====================================================\n",
    "    # get checkpoint manager\n",
    "    # ====================================================\n",
    "    CHKPOINT_DIR = f\"{ROOT_DIR}/chkpoint\"\n",
    "    print(f\"setting checkpoint_manager: {CHKPOINT_DIR}\")\n",
    "\n",
    "    checkpoint_manager = train_utils.restore_and_get_checkpoint_manager(\n",
    "        root_dir=CHKPOINT_DIR, \n",
    "        agent=agent, \n",
    "        metrics=metrics, \n",
    "        step_metric=step_metric\n",
    "    )\n",
    "    # ====================================================\n",
    "    # policy saver\n",
    "    # ====================================================\n",
    "    saver = policy_saver.PolicySaver(\n",
    "        agent.policy, \n",
    "        train_step=global_step\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    print(\"chkpt and saver defined in `train_perarm` script\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a6d089-1f39-4d99-acce-f55a3ad3eec8",
   "metadata": {},
   "source": [
    "# [1] Run simple, in-notebook train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "828f3037-564d-4ce6-9fc1-23698a1355af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_ITER_STEPS = 100\n",
    "log_interval   = 10\n",
    "CHKPT_INTERVAL = 200\n",
    "\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49417d08-a433-41ca-8cc5-1b63b00a08ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.profiler.experimental.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ea849d9-f92d-4572-8d99-1a7d258f303d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting train loop...\n",
      "step = 0: train loss = 15.90999984741211\n",
      "step = 10: train loss = 2.4000000953674316\n",
      "step = 20: train loss = 1.6100000143051147\n",
      "step = 30: train loss = 1.4900000095367432\n",
      "step = 40: train loss = 1.059999942779541\n",
      "step = 50: train loss = 1.4800000190734863\n",
      "step = 60: train loss = 1.4199999570846558\n",
      "step = 70: train loss = 1.4299999475479126\n",
      "step = 80: train loss = 1.4199999570846558\n",
      "step = 90: train loss = 1.399999976158142\n",
      "step = 100: train loss = 1.590000033378601\n",
      "step = 110: train loss = 1.4299999475479126\n",
      "step = 120: train loss = 1.2400000095367432\n",
      "step = 130: train loss = 1.0499999523162842\n",
      "step = 140: train loss = 1.190000057220459\n",
      "train runtime_mins: 2\n",
      "saved trained policy to: gs://mabv1-hybrid-vertex-bucket/acc-paf-v2/run-20230822-114115/artifacts\n"
     ]
    }
   ],
   "source": [
    "if RUN_IN_NOTEBOOK:\n",
    "    # ====================================================\n",
    "    # train loop\n",
    "    # ====================================================\n",
    "    list_o_loss = []\n",
    "\n",
    "    print(f\"starting train loop...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    tf.profiler.experimental.start(LOG_DIR) # LOG_DIR | PROFILER_DIR\n",
    "\n",
    "    # for i in tqdm(range(NUM_ITER_STEPS)):\n",
    "    for i in range(NUM_ITER_STEPS):\n",
    "\n",
    "        with train_summary_writer.as_default():\n",
    "\n",
    "            data = next(train_ds_iterator)\n",
    "            trajectories = _trajectory_fn(data)\n",
    "\n",
    "            # All tensors in experience must be shaped [batch, time, ...] \n",
    "            step = agent.train_step_counter.numpy()\n",
    "            loss = agent.train(experience=trajectories)\n",
    "            list_o_loss.append(loss.loss.numpy())\n",
    "\n",
    "            train_utils._export_metrics_and_summaries(\n",
    "                step=i, \n",
    "                metrics=metrics\n",
    "            )\n",
    "\n",
    "            # print step loss\n",
    "            if step % log_interval == 0:\n",
    "                print(\n",
    "                    'step = {0}: train loss = {1}'.format(\n",
    "                        step, round(loss.loss.numpy(), 2)\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            if i > 0 and i % CHKPT_INTERVAL == 0:\n",
    "                saver.save(os.path.join(CHKPOINT_DIR, 'policy_%d' % step_metric.result()))\n",
    "                print(f\"saved policy to: {CHKPOINT_DIR}\")\n",
    "\n",
    "    tf.profiler.experimental.stop()\n",
    "\n",
    "    runtime_mins = int((time.time() - start_time) / 60)\n",
    "    print(f\"train runtime_mins: {runtime_mins}\")\n",
    "\n",
    "    saver.save(ARTIFACTS_DIR)\n",
    "    print(f\"saved trained policy to: {ARTIFACTS_DIR}\")\n",
    "    \n",
    "else:\n",
    "    print(\"skipping in-notebook loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27e84098-aa96-4b7a-bb9b-88ca48c73355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://mabv1-hybrid-vertex-bucket/acc-paf-v2/run-20230822-114115/logs'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOG_DIR # LOG_DIR | PROFILER_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2853412-1848-438e-94f0-140b472a8f8a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9edf005-80ab-4fd9-bde5-47b1df2c9d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20a8e844-3294-42fd-a230-bb479a20b5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-eba90a6e50b61c18\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-eba90a6e50b61c18\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LOG_DIR | PROFILER_DIR\n",
    "\n",
    "%tensorboard --logdir=$LOG_DIR  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a634d31-306f-445c-8d34-e431ee5839a2",
   "metadata": {},
   "source": [
    "# [2] Run `train_perarm.py` train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb73c9d5-1b50-40ef-8a3c-eb724fe81f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.profiler.experimental.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cd7b0e8-93aa-4846-b532-7b62dee81f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: OffpolicyNeuralEpsGreedyAgent\n",
      "Network: global_and_arm_common_tower_network\n"
     ]
    }
   ],
   "source": [
    "with distribution_strategy.scope():\n",
    "    \n",
    "    global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "    agent, network = agent_factory._get_agent(\n",
    "        agent_type=AGENT_TYPE, \n",
    "        network_type=NETWORK_TYPE, \n",
    "        time_step_spec=time_step_spec, \n",
    "        action_spec=action_spec, \n",
    "        observation_spec=observation_spec,\n",
    "        global_step = global_step,\n",
    "        global_layers = GLOBAL_LAYERS,\n",
    "        arm_layers = ARM_LAYERS,\n",
    "        common_layers = COMMON_LAYERS,\n",
    "        agent_alpha = AGENT_ALPHA,\n",
    "        learning_rate = LR,\n",
    "        epsilon = EPSILON,\n",
    "        encoding_dim = ENCODING_DIM,\n",
    "        eps_phase_steps = EPS_PHASE_STEPS,\n",
    "    )\n",
    "    \n",
    "agent.initialize()\n",
    "\n",
    "print(f\"Agent: {agent.name}\")\n",
    "\n",
    "if network:\n",
    "    print(f\"Network: {network}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55bf86b5-945e-46e7-b6e5-30e64e44870b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MirroredVariable:{\n",
       "  0: <tf.Variable 'global_step:0' shape=() dtype=int64, numpy=0>\n",
       "}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293aef61-3336-4041-befa-27cadbd756fa",
   "metadata": {},
   "source": [
    "## Vertex Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6037dde7-e446-40b3-8c9d-5913b6139147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : acc-paf-v2\n",
      "RUN_NAME          : run-20230822-213342\n",
      "\n",
      "BASE_OUTPUT_DIR   : gs://mabv1-hybrid-vertex-bucket/acc-paf-v2/run-20230822-213342\n",
      "LOG_DIR           : gs://mabv1-hybrid-vertex-bucket/acc-paf-v2/run-20230822-213342/logs\n",
      "ROOT_DIR          : gs://mabv1-hybrid-vertex-bucket/acc-paf-v2/run-20230822-213342/root\n",
      "ARTIFACTS_DIR     : gs://mabv1-hybrid-vertex-bucket/acc-paf-v2/run-20230822-213342/artifacts\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME   = f'acc-paf-v2'\n",
    "\n",
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "vertex_ai.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "033135a5-0fd2-421a-a172-5a15e1e28dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "with distribution_strategy.scope():\n",
    "    train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "        f\"{LOG_DIR}/train\", flush_millis=10 * 1000\n",
    "    )\n",
    "\n",
    "    train_summary_writer.set_as_default()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2b102e-35c9-4ff3-8ae0-6b15103c27de",
   "metadata": {},
   "source": [
    "## train loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e68792ed-9b90-47aa-80d8-d190c4580079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_ITER_STEPS       : 100\n",
      "STEPS_PER_LOOP       : 1\n",
      "LOG_INTERVAL         : 50\n",
      "CHKPT_INTERVAL       : 200\n",
      "NUM_EVAL_STEPS       : 100\n",
      "ASYNC_STEPS_PER_LOOP : 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.perarm_features import train_perarm as train_perarm\n",
    "\n",
    "NUM_ITER_STEPS       = 100\n",
    "STEPS_PER_LOOP       = 1\n",
    "LOG_INTERVAL         = 50\n",
    "CHKPT_INTERVAL       = 200\n",
    "NUM_EVAL_STEPS       = 100\n",
    "ASYNC_STEPS_PER_LOOP = 1\n",
    "\n",
    "print(f\"NUM_ITER_STEPS       : {NUM_ITER_STEPS}\")       #  = 50\n",
    "print(f\"STEPS_PER_LOOP       : {STEPS_PER_LOOP}\")       #  = 1\n",
    "print(f\"LOG_INTERVAL         : {LOG_INTERVAL}\")         #  = 10\n",
    "print(f\"CHKPT_INTERVAL       : {CHKPT_INTERVAL}\")       #  = 200\n",
    "print(f\"NUM_EVAL_STEPS       : {NUM_EVAL_STEPS}\")       #  = 100\n",
    "print(f\"ASYNC_STEPS_PER_LOOP : {ASYNC_STEPS_PER_LOOP}\") # = 1\n",
    "\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef52a68d-d601-4d64-8365-9df5998fae86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12800"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOTAL_TAKE = NUM_ITER_STEPS * HPARAMS['batch_size']\n",
    "TOTAL_TAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c56c7092-b4cb-420c-9b7c-6f1410a740de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distribution_strategy: <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f82df4d1090>\n",
      "train_files: ['gs://mabv1-hybrid-vertex-bucket/data/train/ml-ratings-100k-train.tfrecord']\n",
      "train_ds_iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f81b0787a00>\n",
      "setting checkpoint_manager: gs://mabv1-hybrid-vertex-bucket/acc-paf-v2/run-20230822-213342/root/chkpoint\n",
      "Did not find a pre-existing checkpoint. Starting from scratch.\n",
      "wrapping agent.train in tf-function\n",
      "starting_loop: 0\n",
      "starting train loop...\n",
      "step = 0: loss = 15.90999984741211\n",
      "step = 50: loss = 1.5700000524520874\n",
      "runtime_mins: 1\n",
      "saved trained policy to: gs://mabv1-hybrid-vertex-bucket/acc-paf-v2/run-20230822-213342/artifacts\n",
      "complete train job in 1 minutes\n"
     ]
    }
   ],
   "source": [
    "#start the timer and training\n",
    "start_time = time.time()\n",
    "\n",
    "metric_results, agent = train_perarm.train_perarm(\n",
    "    agent = agent,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    num_iterations = NUM_ITER_STEPS,\n",
    "    steps_per_loop = STEPS_PER_LOOP,\n",
    "    num_eval_steps = NUM_EVAL_STEPS,\n",
    "    # data\n",
    "    batch_size = HPARAMS['batch_size'],\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    # functions\n",
    "    _trajectory_fn = _trajectory_fn,\n",
    "    # _run_bandit_eval_fn = _run_bandit_eval,\n",
    "    # train intervals\n",
    "    chkpt_interval = CHKPT_INTERVAL,\n",
    "    log_interval = LOG_INTERVAL,\n",
    "    # dirs\n",
    "    bucket_name = BUCKET_NAME,\n",
    "    data_dir_prefix_path = DATA_GCS_PREFIX,\n",
    "    log_dir = LOG_DIR,\n",
    "    model_dir = ARTIFACTS_DIR,\n",
    "    root_dir = ROOT_DIR,\n",
    "    async_steps_per_loop = ASYNC_STEPS_PER_LOOP,\n",
    "    resume_training_loops = False,\n",
    "    use_gpu = True,\n",
    "    use_tpu = False,\n",
    "    profiler = True,\n",
    "    train_summary_writer = train_summary_writer,\n",
    "    total_take = TOTAL_TAKE,\n",
    "    global_step = global_step\n",
    "    # additional_metrics = metrics,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"complete train job in {runtime_mins} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae8de567-c152-4deb-99dc-54ed840c9e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e9ba7b2d-3ee7-478a-b634-c809a895103d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7b6f96c691aedae5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7b6f96c691aedae5\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=$LOG_DIR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c027d7ab-b0ae-4801-b0c5-8729a1d826a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
