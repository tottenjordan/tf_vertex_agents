{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64583cdb-2502-4f40-a254-8fa68abe7a32",
   "metadata": {},
   "source": [
    "# Build custom container for Vertex training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e1beb37-0c48-4110-8ca0-24ab78c72b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/04-perarm-features-bandit\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66298299-d4ad-460e-8ab3-ea9fbc012086",
   "metadata": {},
   "source": [
    "## Load env config\n",
    "\n",
    "* use the prefix from `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1d2542f-d87b-436d-b4bb-08edcbb532ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = 'mabv1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35449112-3c26-4ea9-8c3a-21c283951350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"mabv1\"\n",
      "VERSION                  = \"v1\"\n",
      "\n",
      "BUCKET_NAME              = \"mabv1-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://mabv1-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://mabv1-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_ID      = \"hybrid-vertex.movielens_dataset_mabv1\"\n",
      "BIGQUERY_TABLE_ID        = \"hybrid-vertex.movielens_dataset_mabv1.training_dataset\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-mabv1\"\n",
      "IMAGE_NAME               = \"train-perarm-feats-v1\"\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-mabv1/train-perarm-feats-v1\"\n",
      "DOCKERNAME               = \"Dockerfile_perarm_feats\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b16af06-e188-4f4e-a04b-4e0eb8873ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mabv1-hybrid-vertex-bucket/acc-paf-v2/\n",
      "gs://mabv1-hybrid-vertex-bucket/aiplatform-custom-training-2023-07-13-22:02:47.458/\n",
      "gs://mabv1-hybrid-vertex-bucket/aiplatform-custom-training-2023-07-14-12:09:06.643/\n",
      "gs://mabv1-hybrid-vertex-bucket/aiplatform-custom-training-2023-07-14-12:46:07.509/\n",
      "gs://mabv1-hybrid-vertex-bucket/aiplatform-custom-training-2023-07-14-13:48:08.938/\n",
      "gs://mabv1-hybrid-vertex-bucket/aiplatform-custom-training-2023-07-17-18:35:00.675/\n",
      "gs://mabv1-hybrid-vertex-bucket/aiplatform-custom-training-2023-07-17-18:50:42.146/\n",
      "gs://mabv1-hybrid-vertex-bucket/archived/\n",
      "gs://mabv1-hybrid-vertex-bucket/banditos-2/\n",
      "gs://mabv1-hybrid-vertex-bucket/baseline-bandit-v1/\n",
      "gs://mabv1-hybrid-vertex-bucket/config/\n",
      "gs://mabv1-hybrid-vertex-bucket/custom-neural-bandits-a100/\n",
      "gs://mabv1-hybrid-vertex-bucket/custom-neural-bandits-v1/\n",
      "gs://mabv1-hybrid-vertex-bucket/data/\n",
      "gs://mabv1-hybrid-vertex-bucket/linear-bandit-v1/\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-v4/\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-v5/\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-v6/\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-v1/\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-v2/\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-v3/\n",
      "gs://mabv1-hybrid-vertex-bucket/neural-bandit-v2/\n",
      "gs://mabv1-hybrid-vertex-bucket/neural-linear-bandits-v1/\n",
      "gs://mabv1-hybrid-vertex-bucket/perarm-local-test/\n",
      "gs://mabv1-hybrid-vertex-bucket/scale-paf-bandits-v1/\n",
      "gs://mabv1-hybrid-vertex-bucket/scale-paf-bandits-v2/\n",
      "gs://mabv1-hybrid-vertex-bucket/scale-paf-v1/\n",
      "gs://mabv1-hybrid-vertex-bucket/scale-paf-v2/\n",
      "gs://mabv1-hybrid-vertex-bucket/scale-perarm-hpt-v2/\n",
      "gs://mabv1-hybrid-vertex-bucket/scale-perarm-hpt-v3/\n",
      "gs://mabv1-hybrid-vertex-bucket/scale-perarm-hpt/\n",
      "gs://mabv1-hybrid-vertex-bucket/vocabs/\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be79c652-45c8-4b5f-b410-4908829375a3",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92272ed8-bfb5-4b40-b7f4-cdbe029f3bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261a452d-8ce7-427b-8091-d7d41c57e556",
   "metadata": {},
   "source": [
    "# Build Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9bdef1-ac23-49be-96fd-25795f483643",
   "metadata": {},
   "source": [
    "## Container Image Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eedbe408-e2fe-4944-912f-f2b1f6587440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOCKERNAME        = Dockerfile_perarm_feats\n",
      "REPOSITORY        = rl-movielens-mabv1\n",
      "IMAGE_NAME        = train-perarm-feats-v1\n",
      "REMOTE_IMAGE_NAME = us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-mabv1/train-perarm-feats-v1\n"
     ]
    }
   ],
   "source": [
    "print(f\"DOCKERNAME        = {DOCKERNAME}\")\n",
    "print(f\"REPOSITORY        = {REPOSITORY}\")\n",
    "print(f\"IMAGE_NAME        = {IMAGE_NAME}\")\n",
    "print(f\"REMOTE_IMAGE_NAME = {REMOTE_IMAGE_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf953a8e-d282-4d7b-9a7d-fd0bee28c70a",
   "metadata": {},
   "source": [
    "## Create Artifact Repository\n",
    "\n",
    "If you don't have an existing artifact repository, create one using the gcloud command below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8288932-054a-46e6-90e8-326e015f2115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gcloud artifacts repositories create $REPOSITORY --repository-format=docker --location=$LOCATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8411ff1c-cbf7-437c-ba54-b223ad3693c6",
   "metadata": {},
   "source": [
    "## Local Docker build\n",
    "\n",
    "Provide a name for your dockerfile and make sure you are authenticated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2ddd661-18a9-4ed9-85d0-716b0c094026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m Your config file at [/home/jupyter/.docker/config.json] contains these credential helper entries:\n",
      "\n",
      "{\n",
      "  \"credHelpers\": {\n",
      "    \"gcr.io\": \"gcloud\",\n",
      "    \"us.gcr.io\": \"gcloud\",\n",
      "    \"eu.gcr.io\": \"gcloud\",\n",
      "    \"asia.gcr.io\": \"gcloud\",\n",
      "    \"staging-k8s.gcr.io\": \"gcloud\",\n",
      "    \"marketplace.gcr.io\": \"gcloud\",\n",
      "    \"us-central1-docker.pkg.dev\": \"gcloud\"\n",
      "  }\n",
      "}\n",
      "Adding credentials for: us-central1-docker.pkg.dev\n",
      "gcloud credential helpers already registered correctly.\n"
     ]
    }
   ],
   "source": [
    "! gcloud auth configure-docker $REGION-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1374bc-7b85-4e65-86ab-2721ce4908b3",
   "metadata": {},
   "source": [
    "### Create Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88a8b25d-e55c-4a00-ab0e-1151eae8eaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/tf_vertex_agents'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root_path = '..'\n",
    "os.chdir(root_path)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bffd9bb-6d22-4d4e-9eb8-893472702837",
   "metadata": {},
   "source": [
    "### Create train image\n",
    "\n",
    "see [example Dockerfile for GPU](https://github.com/GoogleCloudPlatform/cloudml-samples/blob/main/pytorch/containers/quickstart/mnist/Dockerfile-gpu) jobs in Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7022f8d1-43d0-4291-91b8-4cb27491c2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_profiling : True\n"
     ]
    }
   ],
   "source": [
    "gpu_profiling = True # True | False\n",
    "\n",
    "print(f\"gpu_profiling : {gpu_profiling}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4596864b-f059-438d-a04f-7416c436b644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_BASE_IMAGE : tensorflow/tensorflow:2.13.0-gpu\n",
      "NVTOP_RUN        : RUN apt update && apt -y install nvtop\n",
      "RUN_EXPORT       : RUN export PYTHONPATH=${PYTHONPATH}:${APP_HOME}/\n"
     ]
    }
   ],
   "source": [
    "# TRAIN_BASE_IMAGE = 'us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-11:latest'\n",
    "# docker pull tensorflow/tensorflow:2.13.0-gpu\n",
    "\n",
    "if gpu_profiling:\n",
    "    TRAIN_BASE_IMAGE = 'tensorflow/tensorflow:2.13.0-gpu'\n",
    "    NVTOP_RUN = 'RUN apt update && apt -y install nvtop'\n",
    "    # NVTOP_RUN = 'RUN apt-get update && apt-get -y install nvtop'\n",
    "else:\n",
    "    TRAIN_BASE_IMAGE = 'python:3.10'\n",
    "    NVTOP_RUN = None\n",
    "    \n",
    "RUN_EXPORT = \"RUN export PYTHONPATH=${PYTHONPATH}:${APP_HOME}/\"\n",
    "    \n",
    "print(f\"TRAIN_BASE_IMAGE : {TRAIN_BASE_IMAGE}\")\n",
    "print(f\"NVTOP_RUN        : {NVTOP_RUN}\")\n",
    "print(f\"RUN_EXPORT       : {RUN_EXPORT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b1b1fc6-022b-4e56-b62f-673179bab7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FROM tensorflow/tensorflow:2.13.0-gpu\n",
      "\n",
      "ENV PYTHONUNBUFFERED True\n",
      "\n",
      "ENV APP_HOME /workspace\n",
      "\n",
      "WORKDIR $APP_HOME\n",
      "\n",
      "COPY /requirements.txt $APP_HOME/requirements.txt\n",
      "\n",
      "RUN pip install --upgrade pip\n",
      "RUN pip install --no-cache-dir -r $APP_HOME/requirements.txt\n",
      "\n",
      "RUN ls $APP_HOME\n",
      "\n",
      "COPY src/perarm_features $APP_HOME/src/perarm_features\n",
      "COPY src/per_arm_rl $APP_HOME/src/per_arm_rl\n",
      "\n",
      "RUN apt update && apt -y install nvtop\n",
      "\n",
      "RUN ls $APP_HOME\n",
      "\n",
      "RUN export PYTHONPATH=${PYTHONPATH}:${APP_HOME}/\n",
      "\n",
      "# Sets up the entry point to invoke the task.\n",
      "ENTRYPOINT [\"python3\", \"-m\", \"src.perarm_features.task\"]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dockerfile = f'''\n",
    "FROM {TRAIN_BASE_IMAGE}\n",
    "\n",
    "ENV PYTHONUNBUFFERED True\n",
    "\n",
    "ENV APP_HOME /workspace\n",
    "\n",
    "WORKDIR $APP_HOME\n",
    "\n",
    "COPY /requirements.txt $APP_HOME/requirements.txt\n",
    "\n",
    "RUN pip install --upgrade pip\n",
    "RUN pip install --no-cache-dir -r $APP_HOME/requirements.txt\n",
    "\n",
    "RUN ls $APP_HOME\n",
    "\n",
    "COPY src/perarm_features $APP_HOME/src/perarm_features\n",
    "COPY src/per_arm_rl $APP_HOME/src/per_arm_rl\n",
    "\n",
    "{NVTOP_RUN}\n",
    "\n",
    "RUN ls $APP_HOME\n",
    "\n",
    "{RUN_EXPORT}\n",
    "\n",
    "# Sets up the entry point to invoke the task.\n",
    "ENTRYPOINT [\"python3\", \"-m\", \"src.perarm_features.task\"]\n",
    "'''\n",
    "print(dockerfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cc6cb35-fcb6-4b4d-a665-b6c038ca6f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DOCKERNAME}', 'w') as f:\n",
    "    f.write(dockerfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79387322-1f77-4cd2-b0cc-6c5cd6dc268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile {DOCKERNAME}\n",
    "\n",
    "# FROM python:3.10\n",
    "# ENV PYTHONUNBUFFERED True\n",
    "\n",
    "# ENV APP_HOME /workspace\n",
    "# WORKDIR $APP_HOME\n",
    "\n",
    "# COPY /requirements.txt $APP_HOME/requirements.txt\n",
    "\n",
    "# RUN pip install --upgrade pip\n",
    "# RUN pip install --no-cache-dir -r $APP_HOME/requirements.txt\n",
    "\n",
    "# RUN ls $APP_HOME\n",
    "\n",
    "# COPY src/perarm_features $APP_HOME/src/perarm_features\n",
    "# COPY src/per_arm_rl $APP_HOME/src/per_arm_rl\n",
    "\n",
    "# RUN ls $APP_HOME\n",
    "\n",
    "# RUN export PYTHONPATH=${PYTHONPATH}:${APP_HOME}/\n",
    "\n",
    "# # Sets up the entry point to invoke the task.\n",
    "# ENTRYPOINT [\"python3\", \"-m\", \"src.perarm_features.task\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629eb246-f2fc-48a0-8478-4f9c99dddd0b",
   "metadata": {},
   "source": [
    "### Build Image Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a82cbe6-0ed5-478f-a38f-e6dedc114e2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  13.29MB\n",
      "Step 1/14 : FROM tensorflow/tensorflow:2.13.0-gpu\n",
      " ---> 6bdca089cc38\n",
      "Step 2/14 : ENV PYTHONUNBUFFERED True\n",
      " ---> Using cache\n",
      " ---> d3da8d2bd662\n",
      "Step 3/14 : ENV APP_HOME /workspace\n",
      " ---> Using cache\n",
      " ---> 077e5e85305c\n",
      "Step 4/14 : WORKDIR $APP_HOME\n",
      " ---> Using cache\n",
      " ---> b597986a6c66\n",
      "Step 5/14 : COPY /requirements.txt $APP_HOME/requirements.txt\n",
      " ---> Using cache\n",
      " ---> 7e1d8aeab948\n",
      "Step 6/14 : RUN pip install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> 5b9233eb7d24\n",
      "Step 7/14 : RUN pip install --no-cache-dir -r $APP_HOME/requirements.txt\n",
      " ---> Using cache\n",
      " ---> d1d12f5180ae\n",
      "Step 8/14 : RUN ls $APP_HOME\n",
      " ---> Using cache\n",
      " ---> 759471a524ec\n",
      "Step 9/14 : COPY src/perarm_features $APP_HOME/src/perarm_features\n",
      " ---> 3975a9ecd356\n",
      "Step 10/14 : COPY src/per_arm_rl $APP_HOME/src/per_arm_rl\n",
      " ---> 94ccca194af2\n",
      "Step 11/14 : RUN apt update && apt -y install nvtop\n",
      " ---> Running in 08c0e7332d29\n",
      "\u001b[91m\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
      "\n",
      "\u001b[0mGet:1 http://archive.ubuntu.com/ubuntu focal InRelease [265 kB]\n",
      "Get:2 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
      "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease [1581 B]\n",
      "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  Packages [1127 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
      "Get:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release [564 B]\n",
      "Get:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release.gpg [833 B]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
      "Get:10 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2942 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 Packages [177 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu focal/universe amd64 Packages [11.3 MB]\n",
      "Get:13 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [2648 kB]\n",
      "Get:14 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [29.3 kB]\n",
      "Get:15 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1089 kB]\n",
      "Get:16 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages [73.8 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu focal/main amd64 Packages [1275 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu focal/restricted amd64 Packages [33.4 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1393 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [32.0 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2795 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3430 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu focal-backports/main amd64 Packages [55.2 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [28.6 kB]\n",
      "Fetched 29.1 MB in 2s (13.1 MB/s)\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "30 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "\u001b[91m\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
      "\n",
      "\u001b[0mReading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following additional packages will be installed:\n",
      "  libnvidia-compute-418 libnvidia-compute-430 libnvidia-compute-535\n",
      "The following NEW packages will be installed:\n",
      "  libnvidia-compute-418 libnvidia-compute-430 libnvidia-compute-535 nvtop\n",
      "0 upgraded, 4 newly installed, 0 to remove and 30 not upgraded.\n",
      "Need to get 36.8 MB of archives.\n",
      "After this operation, 175 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal/restricted amd64 libnvidia-compute-418 amd64 430.50-0ubuntu3 [6936 B]\n",
      "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  libnvidia-compute-535 535.86.10-0ubuntu1 [36.8 MB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 nvtop amd64 1.0.0-1ubuntu2 [26.8 kB]\n",
      "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  libnvidia-compute-430 535.86.10-0ubuntu1 [10.9 kB]\n",
      "\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
      "\u001b[0mFetched 36.8 MB in 1s (53.9 MB/s)\n",
      "Selecting previously unselected package libnvidia-compute-535:amd64.\n",
      "(Reading database ... 18823 files and directories currently installed.)\n",
      "Preparing to unpack .../libnvidia-compute-535_535.86.10-0ubuntu1_amd64.deb ...\n",
      "Unpacking libnvidia-compute-535:amd64 (535.86.10-0ubuntu1) ...\n",
      "Selecting previously unselected package libnvidia-compute-430:amd64.\n",
      "Preparing to unpack .../libnvidia-compute-430_535.86.10-0ubuntu1_amd64.deb ...\n",
      "Unpacking libnvidia-compute-430:amd64 (535.86.10-0ubuntu1) ...\n",
      "Selecting previously unselected package libnvidia-compute-418:amd64.\n",
      "Preparing to unpack .../libnvidia-compute-418_430.50-0ubuntu3_amd64.deb ...\n",
      "Unpacking libnvidia-compute-418:amd64 (430.50-0ubuntu3) ...\n",
      "Selecting previously unselected package nvtop.\n",
      "Preparing to unpack .../nvtop_1.0.0-1ubuntu2_amd64.deb ...\n",
      "Unpacking nvtop (1.0.0-1ubuntu2) ...\n",
      "Setting up libnvidia-compute-535:amd64 (535.86.10-0ubuntu1) ...\n",
      "Setting up libnvidia-compute-430:amd64 (535.86.10-0ubuntu1) ...\n",
      "Setting up libnvidia-compute-418:amd64 (430.50-0ubuntu3) ...\n",
      "Setting up nvtop (1.0.0-1ubuntu2) ...\n",
      "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
      "Removing intermediate container 08c0e7332d29\n",
      " ---> b15dd6abd9cd\n",
      "Step 12/14 : RUN ls $APP_HOME\n",
      " ---> Running in c7bf7cfecc7b\n",
      "requirements.txt\n",
      "src\n",
      "Removing intermediate container c7bf7cfecc7b\n",
      " ---> c1824a84fdd1\n",
      "Step 13/14 : RUN export PYTHONPATH=${PYTHONPATH}:${APP_HOME}/\n",
      " ---> Running in c044e4005cd0\n",
      "Removing intermediate container c044e4005cd0\n",
      " ---> 32db137bafda\n",
      "Step 14/14 : ENTRYPOINT [\"python3\", \"-m\", \"src.perarm_features.task\"]\n",
      " ---> Running in b9fe22a9c922\n",
      "Removing intermediate container b9fe22a9c922\n",
      " ---> 515265bafca5\n",
      "Successfully built 515265bafca5\n",
      "Successfully tagged us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-mabv1/train-perarm-feats-v1:latest\n"
     ]
    }
   ],
   "source": [
    "!docker build -t $REMOTE_IMAGE_NAME -f $DOCKERNAME ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6110439-f66a-4d6b-8105-17a08ce9b8da",
   "metadata": {},
   "source": [
    "### Push container to Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54a714cf-053c-4f14-b375-2a42ae2092f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "The push refers to repository [us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-mabv1/train-perarm-feats-v1]\n",
      "\n",
      "\u001b[1Bc3c98e11: Preparing \n",
      "\u001b[1Bf86ff904: Preparing \n",
      "\u001b[1B81339efa: Preparing \n",
      "\u001b[1B30ff1fbf: Preparing \n",
      "\u001b[1Bdd35e987: Preparing \n",
      "\u001b[1B8e604636: Preparing \n",
      "\u001b[1B14dc7caa: Preparing \n",
      "\u001b[1Ba40e4dcd: Preparing \n",
      "\u001b[1Bb5695a98: Preparing \n",
      "\u001b[1Bf0d116f4: Preparing \n",
      "\u001b[1B2813a979: Preparing \n",
      "\u001b[1B6e868aa5: Preparing \n",
      "\u001b[1B136c7d36: Preparing \n",
      "\u001b[1B891e0e76: Preparing \n",
      "\u001b[1Bed848ac5: Preparing \n",
      "\u001b[1B18b47754: Preparing \n",
      "\u001b[1B91e05b94: Preparing \n",
      "\u001b[1Be103257c: Preparing \n",
      "\u001b[1Bb25399cb: Preparing \n",
      "\u001b[1Bb667a965: Preparing \n",
      "\u001b[1B6ad9c95e: Preparing \n",
      "\u001b[1Bb4e1ecd1: Preparing \n",
      "\u001b[1B5c845fcf: Preparing \n",
      "\u001b[1Ba7216f78: Preparing \n",
      "\u001b[25B3c98e11: Pushed   223.9MB/223.8MB\u001b[23A\u001b[2K\u001b[19A\u001b[2K\u001b[25A\u001b[2K\u001b[16A\u001b[2K\u001b[23A\u001b[2K\u001b[10A\u001b[2K\u001b[4A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2K\u001b[25A\u001b[2Klatest: digest: sha256:af42bea6c890a15e18096706e37735534e4663ca6aa1bd28e3042378cac33e55 size: 5553\n"
     ]
    }
   ],
   "source": [
    "# ### push the container to registry\n",
    "!docker push $REMOTE_IMAGE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bc85f6-a86e-48f2-a040-89f35376d57c",
   "metadata": {},
   "source": [
    "### GPU profiling\n",
    "\n",
    "> enter these commands in the Vertex interactive terminal:\n",
    "\n",
    "```bash\n",
    "sudo apt update\n",
    "sudo apt -y install nvtop\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3441c71c-c51e-4153-961e-08f253534996",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
