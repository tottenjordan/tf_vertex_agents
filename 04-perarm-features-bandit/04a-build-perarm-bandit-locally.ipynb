{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385307d6-2058-47ec-8da0-57f7ef5c43d6",
   "metadata": {},
   "source": [
    "# Train Bandits with per-arm features\n",
    "\n",
    "**Exploring linear and nonlinear** (e.g., those with neural network-based value functions) bandit methods for recommendations using TF-Agents\n",
    "\n",
    "> Neural linear bandits provide a nice way to leverage the representation power of deep learning and the bandit approach for uncertainty measure and efficient exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fd257-b98b-426a-a2cd-024429b014f1",
   "metadata": {},
   "source": [
    "## Load notebook config\n",
    "\n",
    "* use the prefix defined in `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f39c9d08-d118-4013-a47f-88450f49f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = 'mabv1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908f6b95-b539-4a9f-a836-840d26ea3b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"mabv1\"\n",
      "VERSION                  = \"v1\"\n",
      "\n",
      "BUCKET_NAME              = \"mabv1-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://mabv1-hybrid-vertex-bucket/data\"\n",
      "BUCKET_URI               = \"gs://mabv1-hybrid-vertex-bucket\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_ID      = \"hybrid-vertex.movielens_dataset_mabv1\"\n",
      "BIGQUERY_TABLE_ID        = \"hybrid-vertex.movielens_dataset_mabv1.training_dataset\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c690a9-e2bd-4759-ba41-4e2469098aee",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d0dfe4-695c-4dd4-9f24-67f7488ce1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c669f1a1-1af7-4efb-ab2d-6bf3b3847991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from collections import defaultdict\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pickle as pkl\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "# from tf_agents.agents import TFAgent\n",
    "\n",
    "# from tf_agents.bandits.environments import stationary_stochastic_per_arm_py_environment as p_a_env\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "# from tf_agents.drivers import dynamic_step_driver\n",
    "# from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "# from tf_agents.bandits.agents import lin_ucb_agent\n",
    "# from tf_agents.bandits.agents import linear_thompson_sampling_agent as lin_ts_agent\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent\n",
    "from tf_agents.bandits.agents import neural_linucb_agent\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "from tf_agents.bandits.policies import policy_utilities\n",
    "\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# this repo\n",
    "from src.per_arm_rl import data_utils\n",
    "from src.per_arm_rl import data_config\n",
    "from src.per_arm_rl import train_utils as train_utils\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29e58dd7-ab2b-419f-9771-bf1e98db758b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for gpu in gpus:\n",
    "#     tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \n",
    "# gpus\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4969d3e-1fc0-45db-8a69-aa6b342019de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "274e7f4a-1802-4946-888e-876638f5c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a866b1-85b9-43e6-9546-edfbbf886bce",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd5b953-14c0-42ed-a511-77147a1bc0ac",
   "metadata": {},
   "source": [
    "### Read TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d0157c8-a04c-4dbd-b6d9-a1ede97687a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c934c06-bf08-4c7f-b0cc-0de04ef3515c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://mabv1-hybrid-vertex-bucket/data/train/ml-ratings-100k-train.tfrecord']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPLIT = \"train\" # \"train\" | \"val\"\n",
    "\n",
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7511e4d-bf81-4800-bde7-8b16dec9aeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([35.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'898'], dtype=object)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([885409515])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'681'], dtype=object)>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'marketing'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "train_dataset = train_dataset.map(data_utils.parse_tfrecord)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8959967-522e-41c8-9a1b-050ca8bc191f",
   "metadata": {},
   "source": [
    "### get vocab\n",
    "\n",
    "**TODO:** \n",
    "* streamline vocab calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b9169bc-d6dc-497e-9dff-6ebb175282ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE_VOCABS: False\n"
     ]
    }
   ],
   "source": [
    "GENERATE_VOCABS = False\n",
    "print(f\"GENERATE_VOCABS: {GENERATE_VOCABS}\")\n",
    "\n",
    "VOCAB_SUBDIR   = \"vocabs\"\n",
    "VOCAB_FILENAME = \"vocab_dict.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3ccf137-7a72-42e7-aa89-3c81a99cf40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab...\n",
      "Downloaded vocab from: gs://mabv1-hybrid-vertex-bucket/vocabs/vocab_dict.pkl\n",
      "\n",
      "'movie_id'\n",
      "'user_id'\n",
      "'user_occupation_text'\n",
      "'movie_genres'\n",
      "'bucketized_user_age'\n",
      "'max_timestamp'\n",
      "'min_timestamp'\n",
      "'timestamp_buckets'\n"
     ]
    }
   ],
   "source": [
    "if not GENERATE_VOCABS:\n",
    "\n",
    "    EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{VOCAB_SUBDIR}/{VOCAB_FILENAME}'\n",
    "    print(f\"Downloading vocab...\")\n",
    "    \n",
    "    os.system(f'gsutil -q cp {EXISTING_VOCAB_FILE} .')\n",
    "    print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "    filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "    vocab_dict = pkl.load(filehandler)\n",
    "    filehandler.close()\n",
    "    \n",
    "    for key in vocab_dict.keys():\n",
    "        pprint(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccaef62-882a-46ff-a1b1-3837e69fdf74",
   "metadata": {},
   "source": [
    "## helper functions\n",
    "\n",
    "**TODO:**\n",
    "* modularize in a train_utils or similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b941063b-ad48-4817-aef0-9afa8a444632",
   "metadata": {},
   "source": [
    "# Multi-Armed Bandits (MAB) with Per-Arm Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28770b8d-836b-448d-8dd1-203d76fc6d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "\n",
    "nest = tf.nest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138a295-2b0d-4359-8496-af8552ec8cff",
   "metadata": {},
   "source": [
    "# [1] Preprocessing layers for global and arm features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e28c002-8d3a-4cf4-b69b-de56a6abab90",
   "metadata": {},
   "source": [
    "The preproccesing layers will ultimately feed the two sampling functions described below. These sampling functions will be used to create [trajectories](https://github.com/tensorflow/agents/blob/master/tf_agents/trajectories/trajectory.py#L36) (i.e., the training examples for our model)\n",
    "\n",
    "`global_context_sampling_fn`: \n",
    "* A function that outputs a random 1d array or list of ints or floats\n",
    "* This output is the global context. Its shape and type must be consistent across calls.\n",
    "\n",
    "`arm_context_sampling_fn`: \n",
    "* A function that outputs a random 1 array or list of ints or floats (same type as the output of `global_context_sampling_fn`). * This output is the per-arm context. Its shape must be consistent across calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8d77956-635c-438a-916a-185eec52f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OOV_BUCKETS        = 1\n",
    "GLOBAL_EMBEDDING_SIZE  = 16\n",
    "MV_EMBEDDING_SIZE      = 32 #32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6142e63e-0a20-4d51-997c-7a4733517f7e",
   "metadata": {},
   "source": [
    "## global context (user) features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195acd92-06b6-42e4-bef7-798fd09da856",
   "metadata": {},
   "source": [
    "#### user ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c28e887b-421a-4603-8899-87071056783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_input_layer = tf.keras.Input(\n",
    "    name=\"user_id\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.string\n",
    ")\n",
    "\n",
    "user_id_lookup = tf.keras.layers.StringLookup(\n",
    "    max_tokens=len(vocab_dict['user_id']) + NUM_OOV_BUCKETS,\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    mask_token=None,\n",
    "    vocabulary=vocab_dict['user_id'],\n",
    ")(user_id_input_layer)\n",
    "\n",
    "user_id_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['user_id']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=GLOBAL_EMBEDDING_SIZE\n",
    ")(user_id_lookup)\n",
    "\n",
    "user_id_embedding = tf.reduce_sum(user_id_embedding, axis=-2)\n",
    "\n",
    "# global_inputs.append(user_id_input_layer)\n",
    "# global_features.append(user_id_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d6a0fe7-26cb-4c62-a3ef-17f98e6ccddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_id_model = tf.keras.Model(inputs=user_id_input_layer, outputs=user_id_embedding)\n",
    "\n",
    "# for x in train_dataset.batch(1).take(1):\n",
    "#     print(x[\"user_id\"])\n",
    "#     print(test_user_id_model(x[\"user_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352d2227-92ec-4386-926f-df2fdb9434ec",
   "metadata": {},
   "source": [
    "#### user AGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70785bf0-5ece-4875-ab72-06d9c45ea9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_age_input_layer = tf.keras.Input(\n",
    "    name=\"bucketized_user_age\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "user_age_lookup = tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=vocab_dict['bucketized_user_age'],\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    oov_value=0,\n",
    ")(user_age_input_layer)\n",
    "\n",
    "user_age_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['bucketized_user_age']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=GLOBAL_EMBEDDING_SIZE\n",
    ")(user_age_lookup)\n",
    "\n",
    "user_age_embedding = tf.reduce_sum(user_age_embedding, axis=-2)\n",
    "\n",
    "# global_inputs.append(user_age_input_layer)\n",
    "# global_features.append(user_age_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e01622a-9418-4ca7-8925-9b0ebef8940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_age_model = tf.keras.Model(inputs=user_age_input_layer, outputs=user_age_embedding)\n",
    "\n",
    "# for x in train_dataset.batch(1).take(1):\n",
    "#     print(x[\"bucketized_user_age\"])\n",
    "#     print(test_user_age_model(x[\"bucketized_user_age\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997ffaa8-ca92-4851-b7e3-bb06fba8958b",
   "metadata": {},
   "source": [
    "#### user OCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03e7344d-71fb-423a-89dd-f1abeb270e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_occ_input_layer = tf.keras.Input(\n",
    "    name=\"user_occupation_text\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.string\n",
    ")\n",
    "\n",
    "user_occ_lookup = tf.keras.layers.StringLookup(\n",
    "    max_tokens=len(vocab_dict['user_occupation_text']) + NUM_OOV_BUCKETS,\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    mask_token=None,\n",
    "    vocabulary=vocab_dict['user_occupation_text'],\n",
    ")(user_occ_input_layer)\n",
    "\n",
    "user_occ_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['user_occupation_text']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=GLOBAL_EMBEDDING_SIZE\n",
    ")(user_occ_lookup)\n",
    "\n",
    "user_occ_embedding = tf.reduce_sum(user_occ_embedding, axis=-2)\n",
    "\n",
    "# global_inputs.append(user_occ_input_layer)\n",
    "# global_features.append(user_occ_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39cbbc31-ca43-4f8f-a804-a4b830e99d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_occ_model = tf.keras.Model(inputs=user_occ_input_layer, outputs=user_occ_embedding)\n",
    "\n",
    "# for x in train_dataset.batch(1).take(1):\n",
    "#     print(x[\"user_occupation_text\"])\n",
    "#     print(test_user_occ_model(x[\"user_occupation_text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee0098-a48a-4de6-88bf-6219ce8c0533",
   "metadata": {},
   "source": [
    "#### user Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61a4e01a-e742-4c68-93a9-aa66eb9a5e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ts_input_layer = tf.keras.Input(\n",
    "    name=\"timestamp\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.int64\n",
    ")\n",
    "\n",
    "user_ts_lookup = tf.keras.layers.Discretization(\n",
    "    vocab_dict['timestamp_buckets'].tolist()\n",
    ")(user_ts_input_layer)\n",
    "\n",
    "user_ts_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['timestamp_buckets'].tolist()) + NUM_OOV_BUCKETS,\n",
    "    output_dim=GLOBAL_EMBEDDING_SIZE\n",
    ")(user_ts_lookup)\n",
    "\n",
    "user_ts_embedding = tf.reduce_sum(user_ts_embedding, axis=-2)\n",
    "\n",
    "# global_inputs.append(user_ts_input_layer)\n",
    "# global_features.append(user_ts_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db99f90b-57f8-45e6-9f28-871658e17358",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_ts_model = tf.keras.Model(inputs=user_ts_input_layer, outputs=user_ts_embedding)\n",
    "\n",
    "# for x in train_dataset.batch(1).take(1):\n",
    "#     print(x[\"timestamp\"])\n",
    "#     print(test_user_ts_model(x[\"timestamp\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc734ea-cb5e-4c6b-8b94-2a8853220178",
   "metadata": {},
   "source": [
    "### define global sampling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff58c380-8b53-4dfa-b5b4-d36853638ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_global_context_features(x):\n",
    "    \"\"\"\n",
    "    This function generates a single global observation vector.\n",
    "    \"\"\"\n",
    "    user_id_value = x['user_id']\n",
    "    user_age_value = x['bucketized_user_age']\n",
    "    user_occ_value = x['user_occupation_text']\n",
    "    user_ts_value = x['timestamp']\n",
    "\n",
    "    _id = test_user_id_model(user_id_value) # input_tensor=tf.Tensor(shape=(4,), dtype=float32)\n",
    "    _age = test_user_age_model(user_age_value)\n",
    "    _occ = test_user_occ_model(user_occ_value)\n",
    "    _ts = test_user_ts_model(user_ts_value)\n",
    "\n",
    "    # # tmp - insepct numpy() values\n",
    "    # print(_id.numpy()) #[0])\n",
    "    # print(_age.numpy()) #[0])\n",
    "    # print(_occ.numpy()) #[0])\n",
    "    # print(_ts.numpy()) #[0])\n",
    "\n",
    "    # to numpy array\n",
    "    _id = np.array(_id.numpy())\n",
    "    _age = np.array(_age.numpy())\n",
    "    _occ = np.array(_occ.numpy())\n",
    "    _ts = np.array(_ts.numpy())\n",
    "\n",
    "    concat = np.concatenate(\n",
    "        [_id, _age, _occ, _ts], axis=-1 # -1\n",
    "    ).astype(np.float32)\n",
    "\n",
    "    return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "bba133ab-bf12-4b3b-926d-6d1dba940837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([35.], dtype=float32)>,\n",
       " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
       " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'898'], dtype=object)>,\n",
       " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([885409515])>,\n",
       " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'681'], dtype=object)>,\n",
       " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'marketing'], dtype=object)>,\n",
       " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    \n",
    "    iterator = iter(train_dataset.batch(1))\n",
    "    data = next(iterator)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7cadad0-b5ac-461b-9efb-4867b52a8736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL_DIM: 64\n"
     ]
    }
   ],
   "source": [
    "GLOBAL_DIM = _get_global_context_features(data).shape[1]\n",
    "print(f\"GLOBAL_DIM: {GLOBAL_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249fa771-35d7-4d04-ab68-2b70911bac17",
   "metadata": {},
   "source": [
    "## arm preprocessing layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534b3bf1-a2ea-4bfb-8c77-efa057f4e391",
   "metadata": {},
   "source": [
    "#### movie ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa53cbe9-2616-4da4-90dc-dc5616258af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_id_input_layer = tf.keras.Input(\n",
    "    name=\"movie_id\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.string\n",
    ")\n",
    "\n",
    "mv_id_lookup = tf.keras.layers.StringLookup(\n",
    "    max_tokens=len(vocab_dict['movie_id']) + NUM_OOV_BUCKETS,\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    mask_token=None,\n",
    "    vocabulary=vocab_dict['movie_id'],\n",
    ")(mv_id_input_layer)\n",
    "\n",
    "mv_id_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['movie_id']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=MV_EMBEDDING_SIZE\n",
    ")(mv_id_lookup)\n",
    "\n",
    "mv_id_embedding = tf.reduce_sum(mv_id_embedding, axis=-2)\n",
    "\n",
    "# arm_inputs.append(mv_id_input_layer)\n",
    "# arm_features.append(mv_id_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bd19f09-a12e-4a21-a1a1-5ec5bc116559",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mv_id_model = tf.keras.Model(inputs=mv_id_input_layer, outputs=mv_id_embedding)\n",
    "\n",
    "# for x in train_dataset.batch(1).take(1):\n",
    "#     print(x[\"movie_id\"])\n",
    "#     print(test_mv_id_model(x[\"movie_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4a0e97-c477-4042-b9c0-fcb0f428de0d",
   "metadata": {},
   "source": [
    "#### movie genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f04a0091-d7b0-4f90-ba7c-3eb41dd0b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_genre_input_layer = tf.keras.Input(\n",
    "    name=\"movie_genres\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "mv_genre_lookup = tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=vocab_dict['movie_genres'],\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    oov_value=0,\n",
    ")(mv_genre_input_layer)\n",
    "\n",
    "mv_genre_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['movie_genres']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=MV_EMBEDDING_SIZE\n",
    ")(mv_genre_lookup)\n",
    "\n",
    "mv_genre_embedding = tf.reduce_sum(mv_genre_embedding, axis=-2)\n",
    "\n",
    "# arm_inputs.append(mv_genre_input_layer)\n",
    "# arm_features.append(mv_genre_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51701f0a-9b3e-461c-a9d9-a0c146e310ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mv_gen_model = tf.keras.Model(inputs=mv_genre_input_layer, outputs=mv_genre_embedding)\n",
    "\n",
    "# for x in train_dataset.batch(1).take(1):\n",
    "#     print(x[\"movie_genres\"])\n",
    "#     print(test_mv_gen_model(x[\"movie_genres\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b41cc9-63f5-4559-a943-1288be9c0892",
   "metadata": {},
   "source": [
    "### define sampling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8727904e-e9b6-4005-8cf3-9da461ca88b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_per_arm_features(x):\n",
    "    \"\"\"\n",
    "    This function generates a single per-arm observation vector\n",
    "    \"\"\"\n",
    "    mv_id_value = x['movie_id']\n",
    "    mv_gen_value = x['movie_genres']\n",
    "\n",
    "    _mid = test_mv_id_model(mv_id_value)\n",
    "    _mgen = test_mv_gen_model(mv_gen_value)\n",
    "\n",
    "    # to numpy array\n",
    "    _mid = np.array(_mid.numpy())\n",
    "    _mgen = np.array(_mgen.numpy())\n",
    "\n",
    "    # print(_mid)\n",
    "    # print(_mgen)\n",
    "\n",
    "    concat = np.concatenate(\n",
    "        [_mid, _mgen], axis=-1 # -1\n",
    "    ).astype(np.float32)\n",
    "    # concat = tf.concat([_mid, _mgen], axis=-1).astype(np.float32)\n",
    "\n",
    "    return concat #this is special to this example - there is only one action dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2f5ba55-2e1a-4b32-b6a8-4f46ba4c2048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER_ARM_DIM: 64\n"
     ]
    }
   ],
   "source": [
    "PER_ARM_DIM = _get_per_arm_features(data).shape[1] #shape checks out at batchdim, nactions, arm feats\n",
    "print(f\"PER_ARM_DIM: {PER_ARM_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac6836c-67b7-4fd4-917a-24ddad708edd",
   "metadata": {},
   "source": [
    "# [2] Implementing MAB with TF-Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1877c79c-b6c8-4048-b1ce-05f011e8d69e",
   "metadata": {},
   "source": [
    "In TF-Agents, the *per-arm features* implementation differs from the *global-only* feature examples in the following aspects:\n",
    "* Reward is modeled not per-arm, but globally.\n",
    "* The arms are permutation invariant: it doesn’t matter which arm is arm 1 or arm 2, only their features.\n",
    "* One can have a different number of arms to choose from in every step (note that unspecified/dynamically changing number of arms will have a problem with XLA compatibility).\n",
    "\n",
    "When implementing per-arm features in TF-Bandits, the following details have to be discussed:\n",
    "* Observation spec and observations,\n",
    "* Action spec and actions,\n",
    "* Implementation of specific policies and agents.\n",
    "\n",
    "\n",
    "**TODO:**\n",
    "* outline the components and highlight their interactions, dependencies on eachother, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ff9baaf-987d-448d-a981-742a79b581e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE      : 128\n",
      "EVAL_BATCH_SIZE : 1\n",
      "NUM_ACTIONS     : 2\n",
      "GLOBAL_DIM      : 64\n",
      "PER_ARM_DIM     : 64\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE      = 128\n",
    "EVAL_BATCH_SIZE = 1\n",
    "\n",
    "NUM_ACTIONS     = 2 #this is kinda deceptive - \n",
    "#our approach is to learn by \"flashing\" one movie rating at a time per user context. \n",
    "#The n_actions = show/don't show the movie with one degree of freedom (n-1)\n",
    "\n",
    "\n",
    "print(f\"BATCH_SIZE      : {BATCH_SIZE}\")\n",
    "print(f\"EVAL_BATCH_SIZE : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"NUM_ACTIONS     : {NUM_ACTIONS}\")\n",
    "print(f\"GLOBAL_DIM      : {GLOBAL_DIM}\")\n",
    "print(f\"PER_ARM_DIM     : {PER_ARM_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeb4902-5bb9-4587-8d29-c01d78b006be",
   "metadata": {},
   "source": [
    "## Tensor Specs\n",
    "\n",
    "* say you have a global observation spec of `[17]`. And you have two batch dimensions `[4, 5]`. Then your observation has to have the shape `[4, 5, 17]`\n",
    "* and then if you have arm_obs_spec with shape `[9, 13]`, then the arm obs shape has to be exactly `[4, 5, 9, 13]`\n",
    "* and this has to be true for every single tensor in your tensor nest\n",
    "* the first 2 dims are the outer dims that are the same for all tensors, the rest of the dimensions have to follow the spec for each tensor\n",
    "\n",
    "**TODO:**\n",
    "* explain relationship between Tensor Specs and their Tensor counterparts\n",
    "* highlight the errors, lessons learned, and utility functions to address these"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f68ebe8-116d-43b3-a6e1-4f5a5c7f4741",
   "metadata": {},
   "source": [
    "### Observation spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9c4746-d01b-4ca4-aa53-ab68da54d37a",
   "metadata": {},
   "source": [
    "**This observation spec allows the user to have a global observation of fixed dimension**, and an unspecified number of *per-arm* features (also of fixed dimension)\n",
    "* The actions output by the policy are still integers as usual, and they indicate which row of the arm-features it has chosen \n",
    "* The action spec must be a single integer value without boundaries:\n",
    "\n",
    "```python\n",
    "global_spec = tensor_spec.TensorSpec([GLOBAL_DIM], tf.float32)\n",
    "per_arm_spec = tensor_spec.TensorSpec([None, PER_ARM_DIM], tf.float32)\n",
    "observation_spec = {'global': global_spec, 'per_arm': per_arm_spec}\n",
    "\n",
    "action_spec = tensor_spec.TensorSpec((), tf.int32)\n",
    "```\n",
    "> Here the only difference compared to the action spec with global features only is that the tensor spec is not bounded, as we don’t know how many arms there will be at any time step\n",
    "\n",
    "**XLA compatibility:**\n",
    "* Since dynamic tensor shapes are not compatible with XLA, the number of arm features (and consequently, number of arms for a step) cannot be dynamic. \n",
    "* One workaround is to fix the maximum number of arms for a problem, then pad the arm features in steps with fewer arms, and use action masking to indicate how many arms are actually active.\n",
    "\n",
    "```python\n",
    "per_arm_spec = tensor_spec.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32)\n",
    "\n",
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=(), dtype=tf.int32, minimum = 0, maximum = NUM_ACTIONS - 1\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36bd3b33-635a-4274-8b9e-7172696ebb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # TF-Agents has many helper and utility functions\n",
    "# observation_spec = bandit_spec_utils.create_per_arm_observation_spec(\n",
    "#     GLOBAL_DIM, PER_ARM_DIM, NUM_ACTIONS, \n",
    "#     add_num_actions_feature=False\n",
    "# ) # 2,3,4\n",
    "\n",
    "observation_spec = {\n",
    "    'global': tf.TensorSpec([GLOBAL_DIM], tf.float32),\n",
    "    'per_arm': tf.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32) #excluding action dim here\n",
    "}\n",
    "observation_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a2da92-7db2-4f42-94a7-b7bad1c8fc42",
   "metadata": {},
   "source": [
    "### Action spec\n",
    "\n",
    "> The time_step_spec and action_spec are specifications for the input time step and the output action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5af42c7-18d7-480f-a7f3-d7da3f4840eb",
   "metadata": {},
   "source": [
    "```python\n",
    "    if (\n",
    "        not tensor_spec.is_bounded(action_spec)\n",
    "        or not tensor_spec.is_discrete(action_spec)\n",
    "        or action_spec.shape.rank > 1\n",
    "        or action_spec.shape.num_elements() != 1\n",
    "    ):\n",
    "      raise NotImplementedError(\n",
    "          'action_spec must be a BoundedTensorSpec of type int32 and shape (). '\n",
    "          'Found {}.'.format(action_spec)\n",
    "      )\n",
    "```\n",
    "\n",
    "* [src](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_base_policy.py#L97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "549a123c-349a-4103-b39a-4502f47d1e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=[], \n",
    "    dtype=tf.int32,\n",
    "    minimum=tf.constant(0),            \n",
    "    maximum=NUM_ACTIONS-1, # n degrees of freedom and will dictate the expected mean reward spec shape\n",
    "    name=\"action_spec\"\n",
    ")\n",
    "\n",
    "action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36ee2635-d4e3-4468-886c-ae9c62e3c80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_num_actions: 2\n",
      "predicted_rewards_mean: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n"
     ]
    }
   ],
   "source": [
    "expected_num_actions = action_spec.maximum - action_spec.minimum + 1\n",
    "print(f\"expected_num_actions: {expected_num_actions}\")\n",
    "\n",
    "predicted_rewards_mean = tensor_spec.TensorSpec([expected_num_actions])\n",
    "print(f\"predicted_rewards_mean: {predicted_rewards_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a51efce-9f1b-42d1-bec4-7b788e3fd7e0",
   "metadata": {},
   "source": [
    "### TimeStep spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95f05860-0fbf-4a5a-8273-9c81761e0ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec = ts.time_step_spec(\n",
    "    observation_spec = observation_spec, \n",
    "    # reward_spec = _reward_spec\n",
    ")\n",
    "time_step_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9181303-6565-45f5-a293-08d50420a805",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Inspect chosen arm features spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6b526a5-997c-4621-b21c-82c6ca1d6a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90d3e03e-619e-4fa4-b817-f02b4cefd6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(64,), dtype=tf.float32, name=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_arm_features_info = (\n",
    "  policy_utilities.create_chosen_arm_features_info_spec(\n",
    "      time_step_spec.observation,\n",
    "  )\n",
    ")\n",
    "chosen_arm_features_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc427092-beb7-4baf-a2e9-b8d10629182c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - dont understand this\n",
    "bandit_policy_type = (\n",
    "    policy_utilities.BanditPolicyType.GREEDY\n",
    ")\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0a4a2a33-c7d4-4d81-8082-80dfc3596741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - dont understand this\n",
    "bandit_policy_type = (\n",
    "    policy_utilities.create_bandit_policy_type_tensor_spec(shape=[1])\n",
    ")\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6e7ac02b-18bd-4519-92fe-5541b1a8ddc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_spec = policy_utilities.PerArmPolicyInfo(\n",
    "  predicted_rewards_mean=predicted_rewards_mean,\n",
    "  bandit_policy_type=bandit_policy_type,\n",
    "  chosen_arm_features=chosen_arm_features_info,\n",
    ")\n",
    "info_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9c197-ae9b-461d-8956-f078b929ac12",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The Agent\n",
    "\n",
    "**Note** that contextual bandits form a special case of RL, where the actions taken by the agent do not alter the state of the environment \n",
    "\n",
    "> “Contextual” refers to the fact that the agent chooses among a set of actions while having knowledge of the context (environment observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81d6e84-688e-48c5-aea1-77df031348c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Agent & Network defined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aadb01-eb5c-4870-ae14-9e66624ba594",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **Agent types**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d075e8a6-11a9-4346-8725-3653fba4bac4",
   "metadata": {},
   "source": [
    "> `AGENT_TYPE = ['LinUCB', 'LinTS', 'epsGreedy', 'NeuralLinUCB']`\n",
    "\n",
    "LinearUCBAgent: (`LinUCB`) \n",
    "* An agent implementing the Linear UCB bandit algorithm ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/lin_ucb_agent/LinearUCBAgent))\n",
    "\n",
    "LinearThompsonSamplingAgent: (`LinTS`) \n",
    "* Implements the Linear Thompson Sampling Agent from the [paper](https://arxiv.org/abs/1209.3352): *Thompson Sampling for Contextual Bandits with Linear Payoffs* ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/linear_thompson_sampling_agent/LinearThompsonSamplingAgent))\n",
    "\n",
    "NeuralEpsilonGreedyAgent: (`epsGreedy`) \n",
    "* A neural network based epsilon greedy agent ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_epsilon_greedy_agent/NeuralEpsilonGreedyAgent))\n",
    "\n",
    "NeuralLinUCBAgent: (`NeuralLinUCB`) \n",
    "* An agent implementing the LinUCB algorithm on top of a neural network ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_linucb_agent/NeuralLinUCBAgent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b8e88e-c8ea-4193-a911-0d974ef3b1a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Network types**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f547087d-5fad-4521-a584-cb46ce52897d",
   "metadata": {},
   "source": [
    "Which network architecture to use for the `epsGreedy` or `NeuralLinUCB` agents\n",
    "\n",
    "```\n",
    "NETWORK_TYPE = ['commontower', 'dotproduct']\n",
    "```\n",
    "\n",
    "**GlobalAndArmCommonTowerNetwork:** (`commontower`)\n",
    "* This network takes the output of the global and per-arm networks, and leads them through a common network, that in turn outputs reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "> * `COMMON_LAYERS` - Iterable of ints. Specifies the layers of the common tower\n",
    "* The network produced by this function can be used either in `GreedyRewardPredictionPolicy`, or `NeuralLinUCBPolicy`\n",
    "> * In the former case, the network must have `output_dim=1`, it is going to be an instance of `QNetwork`, and used in the policy as a reward prediction network\n",
    "> * In the latter case, the network will be an encoding network with its output consumed by a reward layer or a `LinUCB` method. The specified `output_dim` will be the encoding dimension\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmCommonTowerNetwork)\n",
    "\n",
    "**GlobalAndArmDotProductNetwork:** (`dotproduct`)\n",
    "* This network calculates the **dot product** of the output of the global and per-arm networks and returns them as reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmDotProductNetwork)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3dc270-deb5-4e96-8276-74759a06c318",
   "metadata": {},
   "source": [
    "### Agent config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bbe29263-453d-405e-ac50-fee7f379f335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\n",
      "\n",
      "time_step_spec:  TimeStep(\n",
      "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
      "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n",
      "\n",
      "action_spec:  BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))\n",
      "\n",
      "observation_spec:  {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\")\n",
    "print(\"\\ntime_step_spec: \", time_step_spec)\n",
    "print(\"\\naction_spec: \", action_spec)\n",
    "print(\"\\nobservation_spec: \", observation_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6d817bf2-1fa6-4bae-af90-745fad996b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'common_layers': [16, 8],\n",
      " 'epsilon': 0.01,\n",
      " 'eval_batch_size': 1,\n",
      " 'global_layers': [64, 32, 16],\n",
      " 'learning_rate': 0.05,\n",
      " 'model_type': 'epsGreedy',\n",
      " 'network_type': 'commontower',\n",
      " 'num_actions': 2,\n",
      " 'per_arm_layers': [64, 32, 16]}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Agents\n",
    "# ================================\n",
    "AGENT_TYPE      = 'epsGreedy' # 'LinUCB' | 'LinTS |, 'epsGreedy' | 'NeuralLinUCB'\n",
    "\n",
    "# Parameters for linear agents (LinUCB and LinTS).\n",
    "AGENT_ALPHA     = 0.1\n",
    "\n",
    "# Parameters for neural agents (NeuralEpsGreedy and NerualLinUCB).\n",
    "EPSILON         = 0.01\n",
    "LR              = 0.05\n",
    "\n",
    "# Parameters for NeuralLinUCB\n",
    "ENCODING_DIM    = 1\n",
    "EPS_PHASE_STEPS = 1000\n",
    "\n",
    "# ================================\n",
    "# Agent's Preprocess Network\n",
    "# ================================\n",
    "NETWORK_TYPE    = \"commontower\" # 'commontower' | 'dotproduct'\n",
    "\n",
    "if AGENT_TYPE == 'NeuralLinUCB':\n",
    "    NETWORK_TYPE = 'commontower'\n",
    "    \n",
    "GLOBAL_LAYERS   = [64, 32, 16]\n",
    "ARM_LAYERS      = [64, 32, 16]\n",
    "COMMON_LAYERS   = [16, 8]\n",
    "\n",
    "HPARAMS = {  # TODO - streamline and consolidate\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"eval_batch_size\" : EVAL_BATCH_SIZE,\n",
    "    \"num_actions\": NUM_ACTIONS,\n",
    "    \"model_type\": AGENT_TYPE,\n",
    "    \"network_type\": NETWORK_TYPE,\n",
    "    \"global_layers\": GLOBAL_LAYERS,\n",
    "    \"per_arm_layers\": ARM_LAYERS,\n",
    "    \"common_layers\": COMMON_LAYERS,\n",
    "    \"learning_rate\": LR,\n",
    "    \"epsilon\": EPSILON,\n",
    "}\n",
    "pprint(HPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6cb60f0b-90b7-49ab-9c41-046ea00ab750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from tf_agents.bandits.policies import policy_utilities\n",
    "# # from tf_agents.bandits.agents import greedy_reward_prediction_agent\n",
    "\n",
    "# def _get_agent(\n",
    "#     agent_type, \n",
    "#     network_type, \n",
    "#     time_step_spec, \n",
    "#     action_spec, \n",
    "#     observation_spec,\n",
    "#     global_step\n",
    "# ):\n",
    "#     network = None\n",
    "#     observation_and_action_constraint_splitter = None\n",
    "\n",
    "#     if AGENT_TYPE == 'LinUCB':\n",
    "#         agent = lin_ucb_agent.LinearUCBAgent(\n",
    "#             time_step_spec=time_step_spec,\n",
    "#             action_spec=action_spec,\n",
    "#             alpha=AGENT_ALPHA,\n",
    "#             accepts_per_arm_features=True,\n",
    "#             dtype=tf.float32,\n",
    "#         )\n",
    "#     elif AGENT_TYPE == 'LinTS':\n",
    "#         agent = lin_ts_agent.LinearThompsonSamplingAgent(\n",
    "#             time_step_spec=time_step_spec,\n",
    "#             action_spec=action_spec,\n",
    "#             alpha=AGENT_ALPHA,\n",
    "#             observation_and_action_constraint_splitter=(\n",
    "#                 observation_and_action_constraint_splitter\n",
    "#             ),\n",
    "#             accepts_per_arm_features=True,\n",
    "#             dtype=tf.float32,\n",
    "#         )\n",
    "#     elif AGENT_TYPE == 'epsGreedy':\n",
    "#         # obs_spec = per_arm_tf_env.observation_spec()\n",
    "#         if NETWORK_TYPE == 'commontower':\n",
    "#             network = global_and_arm_feature_network.create_feed_forward_common_tower_network(\n",
    "#                 observation_spec = observation_spec, \n",
    "#                 global_layers = GLOBAL_LAYERS, \n",
    "#                 arm_layers = ARM_LAYERS, \n",
    "#                 common_layers = COMMON_LAYERS,\n",
    "#                 output_dim = 1\n",
    "#             )\n",
    "#         elif NETWORK_TYPE == 'dotproduct':\n",
    "#             network = global_and_arm_feature_network.create_feed_forward_dot_product_network(\n",
    "#                 observation_spec = observation_spec, \n",
    "#                 global_layers = GLOBAL_LAYERS, \n",
    "#                 arm_layers = ARM_LAYERS\n",
    "#             )\n",
    "#         agent = neural_epsilon_greedy_agent.NeuralEpsilonGreedyAgent(\n",
    "#             time_step_spec=time_step_spec,\n",
    "#             action_spec=action_spec,\n",
    "#             reward_network=network,\n",
    "#             optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=HPARAMS['learning_rate']),\n",
    "#             epsilon=HPARAMS['epsilon'],\n",
    "#             observation_and_action_constraint_splitter=(\n",
    "#                 observation_and_action_constraint_splitter\n",
    "#             ),\n",
    "#             accepts_per_arm_features=True,\n",
    "#             emit_policy_info=(\n",
    "#                 policy_utilities.InfoFields.PREDICTED_REWARDS_MEAN,\n",
    "#                 policy_utilities.BanditPolicyType.GREEDY,\n",
    "#             ),\n",
    "#             train_step_counter=global_step,\n",
    "#             # info_fields_to_inherit_from_greedy=[\n",
    "#             #     policy_utilities.InfoFields.PREDICTED_REWARDS_MEAN\n",
    "#             # ],\n",
    "#             name='OffpolicyNeuralEpsGreedyAgent'\n",
    "#         )\n",
    "\n",
    "#     elif AGENT_TYPE == 'NeuralLinUCB':\n",
    "#         # obs_spec = per_arm_tf_env.observation_spec()\n",
    "#         network = (\n",
    "#             global_and_arm_feature_network.create_feed_forward_common_tower_network(\n",
    "#                 observation_spec = observation_spec, \n",
    "#                 global_layers = GLOBAL_LAYERS, \n",
    "#                 arm_layers = ARM_LAYERS, \n",
    "#                 common_layers = COMMON_LAYERS,\n",
    "#                 output_dim = ENCODING_DIM\n",
    "#             )\n",
    "#         )\n",
    "#         agent = neural_linucb_agent.NeuralLinUCBAgent(\n",
    "#             time_step_spec=per_arm_tf_env.time_step_spec(),\n",
    "#             action_spec=per_arm_tf_env.action_spec(),\n",
    "#             encoding_network=network,\n",
    "#             encoding_network_num_train_steps=EPS_PHASE_STEPS,\n",
    "#             encoding_dim=ENCODING_DIM,\n",
    "#             optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=LR),\n",
    "#             alpha=1.0,\n",
    "#             gamma=1.0,\n",
    "#             epsilon_greedy=EPSILON,\n",
    "#             accepts_per_arm_features=True,\n",
    "#             debug_summaries=True,\n",
    "#             summarize_grads_and_vars=True,\n",
    "#             emit_policy_info=policy_utilities.InfoFields.PREDICTED_REWARDS_MEAN,\n",
    "#         )\n",
    "        \n",
    "#     print(f\"Agent   : {agent.name}\")\n",
    "\n",
    "#     if network:\n",
    "#         print(f\"Network : {network.name}\")\n",
    "#         network = network.name\n",
    "    \n",
    "#     return agent, network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c22fc915-98d7-4c66-ae56-9b6764490acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent   : OffpolicyNeuralEpsGreedyAgent\n",
      "Network : global_and_arm_common_tower_network\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(Trajectory(\n",
       "{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32)),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}),\n",
       " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None)),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "# agent, network = _get_agent(\n",
    "#     agent_type = AGENT_TYPE, \n",
    "#     network_type = NETWORK_TYPE, \n",
    "#     time_step_spec = time_step_spec, \n",
    "#     action_spec = action_spec, \n",
    "#     observation_spec = observation_spec,\n",
    "#     global_step = global_step\n",
    "# )\n",
    "\n",
    "# agent.initialize() # TODO - does this go here?\n",
    "\n",
    "# agent.policy.trajectory_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2bf060bb-9880-40b4-8583-dd7a3f915bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.perarm_features import agent_factory as agent_factory\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "agent, network = agent_factory._get_agent(\n",
    "    agent_type=AGENT_TYPE, \n",
    "    network_type=NETWORK_TYPE, \n",
    "    time_step_spec=time_step_spec, \n",
    "    action_spec=action_spec, \n",
    "    observation_spec=observation_spec,\n",
    "    global_step = global_step,\n",
    "    global_layers = GLOBAL_LAYERS,\n",
    "    arm_layers = ARM_LAYERS,\n",
    "    common_layers = COMMON_LAYERS,\n",
    "    agent_alpha = AGENT_ALPHA,\n",
    "    learning_rate = LR,\n",
    "    epsilon = EPSILON,\n",
    "    encoding_dim = ENCODING_DIM,\n",
    "    eps_phase_steps = EPS_PHASE_STEPS,\n",
    ")\n",
    "\n",
    "print(f\"Agent: {agent.name}\")\n",
    "\n",
    "if network:\n",
    "    print(f\"Network: {network}\")\n",
    "        \n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "731ce66f-4c19-4e8d-8503-5147ed1de420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OffpolicyNeuralEpsGreedyAgent'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d404dae-3cc3-4f81-962b-4641455ca4f2",
   "metadata": {},
   "source": [
    "## Reward function\n",
    "\n",
    "**TODO:**\n",
    "* explain how to translate reward to this common recommendation objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df9aecd6-d20a-48a7-9ead-4da3bbcfdae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_rewards(element):\n",
    "    \"\"\"Calculates reward for the actions.\"\"\"\n",
    "\n",
    "    def _calc_reward(x):\n",
    "        \"\"\"Calculates reward for a single action.\"\"\"\n",
    "        r0 = lambda: tf.constant(0.0)\n",
    "        r1 = lambda: tf.constant(1.0)\n",
    "        r2 = lambda: tf.constant(2.0)\n",
    "        r3 = lambda: tf.constant(3.0)\n",
    "        r4 = lambda: tf.constant(4.0)\n",
    "        r5 = lambda: tf.constant(5.0)\n",
    "        c1 = tf.equal(x, 1.0)\n",
    "        c2 = tf.equal(x, 2.0)\n",
    "        c3 = tf.equal(x, 3.0)\n",
    "        c4 = tf.equal(x, 4.0)\n",
    "        c5 = tf.equal(x, 5.0)\n",
    "        return tf.case(\n",
    "            [(c1, r1), (c2, r2), (c3, r3),(c4, r4),(c5, r5)], \n",
    "            default=r0, exclusive=True\n",
    "        )\n",
    "\n",
    "    return tf.map_fn(\n",
    "        fn=_calc_reward, \n",
    "        elems=element['user_rating'], \n",
    "        dtype=tf.float32\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac59703a-9a00-4eba-a3b7-45b21b738dd4",
   "metadata": {},
   "source": [
    "## Trajectory function\n",
    "\n",
    "**parking lot**\n",
    "* does trajectory fn need concept of `dummy_chosen_arm_features`, similar to [this](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_base_policy.py#L297)\n",
    "\n",
    "```python\n",
    "      dummy_chosen_arm_features = tf.nest.map_structure(\n",
    "          lambda obs: tf.zeros_like(obs[:, 0, ...]),\n",
    "          time_step.observation[bandit_spec_utils.PER_ARM_FEATURE_KEY],\n",
    "      )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c16aa7b-f328-425e-b02e-a3fc7f200859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "# from tf_agents.trajectories import trajectory\n",
    "# from src.per_arm_rl import train_utils_v2 as train_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f3605d9f-d239-4871-9a61-6e9b21f9c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _trajectory_fn(element): # hparams\n",
    "    \n",
    "    \"\"\"Converts a dataset element into a trajectory.\"\"\"\n",
    "    global_features = _get_global_context_features(element)\n",
    "    arm_features = _get_per_arm_features(element)\n",
    "    \n",
    "    # Adds a time dimension.\n",
    "    arm_features = train_utils._add_outer_dimension(arm_features)\n",
    "\n",
    "    # obs spec\n",
    "    observation = {\n",
    "        bandit_spec_utils.GLOBAL_FEATURE_KEY:\n",
    "            train_utils._add_outer_dimension(global_features),\n",
    "    }\n",
    "\n",
    "    reward = train_utils._add_outer_dimension(_get_rewards(element))\n",
    "\n",
    "    # To emit the predicted rewards in policy_info, we need to create dummy\n",
    "    # rewards to match the definition in TensorSpec for the ones specified in\n",
    "    # emit_policy_info set.\n",
    "    dummy_rewards = tf.zeros([HPARAMS['batch_size'], 1, HPARAMS['num_actions']])\n",
    "    policy_info = policy_utilities.PerArmPolicyInfo(\n",
    "        chosen_arm_features=arm_features,\n",
    "        # Pass dummy mean rewards here to match the model_spec for emitting\n",
    "        # mean rewards in policy info\n",
    "        predicted_rewards_mean=dummy_rewards,\n",
    "        bandit_policy_type=policy_utilities.BanditPolicyType.GREEDY\n",
    "    )\n",
    "    \n",
    "    if HPARAMS['model_type'] == 'neural_ucb':\n",
    "        policy_info = policy_info._replace(\n",
    "            predicted_rewards_optimistic=dummy_rewards\n",
    "        )\n",
    "        \n",
    "    return trajectory.single_step(\n",
    "        observation=observation,\n",
    "        action=tf.zeros_like(\n",
    "            reward, dtype=tf.int32\n",
    "        ),  # Arm features are copied from policy info, put dummy zeros here\n",
    "        policy_info=policy_info,\n",
    "        reward=reward,\n",
    "        discount=tf.zeros_like(reward)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0b9d6180-4b3f-49cc-92f9-b7bce48c329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAJECTORY_SUBDIR = \"trajectories\"\n",
    "# os.mkdir(f'{TRAJECTORY_SUBDIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "52cb38f2-6fcb-4de6-b70f-3d55a5785500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCAL_FILENAME = f\"trajectories_{HPARAMS['batch_size']}\"\n",
    "\n",
    "# print(LOCAL_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "257791d1-c97c-48c0-bc92-f5a4737b6c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for x in train_dataset.batch(HPARAMS['batch_size']).take(1):\n",
    "#     test_traj = _trajectory_fn(x)\n",
    "    \n",
    "# test_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d01f5976-8c40-4d8f-950d-ed9029a82fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.rank(test_traj.observation['global'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ec5d167f-e0e8-4bc8-806e-4968d0983f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.rank(test_traj.reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcbfc9a-049e-49b9-b2a3-ecb9fd4b9964",
   "metadata": {},
   "source": [
    "# [3] Training the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f272a959-5102-4f80-b236-3f908f90fcd1",
   "metadata": {},
   "source": [
    "### calculate train dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "80718191-fa71-499e-908e-667c64a29b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_DATA_SIZE : 80000\n",
      "NUM_TRAIN_STEPS : 625\n"
     ]
    }
   ],
   "source": [
    "# TRAIN_DATA_SIZE = len(list(train_dataset))\n",
    "TRAIN_DATA_SIZE = 80000\n",
    "\n",
    "NUM_TRAIN_STEPS = TRAIN_DATA_SIZE // HPARAMS['batch_size']\n",
    "# NUM_TRAIN_STEPS = 10000\n",
    "\n",
    "print(f\"TRAIN_DATA_SIZE : {TRAIN_DATA_SIZE}\")\n",
    "print(f\"NUM_TRAIN_STEPS : {NUM_TRAIN_STEPS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2136f6-3ed7-47ab-9441-9827845d40c3",
   "metadata": {},
   "source": [
    "### create eval dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c7be8a98-14ff-4dbd-a724-ab9c66acfa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = \"val\"\n",
    "\n",
    "val_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        val_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "val_dataset = tf.data.TFRecordDataset(val_files)\n",
    "val_dataset = val_dataset.map(data_utils.parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13adc1ef-b50e-41a3-9b95-c128d0c55a2b",
   "metadata": {},
   "source": [
    "## set Vertex Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e861fb27-df24-4821-8448-cf1346b186f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : mab-local-v6\n",
      "RUN_NAME          : run-20230821-222258\n",
      "\n",
      "BASE_OUTPUT_DIR   : gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230821-222258\n",
      "LOG_DIR           : gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230821-222258/logs\n",
      "ROOT_DIR          : gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230821-222258/root\n",
      "ARTIFACTS_DIR     : gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230821-222258/artifacts\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME   = f'mab-local-v6'\n",
    "\n",
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b7a5e4-efff-490b-b431-53037a2f4a16",
   "metadata": {},
   "source": [
    "## eval loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "95b0c355-8976-479f-b61a-3e78fb147d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# eval loop\n",
    "# ====================================================\n",
    "\n",
    "def _run_bandit_eval(\n",
    "    policy,\n",
    "    data,\n",
    "    eval_batch_size,\n",
    "    per_arm_dim,\n",
    "    global_dim,\n",
    "):\n",
    "    logged_rewards = []\n",
    "    predicted_rewards = []\n",
    "    trouble_list = []\n",
    "    train_loss_results = []\n",
    "    \n",
    "    dummy_arm = tf.zeros([eval_batch_size, per_arm_dim], dtype=tf.float32)\n",
    "\n",
    "    for x in data:\n",
    "        # get feature tensors\n",
    "        global_feat_infer = _get_global_context_features(x)\n",
    "        arm_feat_infer = _get_per_arm_features(x)\n",
    "        rewards = _get_rewards(x)\n",
    "\n",
    "        # reshape arm features\n",
    "        arm_feat_infer = tf.reshape(arm_feat_infer, [eval_batch_size, per_arm_dim])\n",
    "        concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "\n",
    "        # flatten global\n",
    "        flat_global_infer = tf.reshape(global_feat_infer, [global_dim])\n",
    "        feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "\n",
    "        # get actual reward\n",
    "        actual_reward = rewards.numpy()[0]\n",
    "        # logged_rewards.append(actual_reward)\n",
    "\n",
    "        # build trajectory step\n",
    "        trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "        \n",
    "        # pred w/ trained agent\n",
    "        prediction = policy.action(trajectory_step)\n",
    "        # prediction = trained_policy.action(trajectory_step)\n",
    "        # prediction_list.append(prediction)\n",
    "\n",
    "        predicted_rewards_mean = prediction.info.predicted_rewards_mean #[0]\n",
    "        # pred_rewards_mean_list.append(predicted_rewards_mean)\n",
    "        \n",
    "        predicted_reward_tf = tf.gather(\n",
    "            predicted_rewards_mean,\n",
    "            prediction.action, \n",
    "            batch_dims=0, \n",
    "            axis=-1\n",
    "        )\n",
    "\n",
    "        pred_reward = float(round(predicted_reward_tf.numpy()))\n",
    "\n",
    "        # When the uniform random policy is used, the \n",
    "        #    loss is meaningless for evaluation\n",
    "        # > discard preds from uniform random policy\n",
    "        # > keep preds from greedy policy, \n",
    "        if pred_reward < 0:\n",
    "            trouble_list.append(pred_reward)\n",
    "        elif pred_reward > 5:\n",
    "            trouble_list.append(pred_reward)\n",
    "        else:\n",
    "            predicted_rewards.append(pred_reward)\n",
    "\n",
    "            pred_loss = tf.keras.metrics.mean_squared_error(\n",
    "                rewards, predicted_reward_tf\n",
    "            )\n",
    "            train_loss_results.append(pred_loss)\n",
    "            logged_rewards.append(actual_reward)\n",
    "            \n",
    "    # calculate avg loss\n",
    "    avg_eval_loss = tf.reduce_mean(train_loss_results)\n",
    "    \n",
    "    return (\n",
    "        avg_eval_loss,\n",
    "        predicted_rewards,\n",
    "        logged_rewards,\n",
    "        # train_loss_results\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b3d3c-75f7-46f4-9a1b-6329e419b7f5",
   "metadata": {},
   "source": [
    "## train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "97cfe7c3-4022-47a9-83c2-df0ad8a2abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.metrics import export_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.utils import common\n",
    "\n",
    "# from src.per_arm_rl import train_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bb7ffc-00df-4d46-857b-86c87b78f597",
   "metadata": {},
   "source": [
    "`agent.train(experience=...)`\n",
    "\n",
    "where `experience` is a batch of trajectories data in the form of a Trajectory. \n",
    "* The structure of experience must match that of `self.training_data_spec`. \n",
    "* All tensors in experience must be shaped [batch, time, ...] where time must be equal to self.train_step_length if that property is not None."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94d6d45-c71e-4fe4-9af8-af9a8bda4e4f",
   "metadata": {},
   "source": [
    "### logs & checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "049ee49b-3b1a-4b12-a360-15e759dff7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('metrics: [<tf_agents.metrics.tf_metrics.NumberOfEpisodes object at '\n",
      " '0x7f89dc288070>, <tf_agents.metrics.tf_metrics.AverageEpisodeLengthMetric '\n",
      " 'object at 0x7f89dc289e10>, <tf_agents.metrics.tf_metrics.AverageReturnMetric '\n",
      " 'object at 0x7f89dc28ba00>]')\n",
      "setting checkpoint_manager: gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230821-222258/root/chkpoint\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    f\"{LOG_DIR}/train\", flush_millis=10 * 1000\n",
    ")\n",
    "# train_summary_writer.set_as_default()\n",
    "\n",
    "# eval_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "#     f\"{LOG_DIR}/eval\", flush_millis=10 * 1000\n",
    "# )\n",
    "# ====================================================\n",
    "# metrics\n",
    "# ====================================================\n",
    "step_metric = tf_metrics.EnvironmentSteps()\n",
    "metrics = [\n",
    "    # tf_metrics.NumberOfEpisodes(),\n",
    "    # tf_metrics.AverageEpisodeLengthMetric(batch_size=HPARAMS['batch_size']),\n",
    "    tf_metrics.AverageReturnMetric(batch_size=HPARAMS['batch_size'])\n",
    "]\n",
    "\n",
    "pprint(f\"metrics: {metrics}\")\n",
    "\n",
    "# ====================================================\n",
    "# get checkpoint manager\n",
    "# ====================================================\n",
    "CHKPOINT_DIR = f\"{ROOT_DIR}/chkpoint\"\n",
    "print(f\"setting checkpoint_manager: {CHKPOINT_DIR}\")\n",
    "\n",
    "checkpoint_manager = train_utils.restore_and_get_checkpoint_manager(\n",
    "    root_dir=CHKPOINT_DIR, \n",
    "    agent=agent, \n",
    "    metrics=metrics, \n",
    "    step_metric=step_metric\n",
    ")\n",
    "# ====================================================\n",
    "# policy saver\n",
    "# ====================================================\n",
    "saver = policy_saver.PolicySaver(\n",
    "    agent.policy, \n",
    "    train_step=global_step\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83683f4b-8a1a-44b9-8d5f-7ee3304c794c",
   "metadata": {},
   "source": [
    "### evaluate policy loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f9432613-6583-4828-8a2a-dd939adbc3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_DATA_SIZE : 80000\n",
      "NUM_TRAIN_STEPS : 625\n"
     ]
    }
   ],
   "source": [
    "# TRAIN_DATA_SIZE = len(list(train_dataset))\n",
    "TRAIN_DATA_SIZE = 80000\n",
    "\n",
    "NUM_TRAIN_STEPS = TRAIN_DATA_SIZE // HPARAMS['batch_size']\n",
    "# NUM_TRAIN_STEPS = 10000\n",
    "\n",
    "print(f\"TRAIN_DATA_SIZE : {TRAIN_DATA_SIZE}\")\n",
    "print(f\"NUM_TRAIN_STEPS : {NUM_TRAIN_STEPS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3c220683-8d88-49cb-adee-d13bb2fd5bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL_DATA_SIZE : 20000\n",
      "NUM_EVAL_STEPS : 10000\n"
     ]
    }
   ],
   "source": [
    "# EVAL_DATA_SIZE = len(list(val_dataset))\n",
    "EVAL_DATA_SIZE = 20000\n",
    "\n",
    "# NUM_EVAL_STEPS = EVAL_DATA_SIZE // HPARAMS['eval_batch_size']\n",
    "NUM_EVAL_STEPS = 10000\n",
    "\n",
    "print(f\"EVAL_DATA_SIZE : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS : {NUM_EVAL_STEPS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "379ffc65-4eec-4af1-8fd4-912ef65a9808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_ITER_STEPS: 625\n",
      "CHKPT_INTERVAL: 625\n",
      "log_interval : 50\n",
      "eval_interval : 312\n"
     ]
    }
   ],
   "source": [
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS[\"eval_batch_size\"])\n",
    "\n",
    "if NUM_EVAL_STEPS > 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)\n",
    "# eval_ds = eval_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# NUM_ITER_STEPS = 200\n",
    "NUM_ITER_STEPS = NUM_TRAIN_STEPS #* 2\n",
    "print(f\"NUM_ITER_STEPS: {NUM_ITER_STEPS}\")\n",
    "\n",
    "# CHKPT_INTERVAL = NUM_ITER_STEPS // 5\n",
    "CHKPT_INTERVAL = NUM_TRAIN_STEPS\n",
    "print(f\"CHKPT_INTERVAL: {CHKPT_INTERVAL}\")\n",
    "\n",
    "log_interval = 50\n",
    "print(f\"log_interval : {log_interval}\")\n",
    "\n",
    "# eval_interval = log_interval #* 2\n",
    "eval_interval = NUM_ITER_STEPS // 2\n",
    "print(f\"eval_interval : {eval_interval}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e498d7e3-d166-4e1d-94a5-f721de58694a",
   "metadata": {},
   "source": [
    "### run train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "da4680f3-693b-4530-8e4d-88bc43036c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating pre-trained Agent...\n",
      "pre-train val_loss     : 15.119401931762695\n",
      "pre-train eval runtime : 4\n",
      "starting train loop...\n",
      "step = 0: train loss = 15.90999984741211\n",
      "step = 50: train loss = 1.2799999713897705\n",
      "step = 100: train loss = 1.5299999713897705\n",
      "step = 150: train loss = 1.350000023841858\n",
      "step = 200: train loss = 1.2300000190734863\n",
      "step = 250: train loss = 1.2699999809265137\n",
      "step = 300: train loss = 0.9700000286102295\n",
      "step = 350: train loss = 1.2400000095367432\n",
      "step = 400: train loss = 1.1699999570846558\n",
      "step = 450: train loss = 1.350000023841858\n",
      "step = 500: train loss = 1.2899999618530273\n",
      "step = 550: train loss = 1.2400000095367432\n",
      "step = 600: train loss = 1.2300000190734863\n",
      "train runtime_mins: 6\n",
      "saved trained policy to: gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230821-205512/artifacts\n",
      "evaluating trained Agent...\n",
      "post-train val_loss     : 1.1103360652923584\n",
      "post-train eval runtime : 4\n"
     ]
    }
   ],
   "source": [
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "# agent.train = common.function(agent.train)\n",
    "# train_step_counter = tf.compat.v1.train.get_or_create_global_step()\n",
    "# train_loss = collections.defaultdict(list)\n",
    "\n",
    "list_o_loss = []\n",
    "# list_o_vloss = []\n",
    "\n",
    "# dummy_arm = tf.zeros([HPARAMS['eval_batch_size'], PER_ARM_DIM], dtype=tf.float32)\n",
    "# ====================================================\n",
    "# dataset iterators\n",
    "# ====================================================\n",
    "train_ds_iterator = iter(train_dataset.batch(HPARAMS['batch_size']).repeat(5))\n",
    "# eval_ds_iterator = iter(eval_ds)\n",
    "\n",
    "# ====================================================\n",
    "# Evaluate the agent's policy once before training\n",
    "# ====================================================\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "pre_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "\n",
    "print(f\"evaluating pre-trained Agent...\")\n",
    "start_time = time.time()\n",
    "\n",
    "pre_val_loss, pre_preds, pre_tr_rewards = _run_bandit_eval(\n",
    "    policy = pre_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"pre-train val_loss     : {pre_val_loss}\")\n",
    "print(f\"pre-train eval runtime : {runtime_mins}\")\n",
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "print(f\"starting train loop...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# for i in tqdm(range(NUM_ITER_STEPS)):\n",
    "for i in range(NUM_ITER_STEPS):\n",
    "    \n",
    "    with train_summary_writer.as_default():\n",
    "\n",
    "        data = next(train_ds_iterator)\n",
    "        trajectories = _trajectory_fn(data)\n",
    "\n",
    "        # All tensors in experience must be shaped [batch, time, ...] \n",
    "        step = agent.train_step_counter.numpy()\n",
    "        loss = agent.train(experience=trajectories)\n",
    "        list_o_loss.append(loss.loss.numpy())\n",
    "\n",
    "        train_utils._export_metrics_and_summaries(\n",
    "            step=i, \n",
    "            metrics=metrics\n",
    "        )\n",
    "\n",
    "        # print step loss\n",
    "        if step % log_interval == 0:\n",
    "            print(\n",
    "                'step = {0}: train loss = {1}'.format(\n",
    "                    step, round(loss.loss.numpy(), 2)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if i > 0 and i % CHKPT_INTERVAL == 0:\n",
    "            saver.save(os.path.join(CHKPOINT_DIR, 'policy_%d' % step_metric.result()))\n",
    "            print(f\"saved policy to: {CHKPOINT_DIR}\")\n",
    "   \n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"train runtime_mins: {runtime_mins}\")\n",
    "\n",
    "saver.save(ARTIFACTS_DIR)\n",
    "print(f\"saved trained policy to: {ARTIFACTS_DIR}\")\n",
    "\n",
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = _run_bandit_eval(\n",
    "    policy = post_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "17b2b0d2-9795-4367-b57b-c331e94d1000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1103361"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb1ed8-f67b-4e7b-9cbc-70edd50e49ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate train job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff31fe28-2f05-499f-b1cc-505f3c9074e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### train loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "41937f9a-6c28-48d2-bc7c-bfe4372c7cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_o_loss)\n",
    "# plt.ylim([0, 10])\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e947e1-67f4-4205-99af-6921c6e9c896",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e0f77a33-0962-4af0-af97-cf05f895cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5d0509cb-0777-4d35-86c6-28c8acbcc793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e46cc92fa9897805\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e46cc92fa9897805\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=$LOG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc40143-30b1-479f-b9b1-fa4c07b1690e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [4] Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6c94a0-122f-4ba6-acef-5653a3cc7850",
   "metadata": {
    "tags": []
   },
   "source": [
    "## load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b1c382b5-e2e0-45a2-9c5f-ef2c468d0f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230821-205512/artifacts\n"
     ]
    }
   ],
   "source": [
    "POLICY_URI = ARTIFACTS_DIR\n",
    "# \"gs://mabv1-hybrid-vertex-bucket/mab-local-v4/run-20230817-142118/artifacts\"\n",
    "# \"gs://mabv1-hybrid-vertex-bucket/mab-local-v4/run-20230817-193342/artifacts\"\n",
    "# \"gs://mabv1-hybrid-vertex-bucket/mab-local-v4/run-20230817-211040/artifacts\"\n",
    "print(POLICY_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "68592d97-1272-4c6d-a4bd-43a6f7fe6c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f7cc8667400>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910a06f-678f-4bfa-a132-10b885f871c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "567f64e1-8149-4364-b561-1a9d12581b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec={'bucketized_user_age': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'movie_genres': TensorSpec(shape=(None, 1), dtype=tf.int64, name=None), 'movie_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'timestamp': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'user_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_occupation_text': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_rating': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "aff30396-e0fd-4f43-acaa-6af8b20b12cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "for x in eval_ds.take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    global_feat_infer = _get_global_context_features(x)\n",
    "    arm_feat_infer = _get_per_arm_features(x)\n",
    "    rewards = _get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e58af9ab-f4da-4857-afe5-6b8de26ed0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.5728416, 3.0374527], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=array([ 1.5639726e-02, -3.1821765e-02, -7.5147375e-03, -1.2750387e-02,\n",
       "        4.9963664e-02, -3.3286057e-02,  2.0584855e-02,  4.2843375e-02,\n",
       "        4.7787178e-02,  4.5679066e-02,  3.7793424e-02, -2.6883258e-02,\n",
       "       -3.4554709e-02, -4.9798973e-03,  6.9301240e-03,  1.8555392e-02,\n",
       "       -4.2709459e-02, -3.8219713e-02,  4.1822616e-02,  4.2918887e-02,\n",
       "       -2.9764270e-02, -4.5768548e-02,  2.8009426e-02, -4.6644323e-03,\n",
       "        4.1721944e-02,  3.5448086e-02,  4.0199231e-02,  3.8426746e-02,\n",
       "       -7.5555667e-03, -2.7164925e-02, -2.0989180e-03, -4.8757769e-02,\n",
       "        4.6904575e-02,  9.7514614e-03,  3.5535041e-02, -4.1110791e-02,\n",
       "        1.9986000e-02, -4.6567429e-02, -3.9937124e-03,  1.7358091e-02,\n",
       "        2.0064380e-02,  9.3392134e-03,  2.6355390e-02,  1.0356307e-06,\n",
       "       -1.2009192e-02,  4.8365481e-03, -2.0704998e-02, -1.3790272e-02,\n",
       "        2.6953842e-02, -2.2737980e-03, -4.9168088e-02, -2.4595488e-02,\n",
       "       -3.4203127e-02,  2.5342479e-03, -4.6184253e-02,  2.0559881e-02,\n",
       "       -1.5466165e-02,  5.7197586e-03, -1.0502957e-02,  1.3825621e-02,\n",
       "        1.7151382e-02, -9.0616718e-03,  4.9930923e-03, -3.3612061e-02],\n",
       "      dtype=float32)))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a8266c7c-3688-46a5-a1c8-a63bb7146128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info.bandit_policy_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb6767a-9e78-4297-bce9-826cf0123bde",
   "metadata": {
    "tags": []
   },
   "source": [
    "## get eval on validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e78fa3-df2f-49eb-88f6-943ba1b0e7f9",
   "metadata": {},
   "source": [
    "### prepare eval dataset iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f009ff83-d4df-4c4b-8cae-e430846d19c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL_BATCH_SIZE : 1\n",
      "EVAL_DATA_SIZE  : 20000\n",
      "NUM_EVAL_STEPS  : 10000\n"
     ]
    }
   ],
   "source": [
    "EVAL_BATCH_SIZE = HPARAMS['eval_batch_size']\n",
    "\n",
    "# NUM_EVAL_STEPS = EVAL_DATA_SIZE // EVAL_BATCH_SIZE\n",
    "NUM_EVAL_STEPS = 10000\n",
    "\n",
    "print(f\"EVAL_BATCH_SIZE : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"EVAL_DATA_SIZE  : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS  : {NUM_EVAL_STEPS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2e6a23d3-e68e-4f8f-93de-0c6e2f1c8353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(EVAL_BATCH_SIZE)\n",
    "\n",
    "if NUM_EVAL_STEPS >= 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)\n",
    "\n",
    "# eval_ds = eval_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# eval_ds_iterator = iter(eval_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e06a137-2d37-4a97-bdf8-bec213a17197",
   "metadata": {},
   "source": [
    "### run agent evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d2385e4d-b9d8-4231-9bbb-554528ee7bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating trained Agent...\n",
      "post-train val_loss     : 1.110495924949646\n",
      "post-train eval runtime : 3\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "# post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = _run_bandit_eval(\n",
    "    policy = trained_policy,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9712bc00-7ea0-4003-a3c7-81a0be5bc995",
   "metadata": {},
   "source": [
    "# [5] Prepare training application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1129ee41-b43c-4d5a-b656-cdac6b79688c",
   "metadata": {},
   "source": [
    "#### Vertex Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ef509680-4d19-4efa-9f01-21039e0d573b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : mab-local-v6\n"
     ]
    }
   ],
   "source": [
    "# using same experiment name \n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7ad98430-d836-40f1-8e4f-eb46f0c91fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : mab-local-v6\n",
      "RUN_NAME          : run-20230822-024125\n",
      "\n",
      "BASE_OUTPUT_DIR   : gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230822-024125\n",
      "LOG_DIR           : gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230822-024125/logs\n",
      "ROOT_DIR          : gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230822-024125/root\n",
      "ARTIFACTS_DIR     : gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230822-024125/artifacts\n"
     ]
    }
   ],
   "source": [
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "fbdecf78-94c5-4f8c-a6c0-86f2eace4663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent   : OffpolicyNeuralEpsGreedyAgent\n",
      "Network : global_and_arm_common_tower_network_7\n"
     ]
    }
   ],
   "source": [
    "# global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "# agent, network = _get_agent(\n",
    "#     agent_type = AGENT_TYPE, \n",
    "#     network_type = NETWORK_TYPE, \n",
    "#     time_step_spec = time_step_spec, \n",
    "#     action_spec = action_spec, \n",
    "#     observation_spec = observation_spec,\n",
    "#     global_step = global_step\n",
    "# )\n",
    "\n",
    "# agent.initialize()\n",
    "\n",
    "####\n",
    "\n",
    "from src.perarm_features import agent_factory as agent_factory\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "agent, network = agent_factory._get_agent(\n",
    "    agent_type=AGENT_TYPE, \n",
    "    network_type=NETWORK_TYPE, \n",
    "    time_step_spec=time_step_spec, \n",
    "    action_spec=action_spec, \n",
    "    observation_spec=observation_spec,\n",
    "    global_step = global_step,\n",
    "    global_layers = GLOBAL_LAYERS,\n",
    "    arm_layers = ARM_LAYERS,\n",
    "    common_layers = COMMON_LAYERS,\n",
    "    agent_alpha = AGENT_ALPHA,\n",
    "    learning_rate = LR,\n",
    "    epsilon = EPSILON,\n",
    "    encoding_dim = ENCODING_DIM,\n",
    "    eps_phase_steps = EPS_PHASE_STEPS,\n",
    ")\n",
    "\n",
    "print(f\"Agent: {agent.name}\")\n",
    "\n",
    "if network:\n",
    "    print(f\"Network: {network}\")\n",
    "        \n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "108ed33c-d8ef-4524-97e9-ced9e01c154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHKPT_INTERVAL: 100\n",
      "EVAL_BATCH_SIZE : 1\n",
      "EVAL_DATA_SIZE  : 20000\n",
      "NUM_EVAL_STEPS  : 100\n"
     ]
    }
   ],
   "source": [
    "from src.perarm_features import train_perarm as train_perarm\n",
    "\n",
    "# train args\n",
    "TRAINING_LOOPS = 150\n",
    "STEPS_PER_LOOP = 1\n",
    "drop_arm_feature_fn = None\n",
    "ASYNC_STEPS_PER_LOOP = 1\n",
    "LOG_INTERVAL = 50\n",
    "CHKPT_INTERVAL = 100\n",
    "\n",
    "# eval args\n",
    "EVAL_BATCH_SIZE = HPARAMS['eval_batch_size']\n",
    "NUM_EVAL_STEPS = 100\n",
    "\n",
    "TOTAL_TRAIN_TAKE = TRAINING_LOOPS * HPARAMS['batch_size']\n",
    "\n",
    "print(f\"CHKPT_INTERVAL    : {CHKPT_INTERVAL}\")\n",
    "print(f\"EVAL_BATCH_SIZE   : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"EVAL_DATA_SIZE    : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS    : {NUM_EVAL_STEPS}\")\n",
    "print(f\"TOTAL_TRAIN_TAKE  : {TOTAL_TRAIN_TAKE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a6b96bcc-79b6-4b07-947f-1d3d0e588ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(EVAL_BATCH_SIZE)\n",
    "\n",
    "if NUM_EVAL_STEPS >= 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)\n",
    "# eval_ds = eval_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# eval_ds_iterator = iter(eval_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "61e56496-85c4-4332-bcba-35c75bb5d2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating pre-trained Agent...\n",
      "pre-train val_loss: 15.193801879882812\n",
      "pre-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "pre_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(\n",
    "    agent.policy, use_tf_function=True\n",
    ")\n",
    "\n",
    "# pre_policy_tf = agent.policy\n",
    "\n",
    "print(f\"evaluating pre-trained Agent...\")\n",
    "start_time = time.time()\n",
    "\n",
    "pre_val_loss, pre_preds, pre_tr_rewards = _run_bandit_eval(\n",
    "    policy = pre_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = EVAL_BATCH_SIZE,\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM\n",
    ")\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"pre-train val_loss: {pre_val_loss}\")\n",
    "print(f\"pre-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f6c98398-d545-4dcc-a71f-32249b5f0336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_files: ['gs://mabv1-hybrid-vertex-bucket/data/train/ml-ratings-100k-train.tfrecord']\n",
      "train_files: ['gs://mabv1-hybrid-vertex-bucket/data/val/ml-ratings-100k-val.tfrecord']\n",
      "setting checkpoint_manager: gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230822-024125/root/chkpoint\n",
      "Did not find a pre-existing checkpoint. Starting from scratch.\n",
      "starting_loop: 0\n",
      "starting train loop...\n",
      "step = 0: loss = 15.90999984741211\n",
      "step = 50: loss = 1.399999976158142\n",
      "step = 100: loss = 1.4299999475479126\n",
      "saved policy to: gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230822-024125/root/chkpoint\n",
      "runtime_mins: 1\n",
      "saved trained policy to: gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230822-024125/artifacts\n",
      "Load trained policy & evaluate...\n",
      "load policy from model_dir: gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230822-024125/artifacts\n",
      "trained_policy: <tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy object at 0x7f8ac7a16080>\n",
      "evaluating trained Policy...\n",
      "post-train val_loss: 1.4560811519622803\n",
      "post-train eval runtime : 0\n",
      "complete train job in 1 minutes\n"
     ]
    }
   ],
   "source": [
    "#start the timer and training\n",
    "start_time = time.time()\n",
    "\n",
    "metric_results, agent = train_perarm.train_perarm(\n",
    "    agent = agent,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    num_iterations = TRAINING_LOOPS,\n",
    "    steps_per_loop = STEPS_PER_LOOP,\n",
    "    num_eval_steps = NUM_EVAL_STEPS,\n",
    "    # data\n",
    "    batch_size = HPARAMS['batch_size'],\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    # functions\n",
    "    _trajectory_fn = _trajectory_fn,\n",
    "    # _run_bandit_eval_fn = _run_bandit_eval,\n",
    "    # train intervals\n",
    "    chkpt_interval = CHKPT_INTERVAL,\n",
    "    log_interval = LOG_INTERVAL,\n",
    "    # dirs\n",
    "    bucket_name = BUCKET_NAME,\n",
    "    data_dir_prefix_path = DATA_GCS_PREFIX,\n",
    "    log_dir = LOG_DIR,\n",
    "    model_dir = ARTIFACTS_DIR,\n",
    "    root_dir = ROOT_DIR,\n",
    "    async_steps_per_loop = ASYNC_STEPS_PER_LOOP,\n",
    "    resume_training_loops = False,\n",
    "    use_gpu = True,\n",
    "    use_tpu = False,\n",
    "    profiler = False,\n",
    "    global_step = global_step,\n",
    "    total_train_take = TOTAL_TRAIN_TAKE\n",
    "    # additional_metrics = metrics,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"complete train job in {runtime_mins} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "177aa3ab-05b4-48f9-b434-9335bd9eb54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3686966"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(metric_results)\n",
    "metric_results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba65417f-54e0-436e-b0d4-93cffb981ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(metric_results)\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7ba747-00d5-4908-8d0b-334ae9d2c791",
   "metadata": {},
   "source": [
    "#### eval trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cf9366-d9cd-4c9d-951a-99a50877a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c82396a-7822-41fb-830f-1f6eb9c9b213",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_agent = agent.policy\n",
    "deployment_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6706224-ef5b-4185-bde4-bccb7c8e7ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(deployment_agent, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = _run_bandit_eval(\n",
    "    policy = post_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f899120f-3706-4b72-8f2c-2169221dd66b",
   "metadata": {},
   "source": [
    "## Using Trained Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b0f691-860e-4853-928e-4c7ece714dd0",
   "metadata": {},
   "source": [
    "### load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ea029f73-0638-462a-8f00-54b05c54d69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230821-231500/artifacts\n"
     ]
    }
   ],
   "source": [
    "POLICY_URI = ARTIFACTS_DIR\n",
    "\n",
    "print(POLICY_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "66d1d819-0152-437c-aefc-45ffd34d808a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230821-231500/artifacts/\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230821-231500/artifacts/fingerprint.pb\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230821-231500/artifacts/policy_specs.pbtxt\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230821-231500/artifacts/saved_model.pb\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230821-231500/artifacts/assets/\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230821-231500/artifacts/variables/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $POLICY_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6aad948e-e346-4da3-8cb2-747435c8dc4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f850f64bd30>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "483f8fa5-cbd1-4e3c-8e62-47f91f42e137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(), dtype=dtype('int32'), name='action_spec', minimum=0, maximum=1)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_policy.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8f658891-bc09-49b8-bc58-000a7926df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "for x in eval_ds.take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    global_feat_infer = _get_global_context_features(x)\n",
    "    arm_feat_infer = _get_per_arm_features(x)\n",
    "    rewards = _get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f515fcd0-2228-4f68-9ef9-665ce1fc3fb2",
   "metadata": {},
   "source": [
    "### view prediction response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6af4c297-d2e8-4f7b-bed5-e1da997dfe34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.400942, 3.400942], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=array([ 1.5639726e-02, -3.1821765e-02, -7.5147375e-03, -1.2750387e-02,\n",
       "        4.9963664e-02, -3.3286057e-02,  2.0584855e-02,  4.2843375e-02,\n",
       "        4.7787178e-02,  4.5679066e-02,  3.7793424e-02, -2.6883258e-02,\n",
       "       -3.4554709e-02, -4.9798973e-03,  6.9301240e-03,  1.8555392e-02,\n",
       "       -4.2709459e-02, -3.8219713e-02,  4.1822616e-02,  4.2918887e-02,\n",
       "       -2.9764270e-02, -4.5768548e-02,  2.8009426e-02, -4.6644323e-03,\n",
       "        4.1721944e-02,  3.5448086e-02,  4.0199231e-02,  3.8426746e-02,\n",
       "       -7.5555667e-03, -2.7164925e-02, -2.0989180e-03, -4.8757769e-02,\n",
       "        4.6904575e-02,  9.7514614e-03,  3.5535041e-02, -4.1110791e-02,\n",
       "        1.9986000e-02, -4.6567429e-02, -3.9937124e-03,  1.7358091e-02,\n",
       "        2.0064380e-02,  9.3392134e-03,  2.6355390e-02,  1.0356307e-06,\n",
       "       -1.2009192e-02,  4.8365481e-03, -2.0704998e-02, -1.3790272e-02,\n",
       "        2.6953842e-02, -2.2737980e-03, -4.9168088e-02, -2.4595488e-02,\n",
       "       -3.4203127e-02,  2.5342479e-03, -4.6184253e-02,  2.0559881e-02,\n",
       "       -1.5466165e-02,  5.7197586e-03, -1.0502957e-02,  1.3825621e-02,\n",
       "        1.7151382e-02, -9.0616718e-03,  4.9930923e-03, -3.3612061e-02],\n",
       "      dtype=float32)))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd58d4b-6749-4177-8342-83ee969408c9",
   "metadata": {},
   "source": [
    "#### chosen action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d49adbbb-f747-4e4c-b82d-df88373c644f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0, dtype=int32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd12013-1d12-4197-8254-cef9138df42c",
   "metadata": {},
   "source": [
    "#### Per Arm Policy Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d6126290-546b-4702-8a1e-91f18adb05c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.400942, 3.400942], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=array([ 1.5639726e-02, -3.1821765e-02, -7.5147375e-03, -1.2750387e-02,\n",
       "        4.9963664e-02, -3.3286057e-02,  2.0584855e-02,  4.2843375e-02,\n",
       "        4.7787178e-02,  4.5679066e-02,  3.7793424e-02, -2.6883258e-02,\n",
       "       -3.4554709e-02, -4.9798973e-03,  6.9301240e-03,  1.8555392e-02,\n",
       "       -4.2709459e-02, -3.8219713e-02,  4.1822616e-02,  4.2918887e-02,\n",
       "       -2.9764270e-02, -4.5768548e-02,  2.8009426e-02, -4.6644323e-03,\n",
       "        4.1721944e-02,  3.5448086e-02,  4.0199231e-02,  3.8426746e-02,\n",
       "       -7.5555667e-03, -2.7164925e-02, -2.0989180e-03, -4.8757769e-02,\n",
       "        4.6904575e-02,  9.7514614e-03,  3.5535041e-02, -4.1110791e-02,\n",
       "        1.9986000e-02, -4.6567429e-02, -3.9937124e-03,  1.7358091e-02,\n",
       "        2.0064380e-02,  9.3392134e-03,  2.6355390e-02,  1.0356307e-06,\n",
       "       -1.2009192e-02,  4.8365481e-03, -2.0704998e-02, -1.3790272e-02,\n",
       "        2.6953842e-02, -2.2737980e-03, -4.9168088e-02, -2.4595488e-02,\n",
       "       -3.4203127e-02,  2.5342479e-03, -4.6184253e-02,  2.0559881e-02,\n",
       "       -1.5466165e-02,  5.7197586e-03, -1.0502957e-02,  1.3825621e-02,\n",
       "        1.7151382e-02, -9.0616718e-03,  4.9930923e-03, -3.3612061e-02],\n",
       "      dtype=float32))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f66961-ebb5-4ae5-8e6f-ad73114d8353",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
