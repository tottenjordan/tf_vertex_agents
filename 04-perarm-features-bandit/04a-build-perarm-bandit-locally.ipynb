{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385307d6-2058-47ec-8da0-57f7ef5c43d6",
   "metadata": {},
   "source": [
    "# Train Bandits with per-arm features\n",
    "\n",
    "**Exploring linear and nonlinear** (e.g., those with neural network-based value functions) bandit methods for recommendations using TF-Agents\n",
    "\n",
    "> Neural linear bandits provide a nice way to leverage the representation power of deep learning and the bandit approach for uncertainty measure and efficient exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fd257-b98b-426a-a2cd-024429b014f1",
   "metadata": {},
   "source": [
    "## Load notebook config\n",
    "\n",
    "* use the prefix defined in `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f39c9d08-d118-4013-a47f-88450f49f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = 'mabv1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908f6b95-b539-4a9f-a836-840d26ea3b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"mabv1\"\n",
      "VERSION                  = \"v1\"\n",
      "\n",
      "BUCKET_NAME              = \"mabv1-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://mabv1-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://mabv1-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_ID      = \"hybrid-vertex.movielens_dataset_mabv1\"\n",
      "BIGQUERY_TABLE_ID        = \"hybrid-vertex.movielens_dataset_mabv1.training_dataset\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-mabv1\"\n",
      "IMAGE_NAME               = \"train-perarm-feats-v1\"\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-mabv1/train-perarm-feats-v1\"\n",
      "DOCKERNAME               = \"Dockerfile_perarm_feats\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c690a9-e2bd-4759-ba41-4e2469098aee",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4d0dfe4-695c-4dd4-9f24-67f7488ce1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c669f1a1-1af7-4efb-ab2d-6bf3b3847991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from collections import defaultdict\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pickle as pkl\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "# from tf_agents.agents import TFAgent\n",
    "\n",
    "# from tf_agents.bandits.environments import stationary_stochastic_per_arm_py_environment as p_a_env\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "# from tf_agents.drivers import dynamic_step_driver\n",
    "# from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "# from tf_agents.bandits.agents import lin_ucb_agent\n",
    "# from tf_agents.bandits.agents import linear_thompson_sampling_agent as lin_ts_agent\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent\n",
    "from tf_agents.bandits.agents import neural_linucb_agent\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "from tf_agents.bandits.policies import policy_utilities\n",
    "\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# this repo\n",
    "from src.per_arm_rl import data_utils\n",
    "from src.per_arm_rl import data_config\n",
    "from src.per_arm_rl import train_utils as train_utils\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29e58dd7-ab2b-419f-9771-bf1e98db758b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for gpu in gpus:\n",
    "#     tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \n",
    "# gpus\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4969d3e-1fc0-45db-8a69-aa6b342019de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "274e7f4a-1802-4946-888e-876638f5c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a866b1-85b9-43e6-9546-edfbbf886bce",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd5b953-14c0-42ed-a511-77147a1bc0ac",
   "metadata": {},
   "source": [
    "### Read TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d0157c8-a04c-4dbd-b6d9-a1ede97687a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da0cdac-76af-4608-b70e-be7dbe0584b5",
   "metadata": {},
   "source": [
    "**Train data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c934c06-bf08-4c7f-b0cc-0de04ef3515c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://mabv1-hybrid-vertex-bucket/data/train/ml-ratings-100k-train.tfrecord']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPLIT = \"train\" # \"train\" | \"val\"\n",
    "\n",
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7511e4d-bf81-4800-bde7-8b16dec9aeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([35.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'898'], dtype=object)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([885409515])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'681'], dtype=object)>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'marketing'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "train_dataset = train_dataset.map(data_utils.parse_tfrecord)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452750c1-46a0-4ee1-84d4-0c3b227de38f",
   "metadata": {},
   "source": [
    "**Val data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7b5376f-9438-4304-84aa-de09c30f5e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = \"val\"\n",
    "\n",
    "val_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        val_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "val_dataset = tf.data.TFRecordDataset(val_files)\n",
    "val_dataset = val_dataset.map(data_utils.parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8959967-522e-41c8-9a1b-050ca8bc191f",
   "metadata": {},
   "source": [
    "### get vocab\n",
    "\n",
    "**TODO:** \n",
    "* streamline vocab calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b9169bc-d6dc-497e-9dff-6ebb175282ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE_VOCABS: False\n"
     ]
    }
   ],
   "source": [
    "GENERATE_VOCABS = False\n",
    "print(f\"GENERATE_VOCABS: {GENERATE_VOCABS}\")\n",
    "\n",
    "# VOCAB_SUBDIR   = \"vocabs\"\n",
    "# VOCAB_FILENAME = \"vocab_dict.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3ccf137-7a72-42e7-aa89-3c81a99cf40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab...\n",
      "Downloaded vocab from: gs://mabv1-hybrid-vertex-bucket/vocabs/vocab_dict.pkl\n",
      "\n",
      "'movie_id'\n",
      "'user_id'\n",
      "'user_occupation_text'\n",
      "'movie_genres'\n",
      "'bucketized_user_age'\n",
      "'max_timestamp'\n",
      "'min_timestamp'\n",
      "'timestamp_buckets'\n"
     ]
    }
   ],
   "source": [
    "if not GENERATE_VOCABS:\n",
    "\n",
    "    EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{VOCAB_SUBDIR}/{VOCAB_FILENAME}'\n",
    "    print(f\"Downloading vocab...\")\n",
    "    \n",
    "    os.system(f'gsutil -q cp {EXISTING_VOCAB_FILE} .')\n",
    "    print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "    filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "    vocab_dict = pkl.load(filehandler)\n",
    "    filehandler.close()\n",
    "    \n",
    "    for key in vocab_dict.keys():\n",
    "        pprint(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "57c40c77-4889-46ef-af5e-9a25c94a7f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vocab_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccaef62-882a-46ff-a1b1-3837e69fdf74",
   "metadata": {},
   "source": [
    "## helper functions\n",
    "\n",
    "**TODO:**\n",
    "* modularize in a train_utils or similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b941063b-ad48-4817-aef0-9afa8a444632",
   "metadata": {},
   "source": [
    "# Multi-Armed Bandits (MAB) with Per-Arm Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28770b8d-836b-448d-8dd1-203d76fc6d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "\n",
    "nest = tf.nest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138a295-2b0d-4359-8496-af8552ec8cff",
   "metadata": {},
   "source": [
    "# [1] Preprocessing layers for global and arm features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e28c002-8d3a-4cf4-b69b-de56a6abab90",
   "metadata": {},
   "source": [
    "The preproccesing layers will ultimately feed the two sampling functions described below. These sampling functions will be used to create [trajectories](https://github.com/tensorflow/agents/blob/master/tf_agents/trajectories/trajectory.py#L36) (i.e., the training examples for our model)\n",
    "\n",
    "`global_context_sampling_fn`: \n",
    "* A function that outputs a random 1d array or list of ints or floats\n",
    "* This output is the global context. Its shape and type must be consistent across calls.\n",
    "\n",
    "`arm_context_sampling_fn`: \n",
    "* A function that outputs a random 1 array or list of ints or floats (same type as the output of `global_context_sampling_fn`). * This output is the per-arm context. Its shape must be consistent across calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8d77956-635c-438a-916a-185eec52f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OOV_BUCKETS        = 1\n",
    "GLOBAL_EMBEDDING_SIZE  = 16\n",
    "MV_EMBEDDING_SIZE      = 32 #32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6142e63e-0a20-4d51-997c-7a4733517f7e",
   "metadata": {},
   "source": [
    "## global context (user) features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195acd92-06b6-42e4-bef7-798fd09da856",
   "metadata": {},
   "source": [
    "#### user ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c28e887b-421a-4603-8899-87071056783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_input_layer = tf.keras.Input(\n",
    "    name=\"user_id\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.string\n",
    ")\n",
    "\n",
    "user_id_lookup = tf.keras.layers.StringLookup(\n",
    "    max_tokens=len(vocab_dict['user_id']) + NUM_OOV_BUCKETS,\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    mask_token=None,\n",
    "    vocabulary=vocab_dict['user_id'],\n",
    ")(user_id_input_layer)\n",
    "\n",
    "user_id_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['user_id']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=GLOBAL_EMBEDDING_SIZE\n",
    ")(user_id_lookup)\n",
    "\n",
    "user_id_embedding = tf.reduce_sum(user_id_embedding, axis=-2)\n",
    "\n",
    "# global_inputs.append(user_id_input_layer)\n",
    "# global_features.append(user_id_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d6a0fe7-26cb-4c62-a3ef-17f98e6ccddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_id_model = tf.keras.Model(inputs=user_id_input_layer, outputs=user_id_embedding)\n",
    "\n",
    "# for x in train_dataset.batch(1).take(1):\n",
    "#     print(x[\"user_id\"])\n",
    "#     print(test_user_id_model(x[\"user_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352d2227-92ec-4386-926f-df2fdb9434ec",
   "metadata": {},
   "source": [
    "#### user AGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70785bf0-5ece-4875-ab72-06d9c45ea9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_age_input_layer = tf.keras.Input(\n",
    "    name=\"bucketized_user_age\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "user_age_lookup = tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=vocab_dict['bucketized_user_age'],\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    oov_value=0,\n",
    ")(user_age_input_layer)\n",
    "\n",
    "user_age_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['bucketized_user_age']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=GLOBAL_EMBEDDING_SIZE\n",
    ")(user_age_lookup)\n",
    "\n",
    "user_age_embedding = tf.reduce_sum(user_age_embedding, axis=-2)\n",
    "\n",
    "# global_inputs.append(user_age_input_layer)\n",
    "# global_features.append(user_age_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e01622a-9418-4ca7-8925-9b0ebef8940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_age_model = tf.keras.Model(inputs=user_age_input_layer, outputs=user_age_embedding)\n",
    "\n",
    "# for x in train_dataset.batch(1).take(1):\n",
    "#     print(x[\"bucketized_user_age\"])\n",
    "#     print(test_user_age_model(x[\"bucketized_user_age\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997ffaa8-ca92-4851-b7e3-bb06fba8958b",
   "metadata": {},
   "source": [
    "#### user OCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03e7344d-71fb-423a-89dd-f1abeb270e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_occ_input_layer = tf.keras.Input(\n",
    "    name=\"user_occupation_text\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.string\n",
    ")\n",
    "\n",
    "user_occ_lookup = tf.keras.layers.StringLookup(\n",
    "    max_tokens=len(vocab_dict['user_occupation_text']) + NUM_OOV_BUCKETS,\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    mask_token=None,\n",
    "    vocabulary=vocab_dict['user_occupation_text'],\n",
    ")(user_occ_input_layer)\n",
    "\n",
    "user_occ_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['user_occupation_text']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=GLOBAL_EMBEDDING_SIZE\n",
    ")(user_occ_lookup)\n",
    "\n",
    "user_occ_embedding = tf.reduce_sum(user_occ_embedding, axis=-2)\n",
    "\n",
    "# global_inputs.append(user_occ_input_layer)\n",
    "# global_features.append(user_occ_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39cbbc31-ca43-4f8f-a804-a4b830e99d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_occ_model = tf.keras.Model(inputs=user_occ_input_layer, outputs=user_occ_embedding)\n",
    "\n",
    "# for x in train_dataset.batch(1).take(1):\n",
    "#     print(x[\"user_occupation_text\"])\n",
    "#     print(test_user_occ_model(x[\"user_occupation_text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee0098-a48a-4de6-88bf-6219ce8c0533",
   "metadata": {},
   "source": [
    "#### user Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "61a4e01a-e742-4c68-93a9-aa66eb9a5e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ts_input_layer = tf.keras.Input(\n",
    "    name=\"timestamp\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.int64\n",
    ")\n",
    "\n",
    "user_ts_lookup = tf.keras.layers.Discretization(\n",
    "    vocab_dict['timestamp_buckets'].tolist()\n",
    ")(user_ts_input_layer)\n",
    "\n",
    "user_ts_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['timestamp_buckets'].tolist()) + NUM_OOV_BUCKETS,\n",
    "    output_dim=GLOBAL_EMBEDDING_SIZE\n",
    ")(user_ts_lookup)\n",
    "\n",
    "user_ts_embedding = tf.reduce_sum(user_ts_embedding, axis=-2)\n",
    "\n",
    "# global_inputs.append(user_ts_input_layer)\n",
    "# global_features.append(user_ts_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db99f90b-57f8-45e6-9f28-871658e17358",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_ts_model = tf.keras.Model(inputs=user_ts_input_layer, outputs=user_ts_embedding)\n",
    "\n",
    "# for x in train_dataset.batch(1).take(1):\n",
    "#     print(x[\"timestamp\"])\n",
    "#     print(test_user_ts_model(x[\"timestamp\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc734ea-cb5e-4c6b-8b94-2a8853220178",
   "metadata": {},
   "source": [
    "### define global sampling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff58c380-8b53-4dfa-b5b4-d36853638ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_global_context_features(x):\n",
    "    \"\"\"\n",
    "    This function generates a single global observation vector.\n",
    "    \"\"\"\n",
    "    user_id_value = x['user_id']\n",
    "    user_age_value = x['bucketized_user_age']\n",
    "    user_occ_value = x['user_occupation_text']\n",
    "    user_ts_value = x['timestamp']\n",
    "\n",
    "    _id = test_user_id_model(user_id_value) # input_tensor=tf.Tensor(shape=(4,), dtype=float32)\n",
    "    _age = test_user_age_model(user_age_value)\n",
    "    _occ = test_user_occ_model(user_occ_value)\n",
    "    _ts = test_user_ts_model(user_ts_value)\n",
    "\n",
    "    # # tmp - insepct numpy() values\n",
    "    # print(_id.numpy()) #[0])\n",
    "    # print(_age.numpy()) #[0])\n",
    "    # print(_occ.numpy()) #[0])\n",
    "    # print(_ts.numpy()) #[0])\n",
    "\n",
    "    # to numpy array\n",
    "    _id = np.array(_id.numpy())\n",
    "    _age = np.array(_age.numpy())\n",
    "    _occ = np.array(_occ.numpy())\n",
    "    _ts = np.array(_ts.numpy())\n",
    "\n",
    "    concat = np.concatenate(\n",
    "        [_id, _age, _occ, _ts], axis=-1 # -1\n",
    "    ).astype(np.float32)\n",
    "\n",
    "    return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bba133ab-bf12-4b3b-926d-6d1dba940837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([35.], dtype=float32)>,\n",
       " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
       " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'898'], dtype=object)>,\n",
       " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([885409515])>,\n",
       " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'681'], dtype=object)>,\n",
       " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'marketing'], dtype=object)>,\n",
       " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    \n",
    "    iterator = iter(train_dataset.batch(1))\n",
    "    data = next(iterator)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c7cadad0-b5ac-461b-9efb-4867b52a8736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL_DIM: 64\n"
     ]
    }
   ],
   "source": [
    "GLOBAL_DIM = _get_global_context_features(data).shape[1]\n",
    "print(f\"GLOBAL_DIM: {GLOBAL_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249fa771-35d7-4d04-ab68-2b70911bac17",
   "metadata": {},
   "source": [
    "## arm preprocessing layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534b3bf1-a2ea-4bfb-8c77-efa057f4e391",
   "metadata": {},
   "source": [
    "#### movie ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa53cbe9-2616-4da4-90dc-dc5616258af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_id_input_layer = tf.keras.Input(\n",
    "    name=\"movie_id\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.string\n",
    ")\n",
    "\n",
    "mv_id_lookup = tf.keras.layers.StringLookup(\n",
    "    max_tokens=len(vocab_dict['movie_id']) + NUM_OOV_BUCKETS,\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    mask_token=None,\n",
    "    vocabulary=vocab_dict['movie_id'],\n",
    ")(mv_id_input_layer)\n",
    "\n",
    "mv_id_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['movie_id']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=MV_EMBEDDING_SIZE\n",
    ")(mv_id_lookup)\n",
    "\n",
    "mv_id_embedding = tf.reduce_sum(mv_id_embedding, axis=-2)\n",
    "\n",
    "# arm_inputs.append(mv_id_input_layer)\n",
    "# arm_features.append(mv_id_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9bd19f09-a12e-4a21-a1a1-5ec5bc116559",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mv_id_model = tf.keras.Model(inputs=mv_id_input_layer, outputs=mv_id_embedding)\n",
    "\n",
    "# for x in train_dataset.batch(1).take(1):\n",
    "#     print(x[\"movie_id\"])\n",
    "#     print(test_mv_id_model(x[\"movie_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4a0e97-c477-4042-b9c0-fcb0f428de0d",
   "metadata": {},
   "source": [
    "#### movie genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f04a0091-d7b0-4f90-ba7c-3eb41dd0b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_genre_input_layer = tf.keras.Input(\n",
    "    name=\"movie_genres\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "mv_genre_lookup = tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=vocab_dict['movie_genres'],\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    oov_value=0,\n",
    ")(mv_genre_input_layer)\n",
    "\n",
    "mv_genre_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['movie_genres']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=MV_EMBEDDING_SIZE\n",
    ")(mv_genre_lookup)\n",
    "\n",
    "mv_genre_embedding = tf.reduce_sum(mv_genre_embedding, axis=-2)\n",
    "\n",
    "# arm_inputs.append(mv_genre_input_layer)\n",
    "# arm_features.append(mv_genre_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "51701f0a-9b3e-461c-a9d9-a0c146e310ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mv_gen_model = tf.keras.Model(inputs=mv_genre_input_layer, outputs=mv_genre_embedding)\n",
    "\n",
    "# for x in train_dataset.batch(1).take(1):\n",
    "#     print(x[\"movie_genres\"])\n",
    "#     print(test_mv_gen_model(x[\"movie_genres\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b41cc9-63f5-4559-a943-1288be9c0892",
   "metadata": {},
   "source": [
    "### define sampling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8727904e-e9b6-4005-8cf3-9da461ca88b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_per_arm_features(x):\n",
    "    \"\"\"\n",
    "    This function generates a single per-arm observation vector\n",
    "    \"\"\"\n",
    "    mv_id_value = x['movie_id']\n",
    "    mv_gen_value = x['movie_genres']\n",
    "\n",
    "    _mid = test_mv_id_model(mv_id_value)\n",
    "    _mgen = test_mv_gen_model(mv_gen_value)\n",
    "\n",
    "    # to numpy array\n",
    "    _mid = np.array(_mid.numpy())\n",
    "    _mgen = np.array(_mgen.numpy())\n",
    "\n",
    "    # print(_mid)\n",
    "    # print(_mgen)\n",
    "\n",
    "    concat = np.concatenate(\n",
    "        [_mid, _mgen], axis=-1 # -1\n",
    "    ).astype(np.float32)\n",
    "    # concat = tf.concat([_mid, _mgen], axis=-1).astype(np.float32)\n",
    "\n",
    "    return concat #this is special to this example - there is only one action dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f2f5ba55-2e1a-4b32-b6a8-4f46ba4c2048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER_ARM_DIM: 64\n"
     ]
    }
   ],
   "source": [
    "PER_ARM_DIM = _get_per_arm_features(data).shape[1] #shape checks out at batchdim, nactions, arm feats\n",
    "print(f\"PER_ARM_DIM: {PER_ARM_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ea1f7-0621-44b8-b062-1f59b0964d72",
   "metadata": {},
   "source": [
    "#### tmp - debugging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "48178fff-491f-4f03-b156-7765d1fa9707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.perarm_features.emb_features_v1.EmbeddingModel at 0x7f68ba0c7b50>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from src.perarm_features.agent_factory import PerArmAgentFactory\n",
    "from src.perarm_features import emb_features_v1 as emb_features\n",
    "\n",
    "\n",
    "embs = emb_features.EmbeddingModel(\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "903c63c5-2468-4443-bcb8-5ff6d69810dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04098747, -0.0233472 , -0.03260759, ..., -0.0200816 ,\n",
       "         0.03618945,  0.01389972],\n",
       "       [-0.03361136, -0.00227935,  0.00994014, ...,  0.0295998 ,\n",
       "        -0.04396255,  0.00136508],\n",
       "       [ 0.01763401, -0.03281714, -0.01517392, ..., -0.04467361,\n",
       "        -0.02568197, -0.00740166],\n",
       "       ...,\n",
       "       [ 0.0303948 ,  0.0382851 ,  0.00141155, ...,  0.00028037,\n",
       "        -0.04007195,  0.03424711],\n",
       "       [-0.01990361, -0.01171758, -0.03378993, ...,  0.03167704,\n",
       "         0.04954029,  0.00134794],\n",
       "       [-0.02433637, -0.03956107, -0.01572413, ..., -0.01298159,\n",
       "        -0.02621454, -0.01065227]], dtype=float32)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_globals = embs._get_global_context_features(data)\n",
    "test_globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e776d7af-d8b4-4423-a756-9b380f4b1207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 64)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_globals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ebec4863-c614-4248-b680-8e29ec5b730d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00687509,  0.03537364, -0.00918353, ...,  0.03358675,\n",
       "         0.00576318,  0.02324751],\n",
       "       [-0.00142039, -0.02175533, -0.01458568, ..., -0.00894155,\n",
       "        -0.03189106,  0.0224187 ],\n",
       "       [-0.02293432, -0.04077004,  0.03563522, ..., -0.00894155,\n",
       "        -0.03189106,  0.0224187 ],\n",
       "       ...,\n",
       "       [-0.04664748,  0.02115352,  0.03233257, ..., -0.0030599 ,\n",
       "        -0.04350985, -0.00136615],\n",
       "       [-0.03309958, -0.00851983, -0.02025163, ..., -0.0030599 ,\n",
       "        -0.04350985, -0.00136615],\n",
       "       [-0.04664748,  0.02115352,  0.03233257, ..., -0.0030599 ,\n",
       "        -0.04350985, -0.00136615]], dtype=float32)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arms = embs._get_per_arm_features(data)\n",
    "test_arms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2f4b73b0-0eca-484e-a498-9daa32a6b08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 64)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arms.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac6836c-67b7-4fd4-917a-24ddad708edd",
   "metadata": {},
   "source": [
    "# [2] Implementing MAB with TF-Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1877c79c-b6c8-4048-b1ce-05f011e8d69e",
   "metadata": {},
   "source": [
    "In TF-Agents, the *per-arm features* implementation differs from the *global-only* feature examples in the following aspects:\n",
    "* Reward is modeled not per-arm, but globally.\n",
    "* The arms are permutation invariant: it doesn’t matter which arm is arm 1 or arm 2, only their features.\n",
    "* One can have a different number of arms to choose from in every step (note that unspecified/dynamically changing number of arms will have a problem with XLA compatibility).\n",
    "\n",
    "When implementing per-arm features in TF-Bandits, the following details have to be discussed:\n",
    "* Observation spec and observations,\n",
    "* Action spec and actions,\n",
    "* Implementation of specific policies and agents.\n",
    "\n",
    "\n",
    "**TODO:**\n",
    "* outline the components and highlight their interactions, dependencies on eachother, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7ff9baaf-987d-448d-a981-742a79b581e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE      : 128\n",
      "EVAL_BATCH_SIZE : 1\n",
      "NUM_ACTIONS     : 2\n",
      "GLOBAL_DIM      : 64\n",
      "PER_ARM_DIM     : 64\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE      = 128\n",
    "EVAL_BATCH_SIZE = 1\n",
    "\n",
    "NUM_ACTIONS     = 2 #this is kinda deceptive - \n",
    "#our approach is to learn by \"flashing\" one movie rating at a time per user context. \n",
    "#The n_actions = show/don't show the movie with one degree of freedom (n-1)\n",
    "\n",
    "\n",
    "print(f\"BATCH_SIZE      : {BATCH_SIZE}\")\n",
    "print(f\"EVAL_BATCH_SIZE : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"NUM_ACTIONS     : {NUM_ACTIONS}\")\n",
    "print(f\"GLOBAL_DIM      : {GLOBAL_DIM}\")\n",
    "print(f\"PER_ARM_DIM     : {PER_ARM_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeb4902-5bb9-4587-8d29-c01d78b006be",
   "metadata": {},
   "source": [
    "## Tensor Specs\n",
    "\n",
    "* say you have a global observation spec of `[17]`. And you have two batch dimensions `[4, 5]`. Then your observation has to have the shape `[4, 5, 17]`\n",
    "* and then if you have arm_obs_spec with shape `[9, 13]`, then the arm obs shape has to be exactly `[4, 5, 9, 13]`\n",
    "* and this has to be true for every single tensor in your tensor nest\n",
    "* the first 2 dims are the outer dims that are the same for all tensors, the rest of the dimensions have to follow the spec for each tensor\n",
    "\n",
    "**TODO:**\n",
    "* explain relationship between Tensor Specs and their Tensor counterparts\n",
    "* highlight the errors, lessons learned, and utility functions to address these"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f68ebe8-116d-43b3-a6e1-4f5a5c7f4741",
   "metadata": {},
   "source": [
    "### Observation spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9c4746-d01b-4ca4-aa53-ab68da54d37a",
   "metadata": {},
   "source": [
    "**This observation spec allows the user to have a global observation of fixed dimension**, and an unspecified number of *per-arm* features (also of fixed dimension)\n",
    "* The actions output by the policy are still integers as usual, and they indicate which row of the arm-features it has chosen \n",
    "* The action spec must be a single integer value without boundaries:\n",
    "\n",
    "```python\n",
    "global_spec = tensor_spec.TensorSpec([GLOBAL_DIM], tf.float32)\n",
    "per_arm_spec = tensor_spec.TensorSpec([None, PER_ARM_DIM], tf.float32)\n",
    "observation_spec = {'global': global_spec, 'per_arm': per_arm_spec}\n",
    "\n",
    "action_spec = tensor_spec.TensorSpec((), tf.int32)\n",
    "```\n",
    "> Here the only difference compared to the action spec with global features only is that the tensor spec is not bounded, as we don’t know how many arms there will be at any time step\n",
    "\n",
    "**XLA compatibility:**\n",
    "* Since dynamic tensor shapes are not compatible with XLA, the number of arm features (and consequently, number of arms for a step) cannot be dynamic. \n",
    "* One workaround is to fix the maximum number of arms for a problem, then pad the arm features in steps with fewer arms, and use action masking to indicate how many arms are actually active.\n",
    "\n",
    "```python\n",
    "per_arm_spec = tensor_spec.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32)\n",
    "\n",
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=(), dtype=tf.int32, minimum = 0, maximum = NUM_ACTIONS - 1\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "36bd3b33-635a-4274-8b9e-7172696ebb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # TF-Agents has many helper and utility functions\n",
    "# observation_spec = bandit_spec_utils.create_per_arm_observation_spec(\n",
    "#     GLOBAL_DIM, PER_ARM_DIM, NUM_ACTIONS, \n",
    "#     add_num_actions_feature=False\n",
    "# ) # 2,3,4\n",
    "\n",
    "observation_spec = {\n",
    "    'global': tf.TensorSpec([GLOBAL_DIM], tf.float32),\n",
    "    'per_arm': tf.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32) #excluding action dim here\n",
    "}\n",
    "observation_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a2da92-7db2-4f42-94a7-b7bad1c8fc42",
   "metadata": {},
   "source": [
    "### Action spec\n",
    "\n",
    "> The time_step_spec and action_spec are specifications for the input time step and the output action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5af42c7-18d7-480f-a7f3-d7da3f4840eb",
   "metadata": {},
   "source": [
    "```python\n",
    "    if (\n",
    "        not tensor_spec.is_bounded(action_spec)\n",
    "        or not tensor_spec.is_discrete(action_spec)\n",
    "        or action_spec.shape.rank > 1\n",
    "        or action_spec.shape.num_elements() != 1\n",
    "    ):\n",
    "      raise NotImplementedError(\n",
    "          'action_spec must be a BoundedTensorSpec of type int32 and shape (). '\n",
    "          'Found {}.'.format(action_spec)\n",
    "      )\n",
    "```\n",
    "\n",
    "* [src](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_base_policy.py#L97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "549a123c-349a-4103-b39a-4502f47d1e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=[], \n",
    "    dtype=tf.int32,\n",
    "    minimum=tf.constant(0),            \n",
    "    maximum=NUM_ACTIONS-1, # n degrees of freedom and will dictate the expected mean reward spec shape\n",
    "    name=\"action_spec\"\n",
    ")\n",
    "\n",
    "action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "36ee2635-d4e3-4468-886c-ae9c62e3c80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_num_actions: 2\n",
      "predicted_rewards_mean: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n"
     ]
    }
   ],
   "source": [
    "expected_num_actions = action_spec.maximum - action_spec.minimum + 1\n",
    "print(f\"expected_num_actions: {expected_num_actions}\")\n",
    "\n",
    "predicted_rewards_mean = tensor_spec.TensorSpec([expected_num_actions])\n",
    "print(f\"predicted_rewards_mean: {predicted_rewards_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a51efce-9f1b-42d1-bec4-7b788e3fd7e0",
   "metadata": {},
   "source": [
    "### TimeStep spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "95f05860-0fbf-4a5a-8273-9c81761e0ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec = ts.time_step_spec(\n",
    "    observation_spec = observation_spec, \n",
    "    # reward_spec = _reward_spec\n",
    ")\n",
    "time_step_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9181303-6565-45f5-a293-08d50420a805",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Inspect chosen arm features spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d6b526a5-997c-4621-b21c-82c6ca1d6a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "90d3e03e-619e-4fa4-b817-f02b4cefd6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(64,), dtype=tf.float32, name=None)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_arm_features_info = (\n",
    "  policy_utilities.create_chosen_arm_features_info_spec(\n",
    "      time_step_spec.observation,\n",
    "  )\n",
    ")\n",
    "chosen_arm_features_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dc427092-beb7-4baf-a2e9-b8d10629182c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - dont understand this\n",
    "bandit_policy_type = (\n",
    "    policy_utilities.BanditPolicyType.GREEDY\n",
    ")\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0a4a2a33-c7d4-4d81-8082-80dfc3596741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - dont understand this\n",
    "bandit_policy_type = (\n",
    "    policy_utilities.create_bandit_policy_type_tensor_spec(shape=[1])\n",
    ")\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6e7ac02b-18bd-4519-92fe-5541b1a8ddc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_spec = policy_utilities.PerArmPolicyInfo(\n",
    "  predicted_rewards_mean=predicted_rewards_mean,\n",
    "  bandit_policy_type=bandit_policy_type,\n",
    "  chosen_arm_features=chosen_arm_features_info,\n",
    ")\n",
    "info_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9c197-ae9b-461d-8956-f078b929ac12",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The Agent\n",
    "\n",
    "**Note** that contextual bandits form a special case of RL, where the actions taken by the agent do not alter the state of the environment \n",
    "\n",
    "> “Contextual” refers to the fact that the agent chooses among a set of actions while having knowledge of the context (environment observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81d6e84-688e-48c5-aea1-77df031348c9",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Agent & Network defined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aadb01-eb5c-4870-ae14-9e66624ba594",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **Agent types**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d075e8a6-11a9-4346-8725-3653fba4bac4",
   "metadata": {},
   "source": [
    "> `AGENT_TYPE = ['LinUCB', 'LinTS', 'epsGreedy', 'NeuralLinUCB']`\n",
    "\n",
    "LinearUCBAgent: (`LinUCB`) \n",
    "* An agent implementing the Linear UCB bandit algorithm ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/lin_ucb_agent/LinearUCBAgent))\n",
    "\n",
    "LinearThompsonSamplingAgent: (`LinTS`) \n",
    "* Implements the Linear Thompson Sampling Agent from the [paper](https://arxiv.org/abs/1209.3352): *Thompson Sampling for Contextual Bandits with Linear Payoffs* ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/linear_thompson_sampling_agent/LinearThompsonSamplingAgent))\n",
    "\n",
    "NeuralEpsilonGreedyAgent: (`epsGreedy`) \n",
    "* A neural network based epsilon greedy agent ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_epsilon_greedy_agent/NeuralEpsilonGreedyAgent))\n",
    "\n",
    "NeuralLinUCBAgent: (`NeuralLinUCB`) \n",
    "* An agent implementing the LinUCB algorithm on top of a neural network ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_linucb_agent/NeuralLinUCBAgent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b8e88e-c8ea-4193-a911-0d974ef3b1a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Network types**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f547087d-5fad-4521-a584-cb46ce52897d",
   "metadata": {},
   "source": [
    "Which network architecture to use for the `epsGreedy` or `NeuralLinUCB` agents\n",
    "\n",
    "```\n",
    "NETWORK_TYPE = ['commontower', 'dotproduct']\n",
    "```\n",
    "\n",
    "**GlobalAndArmCommonTowerNetwork:** (`commontower`)\n",
    "* This network takes the output of the global and per-arm networks, and leads them through a common network, that in turn outputs reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "> * `COMMON_LAYERS` - Iterable of ints. Specifies the layers of the common tower\n",
    "* The network produced by this function can be used either in `GreedyRewardPredictionPolicy`, or `NeuralLinUCBPolicy`\n",
    "> * In the former case, the network must have `output_dim=1`, it is going to be an instance of `QNetwork`, and used in the policy as a reward prediction network\n",
    "> * In the latter case, the network will be an encoding network with its output consumed by a reward layer or a `LinUCB` method. The specified `output_dim` will be the encoding dimension\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmCommonTowerNetwork)\n",
    "\n",
    "**GlobalAndArmDotProductNetwork:** (`dotproduct`)\n",
    "* This network calculates the **dot product** of the output of the global and per-arm networks and returns them as reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmDotProductNetwork)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3dc270-deb5-4e96-8276-74759a06c318",
   "metadata": {},
   "source": [
    "### Agent config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bbe29263-453d-405e-ac50-fee7f379f335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\n",
      "\n",
      "time_step_spec:  TimeStep(\n",
      "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
      "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n",
      "\n",
      "action_spec:  BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))\n",
      "\n",
      "observation_spec:  {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\")\n",
    "print(\"\\ntime_step_spec: \", time_step_spec)\n",
    "print(\"\\naction_spec: \", action_spec)\n",
    "print(\"\\nobservation_spec: \", observation_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6d817bf2-1fa6-4bae-af90-745fad996b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'common_layers': [16, 8],\n",
      " 'epsilon': 0.01,\n",
      " 'eval_batch_size': 1,\n",
      " 'global_layers': [64, 32, 16],\n",
      " 'learning_rate': 0.05,\n",
      " 'model_type': 'epsGreedy',\n",
      " 'network_type': 'commontower',\n",
      " 'num_actions': 2,\n",
      " 'per_arm_layers': [64, 32, 16]}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Agents\n",
    "# ================================\n",
    "AGENT_TYPE      = 'epsGreedy' # 'LinUCB' | 'LinTS |, 'epsGreedy' | 'NeuralLinUCB'\n",
    "\n",
    "# Parameters for linear agents (LinUCB and LinTS).\n",
    "AGENT_ALPHA     = 0.1\n",
    "\n",
    "# Parameters for neural agents (NeuralEpsGreedy and NerualLinUCB).\n",
    "EPSILON         = 0.01\n",
    "LR              = 0.05\n",
    "\n",
    "# Parameters for NeuralLinUCB\n",
    "ENCODING_DIM    = 1\n",
    "EPS_PHASE_STEPS = 1000\n",
    "\n",
    "# ================================\n",
    "# Agent's Preprocess Network\n",
    "# ================================\n",
    "NETWORK_TYPE    = \"commontower\" # 'commontower' | 'dotproduct'\n",
    "\n",
    "if AGENT_TYPE == 'NeuralLinUCB':\n",
    "    NETWORK_TYPE = 'commontower'\n",
    "    \n",
    "GLOBAL_LAYERS   = [64, 32, 16]\n",
    "ARM_LAYERS      = [64, 32, 16]\n",
    "COMMON_LAYERS   = [16, 8]\n",
    "\n",
    "HPARAMS = {  # TODO - streamline and consolidate\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"eval_batch_size\" : EVAL_BATCH_SIZE,\n",
    "    \"num_actions\": NUM_ACTIONS,\n",
    "    \"model_type\": AGENT_TYPE,\n",
    "    \"network_type\": NETWORK_TYPE,\n",
    "    \"global_layers\": GLOBAL_LAYERS,\n",
    "    \"per_arm_layers\": ARM_LAYERS,\n",
    "    \"common_layers\": COMMON_LAYERS,\n",
    "    \"learning_rate\": LR,\n",
    "    \"epsilon\": EPSILON,\n",
    "}\n",
    "pprint(HPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2bf060bb-9880-40b4-8583-dd7a3f915bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: OffpolicyNeuralEpsGreedyAgent\n",
      "Network: global_and_arm_common_tower_network\n"
     ]
    }
   ],
   "source": [
    "# from src.perarm_features import agent_factory as agent_factory\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "agent, network = agent_factory._get_agent(\n",
    "    agent_type=AGENT_TYPE, \n",
    "    network_type=NETWORK_TYPE, \n",
    "    time_step_spec=time_step_spec, \n",
    "    action_spec=action_spec, \n",
    "    observation_spec=observation_spec,\n",
    "    global_step = global_step,\n",
    "    global_layers = GLOBAL_LAYERS,\n",
    "    arm_layers = ARM_LAYERS,\n",
    "    common_layers = COMMON_LAYERS,\n",
    "    agent_alpha = AGENT_ALPHA,\n",
    "    learning_rate = LR,\n",
    "    epsilon = EPSILON,\n",
    "    encoding_dim = ENCODING_DIM,\n",
    "    eps_phase_steps = EPS_PHASE_STEPS,\n",
    ")\n",
    "\n",
    "print(f\"Agent: {agent.name}\")\n",
    "\n",
    "if network:\n",
    "    print(f\"Network: {network}\")\n",
    "        \n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d77d1-a0b3-4898-adf0-0b32bfaf5bd7",
   "metadata": {},
   "source": [
    "#### tmp - debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "852503df-0dcf-4935-8d5e-d0d0798d3252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.append(\"..\")\n",
    "# from src.perarm_features import agent_factory as agent_factory\n",
    "# from src.perarm_features.agent_factory import PerArmAgentFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "bb6c9369-445e-4922-8c8a-4ca85d96e392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.bandits.agents.neural_epsilon_greedy_agent.NeuralEpsilonGreedyAgent at 0x7f68f538a3b0>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from src.perarm_features.agent_factory import PerArmAgentFactory\n",
    "from src.perarm_features import agent_factory_v7 as agent_factory\n",
    "\n",
    "# (agent_type = AGENT_TYPE)\n",
    "\n",
    "# agent_cls = agent_factory.PerArmAgentFactory(agent_type = AGENT_TYPE)\n",
    "# agent_cls\n",
    "\n",
    "agent_test = agent_factory.PerArmAgentFactory._get_agent(\n",
    "    agent_type = AGENT_TYPE,\n",
    "    network_type = NETWORK_TYPE,\n",
    "    time_step_spec = time_step_spec,\n",
    "    action_spec = action_spec,\n",
    "    observation_spec=observation_spec,\n",
    "    global_layers = GLOBAL_LAYERS,\n",
    "    arm_layers = ARM_LAYERS,\n",
    "    common_layers = COMMON_LAYERS,\n",
    "    agent_alpha = AGENT_ALPHA,\n",
    "    learning_rate = LR,\n",
    "    epsilon = EPSILON,\n",
    "    train_step_counter = global_step,\n",
    "    output_dim = ENCODING_DIM,\n",
    "    eps_phase_steps = EPS_PHASE_STEPS,\n",
    ")\n",
    "agent_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "78ca56e7-a386-4bf4-8c2b-3d1665521f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_test.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "41483f5a-bda6-48a4-9e1c-88d8b4afeea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_test.time_step_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2f205716-f265-4ca8-81a7-4799de8f60a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(Trajectory(\n",
       "{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32)),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None)}),\n",
       " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None)),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_test.training_data_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d404dae-3cc3-4f81-962b-4641455ca4f2",
   "metadata": {},
   "source": [
    "## Reward function\n",
    "\n",
    "**TODO:**\n",
    "* explain how to translate reward to this common recommendation objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "df9aecd6-d20a-48a7-9ead-4da3bbcfdae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_rewards(element):\n",
    "    \"\"\"Calculates reward for the actions.\"\"\"\n",
    "\n",
    "    def _calc_reward(x):\n",
    "        \"\"\"Calculates reward for a single action.\"\"\"\n",
    "        r0 = lambda: tf.constant(0.0)\n",
    "        r1 = lambda: tf.constant(1.0)\n",
    "        r2 = lambda: tf.constant(2.0)\n",
    "        r3 = lambda: tf.constant(3.0)\n",
    "        r4 = lambda: tf.constant(4.0)\n",
    "        r5 = lambda: tf.constant(5.0)\n",
    "        c1 = tf.equal(x, 1.0)\n",
    "        c2 = tf.equal(x, 2.0)\n",
    "        c3 = tf.equal(x, 3.0)\n",
    "        c4 = tf.equal(x, 4.0)\n",
    "        c5 = tf.equal(x, 5.0)\n",
    "        return tf.case(\n",
    "            [(c1, r1), (c2, r2), (c3, r3),(c4, r4),(c5, r5)], \n",
    "            default=r0, exclusive=True\n",
    "        )\n",
    "\n",
    "    return tf.map_fn(\n",
    "        fn=_calc_reward, \n",
    "        elems=element['user_rating'], \n",
    "        dtype=tf.float32\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac59703a-9a00-4eba-a3b7-45b21b738dd4",
   "metadata": {},
   "source": [
    "## Trajectory function\n",
    "\n",
    "**parking lot**\n",
    "* does trajectory fn need concept of `dummy_chosen_arm_features`, similar to [this](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_base_policy.py#L297)\n",
    "\n",
    "```python\n",
    "      dummy_chosen_arm_features = tf.nest.map_structure(\n",
    "          lambda obs: tf.zeros_like(obs[:, 0, ...]),\n",
    "          time_step.observation[bandit_spec_utils.PER_ARM_FEATURE_KEY],\n",
    "      )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3c16aa7b-f328-425e-b02e-a3fc7f200859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "# from tf_agents.trajectories import trajectory\n",
    "# from src.per_arm_rl import train_utils_v2 as train_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f3605d9f-d239-4871-9a61-6e9b21f9c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _trajectory_fn(element): # hparams\n",
    "    \n",
    "    \"\"\"Converts a dataset element into a trajectory.\"\"\"\n",
    "    global_features = _get_global_context_features(element)\n",
    "    arm_features = _get_per_arm_features(element)\n",
    "    \n",
    "    # Adds a time dimension.\n",
    "    arm_features = train_utils._add_outer_dimension(arm_features)\n",
    "\n",
    "    # obs spec\n",
    "    observation = {\n",
    "        bandit_spec_utils.GLOBAL_FEATURE_KEY:\n",
    "            train_utils._add_outer_dimension(global_features),\n",
    "    }\n",
    "\n",
    "    reward = train_utils._add_outer_dimension(_get_rewards(element))\n",
    "\n",
    "    # To emit the predicted rewards in policy_info, we need to create dummy\n",
    "    # rewards to match the definition in TensorSpec for the ones specified in\n",
    "    # emit_policy_info set.\n",
    "    dummy_rewards = tf.zeros([HPARAMS['batch_size'], 1, HPARAMS['num_actions']])\n",
    "    policy_info = policy_utilities.PerArmPolicyInfo(\n",
    "        chosen_arm_features=arm_features,\n",
    "        # Pass dummy mean rewards here to match the model_spec for emitting\n",
    "        # mean rewards in policy info\n",
    "        predicted_rewards_mean=dummy_rewards,\n",
    "        bandit_policy_type=policy_utilities.BanditPolicyType.GREEDY\n",
    "    )\n",
    "    \n",
    "    if HPARAMS['model_type'] == 'neural_ucb':\n",
    "        policy_info = policy_info._replace(\n",
    "            predicted_rewards_optimistic=dummy_rewards\n",
    "        )\n",
    "        \n",
    "    return trajectory.single_step(\n",
    "        observation=observation,\n",
    "        action=tf.zeros_like(\n",
    "            reward, dtype=tf.int32\n",
    "        ),  # Arm features are copied from policy info, put dummy zeros here\n",
    "        policy_info=policy_info,\n",
    "        reward=reward,\n",
    "        discount=tf.zeros_like(reward)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a0989c-5a06-4fd5-a12d-d92dbbe71a76",
   "metadata": {},
   "source": [
    "Inspect the trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "257791d1-c97c-48c0-bc92-f5a4737b6c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in train_dataset.batch(HPARAMS['batch_size']).take(1):\n",
    "    test_traj = _trajectory_fn(x)\n",
    "    \n",
    "# test_traj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d8994e-ce28-4fd9-8e3b-153451d014d9",
   "metadata": {},
   "source": [
    "#### tmp - debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8a0e451f-1ad8-4af2-84d6-ddc5eaac0e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.action.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.action.shape: {test_traj.action.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "52ed1767-12ce-404c-9caf-0974d55ec5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.discount.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.discount.shape: {test_traj.discount.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "033ff16b-0158-477f-835f-99deec636b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.reward.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.reward.shape: {test_traj.reward.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ee5aded7-7f9c-4a88-868c-f6ab58a0e704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.observation.shape: (128, 1, 64)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.observation.shape: {test_traj.observation['global'].shape}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cb47f4-03b7-424f-ae40-6d00390782b1",
   "metadata": {},
   "source": [
    "#### TODO: write trajectories to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0b9d6180-4b3f-49cc-92f9-b7bce48c329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAJECTORY_SUBDIR = \"trajectories\"\n",
    "# os.mkdir(f'{TRAJECTORY_SUBDIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "52cb38f2-6fcb-4de6-b70f-3d55a5785500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCAL_FILENAME = f\"trajectories_{HPARAMS['batch_size']}\"\n",
    "\n",
    "# print(LOCAL_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcbfc9a-049e-49b9-b2a3-ecb9fd4b9964",
   "metadata": {},
   "source": [
    "# [3] Training the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13adc1ef-b50e-41a3-9b95-c128d0c55a2b",
   "metadata": {},
   "source": [
    "## set Vertex Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e861fb27-df24-4821-8448-cf1346b186f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : mab-local-v6\n",
      "RUN_NAME          : run-20230823-141716\n",
      "\n",
      "BASE_OUTPUT_DIR   : gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230823-141716\n",
      "LOG_DIR           : gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230823-141716/logs\n",
      "ROOT_DIR          : gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230823-141716/root\n",
      "ARTIFACTS_DIR     : gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230823-141716/artifacts\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME   = f'mab-local-v6'\n",
    "\n",
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b7a5e4-efff-490b-b431-53037a2f4a16",
   "metadata": {},
   "source": [
    "## eval loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba0392e-90c8-4dc8-8df2-6d2af1ade490",
   "metadata": {},
   "source": [
    "> When evaluating an epsilon-greedy bandit, we need to remove those predictions that come from the `uniform_random` policy. We only want the predictions from the `GREEDY` policy, becasue we want to know how the model performs when it is actually used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "95b0c355-8976-479f-b61a-3e78fb147d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# eval loop\n",
    "# ====================================================\n",
    "\n",
    "def _run_bandit_eval(\n",
    "    policy,\n",
    "    data,\n",
    "    eval_batch_size,\n",
    "    per_arm_dim,\n",
    "    global_dim,\n",
    "):\n",
    "    logged_rewards = []\n",
    "    predicted_rewards = []\n",
    "    trouble_list = []\n",
    "    train_loss_results = []\n",
    "    \n",
    "    dummy_arm = tf.zeros([eval_batch_size, per_arm_dim], dtype=tf.float32)\n",
    "\n",
    "    for x in data:\n",
    "        # get feature tensors\n",
    "        global_feat_infer = _get_global_context_features(x)\n",
    "        arm_feat_infer = _get_per_arm_features(x)\n",
    "        rewards = _get_rewards(x)\n",
    "\n",
    "        # reshape arm features\n",
    "        arm_feat_infer = tf.reshape(arm_feat_infer, [eval_batch_size, per_arm_dim])\n",
    "        concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "\n",
    "        # flatten global\n",
    "        flat_global_infer = tf.reshape(global_feat_infer, [global_dim])\n",
    "        feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "\n",
    "        # get actual reward\n",
    "        actual_reward = rewards.numpy()[0]\n",
    "        # logged_rewards.append(actual_reward)\n",
    "\n",
    "        # build trajectory step\n",
    "        trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "        \n",
    "        # pred w/ trained agent\n",
    "        prediction = policy.action(trajectory_step)\n",
    "        # prediction = trained_policy.action(trajectory_step)\n",
    "        # prediction_list.append(prediction)\n",
    "\n",
    "        predicted_rewards_mean = prediction.info.predicted_rewards_mean #[0]\n",
    "        # pred_rewards_mean_list.append(predicted_rewards_mean)\n",
    "        \n",
    "        predicted_reward_tf = tf.gather(\n",
    "            predicted_rewards_mean,\n",
    "            prediction.action, \n",
    "            batch_dims=0, \n",
    "            axis=-1\n",
    "        )\n",
    "\n",
    "        pred_reward = float(round(predicted_reward_tf.numpy()))\n",
    "\n",
    "        # When the uniform random policy is used, the \n",
    "        #    loss is meaningless for evaluation\n",
    "        # > discard preds from uniform random policy\n",
    "        # > keep preds from greedy policy, \n",
    "        if pred_reward < 0:\n",
    "            trouble_list.append(pred_reward)\n",
    "        elif pred_reward > 5:\n",
    "            trouble_list.append(pred_reward)\n",
    "        else:\n",
    "            predicted_rewards.append(pred_reward)\n",
    "\n",
    "            pred_loss = tf.keras.metrics.mean_squared_error(\n",
    "                rewards, predicted_reward_tf\n",
    "            )\n",
    "            train_loss_results.append(pred_loss)\n",
    "            logged_rewards.append(actual_reward)\n",
    "            \n",
    "    # calculate avg loss\n",
    "    avg_eval_loss = tf.reduce_mean(train_loss_results)\n",
    "    \n",
    "    return (\n",
    "        avg_eval_loss,\n",
    "        predicted_rewards,\n",
    "        logged_rewards,\n",
    "        # train_loss_results\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b3d3c-75f7-46f4-9a1b-6329e419b7f5",
   "metadata": {},
   "source": [
    "## train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "97cfe7c3-4022-47a9-83c2-df0ad8a2abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.metrics import export_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.utils import common\n",
    "\n",
    "# from src.per_arm_rl import train_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bb7ffc-00df-4d46-857b-86c87b78f597",
   "metadata": {},
   "source": [
    "`agent.train(experience=...)`\n",
    "\n",
    "where `experience` is a batch of trajectories data in the form of a Trajectory. \n",
    "* The structure of experience must match that of `self.training_data_spec`. \n",
    "* All tensors in experience must be shaped [batch, time, ...] where time must be equal to self.train_step_length if that property is not None."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94d6d45-c71e-4fe4-9af8-af9a8bda4e4f",
   "metadata": {},
   "source": [
    "### logs & checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "049ee49b-3b1a-4b12-a360-15e759dff7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('metrics: [<tf_agents.metrics.tf_metrics.AverageReturnMetric object at '\n",
      " '0x7f6ef43ebeb0>]')\n",
      "setting checkpoint_manager: gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230823-141716/root/chkpoint\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    f\"{LOG_DIR}/train\", flush_millis=10 * 1000\n",
    ")\n",
    "# train_summary_writer.set_as_default()\n",
    "\n",
    "# eval_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "#     f\"{LOG_DIR}/eval\", flush_millis=10 * 1000\n",
    "# )\n",
    "# ====================================================\n",
    "# metrics\n",
    "# ====================================================\n",
    "step_metric = tf_metrics.EnvironmentSteps()\n",
    "metrics = [\n",
    "    # tf_metrics.NumberOfEpisodes(),\n",
    "    # tf_metrics.AverageEpisodeLengthMetric(batch_size=HPARAMS['batch_size']),\n",
    "    tf_metrics.AverageReturnMetric(batch_size=HPARAMS['batch_size'])\n",
    "]\n",
    "\n",
    "pprint(f\"metrics: {metrics}\")\n",
    "\n",
    "# ====================================================\n",
    "# get checkpoint manager\n",
    "# ====================================================\n",
    "CHKPOINT_DIR = f\"{ROOT_DIR}/chkpoint\"\n",
    "print(f\"setting checkpoint_manager: {CHKPOINT_DIR}\")\n",
    "\n",
    "checkpoint_manager = train_utils.restore_and_get_checkpoint_manager(\n",
    "    root_dir=CHKPOINT_DIR, \n",
    "    agent=agent, \n",
    "    metrics=metrics, \n",
    "    step_metric=step_metric\n",
    ")\n",
    "# ====================================================\n",
    "# policy saver\n",
    "# ====================================================\n",
    "saver = policy_saver.PolicySaver(\n",
    "    agent.policy, \n",
    "    train_step=global_step\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83683f4b-8a1a-44b9-8d5f-7ee3304c794c",
   "metadata": {},
   "source": [
    "### config\n",
    "\n",
    "* calculate train & val dataset sizes\n",
    "* define logging and chkpt intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f9432613-6583-4828-8a2a-dd939adbc3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_DATA_SIZE : 80000\n",
      "NUM_TRAIN_STEPS : 300\n",
      "EVAL_DATA_SIZE : 20000\n",
      "NUM_EVAL_STEPS : 10000\n",
      "CHKPT_INTERVAL: 300\n",
      "LOG_INTERVAL : 50\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA_SIZE = 80000          # len(list(train_dataset))\n",
    "NUM_TRAIN_STEPS = 300            # TRAIN_DATA_SIZE // HPARAMS['batch_size']\n",
    "\n",
    "EVAL_DATA_SIZE  = 20000          # len(list(val_dataset))\n",
    "NUM_EVAL_STEPS  = 10000          # EVAL_DATA_SIZE // HPARAMS['eval_batch_size']\n",
    "\n",
    "CHKPT_INTERVAL  = NUM_TRAIN_STEPS # // 5\n",
    "LOG_INTERVAL    = 25\n",
    "# EVAL_INTERVAL = NUM_TRAIN_STEPS // 2\n",
    "\n",
    "print(f\"TRAIN_DATA_SIZE : {TRAIN_DATA_SIZE}\")\n",
    "print(f\"NUM_TRAIN_STEPS : {NUM_TRAIN_STEPS}\")\n",
    "print(f\"EVAL_DATA_SIZE : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS : {NUM_EVAL_STEPS}\")\n",
    "\n",
    "print(f\"CHKPT_INTERVAL: {CHKPT_INTERVAL}\")\n",
    "print(f\"LOG_INTERVAL : {LOG_INTERVAL}\")\n",
    "# print(f\"EVAL_INTERVAL : {EVAL_INTERVAL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "379ffc65-4eec-4af1-8fd4-912ef65a9808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec={'bucketized_user_age': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'movie_genres': TensorSpec(shape=(None, 1), dtype=tf.int64, name=None), 'movie_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'timestamp': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'user_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_occupation_text': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_rating': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data\n",
    "train_ds_iterator = iter(train_dataset.batch(HPARAMS['batch_size']).repeat())\n",
    "\n",
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS[\"eval_batch_size\"])\n",
    "\n",
    "if NUM_EVAL_STEPS > 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)\n",
    "\n",
    "# eval_ds = eval_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "eval_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e498d7e3-d166-4e1d-94a5-f721de58694a",
   "metadata": {},
   "source": [
    "### run train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "da4680f3-693b-4530-8e4d-88bc43036c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating pre-trained Agent...\n",
      "pre-train val_loss     : 15.132555961608887\n",
      "pre-train eval runtime : 4\n",
      "starting train loop...\n",
      "step = 0: train loss = 15.920000076293945\n",
      "step = 50: train loss = 1.75\n",
      "step = 100: train loss = 1.5199999809265137\n",
      "step = 150: train loss = 1.409999966621399\n",
      "step = 200: train loss = 1.1699999570846558\n",
      "step = 250: train loss = 1.309999942779541\n",
      "train runtime_mins: 2\n",
      "saved trained policy to: gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230823-141716/artifacts\n",
      "evaluating trained Agent...\n",
      "post-train val_loss     : 1.2452585697174072\n",
      "post-train eval runtime : 4\n"
     ]
    }
   ],
   "source": [
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "# agent.train = common.function(agent.train)\n",
    "\n",
    "list_o_loss = []\n",
    "\n",
    "# ====================================================\n",
    "# Evaluate the agent's policy once before training\n",
    "# ====================================================\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "pre_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "\n",
    "print(f\"evaluating pre-trained Agent...\")\n",
    "start_time = time.time()\n",
    "\n",
    "pre_val_loss, pre_preds, pre_tr_rewards = _run_bandit_eval(\n",
    "    policy = pre_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"pre-train val_loss     : {pre_val_loss}\")\n",
    "print(f\"pre-train eval runtime : {runtime_mins}\")\n",
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "print(f\"starting train loop...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# for i in tqdm(range(NUM_TRAIN_STEPS)):\n",
    "for i in range(NUM_TRAIN_STEPS):\n",
    "    \n",
    "    with train_summary_writer.as_default():\n",
    "\n",
    "        data = next(train_ds_iterator)\n",
    "        trajectories = _trajectory_fn(data)\n",
    "\n",
    "        # All tensors in experience must be shaped [batch, time, ...] \n",
    "        step = agent.train_step_counter.numpy()\n",
    "        loss = agent.train(experience=trajectories)\n",
    "        list_o_loss.append(loss.loss.numpy())\n",
    "\n",
    "        train_utils._export_metrics_and_summaries(\n",
    "            step=i, \n",
    "            metrics=metrics\n",
    "        )\n",
    "\n",
    "        # print step loss\n",
    "        if step % LOG_INTERVAL == 0:\n",
    "            print(\n",
    "                'step = {0}: train loss = {1}'.format(\n",
    "                    step, round(loss.loss.numpy(), 2)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if i > 0 and i % CHKPT_INTERVAL == 0:\n",
    "            saver.save(os.path.join(CHKPOINT_DIR, 'policy_%d' % step_metric.result()))\n",
    "            print(f\"saved policy to: {CHKPOINT_DIR}\")\n",
    "   \n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"train runtime_mins: {runtime_mins}\")\n",
    "\n",
    "saver.save(ARTIFACTS_DIR)\n",
    "print(f\"saved trained policy to: {ARTIFACTS_DIR}\")\n",
    "\n",
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = _run_bandit_eval(\n",
    "    policy = post_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "17b2b0d2-9795-4367-b57b-c331e94d1000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2452586"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb1ed8-f67b-4e7b-9cbc-70edd50e49ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate train job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff31fe28-2f05-499f-b1cc-505f3c9074e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### train loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "41937f9a-6c28-48d2-bc7c-bfe4372c7cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAGdCAYAAAAIbpn/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABHTElEQVR4nO3deXxU9b3/8fdMkpnsCVnIQhIIa1gEFAUirggCbljpvVbtr27ValGr2EXuz2r1tsVr70/Ua8Te1kp7r4qiFeuGIkismiAEkH0JRBIISdiyZ7LN+f2RzJDJApGcmUnI6/l4zINkzsnMdw6T5J3Pd7MYhmEIAACgD7L6uwEAAABniiADAAD6LIIMAADoswgyAACgzyLIAACAPosgAwAA+iyCDAAA6LMIMgAAoM8K9HcDvM3pdKq4uFgRERGyWCz+bg4AAOgGwzBUVVWl5ORkWa1d113O+iBTXFys1NRUfzcDAACcgaKiIqWkpHR5/KwPMhEREZJaLkRkZKSfWwMAALqjsrJSqamp7t/jXTnrg4yrOykyMpIgAwBAH3O6YSEM9gUAAH0WQQYAAPRZBBkAANBnEWQAAECfRZABAAB9FkEGAAD0WQQZAADQZxFkAABAn0WQAQAAfRZBBgAA9FkEGQAA0Gf5Ncj85je/kcVi8bhlZGS4jzscDs2fP1+xsbEKDw/XvHnzVFpa6scWAwCA3sTvFZmxY8fq8OHD7tsXX3zhPvbQQw/pvffe0/Lly5Wdna3i4mLdcMMNfmzt6ZVVOvRS9j4dq673d1MAADjr+X3368DAQCUmJna4v6KiQi+//LJee+01TZ8+XZL0yiuvaPTo0crNzdXUqVN93dRu+WvOt8r6bJ+anYbmXz7c380BAOCs5veKzN69e5WcnKyhQ4fqlltuUWFhoSQpLy9PjY2NmjFjhvvcjIwMpaWlKScnp8vHq6+vV2VlpcfNl2rqmyVJ1fVNPn1eAAD6I78GmSlTpmjp0qVauXKllixZooKCAl188cWqqqpSSUmJbDaboqOjPb4mISFBJSUlXT7mokWLFBUV5b6lpqZ6+VV4Mgyj9V+fPi0AAP2SX7uW5syZ4/54/PjxmjJligYPHqw333xTISEhZ/SYCxcu1IIFC9yfV1ZW+jTMuPKLQZIBAMDr/N611FZ0dLRGjhyp/Px8JSYmqqGhQeXl5R7nlJaWdjqmxsVutysyMtLj5ktOV0XGp88KAED/1KuCTHV1tfbt26ekpCRNmjRJQUFBWr16tfv47t27VVhYqMzMTD+28tRchRgqMgAAeJ9fu5Z+/vOf69prr9XgwYNVXFysxx9/XAEBAbrpppsUFRWlO++8UwsWLFBMTIwiIyN1//33KzMzs9fOWJLadi35tRkAAPQLfg0yBw8e1E033aRjx44pPj5eF110kXJzcxUfHy9JWrx4saxWq+bNm6f6+nrNmjVLL774oj+bfFruiox/mwEAQL/g1yCzbNmyUx4PDg5WVlaWsrKyfNQiMzBrCQAAX+lVY2TOBq4A4yTJAADgdQQZkxFgAADwHYKMyZi1BACA7xBkTGa0+xcAAHgPQcZkJysy/m0HAAD9AUHGZEZrLYaxMgAAeB9BxmysIwMAgM8QZEzmZPdrAAB8hiBjMqOTjwAAgHcQZEzGYF8AAHyHIGMyV35hsC8AAN5HkDGZwRgZAAB8hiBjMhbEAwDAdwgyZmOMDAAAPkOQMZl7+jU1GQAAvI4gYzJmLQEA4DsEGZO5KjHsfg0AgPcRZExmsEUBAAA+Q5AxmXvWEkkGAACvI8iYjIoMAAC+Q5AxmWtsDCv7AgDgfQQZkxkdPgAAAN5CkDGZwToyAAD4DEHGZAz2BQDAdwgyJmNBPAAAfIcgYzJXfmGwLwAA3keQMdnJMTIAAMDbCDImo2sJAADfIciY7ORsJZIMAADeRpAxGRUZAAB8hyBjMleAYbAvAADeR5AxmatriRgDAID3EWRM5qRrCQAAnyHImI3drwEA8BmCjMncXUuUZAAA8DqCjMmYtQQAgO8QZEx2chUZkgwAAN5GkDGZe4sCcgwAAF5HkDEZs5YAAPAdgozJ6FoCAMB3CDJmay3FOMkxAAB4HUHGZEaHDwAAgLcQZEzmnn5NkgEAwOsIMiY7uSCenxsCAEA/QJAxmcEWBQAA+AxBxmQnp18TZQAA8DaCjMkMZi0BAOAzBBkvIccAAOB9BBmTuXuU6FoCAMDrCDImc89a8nM7AADoDwgyJjPYawkAAJ8hyJjM6R7sS5IBAMDbCDImY4gMAAC+Q5AxGwviAQDgMwQZk52syBBlAADwNoKMyQgwAAD4DkHGZK4Yw2BfAAC8r9cEmaeeekoWi0UPPvig+z6Hw6H58+crNjZW4eHhmjdvnkpLS/3XyG5wBRhyDAAA3tcrgsz69ev1xz/+UePHj/e4/6GHHtJ7772n5cuXKzs7W8XFxbrhhhv81MruYfdrAAB8x+9Bprq6Wrfccov+9Kc/acCAAe77Kyoq9PLLL+uZZ57R9OnTNWnSJL3yyiv66quvlJub68cWn5rB7tcAAPiM34PM/PnzdfXVV2vGjBke9+fl5amxsdHj/oyMDKWlpSknJ6fLx6uvr1dlZaXHzR+IMQAAeF+gP5982bJl2rhxo9avX9/hWElJiWw2m6Kjoz3uT0hIUElJSZePuWjRIj3xxBNmN7XbDMbIAADgM36ryBQVFelnP/uZXn31VQUHB5v2uAsXLlRFRYX7VlRUZNpjdwfryAAA4Dt+CzJ5eXkqKyvTeeedp8DAQAUGBio7O1vPP/+8AgMDlZCQoIaGBpWXl3t8XWlpqRITE7t8XLvdrsjISI+bL7lnLfn0WQEA6J/81rV0xRVXaOvWrR733X777crIyNCvfvUrpaamKigoSKtXr9a8efMkSbt371ZhYaEyMzP90eRuYfdrAAB8x29BJiIiQuPGjfO4LywsTLGxse7777zzTi1YsEAxMTGKjIzU/fffr8zMTE2dOtUfTe4Wd9cSNRkAALzOr4N9T2fx4sWyWq2aN2+e6uvrNWvWLL344ov+btYpuSoxTqd/2wEAQH/Qq4LM2rVrPT4PDg5WVlaWsrKy/NOgM0IlBgAAX/H7OjJnGxbEAwDAdwgyJjPa/QsAALyHIGMyNo0EAMB3CDImcw/2JckAAOB1BBmTGSyIBwCAzxBkTHZyiwK/NgMAgH6BIGM2o8MHAADASwgyJqMiAwCA7xBkTOYa5MtgXwAAvI8gYzL3gnj+bQYAAP0CQcZkrs0iKcgAAOB9BBmTsUUBAAC+Q5AxGVsUAADgOwQZs7krMv5tBgAA/QFBxmQn91oiyQAA4G0EGZPRtQQAgO8QZExmsPs1AAA+Q5Ax2cmKDEkGAABvI8iYzFWJcZJjAADwOoKMiTwG+BJkAADwOoKMiTxzDEkGAABvI8iYqG10YbAvAADeR5AxUduuJXIMAADeR5AxkWdFhigDAIC3EWRM1Da7MGsJAADvI8iYiAG+AAD4FkHGRO17k+heAgDAuwgyJuoYZPzTDgAA+guCjInady2RYwAA8C6CjInaV2CclGQAAPAqgoyJ2scWcgwAAN5FkDFR+8G9zGICAMC7CDImoiIDAIBvEWRMZDj93QIAAPoXgoyJ2nclMdgXAADvIsiYiHVkAADwLYKMiTqMkfFLKwAA6D8IMibqMGuJkgwAAF5FkDERFRkAAHyLIGOi9oN7mcUEAIB3EWTM1H6wLzUZAAC8iiBjIhbEAwDAtwgyJuow/do/zQAAoN8gyJiofVcSs5YAAPAugoyJ2ucWJzkGAACvIsiYqMOsJTqXAADwKoKMiTr0JJFjAADwKoKMF5FjAADwLoKMidg0EgAA3yLImKj9mJj2Y2YAAIC5CDImYh0ZAAB8iyBjog6zlqjIAADgVQQZE7FFAQAAvkWQMRHBBQAA3yLImIrBvgAA+BJBxkRMvwYAwLcIMiZiYV8AAHzLr0FmyZIlGj9+vCIjIxUZGanMzEx99NFH7uMOh0Pz589XbGyswsPDNW/ePJWWlvqxxafGrCUAAHzLr0EmJSVFTz31lPLy8rRhwwZNnz5dc+fO1fbt2yVJDz30kN577z0tX75c2dnZKi4u1g033ODPJp8S68gAAOBbgf588muvvdbj89/97ndasmSJcnNzlZKSopdfflmvvfaapk+fLkl65ZVXNHr0aOXm5mrq1Kn+aPIpdRwjQ5QBAMCbes0YmebmZi1btkw1NTXKzMxUXl6eGhsbNWPGDPc5GRkZSktLU05OTpePU19fr8rKSo+br7TfooAcAwCAd/k9yGzdulXh4eGy2+2655579M4772jMmDEqKSmRzWZTdHS0x/kJCQkqKSnp8vEWLVqkqKgo9y01NdXLr+AkupYAAPAtvweZUaNGafPmzVq3bp3uvfde3XrrrdqxY8cZP97ChQtVUVHhvhUVFZnY2u+GigwAAN7l1zEykmSz2TR8+HBJ0qRJk7R+/Xo999xzuvHGG9XQ0KDy8nKPqkxpaakSExO7fDy73S673e7tZneqY0WGJAMAgDf5vSLTntPpVH19vSZNmqSgoCCtXr3afWz37t0qLCxUZmamH1vYtY7Tr/3UEAAA+gm/VmQWLlyoOXPmKC0tTVVVVXrttde0du1affzxx4qKitKdd96pBQsWKCYmRpGRkbr//vuVmZnZK2csSR3HxLBFAQAA3uXXIFNWVqYf/ehHOnz4sKKiojR+/Hh9/PHHmjlzpiRp8eLFslqtmjdvnurr6zVr1iy9+OKL/mzyKbWfbk2OAQDAu/waZF5++eVTHg8ODlZWVpaysrJ81KKeIbcAAOBbvW6MTF/GppEAAPgWQcZU7bqWqNEAAOBVBBkTOY1Tfw4AAMxFkDERey0BAOBbBBkTdZi15Kd2AADQXxBkTNQ+uFCQAQDAuwgyJuoYXEgyAAB4E0HGRO1nKTHYFwAA7yLImIh1ZAAA8C2CjImYtQQAgG8RZEzUvmuJGAMAgHcRZExE1xIAAL5FkDFRx+nXJBkAALyJIGMiFsQDAMC3zijI/PWvf9UHH3zg/vyXv/yloqOjdeGFF+rAgQOmNa6voWsJAADfOqMg8/vf/14hISGSpJycHGVlZenpp59WXFycHnroIVMb2Jd0HOxLkgEAwJsCz+SLioqKNHz4cEnSihUrNG/ePN19992aNm2aLrvsMjPb16dQkQEAwLfOqCITHh6uY8eOSZI++eQTzZw5U5IUHBysuro681rXx7QPLk6SDAAAXnVGFZmZM2fqxz/+sc4991zt2bNHV111lSRp+/btGjJkiJnt61M6zFrySysAAOg/zqgik5WVpczMTB05ckRvv/22YmNjJUl5eXm66aabTG1gX9JhujVJBgAArzqjikx0dLReeOGFDvc/8cQTPW5QX9axIkOSAQDAm86oIrNy5Up98cUX7s+zsrI0ceJE3XzzzTpx4oRpjetrOqwjQ44BAMCrzijI/OIXv1BlZaUkaevWrXr44Yd11VVXqaCgQAsWLDC1gX1Jx8G+/mkHAAD9xRl1LRUUFGjMmDGSpLffflvXXHONfv/732vjxo3ugb/9EVsUAADgW2dUkbHZbKqtrZUkffrpp7ryyislSTExMe5KTX/EWF8AAHzrjCoyF110kRYsWKBp06bp66+/1htvvCFJ2rNnj1JSUkxtYF/SYWVfkgwAAF51RhWZF154QYGBgXrrrbe0ZMkSDRo0SJL00Ucfafbs2aY2sC/pGFxIMgAAeNMZVWTS0tL0/vvvd7h/8eLFPW5QX9Z+JV8G+wIA4F1nFGQkqbm5WStWrNDOnTslSWPHjtV1112ngIAA0xrX19G1BACAd51RkMnPz9dVV12lQ4cOadSoUZKkRYsWKTU1VR988IGGDRtmaiP7io6DfUkyAAB40xmNkXnggQc0bNgwFRUVaePGjdq4caMKCwuVnp6uBx54wOw29hkM9gUAwLfOqCKTnZ2t3NxcxcTEuO+LjY3VU089pWnTppnWuL6G6dcAAPjWGVVk7Ha7qqqqOtxfXV0tm83W40b1VR2CDCUZAAC86oyCzDXXXKO7775b69atk2EYMgxDubm5uueee3TdddeZ3cY+o/2sJXIMAADedUZB5vnnn9ewYcOUmZmp4OBgBQcH68ILL9Tw4cP17LPPmtzEvoPdrwEA8K0zGiMTHR2td999V/n5+e7p16NHj9bw4cNNbVyf06FryT/NAACgv+h2kDndrtafffaZ++NnnnnmzFvUhzFrCQAA3+p2kNm0aVO3zrNYLGfcmL6ufXBpP2YGAACYq9tBpm3FBZ3rOEYGAAB40xkN9kXnOlRgSDIAAHgVQcZEbFEAAIBvEWRM1KFriRwDAIBXEWTM1H5BPD81AwCA/oIgY6L2wYVZSwAAeBdBxkQd91ryTzsAAOgvCDIm6rDXkp/aAQBAf0GQMVGHCgwlGQAAvIogYyIWxAMAwLcIMiYy2lVgnE6iDAAA3kSQ8SJiDAAA3kWQMRGzlgAA8C2CjInab0lAjgEAwLsIMiZqPySm/ZgZAABgLoKMiehaAgDAtwgyJurYtUSSAQDAmwgyJqIiAwCAbxFkvIgcAwCAd/k1yCxatEgXXHCBIiIiNHDgQF1//fXavXu3xzkOh0Pz589XbGyswsPDNW/ePJWWlvqpxafWfnAvFRkAALzLr0EmOztb8+fPV25urlatWqXGxkZdeeWVqqmpcZ/z0EMP6b333tPy5cuVnZ2t4uJi3XDDDX5sddfaz1pqv4kkAAAwV6A/n3zlypUeny9dulQDBw5UXl6eLrnkElVUVOjll1/Wa6+9punTp0uSXnnlFY0ePVq5ubmaOnWqP5rdJXILAAC+1avGyFRUVEiSYmJiJEl5eXlqbGzUjBkz3OdkZGQoLS1NOTk5nT5GfX29KisrPW6+0mHWEskGAACv6jVBxul06sEHH9S0adM0btw4SVJJSYlsNpuio6M9zk1ISFBJSUmnj7No0SJFRUW5b6mpqd5uuhuzlgAA8K1eE2Tmz5+vbdu2admyZT16nIULF6qiosJ9KyoqMqmFp9c+t5BjAADwLr+OkXG577779P777+vzzz9XSkqK+/7ExEQ1NDSovLzcoypTWlqqxMTETh/LbrfLbrd7u8mda1eCYbAvAADe5deKjGEYuu+++/TOO+9ozZo1Sk9P9zg+adIkBQUFafXq1e77du/ercLCQmVmZvq6uafVca8l/7QDAID+wq8Vmfnz5+u1117Tu+++q4iICPe4l6ioKIWEhCgqKkp33nmnFixYoJiYGEVGRur+++9XZmZmr5uxJLH7NQAAvubXILNkyRJJ0mWXXeZx/yuvvKLbbrtNkrR48WJZrVbNmzdP9fX1mjVrll588UUft7R7OlRgKMkAAOBVfg0y3ZmeHBwcrKysLGVlZfmgRT3DYF8AAHyr18xaOhu0z2UM9gUAwLsIMibquCCenxoCAEA/QZAxUYcF8fzTDAAA+g2CjInY/RoAAN8iyJioY0WGJAMAgDcRZEzE7GsAAHyLIGOijptGkmQAAPAmgoyJmLUEAIBvEWRMxKwlAAB8iyBjImYtAQDgWwQZE7XPLazsCwCAdxFkTERuAQDAtwgyJuo42JdkAwCANxFkTMRgXwAAfIsgYyJXcLFYWj8nyQAA4FUEGRO5upKsrUmGwb4AAHgXQcZErtxidVVk/NcUAAD6BYKMiVxBxtJakaEgAwCAdxFkTOSatRTgGiRDTQYAAK8iyPTA8ZoGVdQ1uj93VWACrFRkAADwBYLMGXrojc06799XacWmQ+77mLUEAIBvEWTOUGJUsCRpb1mV+z4ns5YAAPApgswZGh4fLknKL6s+eSezlgAA8CmCzBkakeAKMjXu+1zBxcqsJQAAfIIgc4aGtVZkjlbXq7y2QVKbBfFcg32pyQAA4FUEmTMUZg/UoOgQSSe7l05WZFo/IMcAAOBVBJkeGDawpSqz1xVkXNOvGewLAIBPEGR6oP2AX1dwca/s659mAQDQbxBkeuDkgN92XUutV5WCDAAA3kWQ6YHhA9tNwW7XtUSOAQDAuwgyPTA4NlSSdKi8Ts1Owz1L6eT0a6IMAADeRJDpgQh7kPvjusbmNrtft/xLjgEAwLsIMj0QHGR1h5bahqaOm0bSuQQAgFcRZHrAYrEoJChAklTX0NxhryUqMgAAeBdBpodCbS1BprahmS0KAADwMYJMD4XaAiW1BhnXppGu6dd0LQEA4FUEmR5yVWTqGpqldrOWnOQYAAC8iiDTQyHurqWmNrOW6FoCAMAXCDI91NkYmQDXppHfoWuppMKhA8dqTG0bAABnO4JMD4UEtR0j0xJc3NOvT5NjfvOP7Xr4zW/U2OzU3KwvNOe5f6q6vsmr7QUA4GwS6O8G9HWhbbqWnO27lk7xdaWVDi396ltJ0kUjYlVaWS9JOnCsRmOTo7zVXAAAzipUZHqo7WDfk9OvW/51nqIks+Vghfvjv3zxrfvjw+UO3f/6Jn1/yVdqbHaa3VwAAM4qVGR6yD3Yt/Fk11J31pHZcrDc/fHWQydDTf6Rar33TbEkaXdJlcYNojoDAEBXqMj0UFjrOjIt069bWLvRtdS2ItPW1wXH3R/vO1Ld8wYCAHAWI8j0UGfTr63WU+9+bRiGR0WmrfVtgkx+WbWamp1qoosJAIBOEWR6yHP6deusJcupvkI6eKJOJ2obFRRgUXpcmMexqjazlvLLqvWD/87VpX9Yy2wmAAA6QZDpobZBxtlaODm5sm/nFRlXt1JGYqSmpMdIkuLCbR3O+2LvUW04cEKHyus8KjUAAKAFQaaHQtx7LTW5KzKnWtn34IlaPf3xLknSxNRo3TZtiM5Li9b/vXp0h3PbVmc2HCDIAADQHkGmh0KD2ky/do2Rae1aah9kGpqc+uGf1+nAsVqlxoTo3suGKSMxUn//6TRdMz5ZllN0SW349oQXWg8AQN9GkOmhzrYoODlryTPJfLKjRN8eq1VcuE1v/iRTydEh7mNBAVbFh9vdn8dH2D2+9puD5awrAwBAOwSZHgppE2RcuaWrLQr+N/eAJOnmyWlKigpRe0mtwcYeaFXm0FhJ0oDQIEWHBsnR6NQtf16nXyz/Rk621QYAQBJBpsfC7K3ryDSenLVk7STI5JdVKXf/cVkt0g8mp3X6WMlRwZKktJhQjU2OlCRdPCJe56UNkNSyxszyvIPaVVLlldcCAEBfw8q+PRQS1HGvJfcYmTZdS+9vOSxJmp6R4NGl1JarSjM4NlQ/yhyiAKtFcycO0opNh7RmV5n7vKITtRrTGnQAAOjPqMj0kGuMjKPRqWZn11sUlFW1bAo5blDXAWRyekvlZerQWIXYAvTji4cqPsKuH04drN9eP04TUqMlSUXHa81+GQAA9ElUZHoo1HbyErq2KbC4KzInVdQ1SpKiQoK6fKzZ45K0+bGZig71XFMmxBagH04drKITtfqmqFwHT9SZ03gAAPo4KjI9FBxkdQeXmoaWdV8CLB23KKioPX2QkdQhxLSVOiBUUktFxjAMti4AAPR7BJkeslgsbcbJtFRkTq7se/I8V0UmOvTUQeZUUmNag8yJWv3oL1/rov/4TEer68/48QAA6Ov8GmQ+//xzXXvttUpOTpbFYtGKFSs8jhuGoccee0xJSUkKCQnRjBkztHfvXv809hRc42Rc+yG5Zy21Oac7XUunkzqgZTDw/iM1+ufeoyqpdOj1dYVn/HgAAPR1fg0yNTU1mjBhgrKysjo9/vTTT+v555/XSy+9pHXr1iksLEyzZs2Sw+HwcUtPzbWWTENTS1ePa9ZS29G+ZgSZQQNCZLFITW1KPf+77gAL5QEA+i2/DvadM2eO5syZ0+kxwzD07LPP6tFHH9XcuXMlSX/729+UkJCgFStW6Ac/+IEvm3pKYTbPy3hyZd8WTqehSkdLkInsQZCxBwYoISJYJZUng1xpZb0eeH2TLhgSo9unDXHv8wQAQH/Qa8fIFBQUqKSkRDNmzHDfFxUVpSlTpignJ6fLr6uvr1dlZaXHzdtcFRmX9iv7Vjma3B/3pCIjSakxJ9egmZASJUn6aFuJnnx/h75p3VUbAID+otcGmZKSEklSQkKCx/0JCQnuY51ZtGiRoqKi3LfU1FSvtlM6OUbGxVUUcbamF1e3UkhQgOyBnud+V66ZSxaL9N8/Ol8PzxypUQkRkqT1BeyQDQDoX3ptkDlTCxcuVEVFhftWVFTk9ecMCeqia6m1CmPG+BiXlNaZS2OTI5UQGaz7rxihG84bJEla/y1BBgDQv/TaIJOYmChJKi0t9bi/tLTUfawzdrtdkZGRHjdva1+RsbZbEM/MIDNnXKISIu267cJ0933nD4mRJG04cMJj7RoAAM52vTbIpKenKzExUatXr3bfV1lZqXXr1ikzM9OPLeuoQ5Cxei6IZ2aQGZ0UqXX/NkPfn5Tivm/coEjZA606XtOg/UdrevwcAAD0FX6dtVRdXa38/Hz35wUFBdq8ebNiYmKUlpamBx98UL/97W81YsQIpaen69e//rWSk5N1/fXX+6/RnQgOal+R8Zw5VF7XIEmK6sFieKdiDwzQhNRofV1wXBu+Pa5h8eFeeR4AAHobvwaZDRs26PLLL3d/vmDBAknSrbfeqqVLl+qXv/ylampqdPfdd6u8vFwXXXSRVq5cqeDgYH81uVO2QM/CVoAXx8h05YIhA/R1wXHl7j+uGy9I89rzAADQm/i1a+myyy6TYRgdbkuXLpXUsvz/k08+qZKSEjkcDn366acaOXKkP5vcKVuA52W0djFryZtB5vJRAyVJH207rPLaBq89DwAAvUmvHSPTl7SvyFjaLYhX6YMgM2nwAI1OipSj0ak31nt/phYAAL0BQcYE7YOMtd3u1+W1Pd8w8nQsFotuu3CwJOlvOQfU7GT2EgDg7EeQMUH7riXXp96Yfn0qcycO0oDQIB0qr9Nfv/rWq88FAEBvQJAxQYeKTLuFZFxBpif7LHVHcFCAHr5ylCTpDx/vVtHxWq8+HwAA/kaQMUFXXUu+HOzrcvPkNE1Oj1FdY7MWf7rH688HAIA/EWRMYO8QZFr+9XXXktRSDfrZFSMkSev2s2UBAODsRpAxQcfp1yfXkWl2GqpyNEmSon0QZCRpQmq0LBbpUHmdyqocPnlOAAD8gSBjAntQF0FGhqpbQ4wkRQT7JsiE2wM1cmDLjtibC8t98pwAAPgDQcYEtgDPLQoCrCcrMlX1Ld1K9kBrh7E03jQxNVqStLmo3GfPCQCArxFkTNBxsG/Lv4Yh1dQ3S5Iign27G8TEtGhJBBkAwNmNIGOCLlf2NQxVt1Zkwuw+DjKtFZktBytYHA8AcNYiyJigy8G+knugb7iPg8zIhAiF2gJUXd+kNbvKfPrcAAD4CkHGBKfqWqqu90+QCbBa9K/np0qSHn5zs749WuPT5wcAwBcIMibosI6MteOsJV+PkZGkhVdl6Ly0aFU6mvQfK3f5/PkBAPA2gowJul7Z138VGUmyBwboV7MzJEnfMOgXAHAWIsiYoMtNI9sEGV8P9nUZnRwpSSqucKi8tsEvbQAAwFsIMiboqiKjNl1L4X7oWpKkyOAgpQwIkSTtPFzllzYAAOAtBBkTdD39+mRFJsJPFRlJykhsqcrsKqn0WxsAAPAGgowJAq0WuYsw8tw0ssqPY2RcxiS1bFew8zBBBgBwdiHImMBisXiMkwlwD/Zt27Xkm32WOjM6qaUiQ9cSAOBsQ5AxSdvupbZdSzW9oCKT0Rpk9pRWqanZ6bd2AABgNoKMSdquJXNy00jDr9OvXQbHhCokKED1TU59c7Dcb+0AAMBsBBmTtO1a8hgj4+dZS1LLAn0zxiRIkn6+fIs7XAEA0NcRZEzStmvJPf3azwvitfXkdWOVFBWsgqM1eppVfgEAZwmCjEk8goy1zWDfev9tUdDWgDCbFt1wjiTpH98UsyM2AOCsQJAxiWdFpuXfusZmd2Dwd0VGki4aHqeokCCV1zZqU+EJfzcHAIAeI8iYxHOMzMm9liTJYpFCbQH+aJaHwACrLh8VL0n6dGeZn1sDAEDPEWRM0ukYmVbhtkD3lGx/mz66ZdDvml2lfm4JAAA9R5AxiS3wZMXF2i6z+HPGUnuXjohXgNWiPaXVKjpe6+/mAADQIwQZk3is7NsuyfSG8TEuUaFBGt26ZcHuElb6BQD0bQQZk9g7WdnXpTdVZCRpUHTLbtjFFXV+bgkAAD1DkDFJZ7OWXHpTRUaSkluDzKFyggwAoG8jyJiks1lLLr0tyLgqModOEGQAAH0bQcYktk72WnLprUGmmIoMAKCPI8iY5JTTr3vZGJlkd5Bx+LklAAD0DEHGJJ5bFHgeS4oK9nFrTs0VZEqrHGpsdvq5NQAAnDmCjElONUZmfEq0j1tzarFhNtkCrTIMqaSCqgwAoO8iyJjkVLOWxg2K8nFrTs1qtSi5tUrEOBkAQF9GkDFJUMDJ9NJ2HZmhcWG9brCv1GaczGnWknGySzYAoBcjyJgksM3AmIA2Qaa3VWNcujPgd0dxpc777Sr9esU2XzULAIDvhCBjkqAupl+f08uDTFeL4jmdhh5dsVXltY16Y32RqhyNvmweAADd0vv6PPooW0Dnu1v31orMoOiWMTLtN45sanbqpex92l1arY2F5ZKkhman1uwq09yJg3zdTAAATomKjEmC2sxaCrGd3Al7fErvDDJjk1valXfghOqbmt33r95Vpv/8ZI/e+6ZY0snF8z7cetj3jQQA4DSoyJikbZCxB1r1/v0XyWqxKKwXDvSVpLHJkUqItKu0sl7r9h/XJSPjJUk7D1dKksYNitR1E5I1dWisrnvhS63dfUQ19U299vUAAPonKjImaRtkLBaLxg2K0pjkSD+26NQsFosuHzVQkrRmV5n7/j2lVZKkuRMG6e5LhumcQVEaHBuq+ianvtp3zC9tBQCgKwQZk7Sdft1+HZne6vKMliCzelepDKNlmvWe0mpJ0oiEcEktgWfykBhJ0tZDFX5oJQAAXSPImMSjIqO+kWQuGh4nW4BVRcfrtKe0Wg1NTn17tEaSNDIhwn2ea8DydoIMAKCXIciYxLNryY8N+Q7C7IG6bFTL2JilXxWo4GiNmpyGIuyBHvtDjRvU0kW2rZggAwDoXRi5aRJbYB9JL+3cfclQfbKjVG/nHdKIgS1VmOEJ4R6rE49OipTFIpVW1qusyqGBEZ1vgmkYht7dXKzhA8PdVZzq+iZ9sr1E24srVd/UrLhwu+66eGi3Bw3XNzXrgdc3KSEyWE/OHdfDVwsA6KmNhSf0j83FemjmSEWFBPm7OQQZs/TFiowknT8kRpMGD1DegRN68v0dkqSRAyM8zgm1BWpYfLjyy6q1vbhSA0e1BBnDMNTsNBTY+tqXrS/Swr9vVWRwoD77+WWqdDTpjqXrVdDaXeVy6ESd/vAvEzq0pcrRqD98vFuf7ijVr+ZkaO7EQfqfnAP6eHupJOlfz0/1yro8jc1OOQ1D9sCA058Mn6h0NMrR2NwhNB+uqFNlXZNGJUZ08ZV9Q5WjUUEBVgUH8Z6D+QqP1WrfkWr3OEiz/dvft2pXSZWCgwL0yJwMrzzHd0HXkkn64hgZl/suH+7xuWugb1vjWmdg/e6DnVr00U5V1zfpsXe3a+SjH+lfX8rRkrX79PsPd0qSKh1NuvfVjbo+60sVHK1RYmSwbrtwiH5y6VBZLNLyvIP6dEepx+Mfr2nQVc//U3/LOaDiCod+tmyznvpol/5rTb77nFfXFcrR2KzGZmenr+Nodb1eXXdAFbWNanYa+mrfUX2+58gpd/g+VF6nWYs/1/jffKJ7/ievwwKB/vC7D3bo0j98dsq2NDY7VV3fJMMw9J8f79bMZ7K19WBL15+jsVmf7SrTwr9v1Y/+8rUKj5n7mgzD0Jf5R7W5qLzLc5xOQ4+8vUUL3tyspi7+v9pb+mWBFn24U8XldZrz7D916dNrtbukZRZdQ5NTiz7cqUufXqtZz36ul78oUHF5ndZ/e1xf5h9VdX3TGb+euoZmlVV1/R45Vl3f7dfQ2OzUH7P3ac2uk+/vZqfh3px1R3Gl7li6XhOfXKW5L3yp2oYzb7dL3oHjuvlPucrec6TLcyrqGvU/uQdO+Tp7i4KjNfrJ/2zQtKfW6LM2MyrNVF7boJXbDnusofVdGIah3/xjux5/d5t7osTp/O6DHVrwxuYuf365OJ2Gvikq157SqlOe29DU+bFKR6P+5Y9f6fal6/Xu5kMex45V13f4vi2rcsjR2P3rsPNwpXa1fl++sb7wO32tt1iM7v4v9FGVlZWKiopSRUWFIiO9Nx06v6xaM57JliTt+e0cj92w+4I31xfpl29vafn4J5manB7jcfzP/9yv336w0/35tOGx+jK/43TswbGhOtDmF+fE1Gj9948muf+yfvK9HfrLlwWSpAuGDNCPLx6qmaMT9MCyTXp/y2ENig7R5PQYvbPp5DfggNAgnahtVEhQgOxBVhmGNO+8FI1JjtSU9BilxoTqSFW9bvxjjvYfrdH5gwcoLtyuldtLJLXMKLt9WrruvXSYokODtO9ItT7fc1RFJ2q1akepDp44uU3DhNRorfjphTpUXqcX1uSr8Hitzk2L1o8yhygyOEh/33RQZZX1SooK1vXnDtKHWw/rcIVDd16ULqvFIkdTs0KCAvT86r36aFuJjtc0KCokSJOHxOjx68Yo1Bao6vomrd1dpn1lNbIFWnXz5DTVNTbr4IlaHTxRpwff2CxJ+uHUNP373HHaWHhC724uVlRIkEYlRuibonK9s6lYR6vrdc6gKPdsssGxoZo9LlH/k3NAtQ0nf7hMSY/R63dN1epdZfrdBztU3+TUJSPidfelQzUs3jO0Op2GPtx2WMXldUqKClHmsFh9sr1Ub288qCanoQGhQapyNCnvwAkFWi362x2TdeHwOEktq0L/6u2tanY6df6QGD3aukfXI3MyVHCkRiWVDs0Yk6DrJyZrb1m1Xlq7T5dnDNS/TErR53uP6I6lGyRJIUEBqmv94Tg2OVIr5k/TM6v2aMnafV2+fwdG2PV/rx6ta8cny9rJtMFKR6PsgVYFWa2qaWhSRHCQyipbAvPX3x5Xs9PQkNhQRYYEKS7crieuG6vk6BC9sCZfz63eo+EDw7X09slKjg5RfVOzissdSh0Q4q5GuvzmH9u19KtvZbVIL996gdLjwvSzZZv0zcEKzRidoNz9xzxC120XDtFvrhvb5esyDEMnahsVE2aTo7FZ/9hcrP1HaxQbZtNV45MUE2rTjGeydai8TvZAqx67doychnTlmAQlRLZ8zzU2O3XLn9fp64LjGjEwXA/NHKm/5Xyr709K1fcnpUiSTtQ0yNHUrKSokA5teH9LsZ75ZI/C7IG6YvRA3Xf5cPfr3lVSqZQBocovq9Z/fLRLU4fG6t7Lhul4TYO2F1cowGrRZaMGyuk0lFtwTJ9sL9XMMQma1vqeqXQ0am9ptUYlRijcHqhPtpfovtc2qaH1F7jVIl11TpIyEiM055wk5X17Qtl7j8jpNDRuUJRGJ0XojfVFGhwbpivHJCjrs3zFhtt1x7R0pcSEqKK2UVWOJo1MCHe3uazSoR/8d672H63RzDEJeumHkzy2lXEpqXDota8LNWdcokYnef7u+DL/qG758zpJ0ht3T9WUobEyDEOVjiZFBgfKYrGo8FitcvcfU1RokCKDg3TTn3IlSS/cfK5KKhwqrXTol7MzPP4IPlJVr1+89Y3W7m4JpfERdj1740T39XJZu7tM9722SXPGJeqJuWP1j83Famx2atCAEH2yvVTL1hdJkhIjg/Xpw5fKFmBVUIBF173wpbYeqtDiGyfoe+em6J97j+j2V9brvLQBev3uqZ1eh/LaBv3pn/t1buoAzRiToEUf7tQfP9/vPj7/8mGKCbNr5ugEpcWGdvIuPnPd/f1NkDGJ02noe0u+UpgtQK/+eIrHGJO+Ir+sWntKqzRnXGKH9n9TVK65WV/KFmj1+Etg9thETRkao1U7SlVa6dCSH07S23kH9decb/WTS4bpvunDPb5R6xqateDNzfp4e4lcG2tHhwapvLZRAVaL3vnphTpnUJT+8U2x3so7qPyyai2+caL+7Z2t2n/Es4tKall88FezM/TqugPa1+64LcCq1JgQ9/32QKtiwmw63K5CMzg2VE9cN1Y/fXWjahuadd2EZK3cXuLxOlMGhChlQIhy9x933xdmC1BNa2AYnRSpskqHjtc2KCkyWMWdVIF+culQhQQF6KXsfXI0nnzsyOBA1TQ0q7ndTuPBQVZdPCJeq9pVrzoTGRyoSsfJX5CJkcG6PGOgVmw6pLrGZo1KiNDu1jWCXAKtFo1OilR1fZOqHE1KjQlRSFDAd1ovKCokSPdeNkwXDY9T7v5jHmG3K7FhNlU5mty/rIbEhqq6vllHq+vd5wQHWWUPDFBFXaOuPidJq3aUqqHZqae/P15Hquq1eNUeSdKgASGqbWjWkaqWrx2ZEK5Hrx6jMHuAfvOPHaqpb1J9k9O9p1ig1aImp6GZYxLU0OTssooxNC5MA8Jsyjtwwn1ffIRdl42M19o9R3Skql7BQVZNGxanyzMGqsrRpK2HyvXh1hKP69vUye7xU4fG6HvnDtKv3t4qSXp45khNTo/RviM1chqGsvcc0daDFbp0ZLz2llVpY2G57p8+XJsKy/VF/lGPxxoWH9bhfS+1vB9mjklUwdFqNTsNfXOw84H6N5w7SGOSI7V41R41Og29+uMpumBIjAzD0PpvT+jdzYf06rpCj6+586J0PXr1aD21cpf+mL1f4fZANTQ73d8v9kCr6tt877x4y3l6f0ux+9qEBAXovfunKTEqRPNe/Eq7S6tksUjD48PdEw6mDY9VYmSI3t54sNN2f1eRwYG6bmKyZo1N1GPvbvfo7r5gyAANHxih+ZcPU8qAk7+If/jndfoi/6isFmlKeqxiwm26Y1q6Jg0eoDuXrtfq1mrRtROSNTQuTG/lHdSh8jplJEbIFmjVljbXfGCEXWWt71HXQqSS9OOL0vXoNWOUd+CEHnl7i/aWtSx/YQu0KshqUU1Ds6wWadrwOE0dGqu7LxmqirpGzX72cx2tbpB08g+99lz3Wy0twwPumDZEz7dWuKNCgvTaXVN0+yvr3e1aMHOkzkmJ0qETdXI0toxnLK106JUvv1VJpUO2AKv+cf803faX9SqpdOj8wQO0oc33x3/MO0c3XpDW8/+sNggyrXwVZCS5S4x9McR0x8bCE0qJDtFzq/fq1XWFsgVatebhSz2++V2anUan6d6lpMKh/809oL9+9a2qWv9Cve/y4fr5rFGdnr96Z6me+miXvj8pRcPiw/XJjhJtO1SpHa0rEUstPyB+cskw91if534wUXMnDtJnu8r0/1bt1rZDLefaAq2akh6jsclRGhAapBvOS1F8hF3PfbpXiz/d4368qUNjdPX4ZP35n/vdVaYwW4CumzhIn+4s1ZGqeoUEBSgowOIRIiQp3B6ox68do3GDopR34IS7OuGSHhemC4a0jE1y/SKKCglSRV2jJqZGq6HJ6X5ttgCrrp2QLEdTs4qO12p0YqQuz4hXakyo/jf3gM5LG6DBsWH64cvrFBUSpN9eP05XjkmQxWLRy18U6N9br4fVIt118VBNGx6nv+V8q093dl62twVaNXN0ggqO1mjH4UqF2QL0wBUjNDQ+XMeq61XpaNQVoxP08JvfeJSpgwIsamw2ZLVITkNKiwnVgDCbvikqV5gtQLdPS9cHWw+7f4lMHhKjPWVVKm/9ITw4NlS/u/4cvZS9T7deOEQNTU7d9/pGuX5CXTwiTn+7Y7IsFotq6psUGGCRPTBA9U3N+tPn+/XHz/erqvX/oX3g7ootwKq37s1UelyYNhw4ofrGZj353g53EA2zBejns0bp1XWFym/9JeO6lp1kFEnSA1eM0Lr9x7SuoCX0XjgsVndMS9dL2fuUFhuq33/vHAUHBbirN99FSFCA/vX8FO0qqXI/viQtvnGCPtpaosLjtXIahns9qLbunz5cL2XvU2OzocyhscotOKb2P/3jwm36UeYQfbj1sLv7QFJLhWNAiPt7KyMxwuO4JGUOjdWukkqdaP2jJC7cptLKeoXaAlTb0CxbgFWDBoSo4GiNhsaHKSEiWDn7j3UIfNdPTNZ//ssEBVgt+iL/qLYdqtRX+47qi/yjig2z6/9MHawwe4A+2laifUeqNXtsotYVHFfB0ZrW9720emeZmpyGbAFW2QOt7p8xLslRwbp9Wrp+9+HJ4D04NlSv3HaBAq1WlVU59P2XcmSxyOMaBVgtmnfeIC3PO9jh2rUXaLVoWHy4+w8IW4BVhgw1Nnt+4U2T0/T+N8XuNo5NjtR//ssEpceF6dEV2/RW3skwN2P0QB2radCmwnLFR9jdAT4u3K7z0qJVcLRG+UeqdcuUNF06cqDu+tuGTtvV9npHBAe6v2+6EmC1qNlpuENqZHCgPn34Ut36l/WqcjRqdFKkbp6cZvqYHIJMK18Gmf6iur5J//7eDk0dFqPvnZvSo8dyNDZrd0mVjtc06NKR8Z12C3SlsdmpX6/YpmXri3T1+CQ9ed1YxYbb9fmeI7JYpItHxLvPNQxDWw5WqMrRpEmDB3jsh+VS29CkOc/9U4fLHXr0mtH6P1MHy2Kx6OCJWv3gv3N1vKZBL996gTKHxaq6vkkfbyvRlKExamo29OLafE0aPEBT0mP1z/yjunh4nIbEhbkf+46l690rKD92zRjdPm2ILBaLGpqc+nh7iYbFhysjMUL5R6qV0loefvCNzQoJCtCfbz2/Q2m5M0eq6hURHOgxgLTZaeiPn++T1WLRtROS3XtnSdKWg+WtXxOkUFuANnx7XNuKK/Xji9OVkdjyvVJa6VCYPVDhncwyq3Q06rV1hdrw7Ql9urOlajRp8AD97IoRevbTPfrV7AwNGhCiP/+zQN+flKJxg6LU0OTUW3kH1eR06odTBqu2sVmrdpTo64IT+lHm4A4l/M92l+nBZZvV0OTUu/dN81jfqL2Kukb94eNd+t/clgrCZaPi9ZNLhsliaamYOZ2G6hqbVXC0Rnf+db0cjU49MidD91w6zONx9pRW6YHXN2nYwHD936tGKzk6RHUNzVqzq0zbiis0LD5c105I0v4jNXp/S7G2HapUTJhNQ+PCdEF6jKYOjZWjsVnbDlVoaHy4YsJsnbbX6TT03pZiPb96r2rqmzU6KUJWi0XpcWGanB6j97YcVrg9UBHBgfrv1lL+f910rq6dkCyppYL6v7kHFBtm033Th7v/gGpqdmrZ+iIVl9cpIylSFbUNGjQgRNMzErT1YIWqHI26sLWCtnzDQe0qqdSssYn6aFuJe4sSSQq1BWj22ERdNzFZl7WuAr541R49t3qv+5wn545VelyYjlU36LoJyaptbFbhsVoNjQ+TYUjT/99adwX0kTkZuuG8QbrquS/c1TdbgFXLfjJVKQNCtKWoQjUNTbpmfHKnfwRVORoVHBTgUeF1aWhy6nBFnQbHtnzPGYah+iZna3iQcvcf0+8+2Kkdhyt1zfgkPdH6s2JzUbm2HqrQH7P3eXQxu4LwTZNTdfPkwdpbVqW1u4/oH6170EnS5aPidbymwV3tenLuWM0am6g1u1pC1FXjEhUTZtOjK7bp1XWFumNausrrGvT3jYeUGhOiK8ck6uUvCtyPNzk9Ri/9cJLH+8UwDG0vrlTu/mN6euVudxUzJChAb997obYdqtCmonI9NHOEu/u+qdnp7kbLL6uW0zB032sbtae0WvZAq/5y2wW677WNOlHbqIjgQL3246l6fs1erdpRqrSYUI1KjJA90Kpj1Q2KCbNpfEpUS5fwC1+qqr5JobYAPfOvEzV7XGKn72szEWRaEWTOflWORkUEmzMFsMrRKKdTigr1fLz6pmY5Gp1nPNXwUHmdHluxTZdnDNQPpw4+7fmGYWh53kGNT4lyh4rebFPhCa3cXqJbM4coObrjOIueqHI0qrah2T3m43Q+21WmfUeq9aPMIV2OVdtdUqWdhyt17YTOf2n2JoZhaPmGgwq1B+ia8clee57i8jotXrVHVotFQ+PDdOMFqYoO7RjCvikqV0mlQ0Niw047e+wf3xTrgdc3aWJqtN66J1OBAVYVHa/V8ryDOniiVnPGJWnmmARvvSQPTqehI9X1nb6PCo7W6MY/5qisqt5dsQi0WvTZzy9TaszJivPqnaX6596jOlJdr4dmjFTR8Vo98vctenDGSN00ufNuFcMwtKukSiMGhutYTYMWr9qj/5M5WGOSIrV6Z5nebQ1Hv//euFP+HPtsd5kefWebzhs8QL+4ctR3Go9y4FiNfr78G111TpJun5Yup9NQo9OpAItFgQFWNTU7VV7XqLhwe5eP8WX+Ub2z6ZDuuXSYhg/sOCHEGwgyrQgyAOA/2w5VaEhcWKdVvd6koallGYaGZqdWbivRoOiQblVC4T3d/f3dJ6bWZGVlaciQIQoODtaUKVP09ddf+7tJAIBuGDcoqteHGKmlOyk4KECRwUH61/NTCTF9SK8PMm+88YYWLFigxx9/XBs3btSECRM0a9YslZV5Z30BAADQd/T6IPPMM8/orrvu0u23364xY8bopZdeUmhoqP7yl7/4u2kAAMDPenWQaWhoUF5enmbMmOG+z2q1asaMGcrJyen0a+rr61VZWelxAwAAZ6deHWSOHj2q5uZmJSR4jmpPSEhQSUlJp1+zaNEiRUVFuW+pqam+aCoAAPCDXh1kzsTChQtVUVHhvhUVFfm7SQAAwEt69VDyuLg4BQQEqLTUc4n20tJSJSZ2vhiP3W6X3d71XHgAAHD26NUVGZvNpkmTJmn16tXu+5xOp1avXq3MzEw/tgwAAPQGvboiI0kLFizQrbfeqvPPP1+TJ0/Ws88+q5qaGt1+++3+bhoAAPCzXh9kbrzxRh05ckSPPfaYSkpKNHHiRK1cubLDAGAAAND/sEUBAADodc6qLQoAAAA6Q5ABAAB9FkEGAAD0Wb1+sG9PuYYAsVUBAAB9h+v39umG8p71QaaqqkqS2KoAAIA+qKqqSlFRUV0eP+tnLTmdThUXFysiIkIWi8W0x62srFRqaqqKioqYDdUNXK/u41p9N1yv7uNadR/X6rvxxvUyDENVVVVKTk6W1dr1SJizviJjtVqVkpLitcePjIzkTf4dcL26j2v13XC9uo9r1X1cq+/G7Ot1qkqMC4N9AQBAn0WQAQAAfRZB5gzZ7XY9/vjj7LTdTVyv7uNafTdcr+7jWnUf1+q78ef1OusH+wIAgLMXFRkAANBnEWQAAECfRZABAAB9FkEGAAD0WQSZM5SVlaUhQ4YoODhYU6ZM0ddff+3vJvndb37zG1ksFo9bRkaG+7jD4dD8+fMVGxur8PBwzZs3T6WlpX5ssW99/vnnuvbaa5WcnCyLxaIVK1Z4HDcMQ4899piSkpIUEhKiGTNmaO/evR7nHD9+XLfccosiIyMVHR2tO++8U9XV1T58Fb5xumt12223dXivzZ492+Oc/nKtFi1apAsuuEAREREaOHCgrr/+eu3evdvjnO587xUWFurqq69WaGioBg4cqF/84hdqamry5Uvxuu5cq8suu6zDe+uee+7xOKc/XCtJWrJkicaPH+9e5C4zM1MfffSR+3hveV8RZM7AG2+8oQULFujxxx/Xxo0bNWHCBM2aNUtlZWX+bprfjR07VocPH3bfvvjiC/exhx56SO+9956WL1+u7OxsFRcX64YbbvBja32rpqZGEyZMUFZWVqfHn376aT3//PN66aWXtG7dOoWFhWnWrFlyOBzuc2655RZt375dq1at0vvvv6/PP/9cd999t69egs+c7lpJ0uzZsz3ea6+//rrH8f5yrbKzszV//nzl5uZq1apVamxs1JVXXqmamhr3Oaf73mtubtbVV1+thoYGffXVV/rrX/+qpUuX6rHHHvPHS/Ka7lwrSbrrrrs83ltPP/20+1h/uVaSlJKSoqeeekp5eXnasGGDpk+frrlz52r79u2SetH7ysB3NnnyZGP+/Pnuz5ubm43k5GRj0aJFfmyV/z3++OPGhAkTOj1WXl5uBAUFGcuXL3fft3PnTkOSkZOT46MW9h6SjHfeecf9udPpNBITE40//OEP7vvKy8sNu91uvP7664ZhGMaOHTsMScb69evd53z00UeGxWIxDh065LO2+1r7a2UYhnHrrbcac+fO7fJr+uu1MgzDKCsrMyQZ2dnZhmF073vvww8/NKxWq1FSUuI+Z8mSJUZkZKRRX1/v2xfgQ+2vlWEYxqWXXmr87Gc/6/Jr+uu1chkwYIDx5z//uVe9r6jIfEcNDQ3Ky8vTjBkz3PdZrVbNmDFDOTk5fmxZ77B3714lJydr6NChuuWWW1RYWChJysvLU2Njo8d1y8jIUFpaGtdNUkFBgUpKSjyuT1RUlKZMmeK+Pjk5OYqOjtb555/vPmfGjBmyWq1at26dz9vsb2vXrtXAgQM1atQo3XvvvTp27Jj7WH++VhUVFZKkmJgYSd373svJydE555yjhIQE9zmzZs1SZWWl+6/vs1H7a+Xy6quvKi4uTuPGjdPChQtVW1vrPtZfr1Vzc7OWLVummpoaZWZm9qr31Vm/aaTZjh49qubmZo//GElKSEjQrl27/NSq3mHKlClaunSpRo0apcOHD+uJJ57QxRdfrG3btqmkpEQ2m03R0dEeX5OQkKCSkhL/NLgXcV2Dzt5XrmMlJSUaOHCgx/HAwEDFxMT0u2s4e/Zs3XDDDUpPT9e+ffv0b//2b5ozZ45ycnIUEBDQb6+V0+nUgw8+qGnTpmncuHGS1K3vvZKSkk7fe65jZ6POrpUk3XzzzRo8eLCSk5O1ZcsW/epXv9Lu3bv197//XVL/u1Zbt25VZmamHA6HwsPD9c4772jMmDHavHlzr3lfEWRgmjlz5rg/Hj9+vKZMmaLBgwfrzTffVEhIiB9bhrPND37wA/fH55xzjsaPH69hw4Zp7dq1uuKKK/zYMv+aP3++tm3b5jE2DZ3r6lq1HUd1zjnnKCkpSVdccYX27dunYcOG+bqZfjdq1Cht3rxZFRUVeuutt3TrrbcqOzvb383yQNfSdxQXF6eAgIAOI7NLS0uVmJjop1b1TtHR0Ro5cqTy8/OVmJiohoYGlZeXe5zDdWvhuganel8lJiZ2GFDe1NSk48eP9/trOHToUMXFxSk/P19S/7xW9913n95//3199tlnSklJcd/fne+9xMTETt97rmNnm66uVWemTJkiSR7vrf50rWw2m4YPH65JkyZp0aJFmjBhgp577rle9b4iyHxHNptNkyZN0urVq933OZ1OrV69WpmZmX5sWe9TXV2tffv2KSkpSZMmTVJQUJDHddu9e7cKCwu5bpLS09OVmJjocX0qKyu1bt069/XJzMxUeXm58vLy3OesWbNGTqfT/cO2vzp48KCOHTumpKQkSf3rWhmGofvuu0/vvPOO1qxZo/T0dI/j3fney8zM1NatWz3C36pVqxQZGakxY8b45oX4wOmuVWc2b94sSR7vrf5wrbridDpVX1/fu95Xpg0b7keWLVtm2O12Y+nSpcaOHTuMu+++24iOjvYYmd0fPfzww8batWuNgoIC48svvzRmzJhhxMXFGWVlZYZhGMY999xjpKWlGWvWrDE2bNhgZGZmGpmZmX5ute9UVVUZmzZtMjZt2mRIMp555hlj06ZNxoEDBwzDMIynnnrKiI6ONt59911jy5Ytxty5c4309HSjrq7O/RizZ882zj33XGPdunXGF198YYwYMcK46aab/PWSvOZU16qqqsr4+c9/buTk5BgFBQXGp59+apx33nnGiBEjDIfD4X6M/nKt7r33XiMqKspYu3atcfjwYfettrbWfc7pvveampqMcePGGVdeeaWxefNmY+XKlUZ8fLyxcOFCf7wkrzndtcrPzzeefPJJY8OGDUZBQYHx7rvvGkOHDjUuueQS92P0l2tlGIbxyCOPGNnZ2UZBQYGxZcsW45FHHjEsFovxySefGIbRe95XBJkz9F//9V9GWlqaYbPZjMmTJxu5ubn+bpLf3XjjjUZSUpJhs9mMQYMGGTfeeKORn5/vPl5XV2f89Kc/NQYMGGCEhoYa3/ve94zDhw/7scW+9dlnnxmSOtxuvfVWwzBapmD/+te/NhISEgy73W5cccUVxu7duz0e49ixY8ZNN91khIeHG5GRkcbtt99uVFVV+eHVeNeprlVtba1x5ZVXGvHx8UZQUJAxePBg46677urwh0R/uVadXSdJxiuvvOI+pzvfe99++60xZ84cIyQkxIiLizMefvhho7Gx0cevxrtOd60KCwuNSy65xIiJiTHsdrsxfPhw4xe/+IVRUVHh8Tj94VoZhmHccccdxuDBgw2bzWbEx8cbV1xxhTvEGEbveV9ZDMMwzKvvAAAA+A5jZAAAQJ9FkAEAAH0WQQYAAPRZBBkAANBnEWQAAECfRZABAAB9FkEGAAD0WQQZAADQZxFkAABAn0WQAQAAfRZBBgAA9FkEGQAA0Gf9fznw57kbC7t6AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_o_loss)\n",
    "# plt.ylim([0, 10])\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e947e1-67f4-4205-99af-6921c6e9c896",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e0f77a33-0962-4af0-af97-cf05f895cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5d0509cb-0777-4d35-86c6-28c8acbcc793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9b62bdaa55e33587\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9b62bdaa55e33587\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=$LOG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc40143-30b1-479f-b9b1-fa4c07b1690e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [4] Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6c94a0-122f-4ba6-acef-5653a3cc7850",
   "metadata": {
    "tags": []
   },
   "source": [
    "## load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b1c382b5-e2e0-45a2-9c5f-ef2c468d0f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230823-141716/artifacts\n"
     ]
    }
   ],
   "source": [
    "POLICY_URI = ARTIFACTS_DIR\n",
    "\n",
    "print(POLICY_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "68592d97-1272-4c6d-a4bd-43a6f7fe6c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f6f286f41f0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910a06f-678f-4bfa-a132-10b885f871c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "567f64e1-8149-4364-b561-1a9d12581b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec={'bucketized_user_age': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'movie_genres': TensorSpec(shape=(None, 1), dtype=tf.int64, name=None), 'movie_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'timestamp': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'user_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_occupation_text': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_rating': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eval_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "aff30396-e0fd-4f43-acaa-6af8b20b12cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "for x in eval_ds.take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    global_feat_infer = _get_global_context_features(x)\n",
    "    arm_feat_infer = _get_per_arm_features(x)\n",
    "    rewards = _get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e58af9ab-f4da-4857-afe5-6b8de26ed0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(1, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.3308797, 3.3735833], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c85a0087-7388-4f03-9278-aace31121233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1, dtype=int32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a8266c7c-3688-46a5-a1c8-a63bb7146128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info.bandit_policy_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9712bc00-7ea0-4003-a3c7-81a0be5bc995",
   "metadata": {},
   "source": [
    "# [5] Prepare training application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f62966-123f-410e-9610-832f20566635",
   "metadata": {},
   "source": [
    "To scale this training in Vertex AI's managed training service, we need to package all our code into a python application\n",
    "\n",
    "* This means, we need to modularize all steps executed up until this point. For example, the training loop we ran above is further parameterized in `train_perarm.py`, which will be called from our `task.py` when we submit the job to Vertex AI\n",
    "* This training package will eventually be used to create a custom training image (more on that in `04b-build-training-image` notebook)\n",
    "* For additional details on preparing the training application for Vertex AI, check out [the documentation](https://cloud.google.com/vertex-ai/docs/training/code-requirements) and [this code example](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage2/get_started_vertex_training.ipynb) (which also has good, related commentary)\n",
    "\n",
    "**The remaining cells will repeat steps executed above**\n",
    "> we are just illustrating / validating that they are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1129ee41-b43c-4d5a-b656-cdac6b79688c",
   "metadata": {},
   "source": [
    "#### Vertex Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ef509680-4d19-4efa-9f01-21039e0d573b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : mab-local-v6\n"
     ]
    }
   ],
   "source": [
    "# using same experiment name \n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7ad98430-d836-40f1-8e4f-eb46f0c91fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : mab-local-v6\n",
      "RUN_NAME          : run-20230823-155520\n",
      "\n",
      "BASE_OUTPUT_DIR   : gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230823-155520\n",
      "LOG_DIR           : gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230823-155520/logs\n",
      "ROOT_DIR          : gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230823-155520/root\n",
      "ARTIFACTS_DIR     : gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230823-155520/artifacts\n"
     ]
    }
   ],
   "source": [
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fbdecf78-94c5-4f8c-a6c0-86f2eace4663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: OffpolicyNeuralEpsGreedyAgent\n",
      "Network: global_and_arm_common_tower_network_2\n"
     ]
    }
   ],
   "source": [
    "from src.perarm_features import agent_factory as agent_factory\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "agent, network = agent_factory._get_agent(\n",
    "    agent_type=AGENT_TYPE, \n",
    "    network_type=NETWORK_TYPE, \n",
    "    time_step_spec=time_step_spec, \n",
    "    action_spec=action_spec, \n",
    "    observation_spec=observation_spec,\n",
    "    global_step = global_step,\n",
    "    global_layers = GLOBAL_LAYERS,\n",
    "    arm_layers = ARM_LAYERS,\n",
    "    common_layers = COMMON_LAYERS,\n",
    "    agent_alpha = AGENT_ALPHA,\n",
    "    learning_rate = LR,\n",
    "    epsilon = EPSILON,\n",
    "    encoding_dim = ENCODING_DIM,\n",
    "    eps_phase_steps = EPS_PHASE_STEPS,\n",
    ")\n",
    "\n",
    "print(f\"Agent: {agent.name}\")\n",
    "\n",
    "if network:\n",
    "    print(f\"Network: {network}\")\n",
    "        \n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "108ed33c-d8ef-4524-97e9-ced9e01c154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHKPT_INTERVAL    : 200\n",
      "eval_batch_size   : 1\n",
      "EVAL_DATA_SIZE    : 20000\n",
      "NUM_EVAL_STEPS    : 100\n",
      "TOTAL_TRAIN_TAKE  : 10000\n"
     ]
    }
   ],
   "source": [
    "from src.perarm_features import train_perarm as train_perarm\n",
    "\n",
    "# train args\n",
    "TRAINING_LOOPS        = 150\n",
    "STEPS_PER_LOOP        = 1\n",
    "\n",
    "drop_arm_feature_fn   = None\n",
    "ASYNC_STEPS_PER_LOOP  = 1\n",
    "\n",
    "LOG_INTERVAL          = 10\n",
    "CHKPT_INTERVAL        = 200\n",
    "\n",
    "# eval args\n",
    "NUM_EVAL_STEPS = 100\n",
    "\n",
    "TOTAL_TRAIN_TAKE = 10000 #TRAINING_LOOPS * HPARAMS['batch_size']\n",
    "\n",
    "print(f\"CHKPT_INTERVAL    : {CHKPT_INTERVAL}\")\n",
    "print(f\"eval_batch_size   : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"EVAL_DATA_SIZE    : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS    : {NUM_EVAL_STEPS}\")\n",
    "print(f\"TOTAL_TRAIN_TAKE  : {TOTAL_TRAIN_TAKE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f66ff927-9a39-4abf-b247-845f0dc7721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS['eval_batch_size'])\n",
    "\n",
    "if NUM_EVAL_STEPS >= 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "61e56496-85c4-4332-bcba-35c75bb5d2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reset the train step\n",
    "# agent.train_step_counter.assign(0)\n",
    "\n",
    "# pre_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(\n",
    "#     agent.policy, use_tf_function=True\n",
    "# )\n",
    "\n",
    "# # pre_policy_tf = agent.policy\n",
    "\n",
    "# print(f\"evaluating pre-trained Agent...\")\n",
    "# start_time = time.time()\n",
    "\n",
    "# pre_val_loss, pre_preds, pre_tr_rewards = _run_bandit_eval(\n",
    "#     policy = pre_policy_tf,\n",
    "#     data = eval_ds,\n",
    "#     eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "#     per_arm_dim = PER_ARM_DIM,\n",
    "#     global_dim = GLOBAL_DIM\n",
    "# )\n",
    "# runtime_mins = int((time.time() - start_time) / 60)\n",
    "# print(f\"pre-train val_loss: {pre_val_loss}\")\n",
    "# print(f\"pre-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f6c98398-d545-4dcc-a71f-32249b5f0336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distribution_strategy: <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f693dcfe170>\n",
      "train_files: ['gs://mabv1-hybrid-vertex-bucket/data/train/ml-ratings-100k-train.tfrecord']\n",
      "train_ds_iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f693dba84f0>\n",
      "setting checkpoint_manager: gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230823-155520/root/chkpoint\n",
      "Did not find a pre-existing checkpoint. Starting from scratch.\n",
      "wrapping agent.train in tf-function\n",
      "starting_loop: 0\n",
      "starting train loop...\n",
      "step = 450: loss = 15.920000076293945\n",
      "step = 460: loss = 9.479999542236328\n",
      "step = 470: loss = 1.8799999952316284\n",
      "step = 480: loss = 1.8799999952316284\n",
      "step = 490: loss = 1.059999942779541\n",
      "step = 500: loss = 1.5099999904632568\n",
      "step = 510: loss = 1.649999976158142\n",
      "step = 520: loss = 1.3700000047683716\n",
      "step = 530: loss = 1.4900000095367432\n",
      "step = 540: loss = 1.2200000286102295\n",
      "step = 550: loss = 1.1299999952316284\n",
      "step = 560: loss = 1.2799999713897705\n",
      "step = 570: loss = 1.399999976158142\n",
      "step = 580: loss = 1.2599999904632568\n",
      "step = 590: loss = 1.2400000095367432\n",
      "runtime_mins: 0\n",
      "saved trained policy to: gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230823-155520/artifacts\n",
      "complete train job in 1 minutes\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    f\"{LOG_DIR}/train\", flush_millis=10 * 1000\n",
    ")\n",
    "\n",
    "#start the timer and training\n",
    "start_time = time.time()\n",
    "\n",
    "metric_results, agent = train_perarm.train_perarm(\n",
    "    agent = agent,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    num_iterations = TRAINING_LOOPS,\n",
    "    steps_per_loop = STEPS_PER_LOOP,\n",
    "    num_eval_steps = NUM_EVAL_STEPS,\n",
    "    # data\n",
    "    batch_size = HPARAMS['batch_size'],\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    # functions\n",
    "    _trajectory_fn = _trajectory_fn,\n",
    "    # _run_bandit_eval_fn = _run_bandit_eval,\n",
    "    # train intervals\n",
    "    chkpt_interval = CHKPT_INTERVAL,\n",
    "    log_interval = LOG_INTERVAL,\n",
    "    # dirs\n",
    "    bucket_name = BUCKET_NAME,\n",
    "    data_dir_prefix_path = DATA_GCS_PREFIX,\n",
    "    log_dir = LOG_DIR,\n",
    "    model_dir = ARTIFACTS_DIR,\n",
    "    root_dir = ROOT_DIR,\n",
    "    async_steps_per_loop = ASYNC_STEPS_PER_LOOP,\n",
    "    resume_training_loops = False,\n",
    "    use_gpu = True,\n",
    "    use_tpu = False,\n",
    "    profiler = False,\n",
    "    global_step = global_step,\n",
    "    total_train_take = TOTAL_TRAIN_TAKE,\n",
    "    train_summary_writer = train_summary_writer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"complete train job in {runtime_mins} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "177aa3ab-05b4-48f9-b434-9335bd9eb54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.439152"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(metric_results)\n",
    "metric_results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ba65417f-54e0-436e-b0d4-93cffb981ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(metric_results)\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7ba747-00d5-4908-8d0b-334ae9d2c791",
   "metadata": {},
   "source": [
    "#### eval trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c5cf9366-d9cd-4c9d-951a-99a50877a374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af82506e-95d7-4a4e-a821-e08512615db7",
   "metadata": {},
   "source": [
    "After training, our `agent.policy` is used as the deployment \"model\" that will generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6c82396a-7822-41fb-830f-1f6eb9c9b213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.epsilon_greedy_policy.EpsilonGreedyPolicy at 0x7f6e3046b250>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_agent = agent.policy\n",
    "deployment_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f6706224-ef5b-4185-bde4-bccb7c8e7ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating trained Agent...\n",
      "post-train val_loss     : 1.5619267225265503\n",
      "post-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(deployment_agent, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = _run_bandit_eval(\n",
    "    policy = post_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f899120f-3706-4b72-8f2c-2169221dd66b",
   "metadata": {},
   "source": [
    "## Using Trained Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b0f691-860e-4853-928e-4c7ece714dd0",
   "metadata": {},
   "source": [
    "### load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ea029f73-0638-462a-8f00-54b05c54d69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230823-144451/artifacts\n"
     ]
    }
   ],
   "source": [
    "POLICY_URI = ARTIFACTS_DIR\n",
    "\n",
    "print(POLICY_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "66d1d819-0152-437c-aefc-45ffd34d808a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230823-144451/artifacts/\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230823-144451/artifacts/fingerprint.pb\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230823-144451/artifacts/policy_specs.pbtxt\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230823-144451/artifacts/saved_model.pb\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230823-144451/artifacts/assets/\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-v6/run-20230823-144451/artifacts/variables/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $POLICY_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6aad948e-e346-4da3-8cb2-747435c8dc4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f68f5208eb0>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "483f8fa5-cbd1-4e3c-8e62-47f91f42e137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(), dtype=dtype('int32'), name='action_spec', minimum=0, maximum=1)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_policy.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8f658891-bc09-49b8-bc58-000a7926df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "for x in eval_ds.take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    global_feat_infer = _get_global_context_features(x)\n",
    "    arm_feat_infer = _get_per_arm_features(x)\n",
    "    rewards = _get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f515fcd0-2228-4f68-9ef9-665ce1fc3fb2",
   "metadata": {},
   "source": [
    "### view prediction response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6af4c297-d2e8-4f7b-bed5-e1da997dfe34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.3488185, 3.3488185], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=array([-0.0185369 , -0.01054313,  0.02299232,  0.01790209, -0.0432842 ,\n",
       "        0.04279194, -0.02059042, -0.01041403,  0.00541206,  0.04598064,\n",
       "       -0.04859881, -0.01024654,  0.0280082 ,  0.0302712 , -0.01774674,\n",
       "       -0.00522383, -0.04354972, -0.02023434,  0.02127668,  0.03113781,\n",
       "        0.00587643,  0.00425663, -0.04093727, -0.02917609, -0.03034178,\n",
       "        0.01464484,  0.02382381, -0.0007356 ,  0.02114633,  0.01849813,\n",
       "       -0.0296257 ,  0.03967467, -0.02054541, -0.00426638,  0.01093607,\n",
       "       -0.00982384,  0.0381597 , -0.03454971,  0.03584519, -0.04901643,\n",
       "        0.02666168, -0.02937645, -0.03581516,  0.04674163,  0.0030669 ,\n",
       "        0.02811594,  0.00339998, -0.04442865,  0.01970129,  0.01156823,\n",
       "        0.03109703, -0.03017631, -0.03212112,  0.01220644,  0.04500029,\n",
       "       -0.00624716,  0.01100324, -0.00568478, -0.0028768 ,  0.00248363,\n",
       "        0.02727387,  0.00363865, -0.04958932,  0.00938419], dtype=float32)))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd58d4b-6749-4177-8342-83ee969408c9",
   "metadata": {},
   "source": [
    "#### chosen action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d49adbbb-f747-4e4c-b82d-df88373c644f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0, dtype=int32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd12013-1d12-4197-8254-cef9138df42c",
   "metadata": {},
   "source": [
    "#### Per Arm Policy Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d6126290-546b-4702-8a1e-91f18adb05c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.3488185, 3.3488185], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=array([-0.0185369 , -0.01054313,  0.02299232,  0.01790209, -0.0432842 ,\n",
       "        0.04279194, -0.02059042, -0.01041403,  0.00541206,  0.04598064,\n",
       "       -0.04859881, -0.01024654,  0.0280082 ,  0.0302712 , -0.01774674,\n",
       "       -0.00522383, -0.04354972, -0.02023434,  0.02127668,  0.03113781,\n",
       "        0.00587643,  0.00425663, -0.04093727, -0.02917609, -0.03034178,\n",
       "        0.01464484,  0.02382381, -0.0007356 ,  0.02114633,  0.01849813,\n",
       "       -0.0296257 ,  0.03967467, -0.02054541, -0.00426638,  0.01093607,\n",
       "       -0.00982384,  0.0381597 , -0.03454971,  0.03584519, -0.04901643,\n",
       "        0.02666168, -0.02937645, -0.03581516,  0.04674163,  0.0030669 ,\n",
       "        0.02811594,  0.00339998, -0.04442865,  0.01970129,  0.01156823,\n",
       "        0.03109703, -0.03017631, -0.03212112,  0.01220644,  0.04500029,\n",
       "       -0.00624716,  0.01100324, -0.00568478, -0.0028768 ,  0.00248363,\n",
       "        0.02727387,  0.00363865, -0.04958932,  0.00938419], dtype=float32))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f66961-ebb5-4ae5-8e6f-ad73114d8353",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
