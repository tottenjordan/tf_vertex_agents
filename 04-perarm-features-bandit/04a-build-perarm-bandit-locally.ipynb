{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385307d6-2058-47ec-8da0-57f7ef5c43d6",
   "metadata": {},
   "source": [
    "# Train Bandits with per-arm features\n",
    "\n",
    "**Exploring linear and nonlinear** (e.g., those with neural network-based value functions) bandit methods for recommendations using TF-Agents\n",
    "\n",
    "> Neural linear bandits provide a nice way to leverage the representation power of deep learning and the bandit approach for uncertainty measure and efficient exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fd257-b98b-426a-a2cd-024429b014f1",
   "metadata": {},
   "source": [
    "## Load notebook config\n",
    "\n",
    "* use the prefix defined in `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f39c9d08-d118-4013-a47f-88450f49f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = 'mabv1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908f6b95-b539-4a9f-a836-840d26ea3b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"mabv1\"\n",
      "VERSION                  = \"v1\"\n",
      "\n",
      "BUCKET_NAME              = \"mabv1-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://mabv1-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://mabv1-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_ID      = \"hybrid-vertex.movielens_dataset_mabv1\"\n",
      "BIGQUERY_TABLE_ID        = \"hybrid-vertex.movielens_dataset_mabv1.training_dataset\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-mabv1\"\n",
      "IMAGE_NAME               = \"train-perarm-feats-v1\"\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-mabv1/train-perarm-feats-v1\"\n",
      "DOCKERNAME               = \"Dockerfile_perarm_feats\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c690a9-e2bd-4759-ba41-4e2469098aee",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d0dfe4-695c-4dd4-9f24-67f7488ce1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c669f1a1-1af7-4efb-ab2d-6bf3b3847991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from collections import defaultdict\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pickle as pkl\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "# from tf_agents.agents import TFAgent\n",
    "\n",
    "# from tf_agents.bandits.environments import stationary_stochastic_per_arm_py_environment as p_a_env\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "# from tf_agents.drivers import dynamic_step_driver\n",
    "# from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "# from tf_agents.bandits.agents import lin_ucb_agent\n",
    "# from tf_agents.bandits.agents import linear_thompson_sampling_agent as lin_ts_agent\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent\n",
    "from tf_agents.bandits.agents import neural_linucb_agent\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "from tf_agents.bandits.policies import policy_utilities\n",
    "\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# this repo\n",
    "from src.per_arm_rl import data_utils\n",
    "from src.per_arm_rl import data_config\n",
    "from src.per_arm_rl import train_utils as train_utils\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29e58dd7-ab2b-419f-9771-bf1e98db758b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for gpu in gpus:\n",
    "#     tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \n",
    "# gpus\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4969d3e-1fc0-45db-8a69-aa6b342019de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "274e7f4a-1802-4946-888e-876638f5c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a866b1-85b9-43e6-9546-edfbbf886bce",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd5b953-14c0-42ed-a511-77147a1bc0ac",
   "metadata": {},
   "source": [
    "### Read TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d0157c8-a04c-4dbd-b6d9-a1ede97687a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da0cdac-76af-4608-b70e-be7dbe0584b5",
   "metadata": {},
   "source": [
    "**Train data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c934c06-bf08-4c7f-b0cc-0de04ef3515c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://mabv1-hybrid-vertex-bucket/data/train/ml-ratings-100k-train.tfrecord']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPLIT = \"train\" # \"train\" | \"val\"\n",
    "\n",
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7511e4d-bf81-4800-bde7-8b16dec9aeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([35.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'898'], dtype=object)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([885409515])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'681'], dtype=object)>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'marketing'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "train_dataset = train_dataset.map(data_utils.parse_tfrecord)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452750c1-46a0-4ee1-84d4-0c3b227de38f",
   "metadata": {},
   "source": [
    "**Val data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7b5376f-9438-4304-84aa-de09c30f5e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = \"val\"\n",
    "\n",
    "val_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        val_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "val_dataset = tf.data.TFRecordDataset(val_files)\n",
    "val_dataset = val_dataset.map(data_utils.parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8959967-522e-41c8-9a1b-050ca8bc191f",
   "metadata": {},
   "source": [
    "### get vocab\n",
    "\n",
    "**TODO:** \n",
    "* streamline vocab calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b9169bc-d6dc-497e-9dff-6ebb175282ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE_VOCABS: False\n"
     ]
    }
   ],
   "source": [
    "GENERATE_VOCABS = False\n",
    "print(f\"GENERATE_VOCABS: {GENERATE_VOCABS}\")\n",
    "\n",
    "# VOCAB_SUBDIR   = \"vocabs\"\n",
    "# VOCAB_FILENAME = \"vocab_dict.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3ccf137-7a72-42e7-aa89-3c81a99cf40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab...\n",
      "Downloaded vocab from: gs://mabv1-hybrid-vertex-bucket/vocabs/vocab_dict.pkl\n",
      "\n",
      "'movie_id'\n",
      "'user_id'\n",
      "'user_occupation_text'\n",
      "'movie_genres'\n",
      "'bucketized_user_age'\n",
      "'max_timestamp'\n",
      "'min_timestamp'\n",
      "'timestamp_buckets'\n"
     ]
    }
   ],
   "source": [
    "if not GENERATE_VOCABS:\n",
    "\n",
    "    EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{VOCAB_SUBDIR}/{VOCAB_FILENAME}'\n",
    "    print(f\"Downloading vocab...\")\n",
    "    \n",
    "    os.system(f'gsutil -q cp {EXISTING_VOCAB_FILE} .')\n",
    "    print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "    filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "    vocab_dict = pkl.load(filehandler)\n",
    "    filehandler.close()\n",
    "    \n",
    "    for key in vocab_dict.keys():\n",
    "        pprint(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccaef62-882a-46ff-a1b1-3837e69fdf74",
   "metadata": {},
   "source": [
    "## helper functions\n",
    "\n",
    "**TODO:**\n",
    "* modularize in a train_utils or similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b941063b-ad48-4817-aef0-9afa8a444632",
   "metadata": {},
   "source": [
    "# Multi-Armed Bandits (MAB) with Per-Arm Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28770b8d-836b-448d-8dd1-203d76fc6d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "\n",
    "nest = tf.nest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138a295-2b0d-4359-8496-af8552ec8cff",
   "metadata": {},
   "source": [
    "# [1] Preprocessing layers for global and arm features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e28c002-8d3a-4cf4-b69b-de56a6abab90",
   "metadata": {},
   "source": [
    "The preproccesing layers will ultimately feed the two sampling functions described below. These sampling functions will be used to create [trajectories](https://github.com/tensorflow/agents/blob/master/tf_agents/trajectories/trajectory.py#L36) (i.e., the training examples for our model)\n",
    "\n",
    "`global_context_sampling_fn`: \n",
    "* A function that outputs a random 1d array or list of ints or floats\n",
    "* This output is the global context. Its shape and type must be consistent across calls.\n",
    "\n",
    "`arm_context_sampling_fn`: \n",
    "* A function that outputs a random 1 array or list of ints or floats (same type as the output of `global_context_sampling_fn`). * This output is the per-arm context. Its shape must be consistent across calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8d77956-635c-438a-916a-185eec52f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OOV_BUCKETS        = 1\n",
    "GLOBAL_EMBEDDING_SIZE  = 16\n",
    "MV_EMBEDDING_SIZE      = 32 #32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6142e63e-0a20-4d51-997c-7a4733517f7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## global context (user) features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195acd92-06b6-42e4-bef7-798fd09da856",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### user ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c28e887b-421a-4603-8899-87071056783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_id_input_layer = tf.keras.Input(\n",
    "#     name=\"user_id\",\n",
    "#     shape=(1,),\n",
    "#     dtype=tf.string\n",
    "# )\n",
    "\n",
    "# user_id_lookup = tf.keras.layers.StringLookup(\n",
    "#     max_tokens=len(vocab_dict['user_id']) + NUM_OOV_BUCKETS,\n",
    "#     num_oov_indices=NUM_OOV_BUCKETS,\n",
    "#     mask_token=None,\n",
    "#     vocabulary=vocab_dict['user_id'],\n",
    "# )(user_id_input_layer)\n",
    "\n",
    "# user_id_embedding = tf.keras.layers.Embedding(\n",
    "#     # Let's use the explicit vocabulary lookup.\n",
    "#     input_dim=len(vocab_dict['user_id']) + NUM_OOV_BUCKETS,\n",
    "#     output_dim=GLOBAL_EMBEDDING_SIZE\n",
    "# )(user_id_lookup)\n",
    "\n",
    "# user_id_embedding = tf.reduce_sum(user_id_embedding, axis=-2)\n",
    "\n",
    "# # global_inputs.append(user_id_input_layer)\n",
    "# # global_features.append(user_id_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d6a0fe7-26cb-4c62-a3ef-17f98e6ccddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_user_id_model = tf.keras.Model(inputs=user_id_input_layer, outputs=user_id_embedding)\n",
    "\n",
    "# # for x in train_dataset.batch(1).take(1):\n",
    "# #     print(x[\"user_id\"])\n",
    "# #     print(test_user_id_model(x[\"user_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352d2227-92ec-4386-926f-df2fdb9434ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### user AGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70785bf0-5ece-4875-ab72-06d9c45ea9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_age_input_layer = tf.keras.Input(\n",
    "#     name=\"bucketized_user_age\",\n",
    "#     shape=(1,),\n",
    "#     dtype=tf.float32\n",
    "# )\n",
    "\n",
    "# user_age_lookup = tf.keras.layers.IntegerLookup(\n",
    "#     vocabulary=vocab_dict['bucketized_user_age'],\n",
    "#     num_oov_indices=NUM_OOV_BUCKETS,\n",
    "#     oov_value=0,\n",
    "# )(user_age_input_layer)\n",
    "\n",
    "# user_age_embedding = tf.keras.layers.Embedding(\n",
    "#     # Let's use the explicit vocabulary lookup.\n",
    "#     input_dim=len(vocab_dict['bucketized_user_age']) + NUM_OOV_BUCKETS,\n",
    "#     output_dim=GLOBAL_EMBEDDING_SIZE\n",
    "# )(user_age_lookup)\n",
    "\n",
    "# user_age_embedding = tf.reduce_sum(user_age_embedding, axis=-2)\n",
    "\n",
    "# # global_inputs.append(user_age_input_layer)\n",
    "# # global_features.append(user_age_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e01622a-9418-4ca7-8925-9b0ebef8940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_user_age_model = tf.keras.Model(inputs=user_age_input_layer, outputs=user_age_embedding)\n",
    "\n",
    "# # for x in train_dataset.batch(1).take(1):\n",
    "# #     print(x[\"bucketized_user_age\"])\n",
    "# #     print(test_user_age_model(x[\"bucketized_user_age\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997ffaa8-ca92-4851-b7e3-bb06fba8958b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### user OCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03e7344d-71fb-423a-89dd-f1abeb270e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_occ_input_layer = tf.keras.Input(\n",
    "#     name=\"user_occupation_text\",\n",
    "#     shape=(1,),\n",
    "#     dtype=tf.string\n",
    "# )\n",
    "\n",
    "# user_occ_lookup = tf.keras.layers.StringLookup(\n",
    "#     max_tokens=len(vocab_dict['user_occupation_text']) + NUM_OOV_BUCKETS,\n",
    "#     num_oov_indices=NUM_OOV_BUCKETS,\n",
    "#     mask_token=None,\n",
    "#     vocabulary=vocab_dict['user_occupation_text'],\n",
    "# )(user_occ_input_layer)\n",
    "\n",
    "# user_occ_embedding = tf.keras.layers.Embedding(\n",
    "#     # Let's use the explicit vocabulary lookup.\n",
    "#     input_dim=len(vocab_dict['user_occupation_text']) + NUM_OOV_BUCKETS,\n",
    "#     output_dim=GLOBAL_EMBEDDING_SIZE\n",
    "# )(user_occ_lookup)\n",
    "\n",
    "# user_occ_embedding = tf.reduce_sum(user_occ_embedding, axis=-2)\n",
    "\n",
    "# # global_inputs.append(user_occ_input_layer)\n",
    "# # global_features.append(user_occ_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39cbbc31-ca43-4f8f-a804-a4b830e99d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_user_occ_model = tf.keras.Model(inputs=user_occ_input_layer, outputs=user_occ_embedding)\n",
    "\n",
    "# # for x in train_dataset.batch(1).take(1):\n",
    "# #     print(x[\"user_occupation_text\"])\n",
    "# #     print(test_user_occ_model(x[\"user_occupation_text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee0098-a48a-4de6-88bf-6219ce8c0533",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### user Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "61a4e01a-e742-4c68-93a9-aa66eb9a5e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_ts_input_layer = tf.keras.Input(\n",
    "#     name=\"timestamp\",\n",
    "#     shape=(1,),\n",
    "#     dtype=tf.int64\n",
    "# )\n",
    "\n",
    "# user_ts_lookup = tf.keras.layers.Discretization(\n",
    "#     vocab_dict['timestamp_buckets'].tolist()\n",
    "# )(user_ts_input_layer)\n",
    "\n",
    "# user_ts_embedding = tf.keras.layers.Embedding(\n",
    "#     # Let's use the explicit vocabulary lookup.\n",
    "#     input_dim=len(vocab_dict['timestamp_buckets'].tolist()) + NUM_OOV_BUCKETS,\n",
    "#     output_dim=GLOBAL_EMBEDDING_SIZE\n",
    "# )(user_ts_lookup)\n",
    "\n",
    "# user_ts_embedding = tf.reduce_sum(user_ts_embedding, axis=-2)\n",
    "\n",
    "# # global_inputs.append(user_ts_input_layer)\n",
    "# # global_features.append(user_ts_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db99f90b-57f8-45e6-9f28-871658e17358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_user_ts_model = tf.keras.Model(inputs=user_ts_input_layer, outputs=user_ts_embedding)\n",
    "\n",
    "# # for x in train_dataset.batch(1).take(1):\n",
    "# #     print(x[\"timestamp\"])\n",
    "# #     print(test_user_ts_model(x[\"timestamp\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc734ea-cb5e-4c6b-8b94-2a8853220178",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### define global sampling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff58c380-8b53-4dfa-b5b4-d36853638ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _get_global_context_features(x):\n",
    "#     \"\"\"\n",
    "#     This function generates a single global observation vector.\n",
    "#     \"\"\"\n",
    "#     user_id_value = x['user_id']\n",
    "#     user_age_value = x['bucketized_user_age']\n",
    "#     user_occ_value = x['user_occupation_text']\n",
    "#     user_ts_value = x['timestamp']\n",
    "\n",
    "#     _id = test_user_id_model(user_id_value) # input_tensor=tf.Tensor(shape=(4,), dtype=float32)\n",
    "#     _age = test_user_age_model(user_age_value)\n",
    "#     _occ = test_user_occ_model(user_occ_value)\n",
    "#     _ts = test_user_ts_model(user_ts_value)\n",
    "\n",
    "#     # # tmp - insepct numpy() values\n",
    "#     # print(_id.numpy()) #[0])\n",
    "#     # print(_age.numpy()) #[0])\n",
    "#     # print(_occ.numpy()) #[0])\n",
    "#     # print(_ts.numpy()) #[0])\n",
    "\n",
    "#     # to numpy array\n",
    "#     _id = np.array(_id.numpy())\n",
    "#     _age = np.array(_age.numpy())\n",
    "#     _occ = np.array(_occ.numpy())\n",
    "#     _ts = np.array(_ts.numpy())\n",
    "\n",
    "#     concat = np.concatenate(\n",
    "#         [_id, _age, _occ, _ts], axis=-1 # -1\n",
    "#     ).astype(np.float32)\n",
    "\n",
    "#     return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bba133ab-bf12-4b3b-926d-6d1dba940837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([35.], dtype=float32)>,\n",
       " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
       " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'898'], dtype=object)>,\n",
       " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([885409515])>,\n",
       " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'681'], dtype=object)>,\n",
       " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'marketing'], dtype=object)>,\n",
       " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in range(1):\n",
    "    \n",
    "#     iterator = iter(train_dataset.batch(1))\n",
    "#     data = next(iterator)\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c7cadad0-b5ac-461b-9efb-4867b52a8736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL_DIM: 64\n"
     ]
    }
   ],
   "source": [
    "# GLOBAL_DIM = _get_global_context_features(data).shape[1]\n",
    "# print(f\"GLOBAL_DIM: {GLOBAL_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249fa771-35d7-4d04-ab68-2b70911bac17",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## arm preprocessing layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534b3bf1-a2ea-4bfb-8c77-efa057f4e391",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### movie ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa53cbe9-2616-4da4-90dc-dc5616258af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mv_id_input_layer = tf.keras.Input(\n",
    "#     name=\"movie_id\",\n",
    "#     shape=(1,),\n",
    "#     dtype=tf.string\n",
    "# )\n",
    "\n",
    "# mv_id_lookup = tf.keras.layers.StringLookup(\n",
    "#     max_tokens=len(vocab_dict['movie_id']) + NUM_OOV_BUCKETS,\n",
    "#     num_oov_indices=NUM_OOV_BUCKETS,\n",
    "#     mask_token=None,\n",
    "#     vocabulary=vocab_dict['movie_id'],\n",
    "# )(mv_id_input_layer)\n",
    "\n",
    "# mv_id_embedding = tf.keras.layers.Embedding(\n",
    "#     # Let's use the explicit vocabulary lookup.\n",
    "#     input_dim=len(vocab_dict['movie_id']) + NUM_OOV_BUCKETS,\n",
    "#     output_dim=MV_EMBEDDING_SIZE\n",
    "# )(mv_id_lookup)\n",
    "\n",
    "# mv_id_embedding = tf.reduce_sum(mv_id_embedding, axis=-2)\n",
    "\n",
    "# # arm_inputs.append(mv_id_input_layer)\n",
    "# # arm_features.append(mv_id_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9bd19f09-a12e-4a21-a1a1-5ec5bc116559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mv_id_model = tf.keras.Model(inputs=mv_id_input_layer, outputs=mv_id_embedding)\n",
    "\n",
    "# # for x in train_dataset.batch(1).take(1):\n",
    "# #     print(x[\"movie_id\"])\n",
    "# #     print(test_mv_id_model(x[\"movie_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4a0e97-c477-4042-b9c0-fcb0f428de0d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### movie genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f04a0091-d7b0-4f90-ba7c-3eb41dd0b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mv_genre_input_layer = tf.keras.Input(\n",
    "#     name=\"movie_genres\",\n",
    "#     shape=(1,),\n",
    "#     dtype=tf.float32\n",
    "# )\n",
    "\n",
    "# mv_genre_lookup = tf.keras.layers.IntegerLookup(\n",
    "#     vocabulary=vocab_dict['movie_genres'],\n",
    "#     num_oov_indices=NUM_OOV_BUCKETS,\n",
    "#     oov_value=0,\n",
    "# )(mv_genre_input_layer)\n",
    "\n",
    "# mv_genre_embedding = tf.keras.layers.Embedding(\n",
    "#     # Let's use the explicit vocabulary lookup.\n",
    "#     input_dim=len(vocab_dict['movie_genres']) + NUM_OOV_BUCKETS,\n",
    "#     output_dim=MV_EMBEDDING_SIZE\n",
    "# )(mv_genre_lookup)\n",
    "\n",
    "# mv_genre_embedding = tf.reduce_sum(mv_genre_embedding, axis=-2)\n",
    "\n",
    "# # arm_inputs.append(mv_genre_input_layer)\n",
    "# # arm_features.append(mv_genre_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "51701f0a-9b3e-461c-a9d9-a0c146e310ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mv_gen_model = tf.keras.Model(inputs=mv_genre_input_layer, outputs=mv_genre_embedding)\n",
    "\n",
    "# for x in train_dataset.batch(1).take(1):\n",
    "#     print(x[\"movie_genres\"])\n",
    "#     print(test_mv_gen_model(x[\"movie_genres\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b41cc9-63f5-4559-a943-1288be9c0892",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### define sampling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8727904e-e9b6-4005-8cf3-9da461ca88b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _get_per_arm_features(x):\n",
    "#     \"\"\"\n",
    "#     This function generates a single per-arm observation vector\n",
    "#     \"\"\"\n",
    "#     mv_id_value = x['movie_id']\n",
    "#     mv_gen_value = x['movie_genres']\n",
    "\n",
    "#     _mid = test_mv_id_model(mv_id_value)\n",
    "#     _mgen = test_mv_gen_model(mv_gen_value)\n",
    "\n",
    "#     # to numpy array\n",
    "#     _mid = np.array(_mid.numpy())\n",
    "#     _mgen = np.array(_mgen.numpy())\n",
    "\n",
    "\n",
    "#     concat = np.concatenate(\n",
    "#         [_mid, _mgen], axis=-1 # -1\n",
    "#     ).astype(np.float32)\n",
    "#     # concat = tf.concat([_mid, _mgen], axis=-1).astype(np.float32)\n",
    "\n",
    "#     return concat #this is special to this example - there is only one action dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f2f5ba55-2e1a-4b32-b6a8-4f46ba4c2048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER_ARM_DIM: 64\n"
     ]
    }
   ],
   "source": [
    "# PER_ARM_DIM = _get_per_arm_features(data).shape[1] #shape checks out at batchdim, nactions, arm feats\n",
    "# print(f\"PER_ARM_DIM: {PER_ARM_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ea1f7-0621-44b8-b062-1f59b0964d72",
   "metadata": {},
   "source": [
    "## Global & Per-Arm feature embedding models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea335991-dcec-40b3-ba0d-a0fdfb9c2ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test emb models\n",
    "for i in range(1):\n",
    "    \n",
    "    iterator = iter(train_dataset.batch(1))\n",
    "    data = next(iterator)\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48178fff-491f-4f03-b156-7765d1fa9707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.perarm_features.emb_features.EmbeddingModel at 0x7f644e703040>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.perarm_features import emb_features as emb_features\n",
    "\n",
    "embs = emb_features.EmbeddingModel(\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "903c63c5-2468-4443-bcb8-5ff6d69810dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL_DIM: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.03096414, -0.00652953, -0.04962489, -0.04574445,  0.00762163,\n",
       "        -0.0094418 ,  0.04790444,  0.02397864,  0.03394121,  0.03845248,\n",
       "        -0.04854138, -0.02175176,  0.02807589, -0.02861007, -0.00447381,\n",
       "         0.0245983 , -0.01393074,  0.03043267, -0.01298126,  0.04188105,\n",
       "        -0.04537613, -0.00378704, -0.01769929,  0.02329672, -0.02728639,\n",
       "        -0.03637972,  0.01117314,  0.00332203, -0.0418874 ,  0.01393307,\n",
       "         0.028552  , -0.01802189,  0.0498828 , -0.01075332, -0.00892822,\n",
       "        -0.04008042, -0.00652907,  0.03392888, -0.03684707, -0.02400181,\n",
       "         0.00176112, -0.01337833, -0.00969119,  0.00908446,  0.02383939,\n",
       "         0.01310155, -0.01984283,  0.03559678, -0.01852895,  0.01948665,\n",
       "        -0.027999  ,  0.03888511,  0.03264702,  0.02533846,  0.03804607,\n",
       "         0.0103132 , -0.02785563, -0.00100758, -0.01276225, -0.01021273,\n",
       "         0.01993347, -0.01835465,  0.00372539,  0.04257511]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_globals = embs._get_global_context_features(data)\n",
    "\n",
    "GLOBAL_DIM = test_globals.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"GLOBAL_DIM: {GLOBAL_DIM}\")\n",
    "\n",
    "test_globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebec4863-c614-4248-b680-8e29ec5b730d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER_ARM_DIM: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.04189293,  0.04383738, -0.00456172, -0.02413708, -0.00298729,\n",
       "         0.04471251,  0.03985203,  0.02545903, -0.01180987,  0.04750942,\n",
       "         0.03551508, -0.02705649, -0.0383286 ,  0.00726528,  0.0373598 ,\n",
       "        -0.03573018,  0.00109245, -0.04778224, -0.00535921, -0.02226074,\n",
       "         0.00423795,  0.00463077, -0.04964687,  0.02252597,  0.03995519,\n",
       "        -0.02680382,  0.00618342,  0.03699619,  0.02478773,  0.04249949,\n",
       "         0.03529081,  0.01062858,  0.01136597, -0.04208605, -0.02547827,\n",
       "        -0.01353593, -0.0190497 , -0.01529684,  0.04273078,  0.0439737 ,\n",
       "         0.03535916,  0.00480004, -0.01952623, -0.01353852, -0.02658635,\n",
       "         0.0375492 ,  0.03890932,  0.02386879,  0.04293815,  0.02102635,\n",
       "         0.03404408, -0.04090395,  0.02929869, -0.02267798,  0.03927297,\n",
       "         0.01582119,  0.04270608,  0.00666906, -0.04628035, -0.01465869,\n",
       "        -0.00047426, -0.04193127, -0.01343584, -0.03254454]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arms = embs._get_per_arm_features(data)\n",
    "\n",
    "PER_ARM_DIM = test_arms.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"PER_ARM_DIM: {PER_ARM_DIM}\")\n",
    "\n",
    "test_arms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac6836c-67b7-4fd4-917a-24ddad708edd",
   "metadata": {},
   "source": [
    "# [2] Implementing MAB with TF-Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1877c79c-b6c8-4048-b1ce-05f011e8d69e",
   "metadata": {},
   "source": [
    "In TF-Agents, the *per-arm features* implementation differs from the *global-only* feature examples in the following aspects:\n",
    "* Reward is modeled not per-arm, but globally.\n",
    "* The arms are permutation invariant: it doesn’t matter which arm is arm 1 or arm 2, only their features.\n",
    "* One can have a different number of arms to choose from in every step (note that unspecified/dynamically changing number of arms will have a problem with XLA compatibility).\n",
    "\n",
    "When implementing per-arm features in TF-Bandits, the following details have to be discussed:\n",
    "* Observation spec and observations,\n",
    "* Action spec and actions,\n",
    "* Implementation of specific policies and agents.\n",
    "\n",
    "\n",
    "**TODO:**\n",
    "* outline the components and highlight their interactions, dependencies on eachother, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ff9baaf-987d-448d-a981-742a79b581e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE      : 128\n",
      "EVAL_BATCH_SIZE : 1\n",
      "NUM_ACTIONS     : 2\n",
      "GLOBAL_DIM      : 64\n",
      "PER_ARM_DIM     : 64\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE      = 128\n",
    "EVAL_BATCH_SIZE = 1\n",
    "\n",
    "NUM_ACTIONS     = 2 #this is kinda deceptive - \n",
    "#our approach is to learn by \"flashing\" one movie rating at a time per user context. \n",
    "#The n_actions = show/don't show the movie with one degree of freedom (n-1)\n",
    "\n",
    "\n",
    "print(f\"BATCH_SIZE      : {BATCH_SIZE}\")\n",
    "print(f\"EVAL_BATCH_SIZE : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"NUM_ACTIONS     : {NUM_ACTIONS}\")\n",
    "print(f\"GLOBAL_DIM      : {GLOBAL_DIM}\")\n",
    "print(f\"PER_ARM_DIM     : {PER_ARM_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeb4902-5bb9-4587-8d29-c01d78b006be",
   "metadata": {},
   "source": [
    "## Tensor Specs\n",
    "\n",
    "* say you have a global observation spec of `[17]`. And you have two batch dimensions `[4, 5]`. Then your observation has to have the shape `[4, 5, 17]`\n",
    "* and then if you have arm_obs_spec with shape `[9, 13]`, then the arm obs shape has to be exactly `[4, 5, 9, 13]`\n",
    "* and this has to be true for every single tensor in your tensor nest\n",
    "* the first 2 dims are the outer dims that are the same for all tensors, the rest of the dimensions have to follow the spec for each tensor\n",
    "\n",
    "**TODO:**\n",
    "* explain relationship between Tensor Specs and their Tensor counterparts\n",
    "* highlight the errors, lessons learned, and utility functions to address these"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f68ebe8-116d-43b3-a6e1-4f5a5c7f4741",
   "metadata": {},
   "source": [
    "### Observation spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9c4746-d01b-4ca4-aa53-ab68da54d37a",
   "metadata": {},
   "source": [
    "**This observation spec allows the user to have a global observation of fixed dimension**, and an unspecified number of *per-arm* features (also of fixed dimension)\n",
    "* The actions output by the policy are still integers as usual, and they indicate which row of the arm-features it has chosen \n",
    "* The action spec must be a single integer value without boundaries:\n",
    "\n",
    "```python\n",
    "global_spec = tensor_spec.TensorSpec([GLOBAL_DIM], tf.float32)\n",
    "per_arm_spec = tensor_spec.TensorSpec([None, PER_ARM_DIM], tf.float32)\n",
    "observation_spec = {'global': global_spec, 'per_arm': per_arm_spec}\n",
    "\n",
    "action_spec = tensor_spec.TensorSpec((), tf.int32)\n",
    "```\n",
    "> Here the only difference compared to the action spec with global features only is that the tensor spec is not bounded, as we don’t know how many arms there will be at any time step\n",
    "\n",
    "**XLA compatibility:**\n",
    "* Since dynamic tensor shapes are not compatible with XLA, the number of arm features (and consequently, number of arms for a step) cannot be dynamic. \n",
    "* One workaround is to fix the maximum number of arms for a problem, then pad the arm features in steps with fewer arms, and use action masking to indicate how many arms are actually active.\n",
    "\n",
    "```python\n",
    "per_arm_spec = tensor_spec.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32)\n",
    "\n",
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=(), dtype=tf.int32, minimum = 0, maximum = NUM_ACTIONS - 1\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36bd3b33-635a-4274-8b9e-7172696ebb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_spec = {\n",
    "    'global': tf.TensorSpec([GLOBAL_DIM], tf.float32),\n",
    "    'per_arm': tf.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32) #excluding action dim here\n",
    "}\n",
    "observation_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a2da92-7db2-4f42-94a7-b7bad1c8fc42",
   "metadata": {},
   "source": [
    "### Action spec\n",
    "\n",
    "> The time_step_spec and action_spec are specifications for the input time step and the output action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5af42c7-18d7-480f-a7f3-d7da3f4840eb",
   "metadata": {},
   "source": [
    "```python\n",
    "    if (\n",
    "        not tensor_spec.is_bounded(action_spec)\n",
    "        or not tensor_spec.is_discrete(action_spec)\n",
    "        or action_spec.shape.rank > 1\n",
    "        or action_spec.shape.num_elements() != 1\n",
    "    ):\n",
    "      raise NotImplementedError(\n",
    "          'action_spec must be a BoundedTensorSpec of type int32 and shape (). '\n",
    "          'Found {}.'.format(action_spec)\n",
    "      )\n",
    "```\n",
    "\n",
    "* [src](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_base_policy.py#L97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "549a123c-349a-4103-b39a-4502f47d1e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=[], \n",
    "    dtype=tf.int32,\n",
    "    minimum=tf.constant(0),            \n",
    "    maximum=NUM_ACTIONS-1, # n degrees of freedom and will dictate the expected mean reward spec shape\n",
    "    name=\"action_spec\"\n",
    ")\n",
    "\n",
    "action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36ee2635-d4e3-4468-886c-ae9c62e3c80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_num_actions: 2\n",
      "predicted_rewards_mean: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n"
     ]
    }
   ],
   "source": [
    "expected_num_actions = action_spec.maximum - action_spec.minimum + 1\n",
    "print(f\"expected_num_actions: {expected_num_actions}\")\n",
    "\n",
    "predicted_rewards_mean = tensor_spec.TensorSpec([expected_num_actions])\n",
    "print(f\"predicted_rewards_mean: {predicted_rewards_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a51efce-9f1b-42d1-bec4-7b788e3fd7e0",
   "metadata": {},
   "source": [
    "### TimeStep spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95f05860-0fbf-4a5a-8273-9c81761e0ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec = ts.time_step_spec(\n",
    "    observation_spec = observation_spec, \n",
    "    # reward_spec = _reward_spec\n",
    ")\n",
    "time_step_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9181303-6565-45f5-a293-08d50420a805",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Inspect chosen arm features spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6b526a5-997c-4621-b21c-82c6ca1d6a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90d3e03e-619e-4fa4-b817-f02b4cefd6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(64,), dtype=tf.float32, name=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_arm_features_info = (\n",
    "  policy_utilities.create_chosen_arm_features_info_spec(\n",
    "      time_step_spec.observation,\n",
    "  )\n",
    ")\n",
    "chosen_arm_features_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc427092-beb7-4baf-a2e9-b8d10629182c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - dont understand this\n",
    "bandit_policy_type = (\n",
    "    policy_utilities.BanditPolicyType.GREEDY\n",
    ")\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a4a2a33-c7d4-4d81-8082-80dfc3596741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - dont understand this\n",
    "bandit_policy_type = (\n",
    "    policy_utilities.create_bandit_policy_type_tensor_spec(shape=[1])\n",
    ")\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e7ac02b-18bd-4519-92fe-5541b1a8ddc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_spec = policy_utilities.PerArmPolicyInfo(\n",
    "  predicted_rewards_mean=predicted_rewards_mean,\n",
    "  bandit_policy_type=bandit_policy_type,\n",
    "  chosen_arm_features=chosen_arm_features_info,\n",
    ")\n",
    "info_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9c197-ae9b-461d-8956-f078b929ac12",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The Agent\n",
    "\n",
    "**Note** that contextual bandits form a special case of RL, where the actions taken by the agent do not alter the state of the environment \n",
    "\n",
    "> “Contextual” refers to the fact that the agent chooses among a set of actions while having knowledge of the context (environment observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81d6e84-688e-48c5-aea1-77df031348c9",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Agent & Network defined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aadb01-eb5c-4870-ae14-9e66624ba594",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Agent types**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d075e8a6-11a9-4346-8725-3653fba4bac4",
   "metadata": {},
   "source": [
    "> `AGENT_TYPE = ['LinUCB', 'LinTS', 'epsGreedy', 'NeuralLinUCB']`\n",
    "\n",
    "LinearUCBAgent: (`LinUCB`) \n",
    "* An agent implementing the Linear UCB bandit algorithm ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/lin_ucb_agent/LinearUCBAgent))\n",
    "\n",
    "LinearThompsonSamplingAgent: (`LinTS`) \n",
    "* Implements the Linear Thompson Sampling Agent from the [paper](https://arxiv.org/abs/1209.3352): *Thompson Sampling for Contextual Bandits with Linear Payoffs* ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/linear_thompson_sampling_agent/LinearThompsonSamplingAgent))\n",
    "\n",
    "NeuralEpsilonGreedyAgent: (`epsGreedy`) \n",
    "* A neural network based epsilon greedy agent ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_epsilon_greedy_agent/NeuralEpsilonGreedyAgent))\n",
    "\n",
    "NeuralLinUCBAgent: (`NeuralLinUCB`) \n",
    "* An agent implementing the LinUCB algorithm on top of a neural network ([docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_linucb_agent/NeuralLinUCBAgent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b8e88e-c8ea-4193-a911-0d974ef3b1a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Network types**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f547087d-5fad-4521-a584-cb46ce52897d",
   "metadata": {},
   "source": [
    "Which network architecture to use for the `epsGreedy` or `NeuralLinUCB` agents\n",
    "\n",
    "```\n",
    "NETWORK_TYPE = ['commontower', 'dotproduct']\n",
    "```\n",
    "\n",
    "**GlobalAndArmCommonTowerNetwork:** (`commontower`)\n",
    "* This network takes the output of the global and per-arm networks, and leads them through a common network, that in turn outputs reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "> * `COMMON_LAYERS` - Iterable of ints. Specifies the layers of the common tower\n",
    "* The network produced by this function can be used either in `GreedyRewardPredictionPolicy`, or `NeuralLinUCBPolicy`\n",
    "> * In the former case, the network must have `output_dim=1`, it is going to be an instance of `QNetwork`, and used in the policy as a reward prediction network\n",
    "> * In the latter case, the network will be an encoding network with its output consumed by a reward layer or a `LinUCB` method. The specified `output_dim` will be the encoding dimension\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmCommonTowerNetwork)\n",
    "\n",
    "**GlobalAndArmDotProductNetwork:** (`dotproduct`)\n",
    "* This network calculates the **dot product** of the output of the global and per-arm networks and returns them as reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmDotProductNetwork)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3dc270-deb5-4e96-8276-74759a06c318",
   "metadata": {},
   "source": [
    "### Agent config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bbe29263-453d-405e-ac50-fee7f379f335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\n",
      "\n",
      "time_step_spec:  TimeStep(\n",
      "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
      "                 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)},\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n",
      "\n",
      "action_spec:  BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))\n",
      "\n",
      "observation_spec:  {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\")\n",
    "print(\"\\ntime_step_spec: \", time_step_spec)\n",
    "print(\"\\naction_spec: \", action_spec)\n",
    "print(\"\\nobservation_spec: \", observation_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d817bf2-1fa6-4bae-af90-745fad996b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'common_layers': [16, 8],\n",
      " 'epsilon': 0.01,\n",
      " 'eval_batch_size': 1,\n",
      " 'global_layers': [64, 32, 16],\n",
      " 'learning_rate': 0.05,\n",
      " 'model_type': 'epsGreedy',\n",
      " 'network_type': 'commontower',\n",
      " 'num_actions': 2,\n",
      " 'per_arm_layers': [64, 32, 16]}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Agents\n",
    "# ================================\n",
    "AGENT_TYPE      = 'epsGreedy' # 'LinUCB' | 'LinTS |, 'epsGreedy' | 'NeuralLinUCB'\n",
    "\n",
    "# Parameters for linear agents (LinUCB and LinTS).\n",
    "AGENT_ALPHA     = 0.1\n",
    "\n",
    "# Parameters for neural agents (NeuralEpsGreedy and NerualLinUCB).\n",
    "EPSILON         = 0.01\n",
    "LR              = 0.05\n",
    "\n",
    "# Parameters for NeuralLinUCB\n",
    "ENCODING_DIM    = 1\n",
    "EPS_PHASE_STEPS = 1000\n",
    "\n",
    "# ================================\n",
    "# Agent's Preprocess Network\n",
    "# ================================\n",
    "NETWORK_TYPE    = \"commontower\" # 'commontower' | 'dotproduct'\n",
    "\n",
    "if AGENT_TYPE == 'NeuralLinUCB':\n",
    "    NETWORK_TYPE = 'commontower'\n",
    "    \n",
    "GLOBAL_LAYERS   = [64, 32, 16]\n",
    "ARM_LAYERS      = [64, 32, 16]\n",
    "COMMON_LAYERS   = [16, 8]\n",
    "\n",
    "HPARAMS = {  # TODO - streamline and consolidate\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"eval_batch_size\" : EVAL_BATCH_SIZE,\n",
    "    \"num_actions\": NUM_ACTIONS,\n",
    "    \"model_type\": AGENT_TYPE,\n",
    "    \"network_type\": NETWORK_TYPE,\n",
    "    \"global_layers\": GLOBAL_LAYERS,\n",
    "    \"per_arm_layers\": ARM_LAYERS,\n",
    "    \"common_layers\": COMMON_LAYERS,\n",
    "    \"learning_rate\": LR,\n",
    "    \"epsilon\": EPSILON,\n",
    "}\n",
    "pprint(HPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2bf060bb-9880-40b4-8583-dd7a3f915bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent: NeuralEpsGreedyAgent\n"
     ]
    }
   ],
   "source": [
    "from src.perarm_features import agent_factory as agent_factory\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "    agent_type = AGENT_TYPE,\n",
    "    network_type = NETWORK_TYPE,\n",
    "    time_step_spec = time_step_spec,\n",
    "    action_spec = action_spec,\n",
    "    observation_spec=observation_spec,\n",
    "    global_layers = GLOBAL_LAYERS,\n",
    "    arm_layers = ARM_LAYERS,\n",
    "    common_layers = COMMON_LAYERS,\n",
    "    agent_alpha = AGENT_ALPHA,\n",
    "    learning_rate = LR,\n",
    "    epsilon = EPSILON,\n",
    "    train_step_counter = global_step,\n",
    "    output_dim = ENCODING_DIM,\n",
    "    eps_phase_steps = EPS_PHASE_STEPS,\n",
    ")\n",
    "      \n",
    "agent.initialize()\n",
    "print(f'agent: {agent.name}')\n",
    "\n",
    "# if network:\n",
    "#     print(f\"Network: {network}\")\n",
    "\n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {NETWORK_TYPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d77d1-a0b3-4898-adf0-0b32bfaf5bd7",
   "metadata": {},
   "source": [
    "#### tmp - debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78ca56e7-a386-4bf4-8c2b-3d1665521f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41483f5a-bda6-48a4-9e1c-88d8b4afeea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 64), dtype=tf.float32, name=None)}),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.time_step_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f205716-f265-4ca8-81a7-4799de8f60a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(Trajectory(\n",
       "{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32)),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None)}),\n",
       " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=TensorSpec(shape=(64,), dtype=tf.float32, name=None)),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.training_data_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d404dae-3cc3-4f81-962b-4641455ca4f2",
   "metadata": {},
   "source": [
    "## Reward function\n",
    "\n",
    "**TODO:**\n",
    "* explain how to translate reward to this common recommendation objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "df9aecd6-d20a-48a7-9ead-4da3bbcfdae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_rewards(element):\n",
    "    \"\"\"Calculates reward for the actions.\"\"\"\n",
    "\n",
    "    def _calc_reward(x):\n",
    "        \"\"\"Calculates reward for a single action.\"\"\"\n",
    "        r0 = lambda: tf.constant(0.0)\n",
    "        r1 = lambda: tf.constant(1.0)\n",
    "        r2 = lambda: tf.constant(2.0)\n",
    "        r3 = lambda: tf.constant(3.0)\n",
    "        r4 = lambda: tf.constant(4.0)\n",
    "        r5 = lambda: tf.constant(5.0)\n",
    "        c1 = tf.equal(x, 1.0)\n",
    "        c2 = tf.equal(x, 2.0)\n",
    "        c3 = tf.equal(x, 3.0)\n",
    "        c4 = tf.equal(x, 4.0)\n",
    "        c5 = tf.equal(x, 5.0)\n",
    "        return tf.case(\n",
    "            [(c1, r1), (c2, r2), (c3, r3),(c4, r4),(c5, r5)], \n",
    "            default=r0, exclusive=True\n",
    "        )\n",
    "\n",
    "    return tf.map_fn(\n",
    "        fn=_calc_reward, \n",
    "        elems=element['user_rating'], \n",
    "        dtype=tf.float32\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac59703a-9a00-4eba-a3b7-45b21b738dd4",
   "metadata": {},
   "source": [
    "## Trajectory function\n",
    "\n",
    "**parking lot**\n",
    "* does trajectory fn need concept of `dummy_chosen_arm_features`, similar to [this](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_base_policy.py#L297)\n",
    "\n",
    "```python\n",
    "      dummy_chosen_arm_features = tf.nest.map_structure(\n",
    "          lambda obs: tf.zeros_like(obs[:, 0, ...]),\n",
    "          time_step.observation[bandit_spec_utils.PER_ARM_FEATURE_KEY],\n",
    "      )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c16aa7b-f328-425e-b02e-a3fc7f200859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.perarm_features import reward_factory as reward_factory\n",
    "# from src.perarm_features import agent_factory as agent_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3605d9f-d239-4871-9a61-6e9b21f9c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _trajectory_fn(element): # hparams\n",
    "    \n",
    "    \"\"\"Converts a dataset element into a trajectory.\"\"\"\n",
    "    # global_features = _get_global_context_features(element)\n",
    "    # arm_features = _get_per_arm_features(element)\n",
    "    \n",
    "    global_features = embs._get_global_context_features(element)\n",
    "    arm_features = embs._get_per_arm_features(element)\n",
    "    \n",
    "    # Adds a time dimension.\n",
    "    arm_features = train_utils._add_outer_dimension(arm_features)\n",
    "\n",
    "    # obs spec\n",
    "    observation = {\n",
    "        bandit_spec_utils.GLOBAL_FEATURE_KEY:\n",
    "            train_utils._add_outer_dimension(global_features),\n",
    "    }\n",
    "\n",
    "    # reward = train_utils._add_outer_dimension(_get_rewards(element))\n",
    "    reward = train_utils._add_outer_dimension(reward_factory._get_rewards(element))\n",
    "\n",
    "    # To emit the predicted rewards in policy_info, we need to create dummy\n",
    "    # rewards to match the definition in TensorSpec for the ones specified in\n",
    "    # emit_policy_info set.\n",
    "    dummy_rewards = tf.zeros([HPARAMS['batch_size'], 1, HPARAMS['num_actions']])\n",
    "    policy_info = policy_utilities.PerArmPolicyInfo(\n",
    "        chosen_arm_features=arm_features,\n",
    "        # Pass dummy mean rewards here to match the model_spec for emitting\n",
    "        # mean rewards in policy info\n",
    "        predicted_rewards_mean=dummy_rewards,\n",
    "        bandit_policy_type=policy_utilities.BanditPolicyType.GREEDY\n",
    "    )\n",
    "    \n",
    "    if HPARAMS['model_type'] == 'neural_ucb':\n",
    "        policy_info = policy_info._replace(\n",
    "            predicted_rewards_optimistic=dummy_rewards\n",
    "        )\n",
    "        \n",
    "    return trajectory.single_step(\n",
    "        observation=observation,\n",
    "        action=tf.zeros_like(\n",
    "            reward, dtype=tf.int32\n",
    "        ),  # Arm features are copied from policy info, put dummy zeros here\n",
    "        policy_info=policy_info,\n",
    "        reward=reward,\n",
    "        discount=tf.zeros_like(reward)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a0989c-5a06-4fd5-a12d-d92dbbe71a76",
   "metadata": {},
   "source": [
    "Inspect the trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "257791d1-c97c-48c0-bc92-f5a4737b6c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in train_dataset.batch(HPARAMS['batch_size']).take(1):\n",
    "    test_traj = _trajectory_fn(x)\n",
    "    \n",
    "# test_traj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d8994e-ce28-4fd9-8e3b-153451d014d9",
   "metadata": {},
   "source": [
    "#### tmp - debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a0e451f-1ad8-4af2-84d6-ddc5eaac0e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.action.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.action.shape: {test_traj.action.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "52ed1767-12ce-404c-9caf-0974d55ec5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.discount.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.discount.shape: {test_traj.discount.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "033ff16b-0158-477f-835f-99deec636b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.reward.shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.reward.shape: {test_traj.reward.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee5aded7-7f9c-4a88-868c-f6ab58a0e704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_traj.observation.shape: (128, 1, 64)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_traj.observation.shape: {test_traj.observation['global'].shape}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cb47f4-03b7-424f-ae40-6d00390782b1",
   "metadata": {},
   "source": [
    "#### TODO: write trajectories to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0b9d6180-4b3f-49cc-92f9-b7bce48c329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAJECTORY_SUBDIR = \"trajectories\"\n",
    "# os.mkdir(f'{TRAJECTORY_SUBDIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "52cb38f2-6fcb-4de6-b70f-3d55a5785500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCAL_FILENAME = f\"trajectories_{HPARAMS['batch_size']}\"\n",
    "\n",
    "# print(LOCAL_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcbfc9a-049e-49b9-b2a3-ecb9fd4b9964",
   "metadata": {},
   "source": [
    "# [3] Training the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13adc1ef-b50e-41a3-9b95-c128d0c55a2b",
   "metadata": {},
   "source": [
    "## set Vertex Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e861fb27-df24-4821-8448-cf1346b186f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : mab-local-classy-v1\n",
      "RUN_NAME          : run-20230824-123848\n",
      "\n",
      "BASE_OUTPUT_DIR   : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-123848\n",
      "LOG_DIR           : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-123848/logs\n",
      "ROOT_DIR          : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-123848/root\n",
      "ARTIFACTS_DIR     : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-123848/artifacts\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME   = f'mab-local-classy-v1'\n",
    "\n",
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b7a5e4-efff-490b-b431-53037a2f4a16",
   "metadata": {},
   "source": [
    "## eval loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba0392e-90c8-4dc8-8df2-6d2af1ade490",
   "metadata": {},
   "source": [
    "> When evaluating an epsilon-greedy bandit, we need to remove those predictions that come from the `uniform_random` policy. We only want the predictions from the `GREEDY` policy, becasue we want to know how the model performs when it is actually used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "95b0c355-8976-479f-b61a-3e78fb147d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# eval loop\n",
    "# ====================================================\n",
    "\n",
    "def _run_bandit_eval(\n",
    "    policy,\n",
    "    data,\n",
    "    eval_batch_size,\n",
    "    per_arm_dim,\n",
    "    global_dim,\n",
    "):\n",
    "    logged_rewards = []\n",
    "    predicted_rewards = []\n",
    "    trouble_list = []\n",
    "    train_loss_results = []\n",
    "    \n",
    "    dummy_arm = tf.zeros([eval_batch_size, per_arm_dim], dtype=tf.float32)\n",
    "\n",
    "    for x in data:\n",
    "        # get feature tensors\n",
    "        \n",
    "        # global_feat_infer = _get_global_context_features(x)\n",
    "        # arm_feat_infer = _get_per_arm_features(x)\n",
    "        \n",
    "        global_feat_infer = embs._get_global_context_features(x)\n",
    "        arm_feat_infer = embs._get_per_arm_features(x)\n",
    "        \n",
    "        # rewards = _get_rewards(x)\n",
    "        rewards = reward_factory._get_rewards(x)\n",
    "\n",
    "        # reshape arm features\n",
    "        arm_feat_infer = tf.reshape(arm_feat_infer, [eval_batch_size, per_arm_dim])\n",
    "        concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "\n",
    "        # flatten global\n",
    "        flat_global_infer = tf.reshape(global_feat_infer, [global_dim])\n",
    "        feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "\n",
    "        # get actual reward\n",
    "        actual_reward = rewards.numpy()[0]\n",
    "        # logged_rewards.append(actual_reward)\n",
    "\n",
    "        # build trajectory step\n",
    "        trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "        \n",
    "        # pred w/ trained agent\n",
    "        prediction = policy.action(trajectory_step)\n",
    "        # prediction = trained_policy.action(trajectory_step)\n",
    "        # prediction_list.append(prediction)\n",
    "\n",
    "        predicted_rewards_mean = prediction.info.predicted_rewards_mean #[0]\n",
    "        # pred_rewards_mean_list.append(predicted_rewards_mean)\n",
    "        \n",
    "        predicted_reward_tf = tf.gather(\n",
    "            predicted_rewards_mean,\n",
    "            prediction.action, \n",
    "            batch_dims=0, \n",
    "            axis=-1\n",
    "        )\n",
    "\n",
    "        pred_reward = float(round(predicted_reward_tf.numpy()))\n",
    "\n",
    "        # When the uniform random policy is used, the \n",
    "        #    loss is meaningless for evaluation\n",
    "        # > discard preds from uniform random policy\n",
    "        # > keep preds from greedy policy, \n",
    "        if pred_reward < 0:\n",
    "            trouble_list.append(pred_reward)\n",
    "        elif pred_reward > 5:\n",
    "            trouble_list.append(pred_reward)\n",
    "        else:\n",
    "            predicted_rewards.append(pred_reward)\n",
    "\n",
    "            pred_loss = tf.keras.metrics.mean_squared_error(\n",
    "                rewards, predicted_reward_tf\n",
    "            )\n",
    "            train_loss_results.append(pred_loss)\n",
    "            logged_rewards.append(actual_reward)\n",
    "            \n",
    "    # calculate avg loss\n",
    "    avg_eval_loss = tf.reduce_mean(train_loss_results)\n",
    "    \n",
    "    return (\n",
    "        avg_eval_loss,\n",
    "        predicted_rewards,\n",
    "        logged_rewards,\n",
    "        # train_loss_results\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b3d3c-75f7-46f4-9a1b-6329e419b7f5",
   "metadata": {},
   "source": [
    "## train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "97cfe7c3-4022-47a9-83c2-df0ad8a2abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.metrics import export_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.utils import common\n",
    "\n",
    "# from src.per_arm_rl import train_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bb7ffc-00df-4d46-857b-86c87b78f597",
   "metadata": {},
   "source": [
    "`agent.train(experience=...)`\n",
    "\n",
    "where `experience` is a batch of trajectories data in the form of a Trajectory. \n",
    "* The structure of experience must match that of `self.training_data_spec`. \n",
    "* All tensors in experience must be shaped [batch, time, ...] where time must be equal to self.train_step_length if that property is not None."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94d6d45-c71e-4fe4-9af8-af9a8bda4e4f",
   "metadata": {},
   "source": [
    "### logs & checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "049ee49b-3b1a-4b12-a360-15e759dff7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('metrics: [<tf_agents.metrics.tf_metrics.AverageReturnMetric object at '\n",
      " '0x7f644e703760>]')\n",
      "setting checkpoint_manager: gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-123848/root/chkpoint\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    f\"{LOG_DIR}/train\", flush_millis=10 * 1000\n",
    ")\n",
    "# train_summary_writer.set_as_default()\n",
    "\n",
    "# eval_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "#     f\"{LOG_DIR}/eval\", flush_millis=10 * 1000\n",
    "# )\n",
    "# ====================================================\n",
    "# metrics\n",
    "# ====================================================\n",
    "step_metric = tf_metrics.EnvironmentSteps()\n",
    "metrics = [\n",
    "    # tf_metrics.NumberOfEpisodes(),\n",
    "    # tf_metrics.AverageEpisodeLengthMetric(batch_size=HPARAMS['batch_size']),\n",
    "    tf_metrics.AverageReturnMetric(batch_size=HPARAMS['batch_size'])\n",
    "]\n",
    "\n",
    "pprint(f\"metrics: {metrics}\")\n",
    "\n",
    "# ====================================================\n",
    "# get checkpoint manager\n",
    "# ====================================================\n",
    "CHKPOINT_DIR = f\"{ROOT_DIR}/chkpoint\"\n",
    "print(f\"setting checkpoint_manager: {CHKPOINT_DIR}\")\n",
    "\n",
    "checkpoint_manager = train_utils.restore_and_get_checkpoint_manager(\n",
    "    root_dir=CHKPOINT_DIR, \n",
    "    agent=agent, \n",
    "    metrics=metrics, \n",
    "    step_metric=step_metric\n",
    ")\n",
    "# ====================================================\n",
    "# policy saver\n",
    "# ====================================================\n",
    "saver = policy_saver.PolicySaver(\n",
    "    agent.policy, \n",
    "    train_step=global_step\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83683f4b-8a1a-44b9-8d5f-7ee3304c794c",
   "metadata": {},
   "source": [
    "### config\n",
    "\n",
    "* calculate train & val dataset sizes\n",
    "* define logging and chkpt intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f9432613-6583-4828-8a2a-dd939adbc3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_DATA_SIZE : 80000\n",
      "NUM_TRAIN_STEPS : 300\n",
      "EVAL_DATA_SIZE : 20000\n",
      "NUM_EVAL_STEPS : 10000\n",
      "CHKPT_INTERVAL: 300\n",
      "LOG_INTERVAL : 10\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA_SIZE = 80000          # len(list(train_dataset))\n",
    "NUM_TRAIN_STEPS = 300            # TRAIN_DATA_SIZE // HPARAMS['batch_size']\n",
    "\n",
    "EVAL_DATA_SIZE  = 20000          # len(list(val_dataset))\n",
    "NUM_EVAL_STEPS  = 10000          # EVAL_DATA_SIZE // HPARAMS['eval_batch_size']\n",
    "\n",
    "CHKPT_INTERVAL  = NUM_TRAIN_STEPS # // 5\n",
    "LOG_INTERVAL    = 10\n",
    "# EVAL_INTERVAL = NUM_TRAIN_STEPS // 2\n",
    "\n",
    "print(f\"TRAIN_DATA_SIZE : {TRAIN_DATA_SIZE}\")\n",
    "print(f\"NUM_TRAIN_STEPS : {NUM_TRAIN_STEPS}\")\n",
    "print(f\"EVAL_DATA_SIZE : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS : {NUM_EVAL_STEPS}\")\n",
    "print(f\"CHKPT_INTERVAL: {CHKPT_INTERVAL}\")\n",
    "print(f\"LOG_INTERVAL : {LOG_INTERVAL}\")\n",
    "# print(f\"EVAL_INTERVAL : {EVAL_INTERVAL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "379ffc65-4eec-4af1-8fd4-912ef65a9808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec={'bucketized_user_age': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'movie_genres': TensorSpec(shape=(None, 1), dtype=tf.int64, name=None), 'movie_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'timestamp': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'user_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_occupation_text': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_rating': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data\n",
    "train_ds_iterator = iter(train_dataset.batch(HPARAMS['batch_size']).repeat())\n",
    "\n",
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS[\"eval_batch_size\"])\n",
    "\n",
    "if NUM_EVAL_STEPS > 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)\n",
    "\n",
    "# eval_ds = eval_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "eval_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e498d7e3-d166-4e1d-94a5-f721de58694a",
   "metadata": {},
   "source": [
    "### run train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "da4680f3-693b-4530-8e4d-88bc43036c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating pre-trained Agent...\n",
      "pre-train val_loss     : 15.133792877197266\n",
      "pre-train eval runtime : 4\n",
      "starting train loop...\n",
      "step = 0: train loss = 15.920000076293945\n",
      "step = 10: train loss = 11.890000343322754\n",
      "step = 20: train loss = 9.579999923706055\n",
      "step = 30: train loss = 3.059999942779541\n",
      "step = 40: train loss = 1.559999942779541\n",
      "step = 50: train loss = 1.3600000143051147\n",
      "step = 60: train loss = 1.4299999475479126\n",
      "step = 70: train loss = 1.4700000286102295\n",
      "step = 80: train loss = 1.4199999570846558\n",
      "step = 90: train loss = 1.3600000143051147\n",
      "step = 100: train loss = 1.440000057220459\n",
      "step = 110: train loss = 1.3200000524520874\n",
      "step = 120: train loss = 1.1299999952316284\n",
      "step = 130: train loss = 0.9900000095367432\n",
      "step = 140: train loss = 1.1399999856948853\n",
      "step = 150: train loss = 1.340000033378601\n",
      "step = 160: train loss = 1.3300000429153442\n",
      "step = 170: train loss = 1.2000000476837158\n",
      "step = 180: train loss = 1.5099999904632568\n",
      "step = 190: train loss = 1.3200000524520874\n",
      "step = 200: train loss = 1.2000000476837158\n",
      "step = 210: train loss = 1.2699999809265137\n",
      "step = 220: train loss = 1.2000000476837158\n",
      "step = 230: train loss = 1.2599999904632568\n",
      "step = 240: train loss = 1.2599999904632568\n",
      "step = 250: train loss = 1.2699999809265137\n",
      "step = 260: train loss = 1.1699999570846558\n",
      "step = 270: train loss = 1.3899999856948853\n",
      "step = 280: train loss = 1.1200000047683716\n",
      "step = 290: train loss = 1.1399999856948853\n",
      "train runtime_mins: 2\n",
      "saved trained policy to: gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-123848/artifacts\n",
      "evaluating trained Agent...\n",
      "post-train val_loss     : 1.2236460447311401\n",
      "post-train eval runtime : 4\n"
     ]
    }
   ],
   "source": [
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "# agent.train = common.function(agent.train)\n",
    "\n",
    "list_o_loss = []\n",
    "\n",
    "# ====================================================\n",
    "# Evaluate the agent's policy once before training\n",
    "# ====================================================\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "pre_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "\n",
    "print(f\"evaluating pre-trained Agent...\")\n",
    "start_time = time.time()\n",
    "\n",
    "pre_val_loss, pre_preds, pre_tr_rewards = _run_bandit_eval(\n",
    "    policy = pre_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"pre-train val_loss     : {pre_val_loss}\")\n",
    "print(f\"pre-train eval runtime : {runtime_mins}\")\n",
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "print(f\"starting train loop...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# for i in tqdm(range(NUM_TRAIN_STEPS)):\n",
    "for i in range(NUM_TRAIN_STEPS):\n",
    "    \n",
    "    with train_summary_writer.as_default():\n",
    "\n",
    "        data = next(train_ds_iterator)\n",
    "        trajectories = _trajectory_fn(data)\n",
    "\n",
    "        # All tensors in experience must be shaped [batch, time, ...] \n",
    "        step = agent.train_step_counter.numpy()\n",
    "        loss = agent.train(experience=trajectories)\n",
    "        list_o_loss.append(loss.loss.numpy())\n",
    "\n",
    "        train_utils._export_metrics_and_summaries(\n",
    "            step=i, \n",
    "            metrics=metrics\n",
    "        )\n",
    "\n",
    "        # print step loss\n",
    "        if step % LOG_INTERVAL == 0:\n",
    "            print(\n",
    "                'step = {0}: train loss = {1}'.format(\n",
    "                    step, round(loss.loss.numpy(), 2)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if i > 0 and i % CHKPT_INTERVAL == 0:\n",
    "            saver.save(os.path.join(CHKPOINT_DIR, 'policy_%d' % step_metric.result()))\n",
    "            print(f\"saved policy to: {CHKPOINT_DIR}\")\n",
    "   \n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"train runtime_mins: {runtime_mins}\")\n",
    "\n",
    "saver.save(ARTIFACTS_DIR)\n",
    "print(f\"saved trained policy to: {ARTIFACTS_DIR}\")\n",
    "\n",
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = _run_bandit_eval(\n",
    "    policy = post_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "17b2b0d2-9795-4367-b57b-c331e94d1000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.223646"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb1ed8-f67b-4e7b-9cbc-70edd50e49ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate train job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff31fe28-2f05-499f-b1cc-505f3c9074e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### train loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "41937f9a-6c28-48d2-bc7c-bfe4372c7cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_o_loss)\n",
    "# plt.ylim([0, 10])\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e947e1-67f4-4205-99af-6921c6e9c896",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c24561b-3670-401e-ac71-7a65dc9e7b85",
   "metadata": {},
   "source": [
    "#### Load TensorBoard\n",
    "\n",
    "> load TB in-notebook:\n",
    "\n",
    "<img src=\"./imgs/anb_in_notebook_tb.png\" \n",
    "     align=\"center\" \n",
    "     width=\"750\"\n",
    "     height=\"750\"/>\n",
    "     \n",
    "<!-- tf_vertex_agents/imgs/anb_in_notebook_tb.png -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e0f77a33-0962-4af0-af97-cf05f895cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5d0509cb-0777-4d35-86c6-28c8acbcc793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-89ebb1988463d20b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-89ebb1988463d20b\");\n",
       "          const url = new URL(\"/proxy/6008/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=$LOG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc40143-30b1-479f-b9b1-fa4c07b1690e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [4] Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6c94a0-122f-4ba6-acef-5653a3cc7850",
   "metadata": {
    "tags": []
   },
   "source": [
    "## load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b1c382b5-e2e0-45a2-9c5f-ef2c468d0f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-123848/artifacts\n"
     ]
    }
   ],
   "source": [
    "POLICY_URI = ARTIFACTS_DIR\n",
    "\n",
    "print(POLICY_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "68592d97-1272-4c6d-a4bd-43a6f7fe6c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f63406dc460>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910a06f-678f-4bfa-a132-10b885f871c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "567f64e1-8149-4364-b561-1a9d12581b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aff30396-e0fd-4f43-acaa-6af8b20b12cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "for x in eval_ds.take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    \n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "    \n",
    "    # rewards = _get_rewards(x)\n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e58af9ab-f4da-4857-afe5-6b8de26ed0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.6945362, 3.548005 ], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=array([-0.00748688, -0.00109429,  0.02281768,  0.02389964, -0.02606181,\n",
       "        0.03303723, -0.04066131,  0.01637788,  0.04575255, -0.02789834,\n",
       "        0.04915843, -0.01727874,  0.02383972, -0.00305638, -0.04892061,\n",
       "        0.03675783, -0.00869868,  0.02983257,  0.03898263,  0.00655975,\n",
       "        0.03887727,  0.04585433, -0.03823161,  0.04281414, -0.00119876,\n",
       "        0.04586175, -0.03088927,  0.00073617, -0.00050934, -0.0166369 ,\n",
       "       -0.04326631, -0.02768165, -0.03035653,  0.04344905, -0.01065348,\n",
       "        0.04227955, -0.03122788,  0.01939541, -0.00284283,  0.00097341,\n",
       "       -0.02681171,  0.01477491, -0.00384433,  0.01784479,  0.02782433,\n",
       "        0.01085151,  0.00826206,  0.04470105, -0.03582252,  0.03808347,\n",
       "       -0.02905878,  0.00129922,  0.01870746, -0.03094292, -0.02776368,\n",
       "       -0.02589897,  0.03168622, -0.04877759,  0.00195142, -0.03130781,\n",
       "        0.02843003,  0.00374591,  0.04814385, -0.04249697], dtype=float32)))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c85a0087-7388-4f03-9278-aace31121233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0, dtype=int32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a8266c7c-3688-46a5-a1c8-a63bb7146128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info.bandit_policy_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9712bc00-7ea0-4003-a3c7-81a0be5bc995",
   "metadata": {},
   "source": [
    "# [5] Prepare training application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f62966-123f-410e-9610-832f20566635",
   "metadata": {},
   "source": [
    "To scale this training in Vertex AI's managed training service, we need to package all our code into a python application\n",
    "\n",
    "* This means, we need to modularize all steps executed up until this point. For example, the training loop we ran above is further parameterized in `train_perarm.py`, which will be called from our `task.py` when we submit the job to Vertex AI\n",
    "* This training package will eventually be used to create a custom training image (more on that in `04b-build-training-image` notebook)\n",
    "* For additional details on preparing the training application for Vertex AI, check out [the documentation](https://cloud.google.com/vertex-ai/docs/training/code-requirements) and [this code example](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage2/get_started_vertex_training.ipynb) (which also has good, related commentary)\n",
    "\n",
    "**The remaining cells will repeat steps executed above**\n",
    "> we are just illustrating / validating that they are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1129ee41-b43c-4d5a-b656-cdac6b79688c",
   "metadata": {},
   "source": [
    "#### Vertex Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ef509680-4d19-4efa-9f01-21039e0d573b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : mab-local-classy-v1\n"
     ]
    }
   ],
   "source": [
    "# using same experiment name \n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7ad98430-d836-40f1-8e4f-eb46f0c91fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : mab-local-classy-v1\n",
      "RUN_NAME          : run-20230824-130407\n",
      "\n",
      "BASE_OUTPUT_DIR   : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-130407\n",
      "LOG_DIR           : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-130407/logs\n",
      "ROOT_DIR          : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-130407/root\n",
      "ARTIFACTS_DIR     : gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-130407/artifacts\n"
     ]
    }
   ],
   "source": [
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fbdecf78-94c5-4f8c-a6c0-86f2eace4663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: NeuralEpsGreedyAgent\n",
      "Network: commontower\n"
     ]
    }
   ],
   "source": [
    "# from src.perarm_features import agent_factory as agent_factory\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "    agent_type = AGENT_TYPE,\n",
    "    network_type = NETWORK_TYPE,\n",
    "    time_step_spec = time_step_spec,\n",
    "    action_spec = action_spec,\n",
    "    observation_spec=observation_spec,\n",
    "    global_layers = GLOBAL_LAYERS,\n",
    "    arm_layers = ARM_LAYERS,\n",
    "    common_layers = COMMON_LAYERS,\n",
    "    agent_alpha = AGENT_ALPHA,\n",
    "    learning_rate = LR,\n",
    "    epsilon = EPSILON,\n",
    "    train_step_counter = global_step,\n",
    "    output_dim = ENCODING_DIM,\n",
    "    eps_phase_steps = EPS_PHASE_STEPS,\n",
    ")\n",
    "\n",
    "print(f\"Agent: {agent.name}\")\n",
    "\n",
    "# if network:\n",
    "#     print(f\"Network: {network}\")\n",
    "\n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {NETWORK_TYPE}\")\n",
    "        \n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "108ed33c-d8ef-4524-97e9-ced9e01c154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHKPT_INTERVAL    : 200\n",
      "eval_batch_size   : 1\n",
      "EVAL_DATA_SIZE    : 20000\n",
      "NUM_EVAL_STEPS    : 100\n",
      "TOTAL_TRAIN_TAKE  : 10000\n"
     ]
    }
   ],
   "source": [
    "from src.perarm_features import train_perarm as train_perarm\n",
    "\n",
    "# train args\n",
    "TRAINING_LOOPS        = 150\n",
    "STEPS_PER_LOOP        = 1\n",
    "\n",
    "drop_arm_feature_fn   = None\n",
    "ASYNC_STEPS_PER_LOOP  = 1\n",
    "\n",
    "LOG_INTERVAL          = 10\n",
    "CHKPT_INTERVAL        = 200\n",
    "\n",
    "# eval args\n",
    "NUM_EVAL_STEPS = 100\n",
    "\n",
    "TOTAL_TRAIN_TAKE = 10000 #TRAINING_LOOPS * HPARAMS['batch_size']\n",
    "\n",
    "print(f\"CHKPT_INTERVAL    : {CHKPT_INTERVAL}\")\n",
    "print(f\"eval_batch_size   : {EVAL_BATCH_SIZE}\")\n",
    "print(f\"EVAL_DATA_SIZE    : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS    : {NUM_EVAL_STEPS}\")\n",
    "print(f\"TOTAL_TRAIN_TAKE  : {TOTAL_TRAIN_TAKE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f66ff927-9a39-4abf-b247-845f0dc7721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS['eval_batch_size'])\n",
    "\n",
    "if NUM_EVAL_STEPS >= 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f6c98398-d545-4dcc-a71f-32249b5f0336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distribution_strategy: <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f63406dc730>\n",
      "train_files: ['gs://mabv1-hybrid-vertex-bucket/data/train/ml-ratings-100k-train.tfrecord']\n",
      "train_ds_iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f5ea520bb50>\n",
      "setting checkpoint_manager: gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-130407/root/chkpoint\n",
      "Did not find a pre-existing checkpoint. Starting from scratch.\n",
      "wrapping agent.train in tf-function\n",
      "starting_loop: 0\n",
      "starting train loop...\n",
      "step = 300: loss = 15.90999984741211\n",
      "step = 310: loss = 1.899999976158142\n",
      "step = 320: loss = 2.0199999809265137\n",
      "step = 330: loss = 1.190000057220459\n",
      "step = 340: loss = 1.0\n",
      "step = 350: loss = 1.2999999523162842\n",
      "step = 360: loss = 1.440000057220459\n",
      "step = 370: loss = 1.350000023841858\n",
      "step = 380: loss = 1.2999999523162842\n",
      "step = 390: loss = 1.340000033378601\n",
      "step = 400: loss = 1.5700000524520874\n",
      "step = 410: loss = 1.399999976158142\n",
      "step = 420: loss = 1.2799999713897705\n",
      "step = 430: loss = 0.9399999976158142\n",
      "step = 440: loss = 1.2000000476837158\n",
      "runtime_mins: 0\n",
      "saved trained policy to: gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-130407/artifacts\n",
      "complete train job in 1 minutes\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    f\"{LOG_DIR}/train\", flush_millis=10 * 1000\n",
    ")\n",
    "\n",
    "#start the timer and training\n",
    "start_time = time.time()\n",
    "\n",
    "metric_results, agent = train_perarm.train_perarm(\n",
    "    agent = agent,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    num_iterations = TRAINING_LOOPS,\n",
    "    steps_per_loop = STEPS_PER_LOOP,\n",
    "    num_eval_steps = NUM_EVAL_STEPS,\n",
    "    # data\n",
    "    batch_size = HPARAMS['batch_size'],\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    # functions\n",
    "    _trajectory_fn = _trajectory_fn,\n",
    "    # _run_bandit_eval_fn = _run_bandit_eval,\n",
    "    # train intervals\n",
    "    chkpt_interval = CHKPT_INTERVAL,\n",
    "    log_interval = LOG_INTERVAL,\n",
    "    # dirs\n",
    "    bucket_name = BUCKET_NAME,\n",
    "    data_dir_prefix_path = DATA_GCS_PREFIX,\n",
    "    log_dir = LOG_DIR,\n",
    "    model_dir = ARTIFACTS_DIR,\n",
    "    root_dir = ROOT_DIR,\n",
    "    async_steps_per_loop = ASYNC_STEPS_PER_LOOP,\n",
    "    resume_training_loops = False,\n",
    "    use_gpu = True,\n",
    "    use_tpu = False,\n",
    "    profiler = False,\n",
    "    global_step = global_step,\n",
    "    total_train_take = TOTAL_TRAIN_TAKE,\n",
    "    train_summary_writer = train_summary_writer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"complete train job in {runtime_mins} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "177aa3ab-05b4-48f9-b434-9335bd9eb54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4370875"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(metric_results)\n",
    "metric_results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ba65417f-54e0-436e-b0d4-93cffb981ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(metric_results)\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7ba747-00d5-4908-8d0b-334ae9d2c791",
   "metadata": {},
   "source": [
    "#### eval trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c5cf9366-d9cd-4c9d-951a-99a50877a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af82506e-95d7-4a4e-a821-e08512615db7",
   "metadata": {},
   "source": [
    "After training, our `agent.policy` is used as the deployment \"model\" that will generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6c82396a-7822-41fb-830f-1f6eb9c9b213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.epsilon_greedy_policy.EpsilonGreedyPolicy at 0x7f5ea5209120>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_agent = agent.policy\n",
    "deployment_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f6706224-ef5b-4185-bde4-bccb7c8e7ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating trained Agent...\n",
      "post-train val_loss     : 1.531858205795288\n",
      "post-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(deployment_agent, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = _run_bandit_eval(\n",
    "    policy = post_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f899120f-3706-4b72-8f2c-2169221dd66b",
   "metadata": {},
   "source": [
    "## Using Trained Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b0f691-860e-4853-928e-4c7ece714dd0",
   "metadata": {},
   "source": [
    "### load trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ea029f73-0638-462a-8f00-54b05c54d69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-130407/artifacts\n"
     ]
    }
   ],
   "source": [
    "POLICY_URI = ARTIFACTS_DIR\n",
    "\n",
    "print(POLICY_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "66d1d819-0152-437c-aefc-45ffd34d808a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-130407/artifacts/\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-130407/artifacts/fingerprint.pb\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-130407/artifacts/policy_specs.pbtxt\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-130407/artifacts/saved_model.pb\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-130407/artifacts/assets/\n",
      "gs://mabv1-hybrid-vertex-bucket/mab-local-classy-v1/run-20230824-130407/artifacts/variables/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $POLICY_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6aad948e-e346-4da3-8cb2-747435c8dc4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f5ea59697b0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "trained_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    POLICY_URI, load_specs_from_pbtxt=True\n",
    ")\n",
    "\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "483f8fa5-cbd1-4e3c-8e62-47f91f42e137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(), dtype=dtype('int32'), name='action_spec', minimum=0, maximum=1)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_policy.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8f658891-bc09-49b8-bc58-000a7926df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "for x in eval_ds.take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    \n",
    "    # global_feat_infer = _get_global_context_features(x)\n",
    "    # arm_feat_infer = _get_per_arm_features(x)\n",
    "    \n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "    \n",
    "    # rewards = _get_rewards(x)\n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = trained_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f515fcd0-2228-4f68-9ef9-665ce1fc3fb2",
   "metadata": {},
   "source": [
    "### view prediction response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6af4c297-d2e8-4f7b-bed5-e1da997dfe34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.5065835, 3.3081675], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=array([-0.00748688, -0.00109429,  0.02281768,  0.02389964, -0.02606181,\n",
       "        0.03303723, -0.04066131,  0.01637788,  0.04575255, -0.02789834,\n",
       "        0.04915843, -0.01727874,  0.02383972, -0.00305638, -0.04892061,\n",
       "        0.03675783, -0.00869868,  0.02983257,  0.03898263,  0.00655975,\n",
       "        0.03887727,  0.04585433, -0.03823161,  0.04281414, -0.00119876,\n",
       "        0.04586175, -0.03088927,  0.00073617, -0.00050934, -0.0166369 ,\n",
       "       -0.04326631, -0.02768165, -0.03035653,  0.04344905, -0.01065348,\n",
       "        0.04227955, -0.03122788,  0.01939541, -0.00284283,  0.00097341,\n",
       "       -0.02681171,  0.01477491, -0.00384433,  0.01784479,  0.02782433,\n",
       "        0.01085151,  0.00826206,  0.04470105, -0.03582252,  0.03808347,\n",
       "       -0.02905878,  0.00129922,  0.01870746, -0.03094292, -0.02776368,\n",
       "       -0.02589897,  0.03168622, -0.04877759,  0.00195142, -0.03130781,\n",
       "        0.02843003,  0.00374591,  0.04814385, -0.04249697], dtype=float32)))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd58d4b-6749-4177-8342-83ee969408c9",
   "metadata": {},
   "source": [
    "#### chosen action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d49adbbb-f747-4e4c-b82d-df88373c644f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0, dtype=int32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd12013-1d12-4197-8254-cef9138df42c",
   "metadata": {},
   "source": [
    "#### Per Arm Policy Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d6126290-546b-4702-8a1e-91f18adb05c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.5065835, 3.3081675], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=array([-0.00748688, -0.00109429,  0.02281768,  0.02389964, -0.02606181,\n",
       "        0.03303723, -0.04066131,  0.01637788,  0.04575255, -0.02789834,\n",
       "        0.04915843, -0.01727874,  0.02383972, -0.00305638, -0.04892061,\n",
       "        0.03675783, -0.00869868,  0.02983257,  0.03898263,  0.00655975,\n",
       "        0.03887727,  0.04585433, -0.03823161,  0.04281414, -0.00119876,\n",
       "        0.04586175, -0.03088927,  0.00073617, -0.00050934, -0.0166369 ,\n",
       "       -0.04326631, -0.02768165, -0.03035653,  0.04344905, -0.01065348,\n",
       "        0.04227955, -0.03122788,  0.01939541, -0.00284283,  0.00097341,\n",
       "       -0.02681171,  0.01477491, -0.00384433,  0.01784479,  0.02782433,\n",
       "        0.01085151,  0.00826206,  0.04470105, -0.03582252,  0.03808347,\n",
       "       -0.02905878,  0.00129922,  0.01870746, -0.03094292, -0.02776368,\n",
       "       -0.02589897,  0.03168622, -0.04877759,  0.00195142, -0.03130781,\n",
       "        0.02843003,  0.00374591,  0.04814385, -0.04249697], dtype=float32))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f66961-ebb5-4ae5-8e6f-ad73114d8353",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
