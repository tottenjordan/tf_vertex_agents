{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20186113-434a-46b9-887a-a90644015544",
   "metadata": {},
   "source": [
    "# Build Neural Linear Bandits with per-arm features\n",
    "\n",
    "**Exploring linear and nonlinear** (e.g., those with neural network-based value functions) bandit methods for recommendations using TF-Agents\n",
    "\n",
    "> Neural linear bandits provide a nice way to leverage the representation power of deep learning and the bandit approach for uncertainty measure and efficient exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e1cc80-f6d2-4c3c-88a6-79ba18146af0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1992e479-1aed-401a-ad25-714537f8e7a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Why generalize bandits to neural network models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b828dd5d-fa1b-4d56-a1a8-e1bed7fb4717",
   "metadata": {},
   "source": [
    "* NeuralLinear Bandits are linear contextual bandits use the last layer representation of the neural network as the contextual features\n",
    "* NeuralLinear works well [paper](https://arxiv.org/pdf/1802.09127.pdf)\n",
    "* Decouples representation learning and uncertainty estimation\n",
    "* Computationally inexpensive \n",
    "* Achieves superior performance on multiple datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a2c7ee-c96b-49d1-b825-d004d729b8fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Arm features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebd295e-2dcf-447c-b5c3-120cb9618d73",
   "metadata": {},
   "source": [
    "* In some bandits use cases, each arm has its own features. For example, in movie recommendation problems, the user features play the role of the context and the movies play the role of the arms (aka actions) \n",
    "* Each movie has its own features, such as `text description`, `metadata`, `trailer content` features and so on\n",
    "\n",
    "These problems are often referred to as `arm features problems`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231a80d8-6325-4754-8a26-36f7dc942d1f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Methods in this notebook:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16090153-a1fa-4c94-956c-f3ea232da57b",
   "metadata": {},
   "source": [
    "* [global_and_arm_feature_networks](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network) to preprocess user (global) and item (per-arm) features, and output rewards\n",
    "* `EncodingNetwork` to define a mapping of pre-processing layers to apply to a network's input \n",
    "* `ActorNetworks` to learn a mapping from observations to actions. These networks are usually used by our policies to generate actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1257ebc8-1f8d-4317-b103-830c4915957a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### references"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001d3894-b4a6-459f-b7a4-2a1f8ea03296",
   "metadata": {},
   "source": [
    "**TF-Agent tutorials:**\n",
    "\n",
    "(1) [Multi-Armed Bandits with Per-Arm Features](https://www.tensorflow.org/agents/tutorials/per_arm_bandits_tutorial)\n",
    "\n",
    "* step-by-step guide on how to use the TF-Agents library for contextual bandits problems where the actions (arms) have their own features, such as a list of movies represented by features (genre, year of release, ...)\n",
    "\n",
    "(2) [Networks](https://www.tensorflow.org/agents/tutorials/8_networks_tutorial)\n",
    "\n",
    "* define custom networks for your agents\n",
    "* The networks help us define the model that is trained by agents\n",
    "\n",
    "(3) [Ranking](https://www.tensorflow.org/agents/tutorials/ranking_tutorial)\n",
    "\n",
    "* ranking algorithms implemented as part of the TF-Agents Bandits library \n",
    "* In a ranking problem, in every iteration an agent is presented with a set of items, and is tasked with ranking some or all of them to a list\n",
    "* This ranking decision then receives some form of feedback (maybe a user does or does not click on one or more of the selected items for example)\n",
    "* The goal of the agent is to optimize some metric/reward with the goal of making better decisions over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b43f6ae-355c-4b28-ab76-8002ec3560cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# setup notebook environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "b0365ddc-7035-458e-9d3e-f8dfd6c71eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46b5efda-4f00-4281-9afa-a9244540c7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/tf_vertex_agents/04-perarm-features-bandit'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root_path = '/home/jupyter/tf_vertex_agents/04-perarm-features-bandit'\n",
    "os.chdir(root_path)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b607559b-5cb9-4e2a-b4e2-a4103a03f6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiplatform SDK version: 1.26.0\n"
     ]
    }
   ],
   "source": [
    "! python3 -c \"import google.cloud.aiplatform; print('aiplatform SDK version: {}'.format(google.cloud.aiplatform.__version__))\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b30ef95-19f8-43a0-80c7-4e92d992a698",
   "metadata": {},
   "source": [
    "## Load env config\n",
    "\n",
    "* use the prefix from `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1713,
   "id": "f8fe1d6b-5cc4-4f04-9d66-1218f636dab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = 'mabv1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1fc6a03-f6ab-4084-a9eb-3ee969303067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"mabv1\"\n",
      "VERSION                  = \"v1\"\n",
      "\n",
      "BUCKET_NAME              = \"mabv1-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://mabv1-hybrid-vertex-bucket/data\"\n",
      "BUCKET_URI               = \"gs://mabv1-hybrid-vertex-bucket\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_ID      = \"hybrid-vertex.movielens_dataset_mabv1\"\n",
      "BIGQUERY_TABLE_ID        = \"hybrid-vertex.movielens_dataset_mabv1.training_dataset\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0412d4a8-57e6-46a6-a1cc-79eda9dc7044",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04ed6f19-461e-47b2-99e6-6533372f49ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "700ff6d8-c406-4b95-8435-890e2597578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from collections import defaultdict\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pickle as pkl\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tf_agents.agents import TFAgent\n",
    "\n",
    "from tf_agents.bandits.environments import stationary_stochastic_per_arm_py_environment as p_a_env\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "from tf_agents.bandits.agents import lin_ucb_agent\n",
    "from tf_agents.bandits.agents import linear_thompson_sampling_agent as lin_ts_agent\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent\n",
    "from tf_agents.bandits.agents import neural_linucb_agent\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "# my project\n",
    "from src.per_arm_rl import data_utils\n",
    "from src.per_arm_rl import data_config\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5932fdb-6c52-40c1-8982-73043aec365d",
   "metadata": {},
   "source": [
    "### detect GPUs & reset devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86056d0f-264d-4e91-bd7c-c01ec1978954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for gpu in gpus:\n",
    "#     tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \n",
    "# gpus\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad238cbb-4e17-490f-b9ca-61b0b2facf6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ed3980-935d-4888-b146-0779123c8827",
   "metadata": {},
   "source": [
    "### Initialize Google Cloud SDK Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c379affe-f4d2-46f4-8978-ac1c284bac97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a69631-daf5-4cd2-bfd7-d1ece76c3976",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b364d92-026c-4d2f-97ed-631dab496deb",
   "metadata": {},
   "source": [
    "### Read TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85e5e712-dbf6-42f8-9f7d-1d9d6fa3b3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22b9c216-b368-4b58-b9d1-f35c44008c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://mabv1-hybrid-vertex-bucket/data/val/ml-ratings-100k-val.tfrecord']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/val'): # tmp TODO - \"train\"\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89711072-2807-4c08-9056-f67e8a39cc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([25.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[4]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'211'], dtype=object)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([874948475])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'346'], dtype=object)>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'other'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "train_dataset = train_dataset.map(data_utils.parse_tfrecord)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b4f947-e217-472f-ad08-7b11e829a613",
   "metadata": {},
   "source": [
    "### get vocab\n",
    "\n",
    "**TODO:** \n",
    "* streamline vocab calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12b5616e-7175-4570-90de-2c0cff335f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE_VOCABS: False\n"
     ]
    }
   ],
   "source": [
    "GENERATE_VOCABS = False\n",
    "print(f\"GENERATE_VOCABS: {GENERATE_VOCABS}\")\n",
    "\n",
    "VOCAB_SUBDIR   = \"vocabs\"\n",
    "VOCAB_FILENAME = \"vocab_dict.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3051a3d3-4cda-45e4-8a77-fad4496ff562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab...\n",
      "Downloaded vocab from: gs://mabv1-hybrid-vertex-bucket/vocabs/vocab_dict.pkl\n",
      "\n",
      "'movie_id'\n",
      "'user_id'\n",
      "'user_occupation_text'\n",
      "'movie_genres'\n",
      "'bucketized_user_age'\n",
      "'max_timestamp'\n",
      "'min_timestamp'\n",
      "'timestamp_buckets'\n"
     ]
    }
   ],
   "source": [
    "if not GENERATE_VOCABS:\n",
    "\n",
    "    EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{VOCAB_SUBDIR}/{VOCAB_FILENAME}'\n",
    "    print(f\"Downloading vocab...\")\n",
    "    \n",
    "    os.system(f'gsutil -q cp {EXISTING_VOCAB_FILE} .')\n",
    "    print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "    filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "    vocab_dict = pkl.load(filehandler)\n",
    "    filehandler.close()\n",
    "    \n",
    "    for key in vocab_dict.keys():\n",
    "        pprint(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff47bc89-7031-422c-9db6-18a69fa35676",
   "metadata": {},
   "source": [
    "# Per-Arm Bandits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "427eea7c-9cd5-495c-9bfc-0d52a05d9adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.bandits.agents import lin_ucb_agent\n",
    "from tf_agents.bandits.environments import stationary_stochastic_per_arm_py_environment as p_a_env\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "nest = tf.nest"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b8d58dd5-2fa1-4f1a-9448-570f0815f990",
   "metadata": {},
   "source": [
    "## define preprocessing layers for global and arm features\n",
    "\n",
    "The preproccesing layers will ultimately feed the two functions described below, both of which will ultimately feed the `Environment`\n",
    "\n",
    "`global_context_sampling_fn`: \n",
    "* A function that outputs a random 1d array or list of ints or floats\n",
    "* This output is the global context. Its shape and type must be consistent across calls.\n",
    "\n",
    "`arm_context_sampling_fn`: \n",
    "* A function that outputs a random 1 array or list of ints or floats (same type as the output of `global_context_sampling_fn`). * This output is the per-arm context. Its shape must be consistent across calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17750122-51c8-4cfd-a9bf-67b2b3ae79ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OOV_BUCKETS        = 1\n",
    "GLOBAL_EMBEDDING_SIZE  = 4\n",
    "MV_EMBEDDING_SIZE      = 8 #32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4063e8c9-56b1-441a-88ed-41aff472cbb8",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### global preprcoessing layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12f205cd-b918-40f4-9bfc-c36727ac0e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_inputs = []\n",
    "# global_features = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c06ea19-8bdc-40e1-98f6-f28da6961268",
   "metadata": {},
   "source": [
    "#### user ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eadb0bef-3fe8-4e51-bc80-0ca0e0493844",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_input_layer = tf.keras.Input(\n",
    "    name=\"user_id\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.string\n",
    ")\n",
    "\n",
    "user_id_lookup = tf.keras.layers.StringLookup(\n",
    "    max_tokens=len(vocab_dict['user_id']) + NUM_OOV_BUCKETS,\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    mask_token=None,\n",
    "    vocabulary=vocab_dict['user_id'],\n",
    ")(user_id_input_layer)\n",
    "\n",
    "user_id_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['user_id']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=GLOBAL_EMBEDDING_SIZE\n",
    ")(user_id_lookup)\n",
    "\n",
    "user_id_embedding = tf.reduce_sum(user_id_embedding, axis=-2)\n",
    "\n",
    "# global_inputs.append(user_id_input_layer)\n",
    "# global_features.append(user_id_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a0aca0c-a710-4d0b-b9fe-9613d308149e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'346'], shape=(1,), dtype=string)\n",
      "tf.Tensor([[-0.02599    -0.03078079  0.03106076  0.00133444]], shape=(1, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_user_id_model = tf.keras.Model(inputs=user_id_input_layer, outputs=user_id_embedding)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(x[\"user_id\"])\n",
    "    print(test_user_id_model(x[\"user_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d924a649-2b22-4cad-a58b-61b400b5024f",
   "metadata": {},
   "source": [
    "#### user AGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fed6ae1-3aa3-427d-8db9-c17009af2ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_age_input_layer = tf.keras.Input(\n",
    "    name=\"bucketized_user_age\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "user_age_lookup = tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=vocab_dict['bucketized_user_age'],\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    oov_value=0,\n",
    ")(user_age_input_layer)\n",
    "\n",
    "user_age_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['bucketized_user_age']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=GLOBAL_EMBEDDING_SIZE\n",
    ")(user_age_lookup)\n",
    "\n",
    "user_age_embedding = tf.reduce_sum(user_age_embedding, axis=-2)\n",
    "\n",
    "# global_inputs.append(user_age_input_layer)\n",
    "# global_features.append(user_age_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56f81ef0-e652-4b6b-a7dc-546bf2d1e2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([25.], shape=(1,), dtype=float32)\n",
      "tf.Tensor([[ 0.02207417 -0.02917665  0.02782809 -0.02822751]], shape=(1, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_user_age_model = tf.keras.Model(inputs=user_age_input_layer, outputs=user_age_embedding)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(x[\"bucketized_user_age\"])\n",
    "    print(test_user_age_model(x[\"bucketized_user_age\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ba76d2-d138-4247-b233-57ae0e1c90c4",
   "metadata": {},
   "source": [
    "#### user OCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f726232-b156-4f74-acab-9488956fe3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_occ_input_layer = tf.keras.Input(\n",
    "    name=\"user_occupation_text\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.string\n",
    ")\n",
    "\n",
    "user_occ_lookup = tf.keras.layers.StringLookup(\n",
    "    max_tokens=len(vocab_dict['user_occupation_text']) + NUM_OOV_BUCKETS,\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    mask_token=None,\n",
    "    vocabulary=vocab_dict['user_occupation_text'],\n",
    ")(user_occ_input_layer)\n",
    "\n",
    "user_occ_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['user_occupation_text']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=GLOBAL_EMBEDDING_SIZE\n",
    ")(user_occ_lookup)\n",
    "\n",
    "user_occ_embedding = tf.reduce_sum(user_occ_embedding, axis=-2)\n",
    "\n",
    "# global_inputs.append(user_occ_input_layer)\n",
    "# global_features.append(user_occ_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abb362a1-d1f0-47f0-bbf2-beaa07ebda02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'other'], shape=(1,), dtype=string)\n",
      "tf.Tensor([[-0.04523091  0.0495333  -0.01482558 -0.04208376]], shape=(1, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_user_occ_model = tf.keras.Model(inputs=user_occ_input_layer, outputs=user_occ_embedding)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(x[\"user_occupation_text\"])\n",
    "    print(test_user_occ_model(x[\"user_occupation_text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e072e83-acf4-46c9-8d92-418fa497cd50",
   "metadata": {},
   "source": [
    "#### user Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9b72286-4e8e-4285-b91b-2f30f2ff6856",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ts_input_layer = tf.keras.Input(\n",
    "    name=\"timestamp\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.int64\n",
    ")\n",
    "\n",
    "user_ts_lookup = tf.keras.layers.Discretization(\n",
    "    vocab_dict['timestamp_buckets'].tolist()\n",
    ")(user_ts_input_layer)\n",
    "\n",
    "user_ts_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['timestamp_buckets'].tolist()) + NUM_OOV_BUCKETS,\n",
    "    output_dim=GLOBAL_EMBEDDING_SIZE\n",
    ")(user_ts_lookup)\n",
    "\n",
    "user_ts_embedding = tf.reduce_sum(user_ts_embedding, axis=-2)\n",
    "\n",
    "# global_inputs.append(user_ts_input_layer)\n",
    "# global_features.append(user_ts_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78a3e08b-88ff-4575-a0e0-80d7c75baa9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([874948475], shape=(1,), dtype=int64)\n",
      "tf.Tensor([[ 0.00741076 -0.04264941  0.00693322 -0.03396516]], shape=(1, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_user_ts_model = tf.keras.Model(inputs=user_ts_input_layer, outputs=user_ts_embedding)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(x[\"timestamp\"])\n",
    "    print(test_user_ts_model(x[\"timestamp\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1066734-9c48-46ca-8dcb-2eb16a4a3eb7",
   "metadata": {},
   "source": [
    "### create `global_context_sampling_fn()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9900cf33-8dbe-44de-9f3f-9bab00ad2627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_user_id_emb_model\n",
    "# get_user_age_emb_model\n",
    "# get_user_occ_emb_model\n",
    "# get_ts_emb_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92be6716-3186-4155-9ca5-272f80ff53bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_context_sampling_fn():\n",
    "    \"\"\"\n",
    "    This function generates a single global observation vector.\n",
    "    \"\"\"\n",
    "    # for x in train_dataset.take(1).as_numpy_iterator():\n",
    "    for x in train_dataset.batch(1).take(1):\n",
    "        user_id_value = x['user_id']\n",
    "        user_age_value = x['bucketized_user_age']\n",
    "        user_occ_value = x['user_occupation_text']\n",
    "        user_ts_value = x['timestamp']\n",
    "        \n",
    "        _id = test_user_id_model(user_id_value)\n",
    "        _age = test_user_age_model(user_age_value)\n",
    "        _occ = test_user_occ_model(user_occ_value)\n",
    "        _ts = test_user_ts_model(user_ts_value)\n",
    "        \n",
    "        # # tmp - insepct numpy() values\n",
    "        # print(_id.numpy()) #[0])\n",
    "        # print(_age.numpy()) #[0])\n",
    "        # print(_occ.numpy()) #[0])\n",
    "        # print(_ts.numpy()) #[0])\n",
    "        \n",
    "        # to numpy array\n",
    "        _id = np.array(_id.numpy()[0])\n",
    "        _age = np.array(_age.numpy()[0])\n",
    "        _occ = np.array(_occ.numpy()[0])\n",
    "        _ts = np.array(_ts.numpy()[0])\n",
    "        \n",
    "        concat = np.concatenate(\n",
    "            [_id, _age, _occ, _ts], axis=-1\n",
    "        ).astype(np.float32)\n",
    "        \n",
    "        return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "307f8f7f-1a52-418e-96c7-8aa93cdf4c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02599   , -0.03078079,  0.03106076,  0.00133444,  0.02207417,\n",
       "       -0.02917665,  0.02782809, -0.02822751, -0.04523091,  0.0495333 ,\n",
       "       -0.01482558, -0.04208376,  0.00741076, -0.04264941,  0.00693322,\n",
       "       -0.03396516], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_context_sampling_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "025c8b5c-1c4f-4e70-9f3f-722ae3186fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_DIM = 40\n",
    "GLOBAL_BOUND = 10\n",
    "\n",
    "def test_global_context_sampling_fn():\n",
    "    \"\"\"This function generates a single global observation vector.\"\"\"\n",
    "    return np.random.randint(\n",
    "      -GLOBAL_BOUND, GLOBAL_BOUND, [GLOBAL_DIM]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1a51aaf-b49d-48ec-97ac-e46e8edcfa91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3., -10.,   5.,   4.,   5.,  -8.,  -3.,   4.,  -8.,  -8.,  -3.,\n",
       "        -3.,   6.,  -6.,   5.,  -7.,   5.,   4.,   7.,   9.,   1.,   6.,\n",
       "        -3.,  -1., -10.,  -2.,  -9.,  -3.,  -2.,  -1.,   5.,  -8.,   9.,\n",
       "        -3.,   9., -10.,   2.,   6.,  -1.,  -9.], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_global_context_sampling_fn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0104490c-ada4-40fb-8a75-9a77136db00b",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### arm preprocessing layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0dda1b-fa6c-4178-b6d6-3c1449091b6d",
   "metadata": {},
   "source": [
    "#### movie ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "767df2d8-0cdd-4f53-90f3-01f555e496ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_id_input_layer = tf.keras.Input(\n",
    "    name=\"movie_id\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.string\n",
    ")\n",
    "\n",
    "mv_id_lookup = tf.keras.layers.StringLookup(\n",
    "    max_tokens=len(vocab_dict['movie_id']) + NUM_OOV_BUCKETS,\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    mask_token=None,\n",
    "    vocabulary=vocab_dict['movie_id'],\n",
    ")(mv_id_input_layer)\n",
    "\n",
    "mv_id_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['movie_id']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=MV_EMBEDDING_SIZE\n",
    ")(mv_id_lookup)\n",
    "\n",
    "mv_id_embedding = tf.reduce_sum(mv_id_embedding, axis=-2)\n",
    "\n",
    "# arm_inputs.append(mv_id_input_layer)\n",
    "# arm_features.append(mv_id_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a64bdc9-710f-4f61-82fd-3d2f51591c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'211'], shape=(1,), dtype=string)\n",
      "tf.Tensor(\n",
      "[[-0.02780459 -0.00370889 -0.02864446 -0.02917221 -0.01603731  0.02465415\n",
      "   0.01583499 -0.03253644]], shape=(1, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_mv_id_model = tf.keras.Model(inputs=mv_id_input_layer, outputs=mv_id_embedding)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(x[\"movie_id\"])\n",
    "    print(test_mv_id_model(x[\"movie_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb9f3bd-e4e4-4a26-891e-e04450303f99",
   "metadata": {},
   "source": [
    "#### movie genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1f35343-6416-4311-bff5-4df2bd74ec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_genre_input_layer = tf.keras.Input(\n",
    "    name=\"movie_genres\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "mv_genre_lookup = tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=vocab_dict['movie_genres'],\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    oov_value=0,\n",
    ")(mv_genre_input_layer)\n",
    "\n",
    "mv_genre_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['movie_genres']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=MV_EMBEDDING_SIZE\n",
    ")(mv_genre_lookup)\n",
    "\n",
    "mv_genre_embedding = tf.reduce_sum(mv_genre_embedding, axis=-2)\n",
    "\n",
    "# arm_inputs.append(mv_genre_input_layer)\n",
    "# arm_features.append(mv_genre_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "effa4e73-1568-4cc2-a972-7a6df0ba8f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[4]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[ 0.03956462  0.04351255  0.01470714  0.04936441  0.01360733 -0.0412104\n",
      "   0.02928157  0.01699198]], shape=(1, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_mv_gen_model = tf.keras.Model(inputs=mv_genre_input_layer, outputs=mv_genre_embedding)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(x[\"movie_genres\"])\n",
    "    print(test_mv_gen_model(x[\"movie_genres\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed21d4da-01b9-4fc3-a905-2f3c75dbafef",
   "metadata": {},
   "source": [
    "### create `arm_context_sampling_fn()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e53deb4f-3a99-4935-88bc-d9f90197da83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_arm_context_sampling_fn():\n",
    "    \"\"\"\n",
    "    This function generates a single per-arm observation vector\n",
    "    \"\"\"\n",
    "    for x in train_dataset.batch(1).take(1):\n",
    "        mv_id_value = x['movie_id']\n",
    "        mv_gen_value = x['movie_genres'][0]\n",
    "        \n",
    "        _mid = test_mv_id_model(mv_id_value)\n",
    "        _mgen = test_mv_gen_model(mv_gen_value)\n",
    "        \n",
    "        # to numpy array\n",
    "        _mid = np.array(_mid.numpy()[0])\n",
    "        _mgen = np.array(_mgen.numpy()[0])\n",
    "        \n",
    "        # print(_mid)\n",
    "        # print(_mgen)\n",
    "        \n",
    "        concat = np.concatenate([_mid, _mgen], axis=-1).astype(np.float32)\n",
    "        \n",
    "        return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a0e8993b-aa11-4b26-bf02-8430a4c34993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02780459, -0.00370889, -0.02864446, -0.02917221, -0.01603731,\n",
       "        0.02465415,  0.01583499, -0.03253644,  0.03956462,  0.04351255,\n",
       "        0.01470714,  0.04936441,  0.01360733, -0.0412104 ,  0.02928157,\n",
       "        0.01699198], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_arm_context_sampling_fn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8313dbbc-2df5-46ee-acb3-47e81693ab42",
   "metadata": {},
   "source": [
    "## define reward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "882d8558-89f2-4962-931a-7c2be0ab1a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JT - TODO\n",
    "\n",
    "# from tf_agents.trajectories import time_step as ts\n",
    "# from tf_agents.trajectories import trajectory\n",
    "# # from tf_agents.typing import types\n",
    "\n",
    "# discounts = tf.ones((BATCH_SIZE,), dtype=tf.float32)\n",
    "# rewards = tf.ones((BATCH_SIZE,), dtype=tf.float32)\n",
    "# actions = tf.ones((BATCH_SIZE,), dtype=tf.float32)\n",
    "\n",
    "# next_step_types = tf.ones((BATCH_SIZE,), dtype=tf.int32) * ts.StepType.MID\n",
    "\n",
    "# step_types = tf.concat([[ts.StepType.FIRST], next_step_types[1:]], axis=0)\n",
    "\n",
    "# traj = trajectory.Trajectory(\n",
    "#     step_type=step_types,\n",
    "#     observation=observation, #obs_tensor_spec,\n",
    "#     action=actions,\n",
    "#     policy_info=(),\n",
    "#     next_step_type=next_step_types,\n",
    "#     reward=rewards,\n",
    "#     discount=discounts\n",
    "# )\n",
    "# traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c30a859-4b6e-4856-8587-2ad6bdf7074b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "GLOBAL_DIM = global_context_sampling_fn()\n",
    "GLOBAL_DIM = GLOBAL_DIM.shape[0]\n",
    "print(GLOBAL_DIM)\n",
    "\n",
    "PER_ARM_DIM = per_arm_context_sampling_fn()\n",
    "PER_ARM_DIM = PER_ARM_DIM.shape[0]\n",
    "print(PER_ARM_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6d645532-bae4-4d76-a99a-65f6f203d15e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "PARAM_BOUND = 5 \n",
    "\n",
    "# should be similar to\n",
    "reward_param = list(np.random.randint(-PARAM_BOUND, PARAM_BOUND, [GLOBAL_DIM + PER_ARM_DIM]))\n",
    "print(len(reward_param))\n",
    "# reward_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "afc45587-ca6a-4a64-b0ae-259babbfa74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.24167780205607414"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_global_out = global_context_sampling_fn()\n",
    "test_arm_out = per_arm_context_sampling_fn()\n",
    "\n",
    "x_x = np.concatenate([test_global_out, test_arm_out], axis=-1)\n",
    "# x_x\n",
    "mu = np.dot(x_x, reward_param)\n",
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "306e2b6e-bcbd-4636-80d1-1954b2d359eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.07835058681666851"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_param = list(np.ones(32))\n",
    "print(len(reward_param))\n",
    "\n",
    "mu = np.dot(x_x, reward_param)\n",
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "96485ec8-43b0-4916-8de9-26a272039037",
   "metadata": {},
   "outputs": [],
   "source": [
    "VARIANCE = 100.0 \n",
    "\n",
    "def linear_normal_reward_fn(x):\n",
    "    \"\"\"This function generates a reward from the concatenated global and per-arm observations.\"\"\"\n",
    "    mu = np.dot(x, reward_param)\n",
    "    return np.random.normal(mu, VARIANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "822d41ea-264b-4a92-9e9c-699441ae03a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-46.9599440925143"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_normal_reward_fn(x_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "329cab98-caac-401f-ab5d-5ecf382bba80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _get_rewards(element):\n",
    "#     \"\"\"Calculates reward for the actions.\"\"\"\n",
    "\n",
    "#     def _calc_reward(x):\n",
    "#         \"\"\"Calculates reward for a single action.\"\"\"\n",
    "#         r0 = lambda: tf.constant(0.0)\n",
    "#         r1 = lambda: tf.constant(-10.0)\n",
    "#         r2 = lambda: tf.constant(2.0)\n",
    "#         r3 = lambda: tf.constant(3.0)\n",
    "#         r4 = lambda: tf.constant(4.0)\n",
    "#         r5 = lambda: tf.constant(10.0)\n",
    "#         c1 = tf.equal(x, 1.0)\n",
    "#         c2 = tf.equal(x, 2.0)\n",
    "#         c3 = tf.equal(x, 3.0)\n",
    "#         c4 = tf.equal(x, 4.0)\n",
    "#         c5 = tf.equal(x, 5.0)\n",
    "#         return tf.case([(c1, r1), (c2, r2), (c3, r3),(c4, r4),(c5, r5)], default=r0, exclusive=True)\n",
    "\n",
    "#     return tf.map_fn(\n",
    "#         fn=_calc_reward, \n",
    "#         elems=element['user_rating'], \n",
    "#         dtype=tf.float32\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2e884a48-2ca0-4253-b455-3a430d6a7744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in train_dataset.batch(1).take(3):\n",
    "#     print(f\"Rating: {x['user_rating']}\")\n",
    "#     print(f\"Reward: {_get_rewards(x)}\") #[\"user_rating\"]))\n",
    "\n",
    "# ## output ####\n",
    "# Rating: [4.]\n",
    "# Reward: [4.]\n",
    "# Rating: [4.]\n",
    "# Reward: [4.]\n",
    "# Rating: [1.]\n",
    "# Reward: [-10.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489f5b5d-a15d-4d2e-b5c8-b56aa393311b",
   "metadata": {},
   "source": [
    "## define environment\n",
    "\n",
    "`num_actions_fn`:\n",
    "* a function that outputs a single integer specifying the number of actions for a given time step. \n",
    "* The number of actions will be encoded in the observation by the feature key `num_actions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "420101ac-35bf-4000-add1-b0777b9d6c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ACTIONS = 10\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "# num_actions_fn = None\n",
    "num_actions_fn = lambda: NUM_ACTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a3113fbf-ac12-4f05-8ae0-f6a906914724",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_arm_py_env = p_a_env.StationaryStochasticPerArmPyEnvironment(\n",
    "    global_context_sampling_fn = global_context_sampling_fn,\n",
    "    arm_context_sampling_fn = per_arm_context_sampling_fn,\n",
    "    max_num_actions = NUM_ACTIONS,\n",
    "    reward_fn = linear_normal_reward_fn, # _get_rewards\n",
    "    num_actions_fn = num_actions_fn,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "per_arm_tf_env = tf_py_environment.TFPyEnvironment(per_arm_py_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "897bbc9c-a549-4b39-be95-90a91e7c8cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation spec:  {'global': TensorSpec(shape=(16,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(10, 16), dtype=tf.float32, name=None), 'num_actions': BoundedTensorSpec(shape=(), dtype=tf.int64, name=None, minimum=array(1), maximum=array(10))}\n"
     ]
    }
   ],
   "source": [
    "print('observation spec: ', per_arm_tf_env.observation_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c0d8c084-180e-4920-accb-9b2317d9a610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward_spec:  TensorSpec(shape=(), dtype=tf.float32, name='reward')\n"
     ]
    }
   ],
   "source": [
    "print('reward_spec: ', per_arm_tf_env.reward_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c5007c0-dc03-41d5-acb1-d7d26eee586e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "An observation:  {'global': <tf.Tensor: shape=(20, 16), dtype=float32, numpy=\n",
      "array([[-0.02599   , -0.03078079,  0.03106076,  0.00133444,  0.02207417,\n",
      "        -0.02917665,  0.02782809, -0.02822751, -0.04523091,  0.0495333 ,\n",
      "        -0.01482558, -0.04208376,  0.00741076, -0.04264941,  0.00693322,\n",
      "        -0.03396516],\n",
      "       [-0.02599   , -0.03078079,  0.03106076,  0.00133444,  0.02207417,\n",
      "        -0.02917665,  0.02782809, -0.02822751, -0.04523091,  0.0495333 ,\n",
      "        -0.01482558, -0.04208376,  0.00741076, -0.04264941,  0.00693322,\n",
      "        -0.03396516],\n",
      "       [-0.02599   , -0.03078079,  0.03106076,  0.00133444,  0.02207417,\n",
      "        -0.02917665,  0.02782809, -0.02822751, -0.04523091,  0.0495333 ,\n",
      "        -0.01482558, -0.04208376,  0.00741076, -0.04264941,  0.00693322,\n",
      "        -0.03396516],\n",
      "       [-0.02599   , -0.03078079,  0.03106076,  0.00133444,  0.02207417,\n",
      "        -0.02917665,  0.02782809, -0.02822751, -0.04523091,  0.0495333 ,\n",
      "        -0.01482558, -0.04208376,  0.00741076, -0.04264941,  0.00693322,\n",
      "        -0.03396516],\n",
      "       [-0.02599   , -0.03078079,  0.03106076,  0.00133444,  0.02207417,\n",
      "        -0.02917665,  0.02782809, -0.02822751, -0.04523091,  0.0495333 ,\n",
      "        -0.01482558, -0.04208376,  0.00741076, -0.04264941,  0.00693322,\n",
      "        -0.03396516],\n",
      "       [-0.02599   , -0.03078079,  0.03106076,  0.00133444,  0.02207417,\n",
      "        -0.02917665,  0.02782809, -0.02822751, -0.04523091,  0.0495333 ,\n",
      "        -0.01482558, -0.04208376,  0.00741076, -0.04264941,  0.00693322,\n",
      "        -0.03396516],\n",
      "       [-0.02599   , -0.03078079,  0.03106076,  0.00133444,  0.02207417,\n",
      "        -0.02917665,  0.02782809, -0.02822751, -0.04523091,  0.0495333 ,\n",
      "        -0.01482558, -0.04208376,  0.00741076, -0.04264941,  0.00693322,\n",
      "        -0.03396516],\n",
      "       [-0.02599   , -0.03078079,  0.03106076,  0.00133444,  0.02207417,\n",
      "        -0.02917665,  0.02782809, -0.02822751, -0.04523091,  0.0495333 ,\n",
      "        -0.01482558, -0.04208376,  0.00741076, -0.04264941,  0.00693322,\n",
      "        -0.03396516],\n",
      "       [-0.02599   , -0.03078079,  0.03106076,  0.00133444,  0.02207417,\n",
      "        -0.02917665,  0.02782809, -0.02822751, -0.04523091,  0.0495333 ,\n",
      "        -0.01482558, -0.04208376,  0.00741076, -0.04264941,  0.00693322,\n",
      "        -0.03396516],\n",
      "       [-0.02599   , -0.03078079,  0.03106076,  0.00133444,  0.02207417,\n",
      "        -0.02917665,  0.02782809, -0.02822751, -0.04523091,  0.0495333 ,\n",
      "        -0.01482558, -0.04208376,  0.00741076, -0.04264941,  0.00693322,\n",
      "        -0.03396516],\n",
      "       [-0.02599   , -0.03078079,  0.03106076,  0.00133444,  0.02207417,\n",
      "        -0.02917665,  0.02782809, -0.02822751, -0.04523091,  0.0495333 ,\n",
      "        -0.01482558, -0.04208376,  0.00741076, -0.04264941,  0.00693322,\n",
      "        -0.03396516],\n",
      "       [-0.02599   , -0.03078079,  0.03106076,  0.00133444,  0.02207417,\n",
      "        -0.02917665,  0.02782809, -0.02822751, -0.04523091,  0.0495333 ,\n",
      "        -0.01482558, -0.04208376,  0.00741076, -0.04264941,  0.00693322,\n",
      "        -0.03396516],\n",
      "       [-0.02599   , -0.03078079,  0.03106076,  0.00133444,  0.02207417,\n",
      "        -0.02917665,  0.02782809, -0.02822751, -0.04523091,  0.0495333 ,\n",
      "        -0.01482558, -0.04208376,  0.00741076, -0.04264941,  0.00693322,\n",
      "        -0.03396516],\n",
      "       [-0.02599   , -0.03078079,  0.03106076,  0.00133444,  0.02207417,\n",
      "        -0.02917665,  0.02782809, -0.02822751, -0.04523091,  0.0495333 ,\n",
      "        -0.01482558, -0.04208376,  0.00741076, -0.04264941,  0.00693322,\n",
      "        -0.03396516],\n",
      "       [-0.02599   , -0.03078079,  0.03106076,  0.00133444,  0.02207417,\n",
      "        -0.02917665,  0.02782809, -0.02822751, -0.04523091,  0.0495333 ,\n",
      "        -0.01482558, -0.04208376,  0.00741076, -0.04264941,  0.00693322,\n",
      "        -0.03396516],\n",
      "       [-0.02599   , -0.03078079,  0.03106076,  0.00133444,  0.02207417,\n",
      "        -0.02917665,  0.02782809, -0.02822751, -0.04523091,  0.0495333 ,\n",
      "        -0.01482558, -0.04208376,  0.00741076, -0.04264941,  0.00693322,\n",
      "        -0.03396516],\n",
      "       [-0.02599   , -0.03078079,  0.03106076,  0.00133444,  0.02207417,\n",
      "        -0.02917665,  0.02782809, -0.02822751, -0.04523091,  0.0495333 ,\n",
      "        -0.01482558, -0.04208376,  0.00741076, -0.04264941,  0.00693322,\n",
      "        -0.03396516],\n",
      "       [-0.02599   , -0.03078079,  0.03106076,  0.00133444,  0.02207417,\n",
      "        -0.02917665,  0.02782809, -0.02822751, -0.04523091,  0.0495333 ,\n",
      "        -0.01482558, -0.04208376,  0.00741076, -0.04264941,  0.00693322,\n",
      "        -0.03396516],\n",
      "       [-0.02599   , -0.03078079,  0.03106076,  0.00133444,  0.02207417,\n",
      "        -0.02917665,  0.02782809, -0.02822751, -0.04523091,  0.0495333 ,\n",
      "        -0.01482558, -0.04208376,  0.00741076, -0.04264941,  0.00693322,\n",
      "        -0.03396516],\n",
      "       [-0.02599   , -0.03078079,  0.03106076,  0.00133444,  0.02207417,\n",
      "        -0.02917665,  0.02782809, -0.02822751, -0.04523091,  0.0495333 ,\n",
      "        -0.01482558, -0.04208376,  0.00741076, -0.04264941,  0.00693322,\n",
      "        -0.03396516]], dtype=float32)>, 'per_arm': <tf.Tensor: shape=(20, 10, 16), dtype=float32, numpy=\n",
      "array([[[-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198],\n",
      "        [-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198],\n",
      "        [-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198],\n",
      "        ...,\n",
      "        [-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198],\n",
      "        [-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198],\n",
      "        [-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198]],\n",
      "\n",
      "       [[-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198],\n",
      "        [-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198],\n",
      "        [-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198],\n",
      "        ...,\n",
      "        [-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198],\n",
      "        [-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198],\n",
      "        [-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198]],\n",
      "\n",
      "       [[-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198],\n",
      "        [-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198],\n",
      "        [-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198],\n",
      "        ...,\n",
      "        [-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198],\n",
      "        [-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198],\n",
      "        [-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198],\n",
      "        [-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198],\n",
      "        [-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198],\n",
      "        ...,\n",
      "        [-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198],\n",
      "        [-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198],\n",
      "        [-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198]],\n",
      "\n",
      "       [[-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198],\n",
      "        [-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198],\n",
      "        [-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198],\n",
      "        ...,\n",
      "        [-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198],\n",
      "        [-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198],\n",
      "        [-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198]],\n",
      "\n",
      "       [[-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198],\n",
      "        [-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198],\n",
      "        [-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198],\n",
      "        ...,\n",
      "        [-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198],\n",
      "        [-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198],\n",
      "        [-0.02780459, -0.00370889, -0.02864446, ..., -0.0412104 ,\n",
      "          0.02928157,  0.01699198]]], dtype=float32)>, 'num_actions': <tf.Tensor: shape=(20,), dtype=int64, numpy=\n",
      "array([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "       10, 10, 10])>}\n"
     ]
    }
   ],
   "source": [
    "print('\\nAn observation: ', per_arm_tf_env.reset().observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "11c13ae2-0cb3-45ad-9cf7-cf75a712fb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rewards after taking an action:  tf.Tensor(\n",
      "[-150.27821   134.48189  -297.2999   -140.62787     6.723917   84.13467\n",
      "    0.922849  -36.420517  -20.886211   -7.858317   10.700291  -92.6265\n",
      "  -79.65316   -64.81762    17.944258 -147.62914    77.474724   62.227337\n",
      " -102.064545  191.07434 ], shape=(20,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "action = tf.zeros(BATCH_SIZE, dtype=tf.int32)\n",
    "time_step = per_arm_tf_env.step(action)\n",
    "print('\\nRewards after taking an action: ', time_step.reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bee00db-5a4a-4880-b567-307b0a41c82e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The Agent\n",
    "\n",
    "**Note** that contextual bandits form a special case of RL, where the actions taken by the agent do not alter the state of the environment \n",
    "\n",
    "> “Contextual” refers to the fact that the agent chooses among a set of actions while having knowledge of the context (environment observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867e8834-b652-4c21-8061-9b684a80e182",
   "metadata": {
    "tags": []
   },
   "source": [
    "### agent types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf19f410-4fac-4539-95a2-543034d1a0fe",
   "metadata": {},
   "source": [
    "**Possible Agent Types:**\n",
    "\n",
    "```\n",
    "AGENT_TYPE = ['LinUCB', 'LinTS', 'epsGreedy', 'NeuralLinUCB']\n",
    "```\n",
    "\n",
    "**LinearUCBAgent:** (`LinUCB`)\n",
    "* An agent implementing the Linear UCB bandit algorithm\n",
    "* (whitepaper) [A contextual bandit approach to personalized news recommendation](https://arxiv.org/abs/1003.0146)\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/lin_ucb_agent/LinearUCBAgent)\n",
    "\n",
    "**LinearThompsonSamplingAgent:** (`LinTS`)\n",
    "* Implements the Linear Thompson Sampling Agent from the paper: [Thompson Sampling for Contextual Bandits with Linear Payoffs](https://arxiv.org/abs/1209.3352)\n",
    "* the agent maintains two parameters `weight_covariances` and `parameter_estimators`, and updates them based on experience.\n",
    "* The inverse of the weight covariance parameters are updated with the outer product of the observations using the Woodbury inverse matrix update, while the parameter estimators are updated by the reward-weighted observation vectors for every action\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/linear_thompson_sampling_agent/LinearThompsonSamplingAgent)\n",
    "\n",
    "**NeuralEpsilonGreedyAgent:** (`epsGreedy`) \n",
    "* A neural network based epsilon greedy agent\n",
    "* This agent receives a neural network that it trains to predict rewards\n",
    "* The action is chosen greedily with respect to the prediction with probability `1 - epsilon`, and uniformly randomly with probability epsilon\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_epsilon_greedy_agent/NeuralEpsilonGreedyAgent)\n",
    "\n",
    "**NeuralLinUCBAgent:** (`NeuralLinUCB`)\n",
    "* An agent implementing the LinUCB algorithm on top of a neural network\n",
    "* `ENCODING_DIM` is the output dimension of the encoding network \n",
    "> * This output will be used by either a linear reward layer and epsilon greedy exploration, or by a LinUCB logic, depending on the number of training steps executed so far\n",
    "* `EPS_PHASE_STEPS` is the number training steps to run for training the encoding network before switching to `LinUCB`\n",
    "> * If negative, the encoding network is assumed to be already trained\n",
    "> * If the number of steps is less than or equal to `EPS_PHASE_STEPS`, `epsilon greedy` is used, otherwise `LinUCB`\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_linucb_agent/NeuralLinUCBAgent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1aba6b-453f-4698-b04a-4455859e15e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### network types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dba97d-92b6-46c9-b401-449d7e56b491",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "Which network architecture to use for the `epsGreedy` or `NeuralLinUCB` agents\n",
    "\n",
    "```\n",
    "NETWORK_TYPE = ['commontower', 'dotproduct']\n",
    "```\n",
    "\n",
    "**GlobalAndArmCommonTowerNetwork:** (`commontower`)\n",
    "* This network takes the output of the global and per-arm networks, and leads them through a common network, that in turn outputs reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "> * `COMMON_LAYERS` - Iterable of ints. Specifies the layers of the common tower\n",
    "* The network produced by this function can be used either in `GreedyRewardPredictionPolicy`, or `NeuralLinUCBPolicy`\n",
    "> * In the former case, the network must have `output_dim=1`, it is going to be an instance of `QNetwork`, and used in the policy as a reward prediction network\n",
    "> * In the latter case, the network will be an encoding network with its output consumed by a reward layer or a `LinUCB` method. The specified `output_dim` will be the encoding dimension\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmCommonTowerNetwork)\n",
    "\n",
    "**GlobalAndArmDotProductNetwork:** (`dotproduct`)\n",
    "* This network calculates the **dot product** of the output of the global and per-arm networks and returns them as reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmDotProductNetwork)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f496e4-dba1-498f-a216-e6af56471383",
   "metadata": {},
   "source": [
    "### define agent and network (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "557a70e6-e20f-4bf3-b8dc-04f25e45400c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGENT_TYPE      : epsGreedy\n",
      "NETWORK_TYPE    : dotproduct\n",
      "AGENT_ALPHA     : 0.1\n",
      "EPSILON         : 0.01\n",
      "LR              : 0.05\n",
      "ENCODING_DIM    : 5\n",
      "EPS_PHASE_STEPS : 1000\n",
      "GLOBAL_LAYERS   : [16, 4]\n",
      "ARM_LAYERS      : [16, 4]\n",
      "COMMON_LAYERS   : [4]\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Agents\n",
    "# ================================\n",
    "AGENT_TYPE      = 'epsGreedy' # 'LinUCB' | 'LinTS |, 'epsGreedy' | 'NeuralLinUCB'\n",
    "\n",
    "# Parameters for linear agents (LinUCB and LinTS).\n",
    "AGENT_ALPHA     = 0.1\n",
    "\n",
    "# Parameters for neural agents (NeuralEpsGreedy and NerualLinUCB).\n",
    "EPSILON         = 0.01\n",
    "LR              = 0.05\n",
    "\n",
    "# Parameters for NeuralLinUCB\n",
    "ENCODING_DIM    = 5\n",
    "EPS_PHASE_STEPS = 1000\n",
    "\n",
    "# ================================\n",
    "# Agent's Preprocess Network\n",
    "# ================================\n",
    "NETWORK_TYPE    = \"dotproduct\" # 'commontower' | 'dotproduct'\n",
    "\n",
    "if AGENT_TYPE == 'NeuralLinUCB':\n",
    "    NETWORK_TYPE = 'commontower'\n",
    "    \n",
    "\n",
    "GLOBAL_LAYERS   = [16, 4]\n",
    "ARM_LAYERS      = [16, 4]\n",
    "COMMON_LAYERS   = [4]\n",
    "\n",
    "observation_and_action_constraint_splitter = None\n",
    "\n",
    "print(f\"AGENT_TYPE      : {AGENT_TYPE}\")\n",
    "print(f\"NETWORK_TYPE    : {NETWORK_TYPE}\")\n",
    "print(f\"AGENT_ALPHA     : {AGENT_ALPHA}\")\n",
    "print(f\"EPSILON         : {EPSILON}\")\n",
    "print(f\"LR              : {LR}\")\n",
    "print(f\"ENCODING_DIM    : {ENCODING_DIM}\")\n",
    "print(f\"EPS_PHASE_STEPS : {EPS_PHASE_STEPS}\")\n",
    "print(f\"GLOBAL_LAYERS   : {GLOBAL_LAYERS}\")\n",
    "print(f\"ARM_LAYERS      : {ARM_LAYERS}\")\n",
    "print(f\"COMMON_LAYERS   : {COMMON_LAYERS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5414c280-170b-405e-b9da-48756d721b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: neural_epsilon_greedy_agent\n",
      "\n",
      "Network: GlobalAndArmDotProductNetwork\n"
     ]
    }
   ],
   "source": [
    "from tf_agents.bandits.policies import policy_utilities\n",
    "\n",
    "network = None\n",
    "\n",
    "if AGENT_TYPE == 'LinUCB':\n",
    "    agent = lin_ucb_agent.LinearUCBAgent(\n",
    "        time_step_spec=per_arm_tf_env.time_step_spec(),\n",
    "        action_spec=per_arm_tf_env.action_spec(),\n",
    "        alpha=AGENT_ALPHA,\n",
    "        accepts_per_arm_features=True,\n",
    "        dtype=tf.float32,\n",
    "    )\n",
    "elif AGENT_TYPE == 'LinTS':\n",
    "    agent = lin_ts_agent.LinearThompsonSamplingAgent(\n",
    "        time_step_spec=per_arm_tf_env.time_step_spec(),\n",
    "        action_spec=per_arm_tf_env.action_spec(),\n",
    "        alpha=AGENT_ALPHA,\n",
    "        observation_and_action_constraint_splitter=(\n",
    "            observation_and_action_constraint_splitter\n",
    "        ),\n",
    "        accepts_per_arm_features=True,\n",
    "        dtype=tf.float32,\n",
    "    )\n",
    "elif AGENT_TYPE == 'epsGreedy':\n",
    "    obs_spec = per_arm_tf_env.observation_spec()\n",
    "    if NETWORK_TYPE == 'commontower':\n",
    "        network = global_and_arm_feature_network.create_feed_forward_common_tower_network(\n",
    "            observation_spec = obs_spec, \n",
    "            global_layers = GLOBAL_LAYERS, \n",
    "            arm_layers = ARM_LAYERS, \n",
    "            common_layers = COMMON_LAYERS,\n",
    "            # output_dim = 1\n",
    "        )\n",
    "    elif NETWORK_TYPE == 'dotproduct':\n",
    "        network = global_and_arm_feature_network.create_feed_forward_dot_product_network(\n",
    "            observation_spec = obs_spec, \n",
    "            global_layers = GLOBAL_LAYERS, \n",
    "            arm_layers = ARM_LAYERS\n",
    "        )\n",
    "    agent = neural_epsilon_greedy_agent.NeuralEpsilonGreedyAgent(\n",
    "        time_step_spec=per_arm_tf_env.time_step_spec(),\n",
    "        action_spec=per_arm_tf_env.action_spec(),\n",
    "        reward_network=network,\n",
    "        optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=LR),\n",
    "        epsilon=EPSILON,\n",
    "        observation_and_action_constraint_splitter=(\n",
    "            observation_and_action_constraint_splitter\n",
    "        ),\n",
    "        accepts_per_arm_features=True,\n",
    "        emit_policy_info=policy_utilities.InfoFields.PREDICTED_REWARDS_MEAN,\n",
    "    )\n",
    "\n",
    "elif AGENT_TYPE == 'NeuralLinUCB':\n",
    "    obs_spec = per_arm_tf_env.observation_spec()\n",
    "    network = (\n",
    "        global_and_arm_feature_network.create_feed_forward_common_tower_network(\n",
    "            observation_spec = obs_spec, \n",
    "            global_layers = GLOBAL_LAYERS, \n",
    "            arm_layers = ARM_LAYERS, \n",
    "            common_layers = COMMON_LAYERS,\n",
    "            output_dim = ENCODING_DIM\n",
    "        )\n",
    "    )\n",
    "    agent = neural_linucb_agent.NeuralLinUCBAgent(\n",
    "        time_step_spec=per_arm_tf_env.time_step_spec(),\n",
    "        action_spec=per_arm_tf_env.action_spec(),\n",
    "        encoding_network=network,\n",
    "        encoding_network_num_train_steps=EPS_PHASE_STEPS,\n",
    "        encoding_dim=ENCODING_DIM,\n",
    "        optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=LR),\n",
    "        alpha=1.0,\n",
    "        gamma=1.0,\n",
    "        epsilon_greedy=EPSILON,\n",
    "        accepts_per_arm_features=True,\n",
    "        debug_summaries=True,\n",
    "        summarize_grads_and_vars=True,\n",
    "        emit_policy_info=policy_utilities.InfoFields.PREDICTED_REWARDS_MEAN,\n",
    "    )\n",
    "    \n",
    "print(f\"Agent: {agent.name}\\n\")\n",
    "\n",
    "if network:\n",
    "    print(f\"Network: {network.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4587a396-919c-4c6e-bf37-542715987195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_TupleWrapper(Trajectory(\n",
      "{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(9, dtype=int32)),\n",
      " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
      " 'observation': DictWrapper({'global': TensorSpec(shape=(16,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(10, 16), dtype=tf.float32, name=None), 'num_actions': BoundedTensorSpec(shape=(), dtype=tf.int64, name=None, minimum=array(1), maximum=array(10))}),\n",
      " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(10,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=TensorSpec(shape=(16,), dtype=tf.float32, name=None)),\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))\n"
     ]
    }
   ],
   "source": [
    "pprint(agent.policy.trajectory_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "40f88242-084d-4a08-aea0-11d70466336b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observation_spec = per_arm_tf_env.observation_spec()\n",
    "# time_step_spec = ts.time_step_spec(observation_spec)\n",
    "# time_step_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0f5615a7-6ae1-4ffe-9703-a9e2e6a53419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# action_spec = tensor_spec.BoundedTensorSpec(\n",
    "#     dtype=tf.int32, shape=(), minimum=0, maximum=NUM_ACTIONS - 1)\n",
    "\n",
    "# action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "45a60e11-1c81-4016-bd51-e83b070c522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent = lin_ucb_agent.LinearUCBAgent(\n",
    "#     time_step_spec=time_step_spec,\n",
    "#     action_spec=action_spec,\n",
    "#     accepts_per_arm_features=True\n",
    "# )\n",
    "\n",
    "# agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19a35ac-be89-4647-b4da-5933bf4f33a6",
   "metadata": {},
   "source": [
    "## The flow of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "46d2d711-c0da-42af-9038-dc46391f35ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data spec:  Trajectory(\n",
      "{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(9, dtype=int32)),\n",
      " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
      " 'observation': DictWrapper({'global': TensorSpec(shape=(16,), dtype=tf.float32, name=None), 'num_actions': BoundedTensorSpec(shape=(), dtype=tf.int64, name=None, minimum=array(1), maximum=array(10))}),\n",
      " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(10,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=TensorSpec(shape=(16,), dtype=tf.float32, name=None)),\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n"
     ]
    }
   ],
   "source": [
    "print('training data spec: ', agent.training_data_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ec33187a-3794-4824-b3e6-ddc594129e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation spec in training:  {'global': TensorSpec(shape=(16,), dtype=tf.float32, name=None), 'num_actions': BoundedTensorSpec(shape=(), dtype=tf.int64, name=None, minimum=array(1), maximum=array(10))}\n"
     ]
    }
   ],
   "source": [
    "print('observation spec in training: ', agent.training_data_spec.observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4c5e2a2b-f957-48d4-b9da-a0c13e7eb603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen arm features:  TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n"
     ]
    }
   ],
   "source": [
    "print('chosen arm features: ', agent.training_data_spec.policy_info.chosen_arm_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165a655e-6944-4b96-9c0c-d9465b3de2ac",
   "metadata": {},
   "source": [
    "## Defining the Regret Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f6f98a09-2791-4a22-b014-178ef387596a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _all_rewards(observation, hidden_param):\n",
    "    \"\"\"Outputs rewards for all actions, given an observation.\"\"\"\n",
    "    hidden_param = tf.cast(hidden_param, dtype=tf.float32)\n",
    "    global_obs = observation['global']\n",
    "    per_arm_obs = observation['per_arm']\n",
    "    num_actions = tf.shape(per_arm_obs)[1]\n",
    "    tiled_global = tf.tile(\n",
    "        tf.expand_dims(global_obs, axis=1), [1, num_actions, 1])\n",
    "    concatenated = tf.concat([tiled_global, per_arm_obs], axis=-1)\n",
    "    rewards = tf.linalg.matvec(concatenated, hidden_param)\n",
    "    return rewards\n",
    "\n",
    "def optimal_reward(observation, hidden_param):\n",
    "    \"\"\"Outputs the maximum expected reward for every element in the batch.\"\"\"\n",
    "    return tf.reduce_max(\n",
    "        _all_rewards(observation, hidden_param), axis=1\n",
    "    )\n",
    "\n",
    "def optimal_action(observation, hidden_param):\n",
    "    return tf.argmax(\n",
    "        _all_rewards(observation, hidden_param), axis=1, output_type=tf.int32\n",
    "    )\n",
    "\n",
    "# works\n",
    "# regret_metric = tf_bandit_metrics.RegretMetric(optimal_reward)\n",
    "\n",
    "# new\n",
    "optimal_reward_fn = functools.partial(\n",
    "    optimal_reward, hidden_param=reward_param\n",
    ")\n",
    "optimal_action_fn = functools.partial(\n",
    "    optimal_action, hidden_param=reward_param\n",
    ")\n",
    "\n",
    "suboptimal_arms_metric = tf_bandit_metrics.SuboptimalArmsMetric(\n",
    "    optimal_action_fn\n",
    ")\n",
    "\n",
    "regret_metric = tf_bandit_metrics.RegretMetric(optimal_reward_fn)\n",
    "\n",
    "metrics = [regret_metric, suboptimal_arms_metric]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8874943-2949-4c0d-a800-de56bdf478a4",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "* train stationary env [example](https://github.com/418sec/agents/blob/master/tf_agents/bandits/agents/examples/v2/train_eval_per_arm_stationary_linear.py)\n",
    "* train loop [src](https://github.com/418sec/agents/blob/master/tf_agents/bandits/agents/examples/v2/trainer.py)\n",
    "\n",
    "`async_steps_per_loop`: \n",
    "* an optional integer for simulating offline or asynchronous training\n",
    "* In each training loop iteration, the driver runs this many times, each executing `steps_per_loop` driver steps, and then the agent gets asynchronously trained over this many batches sampled from the replay buffer\n",
    "* When unset or set to 1, the function performs synchronous training, where the agent gets trained on a single batch immediately after the driver runs.\n",
    "\n",
    "\n",
    "**TODO**\n",
    "* add checkpointer\n",
    "* add ditribution strategy (GPU support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ca2d6a26-70da-4d00-a317-e722760f2a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.bandits.agents.examples.v2 import trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2e398e5f-dbd4-4f42-9692-8ba44354c21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : neural-linear-bandits-v1\n",
      "RUN_NAME          : run-20230808-035548\n",
      "LOG_DIR           : gs://mabv1-hybrid-vertex-bucket/neural-linear-bandits-v1/run-20230808-035548/tb-logs\n",
      "ROOT_DIR          : gs://mabv1-hybrid-vertex-bucket/neural-linear-bandits-v1/run-20230808-035548/root\n",
      "ARTIFACTS_DIR     : gs://mabv1-hybrid-vertex-bucket/neural-linear-bandits-v1/run-20230808-035548/artifacts\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME   = f'neural-linear-bandits-v1'\n",
    "\n",
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "LOG_DIR           = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}/tb-logs\"\n",
    "ROOT_DIR          = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "20a48e3c-adbe-4972-b6fe-ada9ae6334d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tf_agents.metrics import tf_metrics\n",
    "\n",
    "from src.perarm_features import trainer_common as trainer_common\n",
    "\n",
    "TRAINING_LOOPS = 25\n",
    "STEPS_PER_LOOP = 2\n",
    "drop_arm_feature_fn = None\n",
    "ASYNC_STEPS_PER_LOOP = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d56d096e-7e8c-4d12-bead-d5927f0caf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# put these in trainer_common.py\n",
    "\n",
    "# replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "#     data_spec=agent.policy.trajectory_spec,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     max_length=STEPS_PER_LOOP * ASYNC_STEPS_PER_LOOP\n",
    "# )\n",
    "\n",
    "# # `step_metric` records the number of individual rounds of bandit interaction;\n",
    "# # that is, (number of trajectories) * batch_size.\n",
    "# step_metric = tf_metrics.EnvironmentSteps()\n",
    "\n",
    "# observers = [replay_buffer.add_batch, regret_metric, step_metric, suboptimal_arms_metric]\n",
    "\n",
    "# driver = dynamic_step_driver.DynamicStepDriver(\n",
    "#     env=per_arm_tf_env,\n",
    "#     policy=agent.collect_policy,\n",
    "#     num_steps=STEPS_PER_LOOP * BATCH_SIZE,\n",
    "#     observers=observers\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8ca5cd13-46cb-47f1-96ff-001df278948a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting checkpoint_manager: gs://mabv1-hybrid-vertex-bucket/neural-linear-bandits-v1/run-20230808-035548/root/chkpoint\n",
      "starting_loop: 0\n",
      "starting train loop...\n",
      "step = 0: loss = 8324.009765625; execution time: 1\n",
      "step = 1: loss = 6709.85986328125; execution time: 1\n",
      "step = 2: loss = 12530.330078125; execution time: 0\n",
      "step = 3: loss = 9894.7001953125; execution time: 0\n",
      "step = 4: loss = 8768.9697265625; execution time: 1\n",
      "step = 5: loss = 7674.60009765625; execution time: 0\n",
      "step = 6: loss = 13309.6201171875; execution time: 0\n",
      "step = 7: loss = 6386.52001953125; execution time: 0\n",
      "step = 8: loss = 9392.3798828125; execution time: 0\n",
      "step = 9: loss = 14712.580078125; execution time: 0\n",
      "step = 10: loss = 10188.759765625; execution time: 1\n",
      "step = 11: loss = 6219.5498046875; execution time: 0\n",
      "step = 12: loss = 7561.740234375; execution time: 0\n",
      "step = 13: loss = 11981.4697265625; execution time: 0\n",
      "step = 14: loss = 14318.349609375; execution time: 0\n",
      "step = 15: loss = 13009.4296875; execution time: 0\n",
      "step = 16: loss = 18136.119140625; execution time: 0\n",
      "step = 17: loss = 12257.7099609375; execution time: 0\n",
      "step = 18: loss = 9032.7001953125; execution time: 0\n",
      "step = 19: loss = 6323.60009765625; execution time: 0\n",
      "step = 20: loss = 9049.8701171875; execution time: 0\n",
      "step = 21: loss = 10969.73046875; execution time: 0\n",
      "step = 22: loss = 9576.4404296875; execution time: 0\n",
      "step = 23: loss = 9468.8896484375; execution time: 0\n",
      "step = 24: loss = 7873.77978515625; execution time: 0\n",
      "runtime_mins: 25\n",
      "saved trained policy to: gs://mabv1-hybrid-vertex-bucket/neural-linear-bandits-v1/run-20230808-035548/artifacts\n",
      "complete train job in 25 minutes\n"
     ]
    }
   ],
   "source": [
    "#start the timer and training\n",
    "start_time = time.time()\n",
    "\n",
    "metric_results = trainer_common.train_perarm(\n",
    "    agent = agent,\n",
    "    # replay_buffer = replay_buffer,\n",
    "    # driver = driver,\n",
    "    environment = per_arm_tf_env,\n",
    "    # step_metric = step_metric,\n",
    "    num_iterations = TRAINING_LOOPS,\n",
    "    steps_per_loop = STEPS_PER_LOOP,\n",
    "    log_interval = 1,\n",
    "    # regret_metric = regret_metric,\n",
    "    log_dir=LOG_DIR,\n",
    "    model_dir=ARTIFACTS_DIR,\n",
    "    root_dir=ROOT_DIR,\n",
    "    async_steps_per_loop = ASYNC_STEPS_PER_LOOP,\n",
    "    resume_training_loops = False,\n",
    "    get_replay_buffer_fn = None,\n",
    "    get_training_loop_fn = None,\n",
    "    training_data_spec_transformation_fn = None,\n",
    "    additional_metrics = metrics\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"complete train job in {runtime_mins} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c78ba7-de28-4d16-9bc3-7ab710e2d521",
   "metadata": {},
   "source": [
    "### bandit eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "b4b4a349-67de-43a6-8936-1ba8e06f6a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(metric_results['RegretMetric'])\n",
    "# metric_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bcb5c2bd-6a76-45ea-9753-fbc6425e222d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumberOfEpisodes\n",
      "AverageEpisodeLengthMetric\n",
      "RegretMetric\n",
      "SuboptimalArmsMetric\n",
      "AverageReturnMetric\n"
     ]
    }
   ],
   "source": [
    "for key in metric_results:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6fce5879-aca0-4842-b56c-2731b2d33d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(metric_results, metric_name):\n",
    "    plt.plot(metric_results[metric_name])\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.title(\"{} versus Step\".format(metric_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "40edd180-16ac-46c3-b08d-f375124188bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(metric_results, \"RegretMetric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "37694f99-723c-41e2-9da8-5a6549edaba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAAHHCAYAAAC88FzIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACF0ElEQVR4nO3dd3iTZfcH8G+SNuledKSluwXKHkUKIiCCDEVEUEAcIIjjBy5e9RUXIipOXK+KA3GhIoIDFBAREWSIlL3LppO2tOlMM57fH+mTNrSFpk3yZHw/19VLmibpaRqbk/s+59wyQRAEEBEREXkoudQBEBEREUmJyRARERF5NCZDRERE5NGYDBEREZFHYzJEREREHo3JEBEREXk0JkNERETk0ZgMERERkUdjMkREREQejckQEZGNJCYmYsqUKVKHQURWYjJEbuf999+HTCZDRkaG1KFI5tSpU5DJZOYPuVyOsLAwjBw5Elu3bm3RfVZWVuK5557Dn3/+adtgWyAxMREymQxDhw5t9Osff/yx+Wf/999/rb7/gwcP4rnnnsOpU6daGSlZY+XKlRg0aBAiIyPh5+eH5ORkjB8/HmvWrDFfJycnB8899xx2794tXaDkdpgMkdtZsmQJEhMT8c8//yArK0vqcCR166234ssvv8TixYtx//33Y9u2bRg8eDD27dtn9X1VVlZi7ty5TpEMAYCPjw82bNiAvLy8Bl9bsmQJfHx8WnzfBw8exNy5c61Oho4cOYKPP/64xd/Xk73++usYPXo0ZDIZZs+ejTfffBPjxo3DsWPH8O2335qvl5OTg7lz5zIZIpvykjoAIls6efIktmzZghUrVuDee+/FkiVLMGfOHIfGYDQaUVNT06oXY1vp1asXbr/9dvPnAwYMwMiRI/HBBx/g/ffflzCyOnq9HkajEUql0qrb9e/fHzt27MDSpUvx0EMPmS8/d+4cNm3ahJtuugnLly+3dbgNCIKA6upq+Pr6QqVS2f372Ur9uKWm1+sxb948XHvttfjtt98afL2goECCqMiTcGWI3MqSJUsQGhqK66+/HjfffDOWLFli/ppOp0NYWBjuuuuuBrfTaDTw8fHBo48+ar5Mq9Vizpw5SE1NhUqlQlxcHB5//HFotVqL28pkMsycORNLlixB586doVKpzMv6r7/+Oq688kq0adMGvr6+SE9Px/fff9/g+1dVVeHBBx9EeHg4AgMDMXr0aGRnZ0Mmk+G5556zuG52djamTp2KqKgoqFQqdO7cGZ9++mmzHp8BAwYAAI4fP25xeUlJCR5++GHExcVBpVIhNTUVr7zyCoxGIwDTtltERAQAYO7cueYtKDG2q6++GldffXWD7zdlyhQkJiaaPxe3715//XW89dZbSElJgUqlMm9LyWQyZGVlYcqUKQgJCUFwcDDuuusuVFZWNrhvHx8fjB07Fl9//bXF5d988w1CQ0MxfPjwRh+Dw4cP4+abb0ZYWBh8fHzQu3dv/Pzzz+avf/bZZ7jlllsAAIMHDzb/rOKKWGJiIkaNGoW1a9eid+/e8PX1xYcffmj+2sU1QyUlJXjkkUeQmJgIlUqF2NhY3HnnnSgsLGw0PgDo0qULBg8e3OByo9GItm3b4uabb7a47K233kLnzp3h4+ODqKgo3Hvvvbhw4YLFbS8V97p163DVVVchJCQEAQEB6NChA5588kmLx0QmkzVYKfvzzz8tHhsAOHbsGMaNGwe1Wg0fHx/ExsZi4sSJKC0tbfLnLSwshEajQf/+/Rv9emRkpPn7XXHFFQCAu+66y/y7+eyzz8zX3b59O0aMGIHg4GD4+flh0KBB+Pvvvy3uT3yuHT58GOPHj0dQUBDatGmDhx56CNXV1U3GSe6LK0PkVpYsWYKxY8dCqVTi1ltvxQcffIAdO3bgiiuugLe3N2666SasWLECH374ocVKxI8//gitVouJEycCML3AjB49Gps3b8Y999yDjh07Yt++fXjzzTdx9OhR/Pjjjxbf948//sB3332HmTNnIjw83JwAvP322xg9ejRuu+021NTU4Ntvv8Utt9yCVatW4frrrzfffsqUKfjuu+9wxx13oG/fvti4caPF10X5+fno27evOQGLiIjA6tWrMW3aNGg0Gjz88MOXfHzEF7PQ0FDzZZWVlRg0aBCys7Nx7733Ij4+Hlu2bMHs2bORm5uLt956CxEREfjggw9w//3346abbsLYsWMBAN26dWvur8bC4sWLUV1djXvuuQcqlQphYWHmr40fPx5JSUmYP38+MjMz8cknnyAyMhKvvPJKg/uZNGkShg0bhuPHjyMlJQUA8PXXX+Pmm2+Gt7d3g+sfOHAA/fv3R9u2bfHEE0/A398f3333HcaMGYPly5fjpptuwsCBA/Hggw/inXfewZNPPomOHTsCgPm/gGk77NZbb8W9996L6dOno0OHDo3+nOXl5RgwYAAOHTqEqVOnolevXigsLMTPP/+Mc+fOITw8vNHbTZgwAc899xzy8vKgVqvNl2/evBk5OTnm5ykA3Hvvvfjss89w11134cEHH8TJkyfxv//9D7t27cLff/9t8Tg0FveBAwcwatQodOvWDc8//zxUKhWysrIaJBDNUVNTg+HDh0Or1eKBBx6AWq1GdnY2Vq1ahZKSEgQHBzd6u8jISPj6+mLlypV44IEHLJ4P9XXs2BHPP/88nn32Wdxzzz3m5P7KK68EYPr/cOTIkUhPT8ecOXMgl8uxePFiXHPNNdi0aRP69OljcX/jx49HYmIi5s+fj23btuGdd97BhQsX8MUXX1j9s5OLE4jcxL///isAENatWycIgiAYjUYhNjZWeOihh8zXWbt2rQBAWLlypcVtr7vuOiE5Odn8+ZdffinI5XJh06ZNFtdbuHChAED4+++/zZcBEORyuXDgwIEGMVVWVlp8XlNTI3Tp0kW45pprzJft3LlTACA8/PDDFtedMmWKAECYM2eO+bJp06YJ0dHRQmFhocV1J06cKAQHB5u/38mTJwUAwty5c4Xz588LeXl5wqZNm4QrrrhCACAsW7bMfNt58+YJ/v7+wtGjRy3u84knnhAUCoVw5swZQRAE4fz58w3iEQ0aNEgYNGhQg8snT54sJCQkmD8X4woKChIKCgosrjtnzhwBgDB16lSLy2+66SahTZs2FpclJCQI119/vaDX6wW1Wi3MmzdPEARBOHjwoABA2Lhxo7B48WIBgLBjxw7z7YYMGSJ07dpVqK6uNl9mNBqFK6+8UmjXrp35smXLlgkAhA0bNjT4mRISEgQAwpo1axr92uTJk82fP/vsswIAYcWKFQ2uazQaG1wmOnLkiABAePfddy0u/7//+z8hICDA/HvetGmTAEBYsmSJxfXWrFnT4PKm4n7zzTcFAML58+ebjEd8LE+ePGlx+YYNGywep127djV4fjWX+Fj5+/sLI0eOFF588UVh586dDa63Y8cOAYCwePFii8uNRqPQrl07Yfjw4RaPbWVlpZCUlCRce+215svE59ro0aMt7uP//u//BADCnj17rI6fXBu3ychtLFmyBFFRUebtBZlMhgkTJuDbb7+FwWAAAFxzzTUIDw/H0qVLzbe7cOEC1q1bhwkTJpgvW7ZsGTp27Ii0tDQUFhaaP6655hoAwIYNGyy+96BBg9CpU6cGMdWvx7hw4QJKS0sxYMAAZGZmmi8Xt9T+7//+z+K2DzzwgMXngiBg+fLluOGGGyAIgkVcw4cPR2lpqcX9AsCcOXMQEREBtVptXqF44403LLZZli1bhgEDBiA0NNTiPocOHQqDwYC//vqrqYe8xcaNG2fedrvYfffdZ/H5gAEDUFRUBI1G0+C6CoUC48ePxzfffAPA9ByIi4szrxjUV1xcjD/++APjx49HWVmZ+ecsKirC8OHDcezYMWRnZzcr/qSkpCa34epbvnw5unfvjptuuqnB12QyWZO3a9++PXr06GHxPDUYDPj+++9xww03mJ9Xy5YtQ3BwMK699lqL3116ejoCAgIaPE8bizskJAQA8NNPP5m3RVtKXPlZu3Zto1ublzJ37lx8/fXX6NmzJ9auXYunnnoK6enp6NWrFw4dOnTZ2+/evRvHjh3DpEmTUFRUZH4sKioqMGTIEPz1118Nfr4ZM2ZYfC7+P/frr79aFTu5PiZD5BYMBgO+/fZbDB48GCdPnkRWVhaysrKQkZGB/Px8rF+/HgDg5eWFcePG4aeffjLX/qxYsQI6nc4iGTp27BgOHDiAiIgIi4/27dsDaFjQmZSU1Ghcq1atQt++feHj44OwsDDzdlP9+onTp09DLpc3uI/U1FSLz8+fP4+SkhJ89NFHDeIS66Aujuuee+7BunXrsHLlSjzyyCOoqqoyJ4b1f9Y1a9Y0uE+xbd0exatNPV4AEB8fb/G5uKV3cQ2MaNKkSTh48CD27NmDr7/+GhMnTmw00cjKyoIgCHjmmWca/KxikX1zf9ZLxV/f8ePH0aVLl2Zd92ITJkzA33//bU7Q/vzzTxQUFDR4npaWliIyMrLBz1ReXt6s5+mECRPQv39/3H333YiKisLEiRPx3XfftSgxSkpKwqxZs/DJJ58gPDwcw4cPx3vvvXfJeqH6br31VmzatAkXLlzAb7/9hkmTJmHXrl244YYbLlvLc+zYMQDA5MmTGzwWn3zyCbRabYM42rVrZ/F5SkoK5HI5Ryp4INYMkVv4448/kJubi2+//daiDVe0ZMkSDBs2DAAwceJEfPjhh1i9ejXGjBmD7777Dmlpaejevbv5+kajEV27dsWCBQsa/X5xcXEWnzfWkbNp0yaMHj0aAwcOxPvvv4/o6Gh4e3tj8eLFDYp+m0N8cbr99tsxefLkRq9zcQ1Pu3btzEnNqFGjoFAo8MQTT2Dw4MHo3bu3+X6vvfZaPP74443ep5gAXopMJoMgCA0uvzjxEl2qg0mhUDR6eWP3DwAZGRlISUnBww8/jJMnT2LSpEmNXk98/B599NEmV3UuTkCb4ogOrAkTJmD27NlYtmwZHn74YXz33XcIDg7GiBEjzNcxGo2IjIy0aBSo7+LVt8bi9vX1xV9//YUNGzbgl19+wZo1a7B06VJcc801+O2336BQKJpcxWrs9/vGG29gypQp+Omnn/Dbb7/hwQcfNNfkxMbGNutnDwoKwrXXXotrr70W3t7e+Pzzz7F9+3YMGjSoyduIv9/XXnsNPXr0aPQ6AQEBl/y+l1qtI/fGZIjcwpIlSxAZGYn33nuvwddWrFiBH374AQsXLoSvry8GDhyI6OhoLF26FFdddRX++OMPPPXUUxa3SUlJwZ49ezBkyJAW/4Fcvnw5fHx8sHbtWouW68WLF1tcLyEhAUajESdPnrR4p3rxjKSIiAgEBgbCYDA0OWzwcp566il8/PHHePrpp83bcykpKSgvL7/sfV7qcQgNDcWJEycaXH769OkWxWmtW2+9FS+88AI6duzY5AthcnIyAMDb27tVP6s1UlJSsH///hbdNikpCX369MHSpUsxc+ZMrFixAmPGjLF4LqWkpOD3339H//79W5WgyeVyDBkyBEOGDMGCBQvw0ksv4amnnsKGDRswdOhQ8+pcSUmJxe2a+v127doVXbt2xdNPP40tW7agf//+WLhwIV544QWrY+vduzc+//xz5ObmAmj6dyMW0AcFBTX7/49jx45ZrJZlZWXBaDRadECSZ+A2Gbm8qqoqrFixAqNGjcLNN9/c4GPmzJkoKyszt0/L5XLcfPPNWLlyJb788kvo9XqLrQfA1GWSnZ3d6AC9qqoqVFRUXDYu8R11/XfPp06datCJJq5SXDz35913321wf+PGjcPy5csbfYE9f/78ZWMKCQnBvffei7Vr15qH1o0fPx5bt27F2rVrG1y/pKQEer0eAODn52e+7GIpKSk4fPiwRQx79uxpUUdSS9x9992YM2cO3njjjSavExkZiauvvhoffvih+YW1vvqx+/v7A2j8Z7XGuHHjsGfPHvzwww8NvtbUSld9EyZMwLZt2/Dpp5+isLCw0eepwWDAvHnzGtxWr9c3K/7i4uIGl4kJpbiVLCYa9evHDAYDPvroI4vbaTQa8/NF1LVrV8jl8gYjKeqrrKxscjL66tWrAcDcsdfU7yY9PR0pKSl4/fXXUV5e3uB+Gvv/4+I3T+L/cyNHjmwyVnJPXBkil/fzzz+jrKwMo0ePbvTrffv2RUREBJYsWWJ+MZkwYQLeffddzJkzB127drVomwaAO+64A9999x3uu+8+bNiwAf3794fBYMDhw4fx3XffmWe1XMr111+PBQsWYMSIEZg0aRIKCgrw3nvvITU1FXv37jVfLz09HePGjcNbb72FoqIic2v90aNHAVi+E3755ZexYcMGZGRkYPr06ejUqROKi4uRmZmJ33//vdEXtos99NBDeOutt/Dyyy/j22+/xWOPPYaff/4Zo0aNwpQpU5Ceno6Kigrs27cP33//PU6dOoXw8HD4+vqiU6dOWLp0Kdq3b4+wsDB06dIFXbp0wdSpU7FgwQIMHz4c06ZNQ0FBARYuXIjOnTs3WvhsawkJCQ3mMTXmvffew1VXXYWuXbti+vTpSE5ORn5+PrZu3Ypz585hz549AEzJgEKhwCuvvILS0lKoVCpcc8015nk3zfXYY4/h+++/xy233IKpU6ciPT0dxcXF+Pnnn7Fw4UKLrdnGjB8/Ho8++igeffRRhIWFNVjxGDRoEO69917Mnz8fu3fvxrBhw+Dt7Y1jx45h2bJlePvtty2K5Rvz/PPP46+//sL111+PhIQEFBQU4P3330dsbCyuuuoqAEDnzp3Rt29fzJ49G8XFxQgLC8O3337bIPH5448/MHPmTNxyyy1o37499Ho9vvzyS3Mi35TKykpceeWV6Nu3L0aMGIG4uDiUlJTgxx9/xKZNmzBmzBj07NkTgCkxCwkJwcKFCxEYGAh/f39kZGQgKSkJn3zyCUaOHInOnTvjrrvuQtu2bZGdnY0NGzYgKCgIK1eutPi+J0+exOjRozFixAhs3boVX331FSZNmnTZ3wu5ISlb2Yhs4YYbbhB8fHyEioqKJq8zZcoUwdvb29ySbjQahbi4OAGA8MILLzR6m5qaGuGVV14ROnfuLKhUKiE0NFRIT08X5s6dK5SWlpqvB0CYMWNGo/exaNEioV27doJKpRLS0tKExYsXm9t666uoqBBmzJghhIWFCQEBAcKYMWPM7dUvv/yyxXXz8/OFGTNmCHFxcYK3t7egVquFIUOGCB999JH5OmIL+2uvvdbk46FQKISsrCxBEAShrKxMmD17tpCamioolUohPDxcuPLKK4XXX39dqKmpMd9uy5YtQnp6uqBUKhu02X/11VdCcnKyoFQqhR49eghr165tsrW+sbjEx+XiFu/G2rrF1vpLaay1XhAE4fjx48Kdd94pqNVqwdvbW2jbtq0watQo4fvvv7e43scffywkJycLCoXCon38Ut/74tZ6QRCEoqIiYebMmULbtm0FpVIpxMbGCpMnT24wHqEp/fv3FwAId999d5PX+eijj4T09HTB19dXCAwMFLp27So8/vjjQk5OjkVsjcW9fv164cYbbxRiYmIEpVIpxMTECLfeemuDUQvHjx8Xhg4dKqhUKiEqKkp48sknhXXr1lk8NidOnBCmTp0qpKSkCD4+PkJYWJgwePBg4ffff7/kz6jT6YSPP/5YGDNmjJCQkCCoVCrBz89P6Nmzp/Daa68JWq3W4vo//fST0KlTJ8HLy6tBm/2uXbuEsWPHCm3atBFUKpWQkJAgjB8/Xli/fr35OuJz7eDBg8LNN98sBAYGCqGhocLMmTOFqqqqS8ZK7kkmCM1YqyUih9u9ezd69uyJr776CrfddpvU4RC5jeeeew5z587F+fPnmxx8SZ6FNUNETqCqqqrBZW+99RbkcjkGDhwoQURERJ6DNUNETuDVV1/Fzp07MXjwYHh5eWH16tVYvXo17rnnngZt/EREZFtMhoicwJVXXol169Zh3rx5KC8vR3x8PJ577rkGLf9ERGR7rBkiIiIij8aaISIiIvJoTIaIiIjIo7Fm6CJGoxE5OTkIDAzkOTVEREQuQhAElJWVISYmBnK5dWs9TIYukpOTw+4dIiIiF3X27NlmHwosYjJ0kcDAQACmBzMoKEjiaIiIiKg5NBoN4uLizK/j1mAydBFxaywoKIjJEBERkYtpSYkLC6iJiIjIozEZIiIiIo/GZIiIiIg8GpMhIiIi8mhMhoiIiMijMRkiIiIij8ZkiIiIiDwakyEiIiLyaEyGiIiIyKMxGSIiIiKPxmSIiIiIPBqTISIiIvJoTIaIiIichM5glDoEj8RkiIiIyAlsySpEp2fX4OO/TkgdisdhMkREROQEFm0+CZ1BwIYjBVKH4nGYDBEREUmsqFyLjUfPAwDOXaiSOBrPw2SIiIhIYqv25kJvFAAAOSVVMNT+mxyDyRAREZHEftiVbf633iggX1MtYTSeh8kQERGRhE4WVmD32RLIZUConzcAbpU5GpMhIiIiCf1Yuyp0VbsIdIwOAgCcu1ApZUgeh8kQERGRRARBwI+7TcnQ2J5tERvqC4ArQ47GZIiIiEgiu86W4HRRJfyUCgzrHIXYUD8AQDaTIYdiMkRERCSRHzJNq0LDO6vhp/SqWxkq4TaZIzEZIiIikkCN3ohVe3MAAGN6tgUA88oQt8kci8kQERGRBP46eh4XKnUID1Chf0obADCvDHHWkGMxGSIiIpLAD7WF0zf2iIGXwvRyHBXkAy+5DDqDgIIyzhpyFCZDREREDqap1uH3g/kAgJtqt8gAQCGXISaEHWWOxmSIiIjIwdbsz4NWb0RqZAA6xwRZfK2uvZ5F1I7CZIiIiMjBxC6ym3q2hUwms/iaORkq5sqQozAZIiIicqCckipsO1kEABjdPabB19uGsKPM0ZgMEREROdDPe3IgCECfpDDEhfk1+DpnDTkekyEiIiIHEs8iq184XZ+YDHEKteMwGSIiInKQQ7kaHM4rg1Ihx3Vdohu9TmztalF2SRWMnDXkEEyGiIiIHERcFbomLRLBft6NXicqUFVv1pDWkeF5LCZDREREDmAw1p1QP6aJLTIA8FLIER3iA4Dt9Y7CZIiIiMgBtp0oQr5Gi2BfbwxOi7jkdWPZUeZQTIaIiIgc4IfaLbLru0VD5aW45HU5eNGxmAwRERHZWVWNAWv25wFouousPp5e71gumwy9/PLLkMlkePjhh82XVVdXY8aMGWjTpg0CAgIwbtw45OfnSxckERERgN8P5aNcq0dsqC/S40Mve/26lSEmQ47gksnQjh078OGHH6Jbt24Wlz/yyCNYuXIlli1bho0bNyInJwdjx46VKEoiIiITcYtsTI+2kMtll7k2t8kczeWSofLyctx22234+OOPERpal12XlpZi0aJFWLBgAa655hqkp6dj8eLF2LJlC7Zt2yZhxERE5MmKyrXYePQ8gEt3kdXXVhy8yFlDDuFyydCMGTNw/fXXY+jQoRaX79y5EzqdzuLytLQ0xMfHY+vWrU3en1arhUajsfggIiKylVV7c2EwCugWG4zUyIBm3UYd5AMFZw05jEslQ99++y0yMzMxf/78Bl/Ly8uDUqlESEiIxeVRUVHIy8tr8j7nz5+P4OBg80dcXJytwzYTBGb3RGQ/B3JKcbaY2yrOpv4WWXN5KeSIDjbNGsrmGWV25zLJ0NmzZ/HQQw9hyZIl8PHxsdn9zp49G6WlpeaPs2fP2uy+RVq9AVe/tgFpz6xBWbXO5vdPRHTuQiVuem8Lbl+0nW+8nMjJwgrsPlsChVyGGxo5of5SWETtOC6TDO3cuRMFBQXo1asXvLy84OXlhY0bN+Kdd96Bl5cXoqKiUFNTg5KSEovb5efnQ61WN3m/KpUKQUFBFh+2pvJSoLiiBlq9EfmaapvfPxHRthPFqDEYcbqoktsqTkQ8fuOq1HBEBKqsui3b6x3HZZKhIUOGYN++fdi9e7f5o3fv3rjtttvM//b29sb69evNtzly5AjOnDmDfv36SRi5SXSwKcPPLWUyRES2t/N0sfnfB3NZ++gMBKHu+I3mzBa6GDvKHMdL6gCaKzAwEF26dLG4zN/fH23atDFfPm3aNMyaNQthYWEICgrCAw88gH79+qFv375ShGxBHeyDI/llyC1hMkREtvfvqQvmfx/M0WBwh0gJoyEAyDxTgtNFlfBTKjCsc5TVt+fKkOO4TDLUHG+++SbkcjnGjRsHrVaL4cOH4/3335c6LAAwF8JxZYiIbK20UodjBeXmzw9xZcgpiFtkIzqr4ae0/uWWNUOO49LJ0J9//mnxuY+PD9577z2899570gR0CeraZChPwyc1EdlW5pkLFp8zGZJejd6IVXtzADR/ttDFxGQo+4Jp1lBzhjVSy7hMzZCr48oQEdnLztOmZGhge9NJ6CcLK1CtM0gZksf76+h5XKjUISJQhStT2rToPsRZQzUGI86XsyjenpgMOYhYQJ3HZIiIbOzf2uLpEZ3VaOOvhFEAjuSVSRyVZ/uhtnB6dPcYeCla9lLrpZBDHWR6I80iavtiMuQgXBkiInvQGYzYc7YUANA7MRQdo03jQbhVJh1NtQ7rDpoOCW9JF1l9rBtyDCZDDiLWDJVW6VBZo5c4GiJyF4dyNajSGRDk44XUiAB0imEyJLU1+/JQozeiXWQAOse0bnYdO8ocg8mQgwT6eCNAZapX5+oQEdmK2FKfnhAKuVyGjtGBAIBDudwmk4r5+I2ebSGTta7omStDjsFkyIHMHWVMhojIRnaeqUuGANRtk+VpeCyHBHJKqrDtZBEA4MYe1h2/0RgOXnQMJkMOxLohIrIlQRCw07wyFAYASIkIgFIhR1m1nqsJEvh5Tw4EAeiTFGbe4moN8T6y+bu0KyZDDhRtXhnik5qIWi+ntBp5mmoo5DJ0jwsGAHgr5EiNDADAuiEpiIMWx7aycFpkXhkqMc0aIvtgMuRAap5PRkQ29O8pU0t955ggiwnH4lYZzyhzrIM5GhzOK4NSIcfIrtE2uc/o4NpZQ3ojCjlryG6YDDlQNGuGiMiGMmuHLfaKD7W4vK6ImsmQI4mHsg7pGIlgX2+b3Gf9WUNnuVVmN0yGHEgsoM5hMkRENvBvbTLUO9EyGepknjXEjjJHMRgF/LS7rovMllhEbX9MhhyINUNEZCvlWr155UfsJBOJ22RniitRVq1zeGyeaNuJIuRrtAj29cbVHSJset9t2V5vd0yGHCg6yPSEvlCp47lBRNQqe86WwCgAbUN8zcf9iEL9leatFR7L4RjibKFR3aKh8lLY9L45eNH+mAw5UJCvF3y9Tf+TsG6IiFqj/rDFxrBuyHGqagxYsz8PQOuP32gMt8nsj8mQA8lkMkSHcNYQEbXexcMWL1bXUcaVIXtbdygf5Vo9YkN9m/x9tIaYDGWXcGXIXpgMOZi5bkjDJzURtYzBKGDX6UsnQzyjzHHE2UI32eD4jcbE1Ru8yKni9sFkyMHUQZw1REStc6ygDGVaPfyVCqSpAxu9jrgydCSvDAYO67Ob4ooabDx6HgBwYw/bb5EBpk5kuQzQ6o04z1lDdsFkyMHMR3KUMBkiopYR64V6xIfAS9H4n/HENv7w8ZajSmfA6aIKR4bnUbadKILBKCBNHWie/G1r3gq5uUieRdT2wWTIwdQ8n4yIWmnnacvzyBqjkMvQQc15Q/aW2cSsJ1tje719MRlyMNYMEVFr7bxMvZCoU21H2cHcUrvH5Kl2nS0BAPSMs28yxI4y+2Iy5GBqHslBRK1QUFaNM8WVkMmAnvEhl7xuR06itqsavRH7sk2JZi87dJHVx1lD9sVkyMFiavd9C8troNVz8CIRWUfclukQFYggn0uff1WXDLGjzB4O5mpQozci1M8biW387Pq9YkO4TWZPTIYcLMTPGyov08NeoGFXABFZ53LDFusTO81yS6tRUllj17g8kZiY9owPtUtLfX3cJrMvJkMOJpPJzHVDORygRURWEoctNqdgN9DHG3FhphfRg1wdsrm6eqEQu3+vWM4asismQxIw1w1pWDdERM1XrTNgf22NSnp8051k9XVkR5ndiCtD9q4XAjhryN6YDElAnBfB9noissbec6XQGQREBKrMKz6Xw7oh+yjQVCO7pAoyGdAtNtju30/pJTcfvpvNuiGbYzIkAXaUEVFLmFvqrahR4bEc9pF5pgSAqZA98DKF7LbCjjL7YTIkgRjz4EU+oYmo+XaeLgZg3YC/TrUrQ8fyy6EzGO0SlyfadVYsng5x2PeM5eBFu2EyJAF17TYZV4aIqLkEQTCvDFlToxIb6otAlRdqDEacOM9jOWxl1+kSAKZOMkdhR5n9MBmSgLmbjMkQETXTicIKXKjUQeUlR5eY5teoyGQypNVOouZWmW3oDEbszS4BAPRy6MoQt8nshcmQBMSaocJyLWr0XLYmossTV4W6x4ZA6WXdn26xiJrt9bZxJK8M1Tojgny8kBxun8NZG8OVIfthMiSBMD8llAo5BME0Wp+I6HJ2nmp5Gzc7ymwrs3bWU4/4UMjl9h22WF/9w1o5a8i2mAxJQC6XISpYBYB1Q0TUPP+KxdNMhiS3q7aTzJFbZIBpLIusdtZQYTknitsSkyGJRAdx1hARNc+Fihocry1+bsnKUIeoQMhlpjMRuRrdeuLKkCOLpwHLWUPcKrMtJkMSiQ7hrCEiah7xxTc5wh9h/kqrb++rVCAx3B8AJ1G3VlG5FqeLTIlIDwccw3ExttfbB5MhiajNs4aYDBHRpYnF0y3ZIhNxq8w2xC2y1MgABPs6ZthifeYzyni2pU0xGZJIdBAHLxJR8/x7uvkn1TelE5MhmxCHLTq6XkjEjjL7YDIkETXPJyOiZtAZjNhTezp6ekLzDmdtDJMh28iUYNhifdwmsw8mQxKJ5vlkRNQMB3I00OqNCPHzRnJt3U9LiNtkx89XoFpnsFV4HsVgFLDnXAkAoJdkyRAHL9oDkyGJiMlQQVk19DwviIia8O8pU0t9eitn2kQFqRDq5w2DUUBWQbmtwvMoR/LKUFljQIDKC6mRjhu2WF/9bTLOGrIdJkMSaROggpdcBqMAnC/XSh0OETkpsZOsJS319clksrpJ1DncKmsJsV6oR1wIFA4ctlifOGuoWmdEUQVnDdkKkyGJKOQyRAWxo4yImiYIAv491fpOMhGP5WidunqhEMliUHrJERUozhriVpmtMBmSkLhVllvCZIiIGjp3oQoFZVp4yWXoboOZNmyvb526TjJp6oVE7CizPSZDEqqbNcTsnogaEucLdW4bDB9vRavvr2O90+tZb2KdksoanKidAi7FsMX62FFme0yGJMSOMiK6FFsMW6wvNTIAXnIZNNV65PDvjlV21Y43SA73R2gLpoDbUl1HGVeGbIXJkITMs4Y0/KNERA3ZYthifSovhbkL6hCLqK2y67R4Un2ItIGAK0P2wGRIQlwZ8kxniysx6eNt2Hq8SOpQyImVVetwJM+UsNgqGQJYN9RS4sqQ1PVCQL0jOZgM2QyTIQkxGfJMS3ecxZbjRXh7/VGpQyEntvtsCYyCaRVA7Dy1BXPdUB6ToeYyGgXsrj2TTMpOMlH9lSHWftkGkyEJRdduk+VrqmEw8gntKU4UmgbeZZ4uQVUNJwFT42zZUl9fp+hgADy93hpZ58tRptXDT6lAh6hAqcNBdIgPZDKgSmdAMWcN2QSTIQlFBKqgkMugNwoo5OBFjyF2pNQYjNhRO12Y6GLisMX0xJafR9YYcWXoVFEFKmv0Nr1vd5VZWy/ULTYYXgrpXzZVXgrOGrIx6X+rHkwhlyEyUAWAgxc9hdEo4GRhhfnzv7MKJYyGnJXBKGBX7bZMuo1rVNoEqBAZqIIgAIfzuDrUHOLvwhnqhUQsorYtJkMSU5vrhviE9gTZJVXQ6uvOotvMZIgacSSvDOVaPQJUXuigtv22DI/lsI64SifVSfWN4eBF23KZZGj+/Pm44oorEBgYiMjISIwZMwZHjhyxuE51dTVmzJiBNm3aICAgAOPGjUN+fr5EETePeQo1V4Y8wonaVaGI2hXBAzka7vlTAztPm7ZPe8bb5wwsdpQ1X2mVDsdqD7Z1huJpUVuuDNmUyyRDGzduxIwZM7Bt2zasW7cOOp0Ow4YNQ0VF3ZbDI488gpUrV2LZsmXYuHEjcnJyMHbsWAmjvjx1kOkJzY4yz3DivOmPaq/4EKTVvuPfcpyrQ2TJ1vOFLlZ/EjVd2p7alvr4MD+EB6ikDaYeDl60LS+pA2iuNWvWWHz+2WefITIyEjt37sTAgQNRWlqKRYsW4euvv8Y111wDAFi8eDE6duyIbdu2oW/fvlKEfVkxIVwZ8iRi8XRyRABiQ/1wOK8Mf2cVYlS3GIkjI2dSN3natsXTok61K0OH88pgNAqQS3QCuyuoqxcKkTSOi7FmyLZcZmXoYqWlpQCAsDDTH4udO3dCp9Nh6NCh5uukpaUhPj4eW7dubfJ+tFotNBqNxYcj8XwyzyK21SeH++Oq1HAArBsiS/maapy7UAW5zH7TjpPC/aH0kqOyxoAzxVxZuBRnrBcC6q8McdaQLbhkMmQ0GvHwww+jf//+6NKlCwAgLy8PSqUSISEhFteNiopCXl5ek/c1f/58BAcHmz/i4uLsGXoDrBnyLPVXhvokhcFLLsPZ4iqcKeILEpmIq0Jp6iAEqOyzeO+lkJvn5XCrrGlGo4DdTjR5uj5xV4GzhmzDJZOhGTNmYP/+/fj2229bfV+zZ89GaWmp+ePs2bM2iLD51PUGLxo5eNGtVdbozUlvSoQ//FVe5j+wXB0ikThs0V71QiLWDV3eicIKlFbp4OMtR1q09MMW61N5KRAVZKphyi5xnZ2Fap0BZ51wNdLlkqGZM2di1apV2LBhA2JjY82Xq9Vq1NTUoKSkxOL6+fn5UKvVTd6fSqVCUFCQxYcjRQaqIJMBOoOAImb3bk1cFQrzVyLEz3Tqdf/arTLOGyLRztptmd6J9k6GatvrOYm6Sbtqfxfd2obA2wmGLV6s/laZK8g8cwHXv7MJUz/bAa3euabvO99vtwmCIGDmzJn44Ycf8McffyApKcni6+np6fD29sb69evNlx05cgRnzpxBv379HB1us3kr5Iio7VBgR5l7E9vqk8P9zZdd1a4NAODv44VcGSRU1RhwINtUD2nvbZlObK+/rEwnOo+sMa4ya6haZ8BLvx7CzR9swfHzFSip0uFUoXPF7DLdZDNmzMDXX3+Nn376CYGBgeY6oODgYPj6+iI4OBjTpk3DrFmzEBYWhqCgIDzwwAPo16+f03aSiaKDfVBQpkVuaRW6xgZLHQ7ZidhWnxxRlwx1iw1BgMoLJZU6HMzVoEtb/v492Z5zJdAbBUQFqcwvdPaSVpsMZZdUobRKh2Bfb7t+P1e0y0mLp0Wu0FG283QxHlu21/xmcGyvtnh2VCfz6rizcJmVoQ8++AClpaW4+uqrER0dbf5YunSp+TpvvvkmRo0ahXHjxmHgwIFQq9VYsWKFhFE3j3hga56GK0PurH7xtMhbIUffZFNHJOuGqH5LvUxm33b3YF9vtA0x/e05zNWhBsq1ehzNN20hOltbvciZt8mqagx4YdVB3LxwK04UViAqSIVFk3tjwfgeTpcIAS1YGVq8eDECAgJwyy23WFy+bNkyVFZWYvLkyTYLrr7mtA76+Pjgvffew3vvvWeXGOxFbK/PKWEy5M7qt9XX1z81HL8fKsDfWYW4b1CKFKGRkxCToV52Lp4WdYwOQnZJFQ7mapCR3MYh39NV7D1bAqMAtA3xRWSQj9ThNEpMZp1tm2zHqWI8/v1e8zmMN6fH4pnrOyHYz3lXH61eGZo/fz7Cw8MbXB4ZGYmXXnrJJkF5mmieT+b2BEHAyUZWhgCY5w39c7IY1TrnKiokxzEaBfNMm94OSoY6saOsSXXzhUKkDeQS6m+TOcOsocoaPeauPIDxH27FycIKqIN8sPiuK/D6Ld2dOhECWrAydObMmQbFywCQkJCAM2fO2CQoT6PmrCG3l6/RoqLGAIVchvgwP4uvpUYGIDJQhYIyLTJPX8CVqQ3fbJD7O1FYjpJKUxt3pxjHdLXWnVHGjrKLOeNJ9ReLqV0Zqqwx4EKlDmH+0m0/bT9RhMeX78Xp2plpE3rH4alRHRHk49xJkMjqlaHIyEjs3bu3weV79uxBmzZcZm0J1gy5P7F4Oj7MD0ovy//tZDIZp1GTeYuse6zj2rjFZOhIfhn0BqNDvqcrEAQBu2qHLTrzypCPtwKRtYc+S7VVVqHVY85P+zHho204XVSJ6GAffD61D165uZvLJEJAC5KhW2+9FQ8++CA2bNgAg8EAg8GAP/74Aw899BAmTpxojxjdXv0p1M6w1Em2d7yRtvr6OG+IHDVssb74MD/4KxWo0RvN9R0EnC6qRHFFDZRecnSOce4OTyk7yrYcL8SIt//C51tPAwBu7ROHtY8MxKD2EQ6PpbWs3iabN28eTp06hSFDhsDLy3Rzo9GIO++8kzVDLRRVW5xXozdKvtRJ9tFYW319YjK0N7sUpZU6p99fJ9szd5LZedhifXK5DB3Ugcg8U4KDuRq0i3KuKctSEeuFusQENVjJdTaxoX7IPFOCbAcmQxVaPV5efRhfbjMlQW1DfDF/bFcMdMEkSGR1MqRUKrF06VLMmzcPe/bsga+vL7p27YqEhAR7xOcRlF5yhAeoUFiuRU5JFZMhN9RYW3196mAfpEYGIKugHFtPFGJEl2hHhkcSK66oMc9hcXSNSsfoIGSeKcGh3DLc2MOh39ppuUK9kMjRgxf/zirEf5fvNa9E3ZYRjydGpiHQhbbEGtPioYvt27dH+/btbRmLR4sO9kFhuRZ5pdUcvOeGmmqrr++q1HBkFZTj76wiJkMeRlwVSo0McPgMlo6cRN2As55U3xhHzRoqq9Zh/urD+Hq7qVGqbYgvXr25m3lV29U1KxmaNWsW5s2bB39/f8yaNeuS112wYIFNAvM06mAf7MsuRS6LqN1Otc5g/kPV1MoQYNoq+2zLKdYNeaC6YYuOf/EVO9eYDJlU1uhxOK922GJCiLTBNIMjaob+PVWMh77dbT4Q9o6+CfjvyDQEqFzmEIvLatZPsmvXLuh0OgBAZmZmk5NR7T0x1Z1x1pD7Ol1UCUEAAn28EB7Q9Lv+jOQwKOQynCisQHZJlXmgGrm/naeLAThu2GJ9aepAyGRAQZkWReVatKk9K9FT7T1XCoNRgDrIx9zp68zqb5MJgmDz12Gt3oD7vspEYbkWcWG+eGVcN1yZ4h6rQfU1KxnasGGD+d9//vmnvWLxaJw15L7qiqcDLvmHKsjHG91jg5F5pgR/ZxVifO84R4VIEqrRG7HnnOlwVilWhvyUXkhs44+ThRU4lFuGq9p5djJkrhdygVUhoG7WUEWNASWVOoTauOb01325KCzXIipIhTUPDYS/G60G1WdVmbxOp4OXlxf2799vr3g8Vt3KEJMhdyMWxqZcol5IdBVb7D3O/pxS1OiNCPNXIqkZzxF76Fg7ifpgbqkk39+ZmOuF4py/XggwzRqKMM8asv3OwmdbTB1jt2UkuG0iBFiZDHl7eyM+Ph4GA48MsDXz4EUmQ27n+GXa6uu7sl4yxJlTnmFn7XyhXvGhkpUadFRzEjVQO2zRxVaGAPt1lO0+W4I9Z0ugVMhxa594m963s7F6gMJTTz2FJ598EsXFxfaIx2OJK0M5pc5xxgzZzuXa6uvrGR8CX28FCstrcCTfs1+YbK2oXIv3NmThbLFzHWopxXyhi7GjzOTchSoUlmvhrZA5/bDF+uzVUfb5llMAgOu7RZtXn9yV1Wte//vf/5CVlYWYmBgkJCTA39/y3W5mZqbNgvMk4uDFap0RpVU6h7fXkn0IgnDZgYv1qbwU6JMUho1Hz2PzsUKkqR1zRpW7EwQBDy/djU3HCvHF1lP47t5+SGgjzZZUfUfyysxboo6cPH2xjrUdZVkF5dDqDVB5KSSLRUriFlmnmGD4eLvOY2CPlaHzZVqs2psDAJh8ZaLN7tdZWZ0M3XjjjewaswMfbwXC/JUorqhBbmk1kyE3UVRRA021HjIZkNjMF9+rUsOx8eh5/J1ViLsHJNs5Qs+wen8eNh0zJR35Gi0mfbwd393XT9KOvayCMtz2yTaUafXoHheCnnEhksUSE+yDIB8vaKr1yCood6lVEVsSt8ik/F20hD3a67/55wx0BgHd40LQw8Uej5awOhl67rnn7BAGAYA6yAfFFTXIK602L1uTaxO3yNqG+Db7naY4xGz7yWLU6I1OfxyAs6vQ6vH8yoMAgDv7JWDzsUKcKKzApI+34bt7+5lXZR3p+Ply3PrxdhSW16BzTBA+v+sKeDnocNbGyGQydIwOwvaTxTiUW+bByVBt/ZaEq3QtIW6TiXOAWktnMGLJdlPh9JQrPeN0Cav/70tOTkZRUVGDy0tKSpCczHexrRHN9nq3U7+tvrnS1IFo469EZY0Bu2tPzqaWe2f9MeRpqhEX5osnr+uIJdMzEBfmi9NFlZj08TYUlmsdGs+p2kTsfJkWaepAfDUtwylWgj29bqhaZ8CBHNPP7sorQ7aoOV2zPw/5Gi3CA5S4rqtnTMO3Ohk6depUo91kWq0W586ds0lQnkrNwYtu58RlTqtvjFwuM3eVbWaLfasczS/Dos0nAQBzR3eGj7cC0cG++PruvogO9sHx8xW4/ZPtKKmscUg8Z4oqcevH25Cv0aJ9VACW3J1h87kwLdXJw5Oh/dml0BsFRASqzMmFqxC3e8u1epRW6Vp9f19sPQUAmNQn3mPqx5q9Tfbzzz+b/7127VoEB9ctoxoMBqxfvx5JSUm2jc7DiMOzcrgy5DbElaGUZhRP13dVahus3JODv7MKMetangHYEoIg4Nmf9kNvFDC0YxSuSYsyfy0uzA9fT++L8R9uxeG8Mtyx6B8smZ6BIDseNnnugikRyi2tRkqEP5bc3deppj3XP5bDHpOMnV3dfKEQl/vZxVlD58u0OHehqlUrjQdySrHj1AV4yWW4ra9nbJEBViRDY8aMAWDaW548ebLF17y9vZGYmIg33njDpsF5GnUQBy+6G2va6usT64Z2ny1BWbXO5U+ElsLPe3Kw7UQxfLzlmHNDpwZfTwr3x9d3Z2DCR9uwL7sUdy3egS+m9rHLYLmckirc+vE2ZJdUITncH99M7+t0rcqpkQFQyGW4UKlDvkZrXqn2FHXzhVyrXkjUNsS3NhmqbNVh32I7/Yguaknq6aTS7G0yo9EIo9GI+Ph4FBQUmD83Go3QarU4cuQIRo0aZc9Y3V5dzRC3ydyBzmDEmdqZNs1pq68vNtQPiW38YDAK2H6CM72spanW4YVfDgEAZg5ORVyYX6PXaxdlqtkJ9vXGztMXMO3zHaiqse1Q2bzSatz68TacLa5CQhvTilSkE77I+HgrzCuYnjaJWhAEi5UhV2SLjrILFTX4abepnX6KB7TT12d1zdDJkycRHm5611pdzRUMW6p/PhkHL7q+M8WV0BsF+CkV5lU/a/Rn3VCLvbXuGM6XaZEU7o/pAy/d2NEpJghfTO2DQJUXtp0oxj1f/otqnW0SogJNNSZ9vA2niyoRF+aLb6b3deoVl7oias8a+JlbWo18jRYKuQzdYkOkDqdFbDF48dsdZ6HVG9E5JkjSuVdSsDoZMhqNmDdvHtq2bYuAgACcOHECAPDMM89g0aJFNg/Qk4h/JCtrDCjT6iWOhlpL3CJLCvdvUQ0CzylrmUO5GnxeWwA6d3TnZhWAdo8LweK7roCfUoFNxwox8+tM1OiNrYrjfJkWt368DScKK9A2xFS0HSPhXKPmEJOhgx5WRC2uCnWMDoSv0jULhls7eFFvMOKrbaZ2+slXJrpc3VRrWZ0MvfDCC/jss8/w6quvQqmsK9Lq0qULPvnkE5sG52n8lF4I9jXVhrBuyPW1pK2+vn4pbSCTAccKypGv4fOhOYxGAc/8uB8Go4DruqoxsH1Es2/bOzEMn0zuDZWXHL8fKsDDS3dBb2hZQlRUrsVtn2zD8fMViA72wTfT+za5VedMPLW93lwvFO+6qyGt3Sb7/VABskuqEOrnjdHdY2wZmkuwOhn64osv8NFHH+G2226DQlGXQXfv3h2HDx+2aXCeiLOG3Ie5eLqFJ5GH+CnRtbYQkqtDzbM88xz+PX0BfkoFnhnVsGj6cq5MCceHd6RDqZDj1315eOz7vTAYrduyvlBRg9s+2Y6j+eWIClLhm+l9Ed/G+RMhoO70+lOFFTavnXJm5nqh+BBpA2mF+ttkLSmzEAunJ/aJd6mjSGzF6mQoOzsbqampDS43Go3Q6Vo/38DTmZMhG00SJemcKGz+mWRNYd1Q85VW6vDyatMbsgeHtEN0cMu2pK7uEIn/TeoJL7kMP+zKxlM/7IOxmQlRaaUOty/ajsN5ZYgIVOHr6X2R2MJkWAqRgT4ID1DCKMBjDgrW6g04kG1aCXOHlaFyrR6aKuvKLI7klWHriSLIZcDtHtROX5/VyVCnTp2wadOmBpd///336Nmzp02C8mTq2j/gXBlyfeLKUEoLt8kAy7ohFtVf2uu/HUFRRQ1SIwMwtX/rZp4N66zGWxN7QC4zFZXOXXngso9/aZUOd3y6HQdyNAgPUOKb6Rmt+t1LxdO2yg7kaFBjMCLMX4l4F9jKbIqPtwLhtXOrzlpZNyTW2A3rpJb0vD4pWT1Q49lnn8XkyZORnZ0No9GIFStW4MiRI/jiiy+watUqe8ToUaKDOWvIHZRW6lBUYZpqnNSKlYH0hFCovOTI12hx/HwFUiNd78XVEfadK8VXtWcpPX9jZ5uc5zaqWwy0OiMe/X4PPt96Gj7eCjwxMq3RwtKyah0mf/oP9p4rRZi/Ekvu7ovUyMBWxyCFjtFB2HSs0GOSobp6Idcbtnix2FBfFJabBi82d9ZQaaUOP2RmA/CM0+mbYvVfjBtvvBErV67E77//Dn9/fzz77LM4dOgQVq5ciWuvvdYeMXoUc3s9C2Zd2vHaLTJ1kE+rhvj5eCtwRWIYANYNNcVoFPD0T/shCMDo7jG4MiXcZvc9Lj0WL47pCgD48K8TePP3Yw2uU67VY8riHdh9tgQhft74aloGOqhdMxEC6uqGPCUZqqsXct0tMlFLOsqW7TyLKp0BHaIC0Tc5zF6hOb0W/ZUeMGAA1q1bZ+tYCPVXhlgz5MrqJk+3vl6kf2o4NmcVYnNWoUe/c2vK0n/PYs/ZEgSovPD09R1tfv+TMuJRozfguZUH8c76Y/DxluP/rjbVTVbW6DF18Q7sPH0BQT5e+GpahvlYC1fVKdq0onA4t8wjjuXYXbsy5MrF06K2VnaUGYwCvtjque309bV+LZlsit1k7qGurb71yZBYN7TteFGLW73dVXFFDV5ZYyqafuTa9nab7DylfxKeGJkGAHh1zREs2nwSVTUGTP1sB/45VYxAHy98dXdGq45BcBbJEf5QKuQo0+pbNcDPFeRrqpFdUgW5DOjuosMW67N28OKfRwpwprgSQT5eGNPT89rp62v2ylBy8qWnuIrEIYzUMmIBdVm1HuVaPQLscE4S2V9dW33ra3w6xQQh2NcbpVU67M0udemOF1t7dc1hlFTqkKYOxOR+9u2CuW9QCqp1Brz1+zHMW3UQ3/xzBlkF5QhQeeGLqX1cdnLxxbwVcrSLCsCBHA0O5GhcYj5SS+2q3SLroA6yy5l0jmbtNtlnte30E66Ig5/S9X/+1mj2T3/q1CkkJCRg0qRJiIyMtGdMHi1A5YVAHy+UVeuRV1rlskWYns4WbfUihVyGK1PaYPX+PPx9rJDJUK3MMxfw7Y6zAIB5Y7rAS2H/he6HhrRDtc6IhRuPI6ugHH5KBT676wq3qDepr2N0EA7kaHAoV4MRXdRSh2M3mW60RQYAcbXJUHbtrKFLbXsdP1+OTccKIZMBd/RNdFCEzqvZydDSpUvx6aefYsGCBRg5ciSmTp2K6667DnI5d9psLTrYB2XV5cgtrWYy5IIMRgGnikzvzGzVWt0/NRyr9+dhc1YhHhjSzib36coMRgHP/rQfADCuV6y5yNzeZDIZ/juiA5QKGX7dn4cXx3RBbwd9b0cS2+u3nyySOBL7EleG3OUNRtsQ0ypeWe2soWA/7yav+0XtqtCQtEiXGQpqT83OZG655RasXr0aWVlZSE9PxyOPPIK4uDg88cQTOHasYYcFtRxnDbm27AtVqNEbofSS2+wsKrFuKPPMBVTW8Ny6JdtPY3+2BoE+Xph9XZpDv7dMJsOsYR3w+6xByEhu49Dv7ShDO0bCWyHDthPF+PNIgdTh2EWN3oi950oBuM/KkK9SgfAA0zFZl5o1VFatw/c7zwHw7Hb6+qxe1mnbti2eeuopHDt2DF9//TW2b9+OtLQ0XLhwwR7xeaToIM4acmViW31SG38o5Lbpzkho44e2Ib7QGQT8c7LYJvfpqgrLtXht7REAwGPDO5gHzZHtJLTxx+R+iQCAeasOQueGhfuH8zTQ6o0I9vVu8ZE5zqhtM4qol+88h4oaA1Ii/M1vtDxdi/a4qqur8dVXX2Hu3LnYvn07brnlFvj5cZnNVtTsKHNptmyrF8lkMp5iX2v+r4dRVq1Hl7ZBuC3DM48OcIQHhrRDmL8Sx89XmE8zdyeZp+vOI3OnlnKxiDq7iSOdjGynb5RVydD27dtxzz33QK1WY8GCBRg7diyys7Px7bffQqXiuzNb4awh12bLtvr6+rcTzylz7zqOS9lxqhjLM89BJgPm3djFZitv1FCwrzf+M6w9AOCt34/hQu1EdXex62wJAPepFxJdrqNsU1YhThRWIEDlhbG9Yh0ZmlNrdgF1586dUVBQgEmTJmHjxo3o3r27PePyaNEhnl0zJAgC9EYB3g7oDrIHW7bV13dliqk+5VCuBoXlWo/bHtIbjHjmR1PR9MQr4tyug8sZTbwiHl9uPY3DeWV48/ejeP7GLlKHZLVqnQHZJVXIKalC9oUqZNf+94/Dplood6kXEl1u1pB4Ov3N6bEc3VJPsx+JQ4cOwd/fH1988QW+/PLLJq9XXOzZ9Qy24MmDF2v0Rtz/1U78c6oYax8eaLMCZEeyZVt9feEBKnSMDsKhXA22HC/C6O6eNSTt89oX5RA/bzw23LFF055KIZfh2Rs6YdLH27Fk+xnc3jcB7aOcp8NVEASUVunMCU79/+aUmP5bWN70ilaAygs94kIcF7ADxF5iCvXpogpsqC2Iv9POc7lcTbOTocWLF9szDqpHrBkqrdKhskbvMcOwBEHAE8v3Yn3tO7bNxwox/oo4iaOyTrlWj3yNFgCQbIcTy69KbYNDuRr8fazQo5KhfE013lx3FADw3xFpCPNXShyR57gyJRwjOqux5kAe5q06iC+m9pGszuRQrgZfbz+DcxcqzYlPRY3hsrfzVyrQNtQXbUN8a//rh5gQH/SKD0WgT9Pt564oNqTpbbIvtp6GIACD2kfY5e+TK2v2q+zkyZPtGQfVE6jygr9SgYoaA/JKqz3mSfvm78ewYle2+fODLnhQ5MnaLbLwACWCfW3/R7Z/ajg+3nQSm7MKPeLcKNGLvxxCuVaP7nEhmNDbtRJkd/DkdR3xx+ECbDpWiN8PFeDaTlEOj+FscSUmfLgVmuqGoyXa+Cvrkh1zwlP332Bfb4/5f0U8n6ysWo/SKp3571CFVo/v/jUNKZ3CdvoGWrzkUFNTg4KCAhiNli2X8fHxrQ7K08lkMqiDfXD8fIXHJEPf7TiLd9ab5lUNaBeOTccKXfLUbPMWmY3rhUR9ksLgrZAhu6QKp4sqkehGLcFN2XK8ED/vyYFMBrxwYxfIWTTtcPFt/DBtQBI++PM4XvzlIAa2D4fKS+Gw71+jN2LmN7ugqddFWD/Z8fF2XCzOzk/phTb+ShRV1ODchUoE+5rOy/thVzbKqvVIbOOHQe0jJI7S+VhdoXr06FEMGDAAvr6+SEhIQFJSEpKSkpCYmIikpCR7xOiRoj1o8OKmY+fx5A/7AAAzB6eaD8Q8lKuBIAhShma143Zoq6/PT+ll7n7Z7AEt9jV6I5796QAA4PaMBHSNdf2DUF3VjMGpiAhU4VRRpbkI11FeXn0Ye86WINjXGwtvT8etfeIxsH0EUiICmAg14uK6IUEQ8MXWUwCAO/ol8g1FI6xOhu666y7I5XKsWrUKO3fuRGZmJjIzM7Fr1y5kZmbaI0aPVFdE7d7t9YdyNbj/q0zojQLG9IjBf4a1R2pkALzkMmiq9S6XDNqrrb4+T5k3ZDAKmPXdbmQVlKONvxKPDusgdUgeLUDlhceGm34H767PQmG51iHfd+2BPHz690kAwBu3dDd3S1HTLu4o23q8CEfzTWfp3dKb7fSNsXqbbPfu3di5cyfS0tjNYU+e0FGWW1qFuxbvQLlWj77JYXjl5m6QyWRQeSmQEhGAI/llOJSrcamOMnu11dfXv1043lh3FFuOF8FgFNxy1o4gCHhyxT6s2psLb4UMCyb0uOQ5S+QYN/eKxZdbT2Nfdine+O0I5o/tZtfvd7a4Eo8t2wMAmD4gCUMlqFVyRRfPGhJPpx/bqy2C3Kxg3FasXhnq1KkTCgvd+x2pMxDPJ3PXIznKqnW4a/EO5GmqkRoZgA9v721Rg9Ax2tS+60p1Q0ajgJOF9t0mA4BubYMRqPJCaZUOB3JK7fZ9pCIIAuatOoSl/56FXAa8PbEnaxychLy21R4Avt1x1q7Pvxq9ETO/zoSmWo+e8SF4fATfgDdX/W2ycxcq8fuhfAAwH7FCDVmdDL3yyit4/PHH8eeff6KoqAgajcbig2zDnVeGdAYj/m9JJg7nlSE8QIXFU65o8K5fPDX7UG6ZFCG2SJ6mGlU6A7zkMsSF2W8p30shR9/aAYzuWDf01u/HzNsir4zrhuu6RkscEdV3RWIYRnWLhiAAz688aLe6vvmrD2HPuVIE+3rjf5N6uewQVimI22TZF6rw5bbTMApA/9Q2aOdEM6KcjdXPrqFDh2Lbtm0YMmQIIiMjERoaitDQUISEhCA0lBNhbUWcNZSnca9kSBAEPPXDPmw6VghfbwUWT7mi0cShLhlynQRb3CKLb+Nn9z/cYt3QFjc7muPjv07g7dquwudu6IRb2EbvlGZf1xEqLzm2nyzGmv15Nr//NftzsfjvUwCABeO7o60LbZU7A3Fl6ExxJZbuMLXTc1Xo0qyuGdqwYYM94qCLiCtDxRU1qNYZ3KZj4n9/ZOG7f89BLgP+N6lnk91BYjJ0sqjCZQZP2rutvr7+tcnQP6eK3eb58fX2M3jx10MATKfRT+nP7lRn1TbEF/cOSsE764/hxV8PYXBapM2eg2eKKvHY93sBAPcOTMaQjqwTspY4a6hca5rJFBvqy8fxMqx6hdHpdHj++eexcOFCtGvXzl4xEUyHJPp4y1GtMyJfU42ENq4/T+aHXefwRu0U4bk3drnk/5wRgSqEByhRWF6Do/nlLjEyX1wZSrFjvZAoJcIf6iAf5GmqsfP0BXNy5Kp+2p2Np340jVe4b1AK/u/qFIkjosu5b1AyvttxFucuVGHR5pOYMTi11fep1Rsw4+tMlFXr0Ss+BI8OZwdhS/gpvRDmr0Rx7eG6d/RNcMtGC1uyai3f29sbe/futVcsNvPee+8hMTERPj4+yMjIwD///CN1SFaTyWSIqS2izilx/a2yLVmFeFx8tzcoGXf0vfy5OK62VXbcAW31IplMhitT3aNuaN3BfMz6bg8EAbi9bzz+O6KDx0wLdmV+Si/zTLD3NmQh3wZb+vN/PYx92aUI8WOdUGuJW2U+3nJMcLFjjaRg9TPt9ttvx6JFi+wRi00sXboUs2bNwpw5c5CZmYnu3btj+PDhKCgokDo0q9XVDbn2rKGj+WW496ud0BkEjOoWjf8285BNV0uGzG31DpoY7g7zhjYfK8SMJZkwGAWM7dkWz4/uwkTIhdzYIwY940NQWWPAq2uOtOq+Vu/LNbeALxjf3aVGajij+NpazDE92iLEj2f5XY7VhRh6vR6ffvopfv/9d6Snp8Pf3/Jd8IIFC2wWXEssWLAA06dPx1133QUAWLhwIX755Rd8+umneOKJJySNzVpqN+goK9BU467FO1BWrccViaF4/ZbuzZ5+6krt9dU6A3JqB2QmO+iIDHFrbF92KUoqa1zuD97O08WY/sW/qDEYMbxzFF69uRsn47oYmUyGOTd0xpj3/sbyzHO4s18CurdgS/t0UYXFyvE1aaxvaa0Zg1MR4ueNh4e2lzoUl2D1ytD+/fvRq1cvBAYG4ujRo9i1a5f5Y/fu3XYIsflqamqwc+dODB061HyZXC7H0KFDsXXrVgkjaxmxiNpVZw1VaPWY+vkOZJdUITncHx/d0duqIktxZehwbpnTH8txsrACgmCq9XLUiepRQT5oFxkAQTBNmHUlB3JKMWXxDlTpDBjQLhzv3NoTXtwScUk94kIwtmdbAMDzq6xvtTfXCWn16J0QyknjNtIxOggvjOmK8ACV1KG4BLfqJissLITBYEBUlOW7iqioKBw+fLjR22i1Wmi1dWPlnWlWktqFzyfTG0wD0/Zna9DGX4nP7uqDUCuThJSIAHgrZCjT6nHuQpVdZ/e01ol6Z5I5cpunW2wIjhWU40TtsEdXkFVQjjsX/YOyatOL34d3pDv00E+yvcdHpGH1/jzsPH0BP+/JwY092jb7ti/+cgj7szUI9fPGO7f2ZJ0QScLjn3Xz589HcHCw+SMuznkKzaKDXHNlSBAEPPvzAWw4ch4+3nJ8Mrk34ttYn8h4K+RIjXSNrTLzmWQOaKuvTx1setdni+JVRzhbXInbP9mOoooadGkbhE/vusIlxibQpamDfTBjsKkD8OXVh1FVY2jW7X7Zm4svtp4GACyY0IN1QiQZq/8KDR48+JLvfP/4449WBdQa4eHhUCgUyM/Pt7g8Pz8farW60dvMnj0bs2bNMn+u0WicJiFSu+hhrQs3nsDX289AJgPemdgTPeNbPoyzY3QgDuVqcCi3DMM6N/47dAYnHHAMR2PULpQw52uqcdsn281HsHx+Vx+ek+RG7h6QjG/+OYvskios3Hgcj1x76VqVU4UV+O9yU53Q/VenYHCHSEeESdQoq1eGevToge7du5s/OnXqhJqaGmRmZqJr1672iLHZlEol0tPTsX79evNlRqMR69evR79+/Rq9jUqlQlBQkMWHsxDfJRWW10Crb947Lan9vCcHr6wxbUk+O6pTqxOYTi7SUSauDDlixlB9kbXJUH6ZY04Qb6niihrc/sl2nCmuRFyYL76aloE2rGVwKz7eCjx5XUcAwId/HUdOSdNv4qp1pjqhcq2pseI/l0mciOzN6pWhN998s9HLn3vuOZSXl7c6oNaaNWsWJk+ejN69e6NPnz546623UFFRYe4ucyWhft5QeslRozeiQKN16poZANh+ogiPfmc6YXraVUm4ywYThM3t9XnOmwwJguDwtnpRVG0yVODE22Rl1TpM/vQfHCsoR1SQCkum9TWvepJ7ua6rGn0Sw/DPqWK8vPow3rm1Z6PXe/GXQziQo0GYv5LF8+QUbPYMvP322/Hpp5/a6u5abMKECXj99dfx7LPPokePHti9ezfWrFnToKjaFchkMpc4sFUQBGw5Xoh7vtyJGoMRIzqr8VTtO8TWEpOh00WV5tHyzuZ8uRZlWj3kMiChBbVRrSFukxWUaWEwOl/HXVWNAdM++xf7sksR5q/EkrszWlQ/Rq5BJjOdai+TmVaJd54ubnCdlXty8OW22jqh8d0RHcw6IZKezZKhrVu3wsfHOd7tzZw5E6dPn4ZWq8X27duRkZEhdUgtJr7YOWPdULXOgO/+PYvr39mMSR9vR2mVDj3jQ/DWxB42mxcT5q9EVJBpO+VInnOeYC+uCsWG+jm8Kyo8QAmZDDAYBRRVONdWmVZvwL1f7cQ/p4oR6OOFL6b2MRfEk/vq0jYY49NNdZdzVx6EsV6SfrKwArNXmI5dmTE4BVezToichNXbZGPHjrX4XBAE5Obm4t9//8Uzzzxjs8DIxBlnDeWVVuPLbafwzT9nzWff+HjLMbZXLB4f3sHmh4amqYOQrzmPQ7kapCe0vBjbXuq31Tual0KO8AAVzpdpUaDRIjLQOd6Q6A1GPPztbvx19Dx8vRVYPOUKdGnb+KG85H4eHd4Bv+zLxd5zpVixKxs3p8ea6oSWmOqE+iSG4REOAyQnYnUyFBQUZNFNJpfL0aFDBzz//PMYNmyYTYMj55k1JAgCMs9cwOK/T2HN/jzoa9/ttQ3xxeQrEzC+d5zdJiB3jA7CxqPnnbaIWqq2epE6yAfny7TI11Q7TcLx9I/7sXp/HpQKOT66Mx29E8OkDokcKCJQhZnXpOLl1Yfx6prDGNlFjZd+PYSDuaa5Y6wTImdjdTL02Wef2SEMakpMiLTbZFq9Ab/sNZ0ZtPdcqfnyjKQw3NU/CUM7Rtr9j5qzH8shVVu9KCpIhX3ZQJ6TFFEXlFXj2x1nIZMB707qiQHtIqQOiSRwV/9EfPPPGZwuqsRdi3fgn1PFkMmANyf0YAE9OR2rk6Hk5GTs2LEDbdq0sbi8pKQEvXr1wokTJ2wWHEk3R6agrBpLtp3Bku1nUFhuqkVReskxpkcMplyZhE4xjhtBILbXH84rg9EoON35VScceFp9Y8zt9RrnqBnKvmBK3GOCfTHciWdDkX2pvBR46rqOuOdLU90YAMy4OhUD2zM5JudjdTJ06tQpGAwNZ95otVpkZ2fbJCiqE+3gbbI9Z0uw+O+T+GVfLnQG01aYOsgHd/RLwK194h127lZ9SeH+UHrJUVljwJniSiQ66CDU5qjRG3G29sU/xcFt9aKoQOdqrxcTd777p2s7RaF/ahv8nVWEjKQwPDy0ndQhETWq2cnQzz//bP732rVrERxcV5tgMBiwfv16JCYm2jQ4qntBOV+uhc5gtMu5PTqDEb/uM22F7TpTYr68d0IopvRPxPDOaknPC/JSyNEhKhD7sktxOE/jVMnQmeIKGIwC/JUKRAZKM0RQPJLDWbbJxMRdXNUkzyWTyfDWhJ5YkXkO43vHsU6InFazk6ExY8YAMD25J0+ebPE1b29vJCYm4o033rBpcAS08VfCWyGDziCgoEyLtjY8u0dvMOKjTSfw+ZZT5i0WpUKOUd2jcdeVSega6xzFuACQpjYlQwdzyzCiS7TU4Zgdrzds0ZEHtNbnbNtk4jlpXBkiwFRMfe+gFKnDILqkZidDRqMRAJCUlIQdO3YgPDzcbkFRHblchqggH5y7UIW80iqbJkP/25CFt34/BsD0B+v2jARMyohHhEQrHJfS0UmP5ZCyrV7kbNtk4spQNJMhInIRVtcMnTx50vzv6upqpxm06M6ig03JUE5JNdITbHOfeaXV+HCjqdj9yevSMOXKJCi9nHcJ23mTIWnb6oG6FZiiihrU6I2S/x7FmqEobpMRkYuw+q+m0WjEvHnz0LZtWwQEBJi7x5555hksWrTI5gFSXRG1LTvKXlt7BFU6A3onhGL6gGTJX0AvR+woO3ehCppqncTR1JG6rR4wnWHnrTBt0RWUSb86JNYucWWIiFyF1a+AL7zwAj777DO8+uqrUCrrOou6dOmCTz75xKbBkYmtzyfbd64UyzPPAQCeHtVJsloXawT7eSOm9nE4nOs8x3JI3VYPmOr4xMnTUtcNCYLAbjIicjlWJ0NffPEFPvroI9x2221QKOqOXejevTsOHz5s0+DIRHxRydO0fvCiIAh44ZeDAIAxPWLQIy6k1ffpKB3N84acY6vsQkUNLlSaVqmSJO5wE89vk7puqLiiBjUGI2QyOM3RIEREl2N1MpSdnY3U1NQGlxuNRuh0zrN94U5suTL028F8bD9ZDJWXHI+NSGv1/TlSmpNNoj5RaFoVign2gZ/S6vI7m6pLmKVNhsTnaBt/ldNvvRIRiaz+a9WpUyds2rSpweXff/89evbsaZOgyJLaRjVDNXoj5v96CABwz8Bkm3amOYK4MnTQSbbJ6rfVS81ZtsnyWS9ERC7I6rezzz77LCZPnozs7GwYjUasWLECR44cwRdffIFVq1bZI0aPJ76w5GuqoTcYWzy47Mttp3GqqBIRgSrc54JzP8Rk6EieBgajAIXEx3I4Q1u9SOzcknqbLJf1QkTkgqx+Vb3xxhuxcuVK/P777/D398ezzz6LQ4cOYeXKlbj22mvtEaPHCw9QwUsug1EwTaJuiZLKGryz3jRT6NFh7eGvknZbpyUS2/jDx1uOap0Rp4oqpA7HXDwtdb0Q4DxTqPM4Y4iIXFCLXhEHDBiAdevWNbj833//Re/evVsdFFlS1A5ezC6pQm5ptbnV3hpv/X4MpVU6pKkDcXN6nB2itD+FXIYO6iDsOVuCQ7kayc4CE9W11Uu/TRYVWLd6KCUxGeOMISJyJVavDJWXl6OqyrKraffu3bjhhhuQkZFhs8DIkrlAtgV1Q8fPl+OrbacBAE9f30ny7aXW6Kg2FVFL3V6vNxhxunZ1KtkJVoYizdtk0tYMcWWIiFxRs5Ohs2fPol+/fggODkZwcDBmzZqFyspK3HnnncjIyIC/vz+2bNliz1g9mroVHWXzfz0MvVHAkLRIXNXOtY9RcZZJ1OcuVEFnEKDykjtFIbr4/CjT6lGh1UsWR25plUU8RESuoNnbZI899hiqq6vx9ttvY8WKFXj77bexadMmZGRk4Pjx44iNjbVnnB4vOkhcGbJu1tCWrEL8figfCrkMs6/raI/QHMpZkiGxrT4p3B9yJ1hpC1B5wV+pQEWNAfmaasm27vJ4Yj0RuaBmJ0N//fUXVqxYgb59+2L8+PFQq9W47bbb8PDDD9sxPBK1ZGXIYBTwwi+mVvrbM+KRGil9bUtribOGckqrUVJZgxA/5WVuYR/O1EkmigrywYnCCuRrtJIkQ2XVOlTUGABwZYiIXEuzt8ny8/ORlJQEAIiMjISfnx9Gjhxpt8DIklg0bU0ytDzzHA7mahDk44WHh7a3V2gOFeTjjdhQ02NxSMK6IfOMIQkPaL1YpDiFWqLzycRVoWBfb8mHUBIRWcOqAmq5XG7x7/pnk5F9RYdYV0BdodXj9bVHAAAPDmmHUH/3+V05w7EcznAm2cXUQS0vsreFXBZPE5GLavbbN0EQ0L59e/OhnuXl5ejZs6dFggQAxcXFto2QAFgOXmzOwMEPNx5HQZkWCW38cEe/BEeE6DAd1YFYdzBf0rohZ2qrF4nt7FJNoRaTMLbVE5GraXYytHjxYnvGQZcREaCCXAbojQKKyrXmVurG5JRU4aNNJwAAs0emQeWlaPK6rqiuiFqabbKyah3Ol5kSDmdaGRKfE/lSbZPxKA4iclHNToYmT55szzjoMrwUckQG+iBPU43c0upLJkOvrz2Cap0RfRLDMLyz2oFROob5WI78slYdT9JSYvF0eIAKQT7eDv3el6KW+EgOHsVBRK6qRa8iJSUl+OSTTzB79mzztlhmZiays7NtGhxZak5H2d5zJVixy/R7eHpUR/O2pjuJD/ODv1KBGr0RJwsdfyyH2FbvTKtCABAVJO2RHOLYB7bVE5GrsToZ2rt3L9q3b49XXnkFr7/+OkpKSgAAK1aswOzZs20dH9UTbU6GGp81JAgCXlhlaqUf27MtusWGOCo0h5LLZehQO4n6oAR1Q+LKUIrTJUN1NUOCIDj8++fV1ipxZYiIXI3VydCsWbMwZcoUHDt2DD4+dX/0rrvuOvz11182DY4sXe5IjrUH8vDPqWL4eMvx6PAOjgzN4eo6yhxfN3TCCdvqASAi0LQyVKM3orRK5/DvL64MteTsPCIiKVmdDO3YsQP33ntvg8vbtm2LvLw8mwRFjYu5xKwhrd6A+asPAwDuGZCMGCc4IsKe0iScRH3cCdvqAcDHW4FQP1MNk6O3yqp1BlyoNCVgXBkiIldjdTKkUqmg0TR8ATp69CgiIiJsEhQ17lIrQ19sOY3TRZWIDFTh3kEpjg7N4TrVTqJ2dDJkNAo4VeR8bfUiqdrrxeekr7cCQT4cuEhErsXqZGj06NF4/vnnodOZ3gXKZDKcOXMG//3vfzFu3DibB0h1zDVDGsuaoeKKGrzzxzEAwKPDO8Bf5f4vRh3UppWhfI0WxRU1Dvu+OaVVqNYZ4a2QIS7U+VbfzO31Dl4Zqt9W745F+0Tk3qxOht544w2Ul5cjMjISVVVVGDRoEFJTUxEYGIgXX3zRHjFSLXFlKL9UC6OxrkD27d+Poqxaj07RQRjXyzMOzA1QeSGhjR8Ax64OifVC8WF+Dm/pbw61eCSHo5MhttUTkQuzegkhODgY69atw+bNm7F3716Ul5ejV69eGDp0qD3io3oiA30gkwE1BiOKK2sQHqBCVkE5vtp+BgDw9PUdLzuZ2p10VAfhdFElDuVq0D813CHfs+4YDufbIgPqtskcXTOUy9PqiciFtXg/5aqrrsJVV11ly1joMpRecoQHqHC+TIvckmqEB6gw/9dDMBgFDO0YhSsdlBA4i47RQVhzIM+hk6jrjuFwruJpUaRENUPithxXhojIFVmdDL3zzjuNXi6TyeDj44PU1FQMHDgQCoV7HQHhLGKCfUzJUGkVSqt0WH+4AF5yGWZflyZ1aA6XJkERtXnGkJO11YuiAqXZJss1t9UzGSIi12N1MvTmm2/i/PnzqKysRGhoKADgwoUL8PPzQ0BAAAoKCpCcnIwNGzYgLi7O5gF7OnWwD/acK0V2SRWW7jgLALi9bwJSnHTbxp461bbXZxWUQ2cwwtsBNTzOeFp9feaOQ8lqhpyvqJyI6HKsfvV46aWXcMUVV+DYsWMoKipCUVERjh49ioyMDLz99ts4c+YM1Go1HnnkEXvE6/HEgXaLNp/E4bwyBPt646Eh7SSOShqxob4IVHmhxmA0z/6xp8oaPXJqX/SdvWbofJkWBqPjplCzZoiIXJnVydDTTz+NN998EykpdbNsUlNT8frrr2P27NmIjY3Fq6++ir///tumgZKJ+M7/3AXTtsSDQ9oh1F8pZUiSkclkDt0qE89BC/HzRpiTPuZt/JWQywCjABSVO6ZuSGcw4nw5j+IgItdldTKUm5sLvV7f4HK9Xm+eQB0TE4OyMscfk+AJ6tdkJLbxwx19EySMRnodzZOo7f98qzuGwzm3yADASyE3H8vhqCLq82VaCALgrZChjZMmiUREl2J1MjR48GDce++92LVrl/myXbt24f7778c111wDANi3bx+SkpJsFyWZ1d+GmH1dRyi9nG/WjSN1dOCxHOZkyEm3yESObq8Xt8giA30g96DRDkTkPqx+JV20aBHCwsKQnp4OlUoFlUqF3r17IywsDIsWLQIABAQE4I033rB5sAR0jQ1Gp+ggjOkRg2GdoqQOR3JpanGbzAErQ4XOXTwtigx07BRqsXianWRE5Kqs7iZTq9VYt24dDh8+jKNHjwIAOnTogA4d6k5JHzx4sO0iJAt+Si/8+tAAqcNwGh3UgZDJgMJyLc6Xac1bRPbgrKfVX0wd7Nj2+jzOGCIiF9fioYtpaWlIS/O82TbkXPyUXkhq448ThRU4lKtBRKB9DgsWBMHcVp/i5CtDUYGO3SbL44whInJxLUqGzp07h59//hlnzpxBTY3lIZkLFiywSWBEzdUxOsicDA1sb59kqKBMi4oaA+QyIL72TDRn5eiT68WaoSi21RORi7I6GVq/fj1Gjx6N5ORkHD58GF26dMGpU6cgCAJ69epljxiJLqljdCB+2ZeLw3n2qxvaeOQ8ACCxjT9UXs49XT0ySOwmc8zKUL75xHoOXCQi12R1AfXs2bPx6KOPYt++ffDx8cHy5ctx9uxZDBo0CLfccos9YiS6pDS1fTvKqnUGvPW7qT5uwhXOP1VdrN0pKHPsyhBrhojIVVmdDB06dAh33nknAMDLywtVVVUICAjA888/j1deecXmARJdTseYumM5tHqDze//q22nkVNajehgH0y+MtHm929rYs1QcUWNXR6P+oxGod7KEJMhInJNVidD/v7+5jqh6OhoHD9+3Py1wsJC20VG1EwxwT4I8vGC3iggq8C2x3JoqnX434YsAMDDQ9vBx9u5t8gA04Rscf5UgZ3rhooqaqAzCJDJYNdOPiIie7I6Gerbty82b94MALjuuuvwn//8By+++CKmTp2Kvn372jxAosuRyWR2m0T90cYTKKnUISXCH+N6xdr0vu1FJpMhqrZuqKDMvnVD4qpQRIDKIQflEhHZg9UF1AsWLEB5uend99y5c1FeXo6lS5eiXbt27CQjyXSMDsL2k8U2rRsqKKvGos0nAQCPDU+Dlwu92EcF+uBscRXySu27MpTLgYtE5AasSoYMBgPOnTuHbt26ATBtmS1cuNAugRFZo1PtytDhPNslQ++uz0KVzoCe8SEY3tm1pn3Xtdfbd2VInDHEtnoicmVWvdVVKBQYNmwYLly4YK94GnXq1ClMmzYNSUlJ8PX1RUpKCubMmdNgxtHevXsxYMAA+Pj4IC4uDq+++qpD4yTp1J1eXwZBEFp9f6cKK/DNP2cAAP8dkQaZzLXO3DK319t5myyPxdNE5Aas3ibr0qULTpw44dCDWA8fPgyj0YgPP/wQqamp2L9/P6ZPn46Kigq8/vrrAACNRoNhw4Zh6NChWLhwIfbt24epU6ciJCQE99xzj8NiJWm0jwqEXGbqoCoo07Z6peKNdUehNwoY1D4CfZPb2ChKxxEP9LV3AXVdWz1nDBGR67I6GXrhhRfw6KOPYt68eUhPT4e/v+XRBEFBQTYLTjRixAiMGDHC/HlycjKOHDmCDz74wJwMLVmyBDU1Nfj000+hVCrRuXNn7N69GwsWLGAy5AF8vBVIjghAVkE5DuZqWpUM7c8uxco9OQCAx0d0uMy1nZP55PpSe2+TcWWIiFyf1cnQddddBwAYPXq0xdaBIAiQyWQwGOw710RUWlqKsLAw8+dbt27FwIEDoVQqzZcNHz4cr7zyCi5cuIDQ0NBG70er1UKrrXv3rNHYZ3Af2V/H6CBkFZTjUK4GgztEtvh+XllzGABwY48YdI4JtlV4DuWwbTIexUFEbsDqZGjDhg32iMMqWVlZePfdd82rQgCQl5fXYOsuKirK/LWmkqH58+dj7ty59guWHKZjdCBW7mlde/2WrEJsOlYIb4UM/7nWNVeFAMdskwmCwJohInILVidDgwYNstk3f+KJJy47tfrQoUNIS0szf56dnY0RI0bglltuwfTp01sdw+zZszFr1izz5xqNBnFxzn/kAjUkzho63ML2ekEQ8MraIwCASX3inf5A1kuJrE2GyrV6lGv1CFC16EzmS9JU61FZY1oJ5lEcROTKWvQXctOmTfjwww9x4sQJLFu2DG3btsWXX36JpKQkXHXVVc2+n//85z+YMmXKJa+TnJxs/ndOTg4GDx6MK6+8Eh999JHF9dRqNfLz8y0uEz9Xq9VN3r9KpYJKxcm57qBj7RllJworUK0zWD0tes3+POw5WwI/pQIzr2lnjxAdJkDlhQCVF8q1euRrqhEQEWDz7yFukYX4ebvEZG4ioqZYPUVu+fLlGD58OHx9fZGZmWmutyktLcVLL71k1X1FREQgLS3tkh9iDVB2djauvvpqpKenY/HixZDLLUPv168f/vrrL+h0OvNl69atQ4cOHZrcIiP3EhWkQqifNwxGAcfyrTuWQ28w4rXfTKtCd1+V5BZHS0TZ+fT63NoZQ2rWCxGRi7M6GXrhhRewcOFCfPzxx/D29jZf3r9/f2RmZto0OJGYCMXHx+P111/H+fPnkZeXh7y8PPN1Jk2aBKVSiWnTpuHAgQNYunQp3n77bYstMHJvlsdyWLdVtmznOZw4X4EwfyWmD0y+/A1cQJSd64Z4QCsRuQurt8mOHDmCgQMHNrg8ODgYJSUltoipgXXr1iErKwtZWVmIjbU8H0ocsBccHIzffvsNM2bMQHp6OsLDw/Hss8+yrd7DdIwOwpbjRThoRTJUVWPAW78fBQDMGJyKQB/vy9zCNZjb6+22MsQZQ0TkHqxOhtRqNbKyspCYmGhx+ebNmy3qe2xpypQpl60tAoBu3bph06ZNdomBXENLVoY+33oK+Rot2ob44va+8fYKzeEi7bxNJtYMcZuMiFyd1dtk06dPx0MPPYTt27dDJpMhJycHS5YswaOPPor777/fHjESNVvH2mM5Duc171iO0kod3t+QBQCYdW17qLzcpxDY3u31bKsnIndh9crQE088AaPRiCFDhqCyshIDBw6ESqXCo48+igceeMAeMRI1W2pkALzkMpRW6ZBbWo2YkEtv4Xyw8Tg01Xp0iArEmJ5tHRSlY9h7m8y8MsRkiIhcnNXJkEwmw1NPPYXHHnsMWVlZKC8vR6dOnRAQYPvWXSJrqbwUSIkIwJH8MhzK1VwyGcorrcbiv08CMB27oZC71mGsl2P/bjImQ0TkHqzeJvvqq69QWVkJpVKJTp06oU+fPkyEyKl0NJ9gf+m6obfXH4VWb0TvhFBck9by4zucVf1usuZsGVqjqsaA0irTGAsmQ0Tk6qxOhh555BFERkZi0qRJ+PXXXx12FhlRc9UVUTd9LMfx8+X47t9zAIAnRqZZnLPnLsRZSTUGI0oqdZe5tnXErTd/pQKBdphuTUTkSFYnQ7m5ufj2228hk8kwfvx4REdHY8aMGdiyZYs94iOymjkZymt6ZeiN347AYBQwtGMkeieGNXk9V6byUiDM3zS01NZ1Q+aBi8E+bplIEpFnsToZ8vLywqhRo7BkyRIUFBTgzTffxKlTpzB48GCkpKTYI0Yiq4jJ0KnCClTVNFy53HO2BL/uy4NMBjw2PK3B191JZKB96oZYPE1E7sTqZKg+Pz8/DB8+HCNHjkS7du1w6tQpG4VF1HIRgSqEByhhFIAj+ZZbZYIg4JU1hwEAY3vGooM6UIoQHUZMVmzdXi+uNKmDOHCRiFxfi5KhyspKLFmyBNdddx3atm2Lt956CzfddBMOHDhg6/iIWqSp4YubjhViy/EiKBVyPHKtax/G2hxRgfZprxdXhjhjiIjcgdXJ0MSJExEZGYlHHnkEycnJ+PPPP5GVlYV58+ZBr9fbI0YiqzWWDBmNdatCt/dNQGyonySxOZK92uvFtvooJkNE5AasbgNRKBT47rvvMHz4cCgUCpSVleGjjz7CokWL8O+//7K7jJxCY+31q/bl4kCOBgEqL8y8JlWq0BxKTFbybb1NJq4M8SgOInIDVidDS5YsAQD89ddfWLRoEZYvX46YmBiMHTsW//vf/2weIFFLiCtDh3NNx3LoDALe+O0IAOCegcnmLit3J26T2byAWsMCaiJyH1YlQ3l5efjss8+waNEiaDQajB8/HlqtFj/++CM6depkrxiJrJYcHgBvhQxlWj3OXajCn0fP43RRJcIDVJh2VZLU4TmMOHjRlslQjd6IwnLTShNrhojIHTS7ZuiGG25Ahw4dsGfPHrz11lvIycnBu+++a8/YiFpM6SVHaqRpqyzzzAW8s/4YAODBIanw96AhgWLNUGG5FnqD0Sb3WVBWDUEAlAq5x6ywEZF7a/arwurVq/Hggw/i/vvvR7t27t+FQ66vY3QgDuVq8NKvh3C+TIv4MD9MvCJe6rAcqk2ACgq5DAajgKKKGvNKUWuIq0xRwSoOXCQit9DslaHNmzejrKwM6enpyMjIwP/+9z8UFhbaMzaiVulUWzckFg//Z1h7KL1aNVrL5SjkMkQEmFaHxKLn1so1F09zxhARuYdmvzL07dsXH3/8MXJzc3Hvvffi22+/RUxMDIxGI9atW4eysqbPgSKSglhEDZgSoxu6xUgYjXRs3V7P6dNE5G6sfpvs7++PqVOnYvPmzdi3bx/+85//4OWXX0ZkZCRGjx5tjxiJWqR+MvT4iA6Qyz1zS8dcRF1mm/b6XCZDRORmWrVn0KFDB7z66qs4d+4cvvnmG1vFRGQTYf5KzB3dGbNHpmFQ+wipw5GMORmy0TZZ3VEcTIaIyD3YpK1GoVBgzJgxGDNmjC3ujshmJl+ZKHUIkrPXNhnb6onIXXhWNSmRB7L1Nlkej+IgIjfDZIjIzYnJUIENVoaMRsG8wsSVISJyF0yGiNycmAzZ4uT6wgot9EYBchnMLftERK6OyRCRmxNrhkoqdajWte4gZXGLLDLQB14K/vkgIvfAv2ZEbi7Y1xuq2mGT51tZN5TLeiEickNMhojcnEwms9lWmbleiG31RORGmAwReQBbtddz4CIRuSMmQ0QewNxer2ndNhmP4iAid8RkiMgD2Kq9Pre0CgDb6onIvTAZIvIA4jZZ62uGTCtLPIqDiNwJkyEiD1C3TdbyZEgQhHorQ742iYuIyBkwGSLyAHXbZC2vGSqt0qFaZwQARAZx4CIRuQ8mQ0QeoH5rvSAILboPcYstzF8JH2+FzWIjIpIakyEiDyDWDFXWGFCu1bfoPsxt9awXIiI3w2SIyAP4Kb0Q6OMFoOXt9WyrJyJ3xWSIyEO0tr2eAxeJyF0xGSLyEK1tr88v5VEcROSemAwReYjWTqHO1XBliIjcE5MhIg/R2llDebUzhpgMEZG7YTJE5CGiAlt3WKtYM8SjOIjI3TAZIvIQrVkZqtDqUVZtaslXc/o0EbkZJkNEHiIquOU1Q2LRdYDKCwEqL5vGRUQkNSZDRB7C3FpfZv0Uas4YIiJ3xmSIyENEBJhqhnQGAcUVNVbdNo/1QkTkxpgMEXkIpZcc4QFKANZvlYnbZDyKg4jcEZMhIg8SGVhbN1RmXRF1LtvqiciNMRki8iDiFGpxmnRzsWaIiNwZkyEiD9LSKdTiNhlrhojIHTEZIvIg5mTIym0y88pQEGcMEZH7YTJE5EFacnK9Vm9AYbmp+4zbZETkjpgMEXmQlpxcX1C7pab0kiPUz9sucRERSYnJEJEHaUnNUP16IZlMZpe4iIik5HLJkFarRY8ePSCTybB7926Lr+3duxcDBgyAj48P4uLi8Oqrr0oTJJGTEpOhwnIt9AZjs24jHtAaxRlDROSmXC4ZevzxxxETE9Pgco1Gg2HDhiEhIQE7d+7Ea6+9hueeew4fffSRBFESOac2/kp4yWUQBOB8efNWh/JqZwyxk4yI3JVLJUOrV6/Gb7/9htdff73B15YsWYKamhp8+umn6Ny5MyZOnIgHH3wQCxYskCBSIuckl8sQGVg7a6iZW2V5pabrsXiaiNyVyyRD+fn5mD59Or788kv4+fk1+PrWrVsxcOBAKJVK82XDhw/HkSNHcOHChSbvV6vVQqPRWHwQubNIc91Q84qo8zS1K0PcJiMiN+USyZAgCJgyZQruu+8+9O7du9Hr5OXlISoqyuIy8fO8vLwm73v+/PkIDg42f8TFxdkucCInJHaUNbe9PpfTp4nIzUmaDD3xxBOQyWSX/Dh8+DDeffddlJWVYfbs2TaPYfbs2SgtLTV/nD171ubfg8iZiIXQzW2vrzuKgwMXicg9eUn5zf/zn/9gypQpl7xOcnIy/vjjD2zduhUqlcria71798Ztt92Gzz//HGq1Gvn5+RZfFz9Xq9VN3r9KpWpwv0TuzJr2eoNRQEGZ6XosoCYidyVpMhQREYGIiIjLXu+dd97BCy+8YP48JycHw4cPx9KlS5GRkQEA6NevH5566inodDp4e5sGw61btw4dOnRAaGiofX4AIhcUZUXNUGG5FgajAIVchvAAvmkgIvckaTLUXPHx8RafBwQEAABSUlIQGxsLAJg0aRLmzp2LadOm4b///S/279+Pt99+G2+++abD4yVyZuaT65uRDIn1QpGBKijkHLhIRO7JJZKh5ggODsZvv/2GGTNmID09HeHh4Xj22Wdxzz33SB0akVNRW7FNlsfiaSLyAC6ZDCUmJkIQhAaXd+vWDZs2bZIgIiLXIbbWl1bpUK0zwMdb0eR1OXCRiDyBS7TWE5HtBPl4wcfb9L9+wWVWh3I1PIqDiNwfkyEiDyOTyZrdXi9uk3FliIjcGZMhIg/U3I4yzhgiIk/AZIjIAzU7Gar9uprbZETkxpgMEXmgqMDLt9cLgmBurec2GRG5MyZDRB5IbJW/VHt9SaUONXojACAyiAMXich9MRki8kDNObleXBUKD1BC5dV0+z0RkatjMkTkgcRtMvHcscbkaUwzhthWT0TujskQkQcyt9aXVjc6wBQA64WIyGMwGSLyQGIyVKUzoEyrb/Q6+TyKg4g8BJMhIg/kq1QgyMd0Gk9BE3VD4soQ2+qJyN0xGSLyUHVbZY3XDZlnDHHgIhG5OSZDRB6qrr3+0itDrBkiInfHZIjIQ0UG1iZDZY0nQ6wZIiJPwWSIyENF1Q5SFJOe+sqqdebCatYMEZG7YzJE5KEuNYVa3DoL9PGCv8rLoXERETkakyEiD3WpbTKxqJr1QkTkCZgMEXkocZusoJGVodxS0/RpdpIRkSdgMkTkoaLqnU9mNFpOoc4zzxjiAa1E5P6YDBF5qIhAFWQyQG8UUFxZY/G1XM4YIiIPwmSIyEN5K+Ro41/bUXbRrKF8zhgiIg/CZIjIg5nb6y9KhngUBxF5EiZDRB5MHdR4e33dURxMhojI/TEZIvJgkUENj+So1hlQXGGqIeI2GRF5AiZDRB6sbpusbmVIbLX38ZYj2NdbkriIiByJyRCRB4tqZGXIPGMoyAcymUySuIiIHInJEJEHUzeSDLFeiIg8DZMhIg8W2cg2WZ65rZ4zhojIMzAZIvJg4jZZUYUWOoMRQF1bfRTb6onIQzAZIvJgYX5KeCtkEATgfJlpdSiPAxeJyMMwGSLyYHK5rO70+tpaoVzWDBGRh2EyROThLq4b4lEcRORpmAwRebj6HWV6gxEFZTyKg4g8C5MhIg9Xf9bQ+XItjALgJZehTYBK4siIiByDyRCRh6u/TZZXr5NMIefARSLyDEyGiDxcVL0C6rpkiKtCROQ5mAwReTixayxfU22eMcSBi0TkSZgMEXm4usNaq3kUBxF5JCZDRB4usraAWlOtx8nCCgBsqyciz8JkiMjDBaq84KdUAAD2nC0BwKM4iMizMBki8nAymcyc/BTUHsnBlSEi8iRMhogIkYGW3WOsGSIiT8JkiIgabIuJ55UREXkCJkNEZLESFB6ggtKLfxqIyHPwLx4RWWyTsV6IiDwNkyEistgmY70QEXkaJkNEZJEA8bR6IvI0TIaIyHw+GcCVISLyPEyGiMh8cj3AmiEi8jxMhogIPt4KBPt6A+DKEBF5HiZDRAQAuCU9Fh2jg9A9NkTqUIiIHMqlkqFffvkFGRkZ8PX1RWhoKMaMGWPx9TNnzuD666+Hn58fIiMj8dhjj0Gv10sTLJGLeXpUJ6x+aAD8VV5Sh0JE5FAu81dv+fLlmD59Ol566SVcc8010Ov12L9/v/nrBoMB119/PdRqNbZs2YLc3Fzceeed8Pb2xksvvSRh5EREROTMZIIgCFIHcTl6vR6JiYmYO3cupk2b1uh1Vq9ejVGjRiEnJwdRUVEAgIULF+K///0vzp8/D6VS2azvpdFoEBwcjNLSUgQFBdnsZyAiIiL7ac3rt0tsk2VmZiI7OxtyuRw9e/ZEdHQ0Ro4cabEytHXrVnTt2tWcCAHA8OHDodFocODAgSbvW6vVQqPRWHwQERGR53CJZOjEiRMAgOeeew5PP/00Vq1ahdDQUFx99dUoLi4GAOTl5VkkQgDMn+fl5TV53/Pnz0dwcLD5Iy4uzk4/BRERETkjSZOhJ554AjKZ7JIfhw8fhtFoBAA89dRTGDduHNLT07F48WLIZDIsW7asVTHMnj0bpaWl5o+zZ8/a4kcjIiIiFyFpAfV//vMfTJky5ZLXSU5ORm5uLgCgU6dO5stVKhWSk5Nx5swZAIBarcY///xjcdv8/Hzz15qiUqmgUqma/DoRERG5N0mToYiICERERFz2eunp6VCpVDhy5AiuuuoqAIBOp8OpU6eQkJAAAOjXrx9efPFFFBQUIDIyEgCwbt06BAUFWSRRRERERPW5RGt9UFAQ7rvvPsyZMwdxcXFISEjAa6+9BgC45ZZbAADDhg1Dp06dcMcdd+DVV19FXl4enn76acyYMYMrP0RERNQkl0iGAOC1116Dl5cX7rjjDlRVVSEjIwN//PEHQkNDAQAKhQKrVq3C/fffj379+sHf3x+TJ0/G888/L3HkRERE5MxcYs6QI3HOEBERketx+zlDRERERPbCZIiIiIg8GpMhIiIi8mhMhoiIiMijuUw3maOI9eQ8o4yIiMh1iK/bLekLYzJ0kbKyMgDgGWVEREQuqKysDMHBwVbdhq31FzEajcjJyUFgYCBkMpnN7lej0SAuLg5nz55ly74D8XGXBh93afBxlwYfd2lc/LgLgoCysjLExMRALreuCogrQxeRy+WIjY212/0HBQXxfxYJ8HGXBh93afBxlwYfd2nUf9ytXRESsYCaiIiIPBqTISIiIvJoTIYcRKVSYc6cOTw01sH4uEuDj7s0+LhLg4+7NGz5uLOAmoiIiDwaV4aIiIjIozEZIiIiIo/GZIiIiIg8GpMhIiIi8mhMhhzkvffeQ2JiInx8fJCRkYF//vlH6pDc2nPPPQeZTGbxkZaWJnVYbuevv/7CDTfcgJiYGMhkMvz4448WXxcEAc8++yyio6Ph6+uLoUOH4tixY9IE60Yu97hPmTKlwfN/xIgR0gTrJubPn48rrrgCgYGBiIyMxJgxY3DkyBGL61RXV2PGjBlo06YNAgICMG7cOOTn50sUsXtozuN+9dVXN3i+33fffVZ9HyZDDrB06VLMmjULc+bMQWZmJrp3747hw4ejoKBA6tDcWufOnZGbm2v+2Lx5s9QhuZ2Kigp0794d7733XqNff/XVV/HOO+9g4cKF2L59O/z9/TF8+HBUV1c7OFL3crnHHQBGjBhh8fz/5ptvHBih+9m4cSNmzJiBbdu2Yd26ddDpdBg2bBgqKirM13nkkUewcuVKLFu2DBs3bkROTg7Gjh0rYdSurzmPOwBMnz7d4vn+6quvWveNBLK7Pn36CDNmzDB/bjAYhJiYGGH+/PkSRuXe5syZI3Tv3l3qMDwKAOGHH34wf240GgW1Wi289tpr5stKSkoElUolfPPNNxJE6J4uftwFQRAmT54s3HjjjZLE4ykKCgoEAMLGjRsFQTA9t729vYVly5aZr3Po0CEBgLB161apwnQ7Fz/ugiAIgwYNEh566KFW3S9XhuyspqYGO3fuxNChQ82XyeVyDB06FFu3bpUwMvd37NgxxMTEIDk5GbfddhvOnDkjdUge5eTJk8jLy7N47gcHByMjI4PPfQf4888/ERkZiQ4dOuD+++9HUVGR1CG5ldLSUgBAWFgYAGDnzp3Q6XQWz/e0tDTEx8fz+W5DFz/uoiVLliA8PBxdunTB7NmzUVlZadX98qBWOyssLITBYEBUVJTF5VFRUTh8+LBEUbm/jIwMfPbZZ+jQoQNyc3Mxd+5cDBgwAPv370dgYKDU4XmEvLw8AGj0uS9+jexjxIgRGDt2LJKSknD8+HE8+eSTGDlyJLZu3QqFQiF1eC7PaDTi4YcfRv/+/dGlSxcApue7UqlESEiIxXX5fLedxh53AJg0aRISEhIQExODvXv34r///S+OHDmCFStWNPu+mQyRWxo5cqT53926dUNGRgYSEhLw3XffYdq0aRJGRmR/EydONP+7a9eu6NatG1JSUvDnn39iyJAhEkbmHmbMmIH9+/ezDtHBmnrc77nnHvO/u3btiujoaAwZMgTHjx9HSkpKs+6b22R2Fh4eDoVC0aCjID8/H2q1WqKoPE9ISAjat2+PrKwsqUPxGOLzm8996SUnJyM8PJzPfxuYOXMmVq1ahQ0bNiA2NtZ8uVqtRk1NDUpKSiyuz+e7bTT1uDcmIyMDAKx6vjMZsjOlUon09HSsX7/efJnRaMT69evRr18/CSPzLOXl5Th+/Diio6OlDsVjJCUlQa1WWzz3NRoNtm/fzue+g507dw5FRUV8/reCIAiYOXMmfvjhB/zxxx9ISkqy+Hp6ejq8vb0tnu9HjhzBmTNn+Hxvhcs97o3ZvXs3AFj1fOc2mQPMmjULkydPRu/evdGnTx+89dZbqKiowF133SV1aG7r0UcfxQ033ICEhATk5ORgzpw5UCgUuPXWW6UOza2Ul5dbvPs6efIkdu/ejbCwMMTHx+Phhx/GCy+8gHbt2iEpKQnPPPMMYmJiMGbMGOmCdgOXetzDwsIwd+5cjBs3Dmq1GsePH8fjjz+O1NRUDB8+XMKoXduMGTPw9ddf46effkJgYKC5Dig4OBi+vr4IDg7GtGnTMGvWLISFhSEoKAgPPPAA+vXrh759+0ocveu63ON+/PhxfP3117juuuvQpk0b7N27F4888ggGDhyIbt26Nf8btaoXjZrt3XffFeLj4wWlUin06dNH2LZtm9QhubUJEyYI0dHRglKpFNq2bStMmDBByMrKkjost7NhwwYBQIOPyZMnC4Jgaq9/5plnhKioKEGlUglDhgwRjhw5Im3QbuBSj3tlZaUwbNgwISIiQvD29hYSEhKE6dOnC3l5eVKH7dIae7wBCIsXLzZfp6qqSvi///s/ITQ0VPDz8xNuuukmITc3V7qg3cDlHvczZ84IAwcOFMLCwgSVSiWkpqYKjz32mFBaWmrV95HVfjMiIiIij8SaISIiIvJoTIaIiIjIozEZIiIiIo/GZIiIiIg8GpMhIiIi8mhMhoiIiMijMRkiIiIij8ZkiIiIiDwakyEicknnz5/H/fffj/j4eKhUKqjVagwfPhx///03AEAmk+HHH3+UNkgicgk8m4yIXNK4ceNQU1ODzz//HMnJycjPz8f69etRVFQkdWhE5GJ4HAcRuZySkhKEhobizz//xKBBgxp8PTExEadPnzZ/npCQgFOnTgEAfvrpJ8ydOxcHDx5ETEwMJk+ejKeeegpeXqb3hjKZDO+//z5+/vln/Pnnn4iOjsarr76Km2++2SE/GxE5HrfJiMjlBAQEICAgAD/++CO0Wm2Dr+/YsQMAsHjxYuTm5po/37RpE+6880489NBDOHjwID788EN89tlnePHFFy1u/8wzz2DcuHHYs2cPbrvtNkycOBGHDh2y/w9GRJLgyhARuaTly5dj+vTpqKqqQq9evTBo0CBMnDgR3bp1A2Ba4fnhhx8wZswY822GDh2KIUOGYPbs2ebLvvrqKzz++OPIyckx3+6+++7DBx98YL5O37590atXL7z//vuO+eGIyKG4MkRELmncuHHIycnBzz//jBEjRuDPP/9Er1698NlnnzV5mz179uD55583rywFBARg+vTpyM3NRWVlpfl6/fr1s7hdv379uDJE5MZYQE1ELsvHxwfXXnstrr32WjzzzDO4++67MWfOHEyZMqXR65eXl2Pu3LkYO3Zso/dFRJ6JK0NE5DY6deqEiooKAIC3tzcMBoPF13v16oUjR44gNTW1wYdcXvfncNu2bRa327ZtGzp27Gj/H4CIJMGVISJyOUVFRbjlllswdepUdOvWDYGBgfj333/x6quv4sYbbwRg6ihbv349+vfvD5VKhdDQUDz77LMYNWoU4uPjcfPNN0Mul2PPnj3Yv38/XnjhBfP9L1u2DL1798ZVV12FJUuW4J9//sGiRYuk+nGJyM5YQE1ELker1eK5557Db7/9huPHj0On0yEuLg633HILnnzySfj6+mLlypWYNWsWTp06hbZt25pb69euXYvnn38eu3btgre3N9LS0nD33Xdj+vTpAEwF1O+99x5+/PFH/PXXX4iOjsYrr7yC8ePHS/gTE5E9MRkiIqqnsS40InJvrBkiIiIij8ZkiIiIiDwaC6iJiOph5QCR5+HKEBEREXk0JkNERETk0ZgMERERkUdjMkREREQejckQEREReTQmQ0REROTRmAwRERGRR2MyRERERB6NyRARERF5tP8HSCZ5WlegE5gAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(metric_results, \"AverageReturnMetric\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bbd212-db7c-4b95-83af-ec7b6885845f",
   "metadata": {},
   "source": [
    "#### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c74689e4-f966-452c-a957-f5f43a184a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a689a0fd-9a5f-4baa-81b0-8306390f492a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9111db0572ce722\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9111db0572ce722\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=$LOG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e312e7c-e47a-49d0-85fb-80bf51f58e61",
   "metadata": {},
   "source": [
    "### log experiment to Vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "99560e10-d674-45e1-a14c-439f199419bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETWORK_NAME    : GlobalAndArmDotProductNetwork\n",
      "GLOBAL_LAYERS   : [16, 4]\n",
      "ARM_LAYERS      : [16, 4]\n",
      "COMMON_LAYERS   : [4]\n",
      "ENCODING_DIM    : 5\n",
      "EPS_PHASE_STEPS : 1000\n"
     ]
    }
   ],
   "source": [
    "if not network:\n",
    "    NETWORK_NAME = \"None\"\n",
    "    GLOBAL_LAYERS = \"None\"\n",
    "    ARM_LAYERS = \"None\"\n",
    "    COMMON_LAYERS = \"None\"\n",
    "    ENCODING_DIM = \"None\"\n",
    "    EPS_PHASE_STEPS = \"None\"\n",
    "else:\n",
    "    NETWORK_NAME = network.name\n",
    "    GLOBAL_LAYERS = GLOBAL_LAYERS\n",
    "    ARM_LAYERS = ARM_LAYERS\n",
    "    COMMON_LAYERS = COMMON_LAYERS\n",
    "    ENCODING_DIM = ENCODING_DIM\n",
    "    EPS_PHASE_STEPS = EPS_PHASE_STEPS\n",
    "\n",
    "print(f\"NETWORK_NAME    : {NETWORK_NAME}\")\n",
    "print(f\"GLOBAL_LAYERS   : {GLOBAL_LAYERS}\")\n",
    "print(f\"ARM_LAYERS      : {ARM_LAYERS}\")\n",
    "print(f\"COMMON_LAYERS   : {COMMON_LAYERS}\")\n",
    "print(f\"ENCODING_DIM    : {ENCODING_DIM}\")\n",
    "print(f\"EPS_PHASE_STEPS : {EPS_PHASE_STEPS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "954971eb-5d72-4727-83c2-b06f204f2a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.start_run(\n",
    "    RUN_NAME\n",
    "    # , tensorboard=TB_RESOURCE_NAME\n",
    "    , resume=False\n",
    ")\n",
    "\n",
    "aiplatform.log_params(\n",
    "    {\n",
    "        \"agent_type\": agent.name,\n",
    "        \"network\": NETWORK_NAME,\n",
    "        \"runtime\": runtime_mins,\n",
    "        \"batch_size\": BATCH_SIZE, \n",
    "        \"training_loops\": TRAINING_LOOPS,\n",
    "        \"steps_pre_loop\": STEPS_PER_LOOP,\n",
    "        # \"rank_k\": RANK_K,\n",
    "        \"num_actions\": NUM_ACTIONS,\n",
    "        \"per_arm\": \"True\",\n",
    "        \"global_lyrs\": str(GLOBAL_LAYERS),\n",
    "        \"arm_lyrs\": str(ARM_LAYERS),\n",
    "        \"common_lyrs\": str(COMMON_LAYERS),\n",
    "        \"encoding_dim\": ENCODING_DIM,\n",
    "        \"eps_steps\": EPS_PHASE_STEPS,\n",
    "    }\n",
    ")\n",
    "\n",
    "# gather the metrics for the last epoch to be saved in metrics\n",
    "aiplatform.log_metrics(\n",
    "    {\n",
    "        \"AverageReturnMetric\" : float(metric_results[\"AverageReturnMetric\"][-1])\n",
    "        , \"FinalRegretMetric\" : float(metric_results[\"RegretMetric\"][-1])\n",
    "    }\n",
    ")\n",
    "\n",
    "aiplatform.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38136270-c034-4807-b8e5-165fd7e9b7fb",
   "metadata": {},
   "source": [
    "# Off-Policy training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1751,
   "id": "e5e9e31d-e12a-4e07-91cd-884ee1cf6064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_rewards(element):\n",
    "    \"\"\"Calculates reward for the actions.\"\"\"\n",
    "\n",
    "    def _calc_reward(x):\n",
    "        \"\"\"Calculates reward for a single action.\"\"\"\n",
    "        r0 = lambda: tf.constant(0.0)\n",
    "        r1 = lambda: tf.constant(-10.0)\n",
    "        r2 = lambda: tf.constant(2.0)\n",
    "        r3 = lambda: tf.constant(3.0)\n",
    "        r4 = lambda: tf.constant(4.0)\n",
    "        r5 = lambda: tf.constant(10.0)\n",
    "        c1 = tf.equal(x, 1.0)\n",
    "        c2 = tf.equal(x, 2.0)\n",
    "        c3 = tf.equal(x, 3.0)\n",
    "        c4 = tf.equal(x, 4.0)\n",
    "        c5 = tf.equal(x, 5.0)\n",
    "        return tf.case([(c1, r1), (c2, r2), (c3, r3),(c4, r4),(c5, r5)], default=r0, exclusive=True)\n",
    "\n",
    "    return tf.map_fn(\n",
    "        fn=_calc_reward, \n",
    "        elems=element['user_rating'], \n",
    "        dtype=tf.float32\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1752,
   "id": "396809c3-c1c9-4326-b445-3a953389c1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_global_feature_list(input_features):\n",
    "    \"\"\"Return list of global features.\"\"\"\n",
    "    global_feature_names = ['user_id', 'bucketized_user_age', 'user_occupation_text', 'timestamp']\n",
    "    global_features = []\n",
    "    for global_feature in global_feature_names:\n",
    "        if global_feature in input_features:\n",
    "            global_features.append(input_features[global_feature])\n",
    "        else:\n",
    "            logging.error('Missing global feature %s', global_feature)\n",
    "    return global_features\n",
    "\n",
    "def _get_per_arm_feature_dict(input_features):\n",
    "    \"\"\"Returns a dictionary mapping feature key to per arm features.\"\"\"\n",
    "    per_arm_feature_names = ['movie_id', 'movie_genres']\n",
    "    arm_features = {}\n",
    "    for per_arm_feature in per_arm_feature_names:\n",
    "        if per_arm_feature in input_features:\n",
    "            arm_features[per_arm_feature] = input_features[per_arm_feature]\n",
    "        else:\n",
    "            logging.error('Missing per arm feature %s', per_arm_feature)\n",
    "    return arm_features\n",
    "\n",
    "def _add_outer_dimension(x):\n",
    "    \"\"\"Adds an extra outer dimension.\"\"\"\n",
    "    if isinstance(x, dict):\n",
    "        for key, value in x.items():\n",
    "            x[key] = tf.expand_dims(value, 1)\n",
    "        return x\n",
    "    return tf.expand_dims(x, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872d88cf-f26c-4cb2-afca-3719bee86ded",
   "metadata": {},
   "source": [
    "#### tmp - debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1753,
   "id": "6883c898-4bba-499c-899c-e7fcba99244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in train_dataset.batch(1).take(1):\n",
    "#     testy = _get_per_arm_feature_dict(x)\n",
    "\n",
    "###    \n",
    "# testz = _add_outer_dimension(testy)\n",
    "# >>>>\n",
    "# {'movie_id': <tf.Tensor: shape=(1, 1), dtype=string, numpy=array([[b'211']], dtype=object)>,\n",
    "#  'movie_genres': <tf.Tensor: shape=(1, 1, 1), dtype=int64, numpy=array([[[4]]])>}\n",
    "\n",
    "### \n",
    "# testx = tensor_spec.add_outer_dim(\n",
    "#     specs=testy,\n",
    "#     dim=None\n",
    "# )\n",
    "# >>>>\n",
    "# {'movie_id': TensorSpec(shape=(None, 1), dtype=tf.string, name=None),\n",
    "#  'movie_genres': TensorSpec(shape=(None, 1, 1), dtype=tf.int64, name=None)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d6b115-bcd3-4c05-9dc8-4feba22a7626",
   "metadata": {},
   "source": [
    "#### tmp - debugging\n",
    "\n",
    "```\n",
    "InvalidArgumentError: Exception encountered when calling layer 'tf.math.reduce_sum' (type TFOpLambda).\n",
    "\n",
    "{{function_node __wrapped__Sum_device_/job:localhost/replica:0/task:0/device:GPU:0}} Invalid reduction dimension (-2 for input with 1 dimension(s) [Op:Sum] name: \n",
    "\n",
    "Call arguments received by layer 'tf.math.reduce_sum' (type TFOpLambda):\n",
    "  • input_tensor=tf.Tensor(shape=(4,), dtype=float32)\n",
    "  • axis=-2\n",
    "  • keepdims=False\n",
    "  • name=None\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1754,
   "id": "d62e1390-d3a9-4e4a-864f-c0339d3892b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # _id = test_user_id_model(user_id_value)\n",
    "# # .batch(1)\n",
    "# for x in train_dataset.take(1):\n",
    "#     user_id_value = x['user_id']\n",
    "#     print(user_id_value)\n",
    "#     _id = test_user_id_model(user_id_value)\n",
    "#     print(_id)\n",
    "#     # XXX = tf.math.reduce_sum(_id, axis=-2)\n",
    "#     # print(XXX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d76ca24-29f5-4748-828f-40488fafc038",
   "metadata": {},
   "source": [
    "## global and arm feature generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1755,
   "id": "d34b6564-20b3-4492-aa43-607eebf81146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_global_context_features(x):\n",
    "    \"\"\"\n",
    "    This function generates a single global observation vector.\n",
    "    \"\"\"\n",
    "    user_id_value = x['user_id']\n",
    "    user_age_value = x['bucketized_user_age']\n",
    "    user_occ_value = x['user_occupation_text']\n",
    "    user_ts_value = x['timestamp']\n",
    "\n",
    "    _id = test_user_id_model(user_id_value) # input_tensor=tf.Tensor(shape=(4,), dtype=float32)\n",
    "    _age = test_user_age_model(user_age_value)\n",
    "    _occ = test_user_occ_model(user_occ_value)\n",
    "    _ts = test_user_ts_model(user_ts_value)\n",
    "\n",
    "    # # tmp - insepct numpy() values\n",
    "    # print(_id.numpy()) #[0])\n",
    "    # print(_age.numpy()) #[0])\n",
    "    # print(_occ.numpy()) #[0])\n",
    "    # print(_ts.numpy()) #[0])\n",
    "\n",
    "    # to numpy array\n",
    "    _id = np.array(_id.numpy()[0])\n",
    "    _age = np.array(_age.numpy()[0])\n",
    "    _occ = np.array(_occ.numpy()[0])\n",
    "    _ts = np.array(_ts.numpy()[0])\n",
    "\n",
    "    concat = np.concatenate(\n",
    "        [_id, _age, _occ, _ts], axis=-1 # -1\n",
    "    ).astype(np.float32)\n",
    "\n",
    "    return concat\n",
    "\n",
    "def _get_per_arm_features(x):\n",
    "    \"\"\"\n",
    "    This function generates a single per-arm observation vector\n",
    "    \"\"\"\n",
    "    mv_id_value = x['movie_id']\n",
    "    mv_gen_value = x['movie_genres'][0]\n",
    "\n",
    "    _mid = test_mv_id_model(mv_id_value)\n",
    "    _mgen = test_mv_gen_model(mv_gen_value)\n",
    "\n",
    "    # to numpy array\n",
    "    _mid = np.array(_mid.numpy()[0])\n",
    "    _mgen = np.array(_mgen.numpy()[0])\n",
    "\n",
    "    # print(_mid)\n",
    "    # print(_mgen)\n",
    "\n",
    "    concat = np.concatenate(\n",
    "        [_mid, _mgen], axis=-1 # -1\n",
    "    ).astype(np.float32)\n",
    "    # concat = tf.concat([_mid, _mgen], axis=-1).astype(np.float32)\n",
    "\n",
    "    return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1756,
   "id": "077f3507-833b-4aeb-83e3-b5f17d1e35a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.02599   , -0.03078079,  0.03106076,  0.00133444,  0.02207417,\n",
       "       -0.02917665,  0.02782809, -0.02822751, -0.04523091,  0.0495333 ,\n",
       "       -0.01482558, -0.04208376,  0.00741076, -0.04264941,  0.00693322,\n",
       "       -0.03396516], dtype=float32)"
      ]
     },
     "execution_count": 1756,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in train_dataset.batch(1).take(1):\n",
    "    test_globals = _get_global_context_features(x)\n",
    "\n",
    "print(test_globals.shape)\n",
    "test_globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1759,
   "id": "e933c988-684d-4e8d-a762-4ddeef5f3a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.02780459, -0.00370889, -0.02864446, -0.02917221, -0.01603731,\n",
       "        0.02465415,  0.01583499, -0.03253644,  0.03956462,  0.04351255,\n",
       "        0.01470714,  0.04936441,  0.01360733, -0.0412104 ,  0.02928157,\n",
       "        0.01699198], dtype=float32)"
      ]
     },
     "execution_count": 1759,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in train_dataset.batch(1).take(1):\n",
    "    test_arms = _get_per_arm_features(x)\n",
    "\n",
    "print(test_arms.shape)\n",
    "test_arms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffed0831-a80e-4834-a0c3-be9ea2563ca8",
   "metadata": {},
   "source": [
    "## trajectory function\n",
    "\n",
    "* see [test example](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_policies_test.py#L309)\n",
    "* see [create_per_arm_observation_spec src](https://github.com/tensorflow/agents/blob/master/tf_agents/specs/bandit_spec_utils.py#L39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1760,
   "id": "45ec6b65-7e74-48f8-8a69-a29be9959e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "HPARAMS = {\n",
    "    \"batch_size\":8,\n",
    "    \"num_docs_to_rank\":1,\n",
    "    \"model_type\": \"neural_epsilon_greedy\",\n",
    "    \"network_type\": 'commontower',\n",
    "    \"global_layers\": [16,4],\n",
    "    \"per_arm_layers\": [16,4],\n",
    "    \"common_layers\": [4],\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"epsilon\":0.01,\n",
    "}\n",
    "\n",
    "num_actions = HPARAMS['num_docs_to_rank']\n",
    "# num_actions=tf.convert_to_tensor(num_actions, dtype=tf.int32)\n",
    "print(num_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8f396e-33ce-439f-8bb6-1aee9edbb092",
   "metadata": {},
   "source": [
    "[create_per_arm_observation_spec](https://github.com/tensorflow/agents/blob/master/tf_agents/specs/bandit_spec_utils.py#L39)\n",
    "```\n",
    "def create_per_arm_observation_spec(\n",
    "    global_dim: int,\n",
    "    per_arm_dim: int,\n",
    "    max_num_actions: Optional[int] = None,\n",
    "    add_num_actions_feature: bool = False,\n",
    ") -> types.NestedTensorSpec:\n",
    "  \"\"\"Creates an observation spec with per-arm features and possibly action mask.\n",
    "\n",
    "  Args:\n",
    "    global_dim: (int) The global feature dimension.\n",
    "    per_arm_dim: (int) The per-arm feature dimension.\n",
    "    max_num_actions: If specified (int), this is the maximum number of actions\n",
    "      in any sample, and the num_actions dimension of the per-arm features will\n",
    "      be set to this number. The actual number of actions for a given sample can\n",
    "      be lower than this parameter: it can be specified via the\n",
    "      NUM_ACTIONS_FEATURE_KEY, or an action mask.\n",
    "    add_num_actions_feature: (bool) whether to use the `num_actions` feature key\n",
    "      to encode the number of actions per sample.\n",
    "\n",
    "  Returns:\n",
    "    A nested structure of observation spec.\n",
    "  \"\"\"\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ab412f-a66e-4d6d-9450-d21bf88363df",
   "metadata": {},
   "source": [
    "#### Debugging from test_script\n",
    "\n",
    "* [src](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_policies_test.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1761,
   "id": "4cd21107-4dba-439e-99aa-527e9cb9042f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(16,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(1, 16), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 1761,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_spec = bandit_spec_utils.create_per_arm_observation_spec(GLOBAL_DIM, PER_ARM_DIM, num_actions) # 2,3,4\n",
    "obs_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1762,
   "id": "cb4ee969-7afb-4efc-ae86-b9810cfbdcea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'global': TensorSpec(shape=(16,), dtype=tf.float32, name=None),\n",
       "                 'per_arm': TensorSpec(shape=(1, 16), dtype=tf.float32, name=None)},\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 1762,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec = ts.time_step_spec(obs_spec)\n",
    "time_step_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1763,
   "id": "b36c4ef8-6a9d-4e9a-8360-912c3050132f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(3, dtype=int32))"
      ]
     },
     "execution_count": 1763,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec = tensor_spec.BoundedTensorSpec((), tf.int32, 0, 3)\n",
    "action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a50afe0-7ea5-413d-8fa7-50dc9fc5acaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reward_network = (\n",
    "#     global_and_arm_feature_network.create_feed_forward_common_tower_network(\n",
    "#         obs_spec, (4, 3), (3, 4), (4, 2)\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9bba1f-4b8a-4c31-9b1d-fe9249c6ea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # policy = policy_class(\n",
    "    #     time_step_spec,\n",
    "    #     action_spec,\n",
    "    #     reward_network=reward_network,\n",
    "    #     accepts_per_arm_features=True,\n",
    "    #     emit_policy_info=('predicted_rewards_mean',),\n",
    "    # )\n",
    "    # just from test script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1770,
   "id": "bb609ecb-a2bf-472f-9096-3bcc220b4690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16, 1, 16), dtype=float32, numpy=\n",
       "array([[[232., 240., 215.,  59.,  25.,  31., 182., 198., 113., 242.,\n",
       "          71.,   6.,  58., 179., 210., 185.]],\n",
       "\n",
       "       [[ 62., 190., 141.,  75., 166., 255., 125., 118.,  78., 233.,\n",
       "         183.,  68., 171., 114., 253., 228.]],\n",
       "\n",
       "       [[  7., 252., 108.,   8., 105., 246.,  94.,  35.,  55., 112.,\n",
       "         209., 207., 172.,   1.,  97.,  67.]],\n",
       "\n",
       "       [[117., 149.,  42.,  39.,  37.,  98.,  61.,  50., 160., 214.,\n",
       "         249., 167.,   4.,  85.,  95.,  45.]],\n",
       "\n",
       "       [[203., 199.,  34.,  81.,  15., 181.,   2., 205.,  49.,  21.,\n",
       "         103., 254., 236., 126.,  79.,   9.]],\n",
       "\n",
       "       [[189., 229., 129.,  44.,  84., 213.,  69.,   5., 104., 110.,\n",
       "          77., 212., 200., 100.,  17.,  41.]],\n",
       "\n",
       "       [[ 87., 146., 148., 170.,  51.,  91.,  38.,  99., 115., 186.,\n",
       "         238., 244., 122.,  18., 234., 151.]],\n",
       "\n",
       "       [[169.,  54.,  80., 237., 132.,  53., 134.,  96.,  56., 226.,\n",
       "          86., 127.,  46., 111., 131.,  16.]],\n",
       "\n",
       "       [[143., 138., 154., 227., 222., 243., 216.,  90.,  30., 193.,\n",
       "         165., 140., 120., 150.,  14., 230.]],\n",
       "\n",
       "       [[ 13., 121., 195., 231.,  88., 142., 224., 218., 204., 136.,\n",
       "          72.,  40.,  43., 155., 217.,  92.]],\n",
       "\n",
       "       [[241., 175., 247.,  93., 178., 184.,   0.,  22., 245.,  19.,\n",
       "          74.,  52.,   3.,  73.,  11., 153.]],\n",
       "\n",
       "       [[250., 162., 219.,  83., 177., 145., 248., 223., 164., 137.,\n",
       "          47.,  48., 124.,  64., 225.,  36.]],\n",
       "\n",
       "       [[197.,  20., 116., 161., 158., 220.,  27., 180.,  33., 156.,\n",
       "         107.,  60., 194., 201., 191., 109.]],\n",
       "\n",
       "       [[ 26., 133., 135., 221.,  10., 208.,  70., 196., 159., 173.,\n",
       "         139., 202., 168.,  65.,  66., 174.]],\n",
       "\n",
       "       [[ 76., 188.,  82., 123., 157., 176., 211.,  28., 152., 163.,\n",
       "         128., 106., 192.,  32., 251.,  63.]],\n",
       "\n",
       "       [[ 57.,  89., 206., 144., 239., 119., 147., 235., 102., 187.,\n",
       "          29., 130.,  12., 101.,  23.,  24.]]], dtype=float32)>"
      ]
     },
     "execution_count": 1770,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_feature = tf.cast(\n",
    "    tf.reshape(tf.random.shuffle(tf.range(256)), shape=[GLOBAL_DIM, num_actions, PER_ARM_DIM]), # 2, 4, 3\n",
    "    dtype=tf.float32,\n",
    ")\n",
    "action_feature #- TODO - comeback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1767,
   "id": "42240bab-455f-4674-8caa-2e38e3188a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[1., 2.],\n",
       "        [3., 4.]], dtype=float32)>,\n",
       " 'per_arm': <tf.Tensor: shape=(16, 1, 16), dtype=float32, numpy=\n",
       " array([[[214., 159.,  86.,  72.,  44., 218., 116., 162., 211.,  60.,\n",
       "          244.,  80., 164.,  66., 215., 188.]],\n",
       " \n",
       "        [[ 43., 243., 114.,  48.,  17., 172., 119., 141.,  38., 187.,\n",
       "          135., 204., 209., 221., 155., 205.]],\n",
       " \n",
       "        [[102., 129., 236., 223.,   8., 111.,  33., 250., 107., 248.,\n",
       "            9.,  58., 242., 125.,  77.,   2.]],\n",
       " \n",
       "        [[  7., 168.,   3., 123., 234., 117.,  84., 101.,  19., 196.,\n",
       "          230., 255.,  24., 150.,  73., 167.]],\n",
       " \n",
       "        [[132.,  30.,  16., 122., 235., 112., 178., 180., 190.,  76.,\n",
       "          171.,  87., 240., 124., 200., 251.]],\n",
       " \n",
       "        [[127.,  45., 198., 136., 254.,  46., 229.,  85., 193., 128.,\n",
       "           70., 133., 142.,  51.,   4.,  67.]],\n",
       " \n",
       "        [[ 64.,  36.,  41., 170., 241.,   1., 113.,  32., 137., 118.,\n",
       "          219.,  26., 181., 208.,  42., 201.]],\n",
       " \n",
       "        [[126., 194.,  15., 224.,  49., 220., 169., 203., 216.,  63.,\n",
       "           14.,  82.,  50.,  83., 245., 120.]],\n",
       " \n",
       "        [[212.,  96.,  39., 166., 151., 156., 189.,  23., 183., 199.,\n",
       "          226., 100.,  55., 165.,  81.,  88.]],\n",
       " \n",
       "        [[179., 104., 145., 110.,  34.,  52., 232., 146., 247., 217.,\n",
       "          139.,  79., 207., 147., 109., 143.]],\n",
       " \n",
       "        [[ 56., 210.,   5.,  62.,  54.,  18., 175.,  27., 144.,  37.,\n",
       "           98., 108., 238.,  93.,  71., 227.]],\n",
       " \n",
       "        [[ 40.,  28., 185., 213., 131., 176., 202.,  99.,  90., 239.,\n",
       "           13., 158.,  78., 148., 140.,   6.]],\n",
       " \n",
       "        [[ 68., 246., 231.,  89., 160.,  47., 206.,  21., 228.,  12.,\n",
       "           35., 134., 154.,  94., 195., 249.]],\n",
       " \n",
       "        [[ 57., 186., 225., 152.,  59., 174., 197., 173., 177., 233.,\n",
       "           74., 103.,  92., 105., 253., 192.]],\n",
       " \n",
       "        [[222., 138.,  61.,  53., 157., 115.,  22.,   0.,  31., 153.,\n",
       "          161.,  11., 182.,  97.,  91., 121.]],\n",
       " \n",
       "        [[ 69., 130., 163.,  10.,  95.,  20.,  25.,  75.,  29., 191.,\n",
       "           65., 252., 237., 184., 106., 149.]]], dtype=float32)>}"
      ]
     },
     "execution_count": 1767,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_test_observations = {\n",
    "    bandit_spec_utils.GLOBAL_FEATURE_KEY: tf.constant(\n",
    "        [[1, 2], [3, 4]], dtype=tf.float32\n",
    "    ),\n",
    "    bandit_spec_utils.PER_ARM_FEATURE_KEY: action_feature,\n",
    "}\n",
    "\n",
    "_test_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1768,
   "id": "4f6d4e7d-c762-4c73-a704-df5682dedf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': array([1., 1.], dtype=float32),\n",
       " 'observation': array([-0.02599   , -0.03078079,  0.03106076,  0.00133444,  0.02207417,\n",
       "       -0.02917665,  0.02782809, -0.02822751, -0.04523091,  0.0495333 ,\n",
       "       -0.01482558, -0.04208376,  0.00741076, -0.04264941,  0.00693322,\n",
       "       -0.03396516], dtype=float32),\n",
       " 'reward': array([0., 0.], dtype=float32),\n",
       " 'step_type': array([0, 0], dtype=int32)})"
      ]
     },
     "execution_count": 1768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step = ts.restart(observations, batch_size=2)\n",
    "time_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1806,
   "id": "a7ff41c9-0bd6-46ca-97a9-5df130d1eb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# action_step = policy.action(time_step, seed=1)\n",
    "# action_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1780,
   "id": "47a792c1-347b-461c-b11e-54223cb16b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16, 1), dtype=float32, numpy=\n",
       "array([[ 0.03700204],\n",
       "       [-0.00503105],\n",
       "       [ 0.0033116 ],\n",
       "       [-0.00502714],\n",
       "       [ 0.02094278],\n",
       "       [ 0.030205  ],\n",
       "       [-0.03883966],\n",
       "       [-0.03852518],\n",
       "       [-0.02759117],\n",
       "       [ 0.01288647],\n",
       "       [-0.02875481],\n",
       "       [-0.01569642],\n",
       "       [ 0.01138375],\n",
       "       [ 0.04505277],\n",
       "       [-0.04091054],\n",
       "       [-0.01733469]], dtype=float32)>"
      ]
     },
     "execution_count": 1780,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in train_dataset.batch(1).take(16):\n",
    "    arm_features = _get_per_arm_features(x)\n",
    "    arm_features = _add_outer_dimension(arm_features)\n",
    "    \n",
    "arm_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8733a494-36d7-4ade-826f-88413f09ecd9",
   "metadata": {},
   "source": [
    "### Trajectory fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1822,
   "id": "19734467-3a84-4ebd-abea-3374261d9313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "# from tf_agents.trajectories import trajectory\n",
    "\n",
    "# # replay_buffer_signature = tensor_spec.add_outer_dim(\n",
    "# #       replay_buffer_signature\n",
    "# # )\n",
    "\n",
    "\n",
    "# def _trajectory_fn(element): # hparams\n",
    "#     \"\"\"Converts a dataset element into a trajectory.\"\"\"\n",
    "#     global_features = _get_global_context_features(element)\n",
    "#     arm_features = _get_per_arm_features(element)\n",
    "    \n",
    "#     # # tmp \n",
    "#     # print(f\"global_features: {global_features}\")\n",
    "#     # print(f\"arm_features: {arm_features}\")\n",
    "    \n",
    "#     # Adds a time dimension.\n",
    "#     # arm_features = _add_outer_dimension(arm_features)\n",
    "#     # arm_features = tensor_spec.add_outer_dim(arm_features)\n",
    "    \n",
    "#     # observations\n",
    "#     observation = {\n",
    "#         bandit_spec_utils.GLOBAL_FEATURE_KEY:\n",
    "#             global_features,\n",
    "#             # _add_outer_dimension(global_features)\n",
    "#         bandit_spec_utils.PER_ARM_FEATURE_KEY:\n",
    "#             arm_features\n",
    "#             # _add_outer_dimension(arm_features),\n",
    "#     }\n",
    "#     # print(\"after adding extra dim...\")\n",
    "#     # print(f\"observation: {observation}\")\n",
    "#     # print(f\"arm_features: {arm_features}\")\n",
    "    \n",
    "#     # reward = tensor_spec.add_outer_dim(_get_rewards(element))\n",
    "#     reward = _get_rewards(element)\n",
    "#     # print(f\"reward: {reward}\")\n",
    "    \n",
    "#     # To emit the predicted rewards in policy_info, we need to create dummy\n",
    "#     # rewards to match the definition in TensorSpec for the ones specified in\n",
    "#     # emit_policy_info set.\n",
    "#     # dummy_rewards = tf.zeros([HPARAMS['batch_size'], 1, HPARAMS['num_docs_to_rank']])\n",
    "#     # dummy_rewards = tf.zeros([HPARAMS['batch_size'], HPARAMS['num_docs_to_rank']])\n",
    "#     dummy_rewards = tf.zeros([HPARAMS['num_docs_to_rank']])\n",
    "#     policy_info = policy_utilities.PerArmPolicyInfo(\n",
    "#         chosen_arm_features=arm_features,\n",
    "#         # Pass dummy mean rewards here to match the model_spec for emitting\n",
    "#         # mean rewards in policy info\n",
    "#         predicted_rewards_mean=dummy_rewards\n",
    "#     )\n",
    "    \n",
    "# # tf_agents.policies.utils.create_chosen_arm_features_info_spec(\n",
    "# #     observation_spec: tf_agents.typing.types.NestedTensorSpec\n",
    "# # ) -> tf_agents.typing.types.NestedTensorSpec\n",
    "    \n",
    "#     if HPARAMS['model_type'] == 'neural_ucb':\n",
    "#         policy_info = policy_info._replace(\n",
    "#             predicted_rewards_optimistic=dummy_rewards\n",
    "#         )\n",
    "        \n",
    "#     # print(f\"observation: {observation}\")\n",
    "#     # print(f\"reward: {reward}\")\n",
    "#     # print(f\"policy_info: {policy_info}\")\n",
    "#     # print(f\"dummy_rewards: {dummy_rewards}\")\n",
    "    \n",
    "#     return trajectory.single_step(\n",
    "#         observation=observation,\n",
    "#         action=tf.zeros_like(\n",
    "#             reward, dtype=tf.int32\n",
    "#         ),  # Arm features are copied from policy info, put dummy zeros here\n",
    "#         policy_info=policy_info,\n",
    "#         reward=reward,\n",
    "#         discount=tf.zeros_like(reward)\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da7ce9d-82f8-4c1a-b6a5-d15ca0d6288b",
   "metadata": {},
   "source": [
    "**TODO:**\n",
    "* investigate `add_outer_dims_nest` [src](https://github.com/tensorflow/agents/blob/master/tf_agents/specs/tensor_spec.py#L472C5-L472C24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1782,
   "id": "4ba729b2-b05c-4ca1-b095-18643efa70f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'action': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>,\n",
       " 'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
       " 'next_step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([2], dtype=int32)>,\n",
       " 'observation': {'global': <tf.Tensor: shape=(16,), dtype=float32, numpy=\n",
       "array([-0.02599   , -0.03078079,  0.03106076,  0.00133444,  0.02207417,\n",
       "       -0.02917665,  0.02782809, -0.02822751, -0.04523091,  0.0495333 ,\n",
       "       -0.01482558, -0.04208376,  0.00741076, -0.04264941,  0.00693322,\n",
       "       -0.03396516], dtype=float32)>,\n",
       "                 'per_arm': <tf.Tensor: shape=(16,), dtype=float32, numpy=\n",
       "array([-0.02780459, -0.00370889, -0.02864446, -0.02917221, -0.01603731,\n",
       "        0.02465415,  0.01583499, -0.03253644,  0.03956462,  0.04351255,\n",
       "        0.01470714,  0.04936441,  0.01360733, -0.0412104 ,  0.02928157,\n",
       "        0.01699198], dtype=float32)>},\n",
       " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=<tf.Tensor: shape=(16,), dtype=float32, numpy=\n",
       "array([-0.02780459, -0.00370889, -0.02864446, -0.02917221, -0.01603731,\n",
       "        0.02465415,  0.01583499, -0.03253644,  0.03956462,  0.04351255,\n",
       "        0.01470714,  0.04936441,  0.01360733, -0.0412104 ,  0.02928157,\n",
       "        0.01699198], dtype=float32)>),\n",
       " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>,\n",
       " 'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>})"
      ]
     },
     "execution_count": 1782,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for x in train_dataset.batch(1).take(1):\n",
    "#     single_traj = _trajectory_fn(x)\n",
    "\n",
    "# single_traj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6771b0e4-3178-491c-8e7a-3a977a14eed7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Observation Spec\n",
    "\n",
    "* see [src](https://github.com/tensorflow/agents/blob/master/tf_agents/specs/bandit_spec_utils.py#L39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1783,
   "id": "1735f71e-914a-4b3d-9466-e871299eccf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "GLOBAL_DIM = global_context_sampling_fn()\n",
    "GLOBAL_DIM = GLOBAL_DIM.shape[0]\n",
    "print(GLOBAL_DIM)\n",
    "\n",
    "PER_ARM_DIM = per_arm_context_sampling_fn()\n",
    "PER_ARM_DIM = PER_ARM_DIM.shape[0]\n",
    "print(PER_ARM_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1718,
   "id": "15f1cea7-632e-4c44-a4eb-069b5a70733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_spec = tensor_spec.TensorSpec([GLOBAL_DIM], tf.float32)\n",
    "# per_arm_spec = tensor_spec.TensorSpec([None, PER_ARM_DIM], tf.float32)\n",
    "# observation_spec = {'global': global_spec, 'per_arm': per_arm_spec}\n",
    "# observation_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4c7902-5eb7-4f0a-af36-c61b3f45b4b2",
   "metadata": {},
   "source": [
    "This observation spec allows the user to have a global observation of fixed dimension (as usual), and an unspecified number of per-arm features (also of fixed dimension). \n",
    "* Then, the actions output by the policy are still integers as usual, and they indicate which row of the arm-features it has chosen. \n",
    "* So the action spec has to be the following (describing a single integer value without boundaries):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d40ee24-0ffd-440b-a214-5f68c1f899af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# action_spec = tensor_spec.TensorSpec((), tf.int32)\n",
    "# action_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd230c27-5528-476f-8f17-c047e9fc36ba",
   "metadata": {},
   "source": [
    "**XLA compatibility:**\n",
    "* Since dynamic tensor shapes are not compatible with XLA, the number of arm features (and consequently, number of arms for a step) cannot be dynamic. \n",
    "* One workaround is to fix the maximum number of arms for a problem, then pad the arm features in steps with fewer arms, and use action masking to indicate how many arms are actually active. \n",
    "\n",
    "In this case, the specs change as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1925,
   "id": "3e5abf7d-559d-43ee-a631-c78e7bca1e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "num_actions = HPARAMS['num_docs_to_rank']\n",
    "# num_actions=tf.convert_to_tensor(num_actions, dtype=tf.int32)\n",
    "print(num_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20348f5-9e1e-47af-a87a-115f28bd1abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_spec = tensor_spec.TensorSpec(shape=[GLOBAL_DIM], dtype=tf.float32)\n",
    "# per_arm_spec = tensor_spec.TensorSpec(shape=[num_actions, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "# add outer nested dim\n",
    "# global_spec = tensor_spec.add_outer_dims_nest(      # add_outer_dim\n",
    "#     specs=global_spec,\n",
    "#     outer_dims=[HPARAMS['batch_size']]\n",
    "# )\n",
    "# per_arm_spec = tensor_spec.add_outer_dims_nest( # add_outer_dim\n",
    "#     specs=per_arm_spec,\n",
    "#     outer_dims=[HPARAMS['batch_size']]\n",
    "# )\n",
    "\n",
    "# observation_spec = {'global': global_spec, 'per_arm': per_arm_spec}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1953,
   "id": "ced640fe-ad9e-4932-8641-7c83a22d0013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(16,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(1, 16), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 1953,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_spec = bandit_spec_utils.create_per_arm_observation_spec(\n",
    "    GLOBAL_DIM, PER_ARM_DIM, num_actions, add_num_actions_feature=False\n",
    ") # 2,3,4\n",
    "\n",
    "observation_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1721,
   "id": "29f9d300-9914-4712-bbeb-e5a833306799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(16,), dtype=tf.float32, name=None)"
      ]
     },
     "execution_count": 1721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import tf_agents\n",
    "\n",
    "# test_chosen_arm_feats = tf_agents.policies.utils.create_chosen_arm_features_info_spec(observation_spec=observation_spec)\n",
    "# test_chosen_arm_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9c7b66-05e8-486c-9e14-f2b1feb6206a",
   "metadata": {},
   "source": [
    "### Action Spec\n",
    "\n",
    "> The time_step_spec and action_spec are specifications for the input time step and the output action\n",
    "\n",
    "```\n",
    "    if (\n",
    "        not tensor_spec.is_bounded(action_spec)\n",
    "        or not tensor_spec.is_discrete(action_spec)\n",
    "        or action_spec.shape.rank > 1\n",
    "        or action_spec.shape.num_elements() != 1\n",
    "    ):\n",
    "      raise NotImplementedError(\n",
    "          'action_spec must be a BoundedTensorSpec of type int32 and shape (). '\n",
    "          'Found {}.'.format(action_spec)\n",
    "      )\n",
    "```\n",
    "\n",
    "* [src](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_base_policy.py#L97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1951,
   "id": "bf5e68ee-15b7-4f32-8961-b57d72f91233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(3, dtype=int32))"
      ]
     },
     "execution_count": 1951,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec_test = tensor_spec.BoundedTensorSpec((), tf.int32, 0, 3)\n",
    "action_spec_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1969,
   "id": "2fc70e1b-3a25-4f87-bacc-4a43e5dd7ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(0, dtype=int32))"
      ]
     },
     "execution_count": 1969,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=(), \n",
    "    dtype=tf.int32,\n",
    "    minimum=tf.constant(0),                # 0  | Variable()\n",
    "    maximum=num_actions-tf.constant(1),    # -1 | Variable()\n",
    "    name=\"action_spec\"\n",
    ")\n",
    "action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1928,
   "id": "f3591673-1c7f-4fd0-ae58-b4c1fffe328e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(flat_action_spec): 1\n",
      "flat_action_spec     : [BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(0, dtype=int32))]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(0, dtype=int32))"
      ]
     },
     "execution_count": 1928,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len() should not be > 1\n",
    "flat_action_spec = tf.nest.flatten(action_spec)\n",
    "print(f\"len(flat_action_spec): {len(flat_action_spec)}\")\n",
    "print(f\"flat_action_spec     : {flat_action_spec}\")\n",
    "\n",
    "action_spec = flat_action_spec[0]\n",
    "action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1929,
   "id": "a991904e-332e-48f5-b0cc-9b5f7704b475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_num_actions: 1\n",
      "predicted_rewards_mean: TensorSpec(shape=(1,), dtype=tf.float32, name=None)\n"
     ]
    }
   ],
   "source": [
    "expected_num_actions = action_spec.maximum - action_spec.minimum + 1\n",
    "print(f\"expected_num_actions: {expected_num_actions}\")\n",
    "\n",
    "predicted_rewards_mean = tensor_spec.TensorSpec([expected_num_actions])\n",
    "print(f\"predicted_rewards_mean: {predicted_rewards_mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8826bd77-4ec0-4d66-a2fe-57ba961c262d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bandit_policy_type = (\n",
    "#   policy_utilities.create_bandit_policy_type_tensor_spec(shape=[1])\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1726,
   "id": "3c36eba0-8474-4ecf-a51e-a369a64353e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observation_spec.update({bandit_spec_utils.NUM_ACTIONS_FEATURE_KEY: action_spec})\n",
    "# observation_spec\n",
    "\n",
    "# TODO - JT check "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bcedd3-909d-4be4-9c4d-aa02ceea4d93",
   "metadata": {},
   "source": [
    "### Time step spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1952,
   "id": "96002050-a6be-4ace-ba0f-12726b24d164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'global': TensorSpec(shape=(2,), dtype=tf.float32, name=None),\n",
       "                 'per_arm': TensorSpec(shape=(4, 3), dtype=tf.float32, name=None)},\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 1952,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec_test = ts.time_step_spec(obs_spec)\n",
    "time_step_spec_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1950,
   "id": "83ce9aa0-9f5c-4968-b8f5-7128e79375e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': array([1., 1.], dtype=float32),\n",
       " 'observation': array([-0.02599   , -0.03078079,  0.03106076,  0.00133444,  0.02207417,\n",
       "       -0.02917665,  0.02782809, -0.02822751, -0.04523091,  0.0495333 ,\n",
       "       -0.01482558, -0.04208376,  0.00741076, -0.04264941,  0.00693322,\n",
       "       -0.03396516], dtype=float32),\n",
       " 'reward': array([0., 0.], dtype=float32),\n",
       " 'step_type': array([0, 0], dtype=int32)})"
      ]
     },
     "execution_count": 1950,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time_step = ts.restart(observations, batch_size=2)\n",
    "\n",
    "# >>>\n",
    "\n",
    "# TimeStep(\n",
    "# {'discount': array([1., 1.], dtype=float32),\n",
    "#  'observation': array([-0.02599   , -0.03078079,  0.03106076,  0.00133444,  0.02207417,\n",
    "#        -0.02917665,  0.02782809, -0.02822751, -0.04523091,  0.0495333 ,\n",
    "#        -0.01482558, -0.04208376,  0.00741076, -0.04264941,  0.00693322,\n",
    "#        -0.03396516], dtype=float32),\n",
    "#  'reward': array([0., 0.], dtype=float32),\n",
    "#  'step_type': array([0, 0], dtype=int32)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1956,
   "id": "c0b6f534-2e12-418b-951d-e83af3098ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'global': TensorSpec(shape=(16,), dtype=tf.float32, name=None),\n",
       "                 'per_arm': TensorSpec(shape=(1, 16), dtype=tf.float32, name=None)},\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 1956,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec = ts.time_step_spec(\n",
    "    observation_spec = observation_spec, \n",
    "    # reward_spec = _reward_spec\n",
    ")\n",
    "time_step_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f4b432-4935-40e5-abaa-028f8ebb7377",
   "metadata": {},
   "source": [
    "## chosen arm features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1957,
   "id": "ba3691eb-880b-4638-b1c1-d4697f60c82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(16,), dtype=tf.float32, name=None)"
      ]
     },
     "execution_count": 1957,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_arm_features_info = (\n",
    "  policy_utilities.create_chosen_arm_features_info_spec(\n",
    "      time_step_spec.observation,\n",
    "  )\n",
    ")\n",
    "chosen_arm_features_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1966,
   "id": "f4eaee34-6948-457f-90b1-abfdd2aff49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(16,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(1, 16), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 1966,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec.observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5be46e-0760-4c3a-b406-db4d0c968d6d",
   "metadata": {},
   "source": [
    "```\n",
    "class BanditPolicyType(object):\n",
    "  \"\"\"Enumeration of bandit policy types.\"\"\"\n",
    "\n",
    "  # No bandit policy type specified.\n",
    "  UNKNOWN = 0\n",
    "  # Greedy decision made by bandit agent.\n",
    "  GREEDY = 1\n",
    "  # Random decision for exploration made by epsilon-greedy agent sampled from\n",
    "  # uniform distribution over actions.\n",
    "  UNIFORM = 2\n",
    "  # Decision made by Boltzmann exploration.\n",
    "  BOLTZMANN = 3\n",
    "  # Decision made by FALCON.\n",
    "  FALCON = 4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1958,
   "id": "477471ec-de96-41b0-be71-a926dffae066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32))"
      ]
     },
     "execution_count": 1958,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandit_policy_type = (\n",
    "    policy_utilities.create_bandit_policy_type_tensor_spec(shape=[1])\n",
    ")\n",
    "bandit_policy_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1959,
   "id": "cb544fc5-615b-4f54-a4c0-603616679c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(1,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), chosen_arm_features=TensorSpec(shape=(16,), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 1959,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_spec = policy_utilities.PerArmPolicyInfo(\n",
    "  predicted_rewards_mean=predicted_rewards_mean,\n",
    "  bandit_policy_type=bandit_policy_type,\n",
    "  chosen_arm_features=chosen_arm_features_info,\n",
    ")\n",
    "info_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef88b7ca-2cf6-4962-a47f-97ad6be652e2",
   "metadata": {},
   "source": [
    "## define Agent & network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1960,
   "id": "eb95db2f-39f9-4caf-a7b5-360618a6ac7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: OffpolicyNeuralEpsGreedyAgent\n",
      "\n",
      "Network: global_and_arm_common_tower_network_70\n"
     ]
    }
   ],
   "source": [
    "from tf_agents.bandits.agents import greedy_reward_prediction_agent\n",
    "\n",
    "network = None\n",
    "observation_and_action_constraint_splitter = None\n",
    "\n",
    "# global_step = tf.Variable(0)\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "if HPARAMS['network_type'] == 'commontower':\n",
    "    network = global_and_arm_feature_network.create_feed_forward_common_tower_network(\n",
    "        observation_spec = observation_spec, \n",
    "        global_layers = HPARAMS['global_layers'], \n",
    "        arm_layers = HPARAMS['per_arm_layers'], \n",
    "        common_layers = HPARAMS['common_layers'],\n",
    "        output_dim = 1\n",
    "    )\n",
    "elif HPARAMS['network_type'] == 'dotproduct':\n",
    "    network = global_and_arm_feature_network.create_feed_forward_dot_product_network(\n",
    "        observation_spec = observation_spec, \n",
    "        global_layers = HPARAMS['global_layers'], \n",
    "        arm_layers = HPARAMS['per_arm_layers']\n",
    "    )\n",
    "    \n",
    "# agent = greedy_reward_prediction_agent.GreedyRewardPredictionAgent()\n",
    "    \n",
    "agent = neural_epsilon_greedy_agent.NeuralEpsilonGreedyAgent(\n",
    "    time_step_spec=time_step_spec,\n",
    "    action_spec=action_spec,\n",
    "    reward_network=network,\n",
    "    optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=HPARAMS['learning_rate']),\n",
    "    epsilon=HPARAMS['epsilon'],\n",
    "    observation_and_action_constraint_splitter=(\n",
    "        observation_and_action_constraint_splitter\n",
    "    ),\n",
    "    accepts_per_arm_features=True,\n",
    "    emit_policy_info=(policy_utilities.InfoFields.PREDICTED_REWARDS_MEAN),\n",
    "    train_step_counter=global_step,\n",
    "    # info_fields_to_inherit_from_greedy=[\n",
    "    #     policy_utilities.InfoFields.PREDICTED_REWARDS_MEAN\n",
    "    # ],\n",
    "    name='OffpolicyNeuralEpsGreedyAgent'\n",
    ")\n",
    "agent.initialize()\n",
    "\n",
    "print(f\"Agent: {agent.name}\\n\")\n",
    "if network:\n",
    "    print(f\"Network: {network.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1961,
   "id": "e72f7c41-c462-441b-933b-0c276ad67225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeStep Spec (for each batch):\n",
      " TimeStep(\n",
      "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'observation': DictWrapper({'global': TensorSpec(shape=(16,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(1, 16), dtype=tf.float32, name=None)}),\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"TimeStep Spec (for each batch):\\n\", agent.time_step_spec, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1962,
   "id": "71aa359d-28c5-40af-a8d0-2d140a2da3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Spec (for each batch):\n",
      " BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(0, dtype=int32)) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Action Spec (for each batch):\\n\", agent.action_spec, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1963,
   "id": "65ba7b4a-9544-46e0-b3a5-89ba145917e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_TupleWrapper(Trajectory(\n",
      "{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(0, dtype=int32)),\n",
      " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
      " 'observation': DictWrapper({'global': TensorSpec(shape=(16,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(1, 16), dtype=tf.float32, name=None)}),\n",
      " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(1,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=TensorSpec(shape=(16,), dtype=tf.float32, name=None)),\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))\n"
     ]
    }
   ],
   "source": [
    "pprint(agent.policy.trajectory_spec) # TODO check observation between this and next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1964,
   "id": "a5ce9aab-8ce8-40d2-9c4c-22293b09655c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data spec:  Trajectory(\n",
      "{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(0, dtype=int32)),\n",
      " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
      " 'observation': DictWrapper({'global': TensorSpec(shape=(16,), dtype=tf.float32, name=None)}),\n",
      " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(1,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=TensorSpec(shape=(16,), dtype=tf.float32, name=None)),\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n"
     ]
    }
   ],
   "source": [
    "print('training data spec: ', agent.training_data_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1965,
   "id": "ac017837-8837-4f10-b158-91ab1f7e7849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation spec in training:  {'global': TensorSpec(shape=(16,), dtype=tf.float32, name=None)}\n"
     ]
    }
   ],
   "source": [
    "print('observation spec in training: ', agent.training_data_spec.observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1940,
   "id": "fbbbd916-149f-4aa6-bc30-4582a684179a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen arm features:  TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n"
     ]
    }
   ],
   "source": [
    "print('chosen arm features: ', agent.training_data_spec.policy_info.chosen_arm_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66054a77-6abf-4809-ab37-80c7d94675ce",
   "metadata": {},
   "source": [
    "### Trajectory fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1944,
   "id": "080b03f9-5679-436e-a672-229d4b773805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "\n",
    "# replay_buffer_signature = tensor_spec.add_outer_dim(\n",
    "#       replay_buffer_signature\n",
    "# )\n",
    "\n",
    "\n",
    "def _trajectory_fn(element): # hparams\n",
    "    \"\"\"\n",
    "    Converts a dataset element into a trajectory.\n",
    "    \"\"\"\n",
    "    # specs\n",
    "    obs_spec = bandit_spec_utils.create_per_arm_observation_spec(\n",
    "        GLOBAL_DIM, PER_ARM_DIM, num_actions, add_num_actions_feature=False\n",
    "    )\n",
    "    time_step_spec = ts.time_step_spec(obs_spec)\n",
    "    action_spec = tensor_spec.BoundedTensorSpec((), tf.int32, 0, num_actions-tf.constant(1))\n",
    "\n",
    "    # process features from train example\n",
    "    global_features = _get_global_context_features(element)\n",
    "    arm_features = _get_per_arm_features(element)\n",
    "    \n",
    "    # # tmp \n",
    "    # print(f\"global_features: {global_features}\")\n",
    "    # print(f\"arm_features: {arm_features}\")\n",
    "    \n",
    "    # Adds a time dimension.\n",
    "    # arm_features = _add_outer_dimension(arm_features)\n",
    "    # arm_features = tensor_spec.add_outer_dim(arm_features)\n",
    "    \n",
    "    # observations\n",
    "    observation = {\n",
    "        bandit_spec_utils.GLOBAL_FEATURE_KEY:\n",
    "            global_features,\n",
    "            # _add_outer_dimension(global_features)\n",
    "        # bandit_spec_utils.PER_ARM_FEATURE_KEY:\n",
    "        #     arm_features\n",
    "            # _add_outer_dimension(arm_features),\n",
    "    }\n",
    "    # print(\"after adding extra dim...\")\n",
    "    # print(f\"observation: {observation}\")\n",
    "    # print(f\"arm_features: {arm_features}\")\n",
    "    \n",
    "    # ts spec\n",
    "    chosen_arm_features_info = (\n",
    "      policy_utilities.create_chosen_arm_features_info_spec(\n",
    "          time_step_spec.observation,\n",
    "      )\n",
    "    )\n",
    "    \n",
    "    # reward = tensor_spec.add_outer_dim(_get_rewards(element))\n",
    "    reward = _get_rewards(element)\n",
    "    # print(f\"reward: {reward}\")\n",
    "    \n",
    "    # To emit the predicted rewards in policy_info, we need to create dummy\n",
    "    # rewards to match the definition in TensorSpec for the ones specified in\n",
    "    # emit_policy_info set.\n",
    "    dummy_rewards = tf.zeros([HPARAMS['batch_size'], 1, HPARAMS['num_docs_to_rank']])\n",
    "    # dummy_rewards = tf.zeros([HPARAMS['batch_size'], HPARAMS['num_docs_to_rank']])\n",
    "    # dummy_rewards = tf.zeros([HPARAMS['num_docs_to_rank']])\n",
    "    policy_info = policy_utilities.PerArmPolicyInfo(\n",
    "        chosen_arm_features=arm_features,\n",
    "        # Pass dummy mean rewards here to match the model_spec for emitting\n",
    "        # mean rewards in policy info\n",
    "        predicted_rewards_mean=dummy_rewards\n",
    "    )\n",
    "    \n",
    "# tf_agents.policies.utils.create_chosen_arm_features_info_spec(\n",
    "#     observation_spec: tf_agents.typing.types.NestedTensorSpec\n",
    "# ) -> tf_agents.typing.types.NestedTensorSpec\n",
    "    \n",
    "    if HPARAMS['model_type'] == 'neural_ucb':\n",
    "        policy_info = policy_info._replace(\n",
    "            predicted_rewards_optimistic=dummy_rewards\n",
    "        )\n",
    "        \n",
    "    # print(f\"observation: {observation}\")\n",
    "    # print(f\"reward: {reward}\")\n",
    "    # print(f\"policy_info: {policy_info}\")\n",
    "    # print(f\"dummy_rewards: {dummy_rewards}\")\n",
    "    \n",
    "    return trajectory.single_step(\n",
    "        observation=observation,\n",
    "        action=tf.zeros_like(\n",
    "            reward, dtype=tf.int32\n",
    "        ),  # Arm features are copied from policy info, put dummy zeros here\n",
    "        policy_info=policy_info,\n",
    "        reward=reward,\n",
    "        discount=tf.zeros_like(reward)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e563b2ea-c44b-497b-bac4-e06d6bdaadad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in train_dataset.batch(2).take(1):\n",
    "#     single_traj = _trajectory_fn(x)\n",
    "    \n",
    "# single_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1970,
   "id": "7d931eef-f448-42d6-87ce-f24799cacdb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(Trajectory(\n",
       "{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(0, dtype=int32)),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(16,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(1, 16), dtype=tf.float32, name=None)}),\n",
       " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(1,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=TensorSpec(shape=(16,), dtype=tf.float32, name=None)),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 1970,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.policy.trajectory_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f35a8a-6e7f-4da4-8001-98349dfef6bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### replay buffers\n",
    "\n",
    "* Note that when the replay buffer object is initialized, it requires the `data_spec` of the elements that it will store. * This spec corresponds to the TensorSpec of trajectory elements that will be added to the buffer\n",
    "* This spec is usually acquired by looking at an agent's `agent.collect_data_spec` which defines the shapes, types, and structures expected by the agent when training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1797,
   "id": "0e4482e8-f681-409d-a0f6-d018813b21b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import reverb\n",
    "from tf_agents.replay_buffers import reverb_replay_buffer\n",
    "from tf_agents.replay_buffers import reverb_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1798,
   "id": "32ba8ed3-1fef-4912-b69c-9e9d81e185d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(Trajectory(\n",
       "{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32)),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(16,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(1, 16), dtype=tf.float32, name=None)}),\n",
       " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=TensorSpec(shape=(16,), dtype=tf.float32, name=None)),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 1798,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.collect_data_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1799,
   "id": "950cc38d-c904-413b-a838-fe558904caf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32)),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(16,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(1, 16), dtype=tf.float32, name=None)}),\n",
       " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=TensorSpec(shape=(16,), dtype=tf.float32, name=None)),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 1799,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replay_buffer_signature = tensor_spec.from_spec(\n",
    "#       agent.collect_data_spec\n",
    "# )\n",
    "# replay_buffer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1800,
   "id": "cdb33123-d5eb-41ce-abc9-342baa16ad10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'action': BoundedTensorSpec(shape=(None,), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32)),\n",
       " 'discount': BoundedTensorSpec(shape=(None,), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'next_step_type': TensorSpec(shape=(None,), dtype=tf.int32, name='step_type'),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(None, 16), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(None, 1, 16), dtype=tf.float32, name=None)}),\n",
       " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(None, 2), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=TensorSpec(shape=(None, 16), dtype=tf.float32, name=None)),\n",
       " 'reward': TensorSpec(shape=(None,), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(None,), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 1800,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replay_buffer_signature = tensor_spec.add_outer_dim(\n",
    "#       replay_buffer_signature\n",
    "# )\n",
    "# replay_buffer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1801,
   "id": "3df54f96-08ae-484a-89aa-e0c66646b51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[reverb/cc/platform/tfrecord_checkpointer.cc:162]  Initializing TFRecordCheckpointer in /var/tmp/tmp9ec1pvzn.\n",
      "[reverb/cc/platform/tfrecord_checkpointer.cc:567] Loading latest checkpoint from /var/tmp/tmp9ec1pvzn\n",
      "[reverb/cc/platform/default/server.cc:71] Started replay server on port 42605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_agents.replay_buffers.reverb_replay_buffer.ReverbReplayBuffer at 0x7f6d5c5894b0>"
      ]
     },
     "execution_count": 1801,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# table_name = 'uniform_table'\n",
    "# replay_buffer_capacity = 2000 # @param {type:\"integer\"}\n",
    "\n",
    "# table = reverb.Table(\n",
    "#     table_name,\n",
    "#     max_size=replay_buffer_capacity,\n",
    "#     sampler=reverb.selectors.Uniform(),\n",
    "#     remover=reverb.selectors.Fifo(),\n",
    "#     rate_limiter=reverb.rate_limiters.MinSize(1),\n",
    "#     signature=replay_buffer_signature\n",
    "# )\n",
    "# reverb_server = reverb.Server([table])\n",
    "\n",
    "# replay_buffer = reverb_replay_buffer.ReverbReplayBuffer(\n",
    "#     agent.collect_data_spec,\n",
    "#     table_name=table_name,\n",
    "#     sequence_length=None,\n",
    "#     local_server=reverb_server\n",
    "# )\n",
    "\n",
    "# rb_observer = reverb_utils.ReverbAddEpisodeObserver(\n",
    "#     replay_buffer.py_client,\n",
    "#     table_name,\n",
    "#     replay_buffer_capacity\n",
    "# )\n",
    "\n",
    "# replay_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1597,
   "id": "37a2138f-2c54-4e9c-86a2-fefd3e64ef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_iterations = 15                 # @param {type:\"integer\"}\n",
    "# collect_episodes_per_iteration = 2  # @param {type:\"integer\"}\n",
    "\n",
    "# fc_layer_params = (100,)\n",
    "\n",
    "# learning_rate = 1e-3   # @param {type:\"number\"}\n",
    "# log_interval = 25      # @param {type:\"integer\"}\n",
    "# num_eval_episodes = 10 # @param {type:\"integer\"}\n",
    "# eval_interval = 50     # @param {type:\"integer\"}\n",
    "\n",
    "# def collect_episode(\n",
    "#     environment, policy, num_episodes\n",
    "# ):    \n",
    "#     driver = py_driver.PyDriver(\n",
    "#         environment,\n",
    "#         py_tf_eager_policy.PyTFEagerPolicy(\n",
    "#             policy, \n",
    "#             use_tf_function=True\n",
    "#         ),\n",
    "#         [rb_observer],\n",
    "#         max_episodes=num_episodes\n",
    "#     )\n",
    "#     initial_time_step = environment.reset()\n",
    "#     driver.run(initial_time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1599,
   "id": "b9ea3d7e-406e-473d-a363-1c6f89c1a0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _ in range(num_iterations):\n",
    "    \n",
    "#     # Collect a few episodes using collect_policy and save to the replay buffer.\n",
    "#     collect_episode(\n",
    "#         train_py_env, tf_agent.collect_policy, collect_episodes_per_iteration\n",
    "#     )\n",
    "\n",
    "#     # Use data from the buffer and update the agent's network.\n",
    "#     iterator = iter(replay_buffer.as_dataset(sample_batch_size=1))\n",
    "    \n",
    "#     trajectories, _ = next(iterator)\n",
    "    \n",
    "#     train_loss = tf_agent.train(experience=trajectories)  \n",
    "\n",
    "#     replay_buffer.clear()\n",
    "\n",
    "#     step = tf_agent.train_step_counter.numpy()\n",
    "\n",
    "#     if step % log_interval == 0:\n",
    "#         print('step = {0}: loss = {1}'.format(step, train_loss.loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1600,
   "id": "1b25eb8f-14fe-4f7b-8a9e-4447c33abd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 32\n",
    "# max_length = 100\n",
    "\n",
    "# replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "#     data_spec,\n",
    "#     batch_size=batch_size,\n",
    "#     max_length=max_length\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77b011f-695c-433b-9bee-e62bf560746b",
   "metadata": {},
   "source": [
    "## train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1601,
   "id": "2c87762d-df4c-4d8f-82e5-c486eba5a79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tf_agents.utils import common\n",
    "\n",
    "# agent.initialize()\n",
    "\n",
    "# # (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "# agent.train = common.function(agent.train)\n",
    "\n",
    "# # Reset the train step\n",
    "# agent.train_step_counter.assign(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b6057c-2690-4530-a453-7984f456ab8c",
   "metadata": {},
   "source": [
    "`agent.train(experience=...)`\n",
    "\n",
    "where `experience` is a batch of trajectories data in the form of a Trajectory. \n",
    "* The structure of experience must match that of `self.training_data_spec`. \n",
    "* All tensors in experience must be shaped [batch, time, ...] where time must be equal to self.train_step_length if that property is not None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1942,
   "id": "a349ecc4-81aa-4067-9880-20cd25f661ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data spec:  Trajectory(\n",
      "{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(0, dtype=int32)),\n",
      " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
      " 'observation': DictWrapper({'global': TensorSpec(shape=(16,), dtype=tf.float32, name=None), 'num_actions': BoundedTensorSpec(shape=(), dtype=tf.int32, name=None, minimum=array(1, dtype=int32), maximum=array(1, dtype=int32))}),\n",
      " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(1,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=TensorSpec(shape=(16,), dtype=tf.float32, name=None)),\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n"
     ]
    }
   ],
   "source": [
    "print('training data spec: ', agent.training_data_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1946,
   "id": "f7670671-8205-4776-96fe-95464182f8b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'action': <tf.Tensor: shape=(8,), dtype=int32, numpy=array([0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
       " 'discount': <tf.Tensor: shape=(8,), dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " 'next_step_type': <tf.Tensor: shape=(8,), dtype=int32, numpy=array([2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
       " 'observation': {'global': <tf.Tensor: shape=(16,), dtype=float32, numpy=\n",
       "array([-0.02599   , -0.03078079,  0.03106076,  0.00133444,  0.02207417,\n",
       "       -0.02917665,  0.02782809, -0.02822751, -0.04523091,  0.0495333 ,\n",
       "       -0.01482558, -0.04208376,  0.00741076, -0.04264941,  0.00693322,\n",
       "       -0.03396516], dtype=float32)>},\n",
       " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=<tf.Tensor: shape=(8, 1), dtype=float32, numpy=\n",
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)>, multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=<tf.Tensor: shape=(16,), dtype=float32, numpy=\n",
       "array([-0.02780459, -0.00370889, -0.02864446, -0.02917221, -0.01603731,\n",
       "        0.02465415,  0.01583499, -0.03253644,  0.03956462,  0.04351255,\n",
       "        0.01470714,  0.04936441,  0.01360733, -0.0412104 ,  0.02928157,\n",
       "        0.01699198], dtype=float32)>),\n",
       " 'reward': <tf.Tensor: shape=(8,), dtype=float32, numpy=array([  4.,   4., -10.,  10.,   3.,   2.,  10.,  10.], dtype=float32)>,\n",
       " 'step_type': <tf.Tensor: shape=(8,), dtype=int32, numpy=array([0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>})"
      ]
     },
     "execution_count": 1946,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in train_dataset.batch(HPARAMS['batch_size']).take(1):\n",
    "    single_traj = _trajectory_fn(x)\n",
    "    \n",
    "single_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1743,
   "id": "d3bf9065-5b38-4213-9b2e-927ea397e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_traj.observation['global'].shape\n",
    "# <tf.Tensor: shape=(16,), dtype=float32, numpy=\n",
    "# array([-0.02599   , -0.03078079,  0.03106076,  0.00133444,  0.02207417,\n",
    "#        -0.02917665,  0.02782809, -0.02822751, -0.04523091,  0.0495333 ,\n",
    "#        -0.01482558, -0.04208376,  0.00741076, -0.04264941,  0.00693322,\n",
    "#        -0.03396516], dtype=float32)>\n",
    "\n",
    "# agent.training_data_spec.observation['global'].shape\n",
    "# >TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
    "\n",
    "# single_traj.policy_info.chosen_arm_features\n",
    "# <tf.Tensor: shape=(16,), dtype=float32, numpy=\n",
    "# array([-0.02780459, -0.00370889, -0.02864446, -0.02917221, -0.01603731,\n",
    "#         0.02465415,  0.01583499, -0.03253644,  0.03956462,  0.04351255,\n",
    "#         0.01470714,  0.04936441,  0.01360733, -0.0412104 ,  0.02928157,\n",
    "#         0.01699198], dtype=float32)>\n",
    "\n",
    "# agent.training_data_spec.policy_info.chosen_arm_features\n",
    "# TensorSpec(shape=(), dtype=tf.float32, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1914,
   "id": "b75574f5-0fa7-4d33-bc91-b1ea4671a021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(16,), dtype=tf.float32, name=None)"
      ]
     },
     "execution_count": 1914,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.training_data_spec.policy_info.chosen_arm_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1900,
   "id": "1103f98c-9547-4293-9010-499534e724d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16, 1), dtype=float32, numpy=\n",
       "array([[-0.02780459],\n",
       "       [-0.00370889],\n",
       "       [-0.02864446],\n",
       "       [-0.02917221],\n",
       "       [-0.01603731],\n",
       "       [ 0.02465415],\n",
       "       [ 0.01583499],\n",
       "       [-0.03253644],\n",
       "       [ 0.03956462],\n",
       "       [ 0.04351255],\n",
       "       [ 0.01470714],\n",
       "       [ 0.04936441],\n",
       "       [ 0.01360733],\n",
       "       [-0.0412104 ],\n",
       "       [ 0.02928157],\n",
       "       [ 0.01699198]], dtype=float32)>"
      ]
     },
     "execution_count": 1900,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # test_chosen = _add_outer_dimension(single_traj.policy_info.chosen_arm_features)\n",
    "# test_chosen = tf.expand_dims(tf.reshape(single_traj.policy_info.chosen_arm_features, [-1]), -1)\n",
    "# test_chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1917,
   "id": "8492d02c-f947-45a1-944d-6706422f79cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nest_utils.is_batched_nested_tensors(\n",
    "#     tensors=test_chosen,\n",
    "#     specs=agent.training_data_spec.policy_info.chosen_arm_features,\n",
    "#     num_outer_dims=1,\n",
    "#     allow_extra_fields=False,\n",
    "#     check_dtypes=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1920,
   "id": "c81ccd84-874d-4f4a-ab04-27ed58a35dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1920,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.utils import nest_utils\n",
    "\n",
    "nest_utils.is_batched_nested_tensors(\n",
    "    tensors=single_traj.policy_info.chosen_arm_features,\n",
    "    specs=agent.training_data_spec.policy_info.chosen_arm_features,\n",
    "    num_outer_dims=1,\n",
    "    allow_extra_fields=False,\n",
    "    check_dtypes=True\n",
    ")\n",
    "\n",
    "# nest_utils.is_batched_nested_tensors(\n",
    "#     tensors=single_traj.observation['global'],\n",
    "#     specs=agent.training_data_spec.observation['global'],\n",
    "#     num_outer_dims=0,\n",
    "#     allow_extra_fields=False,\n",
    "#     check_dtypes=True\n",
    "# )\n",
    "\n",
    "# nest_utils.is_batched_nested_tensors(\n",
    "#     tensors=single_traj.action,\n",
    "#     specs=agent.training_data_spec.action,\n",
    "#     num_outer_dims=1,\n",
    "#     allow_extra_fields=False,\n",
    "#     check_dtypes=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1947,
   "id": "90a2124c-7e7c-420e-88c2-5845a7b20e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print data: {'bucketized_user_age': <tf.Tensor: shape=(8,), dtype=float32, numpy=array([25., 45., 18., 25., 35., 45., 50., 25.], dtype=float32)>, 'movie_genres': <tf.Tensor: shape=(8, 1), dtype=int64, numpy=\n",
      "array([[4],\n",
      "       [7],\n",
      "       [7],\n",
      "       [1],\n",
      "       [0],\n",
      "       [4],\n",
      "       [7],\n",
      "       [0]])>, 'movie_id': <tf.Tensor: shape=(8,), dtype=string, numpy=\n",
      "array([b'211', b'678', b'135', b'97', b'568', b'150', b'483', b'121'],\n",
      "      dtype=object)>, 'timestamp': <tf.Tensor: shape=(8,), dtype=int64, numpy=\n",
      "array([874948475, 888638193, 887747108, 882475618, 875350485, 875946055,\n",
      "       879453933, 880149166])>, 'user_id': <tf.Tensor: shape=(8,), dtype=string, numpy=\n",
      "array([b'346', b'602', b'393', b'152', b'738', b'382', b'85', b'152'],\n",
      "      dtype=object)>, 'user_occupation_text': <tf.Tensor: shape=(8,), dtype=string, numpy=\n",
      "array([b'other', b'other', b'student', b'educator', b'technician',\n",
      "       b'engineer', b'educator', b'educator'], dtype=object)>, 'user_rating': <tf.Tensor: shape=(8,), dtype=float32, numpy=array([4., 4., 1., 5., 3., 2., 5., 5.], dtype=float32)>}\n",
      "print trajectories: Trajectory(\n",
      "{'action': <tf.Tensor: shape=(8,), dtype=int32, numpy=array([0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
      " 'discount': <tf.Tensor: shape=(8,), dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
      " 'next_step_type': <tf.Tensor: shape=(8,), dtype=int32, numpy=array([2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
      " 'observation': {'global': <tf.Tensor: shape=(16,), dtype=float32, numpy=\n",
      "array([-0.02599   , -0.03078079,  0.03106076,  0.00133444,  0.02207417,\n",
      "       -0.02917665,  0.02782809, -0.02822751, -0.04523091,  0.0495333 ,\n",
      "       -0.01482558, -0.04208376,  0.00741076, -0.04264941,  0.00693322,\n",
      "       -0.03396516], dtype=float32)>},\n",
      " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=<tf.Tensor: shape=(8, 1), dtype=float32, numpy=\n",
      "array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)>, multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=<tf.Tensor: shape=(16,), dtype=float32, numpy=\n",
      "array([-0.02780459, -0.00370889, -0.02864446, -0.02917221, -0.01603731,\n",
      "        0.02465415,  0.01583499, -0.03253644,  0.03956462,  0.04351255,\n",
      "        0.01470714,  0.04936441,  0.01360733, -0.0412104 ,  0.02928157,\n",
      "        0.01699198], dtype=float32)>),\n",
      " 'reward': <tf.Tensor: shape=(8,), dtype=float32, numpy=array([  4.,   4., -10.,  10.,   3.,   2.,  10.,  10.], dtype=float32)>,\n",
      " 'step_type': <tf.Tensor: shape=(8,), dtype=int32, numpy=array([0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>})\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tensors and specs do not have matching structures:\n  Trajectory(\n{'action': .,\n 'discount': .,\n 'next_step_type': .,\n 'observation': {'global': .},\n 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=., multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=.),\n 'reward': .,\n 'step_type': .})\nvs.\n  Trajectory(\n{'action': .,\n 'discount': .,\n 'next_step_type': .,\n 'observation': DictWrapper({'global': ., 'num_actions': .}),\n 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=., multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=.),\n 'reward': .,\n 'step_type': .})\nValues:\n  Trajectory(\n{'action': <tf.Tensor 'experience_2:0' shape=(8,) dtype=int32>,\n 'discount': <tf.Tensor 'experience_7:0' shape=(8,) dtype=float32>,\n 'next_step_type': <tf.Tensor 'experience_5:0' shape=(8,) dtype=int32>,\n 'observation': {'global': <tf.Tensor 'experience_1:0' shape=(16,) dtype=float32>},\n 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=<tf.Tensor 'experience_3:0' shape=(8, 1) dtype=float32>, multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=<tf.Tensor 'experience_4:0' shape=(16,) dtype=float32>),\n 'reward': <tf.Tensor 'experience_6:0' shape=(8,) dtype=float32>,\n 'step_type': <tf.Tensor 'experience:0' shape=(8,) dtype=int32>})\nvs.\n  Trajectory(\n{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(0, dtype=int32)),\n 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n 'observation': DictWrapper({'global': TensorSpec(shape=(16,), dtype=tf.float32, name=None), 'num_actions': BoundedTensorSpec(shape=(), dtype=tf.int32, name=None, minimum=array(1, dtype=int32), maximum=array(1, dtype=int32))}),\n 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(1,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=TensorSpec(shape=(16,), dtype=tf.float32, name=None)),\n 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1947], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# All tensors in experience must be shaped [batch, time, ...] \u001b[39;00m\n\u001b[1;32m     26\u001b[0m     step \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mtrain_step_counter\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m---> 28\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrajectories\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m#     for x in train_dataset.batch(1).take(1): #HPARAMS['batch_size']).take(1):\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#         # print(f\"print X: {len(x)}\")\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#         # break\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# train_outputs(agent.policy, train_loss)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_agents/agents/tf_agent.py:330\u001b[0m, in \u001b[0;36mTFAgent.train\u001b[0;34m(self, experience, weights, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    326\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find _train_fn.  Did \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.__init__ call super?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    327\u001b[0m       \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_functions:\n\u001b[0;32m--> 330\u001b[0m   loss_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m      \u001b[49m\u001b[43mexperience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperience\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m   loss_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train(experience\u001b[38;5;241m=\u001b[39mexperience, weights\u001b[38;5;241m=\u001b[39mweights, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_agents/utils/common.py:188\u001b[0m, in \u001b[0;36mfunction_in_tf1.<locals>.maybe_wrap.<locals>.with_check_resource_vars\u001b[0;34m(*fn_args, **fn_kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m check_tf1_allowed()\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_eager_been_enabled():\n\u001b[1;32m    186\u001b[0m   \u001b[38;5;66;03m# We're either in eager mode or in tf.function mode (no in-between); so\u001b[39;00m\n\u001b[1;32m    187\u001b[0m   \u001b[38;5;66;03m# autodep-like behavior is already expected of fn.\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m resource_variables_enabled():\n\u001b[1;32m    190\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(MISSING_RESOURCE_VARIABLES_ERROR)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_agents/bandits/agents/greedy_reward_prediction_agent.py:228\u001b[0m, in \u001b[0;36mGreedyRewardPredictionAgent._train\u001b[0;34m(self, experience, weights)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, experience, weights):\n\u001b[0;32m--> 228\u001b[0m   experience \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_as_trajectory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperience\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m    231\u001b[0m     loss_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss(experience, weights\u001b[38;5;241m=\u001b[39mweights, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_agents/agents/data_converter.py:340\u001b[0m, in \u001b[0;36mAsTrajectory.__call__\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput type not supported: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(value))\n\u001b[0;32m--> 340\u001b[0m \u001b[43m_validate_trajectory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrajectory_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43msequence_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sequence_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_outer_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outer_dims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m value \u001b[38;5;241m=\u001b[39m nest_utils\u001b[38;5;241m.\u001b[39mprune_extra_keys(\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_context\u001b[38;5;241m.\u001b[39mtrajectory_spec, value)\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_agents/agents/data_converter.py:174\u001b[0m, in \u001b[0;36m_validate_trajectory\u001b[0;34m(value, trajectory_spec, sequence_length, num_outer_dims)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_trajectory\u001b[39m(\n\u001b[1;32m    169\u001b[0m     value: trajectory\u001b[38;5;241m.\u001b[39mTrajectory,\n\u001b[1;32m    170\u001b[0m     trajectory_spec: trajectory\u001b[38;5;241m.\u001b[39mTrajectory,\n\u001b[1;32m    171\u001b[0m     sequence_length: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m    172\u001b[0m     num_outer_dims: te\u001b[38;5;241m.\u001b[39mLiteral[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=bad-whitespace\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Validate a Trajectory given its spec and a sequence length.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mnest_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_batched_nested_tensors\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrajectory_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outer_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outer_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m      \u001b[49m\u001b[43mallow_extra_fields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m:\n\u001b[1;32m    177\u001b[0m     debug_str_1 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m tp: tp\u001b[38;5;241m.\u001b[39mshape, value)\n\u001b[1;32m    178\u001b[0m     debug_str_2 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m spec: spec\u001b[38;5;241m.\u001b[39mshape, trajectory_spec)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_agents/utils/nest_utils.py:468\u001b[0m, in \u001b[0;36mis_batched_nested_tensors\u001b[0;34m(tensors, specs, num_outer_dims, allow_extra_fields, check_dtypes)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_extra_fields:\n\u001b[1;32m    466\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m prune_extra_keys(specs, tensors)\n\u001b[0;32m--> 468\u001b[0m \u001b[43massert_same_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspecs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTensors and specs do not have matching structures\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m flat_tensors \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mflatten(tensors)\n\u001b[1;32m    473\u001b[0m flat_specs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(specs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_agents/utils/nest_utils.py:124\u001b[0m, in \u001b[0;36massert_same_structure\u001b[0;34m(nest1, nest2, check_types, expand_composites, allow_shallow_nest1, message)\u001b[0m\n\u001b[1;32m    120\u001b[0m str1 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m _: _DOT, nest1, expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n\u001b[1;32m    122\u001b[0m str2 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m _: _DOT, nest2, expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mvs.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mValues:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mvs.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    125\u001b[0m                 \u001b[38;5;241m.\u001b[39mformat(message, str1, str2, nest1, nest2))\n",
      "\u001b[0;31mValueError\u001b[0m: Tensors and specs do not have matching structures:\n  Trajectory(\n{'action': .,\n 'discount': .,\n 'next_step_type': .,\n 'observation': {'global': .},\n 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=., multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=.),\n 'reward': .,\n 'step_type': .})\nvs.\n  Trajectory(\n{'action': .,\n 'discount': .,\n 'next_step_type': .,\n 'observation': DictWrapper({'global': ., 'num_actions': .}),\n 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=., multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=.),\n 'reward': .,\n 'step_type': .})\nValues:\n  Trajectory(\n{'action': <tf.Tensor 'experience_2:0' shape=(8,) dtype=int32>,\n 'discount': <tf.Tensor 'experience_7:0' shape=(8,) dtype=float32>,\n 'next_step_type': <tf.Tensor 'experience_5:0' shape=(8,) dtype=int32>,\n 'observation': {'global': <tf.Tensor 'experience_1:0' shape=(16,) dtype=float32>},\n 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=<tf.Tensor 'experience_3:0' shape=(8, 1) dtype=float32>, multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=<tf.Tensor 'experience_4:0' shape=(16,) dtype=float32>),\n 'reward': <tf.Tensor 'experience_6:0' shape=(8,) dtype=float32>,\n 'step_type': <tf.Tensor 'experience:0' shape=(8,) dtype=int32>})\nvs.\n  Trajectory(\n{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(0, dtype=int32)),\n 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n 'observation': DictWrapper({'global': TensorSpec(shape=(16,), dtype=tf.float32, name=None), 'num_actions': BoundedTensorSpec(shape=(), dtype=tf.int32, name=None, minimum=array(1, dtype=int32), maximum=array(1, dtype=int32))}),\n 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(1,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=TensorSpec(shape=(16,), dtype=tf.float32, name=None)),\n 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})."
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from tf_agents.utils import common\n",
    "\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "# global_step = tf.compat.v1.train.get_global_step()\n",
    "\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "agent.train = common.function(agent.train)\n",
    "\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "train_loss = collections.defaultdict(list)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    iterator = iter(train_dataset.batch(HPARAMS['batch_size']))\n",
    "    data = next(iterator)\n",
    "    print(f\"print data: {data}\")\n",
    "    \n",
    "    trajectories = _trajectory_fn(data)\n",
    "    print(f\"print trajectories: {trajectories}\")\n",
    "    \n",
    "    # All tensors in experience must be shaped [batch, time, ...] \n",
    "    step = agent.train_step_counter.numpy()\n",
    "    \n",
    "    loss = agent.train(experience=trajectories)\n",
    "    \n",
    "    break\n",
    "    \n",
    "#     for x in train_dataset.batch(1).take(1): #HPARAMS['batch_size']).take(1):\n",
    "#         # print(f\"print X: {len(x)}\")\n",
    "#         # break\n",
    "#         step = agent.train_step_counter.numpy()\n",
    "#         print(f\"step X: {step}\")\n",
    "#         trajectories = _trajectory_fn(x)\n",
    "#         # print(f\"print trajectories: {trajectories}\")\n",
    "#         # break\n",
    "    \n",
    "#         loss = agent.train(experience=trajectories)\n",
    "\n",
    "#         train_loss[f\"epoch:{epoch + 1}\"].append(loss.numpy())\n",
    "    \n",
    "# train_outputs = collections.namedtuple(\n",
    "#     \"TrainOutputs\",[\"policy\", \"train_loss\"]\n",
    "# )\n",
    "\n",
    "# train_outputs(agent.policy, train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1395,
   "id": "cfdb8771-4b75-4632-873b-b07b0d71959e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'action': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 0], dtype=int32)>,\n",
       " 'discount': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 0.], dtype=float32)>,\n",
       " 'next_step_type': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 2], dtype=int32)>,\n",
       " 'observation': {'global': <tf.Tensor: shape=(16, 1), dtype=float32, numpy=\n",
       "array([[-0.02599   ],\n",
       "       [-0.03078079],\n",
       "       [ 0.03106076],\n",
       "       [ 0.00133444],\n",
       "       [ 0.02207417],\n",
       "       [-0.02917665],\n",
       "       [ 0.02782809],\n",
       "       [-0.02822751],\n",
       "       [-0.04523091],\n",
       "       [ 0.0495333 ],\n",
       "       [-0.01482558],\n",
       "       [-0.04208376],\n",
       "       [ 0.00741076],\n",
       "       [-0.04264941],\n",
       "       [ 0.00693322],\n",
       "       [-0.03396516]], dtype=float32)>},\n",
       " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>, multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=<tf.Tensor: shape=(16,), dtype=float32, numpy=\n",
       "array([-0.02780459, -0.00370889, -0.02864446, -0.02917221, -0.01603731,\n",
       "        0.02465415,  0.01583499, -0.03253644,  0.03956462,  0.04351255,\n",
       "        0.01470714,  0.04936441,  0.01360733, -0.0412104 ,  0.02928157,\n",
       "        0.01699198], dtype=float32)>),\n",
       " 'reward': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([4., 4.], dtype=float32)>,\n",
       " 'step_type': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 0], dtype=int32)>})"
      ]
     },
     "execution_count": 1395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1501,
   "id": "77efee76-7c6b-4911-b1b9-165f68029adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents import trajectories\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "def get_trajectory_from_environment(element): # hparams\n",
    "    \"\"\"Converts a dataset element into a trajectory.\"\"\"\n",
    "    \n",
    "    orig_trajectory = agent.policy.trajectory_spec\n",
    "    # print(f\"orig_trajectory.step_type: {orig_trajectory.step_type}\")\n",
    "    # print(f\"orig_trajectory.next_step_type: {orig_trajectory.next_step_type}\")\n",
    "    \n",
    "    global_features = _get_global_context_features(element)\n",
    "    arm_features = _get_per_arm_features(element)\n",
    "    \n",
    "    # Adds a time dimension.\n",
    "    # arm_features = _add_outer_dimension(arm_features)\n",
    "    observation = {\n",
    "        bandit_spec_utils.GLOBAL_FEATURE_KEY:\n",
    "            global_features,\n",
    "            # _add_outer_dimension(global_features)\n",
    "        # bandit_spec_utils.PER_ARM_FEATURE_KEY:\n",
    "        #     _add_outer_dimension(arm_features),\n",
    "    }\n",
    "    \n",
    "    # reward = _add_outer_dimension(_get_rewards(element))\n",
    "    reward = _get_rewards(element)\n",
    "    # print(f\"reward:  {reward}\")\n",
    "    # print(f\"reward shape:  {tf.shape(reward).numpy()}\")\n",
    "    \n",
    "    reward_2 = tf.expand_dims(reward, 0)\n",
    "    # print(f\"reward_2:  {reward_2}\")\n",
    "    # print(f\"reward_2 shape:  {tf.shape(reward_2).numpy()}\")\n",
    "    \n",
    "    \n",
    "    dummy_rewards = tf.zeros([HPARAMS['num_docs_to_rank']])\n",
    "    policy_info = policy_utilities.PerArmPolicyInfo(\n",
    "        chosen_arm_features=arm_features,\n",
    "        predicted_rewards_mean=dummy_rewards\n",
    "    )\n",
    "    if HPARAMS['model_type'] == 'neural_ucb':\n",
    "        policy_info = policy_info._replace(\n",
    "            predicted_rewards_optimistic=dummy_rewards\n",
    "        )\n",
    "        \n",
    "    # observation\n",
    "    obs = observation['global']\n",
    "    # print(f\"obs:  {obs}\")\n",
    "    # print(f\"obs shape:  {tf.shape(obs).numpy()}\")\n",
    "    \n",
    "    obs_2 = tf.expand_dims(obs, 0)\n",
    "    # print(f\"obs_2:  {obs_2}\")\n",
    "    # print(f\"obs_2 shape:  {tf.shape(obs_2).numpy()}\")\n",
    "    \n",
    "    return trajectory.Trajectory(\n",
    "        observation=obs_2,\n",
    "        action=tf.zeros_like(\n",
    "            reward_2, dtype=tf.int32\n",
    "        ),  # Arm features are copied from policy info, put dummy zeros here\n",
    "        policy_info=policy_info,\n",
    "        reward=reward_2,\n",
    "        discount=tf.zeros_like(reward_2),\n",
    "        step_type=orig_trajectory.step_type,\n",
    "        next_step_type=orig_trajectory.next_step_type\n",
    "    )\n",
    "\n",
    "def build_dict_from_trajectory(\n",
    "    step: int,\n",
    "    next_step: int,\n",
    "    trajectory: trajectories.Trajectory) -> Dict[str, Any]:\n",
    "    \"\"\"Builds a dict from `trajectory` data.\n",
    "\n",
    "    Args:\n",
    "    trajectory: A `trajectories.Trajectory` object.\n",
    "\n",
    "    Returns:\n",
    "    A dict holding the same data as `trajectory`.\n",
    "    \"\"\"\n",
    "    trajectory_dict = {\n",
    "        \"step_type\": [step].numpy(),\n",
    "        \"observation\": [{\n",
    "            \"observation_batch\": batch\n",
    "        } for batch in trajectory.observation.numpy().tolist()],\n",
    "        \"action\": trajectory.action.numpy().tolist(),\n",
    "        \"policy_info\": trajectory.policy_info,\n",
    "        \"next_step_type\": [next_step],\n",
    "        \"reward\": trajectory.reward.numpy().tolist(),\n",
    "        \"discount\": trajectory.discount.numpy().tolist(),\n",
    "    }\n",
    "    return trajectory_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1511,
   "id": "47ec38ec-b5f8-4d6c-b413-f9470fe8140a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5]"
      ]
     },
     "execution_count": 1511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step=5\n",
    "\n",
    "[step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1516,
   "id": "7b20f4ec-09ad-4037-ae74-aee98b85f6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tf_agents.trajectories' from '/opt/conda/lib/python3.10/site-packages/tf_agents/trajectories/__init__.py'>"
      ]
     },
     "execution_count": 1516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories#.reward.numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1512,
   "id": "ad148f57-8156-49b2-a5a4-1ce360d540b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tf_agents.trajectories.trajectory' from '/opt/conda/lib/python3.10/site-packages/tf_agents/trajectories/trajectory.py'>"
      ]
     },
     "execution_count": 1512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1488,
   "id": "1c8156e2-15bf-413f-a25a-abc0bf60ecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 'v1'\n",
    "\n",
    "DATASET_FILE = f'{VERSION}-off-policy-trajectories.json'\n",
    "!touch $DATASET_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1491,
   "id": "12bce6a7-02cb-44bc-a3ba-3652e7cbe018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_size: 20000\n",
      "small_count: 200.0\n"
     ]
    }
   ],
   "source": [
    "dataset_size = len(list(train_dataset))\n",
    "print(f\"dataset_size: {dataset_size}\")\n",
    "\n",
    "small_count = dataset_size/100\n",
    "print(f\"small_count: {small_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1580,
   "id": "2853014b-613f-4b9a-a6a8-31567f5c3efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "def write_trajectories_to_file(\n",
    "    dataset_size: int,\n",
    "    data_file: str,\n",
    "    batch_size: int,\n",
    "):\n",
    "    batched_dataset = train_dataset.batch(batch_size)\n",
    "    print(f\"writting file...\")\n",
    "    \n",
    "    data_list = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    step = 1\n",
    "    with open(data_file, \"w\") as f:\n",
    "        for x in batched_dataset.take(count=dataset_size):\n",
    "            # print(f\"step: {step}\")\n",
    "            nexx_step = step + 1\n",
    "            # print(f\"nexx_step: {nexx_step}\")\n",
    "\n",
    "            single_traj = get_trajectory_from_environment(x)\n",
    "            print(single_traj)\n",
    "            \n",
    "            _trajectory_dict = build_dict_from_trajectory(step=step, next_step=nexx_step, trajectory=single_traj)\n",
    "            # print(type(trajectory_dict))\n",
    "            decoded = _trajectory_dict.decode('utf-8')\n",
    "            print(f\"decoded: {decoded}\")\n",
    "            data_list.append(_trajectory_dict)\n",
    "\n",
    "            step+=1\n",
    "            \n",
    "            break\n",
    "            \n",
    "        for entry in data_list:\n",
    "            traj_dict_tmp = {}\n",
    "            traj_dict_tmp['step_type'] = entry['step_type']\n",
    "            traj_dict_tmp['observation'] = entry['observation']\n",
    "            traj_dict_tmp['action'] = entry['action']\n",
    "            traj_dict_tmp['policy_info'] = entry['policy_info']\n",
    "            traj_dict_tmp['next_step_type'] = entry['next_step_type']\n",
    "            traj_dict_tmp['reward'] = entry['reward']\n",
    "            traj_dict_tmp['discount'] = entry['discount']\n",
    "            \n",
    "            # f.write(json.dumps(traj_dict_tmp) + \"\\n\")\n",
    "            \n",
    "        print(f\"writting to file complete...\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    runtime_mins = int((end_time - start_time) / 60)\n",
    "    print(f\"runtime_mins: {runtime_mins}\")\n",
    "\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1581,
   "id": "d1fd03bf-6fb3-4da7-82c7-99cf394d077d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writting file...\n",
      "Trajectory(\n",
      "{'action': <tf.Tensor: shape=(1, 2), dtype=int32, numpy=array([[0, 0]], dtype=int32)>,\n",
      " 'discount': <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0., 0.]], dtype=float32)>,\n",
      " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
      " 'observation': <tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n",
      "array([[-0.02599   , -0.03078079,  0.03106076,  0.00133444,  0.02207417,\n",
      "        -0.02917665,  0.02782809, -0.02822751, -0.04523091,  0.0495333 ,\n",
      "        -0.01482558, -0.04208376,  0.00741076, -0.04264941,  0.00693322,\n",
      "        -0.03396516]], dtype=float32)>,\n",
      " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>, multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=array([-0.02780459, -0.00370889, -0.02864446, -0.02917221, -0.01603731,\n",
      "        0.02465415,  0.01583499, -0.03253644,  0.03956462,  0.04351255,\n",
      "        0.01470714,  0.04936441,  0.01360733, -0.0412104 ,  0.02928157,\n",
      "        0.01699198], dtype=float32)),\n",
      " 'reward': <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[4., 4.]], dtype=float32)>,\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1581], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sample_data_list \u001b[38;5;241m=\u001b[39m \u001b[43mwrite_trajectories_to_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msmall_count\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDATASET_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m sample_data_list[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[1580], line 27\u001b[0m, in \u001b[0;36mwrite_trajectories_to_file\u001b[0;34m(dataset_size, data_file, batch_size)\u001b[0m\n\u001b[1;32m     25\u001b[0m _trajectory_dict \u001b[38;5;241m=\u001b[39m build_dict_from_trajectory(step\u001b[38;5;241m=\u001b[39mstep, next_step\u001b[38;5;241m=\u001b[39mnexx_step, trajectory\u001b[38;5;241m=\u001b[39msingle_traj)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# print(type(trajectory_dict))\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m decoded \u001b[38;5;241m=\u001b[39m \u001b[43m_trajectory_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoded: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdecoded\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m data_list\u001b[38;5;241m.\u001b[39mappend(_trajectory_dict)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "sample_data_list = write_trajectories_to_file(\n",
    "    dataset_size=int(small_count),\n",
    "    data_file=DATASET_FILE,\n",
    "    batch_size=2\n",
    ")\n",
    "\n",
    "sample_data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1575,
   "id": "48a01e65-0ba3-4ea1-b011-bb80581ae351",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 1575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for entry in _trajectory_dict:\n",
    "#     print(type(entry))\n",
    "#     print(entry)\n",
    "\n",
    "for entry in sample_data_list:\n",
    "    traj_dict_tmp = {}\n",
    "    traj_dict_tmp['step_type'] = entry['step_type']\n",
    "    # print(f\"traj_dict_tmp: {traj_dict_tmp}\")\n",
    "    \n",
    "    traj_dict_tmp['observation'] = entry['observation']\n",
    "    # print(f\"traj_dict_tmp: {traj_dict_tmp}\")\n",
    "    \n",
    "    traj_dict_tmp['action'] = entry['action']\n",
    "    traj_dict_tmp['policy_info'] = entry['policy_info']\n",
    "    traj_dict_tmp['next_step_type'] = entry['next_step_type']\n",
    "    traj_dict_tmp['reward'] = entry['reward']\n",
    "    traj_dict_tmp['discount'] = entry['discount']\n",
    "    \n",
    "type(traj_dict_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1571,
   "id": "191dbd66-d61f-4055-8d41-9a56f20d6fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'step_type': [10],\n",
       " 'observation': [{'observation_batch': [0.01847800239920616,\n",
       "    0.02198561653494835,\n",
       "    0.014523360878229141,\n",
       "    0.030534852296113968,\n",
       "    -0.042274583131074905,\n",
       "    0.042358625680208206,\n",
       "    -0.03376084566116333,\n",
       "    -0.02007082663476467,\n",
       "    -0.034898411482572556,\n",
       "    -0.0003517270088195801,\n",
       "    0.044689346104860306,\n",
       "    0.03770342841744423,\n",
       "    0.047657739371061325,\n",
       "    -0.0015833377838134766,\n",
       "    0.010477341711521149,\n",
       "    0.044041361659765244]}],\n",
       " 'action': [[0, 0]],\n",
       " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>, multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=array([-0.03809992, -0.03608539,  0.03337479,  0.02976027,  0.02404537,\n",
       "         0.02131835, -0.03314126, -0.03678827,  0.04321641, -0.03485628,\n",
       "         0.02968835,  0.00450085, -0.01462041,  0.04984425, -0.00887213,\n",
       "        -0.04515211], dtype=float32)),\n",
       " 'next_step_type': [11],\n",
       " 'reward': [[4.0, 10.0]],\n",
       " 'discount': [[0.0, 0.0]]}"
      ]
     },
     "execution_count": 1571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_dict_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1577,
   "id": "3b6f1598-be46-4398-9eec-32e609b7dc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(DATASET_FILE, \"w\") as f:\n",
    "#     f.write(json.dump(traj_dict_tmp, f) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1557,
   "id": "8c850d51-eb5b-4cdf-9f5b-bd0853a39c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'observation_batch': [-0.025989998131990433,\n",
       "   -0.030780792236328125,\n",
       "   0.031060758978128433,\n",
       "   0.0013344399631023407,\n",
       "   0.02207416668534279,\n",
       "   -0.029176652431488037,\n",
       "   0.02782808616757393,\n",
       "   -0.028227508068084717,\n",
       "   -0.045230913907289505,\n",
       "   0.04953329637646675,\n",
       "   -0.014825582504272461,\n",
       "   -0.04208376258611679,\n",
       "   0.007410764694213867,\n",
       "   -0.042649414390325546,\n",
       "   0.006933223456144333,\n",
       "   -0.033965159207582474]}]"
      ]
     },
     "execution_count": 1557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data_list[0]['observation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1553,
   "id": "0205d198-cff8-461c-935e-eaaf79034e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step_type\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'step_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1553], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m sample_data_list[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(entry) \u001b[38;5;66;03m#['observation']\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mentry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_type\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'step_type'"
     ]
    }
   ],
   "source": [
    "# sample_data_list[0]['step_type']\n",
    "for entry in sample_data_list[0]:\n",
    "    print(entry) #['observation']\n",
    "    print(entry.step_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b129a381-c108-4a37-9914-6a8b79db7d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_utils.upload_blob(\n",
    "    bucket_name='two-tower-models',\n",
    "    source_file_name=CANDIDATE_EMB_JSON,\n",
    "    destination_blob_name=f'{RUN_NAME}/candidates/candidate_embeddings.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1498,
   "id": "766414fb-30aa-4c16-a8d4-66ee79a8be3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([25., 45.], dtype=float32)>, 'movie_genres': <tf.Tensor: shape=(2, 1), dtype=int64, numpy=\n",
      "array([[4],\n",
      "       [7]])>, 'movie_id': <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'211', b'678'], dtype=object)>, 'timestamp': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([874948475, 888638193])>, 'user_id': <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'346', b'602'], dtype=object)>, 'user_occupation_text': <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'other', b'other'], dtype=object)>, 'user_rating': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([4., 4.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "batched_dataset = train_dataset.batch(2)\n",
    "\n",
    "for example in batched_dataset.take(count=10):\n",
    "    print(example)\n",
    "    # print(example[0])\n",
    "    break\n",
    "    # traj_dict = build_dict_from_trajectory(example[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1420,
   "id": "3f2df15f-6746-4ef4-b93f-b35c89bba2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: 16\n",
      "[16  1]\n",
      "thingy: [[[-0.02599   ]\n",
      "  [-0.03078079]\n",
      "  [ 0.03106076]\n",
      "  [ 0.00133444]\n",
      "  [ 0.02207417]\n",
      "  [-0.02917665]\n",
      "  [ 0.02782809]\n",
      "  [-0.02822751]\n",
      "  [-0.04523091]\n",
      "  [ 0.0495333 ]\n",
      "  [-0.01482558]\n",
      "  [-0.04208376]\n",
      "  [ 0.00741076]\n",
      "  [-0.04264941]\n",
      "  [ 0.00693322]\n",
      "  [-0.03396516]]]\n",
      "[ 1 16  1]\n"
     ]
    }
   ],
   "source": [
    "# len(thing['global'].numpy().tolist())\n",
    "test = thing['global'].numpy().tolist()\n",
    "print(f\"test: {len(test)}\")\n",
    "print(tf.shape(test).numpy())\n",
    "\n",
    "thingy = tf.expand_dims(test, axis=0)\n",
    "print(f\"thingy: {thingy}\")\n",
    "print(tf.shape(thingy).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1422,
   "id": "a529c4c0-9960-42ae-9f46-5609811932d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 3]\n",
      "[2 3 2]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[[ 1,  2,  3],\n",
    "                  [ 4,  5,  6]],\n",
    "                 [[ 7,  8,  9],\n",
    "                  [10, 11, 12]]])\n",
    "print(tf.shape(x).numpy())\n",
    "\n",
    "y = tf.transpose(x, perm=[0, 2, 1])\n",
    "print(tf.shape(y).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "6728f217-d1b1-4a96-b832-b63474f03380",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: [[  4.]\n",
      " [  4.]\n",
      " [-10.]\n",
      " [ 10.]\n",
      " [  3.]\n",
      " [  2.]\n",
      " [ 10.]\n",
      " [ 10.]]\n",
      "dummy_rewards: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "Trajectory(\n",
      "{'action': <tf.Tensor: shape=(8, 1), dtype=int32, numpy=\n",
      "array([[0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0]], dtype=int32)>,\n",
      " 'discount': <tf.Tensor: shape=(8, 1), dtype=float32, numpy=\n",
      "array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)>,\n",
      " 'next_step_type': <tf.Tensor: shape=(8, 1), dtype=int32, numpy=\n",
      "array([[2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2]], dtype=int32)>,\n",
      " 'observation': {'global': <tf.Tensor: shape=(16, 1), dtype=float32, numpy=\n",
      "array([[-0.02599   ],\n",
      "       [-0.03078079],\n",
      "       [ 0.03106076],\n",
      "       [ 0.00133444],\n",
      "       [ 0.02207417],\n",
      "       [-0.02917665],\n",
      "       [ 0.02782809],\n",
      "       [-0.02822751],\n",
      "       [-0.04523091],\n",
      "       [ 0.0495333 ],\n",
      "       [-0.01482558],\n",
      "       [-0.04208376],\n",
      "       [ 0.00741076],\n",
      "       [-0.04264941],\n",
      "       [ 0.00693322],\n",
      "       [-0.03396516]], dtype=float32)>},\n",
      " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=<tf.Tensor: shape=(8, 3), dtype=float32, numpy=\n",
      "array([[0., 0., 0.],\n",
      "       [0., 0., 0.],\n",
      "       [0., 0., 0.],\n",
      "       [0., 0., 0.],\n",
      "       [0., 0., 0.],\n",
      "       [0., 0., 0.],\n",
      "       [0., 0., 0.],\n",
      "       [0., 0., 0.]], dtype=float32)>, multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=<tf.Tensor: shape=(16, 1), dtype=float32, numpy=\n",
      "array([[-0.02780459],\n",
      "       [-0.00370889],\n",
      "       [-0.02864446],\n",
      "       [-0.02917221],\n",
      "       [-0.01603731],\n",
      "       [ 0.02465415],\n",
      "       [ 0.01583499],\n",
      "       [-0.03253644],\n",
      "       [ 0.03956462],\n",
      "       [ 0.04351255],\n",
      "       [ 0.01470714],\n",
      "       [ 0.04936441],\n",
      "       [ 0.01360733],\n",
      "       [-0.0412104 ],\n",
      "       [ 0.02928157],\n",
      "       [ 0.01699198]], dtype=float32)>),\n",
      " 'reward': <tf.Tensor: shape=(8, 1), dtype=float32, numpy=\n",
      "array([[  4.],\n",
      "       [  4.],\n",
      "       [-10.],\n",
      "       [ 10.],\n",
      "       [  3.],\n",
      "       [  2.],\n",
      "       [ 10.],\n",
      "       [ 10.]], dtype=float32)>,\n",
      " 'step_type': <tf.Tensor: shape=(8, 1), dtype=int32, numpy=\n",
      "array([[0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0]], dtype=int32)>})\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Received a mix of batched and unbatched Tensors, or Tensors are not compatible with Specs.  num_outer_dims: 2.\nSaw tensor_shapes:\n   Trajectory(\n{'action': TensorShape([8, 1]),\n 'discount': TensorShape([8, 1]),\n 'next_step_type': TensorShape([8, 1]),\n 'observation': DictWrapper({'global': TensorShape([16, 1])}),\n 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorShape([8, 3]), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=TensorShape([16, 1])),\n 'reward': TensorShape([8, 1]),\n 'step_type': TensorShape([8, 1])})\nAnd spec_shapes:\n   Trajectory(\n{'action': TensorShape([]),\n 'discount': TensorShape([]),\n 'next_step_type': TensorShape([]),\n 'observation': DictWrapper({'global': TensorShape([16])}),\n 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorShape([3]), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=TensorShape([16])),\n 'reward': TensorShape([]),\n 'step_type': TensorShape([])})",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[424], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m         trajectory \u001b[38;5;241m=\u001b[39m _trajectory_fn(parsed_record, HPARAMS)\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28mprint\u001b[39m(trajectory)\n\u001b[0;32m---> 11\u001b[0m         loss, _ \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrajectory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m         train_loss[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     14\u001b[0m train_outputs \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mnamedtuple(\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainOutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m,[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     16\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_agents/agents/tf_agent.py:330\u001b[0m, in \u001b[0;36mTFAgent.train\u001b[0;34m(self, experience, weights, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    326\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find _train_fn.  Did \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.__init__ call super?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    327\u001b[0m       \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_functions:\n\u001b[0;32m--> 330\u001b[0m   loss_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m      \u001b[49m\u001b[43mexperience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperience\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m   loss_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train(experience\u001b[38;5;241m=\u001b[39mexperience, weights\u001b[38;5;241m=\u001b[39mweights, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_agents/utils/common.py:188\u001b[0m, in \u001b[0;36mfunction_in_tf1.<locals>.maybe_wrap.<locals>.with_check_resource_vars\u001b[0;34m(*fn_args, **fn_kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m check_tf1_allowed()\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_eager_been_enabled():\n\u001b[1;32m    186\u001b[0m   \u001b[38;5;66;03m# We're either in eager mode or in tf.function mode (no in-between); so\u001b[39;00m\n\u001b[1;32m    187\u001b[0m   \u001b[38;5;66;03m# autodep-like behavior is already expected of fn.\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m resource_variables_enabled():\n\u001b[1;32m    190\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(MISSING_RESOURCE_VARIABLES_ERROR)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_agents/bandits/agents/greedy_reward_prediction_agent.py:228\u001b[0m, in \u001b[0;36mGreedyRewardPredictionAgent._train\u001b[0;34m(self, experience, weights)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, experience, weights):\n\u001b[0;32m--> 228\u001b[0m   experience \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_as_trajectory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperience\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m    231\u001b[0m     loss_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss(experience, weights\u001b[38;5;241m=\u001b[39mweights, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_agents/agents/data_converter.py:340\u001b[0m, in \u001b[0;36mAsTrajectory.__call__\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput type not supported: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(value))\n\u001b[0;32m--> 340\u001b[0m \u001b[43m_validate_trajectory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrajectory_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43msequence_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sequence_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_outer_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outer_dims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m value \u001b[38;5;241m=\u001b[39m nest_utils\u001b[38;5;241m.\u001b[39mprune_extra_keys(\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_context\u001b[38;5;241m.\u001b[39mtrajectory_spec, value)\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_agents/agents/data_converter.py:174\u001b[0m, in \u001b[0;36m_validate_trajectory\u001b[0;34m(value, trajectory_spec, sequence_length, num_outer_dims)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_trajectory\u001b[39m(\n\u001b[1;32m    169\u001b[0m     value: trajectory\u001b[38;5;241m.\u001b[39mTrajectory,\n\u001b[1;32m    170\u001b[0m     trajectory_spec: trajectory\u001b[38;5;241m.\u001b[39mTrajectory,\n\u001b[1;32m    171\u001b[0m     sequence_length: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m    172\u001b[0m     num_outer_dims: te\u001b[38;5;241m.\u001b[39mLiteral[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=bad-whitespace\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Validate a Trajectory given its spec and a sequence length.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mnest_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_batched_nested_tensors\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrajectory_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outer_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outer_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m      \u001b[49m\u001b[43mallow_extra_fields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m:\n\u001b[1;32m    177\u001b[0m     debug_str_1 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m tp: tp\u001b[38;5;241m.\u001b[39mshape, value)\n\u001b[1;32m    178\u001b[0m     debug_str_2 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m spec: spec\u001b[38;5;241m.\u001b[39mshape, trajectory_spec)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_agents/utils/nest_utils.py:546\u001b[0m, in \u001b[0;36mis_batched_nested_tensors\u001b[0;34m(tensors, specs, num_outer_dims, allow_extra_fields, check_dtypes)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    542\u001b[0m     discrepancy \u001b[38;5;241m==\u001b[39m tensor_ndims_discrepancy[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    543\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m discrepancy \u001b[38;5;129;01min\u001b[39;00m tensor_ndims_discrepancy) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(tensor_matches_spec):\n\u001b[1;32m    544\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 546\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReceived a mix of batched and unbatched Tensors, or Tensors\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m are not compatible with Specs.  num_outer_dims: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSaw tensor_shapes:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m   \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnd spec_shapes:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m   \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    551\u001b[0m     (num_outer_dims, tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mpack_sequence_as(specs, tensor_shapes),\n\u001b[1;32m    552\u001b[0m      tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mpack_sequence_as(specs, spec_shapes)))\n",
      "\u001b[0;31mValueError\u001b[0m: Received a mix of batched and unbatched Tensors, or Tensors are not compatible with Specs.  num_outer_dims: 2.\nSaw tensor_shapes:\n   Trajectory(\n{'action': TensorShape([8, 1]),\n 'discount': TensorShape([8, 1]),\n 'next_step_type': TensorShape([8, 1]),\n 'observation': DictWrapper({'global': TensorShape([16, 1])}),\n 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorShape([8, 3]), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=TensorShape([16, 1])),\n 'reward': TensorShape([8, 1]),\n 'step_type': TensorShape([8, 1])})\nAnd spec_shapes:\n   Trajectory(\n{'action': TensorShape([]),\n 'discount': TensorShape([]),\n 'next_step_type': TensorShape([]),\n 'observation': DictWrapper({'global': TensorShape([16])}),\n 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorShape([3]), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=TensorShape([16])),\n 'reward': TensorShape([]),\n 'step_type': TensorShape([])})"
     ]
    }
   ],
   "source": [
    "# import collections\n",
    "\n",
    "# NUM_EPOCHS = 10\n",
    "\n",
    "# train_loss = collections.defaultdict(list)\n",
    "\n",
    "# for epoch in range(NUM_EPOCHS):\n",
    "#     for parsed_record in train_dataset.batch(HPARAMS['batch_size']): #.take(1):\n",
    "#         trajectory = _trajectory_fn(parsed_record, HPARAMS)\n",
    "#         print(trajectory)\n",
    "#         loss, _ = agent.train(trajectory)\n",
    "#         train_loss[f\"epoch:{epoch + 1}\"].append(loss.numpy())\n",
    "        \n",
    "# train_outputs = collections.namedtuple(\n",
    "#     \"TrainOutputs\",[\"policy\", \"train_loss\"]\n",
    "# )\n",
    "\n",
    "# train_outputs(agent.policy, train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cefc6c-dbab-46c1-b4d2-48b01ce80a51",
   "metadata": {},
   "source": [
    "see `TFUniformReplayBuffer` [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/replay_buffers/TFUniformReplayBuffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "443a8215-4eee-4d12-8f2f-8ac59132fee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_length = 1000\n",
    "\n",
    "# replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "#     data_spec = agent.policy.trajectory_spec,\n",
    "#     batch_size=HPARAMS['batch_size'],\n",
    "#     max_length=max_length\n",
    "# )\n",
    "# # Add an observer that adds to the replay buffer:\n",
    "# replay_observer = [replay_buffer.add_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "2c774a28-1193-44ff-a595-c965fe46d4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.replay_buffers.tf_uniform_replay_buffer.TFUniformReplayBuffer at 0x7f6d6694de40>"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Read the replay buffer as a Dataset,\n",
    "# # read batches of 4 elements, each with 2 timesteps:\n",
    "# dataset = replay_buffer.as_dataset(\n",
    "#     sample_batch_size=4,\n",
    "#     num_steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "40c94339-05ef-4ab8-8ec9-b5bdc1cdfc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: [[  4.]\n",
      " [  4.]\n",
      " [-10.]\n",
      " [ 10.]\n",
      " [  3.]\n",
      " [  2.]\n",
      " [ 10.]\n",
      " [ 10.]]\n",
      "dummy_rewards: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "Trajectory(\n",
      "{'action': <tf.Tensor: shape=(8, 1), dtype=int32, numpy=\n",
      "array([[0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0]], dtype=int32)>,\n",
      " 'discount': <tf.Tensor: shape=(8, 1), dtype=float32, numpy=\n",
      "array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)>,\n",
      " 'next_step_type': <tf.Tensor: shape=(8, 1), dtype=int32, numpy=\n",
      "array([[2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2]], dtype=int32)>,\n",
      " 'observation': {'global': <tf.Tensor: shape=(16, 1), dtype=float32, numpy=\n",
      "array([[-0.02599   ],\n",
      "       [-0.03078079],\n",
      "       [ 0.03106076],\n",
      "       [ 0.00133444],\n",
      "       [ 0.02207417],\n",
      "       [-0.02917665],\n",
      "       [ 0.02782809],\n",
      "       [-0.02822751],\n",
      "       [-0.04523091],\n",
      "       [ 0.0495333 ],\n",
      "       [-0.01482558],\n",
      "       [-0.04208376],\n",
      "       [ 0.00741076],\n",
      "       [-0.04264941],\n",
      "       [ 0.00693322],\n",
      "       [-0.03396516]], dtype=float32)>},\n",
      " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=<tf.Tensor: shape=(8, 3), dtype=float32, numpy=\n",
      "array([[0., 0., 0.],\n",
      "       [0., 0., 0.],\n",
      "       [0., 0., 0.],\n",
      "       [0., 0., 0.],\n",
      "       [0., 0., 0.],\n",
      "       [0., 0., 0.],\n",
      "       [0., 0., 0.],\n",
      "       [0., 0., 0.]], dtype=float32)>, multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=<tf.Tensor: shape=(16, 1), dtype=float32, numpy=\n",
      "array([[-0.02780459],\n",
      "       [-0.00370889],\n",
      "       [-0.02864446],\n",
      "       [-0.02917221],\n",
      "       [-0.01603731],\n",
      "       [ 0.02465415],\n",
      "       [ 0.01583499],\n",
      "       [-0.03253644],\n",
      "       [ 0.03956462],\n",
      "       [ 0.04351255],\n",
      "       [ 0.01470714],\n",
      "       [ 0.04936441],\n",
      "       [ 0.01360733],\n",
      "       [-0.0412104 ],\n",
      "       [ 0.02928157],\n",
      "       [ 0.01699198]], dtype=float32)>),\n",
      " 'reward': <tf.Tensor: shape=(8, 1), dtype=float32, numpy=\n",
      "array([[  4.],\n",
      "       [  4.],\n",
      "       [-10.],\n",
      "       [ 10.],\n",
      "       [  3.],\n",
      "       [  2.],\n",
      "       [ 10.],\n",
      "       [ 10.]], dtype=float32)>,\n",
      " 'step_type': <tf.Tensor: shape=(8, 1), dtype=int32, numpy=\n",
      "array([[0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0]], dtype=int32)>})\n"
     ]
    }
   ],
   "source": [
    "# for x in train_dataset.batch(HPARAMS['batch_size']).take(1):\n",
    "#     trajectory = _trajectory_fn(x)\n",
    "#     print(trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5a3a4686-022f-488b-8d74-f6e96a4e532d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([25.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[4]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'211'], dtype=object)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([874948475])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'346'], dtype=object)>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'other'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "for x in train_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b00d965-fd98-48c6-9d89-89081ebe531d",
   "metadata": {},
   "source": [
    "# Bandito's Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1623,
   "id": "a2fb1bb0-42ff-4fa0-896d-309237fae8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_global_context_features(x):\n",
    "    \"\"\"\n",
    "    This function generates a single global observation vector.\n",
    "    \"\"\"\n",
    "    user_id_value = x['user_id']\n",
    "    user_age_value = x['bucketized_user_age']\n",
    "    user_occ_value = x['user_occupation_text']\n",
    "    user_ts_value = x['timestamp']\n",
    "\n",
    "    _id = test_user_id_model(user_id_value) # input_tensor=tf.Tensor(shape=(4,), dtype=float32)\n",
    "    _age = test_user_age_model(user_age_value)\n",
    "    _occ = test_user_occ_model(user_occ_value)\n",
    "    _ts = test_user_ts_model(user_ts_value)\n",
    "\n",
    "    # # tmp - insepct numpy() values\n",
    "    # print(_id.numpy()) #[0])\n",
    "    # print(_age.numpy()) #[0])\n",
    "    # print(_occ.numpy()) #[0])\n",
    "    # print(_ts.numpy()) #[0])\n",
    "\n",
    "    # to numpy array\n",
    "    _id = np.array(_id.numpy()[0])\n",
    "    _age = np.array(_age.numpy()[0])\n",
    "    _occ = np.array(_occ.numpy()[0])\n",
    "    _ts = np.array(_ts.numpy()[0])\n",
    "\n",
    "    concat = np.concatenate(\n",
    "        [_id, _age, _occ, _ts], axis=-1 # -1\n",
    "    ).astype(np.float32)\n",
    "\n",
    "    return concat\n",
    "\n",
    "def _get_per_arm_features(x):\n",
    "    \"\"\"\n",
    "    This function generates a single per-arm observation vector\n",
    "    \"\"\"\n",
    "    mv_id_value = x['movie_id']\n",
    "    mv_gen_value = x['movie_genres'][0]\n",
    "\n",
    "    _mid = test_mv_id_model(mv_id_value)\n",
    "    _mgen = test_mv_gen_model(mv_gen_value)\n",
    "\n",
    "    # to numpy array\n",
    "    _mid = np.array(_mid.numpy()[0])\n",
    "    _mgen = np.array(_mgen.numpy()[0])\n",
    "\n",
    "    # print(_mid)\n",
    "    # print(_mgen)\n",
    "\n",
    "    concat = np.concatenate(\n",
    "        [_mid, _mgen], axis=-1 # -1\n",
    "    ).astype(np.float32)\n",
    "    # concat = tf.concat([_mid, _mgen], axis=-1).astype(np.float32)\n",
    "\n",
    "    return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1624,
   "id": "3756a957-5cd2-4f52-80f7-685ed8e9a851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "GLOBAL_DIM = global_context_sampling_fn()\n",
    "GLOBAL_DIM = GLOBAL_DIM.shape[0]\n",
    "print(GLOBAL_DIM)\n",
    "\n",
    "PER_ARM_DIM = per_arm_context_sampling_fn()\n",
    "PER_ARM_DIM = PER_ARM_DIM.shape[0]\n",
    "print(PER_ARM_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1627,
   "id": "4d85cd9a-1c66-42fd-9b6a-6db977fafc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "\n",
    "HPARAMS = {\n",
    "    \"batch_size\":8,\n",
    "    \"num_docs_to_rank\":3,\n",
    "    \"model_type\": \"neural_epsilon_greedy\",\n",
    "    \"network_type\": 'commontower',\n",
    "    \"global_layers\": [16,4],\n",
    "    \"per_arm_layers\": [16,4],\n",
    "    \"common_layers\": [4],\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"epsilon\":0.01,\n",
    "}\n",
    "\n",
    "async_steps_per_loop = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1626,
   "id": "72acf106-e385-4fce-b954-eb84b915dce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(16,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(3, 16), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 1626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_actions = HPARAMS['num_docs_to_rank']\n",
    "# num_actions=tf.convert_to_tensor(num_actions, dtype=tf.int32)\n",
    "print(num_actions)\n",
    "\n",
    "global_spec = tensor_spec.TensorSpec(shape=[GLOBAL_DIM], dtype=tf.float32)\n",
    "per_arm_spec = tensor_spec.TensorSpec(shape=[num_actions, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "observation_spec = {'global': global_spec, 'per_arm': per_arm_spec}\n",
    "observation_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1628,
   "id": "30c68f99-c5ac-44e7-87e9-f842412a7e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf_agents\n",
    "\n",
    "# test_chosen_arm_feats = tf_agents.policies.utils.create_chosen_arm_features_info_spec(observation_spec=observation_spec)\n",
    "# test_chosen_arm_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1629,
   "id": "43589dc7-80bf-4ff1-bf3e-5a8e52af7a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(2, dtype=int32))"
      ]
     },
     "execution_count": 1629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=(), \n",
    "    dtype=tf.int32,\n",
    "    minimum=tf.Variable(0), # 0 \n",
    "    maximum=num_actions-tf.Variable(1), # -1\n",
    "    name=\"action_spec\"\n",
    ")\n",
    "action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1631,
   "id": "69264d46-ffc8-4bd2-9bd7-ced5aefa546e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'global': TensorSpec(shape=(16,), dtype=tf.float32, name=None),\n",
       "                 'per_arm': TensorSpec(shape=(3, 16), dtype=tf.float32, name=None)},\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 1631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec = ts.time_step_spec(\n",
    "    observation_spec = observation_spec, \n",
    "    # reward_spec = _reward_spec\n",
    ")\n",
    "time_step_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1632,
   "id": "1ed87615-357f-45eb-b23c-c8412e8766ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: OffpolicyNeuralEpsGreedyAgent\n",
      "\n",
      "Network: global_and_arm_common_tower_network_63\n"
     ]
    }
   ],
   "source": [
    "from tf_agents.bandits.agents import greedy_reward_prediction_agent\n",
    "\n",
    "network = None\n",
    "observation_and_action_constraint_splitter = None\n",
    "\n",
    "# global_step = tf.Variable(0)\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "if HPARAMS['network_type'] == 'commontower':\n",
    "    network = global_and_arm_feature_network.create_feed_forward_common_tower_network(\n",
    "        observation_spec = observation_spec, \n",
    "        global_layers = HPARAMS['global_layers'], \n",
    "        arm_layers = HPARAMS['per_arm_layers'], \n",
    "        common_layers = HPARAMS['common_layers'],\n",
    "        # output_dim = 1\n",
    "    )\n",
    "elif HPARAMS['network_type'] == 'dotproduct':\n",
    "    network = global_and_arm_feature_network.create_feed_forward_dot_product_network(\n",
    "        observation_spec = observation_spec, \n",
    "        global_layers = HPARAMS['global_layers'], \n",
    "        arm_layers = HPARAMS['per_arm_layers']\n",
    "    )\n",
    "    \n",
    "# agent = greedy_reward_prediction_agent.GreedyRewardPredictionAgent()\n",
    "    \n",
    "agent = neural_epsilon_greedy_agent.NeuralEpsilonGreedyAgent(\n",
    "    time_step_spec=time_step_spec,\n",
    "    action_spec=action_spec,\n",
    "    reward_network=network,\n",
    "    optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=HPARAMS['learning_rate']),\n",
    "    epsilon=HPARAMS['epsilon'],\n",
    "    observation_and_action_constraint_splitter=(\n",
    "        observation_and_action_constraint_splitter\n",
    "    ),\n",
    "    accepts_per_arm_features=True,\n",
    "    emit_policy_info=policy_utilities.InfoFields.PREDICTED_REWARDS_MEAN,\n",
    "    train_step_counter=global_step,\n",
    "    info_fields_to_inherit_from_greedy=[\n",
    "        policy_utilities.InfoFields.PREDICTED_REWARDS_MEAN\n",
    "    ],\n",
    "    name='OffpolicyNeuralEpsGreedyAgent'\n",
    ")\n",
    "agent.initialize()\n",
    "\n",
    "print(f\"Agent: {agent.name}\\n\")\n",
    "if network:\n",
    "    print(f\"Network: {network.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1633,
   "id": "c11d03b5-270a-4f31-ac0d-a7496527f390",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_spec = agent.policy.trajectory_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1636,
   "id": "c64e44af-0dbe-444b-a998-7f15ad05f8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.bandits.replay_buffers import bandit_replay_buffer\n",
    "\n",
    "steps_per_loop=2\n",
    "\n",
    "def _get_replay_buffer(\n",
    "    data_spec, batch_size, steps_per_loop, async_steps_per_loop\n",
    "):\n",
    "    \"\"\"Return a `TFUniformReplayBuffer` for the given `agent`.\"\"\"\n",
    "    return bandit_replay_buffer.BanditReplayBuffer(\n",
    "        data_spec=data_spec,\n",
    "        batch_size=batch_size,\n",
    "        max_length=steps_per_loop * async_steps_per_loop,\n",
    "    )\n",
    "\n",
    "# if get_replay_buffer_fn is None:\n",
    "get_replay_buffer_fn = _get_replay_buffer\n",
    "\n",
    "replay_buffer = get_replay_buffer_fn(\n",
    "    data_spec, HPARAMS['batch_size'], steps_per_loop, async_steps_per_loop\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1637,
   "id": "6e640d30-65c3-443e-bd17-9b3fe571c752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.replay_buffers.tf_uniform_replay_buffer.TFUniformReplayBuffer at 0x7f6d64e6dc60>"
      ]
     },
     "execution_count": 1637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `step_metric` records the number of individual rounds of bandit interaction;\n",
    "# that is, (number of trajectories) * batch_size.\n",
    "step_metric = tf_metrics.EnvironmentSteps()\n",
    "metrics = [\n",
    "    tf_metrics.NumberOfEpisodes(),\n",
    "    tf_metrics.AverageEpisodeLengthMetric(batch_size=environment.batch_size),\n",
    "] # + list(additional_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1638,
   "id": "ea32b764-9689-4f4b-a667-63e6ad61c8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ReplayBuffer.add_batch of <tf_agents.replay_buffers.tf_uniform_replay_buffer.TFUniformReplayBuffer object at 0x7f6d64e6dc60>>"
      ]
     },
     "execution_count": 1638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if training_data_spec_transformation_fn is not None:\n",
    "#     add_batch_fn = lambda data: replay_buffer.add_batch(\n",
    "#         training_data_spec_transformation_fn(data)\n",
    "#     )\n",
    "# else:\n",
    "\n",
    "add_batch_fn = replay_buffer.add_batch\n",
    "add_batch_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1640,
   "id": "5c5b56d6-be3d-4a56-a2aa-4b92a10a6adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<bound method ReplayBuffer.add_batch of <tf_agents.replay_buffers.tf_uniform_replay_buffer.TFUniformReplayBuffer object at 0x7f6d64e6dc60>>,\n",
       " <tf_agents.metrics.tf_metrics.EnvironmentSteps at 0x7f6d66ab73a0>,\n",
       " <tf_agents.bandits.metrics.tf_metrics.RegretMetric at 0x7f71a8649960>,\n",
       " <tf_agents.bandits.metrics.tf_metrics.SuboptimalArmsMetric at 0x7f71a8649bd0>]"
      ]
     },
     "execution_count": 1640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_metric = tf_metrics.EnvironmentSteps()\n",
    "\n",
    "observers = [add_batch_fn, step_metric] + metrics\n",
    "observers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1646,
   "id": "781797ad-142c-4542-89d6-f30d8c81bac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_expected_shape(experience, num_steps):\n",
    "    \"\"\"Sets expected shape.\"\"\"\n",
    "\n",
    "    def set_time_dim(input_tensor, steps):\n",
    "        tensor_shape = input_tensor.shape.as_list()\n",
    "        if len(tensor_shape) < 2:\n",
    "            raise ValueError(\n",
    "                'input_tensor is expected to be of rank-2, but found otherwise: '\n",
    "                f'input_tensor={input_tensor}, tensor_shape={tensor_shape}'\n",
    "            )\n",
    "        tensor_shape[1] = steps\n",
    "        input_tensor.set_shape(tensor_shape)\n",
    "\n",
    "    tf.nest.map_structure(lambda t: set_time_dim(t, num_steps), experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1704,
   "id": "1ca8f81a-d8ea-47f8-8e74-8eb9e1f234fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _trajectory_fn(element): # hparams\n",
    "    \"\"\"Converts a dataset element into a trajectory.\"\"\"\n",
    "    global_features = _get_global_context_features(element)\n",
    "    arm_features = _get_per_arm_features(element)\n",
    "    \n",
    "    # obs spec\n",
    "    observation = {\n",
    "        bandit_spec_utils.GLOBAL_FEATURE_KEY:\n",
    "            global_features,\n",
    "            # _add_outer_dimension(global_features)\n",
    "        # bandit_spec_utils.PER_ARM_FEATURE_KEY:\n",
    "        #     _add_outer_dimension(arm_features),\n",
    "    }\n",
    "    # reward = tensor_spec.add_outer_dim(_get_rewards(element))\n",
    "    reward = _get_rewards(element)\n",
    "    # print(f\"reward: {reward}\")\n",
    "    \n",
    "    # To emit the predicted rewards in policy_info, we need to create dummy\n",
    "    # rewards to match the definition in TensorSpec for the ones specified in\n",
    "    # emit_policy_info set.\n",
    "    # dummy_rewards = tf.zeros([HPARAMS['batch_size'], 1, HPARAMS['num_docs_to_rank']])\n",
    "    # dummy_rewards = tf.zeros([HPARAMS['batch_size'], HPARAMS['num_docs_to_rank']])\n",
    "    dummy_rewards = tf.zeros([HPARAMS['num_docs_to_rank']])\n",
    "    policy_info = policy_utilities.PerArmPolicyInfo(\n",
    "        chosen_arm_features=arm_features,\n",
    "        # Pass dummy mean rewards here to match the model_spec for emitting\n",
    "        # mean rewards in policy info\n",
    "        predicted_rewards_mean=dummy_rewards\n",
    "    )\n",
    "    \n",
    "# tf_agents.policies.utils.create_chosen_arm_features_info_spec(\n",
    "#     observation_spec: tf_agents.typing.types.NestedTensorSpec\n",
    "# ) -> tf_agents.typing.types.NestedTensorSpec\n",
    "    \n",
    "    if HPARAMS['model_type'] == 'neural_ucb':\n",
    "        policy_info = policy_info._replace(\n",
    "            predicted_rewards_optimistic=dummy_rewards\n",
    "        )\n",
    "        \n",
    "    # print(f\"observation: {observation}\")\n",
    "    # print(f\"reward: {reward}\")\n",
    "    # print(f\"policy_info: {policy_info}\")\n",
    "    # print(f\"dummy_rewards: {dummy_rewards}\")\n",
    "    \n",
    "    return trajectory.single_step(\n",
    "        observation=observation,\n",
    "        action=tf.zeros_like(\n",
    "            reward, dtype=tf.int32\n",
    "        ),  # Arm features are copied from policy info, put dummy zeros here\n",
    "        policy_info=policy_info, # policy_info,\n",
    "        reward=reward,\n",
    "        discount=tf.zeros_like(reward)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1705,
   "id": "9d307199-7220-4420-a5e7-1b349a35cc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_training_loop(\n",
    "    batch_size, \n",
    "    replay_buffer, \n",
    "    agent, \n",
    "    steps, \n",
    "    async_steps_per_loop\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns a `tf.function` that runs the driver and training loops.\n",
    "    \"\"\"\n",
    "\n",
    "    def _export_metrics_and_summaries(step, metrics):\n",
    "        \"\"\"Exports metrics and tf summaries.\"\"\"\n",
    "        metric_utils.log_metrics(metrics)\n",
    "        export_utils.export_metrics(step=step, metrics=metrics)\n",
    "        for metric in metrics:\n",
    "            metric.tf_summaries(train_step=step)\n",
    "\n",
    "    def training_loop(train_step, metrics):\n",
    "        \"\"\"Returns a function that runs a single training loop and logs metrics.\"\"\"\n",
    "        # for batch_id in range(async_steps_per_loop):\n",
    "        #     # driver.run()\n",
    "        #     _export_metrics_and_summaries(\n",
    "        #         step=train_step * async_steps_per_loop + batch_id, metrics=metrics\n",
    "        #     )\n",
    "        # batch_size = driver.env.batch_size\n",
    "        # dataset_it = iter(\n",
    "        #     replay_buffer.as_dataset(\n",
    "        #         sample_batch_size=batch_size,\n",
    "        #         num_steps=steps,\n",
    "        #         single_deterministic_pass=True,\n",
    "        #     )\n",
    "        # )\n",
    "        dataset = train_dataset.batch(batch_size)\n",
    "        dataset_it = iter(dataset)\n",
    "        # data = next(iterator)\n",
    "\n",
    "        for batch_id in range(async_steps_per_loop):\n",
    "            # experience, unused_info = dataset_it.get_next()\n",
    "            experience, _ = next(dataset_it)\n",
    "            print(f\"experience-v1: {experience}\")\n",
    "            set_expected_shape(experience, steps)\n",
    "            print(f\"experience-v2: {experience}\")\n",
    "            \n",
    "            trajectories = _trajectory_fn(experience)\n",
    "            \n",
    "            loss_info = agent.train(experience=trajectories)\n",
    "            \n",
    "            export_utils.export_metrics(\n",
    "                step=train_step * async_steps_per_loop + batch_id,\n",
    "                metrics=[],\n",
    "                loss_info=loss_info,\n",
    "            )\n",
    "\n",
    "        replay_buffer.clear()\n",
    "\n",
    "    return training_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1684,
   "id": "ab2d2b46-1390-4292-9a5f-a330e8f7dd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testy = next(dataset_it) \n",
    "# testy = dataset_it.get_next()\n",
    "# testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1685,
   "id": "c1a259c8-7288-410b-9e7d-1ca5cbda8598",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_training_loop_fn = _get_training_loop\n",
    "\n",
    "training_looper = get_training_loop_fn(\n",
    "    HPARAMS['batch_size'], replay_buffer, agent, steps_per_loop, async_steps_per_loop\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1686,
   "id": "843ada6c-2810-499b-b392-85691e7e7260",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1686], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtraining_looper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1683], line 39\u001b[0m, in \u001b[0;36m_get_training_loop.<locals>.training_loop\u001b[0;34m(train_step, metrics)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# data = next(iterator)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(async_steps_per_loop):\n\u001b[0;32m---> 39\u001b[0m     experience, unused_info \u001b[38;5;241m=\u001b[39m dataset_it\u001b[38;5;241m.\u001b[39mget_next()\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# experience, _ = next(dataset_it)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperience-v1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperience\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "training_looper(train_step=1, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1680,
   "id": "fdeb93ea-cc42-4160-a2d8-0c12cfd1c176",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1680], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mdefaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[0;32m---> 12\u001b[0m     \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# iterator = iter(train_dataset.batch(2))\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# data = next(iterator)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# pprint(f\"print data: {data}\")\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#     loss = agent.train(experience=trajectories)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1676], line 40\u001b[0m, in \u001b[0;36m_get_training_loop.<locals>.training_loop\u001b[0;34m(train_step, metrics)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# data = next(iterator)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(async_steps_per_loop):\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# experience, unused_info = dataset_it.get_next()\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     experience, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataset_it)\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperience-v1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperience\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m     set_expected_shape(experience, steps)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 3\n",
    "\n",
    "# agent.train = common.function(agent.train)\n",
    "\n",
    "# # Reset the train step\n",
    "# agent.train_step_counter.assign(0)\n",
    "\n",
    "# train_loss = collections.defaultdict(list)\n",
    "\n",
    "for i in range(NUM_EPOCHS):\n",
    "    \n",
    "    training_looper(train_step=i, metrics=metrics)\n",
    "    \n",
    "    # iterator = iter(train_dataset.batch(2))\n",
    "    # data = next(iterator)\n",
    "    # pprint(f\"print data: {data}\")\n",
    "    \n",
    "#     trajectories = _trajectory_fn(data)\n",
    "#     # pprint(f\"print trajectories: {trajectories}\")\n",
    "    \n",
    "#     # All tensors in experience must be shaped [batch, time, ...] \n",
    "#     step = agent.train_step_counter.numpy()\n",
    "    \n",
    "#     loss = agent.train(experience=trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1644,
   "id": "26880ec7-58c6-466a-97ee-e1ca0ea453d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : banditos-2\n",
      "RUN_NAME          : run-20230809-151029\n",
      "LOG_DIR           : gs://mabv1-hybrid-vertex-bucket/banditos-2/run-20230809-151029/logs\n",
      "ROOT_DIR          : gs://mabv1-hybrid-vertex-bucket/banditos-2/run-20230809-151029/root\n",
      "ARTIFACTS_DIR     : gs://mabv1-hybrid-vertex-bucket/banditos-2/run-20230809-151029/artifacts\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME   = f'banditos-2'\n",
    "\n",
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "LOG_DIR           = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}/logs\"\n",
    "ROOT_DIR          = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1706,
   "id": "61d1af39-95b5-470a-a3ed-497c75d3d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step_counter = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "summary_writer = tf.summary.create_file_writer(LOG_DIR)\n",
    "summary_writer.set_as_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1708,
   "id": "211d1f91-67ef-42d9-be2f-22581ecf83cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(starting_loop, training_loops):\n",
    "#     training_loop(train_step=i, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1709,
   "id": "62da450c-c2ea-4d25-9725-a581b2a3d43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_spec = agent.policy.trajectory_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1710,
   "id": "4eedb557-5c0a-4428-a6bd-5dd12b4e6eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(train_step, metrics, steps):\n",
    "    \"\"\"Returns a function that runs a single training loop and logs metrics.\"\"\"\n",
    "    # for batch_id in range(async_steps_per_loop):\n",
    "    #     # driver.run()\n",
    "    #     _export_metrics_and_summaries(\n",
    "    #         step=train_step * async_steps_per_loop + batch_id, metrics=metrics\n",
    "    #     )\n",
    "    # batch_size = driver.env.batch_size\n",
    "    # dataset_it = iter(\n",
    "    #     replay_buffer.as_dataset(\n",
    "    #         sample_batch_size=batch_size,\n",
    "    #         num_steps=steps,\n",
    "    #         single_deterministic_pass=True,\n",
    "    #     )\n",
    "    # )\n",
    "    dataset = train_dataset.batch(1) # HPARAMS['batch_size']\n",
    "    dataset_it = iter(dataset)\n",
    "    # data = next(iterator)\n",
    "\n",
    "    for batch_id in range(async_steps_per_loop):\n",
    "        # experience, unused_info = dataset_it.get_next()\n",
    "        experience = next(dataset_it)\n",
    "        print(f\"experience-v1: {experience}\")\n",
    "        # set_expected_shape(experience, steps)\n",
    "        # print(f\"experience-v2: {experience}\")\n",
    "\n",
    "        trajectories = _trajectory_fn(experience)\n",
    "\n",
    "        loss_info = agent.train(experience=trajectories)\n",
    "\n",
    "        export_utils.export_metrics(\n",
    "            step=train_step * async_steps_per_loop + batch_id,\n",
    "            metrics=[],\n",
    "            loss_info=loss_info,\n",
    "        )\n",
    "\n",
    "    # replay_buffer.clear()\n",
    "\n",
    "    return training_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1711,
   "id": "92bba49d-a014-4169-968c-92cd9103279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = train_dataset.batch(1) # HPARAMS['batch_size']\n",
    "# dataset_it = iter(dataset)\n",
    "\n",
    "# experience = next(dataset_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1712,
   "id": "89c5a71e-c7b1-4e17-81d4-5f7c2c34b353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experience-v1: {'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([25.], dtype=float32)>, 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[4]])>, 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'211'], dtype=object)>, 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([874948475])>, 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'346'], dtype=object)>, 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'other'], dtype=object)>, 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Received a mix of batched and unbatched Tensors, or Tensors are not compatible with Specs.  num_outer_dims: 2.\nSaw tensor_shapes:\n   Trajectory(\n{'action': TensorShape([1]),\n 'discount': TensorShape([1]),\n 'next_step_type': TensorShape([1]),\n 'observation': DictWrapper({'global': TensorShape([16])}),\n 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorShape([3]), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=TensorShape([16])),\n 'reward': TensorShape([1]),\n 'step_type': TensorShape([1])})\nAnd spec_shapes:\n   Trajectory(\n{'action': TensorShape([]),\n 'discount': TensorShape([]),\n 'next_step_type': TensorShape([]),\n 'observation': DictWrapper({'global': TensorShape([16])}),\n 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorShape([3]), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=TensorShape([16])),\n 'reward': TensorShape([]),\n 'step_type': TensorShape([])})",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1712], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_loop\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1710], line 29\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(train_step, metrics, steps)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# set_expected_shape(experience, steps)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# print(f\"experience-v2: {experience}\")\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     trajectories \u001b[38;5;241m=\u001b[39m _trajectory_fn(experience)\n\u001b[0;32m---> 29\u001b[0m     loss_info \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrajectories\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     export_utils\u001b[38;5;241m.\u001b[39mexport_metrics(\n\u001b[1;32m     32\u001b[0m         step\u001b[38;5;241m=\u001b[39mtrain_step \u001b[38;5;241m*\u001b[39m async_steps_per_loop \u001b[38;5;241m+\u001b[39m batch_id,\n\u001b[1;32m     33\u001b[0m         metrics\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m     34\u001b[0m         loss_info\u001b[38;5;241m=\u001b[39mloss_info,\n\u001b[1;32m     35\u001b[0m     )\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# replay_buffer.clear()\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_agents/agents/tf_agent.py:330\u001b[0m, in \u001b[0;36mTFAgent.train\u001b[0;34m(self, experience, weights, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    326\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find _train_fn.  Did \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.__init__ call super?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    327\u001b[0m       \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_functions:\n\u001b[0;32m--> 330\u001b[0m   loss_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m      \u001b[49m\u001b[43mexperience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperience\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m   loss_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train(experience\u001b[38;5;241m=\u001b[39mexperience, weights\u001b[38;5;241m=\u001b[39mweights, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_agents/utils/common.py:188\u001b[0m, in \u001b[0;36mfunction_in_tf1.<locals>.maybe_wrap.<locals>.with_check_resource_vars\u001b[0;34m(*fn_args, **fn_kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m check_tf1_allowed()\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_eager_been_enabled():\n\u001b[1;32m    186\u001b[0m   \u001b[38;5;66;03m# We're either in eager mode or in tf.function mode (no in-between); so\u001b[39;00m\n\u001b[1;32m    187\u001b[0m   \u001b[38;5;66;03m# autodep-like behavior is already expected of fn.\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m resource_variables_enabled():\n\u001b[1;32m    190\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(MISSING_RESOURCE_VARIABLES_ERROR)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_agents/bandits/agents/greedy_reward_prediction_agent.py:228\u001b[0m, in \u001b[0;36mGreedyRewardPredictionAgent._train\u001b[0;34m(self, experience, weights)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, experience, weights):\n\u001b[0;32m--> 228\u001b[0m   experience \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_as_trajectory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperience\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m    231\u001b[0m     loss_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss(experience, weights\u001b[38;5;241m=\u001b[39mweights, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_agents/agents/data_converter.py:340\u001b[0m, in \u001b[0;36mAsTrajectory.__call__\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput type not supported: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(value))\n\u001b[0;32m--> 340\u001b[0m \u001b[43m_validate_trajectory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrajectory_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43msequence_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sequence_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_outer_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outer_dims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m value \u001b[38;5;241m=\u001b[39m nest_utils\u001b[38;5;241m.\u001b[39mprune_extra_keys(\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_context\u001b[38;5;241m.\u001b[39mtrajectory_spec, value)\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_agents/agents/data_converter.py:174\u001b[0m, in \u001b[0;36m_validate_trajectory\u001b[0;34m(value, trajectory_spec, sequence_length, num_outer_dims)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_trajectory\u001b[39m(\n\u001b[1;32m    169\u001b[0m     value: trajectory\u001b[38;5;241m.\u001b[39mTrajectory,\n\u001b[1;32m    170\u001b[0m     trajectory_spec: trajectory\u001b[38;5;241m.\u001b[39mTrajectory,\n\u001b[1;32m    171\u001b[0m     sequence_length: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m    172\u001b[0m     num_outer_dims: te\u001b[38;5;241m.\u001b[39mLiteral[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=bad-whitespace\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Validate a Trajectory given its spec and a sequence length.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mnest_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_batched_nested_tensors\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrajectory_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outer_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outer_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m      \u001b[49m\u001b[43mallow_extra_fields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m:\n\u001b[1;32m    177\u001b[0m     debug_str_1 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m tp: tp\u001b[38;5;241m.\u001b[39mshape, value)\n\u001b[1;32m    178\u001b[0m     debug_str_2 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m spec: spec\u001b[38;5;241m.\u001b[39mshape, trajectory_spec)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_agents/utils/nest_utils.py:546\u001b[0m, in \u001b[0;36mis_batched_nested_tensors\u001b[0;34m(tensors, specs, num_outer_dims, allow_extra_fields, check_dtypes)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    542\u001b[0m     discrepancy \u001b[38;5;241m==\u001b[39m tensor_ndims_discrepancy[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    543\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m discrepancy \u001b[38;5;129;01min\u001b[39;00m tensor_ndims_discrepancy) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(tensor_matches_spec):\n\u001b[1;32m    544\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 546\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReceived a mix of batched and unbatched Tensors, or Tensors\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m are not compatible with Specs.  num_outer_dims: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSaw tensor_shapes:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m   \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnd spec_shapes:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m   \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    551\u001b[0m     (num_outer_dims, tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mpack_sequence_as(specs, tensor_shapes),\n\u001b[1;32m    552\u001b[0m      tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mpack_sequence_as(specs, spec_shapes)))\n",
      "\u001b[0;31mValueError\u001b[0m: Received a mix of batched and unbatched Tensors, or Tensors are not compatible with Specs.  num_outer_dims: 2.\nSaw tensor_shapes:\n   Trajectory(\n{'action': TensorShape([1]),\n 'discount': TensorShape([1]),\n 'next_step_type': TensorShape([1]),\n 'observation': DictWrapper({'global': TensorShape([16])}),\n 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorShape([3]), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=TensorShape([16])),\n 'reward': TensorShape([1]),\n 'step_type': TensorShape([1])})\nAnd spec_shapes:\n   Trajectory(\n{'action': TensorShape([]),\n 'discount': TensorShape([]),\n 'next_step_type': TensorShape([]),\n 'observation': DictWrapper({'global': TensorShape([16])}),\n 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorShape([3]), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=(), chosen_arm_features=TensorShape([16])),\n 'reward': TensorShape([]),\n 'step_type': TensorShape([])})"
     ]
    }
   ],
   "source": [
    "training_loop(1,metrics, steps_per_loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1695,
   "id": "3b2e2ed9-ab79-44b2-939b-6286e5faff78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([25.], dtype=float32)>,\n",
       " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[4]])>,\n",
       " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'211'], dtype=object)>,\n",
       " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([874948475])>,\n",
       " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'346'], dtype=object)>,\n",
       " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'other'], dtype=object)>,\n",
       " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>}"
      ]
     },
     "execution_count": 1695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53db8881-c4af-4ae8-b294-85fd8a7a2637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "166f26b9-1c5e-47a1-bcab-61e7afa4d931",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Neural Bandits\n",
    "\n",
    "* `ActorNetwork` and `EncodingNetwork`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "dcff2e79-e0a9-4d46-896a-9d1129ac413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent as eps_greedy_agent\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "9390909d-c0e6-4cee-bdb9-c668a8a7ad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYERS = [16, 4]\n",
    "LR = 0.05\n",
    "EPSILON = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "0d78a5f7-b982-416f-841f-a40ae464d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = (\n",
    "    global_and_arm_feature_network.create_feed_forward_dot_product_network(\n",
    "        per_arm_tf_env.time_step_spec().observation,\n",
    "        global_layers=LAYERS,\n",
    "        arm_layers=LAYERS\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "79c9ca26-1efd-450f-a080-8771fba543f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = eps_greedy_agent.NeuralEpsilonGreedyAgent(\n",
    "    time_step_spec=per_arm_tf_env.time_step_spec(),\n",
    "    action_spec=per_arm_tf_env.action_spec(),\n",
    "    reward_network=network,\n",
    "    optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=LR),\n",
    "    epsilon=EPSILON,\n",
    "    emit_policy_info='predicted_rewards_mean',\n",
    "    info_fields_to_inherit_from_greedy=['predicted_rewards_mean']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "013dbde9-901c-4aeb-b5e7-1ce74ccbd5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data spec:  Trajectory(\n",
      "{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(9, dtype=int32)),\n",
      " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
      " 'observation': DictWrapper({'global': TensorSpec(shape=(16,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(10, 16), dtype=tf.float32, name=None)}),\n",
      " 'policy_info': PolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(10,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=()),\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n"
     ]
    }
   ],
   "source": [
    "print('training data spec: ', agent.training_data_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c37d0604-d73c-4db4-a1f2-858d6cc84989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation spec in training:  {'global': TensorSpec(shape=(16,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(10, 16), dtype=tf.float32, name=None)}\n"
     ]
    }
   ],
   "source": [
    "print('observation spec in training: ', agent.training_data_spec.observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "449ccbaf-2245-40f9-ad23-9b16e1aa03ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('chosen arm features: ', agent.training_data_spec.policy_info.chosen_arm_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "8851d632-62dd-4c41-ae5e-1c944e0ff9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_LOOPS=10\n",
    "STEPS_PER_LOOP=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "b6639883-0549-4fd0-83c1-a2723f946b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete train job in 1 minutes\n"
     ]
    }
   ],
   "source": [
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=agent.policy.trajectory_spec,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_length=steps_per_loop)\n",
    "\n",
    "observers = [replay_buffer.add_batch, regret_metric]\n",
    "\n",
    "driver = dynamic_step_driver.DynamicStepDriver(\n",
    "    env=per_arm_tf_env,\n",
    "    policy=agent.collect_policy,\n",
    "    num_steps=steps_per_loop * BATCH_SIZE,\n",
    "    observers=observers\n",
    ")\n",
    "\n",
    "regret_values = []\n",
    "\n",
    "#start the timer and training\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in range(TRAINING_LOOPS):\n",
    "    driver.run()\n",
    "    loss_info = agent.train(replay_buffer.gather_all())\n",
    "    replay_buffer.clear()\n",
    "    regret_values.append(regret_metric.result())\n",
    "    \n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"complete train job in {runtime_mins} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "3c46b97b-64bb-4b34-90fa-9d54ab8d2775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(regret_values)\n",
    "plt.title('Regret of LinUCB on the Linear per-arm environment')\n",
    "plt.xlabel('Number of Iterations')\n",
    "_ = plt.ylabel('Average Regret')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ada77e-a81d-408e-9c1e-7bfab1ffaf71",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bca1220-b08c-46af-9f20-6032d61cb73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# elif FLAGS.agent == 'NeuralLinUCB':\n",
    "# obs_spec = environment.observation_spec()\n",
    "# network = (\n",
    "#     global_and_arm_feature_network.create_feed_forward_common_tower_network(\n",
    "#         obs_spec, (40, 30), (30, 40), (40, 20), ENCODING_DIM\n",
    "#     )\n",
    "# )\n",
    "# agent = neural_linucb_agent.NeuralLinUCBAgent(\n",
    "#     time_step_spec=environment.time_step_spec(),\n",
    "#     action_spec=environment.action_spec(),\n",
    "#     encoding_network=network,\n",
    "#     encoding_network_num_train_steps=EPS_PHASE_STEPS,\n",
    "#     encoding_dim=ENCODING_DIM,\n",
    "#     optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=LR),\n",
    "#     alpha=1.0,\n",
    "#     gamma=1.0,\n",
    "#     epsilon_greedy=EPSILON,\n",
    "#     accepts_per_arm_features=True,\n",
    "#     debug_summaries=True,\n",
    "#     summarize_grads_and_vars=True,\n",
    "#     emit_policy_info=policy_utilities.InfoFields.PREDICTED_REWARDS_MEAN,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c7403d-a6b2-4a46-979c-a9942a2a4149",
   "metadata": {},
   "source": [
    "# Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b91482a5-2c42-4e0f-89d8-558d2462850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_dim = 9 \n",
    "item_dim   = 11 \n",
    "num_items  = 50\n",
    "num_slots  = 3 \n",
    "distance_threshold = 5.0 \n",
    "batch_size = 128  \n",
    "\n",
    "def global_sampling_fn():\n",
    "    return np.random.randint(-1, 1, [global_dim]).astype(np.float32)\n",
    "\n",
    "def item_sampling_fn():\n",
    "    return np.random.randint(-2, 3, [item_dim]).astype(np.float32)\n",
    "\n",
    "# Inner product with excess dimensions ignored.\n",
    "scores_weight_matrix = np.eye(11, 9, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4027d62e-33f0-4e5c-9d2c-22eb59896d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1.,  0., -1.,  0., -1.,  0., -1.], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_sampling_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62aea43d-d918-4ffb-9a04-00fd301f2ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  0.,  0., -1.,  0.,  2.,  0., -2.,  0.,  0.,  1.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_sampling_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f62c49c-4627-4be1-b354-a5ea379b85f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f244b2ee-03c0-4135-bdff-20f05acf9d77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
