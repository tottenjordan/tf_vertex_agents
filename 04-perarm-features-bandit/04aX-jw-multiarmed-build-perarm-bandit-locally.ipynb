{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385307d6-2058-47ec-8da0-57f7ef5c43d6",
   "metadata": {},
   "source": [
    "# Contextual Multi Armed Bandits with âœ¨Generativeâœ¨ Reward Functions\n",
    "\n",
    "Inspiration from this idea - somewhat of a LLM distillation method:\n",
    "https://arxiv.org/abs/2303.00001\n",
    "\n",
    "### Reward Design with Language Models\n",
    "##### Minae Kwon, Sang Michael Xie, Kalesha Bullard, Dorsa Sadigh\n",
    "`Reward design in reinforcement learning (RL) is challenging since specifying human notions of desired behavior may be difficult via reward functions or require many expert demonstrations. Can we instead cheaply design rewards using a natural language interface? This paper explores how to simplify reward design by prompting a large language model (LLM) such as GPT-3 as a proxy reward function, where the user provides a textual prompt containing a few examples (few-shot) or a description (zero-shot) of the desired behavior. Our approach leverages this proxy reward function in an RL framework. Specifically, users specify a prompt once at the beginning of training. During training, the LLM evaluates an RL agent's behavior against the desired behavior described by the prompt and outputs a corresponding reward signal. The RL agent then uses this reward to update its behavior. We evaluate whether our approach can train agents aligned with user objectives in the Ultimatum Game, matrix games, and the DealOrNoDeal negotiation task. In all three tasks, we show that RL agents trained with our framework are well-aligned with the user's objectives and outperform RL agents trained with reward functions learned via supervised learning`\n",
    "\n",
    "In this we will use PALM Text Bison. We will do the following\n",
    "\n",
    "1. Generate \"trajectory\" training examples where we have a batch of n users, shown a randomly selected batch of n_actions movies\n",
    "2. Take the raw textual data of those features and format a prompt asking text bison to rate the movie (float) on a 0-5 rating scale\n",
    "3. These rewards are then used as we generte the reward and update the trajectory\n",
    "4. Either generate the rest of these examples online (suggested for scale), or generate as-you-train\n",
    "5. Create a deep network for an epsilon-greed multi-armed bandit agent to explore/exlpoit the rewards generated by text-bison\n",
    "\n",
    "\n",
    "Future ideas\n",
    "\n",
    "- When tempurature is set to high and/or token count is extended, it can be interesting to see it rationalize the ratings. \n",
    "\n",
    "- Mapreduce multiple prompts with...\n",
    "\n",
    "- Mixture-of-experts approach\n",
    "\n",
    "# Train Bandits with per-arm features\n",
    "\n",
    "**Exploring linear and nonlinear** (e.g., those with neural network-based value functions) bandit methods for recommendations using TF-Agents\n",
    "\n",
    "> Neural linear bandits provide a nice way to leverage the representation power of deep learning and the bandit approach for uncertainty measure and efficient exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fd257-b98b-426a-a2cd-024429b014f1",
   "metadata": {},
   "source": [
    "## Load notebook config\n",
    "\n",
    "* use the prefix defined in `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f39c9d08-d118-4013-a47f-88450f49f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = 'mabv1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908f6b95-b539-4a9f-a836-840d26ea3b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"wortz-project-352116\"\n",
      "PROJECT_NUM              = \"679926387543\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"679926387543-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"mabv1\"\n",
      "VERSION                  = \"v1\"\n",
      "\n",
      "BUCKET_NAME              = \"mabv1-wortz-project-352116-bucket\"\n",
      "BUCKET_URI               = \"gs://mabv1-wortz-project-352116-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://mabv1-wortz-project-352116-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/679926387543/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_ID      = \"wortz-project-352116.movielens_dataset_mabv1\"\n",
      "BIGQUERY_TABLE_ID        = \"wortz-project-352116.movielens_dataset_mabv1.training_dataset\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "REPOSITORY               = \"rl-movielens-mabv1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c690a9-e2bd-4759-ba41-4e2469098aee",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d0dfe4-695c-4dd4-9f24-67f7488ce1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c669f1a1-1af7-4efb-ab2d-6bf3b3847991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tensorflow/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/envs/tensorflow/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/envs/tensorflow/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/envs/tensorflow/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/envs/tensorflow/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/envs/tensorflow/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "from collections import defaultdict\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pickle as pkl\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "# from tf_agents.agents import TFAgent\n",
    "\n",
    "# from tf_agents.bandits.environments import stationary_stochastic_per_arm_py_environment as p_a_env\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "# from tf_agents.drivers import dynamic_step_driver\n",
    "# from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "# from tf_agents.bandits.agents import lin_ucb_agent\n",
    "# from tf_agents.bandits.agents import linear_thompson_sampling_agent as lin_ts_agent\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent\n",
    "from tf_agents.bandits.agents import neural_linucb_agent\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "from tf_agents.bandits.policies import policy_utilities\n",
    "\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# this repo\n",
    "from src.per_arm_rl import data_utils\n",
    "from src.per_arm_rl import data_config\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29e58dd7-ab2b-419f-9771-bf1e98db758b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for gpu in gpus:\n",
    "#     tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \n",
    "# gpus\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4969d3e-1fc0-45db-8a69-aa6b342019de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = cuda.get_current_device()\n",
    "# device.reset()\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "274e7f4a-1802-4946-888e-876638f5c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a866b1-85b9-43e6-9546-edfbbf886bce",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd5b953-14c0-42ed-a511-77147a1bc0ac",
   "metadata": {},
   "source": [
    "### Read TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d0157c8-a04c-4dbd-b6d9-a1ede97687a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c934c06-bf08-4c7f-b0cc-0de04ef3515c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://mabv1-wortz-project-352116-bucket/data/train/ml-ratings-100k-train.tfrecord']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPLIT = \"train\" # \"train\" | \"val\"\n",
    "\n",
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7511e4d-bf81-4800-bde7-8b16dec9aeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([35.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'898'], dtype=object)>,\n",
      " 'movie_title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Postman, The (1997)'], dtype=object)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([885409515])>,\n",
      " 'user_gender': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'False'], dtype=object)>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'681'], dtype=object)>,\n",
      " 'user_occupation_label': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([14])>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'marketing'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>,\n",
      " 'user_zip_code': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'97208'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "train_dataset = train_dataset.map(data_utils.parse_tfrecord)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8959967-522e-41c8-9a1b-050ca8bc191f",
   "metadata": {},
   "source": [
    "### get vocab\n",
    "\n",
    "**TODO:** \n",
    "* streamline vocab calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b9169bc-d6dc-497e-9dff-6ebb175282ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE_VOCABS: False\n"
     ]
    }
   ],
   "source": [
    "GENERATE_VOCABS = False\n",
    "print(f\"GENERATE_VOCABS: {GENERATE_VOCABS}\")\n",
    "\n",
    "VOCAB_SUBDIR   = \"vocabs\"\n",
    "VOCAB_FILENAME = \"vocab_dict.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3ccf137-7a72-42e7-aa89-3c81a99cf40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab...\n",
      "Downloaded vocab from: gs://mabv1-wortz-project-352116-bucket/vocabs/vocab_dict.pkl\n",
      "\n",
      "'movie_id'\n",
      "'user_id'\n",
      "'user_occupation_text'\n",
      "'movie_genres'\n",
      "'bucketized_user_age'\n",
      "'max_timestamp'\n",
      "'min_timestamp'\n",
      "'timestamp_buckets'\n"
     ]
    }
   ],
   "source": [
    "if not GENERATE_VOCABS:\n",
    "\n",
    "    EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{VOCAB_SUBDIR}/{VOCAB_FILENAME}'\n",
    "    print(f\"Downloading vocab...\")\n",
    "    \n",
    "    os.system(f'gsutil -q cp {EXISTING_VOCAB_FILE} .')\n",
    "    print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "    filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "    vocab_dict = pkl.load(filehandler)\n",
    "    filehandler.close()\n",
    "    \n",
    "    for key in vocab_dict.keys():\n",
    "        pprint(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccaef62-882a-46ff-a1b1-3837e69fdf74",
   "metadata": {},
   "source": [
    "## helper functions\n",
    "\n",
    "**TODO:**\n",
    "* modularize in a train_utils or similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cba2bb14-bf94-466b-b60f-8c7d96c7aab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_outer_dimension(x):\n",
    "    \"\"\"Adds an extra outer dimension.\"\"\"\n",
    "    if isinstance(x, dict):\n",
    "        for key, value in x.items():\n",
    "            x[key] = tf.expand_dims(value, 1)\n",
    "        return x\n",
    "    return tf.expand_dims(x, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b941063b-ad48-4817-aef0-9afa8a444632",
   "metadata": {},
   "source": [
    "# Multi-Armed Bandits with Per-Arm Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28770b8d-836b-448d-8dd1-203d76fc6d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "\n",
    "nest = tf.nest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138a295-2b0d-4359-8496-af8552ec8cff",
   "metadata": {},
   "source": [
    "## Preprocessing layers for global and arm features\n",
    "\n",
    "The preproccesing layers will ultimately feed the two functions described below, both of which will ultimately feed the `Environment`\n",
    "\n",
    "`global_context_sampling_fn`: \n",
    "* A function that outputs a random 1d array or list of ints or floats\n",
    "* This output is the global context. Its shape and type must be consistent across calls.\n",
    "\n",
    "`arm_context_sampling_fn`: \n",
    "* A function that outputs a random 1 array or list of ints or floats (same type as the output of `global_context_sampling_fn`). * This output is the per-arm context. Its shape must be consistent across calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8d77956-635c-438a-916a-185eec52f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OOV_BUCKETS        = 1\n",
    "GLOBAL_EMBEDDING_SIZE  = 16\n",
    "MV_EMBEDDING_SIZE      = 32 #32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6142e63e-0a20-4d51-997c-7a4733517f7e",
   "metadata": {},
   "source": [
    "### global context (user) features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195acd92-06b6-42e4-bef7-798fd09da856",
   "metadata": {},
   "source": [
    "#### user ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c28e887b-421a-4603-8899-87071056783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_input_layer = tf.keras.Input(\n",
    "    name=\"user_id\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.string\n",
    ")\n",
    "\n",
    "user_id_lookup = tf.keras.layers.StringLookup(\n",
    "    max_tokens=len(vocab_dict['user_id']) + NUM_OOV_BUCKETS,\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    mask_token=None,\n",
    "    vocabulary=vocab_dict['user_id'],\n",
    ")(user_id_input_layer)\n",
    "\n",
    "user_id_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['user_id']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=GLOBAL_EMBEDDING_SIZE\n",
    ")(user_id_lookup)\n",
    "\n",
    "user_id_embedding = tf.reduce_sum(user_id_embedding, axis=-2)\n",
    "\n",
    "# global_inputs.append(user_id_input_layer)\n",
    "# global_features.append(user_id_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d6a0fe7-26cb-4c62-a3ef-17f98e6ccddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'681'], shape=(1,), dtype=string)\n",
      "tf.Tensor(\n",
      "[[ 0.01806823 -0.04779295  0.0041648   0.00260639  0.03467104  0.04654689\n",
      "   0.04471311  0.04795665  0.03117226 -0.04857733  0.03781874  0.00906665\n",
      "   0.02386748 -0.04607007 -0.04949344 -0.02612308]], shape=(1, 16), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_user_id_model = tf.keras.Model(inputs=user_id_input_layer, outputs=user_id_embedding)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(x[\"user_id\"])\n",
    "    print(test_user_id_model(x[\"user_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352d2227-92ec-4386-926f-df2fdb9434ec",
   "metadata": {},
   "source": [
    "#### user AGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70785bf0-5ece-4875-ab72-06d9c45ea9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_age_input_layer = tf.keras.Input(\n",
    "    name=\"bucketized_user_age\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "user_age_lookup = tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=vocab_dict['bucketized_user_age'],\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    oov_value=0,\n",
    ")(user_age_input_layer)\n",
    "\n",
    "user_age_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['bucketized_user_age']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=GLOBAL_EMBEDDING_SIZE\n",
    ")(user_age_lookup)\n",
    "\n",
    "user_age_embedding = tf.reduce_sum(user_age_embedding, axis=-2)\n",
    "\n",
    "# global_inputs.append(user_age_input_layer)\n",
    "# global_features.append(user_age_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e01622a-9418-4ca7-8925-9b0ebef8940e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([35.], shape=(1,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.02718775  0.00225193 -0.01391349  0.02715372  0.00741552 -0.01082809\n",
      "   0.04307974 -0.02445748  0.01875145  0.00548017  0.0299812   0.04886207\n",
      "   0.03581295  0.01254937  0.00118531  0.0196553 ]], shape=(1, 16), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_user_age_model = tf.keras.Model(inputs=user_age_input_layer, outputs=user_age_embedding)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(x[\"bucketized_user_age\"])\n",
    "    print(test_user_age_model(x[\"bucketized_user_age\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997ffaa8-ca92-4851-b7e3-bb06fba8958b",
   "metadata": {},
   "source": [
    "#### user OCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03e7344d-71fb-423a-89dd-f1abeb270e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_occ_input_layer = tf.keras.Input(\n",
    "    name=\"user_occupation_text\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.string\n",
    ")\n",
    "\n",
    "user_occ_lookup = tf.keras.layers.StringLookup(\n",
    "    max_tokens=len(vocab_dict['user_occupation_text']) + NUM_OOV_BUCKETS,\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    mask_token=None,\n",
    "    vocabulary=vocab_dict['user_occupation_text'],\n",
    ")(user_occ_input_layer)\n",
    "\n",
    "user_occ_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['user_occupation_text']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=GLOBAL_EMBEDDING_SIZE\n",
    ")(user_occ_lookup)\n",
    "\n",
    "user_occ_embedding = tf.reduce_sum(user_occ_embedding, axis=-2)\n",
    "\n",
    "# global_inputs.append(user_occ_input_layer)\n",
    "# global_features.append(user_occ_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39cbbc31-ca43-4f8f-a804-a4b830e99d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'marketing'], shape=(1,), dtype=string)\n",
      "tf.Tensor(\n",
      "[[-0.01417934  0.02128417 -0.04060601 -0.01150981  0.00822403  0.03577134\n",
      "  -0.02120326  0.04239904  0.04134711 -0.04658265  0.02343202 -0.03448397\n",
      "   0.03723052  0.04310123 -0.02240143  0.01510868]], shape=(1, 16), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_user_occ_model = tf.keras.Model(inputs=user_occ_input_layer, outputs=user_occ_embedding)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(x[\"user_occupation_text\"])\n",
    "    print(test_user_occ_model(x[\"user_occupation_text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee0098-a48a-4de6-88bf-6219ce8c0533",
   "metadata": {},
   "source": [
    "#### user Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61a4e01a-e742-4c68-93a9-aa66eb9a5e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ts_input_layer = tf.keras.Input(\n",
    "    name=\"timestamp\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.int64\n",
    ")\n",
    "\n",
    "user_ts_lookup = tf.keras.layers.Discretization(\n",
    "    vocab_dict['timestamp_buckets'].tolist()\n",
    ")(user_ts_input_layer)\n",
    "\n",
    "user_ts_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['timestamp_buckets'].tolist()) + NUM_OOV_BUCKETS,\n",
    "    output_dim=GLOBAL_EMBEDDING_SIZE\n",
    ")(user_ts_lookup)\n",
    "\n",
    "user_ts_embedding = tf.reduce_sum(user_ts_embedding, axis=-2)\n",
    "\n",
    "# global_inputs.append(user_ts_input_layer)\n",
    "# global_features.append(user_ts_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db99f90b-57f8-45e6-9f28-871658e17358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([885409515], shape=(1,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[-0.03811013  0.02838352 -0.03494694  0.0208756   0.03828151 -0.04900249\n",
      "  -0.02319418  0.02015351  0.04617448 -0.04039234 -0.00997448  0.0416292\n",
      "   0.03852597  0.03787447 -0.04810251 -0.01708328]], shape=(1, 16), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_user_ts_model = tf.keras.Model(inputs=user_ts_input_layer, outputs=user_ts_embedding)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(x[\"timestamp\"])\n",
    "    print(test_user_ts_model(x[\"timestamp\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc734ea-cb5e-4c6b-8b94-2a8853220178",
   "metadata": {},
   "source": [
    "#### define global sampling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff58c380-8b53-4dfa-b5b4-d36853638ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_global_context_features(x):\n",
    "    \"\"\"\n",
    "    This function generates a single global observation vector.\n",
    "    \"\"\"\n",
    "    user_id_value = x['user_id']\n",
    "    user_age_value = x['bucketized_user_age']\n",
    "    user_occ_value = x['user_occupation_text']\n",
    "    user_ts_value = x['timestamp']\n",
    "\n",
    "    _id = test_user_id_model(user_id_value) # input_tensor=tf.Tensor(shape=(4,), dtype=float32)\n",
    "    _age = test_user_age_model(user_age_value)\n",
    "    _occ = test_user_occ_model(user_occ_value)\n",
    "    _ts = test_user_ts_model(user_ts_value)\n",
    "\n",
    "    # # tmp - insepct numpy() values\n",
    "    # print(_id.numpy()) #[0])\n",
    "    # print(_age.numpy()) #[0])\n",
    "    # print(_occ.numpy()) #[0])\n",
    "    # print(_ts.numpy()) #[0])\n",
    "\n",
    "    # to numpy array\n",
    "    _id = np.array(_id.numpy())\n",
    "    _age = np.array(_age.numpy())\n",
    "    _occ = np.array(_occ.numpy())\n",
    "    _ts = np.array(_ts.numpy())\n",
    "\n",
    "    concat = np.concatenate(\n",
    "        [_id, _age, _occ, _ts], axis=-1 # -1\n",
    "    ).astype(np.float32)\n",
    "    \n",
    "    user_info = [\n",
    "                user_age_value.numpy(),\n",
    "                user_occ_value.numpy(),\n",
    "                user_ts_value.numpy(),\n",
    "                x['user_zip_code'].numpy(),\n",
    "                x['user_gender'].numpy(),\n",
    "                x['movie_title'].numpy(),\n",
    "                x['user_rating'].numpy()\n",
    "                ]\n",
    "\n",
    "    return concat, user_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d583b8f8-df19-4bfc-a963-81874d41523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1):\n",
    "    \n",
    "    iterator = iter(train_dataset.batch(5))\n",
    "    data = next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d693e5b-ab19-438c-b8eb-3be677e4c621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bucketized_user_age': <tf.Tensor: shape=(5,), dtype=float32, numpy=array([35., 18., 56., 45., 35.], dtype=float32)>,\n",
       " 'movie_genres': <tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n",
       " array([[7],\n",
       "        [4],\n",
       "        [9],\n",
       "        [4],\n",
       "        [7]])>,\n",
       " 'movie_id': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'898', b'367', b'484', b'494', b'58'], dtype=object)>,\n",
       " 'movie_title': <tf.Tensor: shape=(5,), dtype=string, numpy=\n",
       " array([b'Postman, The (1997)', b'Clueless (1995)',\n",
       "        b'Maltese Falcon, The (1941)', b'His Girl Friday (1940)',\n",
       "        b'Quiz Show (1994)'], dtype=object)>,\n",
       " 'timestamp': <tf.Tensor: shape=(5,), dtype=int64, numpy=array([885409515, 883388887, 891249586, 878044851, 880130613])>,\n",
       " 'user_gender': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'False', b'True', b'True', b'True', b'False'], dtype=object)>,\n",
       " 'user_id': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'681', b'442', b'932', b'506', b'18'], dtype=object)>,\n",
       " 'user_occupation_label': <tf.Tensor: shape=(5,), dtype=int64, numpy=array([14, 17,  0, 12, 11])>,\n",
       " 'user_occupation_text': <tf.Tensor: shape=(5,), dtype=string, numpy=\n",
       " array([b'marketing', b'student', b'educator', b'programmer', b'other'],\n",
       "       dtype=object)>,\n",
       " 'user_rating': <tf.Tensor: shape=(5,), dtype=float32, numpy=array([4., 2., 5., 5., 4.], dtype=float32)>,\n",
       " 'user_zip_code': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'97208', b'85282', b'06437', b'03869', b'37212'], dtype=object)>}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "557c2d7a-bac0-405b-904c-f05731abb8a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.01806823, -0.04779295,  0.0041648 ,  0.00260639,  0.03467104,\n",
       "          0.04654689,  0.04471311,  0.04795665,  0.03117226, -0.04857733,\n",
       "          0.03781874,  0.00906665,  0.02386748, -0.04607007, -0.04949344,\n",
       "         -0.02612308,  0.02718775,  0.00225193, -0.01391349,  0.02715372,\n",
       "          0.00741552, -0.01082809,  0.04307974, -0.02445748,  0.01875145,\n",
       "          0.00548017,  0.0299812 ,  0.04886207,  0.03581295,  0.01254937,\n",
       "          0.00118531,  0.0196553 , -0.01417934,  0.02128417, -0.04060601,\n",
       "         -0.01150981,  0.00822403,  0.03577134, -0.02120326,  0.04239904,\n",
       "          0.04134711, -0.04658265,  0.02343202, -0.03448397,  0.03723052,\n",
       "          0.04310123, -0.02240143,  0.01510868, -0.03811013,  0.02838352,\n",
       "         -0.03494694,  0.0208756 ,  0.03828151, -0.04900249, -0.02319418,\n",
       "          0.02015351,  0.04617448, -0.04039234, -0.00997448,  0.0416292 ,\n",
       "          0.03852597,  0.03787447, -0.04810251, -0.01708328],\n",
       "        [ 0.01173317,  0.0293087 , -0.03396907,  0.01711643, -0.04858625,\n",
       "          0.00351018,  0.04701899, -0.04647779, -0.02991669,  0.01095104,\n",
       "          0.04204906, -0.04339839, -0.00029627, -0.0112906 , -0.00929779,\n",
       "         -0.03638772, -0.03950529,  0.04482278, -0.02669758, -0.01762331,\n",
       "         -0.03353228,  0.01637063,  0.01606521, -0.02956507,  0.01227285,\n",
       "          0.0143383 , -0.00083748,  0.02973783, -0.03583926,  0.00885219,\n",
       "          0.01172044,  0.02544657,  0.04584629,  0.01297022,  0.04718215,\n",
       "          0.03409168,  0.03398237, -0.03476388,  0.03408717, -0.0354223 ,\n",
       "          0.00389145,  0.00050206, -0.0081876 ,  0.01306553,  0.04224047,\n",
       "         -0.0145766 , -0.00426328, -0.02153074, -0.02318552, -0.03583523,\n",
       "          0.04536982, -0.0305141 ,  0.01555479,  0.04526097, -0.04332656,\n",
       "         -0.00195814, -0.0350917 ,  0.01664541,  0.01590312, -0.03707576,\n",
       "         -0.01403153,  0.0002805 , -0.02755331,  0.00687481],\n",
       "        [-0.03471743,  0.04015321,  0.00841215, -0.01088787, -0.02831354,\n",
       "         -0.03262772,  0.00405797,  0.03148032,  0.0421175 ,  0.03174043,\n",
       "         -0.00624854, -0.00304792,  0.03763758, -0.00867292,  0.02088115,\n",
       "          0.03058859,  0.00143541, -0.03251796, -0.02034678,  0.00428031,\n",
       "          0.00874201, -0.02303927,  0.00914434,  0.03833867,  0.02564324,\n",
       "          0.0032326 , -0.04057788,  0.00293385,  0.0341619 ,  0.01757983,\n",
       "         -0.01149748, -0.04979226,  0.04011757,  0.01918549,  0.03695825,\n",
       "          0.00741087, -0.01357064, -0.0258343 , -0.01097918, -0.04742093,\n",
       "         -0.04662563,  0.0042192 , -0.03271295,  0.04809156,  0.02206084,\n",
       "         -0.04144447,  0.02869156, -0.01365932,  0.01316292, -0.03858906,\n",
       "          0.02204936, -0.02498662,  0.02982428, -0.03526814, -0.04905478,\n",
       "          0.04068147, -0.01342503, -0.01356005, -0.02836603, -0.0406018 ,\n",
       "          0.00989036,  0.04270283,  0.00949628,  0.00769355],\n",
       "        [-0.00636433,  0.03970108,  0.02669746, -0.00746797, -0.02058232,\n",
       "         -0.02827929,  0.00499749,  0.03996731, -0.02334701,  0.02663143,\n",
       "         -0.00470978, -0.02371551,  0.00242852,  0.03128088, -0.02678161,\n",
       "         -0.02482939,  0.01441741,  0.03527644,  0.04839798, -0.00723649,\n",
       "         -0.04068597,  0.03264995,  0.03739417, -0.01903692,  0.04983873,\n",
       "         -0.04024289,  0.04025416, -0.02726499,  0.04826218, -0.03987173,\n",
       "         -0.00078481, -0.02234128, -0.04833729,  0.03621793,  0.00123948,\n",
       "          0.0167386 ,  0.03443152,  0.03188882,  0.02605389, -0.00063732,\n",
       "         -0.01944311, -0.01463698,  0.04351887, -0.0486164 ,  0.01987514,\n",
       "          0.04338953,  0.02011541, -0.03729993, -0.02571519, -0.02783617,\n",
       "          0.00047718,  0.0064139 ,  0.0271816 ,  0.00558853, -0.01919349,\n",
       "          0.03225571,  0.00058745, -0.0291437 ,  0.02863275,  0.03086693,\n",
       "         -0.02339052,  0.00229885, -0.04424715, -0.01754788],\n",
       "        [-0.03043634, -0.02506465, -0.01943783,  0.02123902, -0.03108054,\n",
       "         -0.02677798, -0.02265912, -0.01491805,  0.02675171, -0.03068452,\n",
       "          0.02056048, -0.01812191,  0.04515609, -0.0434021 ,  0.03926954,\n",
       "          0.00318621,  0.02718775,  0.00225193, -0.01391349,  0.02715372,\n",
       "          0.00741552, -0.01082809,  0.04307974, -0.02445748,  0.01875145,\n",
       "          0.00548017,  0.0299812 ,  0.04886207,  0.03581295,  0.01254937,\n",
       "          0.00118531,  0.0196553 ,  0.02305026,  0.03120137,  0.00100931,\n",
       "         -0.04339117, -0.03806695, -0.00190886,  0.03448367,  0.04234156,\n",
       "          0.03478875,  0.00493959,  0.01936454, -0.02355268,  0.03048946,\n",
       "         -0.02013915, -0.01231258, -0.02884197,  0.04199347,  0.03215679,\n",
       "         -0.04542422, -0.01687073,  0.0104754 , -0.0295318 , -0.0394967 ,\n",
       "          0.01927583,  0.03304518, -0.03488532,  0.03686247, -0.0479085 ,\n",
       "          0.03990734, -0.00661734,  0.02360663,  0.04208832]],\n",
       "       dtype=float32),\n",
       " [array([35., 18., 56., 45., 35.], dtype=float32),\n",
       "  array([b'marketing', b'student', b'educator', b'programmer', b'other'],\n",
       "        dtype=object),\n",
       "  array([885409515, 883388887, 891249586, 878044851, 880130613]),\n",
       "  array([b'97208', b'85282', b'06437', b'03869', b'37212'], dtype=object),\n",
       "  array([b'False', b'True', b'True', b'True', b'False'], dtype=object),\n",
       "  array([b'Postman, The (1997)', b'Clueless (1995)',\n",
       "         b'Maltese Falcon, The (1941)', b'His Girl Friday (1940)',\n",
       "         b'Quiz Show (1994)'], dtype=object),\n",
       "  array([4., 2., 5., 5., 4.], dtype=float32)])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_get_global_context_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c9f64a0-a713-49bc-9043-d6e9598ecc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #check how this works with batches - new JW\n",
    "\n",
    "# batch_elem = train_dataset.batch(4)\n",
    "# _get_global_context_features(batch_elem)\n",
    "_get_global_context_features(data)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bba133ab-bf12-4b3b-926d-6d1dba940837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01806823, -0.04779295,  0.0041648 ,  0.00260639,  0.03467104,\n",
       "         0.04654689,  0.04471311,  0.04795665,  0.03117226, -0.04857733,\n",
       "         0.03781874,  0.00906665,  0.02386748, -0.04607007, -0.04949344,\n",
       "        -0.02612308,  0.02718775,  0.00225193, -0.01391349,  0.02715372,\n",
       "         0.00741552, -0.01082809,  0.04307974, -0.02445748,  0.01875145,\n",
       "         0.00548017,  0.0299812 ,  0.04886207,  0.03581295,  0.01254937,\n",
       "         0.00118531,  0.0196553 , -0.01417934,  0.02128417, -0.04060601,\n",
       "        -0.01150981,  0.00822403,  0.03577134, -0.02120326,  0.04239904,\n",
       "         0.04134711, -0.04658265,  0.02343202, -0.03448397,  0.03723052,\n",
       "         0.04310123, -0.02240143,  0.01510868, -0.03811013,  0.02838352,\n",
       "        -0.03494694,  0.0208756 ,  0.03828151, -0.04900249, -0.02319418,\n",
       "         0.02015351,  0.04617448, -0.04039234, -0.00997448,  0.0416292 ,\n",
       "         0.03852597,  0.03787447, -0.04810251, -0.01708328]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in train_dataset.batch(1).take(1):\n",
    "    test_globals = _get_global_context_features(x)[0]\n",
    "\n",
    "\n",
    "test_globals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249fa771-35d7-4d04-ab68-2b70911bac17",
   "metadata": {},
   "source": [
    "### arm preprocessing layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534b3bf1-a2ea-4bfb-8c77-efa057f4e391",
   "metadata": {},
   "source": [
    "#### movie ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa53cbe9-2616-4da4-90dc-dc5616258af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_id_input_layer = tf.keras.Input(\n",
    "    name=\"movie_id\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.string\n",
    ")\n",
    "\n",
    "mv_id_lookup = tf.keras.layers.StringLookup(\n",
    "    max_tokens=len(vocab_dict['movie_id']) + NUM_OOV_BUCKETS,\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    mask_token=None,\n",
    "    vocabulary=vocab_dict['movie_id'],\n",
    ")(mv_id_input_layer)\n",
    "\n",
    "mv_id_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['movie_id']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=MV_EMBEDDING_SIZE\n",
    ")(mv_id_lookup)\n",
    "\n",
    "mv_id_embedding = tf.reduce_sum(mv_id_embedding, axis=-2)\n",
    "\n",
    "# arm_inputs.append(mv_id_input_layer)\n",
    "# arm_features.append(mv_id_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9bd19f09-a12e-4a21-a1a1-5ec5bc116559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'898'], shape=(1,), dtype=string)\n",
      "tf.Tensor(\n",
      "[[ 0.0149034   0.02211714 -0.03610321  0.031705    0.02543335 -0.01570002\n",
      "  -0.03275279  0.01593149 -0.02251795 -0.02397108 -0.04835068 -0.01613964\n",
      "   0.00015687 -0.02030194  0.02126869 -0.0016198  -0.02628407  0.02753797\n",
      "   0.02957105  0.00014911  0.02806291 -0.04617434 -0.04885953 -0.00116618\n",
      "  -0.00473685  0.04056     0.03152457 -0.01354893 -0.04464444  0.03381531\n",
      "  -0.02021343  0.00452866]], shape=(1, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_mv_id_model = tf.keras.Model(inputs=mv_id_input_layer, outputs=mv_id_embedding)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(x[\"movie_id\"])\n",
    "    print(test_mv_id_model(x[\"movie_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4a0e97-c477-4042-b9c0-fcb0f428de0d",
   "metadata": {},
   "source": [
    "#### movie genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f04a0091-d7b0-4f90-ba7c-3eb41dd0b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_genre_input_layer = tf.keras.Input(\n",
    "    name=\"movie_genres\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "mv_genre_lookup = tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=vocab_dict['movie_genres'],\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    oov_value=0,\n",
    ")(mv_genre_input_layer)\n",
    "\n",
    "mv_genre_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['movie_genres']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=MV_EMBEDDING_SIZE\n",
    ")(mv_genre_lookup)\n",
    "\n",
    "mv_genre_embedding = tf.reduce_sum(mv_genre_embedding, axis=-2)\n",
    "\n",
    "# arm_inputs.append(mv_genre_input_layer)\n",
    "# arm_features.append(mv_genre_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51701f0a-9b3e-461c-a9d9-a0c146e310ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[7]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([b'898'], shape=(1,), dtype=string)\n",
      "tf.Tensor(\n",
      "[[-0.04108281  0.02260021 -0.04625281  0.04728014 -0.02532916 -0.03725855\n",
      "  -0.03479556  0.00253215 -0.04513829  0.03330678  0.01455655  0.00140586\n",
      "   0.01602683 -0.01841575 -0.04826682 -0.03074406  0.01182368 -0.03827454\n",
      "  -0.0363717   0.01902633 -0.04306298 -0.03306596 -0.03464795  0.04399362\n",
      "   0.0038408  -0.04657231  0.0177225   0.01950773  0.04313185 -0.0398006\n",
      "   0.01336098 -0.00219304]], shape=(1, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_mv_gen_model = tf.keras.Model(inputs=mv_genre_input_layer, outputs=mv_genre_embedding)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(x[\"movie_genres\"])\n",
    "    print(x[\"movie_id\"])\n",
    "    print(test_mv_gen_model(x[\"movie_genres\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b41cc9-63f5-4559-a943-1288be9c0892",
   "metadata": {},
   "source": [
    "#### define sampling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8727904e-e9b6-4005-8cf3-9da461ca88b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_per_arm_features(x):\n",
    "    \"\"\"\n",
    "    This function generates a single per-arm observation vector\n",
    "    \"\"\"\n",
    "    mv_id_value = x['movie_id']\n",
    "    mv_gen_value = x['movie_genres']\n",
    "\n",
    "    _mid = test_mv_id_model(mv_id_value)\n",
    "    _mgen = test_mv_gen_model(mv_gen_value)\n",
    "\n",
    "    # to numpy array\n",
    "    _mid = np.array(_mid.numpy())\n",
    "    _mgen = np.array(_mgen.numpy())\n",
    "\n",
    "    # print(_mid)\n",
    "    # print(_mgen)\n",
    "\n",
    "    concat = np.concatenate(\n",
    "        [_mid, _mgen], axis=-1 # -1\n",
    "    ).astype(np.float32)\n",
    "    # concat = tf.concat([_mid, _mgen], axis=-1).astype(np.float32)\n",
    "\n",
    "    return concat #this is special to this example - there is only one action dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78d3c6bb-e525-4408-b321-34ac9684f881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_get_per_arm_features(data).shape #shape checks out at batchdim, nactions, arm feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ff5764-25de-4f4c-ada3-3a417bdf22b5",
   "metadata": {},
   "source": [
    "### Create a moive lookup Table ðŸ†•\n",
    "\n",
    "This will be used in our trajectories to randomly select a movie. Using the produced embeddings, we will also have a reward function for each combination by taking the inner product via `tf_agents.bandits.networks.global_and_arm_feature_network.create_feed_forward_dot_product_network` [link](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/create_feed_forward_dot_product_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "770c3473-622f-44eb-b512-e96c4b08a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_lookup_table = {'id': [],\n",
    "                      'movie_features': [],\n",
    "                      'movie_title': [],\n",
    "                      'movie_genres': []\n",
    "                     }\n",
    "    \n",
    "iterator = iter(train_dataset.batch(1000))\n",
    "for data in iterator:\n",
    "    _get_per_arm_features(data)\n",
    "    movie_lookup_table['id'].extend(data['movie_id'].numpy())\n",
    "    movie_lookup_table['movie_title'].extend(data['movie_title'].numpy())\n",
    "    movie_lookup_table['movie_genres'].extend(data['movie_genres'].numpy())\n",
    "    movie_lookup_table['movie_features'].extend(_get_per_arm_features(data))\n",
    "    \n",
    "#fix string ids to integers for random lookup later\n",
    "movie_lookup_table['id'] = [int(x) for x in movie_lookup_table['id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66eed76c-79c2-415e-8dd9-e4ee85b5e769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "movie_lookup_table = pd.DataFrame(movie_lookup_table)\n",
    "movie_lookup_table.set_index(['id'])\n",
    "\n",
    "unique_table = movie_lookup_table.groupby(['id'])[['movie_features', 'movie_title', 'movie_genres']].first().reset_index() #resetting index to get consecutive counts from min-max (no gaps)\n",
    "# unique_table = unique_table['movie_features']\n",
    "MAX_ARM_ID = len(unique_table)-1\n",
    "MIN_ARM_ID = 0\n",
    "\n",
    "# unique_table\n",
    "# print(f\"Max movie id is: {MAX_ARM_ID} \\nMin movie id is: {MIN_ARM_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8184ea44-5ae0-4986-922b-57ee76cc4783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04881153, -0.00451051, -0.0166389 ,  0.01546183, -0.02877082,\n",
       "        0.02816169, -0.01822083, -0.02082814, -0.00335509, -0.0418419 ,\n",
       "       -0.03711364, -0.03304502,  0.00269406, -0.02664441,  0.0091985 ,\n",
       "        0.04296811,  0.00957156, -0.04182948,  0.00317786,  0.03292357,\n",
       "        0.04554881,  0.04275218, -0.01824564, -0.02239871, -0.03127362,\n",
       "       -0.01298369, -0.00058763, -0.0232707 , -0.04251892, -0.01675228,\n",
       "       -0.02531035,  0.04032182,  0.01051295, -0.01857275, -0.02356436,\n",
       "        0.026142  , -0.00813157, -0.02341809, -0.04312834,  0.02744973,\n",
       "       -0.00385386,  0.02135359,  0.01841906, -0.02394762, -0.00963492,\n",
       "       -0.00694396,  0.00531589, -0.04025782, -0.00825388,  0.01376517,\n",
       "       -0.00647968,  0.04013718, -0.04550926,  0.01558368,  0.03223891,\n",
       "       -0.01988158,  0.03520492,  0.01223153,  0.0065089 , -0.02247771,\n",
       "       -0.00966214,  0.00816732,  0.02844465, -0.03767228], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_table.iloc[2,:]['movie_features'] #example of getting a ra movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6284375d-410c-4cd5-be8b-3889d39f98b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 64), dtype=float32, numpy=\n",
       " array([[ 8.38041306e-05,  3.02394368e-02, -5.36654145e-03,\n",
       "         -2.36439463e-02, -3.80471945e-02,  9.83384997e-03,\n",
       "          3.47963683e-02,  4.03387062e-02, -2.36513503e-02,\n",
       "          1.18945129e-02, -2.76782271e-02, -4.95838411e-02,\n",
       "         -2.43660063e-03,  4.06836346e-03, -2.22729687e-02,\n",
       "          1.92618109e-02, -4.80554961e-02,  4.89595868e-02,\n",
       "         -2.33495366e-02, -4.86886986e-02, -1.24010816e-02,\n",
       "         -1.65898688e-02, -3.28477845e-02,  1.70088075e-02,\n",
       "         -1.30626932e-02, -3.71491425e-02, -4.85267043e-02,\n",
       "         -3.47499736e-02, -8.91630724e-03, -2.32504681e-03,\n",
       "         -1.18386000e-04,  4.61189635e-02, -4.10828106e-02,\n",
       "          2.26002075e-02, -4.62528132e-02,  4.72801439e-02,\n",
       "         -2.53291614e-02, -3.72585543e-02, -3.47955599e-02,\n",
       "          2.53214687e-03, -4.51382883e-02,  3.33067812e-02,\n",
       "          1.45565532e-02,  1.40585750e-03,  1.60268284e-02,\n",
       "         -1.84157491e-02, -4.82668169e-02, -3.07440646e-02,\n",
       "          1.18236765e-02, -3.82745378e-02, -3.63716967e-02,\n",
       "          1.90263279e-02, -4.30629849e-02, -3.30659635e-02,\n",
       "         -3.46479528e-02,  4.39936183e-02,  3.84080410e-03,\n",
       "         -4.65723053e-02,  1.77224986e-02,  1.95077322e-02,\n",
       "          4.31318544e-02, -3.98005955e-02,  1.33609809e-02,\n",
       "         -2.19304487e-03]], dtype=float32)>,\n",
       " [b'Sling Blade (1996)', array([7])])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_random_arm_features(movie_id):\n",
    "    movie_info = unique_table.iloc[movie_id]\n",
    "    tensor = tf.constant(movie_info['movie_features'], dtype=tf.float32)\n",
    "    return tf.reshape(tensor, [1, tensor.shape[0]]), [movie_info['movie_title'],\n",
    "                                                     movie_info['movie_genres']]\n",
    "\n",
    "get_random_arm_features(222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4502fdb6-26ff-46d2-8bb4-1bcf5a06eff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_random_set_of_arm_features(n_actions, batch_size):\n",
    "#     random_arm_ids = list(np.random.randint(MIN_ARM_ID, MAX_ARM_ID, [n_actions, batch_size]))\n",
    "#     features = [[get_random_arm_features(y)for  y in x] for x in random_arm_ids]\n",
    "\n",
    "\n",
    "#     just_features = []\n",
    "#     movie_info = []\n",
    "\n",
    "#     for batch in features:\n",
    "#         mv_batch = []\n",
    "#         ft_batch = []\n",
    "#         for movie in batch:\n",
    "#             mv_batch.append(movie[1])\n",
    "#             ft_batch.append(movie[0])\n",
    "\n",
    "#         just_features.append(ft_batch)\n",
    "#         movie_info.append(mv_batch)\n",
    "        \n",
    "#     return tf.concat(just_features, axis=1), movie_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "56f020a5-9ac8-46b7-b4b5-257a5cd03398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_set_of_arm_features(n_actions):\n",
    "    random_arm_ids = list(np.random.randint(MIN_ARM_ID, MAX_ARM_ID, n_actions))\n",
    "    features = [get_random_arm_features(x) for x in random_arm_ids]\n",
    "    just_features = [x[0] for x in features]\n",
    "    movie_info = [x[1] for x in features]\n",
    "    return tf.concat(just_features, axis=0), movie_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a334c538-6dab-4db3-9593-8621d5ef060c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 64), dtype=float32, numpy=\n",
       "array([[-0.00704504, -0.02894876, -0.02593981,  0.02846244,  0.02729566,\n",
       "         0.03877437,  0.01572851,  0.03836662, -0.04739806, -0.02195525,\n",
       "        -0.03798313,  0.01314006, -0.01090568,  0.03565491, -0.04115955,\n",
       "         0.02945197, -0.04002921,  0.03033074, -0.0204521 ,  0.02910561,\n",
       "        -0.04632826, -0.04656759,  0.04557437,  0.02404306, -0.04186109,\n",
       "         0.00141704,  0.00457773, -0.00373795, -0.02787418, -0.01240032,\n",
       "         0.00062846,  0.04642929, -0.02574708,  0.00729937,  0.00595119,\n",
       "        -0.00136894,  0.03951862,  0.04841298, -0.00172037, -0.01568767,\n",
       "        -0.04754845, -0.0355254 , -0.00015395, -0.01126096, -0.04017977,\n",
       "        -0.01770066,  0.00559515,  0.03037573, -0.03001535, -0.03416227,\n",
       "        -0.0309287 ,  0.00176487, -0.0041039 ,  0.04686356,  0.04547942,\n",
       "         0.04412935,  0.01597119,  0.00169616,  0.04641579,  0.02780335,\n",
       "        -0.01954033, -0.00605553,  0.01523167,  0.00339165],\n",
       "       [-0.01073702,  0.02387163, -0.03521882,  0.02702073,  0.02963071,\n",
       "         0.00853948,  0.04945524,  0.0436081 , -0.04537084, -0.04633017,\n",
       "         0.02634652, -0.01416529,  0.00772785,  0.04382309,  0.01704402,\n",
       "         0.04883612,  0.02491847,  0.0176635 , -0.01819286, -0.03077033,\n",
       "        -0.01333935, -0.04955557, -0.03517041,  0.00962341,  0.01710308,\n",
       "         0.03209126, -0.01857569, -0.0214734 ,  0.01472447, -0.01954681,\n",
       "         0.01022177, -0.02481314,  0.00299861, -0.04809837, -0.04475717,\n",
       "        -0.03696201, -0.00614906, -0.00336434, -0.03949549, -0.01404626,\n",
       "         0.00904559,  0.03600294, -0.00646951,  0.03900558,  0.01455874,\n",
       "        -0.01343437, -0.03973825,  0.01111577,  0.02957846, -0.02831782,\n",
       "        -0.04426804,  0.04903812,  0.01541027,  0.02045632,  0.00811329,\n",
       "         0.00508104, -0.02082465, -0.00291753,  0.04763483,  0.04439448,\n",
       "         0.02113673,  0.03821741, -0.04563451,  0.03276036]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_set_of_arm_features(n_actions=2)[0] #NEW - there's a tuple returned with the movies we will use for PALM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a52c9f62-04f9-4f50-912c-d2f75b5f6986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([35., 18., 56., 45., 35., 25., 25., 35.], dtype=float32), array([b'marketing', b'student', b'educator', b'programmer', b'other',\n",
      "       b'programmer', b'other', b'executive'], dtype=object), array([885409515, 883388887, 891249586, 878044851, 880130613, 892778202,\n",
      "       879959212, 877131685]), array([b'97208', b'85282', b'06437', b'03869', b'37212', b'55414',\n",
      "       b'06405', b'L1V3W'], dtype=object), array([b'False', b'True', b'True', b'True', b'False', b'True', b'False',\n",
      "       b'True'], dtype=object), array([b'Postman, The (1997)', b'Clueless (1995)',\n",
      "       b'Maltese Falcon, The (1941)', b'His Girl Friday (1940)',\n",
      "       b'Quiz Show (1994)', b\"Carlito's Way (1993)\",\n",
      "       b'Primal Fear (1996)', b'Aladdin (1992)'], dtype=object), array([4., 2., 5., 5., 4., 4., 5., 4.], dtype=float32)] [[b'Hot Shots! Part Deux (1993)', array([0])], [b'Tommy Boy (1995)', array([4])], [b'Tales from the Hood (1995)', array([4])], [b'Don Juan DeMarco (1995)', array([4])], [b'Passion Fish (1992)', array([7])]]\n"
     ]
    }
   ],
   "source": [
    "### Look at the raw input features to format a good prompt for ranking movies\n",
    "NUM_ACTIONS = 5\n",
    "batch_size = 8\n",
    "iterator = iter(train_dataset.batch(batch_size))\n",
    "data = next(iterator)\n",
    "\n",
    "_, user_info = _get_global_context_features(data) #new - user info passes on the raw user features for prompting with PALM\n",
    "###NEW - we are getting the arm features here\n",
    "_, movie_info = get_random_set_of_arm_features(n_actions=NUM_ACTIONS)\n",
    "\n",
    "print(user_info, movie_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f331390-f23b-4f41-a218-2a9211fba9c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wed Jan 21 19:05:15 1998'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "dt = datetime.utcfromtimestamp(885409515)\n",
    "dt.ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce9675e3-1a41-4533-b9fa-7fd02bba84c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[b'Hot Shots! Part Deux (1993)', array([0])],\n",
       " [b'Tommy Boy (1995)', array([4])],\n",
       " [b'Tales from the Hood (1995)', array([4])],\n",
       " [b'Don Juan DeMarco (1995)', array([4])],\n",
       " [b'Passion Fish (1992)', array([7])]]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf81d87-00c0-40f6-ae0e-0fa9a1e7aa7a",
   "metadata": {},
   "source": [
    "### Feature formats info\n",
    "https://www.tensorflow.org/datasets/catalog/movielens\n",
    "BUCKETIZED AGE\n",
    "```python\n",
    "{\n",
    "'1': \"Under 18\"\n",
    "'18': \"18-24\"\n",
    "'25': \"25-34\"\n",
    "'35': \"35-44\"\n",
    "'45': \"45-49\"\n",
    "'50': \"50-55\"\n",
    "'56': \"56+\"\n",
    "}\n",
    "```\n",
    "\n",
    "https://files.grouplens.org/datasets/movielens/ml-10m-README.html\n",
    "\n",
    "```python\n",
    "genre_list = \n",
    "[\n",
    "\"Action\",\n",
    "\"Adventure\",\n",
    "\"Animation\",\n",
    "\"Children's\",\n",
    "\"Comedy\",\n",
    "\"Crime\",\n",
    "\"Documentary\",\n",
    "\"Drama\",\n",
    "\"Fantasy\",\n",
    "\"Film-Noir\",\n",
    "\"Horror\",\n",
    "\"Musical\",\n",
    "\"Mystery\",\n",
    "\"Romance\",\n",
    "\"Sci-Fi\",\n",
    "\"Thriller\",\n",
    "\"War\",\n",
    "\"Western\",\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a804c78a-40b3-4b4c-85ff-b8810e93192d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You are looking to watch a movie and need to rate each movie based on user '\n",
      " 'demographics \\n'\n",
      " 'Here are some info on this the user: \\n'\n",
      " 'the user is age is 35-44, n\\n'\n",
      " 'and lives in zipcode 97208\\n'\n",
      " \"the user's occupation is marketing \\n\"\n",
      " 'the user previously reviewed Postman, The (1997), \\n'\n",
      " 'giving it a 4 out five star review during Wed Jan 21 19:05:15 1998\\n'\n",
      " '    \\n'\n",
      " 'Please rate these movies below using using \\n'\n",
      " '5 - highly recomended movie\\n'\n",
      " '4 - somewhat recommend movie\\n'\n",
      " '3 - maybe watch movie\\n'\n",
      " '2 - not a good movie\\n'\n",
      " '1 - really bad movie\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '1. Hot Shots! Part Deux (1993), Action\\n'\n",
      " '2. Tommy Boy (1995), Comedy\\n'\n",
      " '3. Tales from the Hood (1995), Comedy\\n'\n",
      " '4. Don Juan DeMarco (1995), Comedy\\n'\n",
      " '5. Passion Fish (1992), Drama\\n'\n",
      " ' please rate the 5 movies\\n'\n",
      " ' ensure you return the ratings as a python list of just the ratings for 5 '\n",
      " 'movies')\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "age_text_lookup = {\n",
    "'1': \"Under 18\",\n",
    "'18': \"18-24\",\n",
    "'25': \"25-34\",\n",
    "'35': \"35-44\",\n",
    "'45': \"45-49\",\n",
    "'50': \"50-55\",\n",
    "'56': \"56+\"\n",
    "}\n",
    "\n",
    "genre_list = [\n",
    "    \"Action\",\n",
    "    \"Adventure\",\n",
    "    \"Animation\",\n",
    "    \"Children's\",\n",
    "    \"Comedy\",\n",
    "    \"Crime\",\n",
    "    \"Documentary\",\n",
    "    \"Drama\",\n",
    "    \"Fantasy\",\n",
    "    \"Film-Noir\",\n",
    "    \"Horror\",\n",
    "    \"Musical\",\n",
    "    \"Mystery\",\n",
    "    \"Romance\",\n",
    "    \"Sci-Fi\",\n",
    "    \"Thriller\",\n",
    "    \"War\",\n",
    "    \"Western\",\n",
    "] #use this to lookup genres\n",
    "\n",
    "def gender_movielens_translator(elem):\n",
    "    if elem==\"True\":\n",
    "        return \"male\" \n",
    "    else:\n",
    "        return \"non-male\"\n",
    "\n",
    "rating_scale = '''\n",
    "5 - highly recomended movie\n",
    "4 - somewhat recommend movie\n",
    "3 - maybe watch movie\n",
    "2 - not a good movie\n",
    "1 - really bad movie\n",
    "'''\n",
    "\n",
    "age, occ, time, zipcode, gender, ex_movie, ex_movie_rating = user_info[0], user_info[1], user_info[2], user_info[3], user_info[4], user_info[5], user_info[6]\n",
    "\n",
    "prompts = []\n",
    "for i in range(len(age)):\n",
    "    formatted_datetime = datetime.utcfromtimestamp(time[i]).ctime()\n",
    "    gender = gender_movielens_translator(gender[i])\n",
    "    prompt = f\"\"\"You are looking to watch a movie and need to rate each movie based on user demographics \n",
    "Here are some info on this the user: \n",
    "the user is age is {age_text_lookup[str(int(age[i]))]}, {gender[i]}\n",
    "and lives in zipcode {zipcode[i].decode(\"utf-8\")}\n",
    "the user's occupation is {occ[i].decode(\"utf-8\")} \n",
    "the user previously reviewed {ex_movie[i].decode(\"utf-8\")}, \n",
    "giving it a {int(ex_movie_rating[i])} out five star review during {formatted_datetime}\n",
    "    \n",
    "Please rate these movies below using using {rating_scale}\n",
    "\"\"\"\n",
    "    \n",
    "    for j, movie in enumerate(movie_info):\n",
    "        try:\n",
    "            genre = genre_list[movie[1][0]]\n",
    "        except:\n",
    "            genre = 'NA'\n",
    "        prompt += f\"\\n{j+1}. {movie[0].decode('utf-8')}, {genre}\"\n",
    "        total_movies = j+1\n",
    "    prompt += f\"\\n please rate the {total_movies} movies\"\n",
    "    prompt += f\"\\n ensure you return the ratings as a python list of just the ratings for {total_movies} movies\"\n",
    "        \n",
    "    ## next add in the movie selections\n",
    "    prompts.append(prompt)\n",
    "pprint(prompts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a03c7f6d-9825-4923-b984-376e4ddd16b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[b'Hot Shots! Part Deux (1993)', array([0])],\n",
       " [b'Tommy Boy (1995)', array([4])],\n",
       " [b'Tales from the Hood (1995)', array([4])],\n",
       " [b'Don Juan DeMarco (1995)', array([4])],\n",
       " [b'Passion Fish (1992)', array([7])]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb050b77-ede5-4745-a166-6ade8e401c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RL_prompt(user_info, movie_info):\n",
    "    \n",
    "    age, occ, time, zipcode, gender, ex_movie, ex_movie_rating = user_info[0], user_info[1], user_info[2], user_info[3], user_info[4], user_info[5], user_info[6]\n",
    "\n",
    "    prompts = []\n",
    "    for i in range(len(age)):\n",
    "        formatted_datetime = datetime.utcfromtimestamp(time[i]).ctime()\n",
    "        gender = gender_movielens_translator(gender[i])\n",
    "        prompt = f\"\"\"You are looking to watch a movie and need to rate each movie based on user demographics \n",
    "Here are some info on this the user: \n",
    "the user is age is {age_text_lookup[str(int(age[i]))]}, {gender[i]}\n",
    "and lives in zipcode {zipcode[i].decode(\"utf-8\")}\n",
    "the user's occupation is {occ[i].decode(\"utf-8\")} \n",
    "the user previously reviewed {ex_movie[i].decode(\"utf-8\")}, \n",
    "giving it a {int(ex_movie_rating[i])} out five star review during {formatted_datetime}\n",
    "\n",
    "Please rate these movies below using using {rating_scale} in order in a comma seperated list\n",
    "    \"\"\"\n",
    "        for j, movie in enumerate(movie_info):\n",
    "            try:\n",
    "                genre = genre_list[movie[1][0]]\n",
    "            except:\n",
    "                genre = 'NA'\n",
    "            prompt += f\"\\n{j+1}. {movie[0].decode('utf-8')}, {genre}\"\n",
    "        prompt += f\"\\n please rate the {j+1} movies\"\n",
    "        prompt += f\"\\n ensure you return the numeric float ratings in a comma seperated list for eaxtly {j+1} movies:\"\n",
    "        prompts.append(prompt)\n",
    "    return prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "697199de-e949-4533-affb-a8c96563c55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You are looking to watch a movie and need to rate each movie based on user '\n",
      " 'demographics \\n'\n",
      " 'Here are some info on this the user: \\n'\n",
      " 'the user is age is 35-44, n\\n'\n",
      " 'and lives in zipcode 97208\\n'\n",
      " \"the user's occupation is marketing \\n\"\n",
      " 'the user previously reviewed Postman, The (1997), \\n'\n",
      " 'giving it a 4 out five star review during Wed Jan 21 19:05:15 1998\\n'\n",
      " '\\n'\n",
      " 'Please rate these movies below using using \\n'\n",
      " '5 - highly recomended movie\\n'\n",
      " '4 - somewhat recommend movie\\n'\n",
      " '3 - maybe watch movie\\n'\n",
      " '2 - not a good movie\\n'\n",
      " '1 - really bad movie\\n'\n",
      " ' in order in a comma seperated list\\n'\n",
      " '    \\n'\n",
      " '1. Hot Shots! Part Deux (1993), Action\\n'\n",
      " '2. Tommy Boy (1995), Comedy\\n'\n",
      " '3. Tales from the Hood (1995), Comedy\\n'\n",
      " '4. Don Juan DeMarco (1995), Comedy\\n'\n",
      " '5. Passion Fish (1992), Drama\\n'\n",
      " ' please rate the 5 movies\\n'\n",
      " ' ensure you return the numeric float ratings in a comma seperated list for '\n",
      " 'eaxtly 5 movies:')\n"
     ]
    }
   ],
   "source": [
    "prompts = RL_prompt(user_info, movie_info)\n",
    "\n",
    "len(prompts)\n",
    "pprint(prompts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3458f058-6346-4636-97db-f8fa02e89984",
   "metadata": {},
   "source": [
    "## Adding in reward function with PALM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a1526b43-e69e-4d35-9145-05d0c2aaee18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am doing well today, thank you for asking! I am excited to be learning more about natural language processing and how it can be used to improve the customer experience.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Adding in reward function with PALM!\n",
    "\n",
    "import vertexai\n",
    "from vertexai.language_models import TextGenerationModel\n",
    "\n",
    "vertexai.init(project=\"wortz-project-352116\", location=\"us-central1\")\n",
    "parameters = {\n",
    "    \"temperature\": 0.0,\n",
    "    \"max_output_tokens\": 400,\n",
    "    \"top_p\": 0.8,\n",
    "    \"top_k\": 40\n",
    "}\n",
    "llm = TextGenerationModel.from_pretrained(\"text-bison\")\n",
    "response = llm.predict(\n",
    "    \"How are you today?\",\n",
    "    **parameters\n",
    ")\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b7223dca-5b0a-42a4-bea8-857e14649535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4, 4, 3, 4, 3'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "### Test prompt!\n",
    "# pprint(prompts[0])\n",
    "rating = llm.predict(prompts[0], **parameters)\n",
    "extraction_prompt = \"extract the ratings in order in a simple comma seperated list:\"\n",
    "ratings = llm.predict(f\"{rating.text} {extraction_prompt}\", **parameters)\n",
    "ratings.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b4911b38-0cec-4f9f-874b-b37040e7f678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def llm_call(prompts):\n",
    "    ratings_list = []\n",
    "    for prompt in prompts:\n",
    "        rating = llm.predict(prompt, **parameters)\n",
    "        time.sleep(1) # for rate limits\n",
    "        extraction_prompt = \"extract the numeric-only ratings a comma seperated list:\"\n",
    "        ratings = llm.predict(f\"given the output {rating.text}, {extraction_prompt}\", **parameters)\n",
    "        time.sleep(1) # for rate limits\n",
    "        ratings_list.append(ratings.text)\n",
    "    return ratings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "39574548-f50e-437f-a2af-fddc565e23fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 5\n"
     ]
    }
   ],
   "source": [
    "#now try to put it together by getting ratings for a batch with multiple arms\n",
    "\n",
    "print(batch_size, NUM_ACTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a267366d-6f6e-4b28-a4da-85dc4b3538c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unvalidated_llm_response = llm_call(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d0e6b0b2-f0ba-46bb-a7d9-1648e6a099ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4, 4, 3, 4, 3',\n",
       " '3.5, 4.5, 3.5, 4.0, 3.0',\n",
       " '3, 3, 3, 3, 3',\n",
       " '3.5, 4.5, 3.5, 4.5, 3.5',\n",
       " '4, 4, 3, 4, 3',\n",
       " '4, 4, 3, 4, 3',\n",
       " '4, 4, 3, 4, 3',\n",
       " '4, 4, 3, 4, 3']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unvalidated_llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "56487957-39af-43e6-bc52-9bae34bfc6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def validate_llm_response(llm_response, n_actions):\n",
    "    \"this formats the text lists into a list of floats and also\"\n",
    "    \"TODO - handles when LLM has poor output\"\n",
    "    str_list = []\n",
    "    for resp in llm_response:\n",
    "        str_elem = [y for y in resp.split(',')]\n",
    "        if len(str_elem) != n_actions:\n",
    "             str_elem = list(np.ones(n_actions)*3) #default rating of all threes if we can't figure it out TODO\n",
    "        str_list.append(str_elem)\n",
    "    # re_clean_list = [[re.findall(r'\\d+', y) for y in x] for x in str_list]\n",
    "    return [[float(y) for y in x] for x in str_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9e656d8f-63f2-4855-bdae-711b933ed9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4.0, 4.0, 3.0, 4.0, 3.0],\n",
       " [3.5, 4.5, 3.5, 4.0, 3.0],\n",
       " [3.0, 3.0, 3.0, 3.0, 3.0],\n",
       " [3.5, 4.5, 3.5, 4.5, 3.5],\n",
       " [4.0, 4.0, 3.0, 4.0, 3.0],\n",
       " [4.0, 4.0, 3.0, 4.0, 3.0],\n",
       " [4.0, 4.0, 3.0, 4.0, 3.0],\n",
       " [4.0, 4.0, 3.0, 4.0, 3.0]]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_rewards = validate_llm_response(unvalidated_llm_response, NUM_ACTIONS)\n",
    "llm_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3e01ba-8d4f-4d18-b07e-e4183dddd48e",
   "metadata": {},
   "source": [
    "## Finally, put it together into the LLM reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3a08075a-4cae-45d1-b0fc-cb6418cd338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_reward(user_info, movie_info, num_actions):\n",
    "    prompts = RL_prompt(user_info, movie_info)\n",
    "    unvalidated_llm_response = llm_call(prompts)\n",
    "    return validate_llm_response(unvalidated_llm_response, num_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "03de09e2-5ce4-4158-8185-e7635e6be7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Look at the raw input features to format a good prompt for ranking movies\n",
    "NUM_ACTIONS = 5\n",
    "batch_size = 8\n",
    "iterator = iter(train_dataset.batch(batch_size))\n",
    "test_steps = 3\n",
    "for _ in range(3):\n",
    "    data = next(iterator)\n",
    "\n",
    "    _, user_info = _get_global_context_features(data) #new - user info passes on the raw user features for prompting with PALM\n",
    "    ###NEW - we are getting the arm features here\n",
    "    _, movie_info = get_random_set_of_arm_features(n_actions=NUM_ACTIONS)\n",
    "\n",
    "\n",
    "    llm_reward(user_info, movie_info, NUM_ACTIONS) #batch size by n_actions/arms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "65c1db42-81ab-46a6-b4a5-9f44d76ca4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add one more validation - we will add a null tie in case of bad formatting TODO\n",
    "### should make sure we have the correct shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac6836c-67b7-4fd4-917a-24ddad708edd",
   "metadata": {},
   "source": [
    "## TF-Agents implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1877c79c-b6c8-4048-b1ce-05f011e8d69e",
   "metadata": {},
   "source": [
    "In TF-Agents, the *per-arm features* implementation differs from the *global-only* feature examples in the following aspects:\n",
    "* Reward is modeled not per-arm, but globally.\n",
    "* The arms are permutation invariant: it doesnâ€™t matter which arm is arm 1 or arm 2, only their features.\n",
    "* One can have a different number of arms to choose from in every step (note that unspecified/dynamically changing number of arms will have a problem with XLA compatibility).\n",
    "\n",
    "When implementing per-arm features in TF-Bandits, the following details have to be discussed:\n",
    "* Observation spec and observations,\n",
    "* Action spec and actions,\n",
    "* Implementation of specific policies and agents.\n",
    "\n",
    "\n",
    "**TODO:**\n",
    "* outline the components and highlight their interactions, dependencies on eachother, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7ff9baaf-987d-448d-a981-742a79b581e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE  : 8\n",
      "NUM_ACTIONS : 5\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE  = 8\n",
    "NUM_ACTIONS = 5 \n",
    "\n",
    "# GLOBAL_EMBEDDING_SIZE  = 16\n",
    "# MV_EMBEDDING_SIZE      = 32 #32\n",
    "\n",
    "GLOBAL_DIM = GLOBAL_EMBEDDING_SIZE * 4 # 4 global features in this example\n",
    "PER_ARM_DIM = MV_EMBEDDING_SIZE * 2 # 2 movie features\n",
    "\n",
    "print(f\"BATCH_SIZE  : {BATCH_SIZE}\")\n",
    "print(f\"NUM_ACTIONS : {NUM_ACTIONS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeb4902-5bb9-4587-8d29-c01d78b006be",
   "metadata": {},
   "source": [
    "## Tensor Specs\n",
    "\n",
    "**TODO:**\n",
    "* explain relationship between Tensor Specs and their Tensor counterparts\n",
    "* highlight the errors, lessons learned, and utility functions to address these"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f68ebe8-116d-43b3-a6e1-4f5a5c7f4741",
   "metadata": {},
   "source": [
    "### Observation spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9c4746-d01b-4ca4-aa53-ab68da54d37a",
   "metadata": {},
   "source": [
    "**This observation spec allows the user to have a global observation of fixed dimension**, and an unspecified number of *per-arm* features (also of fixed dimension)\n",
    "* The actions output by the policy are still integers as usual, and they indicate which row of the arm-features it has chosen \n",
    "* The action spec must be a single integer value without boundaries:\n",
    "\n",
    "```python\n",
    "global_spec = tensor_spec.TensorSpec([GLOBAL_DIM], tf.float32)\n",
    "per_arm_spec = tensor_spec.TensorSpec([None, PER_ARM_DIM], tf.float32)\n",
    "observation_spec = {'global': global_spec, 'per_arm': per_arm_spec}\n",
    "\n",
    "action_spec = tensor_spec.TensorSpec((), tf.int32)\n",
    "```\n",
    "> Here the only difference compared to the action spec with global features only is that the tensor spec is not bounded, as we donâ€™t know how many arms there will be at any time step\n",
    "\n",
    "**XLA compatibility:**\n",
    "* Since dynamic tensor shapes are not compatible with XLA, the number of arm features (and consequently, number of arms for a step) cannot be dynamic. \n",
    "* One workaround is to fix the maximum number of arms for a problem, then pad the arm features in steps with fewer arms, and use action masking to indicate how many arms are actually active.\n",
    "\n",
    "```python\n",
    "per_arm_spec = tensor_spec.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32)\n",
    "\n",
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=(), dtype=tf.int32, minimum = 0, maximum = NUM_ACTIONS - 1\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "36bd3b33-635a-4274-8b9e-7172696ebb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(5, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_spec = {\n",
    "    'global': tf.TensorSpec([GLOBAL_DIM], tf.float32),\n",
    "    'per_arm': tf.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32) #excluding action dim here\n",
    "}\n",
    "observation_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a2da92-7db2-4f42-94a7-b7bad1c8fc42",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Action spec\n",
    "\n",
    "> The time_step_spec and action_spec are specifications for the input time step and the output action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5af42c7-18d7-480f-a7f3-d7da3f4840eb",
   "metadata": {},
   "source": [
    "```python\n",
    "    if (\n",
    "        not tensor_spec.is_bounded(action_spec)\n",
    "        or not tensor_spec.is_discrete(action_spec)\n",
    "        or action_spec.shape.rank > 1\n",
    "        or action_spec.shape.num_elements() != 1\n",
    "    ):\n",
    "      raise NotImplementedError(\n",
    "          'action_spec must be a BoundedTensorSpec of type int32 and shape (). '\n",
    "          'Found {}.'.format(action_spec)\n",
    "      )\n",
    "```\n",
    "\n",
    "* [src](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_base_policy.py#L97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "549a123c-349a-4103-b39a-4502f47d1e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(4, dtype=int32))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=[], \n",
    "    dtype=tf.int32,\n",
    "    minimum=tf.constant(0),            \n",
    "    maximum=NUM_ACTIONS-1, #n degrees of freedom and will dictate the expected mean reward spec shape\n",
    "    name=\"action_spec\"\n",
    ")\n",
    "\n",
    "action_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a51efce-9f1b-42d1-bec4-7b788e3fd7e0",
   "metadata": {},
   "source": [
    "### TimeStep spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "95f05860-0fbf-4a5a-8273-9c81761e0ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       "                 'per_arm': TensorSpec(shape=(5, 64), dtype=tf.float32, name=None)},\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec = ts.time_step_spec(observation_spec)#, reward_spec=tf.TensorSpec([1, NUM_ACTIONS]))\n",
    "time_step_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9c197-ae9b-461d-8956-f078b929ac12",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The Agent\n",
    "\n",
    "**Note** that contextual bandits form a special case of RL, where the actions taken by the agent do not alter the state of the environment \n",
    "\n",
    "> â€œContextualâ€ refers to the fact that the agent chooses among a set of actions while having knowledge of the context (environment observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aadb01-eb5c-4870-ae14-9e66624ba594",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Agent types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d075e8a6-11a9-4346-8725-3653fba4bac4",
   "metadata": {},
   "source": [
    "**Possible Agent Types:**\n",
    "\n",
    "```\n",
    "AGENT_TYPE = ['LinUCB', 'LinTS', 'epsGreedy', 'NeuralLinUCB']\n",
    "```\n",
    "\n",
    "**LinearUCBAgent:** (`LinUCB`)\n",
    "* An agent implementing the Linear UCB bandit algorithm\n",
    "* (whitepaper) [A contextual bandit approach to personalized news recommendation](https://arxiv.org/abs/1003.0146)\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/lin_ucb_agent/LinearUCBAgent)\n",
    "\n",
    "**LinearThompsonSamplingAgent:** (`LinTS`)\n",
    "* Implements the Linear Thompson Sampling Agent from the paper: [Thompson Sampling for Contextual Bandits with Linear Payoffs](https://arxiv.org/abs/1209.3352)\n",
    "* the agent maintains two parameters `weight_covariances` and `parameter_estimators`, and updates them based on experience.\n",
    "* The inverse of the weight covariance parameters are updated with the outer product of the observations using the Woodbury inverse matrix update, while the parameter estimators are updated by the reward-weighted observation vectors for every action\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/linear_thompson_sampling_agent/LinearThompsonSamplingAgent)\n",
    "\n",
    "**NeuralEpsilonGreedyAgent:** (`epsGreedy`) \n",
    "* A neural network based epsilon greedy agent\n",
    "* This agent receives a neural network that it trains to predict rewards\n",
    "* The action is chosen greedily with respect to the prediction with probability `1 - epsilon`, and uniformly randomly with probability epsilon\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_epsilon_greedy_agent/NeuralEpsilonGreedyAgent)\n",
    "\n",
    "**NeuralLinUCBAgent:** (`NeuralLinUCB`)\n",
    "* An agent implementing the LinUCB algorithm on top of a neural network\n",
    "* `ENCODING_DIM` is the output dimension of the encoding network \n",
    "> * This output will be used by either a linear reward layer and epsilon greedy exploration, or by a LinUCB logic, depending on the number of training steps executed so far\n",
    "* `EPS_PHASE_STEPS` is the number training steps to run for training the encoding network before switching to `LinUCB`\n",
    "> * If negative, the encoding network is assumed to be already trained\n",
    "> * If the number of steps is less than or equal to `EPS_PHASE_STEPS`, `epsilon greedy` is used, otherwise `LinUCB`\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_linucb_agent/NeuralLinUCBAgent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b8e88e-c8ea-4193-a911-0d974ef3b1a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### network types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f547087d-5fad-4521-a584-cb46ce52897d",
   "metadata": {},
   "source": [
    "Which network architecture to use for the `epsGreedy` or `NeuralLinUCB` agents\n",
    "\n",
    "```\n",
    "NETWORK_TYPE = ['commontower', 'dotproduct']\n",
    "```\n",
    "\n",
    "**GlobalAndArmCommonTowerNetwork:** (`commontower`)\n",
    "* This network takes the output of the global and per-arm networks, and leads them through a common network, that in turn outputs reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "> * `COMMON_LAYERS` - Iterable of ints. Specifies the layers of the common tower\n",
    "* The network produced by this function can be used either in `GreedyRewardPredictionPolicy`, or `NeuralLinUCBPolicy`\n",
    "> * In the former case, the network must have `output_dim=1`, it is going to be an instance of `QNetwork`, and used in the policy as a reward prediction network\n",
    "> * In the latter case, the network will be an encoding network with its output consumed by a reward layer or a `LinUCB` method. The specified `output_dim` will be the encoding dimension\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmCommonTowerNetwork)\n",
    "\n",
    "**GlobalAndArmDotProductNetwork:** (`dotproduct`)\n",
    "* This network calculates the **dot product** of the output of the global and per-arm networks and returns them as reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmDotProductNetwork)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3dc270-deb5-4e96-8276-74759a06c318",
   "metadata": {},
   "source": [
    "### define agent and network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6d817bf2-1fa6-4bae-af90-745fad996b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 8,\n",
      " 'common_layers': [100],\n",
      " 'epsilon': 0.4,\n",
      " 'global_layers': [50, 50, 50],\n",
      " 'learning_rate': 0.005,\n",
      " 'model_type': 'epsGreedy',\n",
      " 'network_type': 'dotproduct',\n",
      " 'num_actions': 5,\n",
      " 'per_arm_layers': [50, 50, 50]}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Agents\n",
    "# ================================\n",
    "AGENT_TYPE      = 'epsGreedy' # 'LinUCB' | 'LinTS |, 'epsGreedy' | 'NeuralLinUCB'\n",
    "\n",
    "# Parameters for linear agents (LinUCB and LinTS).\n",
    "AGENT_ALPHA     = 0.1\n",
    "\n",
    "# Parameters for neural agents (NeuralEpsGreedy and NerualLinUCB).\n",
    "EPSILON         = 0.4\n",
    "LR              = 0.005\n",
    "\n",
    "# Parameters for NeuralLinUCB\n",
    "ENCODING_DIM    = 1\n",
    "EPS_PHASE_STEPS = 1000\n",
    "\n",
    "# ================================\n",
    "# Agent's Preprocess Network\n",
    "# ================================\n",
    "NETWORK_TYPE    = \"dotproduct\" # 'commontower' | 'dotproduct'\n",
    "\n",
    "if AGENT_TYPE == 'NeuralLinUCB':\n",
    "    NETWORK_TYPE = 'commontower'\n",
    "    \n",
    "\n",
    "GLOBAL_LAYERS   = [50, 50, 50]\n",
    "ARM_LAYERS      = [50, 50, 50]\n",
    "COMMON_LAYERS   = [100]\n",
    "\n",
    "observation_and_action_constraint_splitter = None\n",
    "\n",
    "HPARAMS = {  # TODO - streamline and consolidate\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"num_actions\": NUM_ACTIONS,\n",
    "    \"model_type\": AGENT_TYPE,\n",
    "    \"network_type\": NETWORK_TYPE,\n",
    "    \"global_layers\": GLOBAL_LAYERS,\n",
    "    \"per_arm_layers\": ARM_LAYERS,\n",
    "    \"common_layers\": COMMON_LAYERS,\n",
    "    \"learning_rate\": LR,\n",
    "    \"epsilon\": EPSILON,\n",
    "}\n",
    "pprint(HPARAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db165067-6e9d-4b79-b675-bae69ec98c10",
   "metadata": {},
   "source": [
    "### Agent Factory\n",
    "\n",
    "**TODO:**\n",
    "* consolidate agent, network, and hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e7c79df4-f975-49fc-b598-d6fd2f6be125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\n",
      "\n",
      "time_step_spec:  TimeStep(\n",
      "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
      "                 'per_arm': TensorSpec(shape=(5, 64), dtype=tf.float32, name=None)},\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n",
      "\n",
      "action_spec:  BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(4, dtype=int32))\n",
      "\n",
      "observation_spec:  {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(5, 64), dtype=tf.float32, name=None)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\")\n",
    "print(\"\\ntime_step_spec: \", time_step_spec)\n",
    "print(\"\\naction_spec: \", action_spec)\n",
    "print(\"\\nobservation_spec: \", observation_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6cb60f0b-90b7-49ab-9c41-046ea00ab750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: OffpolicyNeuralEpsGreedyAgent\n",
      "\n",
      "Network: GlobalAndArmDotProductNetwork\n"
     ]
    }
   ],
   "source": [
    "# from tf_agents.bandits.policies import policy_utilities\n",
    "# from tf_agents.bandits.agents import greedy_reward_prediction_agent\n",
    "\n",
    "network = None\n",
    "observation_and_action_constraint_splitter = None\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "if AGENT_TYPE == 'LinUCB':\n",
    "    agent = lin_ucb_agent.LinearUCBAgent(\n",
    "        time_step_spec=time_step_spec,\n",
    "        action_spec=action_spec,\n",
    "        alpha=AGENT_ALPHA,\n",
    "        accepts_per_arm_features=True,\n",
    "        dtype=tf.float32,\n",
    "    )\n",
    "elif AGENT_TYPE == 'LinTS':\n",
    "    agent = lin_ts_agent.LinearThompsonSamplingAgent(\n",
    "        time_step_spec=time_step_spec,\n",
    "        action_spec=action_spec,\n",
    "        alpha=AGENT_ALPHA,\n",
    "        observation_and_action_constraint_splitter=(\n",
    "            observation_and_action_constraint_splitter\n",
    "        ),\n",
    "        accepts_per_arm_features=True,\n",
    "        dtype=tf.float32,\n",
    "    )\n",
    "elif AGENT_TYPE == 'epsGreedy':\n",
    "    # obs_spec = per_arm_tf_env.observation_spec()\n",
    "    if NETWORK_TYPE == 'commontower':\n",
    "        network = global_and_arm_feature_network.create_feed_forward_common_tower_network(\n",
    "            observation_spec = observation_spec, \n",
    "            global_layers = GLOBAL_LAYERS, \n",
    "            arm_layers = ARM_LAYERS, \n",
    "            common_layers = COMMON_LAYERS,\n",
    "            # output_dim = 1\n",
    "        )\n",
    "    elif NETWORK_TYPE == 'dotproduct':\n",
    "        network = global_and_arm_feature_network.create_feed_forward_dot_product_network(\n",
    "            observation_spec = observation_spec, \n",
    "            global_layers = GLOBAL_LAYERS, \n",
    "            arm_layers = ARM_LAYERS\n",
    "        )\n",
    "    agent = neural_epsilon_greedy_agent.NeuralEpsilonGreedyAgent(\n",
    "        time_step_spec=time_step_spec,\n",
    "        action_spec=action_spec,\n",
    "        reward_network=network,\n",
    "        optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=HPARAMS['learning_rate']),\n",
    "        epsilon=HPARAMS['epsilon'],\n",
    "        observation_and_action_constraint_splitter=(\n",
    "            observation_and_action_constraint_splitter\n",
    "        ),\n",
    "        accepts_per_arm_features=True,\n",
    "        emit_policy_info=policy_utilities.InfoFields.PREDICTED_REWARDS_MEAN,\n",
    "        train_step_counter=global_step,\n",
    "        # info_fields_to_inherit_from_greedy=['predicted_rewards_mean'],\n",
    "        name='OffpolicyNeuralEpsGreedyAgent'\n",
    "    )\n",
    "\n",
    "elif AGENT_TYPE == 'NeuralLinUCB':\n",
    "    # obs_spec = per_arm_tf_env.observation_spec()\n",
    "    network = (\n",
    "        global_and_arm_feature_network.create_feed_forward_common_tower_network(\n",
    "            observation_spec = observation_spec, \n",
    "            global_layers = GLOBAL_LAYERS, \n",
    "            arm_layers = ARM_LAYERS, \n",
    "            common_layers = COMMON_LAYERS,\n",
    "            output_dim = ENCODING_DIM\n",
    "        )\n",
    "    )\n",
    "    agent = neural_linucb_agent.NeuralLinUCBAgent(\n",
    "        time_step_spec=per_arm_tf_env.time_step_spec(),\n",
    "        action_spec=per_arm_tf_env.action_spec(),\n",
    "        encoding_network=network,\n",
    "        encoding_network_num_train_steps=EPS_PHASE_STEPS,\n",
    "        encoding_dim=ENCODING_DIM,\n",
    "        optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=LR),\n",
    "        alpha=1.0,\n",
    "        gamma=1.0,\n",
    "        epsilon_greedy=EPSILON,\n",
    "        accepts_per_arm_features=True,\n",
    "        debug_summaries=True,\n",
    "        summarize_grads_and_vars=True,\n",
    "        emit_policy_info=policy_utilities.InfoFields.PREDICTED_REWARDS_MEAN,\n",
    "    )\n",
    "    \n",
    "agent.initialize() # TODO - does this go here?\n",
    "    \n",
    "print(f\"Agent: {agent.name}\\n\")\n",
    "if network:\n",
    "    print(f\"Network: {network.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d404dae-3cc3-4f81-962b-4641455ca4f2",
   "metadata": {},
   "source": [
    "## Reward function\n",
    "\n",
    "**TODO:**\n",
    "* explain how to translate reward to this common recommendation objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "df9aecd6-d20a-48a7-9ead-4da3bbcfdae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _get_rewards(element):\n",
    "#     \"\"\"Calculates reward for the actions.\"\"\"\n",
    "\n",
    "#     def _calc_reward(x):\n",
    "#         \"\"\"Calculates reward for a single action.\"\"\"\n",
    "#         r0 = lambda: tf.constant(0.0)\n",
    "#         r1 = lambda: tf.constant(-10.0)\n",
    "#         r2 = lambda: tf.constant(2.0)\n",
    "#         r3 = lambda: tf.constant(3.0)\n",
    "#         r4 = lambda: tf.constant(4.0)\n",
    "#         r5 = lambda: tf.constant(10.0)\n",
    "#         c1 = tf.equal(x, 1.0)\n",
    "#         c2 = tf.equal(x, 2.0)\n",
    "#         c3 = tf.equal(x, 3.0)\n",
    "#         c4 = tf.equal(x, 4.0)\n",
    "#         c5 = tf.equal(x, 5.0)\n",
    "#         return tf.case(\n",
    "#             [(c1, r1), (c2, r2), (c3, r3),(c4, r4),(c5, r5)], \n",
    "#             default=r0, exclusive=True\n",
    "#         )\n",
    "\n",
    "#     return tf.map_fn(\n",
    "#         fn=_calc_reward, \n",
    "#         elems=element['user_rating'], \n",
    "#         dtype=tf.float32\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a18218-5062-470d-a715-86020e6a2f51",
   "metadata": {},
   "source": [
    "### New - exploring the dot product network\n",
    "\n",
    "Let's get the dot proudcut of arm/global features for the trajectories\n",
    "\n",
    "Looking at source [code](https://github.com/tensorflow/agents/blob/v0.17.0/tf_agents/bandits/networks/global_and_arm_feature_network.py#L54-L138)\n",
    "\n",
    "```python\n",
    "return GlobalAndArmDotProductNetwork(obs_spec_no_num_actions, global_network,\n",
    "                                       arm_network)\n",
    "```\n",
    "\n",
    "Leads to [here](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmDotProductNetwork#get_initial_state)\n",
    "\n",
    "Also member the config\n",
    "\n",
    "- GLOBAL_LAYERS   = [16, 4]\n",
    "- ARM_LAYERS      = [16, 4]\n",
    "- COMMON_LAYERS   = [4]\n",
    "\n",
    "```python\n",
    "network = global_and_arm_feature_network.create_feed_forward_dot_product_network(\n",
    "            observation_spec = observation_spec, \n",
    "            global_layers = GLOBAL_LAYERS, \n",
    "            arm_layers = ARM_LAYERS\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac59703a-9a00-4eba-a3b7-45b21b738dd4",
   "metadata": {},
   "source": [
    "## Trajectory function\n",
    "\n",
    "**parking lot**\n",
    "* does trajectory fn need concept of `dummy_chosen_arm_features`, similar to [this](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_base_policy.py#L297)\n",
    "\n",
    "```python\n",
    "      dummy_chosen_arm_features = tf.nest.map_structure(\n",
    "          lambda obs: tf.zeros_like(obs[:, 0, ...]),\n",
    "          time_step.observation[bandit_spec_utils.PER_ARM_FEATURE_KEY],\n",
    "      )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bcb31c7b-f03e-4d9f-a0f8-2f8ad8318d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "\n",
    "def _trajectory_fn(element, batch_size): # hparams\n",
    "        \n",
    "    \"\"\"Converts a dataset element into a trajectory.\"\"\"\n",
    "    global_features, user_info = _get_global_context_features(element) #new - user info passes on the raw user features for prompting with PALM\n",
    "    ###NEW - we are getting the arm features here\n",
    "    arm_features, movie_info = get_random_set_of_arm_features(n_actions=NUM_ACTIONS)\n",
    "    # arm_features = get_random_set_of_arm_features(n_actions=NUM_ACTIONS)\n",
    "    \n",
    "    #get the dot product reward of the feed-forward network\n",
    "    reward = llm_reward(user_info, movie_info, NUM_ACTIONS)\n",
    "    \n",
    "    reward = tf.constant(reward, tf.float32)\n",
    "    \n",
    "    #chose an arm\n",
    "    best_arm_ids = tf.argmax(reward, axis=1)\n",
    "    # best_arm_ids = tf.cast(best_arm_ids, dtype=tf.int32)\n",
    "    max_rewards = tf.math.reduce_max(reward, axis=1)\n",
    "    max_rewards = _add_outer_dimension(max_rewards) # add time dim\n",
    "    chosen_arm_feats = tf.gather(arm_features, best_arm_ids) # [batch_size, arm_features]\n",
    "    \n",
    "    chosen_arm_feats = _add_outer_dimension(chosen_arm_feats)\n",
    "    # Adds a time dimension.\n",
    "    arm_features = _add_outer_dimension(arm_features)\n",
    "\n",
    "    # obs spec\n",
    "    observation = {\n",
    "        bandit_spec_utils.GLOBAL_FEATURE_KEY:\n",
    "            _add_outer_dimension(global_features), #timedim bloat\n",
    "    }\n",
    "    \n",
    "    \n",
    "    reward = _add_outer_dimension(reward)\n",
    "    \n",
    "    ###TODO - not sure if this should actually go in the action for trajectory\n",
    "    # best_arm_ids =  _add_outer_dimension(best_arm_ids)\n",
    "    \n",
    "    dummy_rewards = tf.zeros([batch_size, 1, NUM_ACTIONS])\n",
    "    \n",
    "    policy_info = policy_utilities.PerArmPolicyInfo(\n",
    "        chosen_arm_features=chosen_arm_feats,\n",
    "        # Pass dummy mean rewards here to match the model_spec for emitting\n",
    "        # mean rewards in policy info\n",
    "        predicted_rewards_mean=dummy_rewards\n",
    "    )\n",
    "    \n",
    "    if HPARAMS['model_type'] == 'neural_ucb':\n",
    "        policy_info = policy_info._replace(\n",
    "            predicted_rewards_optimistic=dummy_rewards\n",
    "        )\n",
    "        \n",
    "    return trajectory.single_step(\n",
    "        observation=observation,\n",
    "        action=tf.zeros_like(\n",
    "            max_rewards, dtype=tf.int32\n",
    "        ),  # Arm features are copied from policy info, put dummy zeros here\n",
    "        policy_info=policy_info,\n",
    "        reward=max_rewards,\n",
    "        discount=tf.zeros_like(max_rewards)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b3d3c-75f7-46f4-9a1b-6329e419b7f5",
   "metadata": {},
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bb7ffc-00df-4d46-857b-86c87b78f597",
   "metadata": {},
   "source": [
    "`agent.train(experience=...)`\n",
    "\n",
    "where `experience` is a batch of trajectories data in the form of a Trajectory. \n",
    "* The structure of experience must match that of `self.training_data_spec`. \n",
    "* All tensors in experience must be shaped [batch, time, ...] where time must be equal to self.train_step_length if that property is not None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4cf53ca1-f827-424f-adf4-0edaf863da42",
   "metadata": {},
   "outputs": [],
   "source": [
    "##todo - create a function that selects the best movie features along with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6332c741-cdff-4956-831f-fb68417fa52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 5)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE, NUM_ACTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9b4bf964-1028-4bb5-bf1d-939caac7904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.metrics import export_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "\n",
    "LOG_DIR = '.'\n",
    "agent.initialize() # TODO - does this go here?\n",
    "\n",
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "logging.info(f\" log_dir: {LOG_DIR}\")\n",
    "\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    LOG_DIR, flush_millis=10 * 1000\n",
    ")\n",
    "train_summary_writer.set_as_default()\n",
    "\n",
    "# ====================================================\n",
    "# metrics\n",
    "# ====================================================\n",
    "step_metric = tf_metrics.EnvironmentSteps()\n",
    "metrics = [\n",
    "    tf_metrics.NumberOfEpisodes(),\n",
    "    tf_metrics.AverageEpisodeLengthMetric(batch_size=HPARAMS['batch_size']),\n",
    "    tf_metrics.AverageReturnMetric(batch_size=HPARAMS['batch_size'])\n",
    "]\n",
    "# if additional_metrics:\n",
    "#     metrics += additional_metrics\n",
    "    \n",
    "metric_results = defaultdict(list)\n",
    "\n",
    "def _export_metrics_and_summaries(step, metrics):\n",
    "    \"\"\"Exports metrics and tf summaries.\"\"\"\n",
    "    metric_utils.log_metrics(metrics)\n",
    "    export_utils.export_metrics(step=step, metrics=metrics)\n",
    "    for metric in metrics:\n",
    "        metric.tf_summaries(train_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4bfcb9d7-b24a-4526-ae2a-727ba0c55a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting train loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 8/100 [04:09<49:13, 32.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 20: loss = 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆ         | 11/100 [05:35<44:09, 29.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved policy to: .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|â–ˆâ–Š        | 18/100 [09:14<43:24, 31.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 30: loss = 2.2200000286102295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|â–ˆâ–ˆ        | 21/100 [10:34<37:12, 28.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved policy to: .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|â–ˆâ–ˆâ–Š       | 28/100 [14:14<37:35, 31.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 40: loss = 0.3400000035762787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [15:36<33:21, 29.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved policy to: .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [18:58<28:58, 28.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 50: loss = 0.5600000023841858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [20:19<27:08, 27.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved policy to: .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [23:32<24:07, 27.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 60: loss = 1.0099999904632568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [25:00<23:30, 28.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved policy to: .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [28:16<19:22, 27.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 70: loss = 0.18000000715255737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [29:51<19:37, 30.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved policy to: .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [33:14<15:11, 28.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 80: loss = 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [34:36<13:41, 28.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved policy to: .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [38:16<11:00, 30.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 90: loss = 0.10999999940395355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [39:44<09:15, 29.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved policy to: .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [44:00<07:01, 35.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 100: loss = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [45:36<04:58, 33.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved policy to: .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [49:14<01:05, 32.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 110: loss = 0.38999998569488525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [50:11<00:00, 30.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved trained policy to: .\n",
      "runtime_mins: 50\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from tf_agents.utils import common\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.policies import policy_saver\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "ARTIFACTS_DIR = '.'\n",
    "CHKPOINT_DIR = '.'\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "# NUM_ITERATION_PER_LOOP = NUM_ITER_STEPS\n",
    "log_interval = 10\n",
    "\n",
    "# global_step = tf.compat.v1.train.get_global_step()\n",
    "\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "# agent.train = common.function(agent.train)\n",
    "\n",
    "# Reset the train step\n",
    "# agent.train_step_counter.assign(0)\n",
    "\n",
    "train_step_counter = tf.compat.v1.train.get_or_create_global_step()\n",
    "saver = policy_saver.PolicySaver(\n",
    "    agent.policy, \n",
    "    train_step=train_step_counter\n",
    ")\n",
    "starting_loop = 0\n",
    "\n",
    "# train_loss = collections.defaultdict(list)\n",
    "list_o_loss = []\n",
    "\n",
    "print(f\"starting train loop...\")\n",
    "start_time = time.time()\n",
    "\n",
    "iterator = iter(train_dataset.batch(BATCH_SIZE))\n",
    "\n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "\n",
    "    # iterator = iter(train_dataset.batch(HPARAMS['batch_size']))\n",
    "    data = next(iterator)\n",
    "    # print(f\"print data: {data}\")\n",
    "\n",
    "    trajectories = _trajectory_fn(data, BATCH_SIZE)\n",
    "    # print(f\"print trajectories: {trajectories}\")\n",
    "\n",
    "    # All tensors in experience must be shaped [batch, time, ...] \n",
    "    step = agent.train_step_counter.numpy()\n",
    "    loss = agent.train(experience=trajectories)\n",
    "    # agent.train(experience=trajectories)\n",
    "    list_o_loss.append(loss.loss.numpy())\n",
    "\n",
    "    _export_metrics_and_summaries(\n",
    "        step=epoch, \n",
    "        metrics=metrics\n",
    "    )\n",
    "    \n",
    "    # print \n",
    "    if log_interval and step % log_interval == 0:\n",
    "        print(\n",
    "            'step = {0}: loss = {1}'.format(\n",
    "                step, round(loss.loss.numpy(), 2)\n",
    "            )\n",
    "        )\n",
    "        # print(f\"trajectories: {trajectories}\")\n",
    "        \n",
    "    if epoch > 0 and epoch % 10 == 0:\n",
    "        saver.save(os.path.join(CHKPOINT_DIR, 'policy_%d' % step_metric.result()))\n",
    "        print(f\"saved policy to: {CHKPOINT_DIR}\")\n",
    "        \n",
    "saver.save(ARTIFACTS_DIR)\n",
    "print(f\"saved trained policy to: {ARTIFACTS_DIR}\")\n",
    "    \n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"runtime_mins: {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313f23f1-6870-48fb-97fd-1bda065edffc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualize the agent's loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a4c4dc23-83fe-465b-aff6-c786a0866408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_o_loss)\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m109"
  },
  "kernelspec": {
   "display_name": "TensorFlow 2-11 (Local)",
   "language": "python",
   "name": "local-conda-env-tensorflow-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
