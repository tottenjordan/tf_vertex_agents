{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385307d6-2058-47ec-8da0-57f7ef5c43d6",
   "metadata": {},
   "source": [
    "# Train Bandits with per-arm features\n",
    "\n",
    "**Exploring linear and nonlinear** (e.g., those with neural network-based value functions) bandit methods for recommendations using TF-Agents\n",
    "\n",
    "> Neural linear bandits provide a nice way to leverage the representation power of deep learning and the bandit approach for uncertainty measure and efficient exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fd257-b98b-426a-a2cd-024429b014f1",
   "metadata": {},
   "source": [
    "## Load notebook config\n",
    "\n",
    "* use the prefix defined in `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f39c9d08-d118-4013-a47f-88450f49f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = 'mabv1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908f6b95-b539-4a9f-a836-840d26ea3b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"wortz-project-352116\"\n",
      "PROJECT_NUM              = \"679926387543\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"679926387543-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"mabv1\"\n",
      "VERSION                  = \"v1\"\n",
      "\n",
      "BUCKET_NAME              = \"mabv1-wortz-project-352116-bucket\"\n",
      "BUCKET_URI               = \"gs://mabv1-wortz-project-352116-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://mabv1-wortz-project-352116-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/679926387543/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_ID      = \"wortz-project-352116.movielens_dataset_mabv1\"\n",
      "BIGQUERY_TABLE_ID        = \"wortz-project-352116.movielens_dataset_mabv1.training_dataset\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "REPOSITORY               = \"rl-movielens-mabv1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c690a9-e2bd-4759-ba41-4e2469098aee",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d0dfe4-695c-4dd4-9f24-67f7488ce1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c669f1a1-1af7-4efb-ab2d-6bf3b3847991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tensorflow/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/envs/tensorflow/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/envs/tensorflow/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/envs/tensorflow/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/envs/tensorflow/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/envs/tensorflow/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "from collections import defaultdict\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pickle as pkl\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "# from tf_agents.agents import TFAgent\n",
    "\n",
    "# from tf_agents.bandits.environments import stationary_stochastic_per_arm_py_environment as p_a_env\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "# from tf_agents.drivers import dynamic_step_driver\n",
    "# from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "# from tf_agents.bandits.agents import lin_ucb_agent\n",
    "# from tf_agents.bandits.agents import linear_thompson_sampling_agent as lin_ts_agent\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent\n",
    "from tf_agents.bandits.agents import neural_linucb_agent\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "from tf_agents.bandits.policies import policy_utilities\n",
    "\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# this repo\n",
    "from src.per_arm_rl import data_utils\n",
    "from src.per_arm_rl import data_config\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29e58dd7-ab2b-419f-9771-bf1e98db758b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for gpu in gpus:\n",
    "#     tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \n",
    "# gpus\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4969d3e-1fc0-45db-8a69-aa6b342019de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = cuda.get_current_device()\n",
    "# device.reset()\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "274e7f4a-1802-4946-888e-876638f5c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a866b1-85b9-43e6-9546-edfbbf886bce",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd5b953-14c0-42ed-a511-77147a1bc0ac",
   "metadata": {},
   "source": [
    "### Read TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d0157c8-a04c-4dbd-b6d9-a1ede97687a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c934c06-bf08-4c7f-b0cc-0de04ef3515c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://mabv1-wortz-project-352116-bucket/data/train/ml-ratings-100k-train.tfrecord']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPLIT = \"train\" # \"train\" | \"val\"\n",
    "\n",
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_GCS_PREFIX}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7511e4d-bf81-4800-bde7-8b16dec9aeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([35.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'898'], dtype=object)>,\n",
      " 'movie_title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Postman, The (1997)'], dtype=object)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([885409515])>,\n",
      " 'user_gender': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'False'], dtype=object)>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'681'], dtype=object)>,\n",
      " 'user_occupation_label': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([14])>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'marketing'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>,\n",
      " 'user_zip_code': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'97208'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "train_dataset = train_dataset.map(data_utils.parse_tfrecord)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8959967-522e-41c8-9a1b-050ca8bc191f",
   "metadata": {},
   "source": [
    "### get vocab\n",
    "\n",
    "**TODO:** \n",
    "* streamline vocab calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b9169bc-d6dc-497e-9dff-6ebb175282ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE_VOCABS: False\n"
     ]
    }
   ],
   "source": [
    "GENERATE_VOCABS = False\n",
    "print(f\"GENERATE_VOCABS: {GENERATE_VOCABS}\")\n",
    "\n",
    "VOCAB_SUBDIR   = \"vocabs\"\n",
    "VOCAB_FILENAME = \"vocab_dict.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3ccf137-7a72-42e7-aa89-3c81a99cf40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab...\n",
      "Downloaded vocab from: gs://mabv1-wortz-project-352116-bucket/vocabs/vocab_dict.pkl\n",
      "\n",
      "'movie_id'\n",
      "'user_id'\n",
      "'user_occupation_text'\n",
      "'movie_genres'\n",
      "'bucketized_user_age'\n",
      "'max_timestamp'\n",
      "'min_timestamp'\n",
      "'timestamp_buckets'\n"
     ]
    }
   ],
   "source": [
    "if not GENERATE_VOCABS:\n",
    "\n",
    "    EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{VOCAB_SUBDIR}/{VOCAB_FILENAME}'\n",
    "    print(f\"Downloading vocab...\")\n",
    "    \n",
    "    os.system(f'gsutil -q cp {EXISTING_VOCAB_FILE} .')\n",
    "    print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "    filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "    vocab_dict = pkl.load(filehandler)\n",
    "    filehandler.close()\n",
    "    \n",
    "    for key in vocab_dict.keys():\n",
    "        pprint(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccaef62-882a-46ff-a1b1-3837e69fdf74",
   "metadata": {},
   "source": [
    "## helper functions\n",
    "\n",
    "**TODO:**\n",
    "* modularize in a train_utils or similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cba2bb14-bf94-466b-b60f-8c7d96c7aab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_outer_dimension(x):\n",
    "    \"\"\"Adds an extra outer dimension.\"\"\"\n",
    "    if isinstance(x, dict):\n",
    "        for key, value in x.items():\n",
    "            x[key] = tf.expand_dims(value, 1)\n",
    "        return x\n",
    "    return tf.expand_dims(x, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b941063b-ad48-4817-aef0-9afa8a444632",
   "metadata": {},
   "source": [
    "# Multi-Armed Bandits with Per-Arm Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28770b8d-836b-448d-8dd1-203d76fc6d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "\n",
    "nest = tf.nest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138a295-2b0d-4359-8496-af8552ec8cff",
   "metadata": {},
   "source": [
    "## Preprocessing layers for global and arm features\n",
    "\n",
    "The preproccesing layers will ultimately feed the two functions described below, both of which will ultimately feed the `Environment`\n",
    "\n",
    "`global_context_sampling_fn`: \n",
    "* A function that outputs a random 1d array or list of ints or floats\n",
    "* This output is the global context. Its shape and type must be consistent across calls.\n",
    "\n",
    "`arm_context_sampling_fn`: \n",
    "* A function that outputs a random 1 array or list of ints or floats (same type as the output of `global_context_sampling_fn`). * This output is the per-arm context. Its shape must be consistent across calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8d77956-635c-438a-916a-185eec52f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OOV_BUCKETS        = 1\n",
    "GLOBAL_EMBEDDING_SIZE  = 16\n",
    "MV_EMBEDDING_SIZE      = 32 #32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6142e63e-0a20-4d51-997c-7a4733517f7e",
   "metadata": {},
   "source": [
    "### global context (user) features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195acd92-06b6-42e4-bef7-798fd09da856",
   "metadata": {},
   "source": [
    "#### user ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c28e887b-421a-4603-8899-87071056783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_input_layer = tf.keras.Input(\n",
    "    name=\"user_id\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.string\n",
    ")\n",
    "\n",
    "user_id_lookup = tf.keras.layers.StringLookup(\n",
    "    max_tokens=len(vocab_dict['user_id']) + NUM_OOV_BUCKETS,\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    mask_token=None,\n",
    "    vocabulary=vocab_dict['user_id'],\n",
    ")(user_id_input_layer)\n",
    "\n",
    "user_id_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['user_id']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=GLOBAL_EMBEDDING_SIZE\n",
    ")(user_id_lookup)\n",
    "\n",
    "user_id_embedding = tf.reduce_sum(user_id_embedding, axis=-2)\n",
    "\n",
    "# global_inputs.append(user_id_input_layer)\n",
    "# global_features.append(user_id_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d6a0fe7-26cb-4c62-a3ef-17f98e6ccddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'681'], shape=(1,), dtype=string)\n",
      "tf.Tensor(\n",
      "[[-0.04985065 -0.00532871 -0.03634857 -0.04782307 -0.0151373   0.01437653\n",
      "   0.03545219  0.03968345  0.02484528 -0.0112708   0.02281231 -0.02392597\n",
      "  -0.01318774 -0.00431702  0.00012762  0.03880258]], shape=(1, 16), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_user_id_model = tf.keras.Model(inputs=user_id_input_layer, outputs=user_id_embedding)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(x[\"user_id\"])\n",
    "    print(test_user_id_model(x[\"user_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352d2227-92ec-4386-926f-df2fdb9434ec",
   "metadata": {},
   "source": [
    "#### user AGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70785bf0-5ece-4875-ab72-06d9c45ea9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_age_input_layer = tf.keras.Input(\n",
    "    name=\"bucketized_user_age\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "user_age_lookup = tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=vocab_dict['bucketized_user_age'],\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    oov_value=0,\n",
    ")(user_age_input_layer)\n",
    "\n",
    "user_age_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['bucketized_user_age']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=GLOBAL_EMBEDDING_SIZE\n",
    ")(user_age_lookup)\n",
    "\n",
    "user_age_embedding = tf.reduce_sum(user_age_embedding, axis=-2)\n",
    "\n",
    "# global_inputs.append(user_age_input_layer)\n",
    "# global_features.append(user_age_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e01622a-9418-4ca7-8925-9b0ebef8940e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([35.], shape=(1,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.0498643   0.01750484  0.02067177  0.04393334 -0.04336467  0.03129146\n",
      "  -0.01701912  0.01351896 -0.01740777 -0.04474656 -0.00899174 -0.02451527\n",
      "  -0.01704979  0.03550223 -0.02412467 -0.04029829]], shape=(1, 16), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_user_age_model = tf.keras.Model(inputs=user_age_input_layer, outputs=user_age_embedding)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(x[\"bucketized_user_age\"])\n",
    "    print(test_user_age_model(x[\"bucketized_user_age\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997ffaa8-ca92-4851-b7e3-bb06fba8958b",
   "metadata": {},
   "source": [
    "#### user OCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03e7344d-71fb-423a-89dd-f1abeb270e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_occ_input_layer = tf.keras.Input(\n",
    "    name=\"user_occupation_text\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.string\n",
    ")\n",
    "\n",
    "user_occ_lookup = tf.keras.layers.StringLookup(\n",
    "    max_tokens=len(vocab_dict['user_occupation_text']) + NUM_OOV_BUCKETS,\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    mask_token=None,\n",
    "    vocabulary=vocab_dict['user_occupation_text'],\n",
    ")(user_occ_input_layer)\n",
    "\n",
    "user_occ_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['user_occupation_text']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=GLOBAL_EMBEDDING_SIZE\n",
    ")(user_occ_lookup)\n",
    "\n",
    "user_occ_embedding = tf.reduce_sum(user_occ_embedding, axis=-2)\n",
    "\n",
    "# global_inputs.append(user_occ_input_layer)\n",
    "# global_features.append(user_occ_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39cbbc31-ca43-4f8f-a804-a4b830e99d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'marketing'], shape=(1,), dtype=string)\n",
      "tf.Tensor(\n",
      "[[-0.04159627  0.02417859 -0.04973073  0.04730998  0.02376128 -0.03412268\n",
      "  -0.00291198  0.02347748 -0.03014418 -0.01471244  0.00205895  0.03073821\n",
      "   0.00395476 -0.03008027  0.0374867  -0.00221273]], shape=(1, 16), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_user_occ_model = tf.keras.Model(inputs=user_occ_input_layer, outputs=user_occ_embedding)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(x[\"user_occupation_text\"])\n",
    "    print(test_user_occ_model(x[\"user_occupation_text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee0098-a48a-4de6-88bf-6219ce8c0533",
   "metadata": {},
   "source": [
    "#### user Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61a4e01a-e742-4c68-93a9-aa66eb9a5e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ts_input_layer = tf.keras.Input(\n",
    "    name=\"timestamp\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.int64\n",
    ")\n",
    "\n",
    "user_ts_lookup = tf.keras.layers.Discretization(\n",
    "    vocab_dict['timestamp_buckets'].tolist()\n",
    ")(user_ts_input_layer)\n",
    "\n",
    "user_ts_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['timestamp_buckets'].tolist()) + NUM_OOV_BUCKETS,\n",
    "    output_dim=GLOBAL_EMBEDDING_SIZE\n",
    ")(user_ts_lookup)\n",
    "\n",
    "user_ts_embedding = tf.reduce_sum(user_ts_embedding, axis=-2)\n",
    "\n",
    "# global_inputs.append(user_ts_input_layer)\n",
    "# global_features.append(user_ts_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db99f90b-57f8-45e6-9f28-871658e17358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([885409515], shape=(1,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[ 0.04824615 -0.03723484 -0.02526428 -0.02786946  0.01017333 -0.04271851\n",
      "   0.04245594 -0.02367212 -0.00820632  0.04160209  0.03692377 -0.00322026\n",
      "  -0.04952119  0.01209617 -0.02420617 -0.00394206]], shape=(1, 16), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_user_ts_model = tf.keras.Model(inputs=user_ts_input_layer, outputs=user_ts_embedding)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(x[\"timestamp\"])\n",
    "    print(test_user_ts_model(x[\"timestamp\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc734ea-cb5e-4c6b-8b94-2a8853220178",
   "metadata": {},
   "source": [
    "#### define global sampling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff58c380-8b53-4dfa-b5b4-d36853638ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_global_context_features(x):\n",
    "    \"\"\"\n",
    "    This function generates a single global observation vector.\n",
    "    \"\"\"\n",
    "    user_id_value = x['user_id']\n",
    "    user_age_value = x['bucketized_user_age']\n",
    "    user_occ_value = x['user_occupation_text']\n",
    "    user_ts_value = x['timestamp']\n",
    "\n",
    "    _id = test_user_id_model(user_id_value) # input_tensor=tf.Tensor(shape=(4,), dtype=float32)\n",
    "    _age = test_user_age_model(user_age_value)\n",
    "    _occ = test_user_occ_model(user_occ_value)\n",
    "    _ts = test_user_ts_model(user_ts_value)\n",
    "\n",
    "    # # tmp - insepct numpy() values\n",
    "    # print(_id.numpy()) #[0])\n",
    "    # print(_age.numpy()) #[0])\n",
    "    # print(_occ.numpy()) #[0])\n",
    "    # print(_ts.numpy()) #[0])\n",
    "\n",
    "    # to numpy array\n",
    "    _id = np.array(_id.numpy())\n",
    "    _age = np.array(_age.numpy())\n",
    "    _occ = np.array(_occ.numpy())\n",
    "    _ts = np.array(_ts.numpy())\n",
    "\n",
    "    concat = np.concatenate(\n",
    "        [_id, _age, _occ, _ts], axis=-1 # -1\n",
    "    ).astype(np.float32)\n",
    "    \n",
    "    user_info = [\n",
    "                user_age_value.numpy(),\n",
    "                user_occ_value.numpy(),\n",
    "                user_ts_value.numpy(),\n",
    "                x['user_zip_code'].numpy(),\n",
    "                x['user_gender'].numpy(),\n",
    "                x['movie_title'].numpy(),\n",
    "                x['user_rating'].numpy()\n",
    "                ]\n",
    "\n",
    "    return concat, user_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d583b8f8-df19-4bfc-a963-81874d41523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1):\n",
    "    \n",
    "    iterator = iter(train_dataset.batch(5))\n",
    "    data = next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d693e5b-ab19-438c-b8eb-3be677e4c621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bucketized_user_age': <tf.Tensor: shape=(5,), dtype=float32, numpy=array([35., 18., 56., 45., 35.], dtype=float32)>,\n",
       " 'movie_genres': <tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n",
       " array([[7],\n",
       "        [4],\n",
       "        [9],\n",
       "        [4],\n",
       "        [7]])>,\n",
       " 'movie_id': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'898', b'367', b'484', b'494', b'58'], dtype=object)>,\n",
       " 'movie_title': <tf.Tensor: shape=(5,), dtype=string, numpy=\n",
       " array([b'Postman, The (1997)', b'Clueless (1995)',\n",
       "        b'Maltese Falcon, The (1941)', b'His Girl Friday (1940)',\n",
       "        b'Quiz Show (1994)'], dtype=object)>,\n",
       " 'timestamp': <tf.Tensor: shape=(5,), dtype=int64, numpy=array([885409515, 883388887, 891249586, 878044851, 880130613])>,\n",
       " 'user_gender': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'False', b'True', b'True', b'True', b'False'], dtype=object)>,\n",
       " 'user_id': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'681', b'442', b'932', b'506', b'18'], dtype=object)>,\n",
       " 'user_occupation_label': <tf.Tensor: shape=(5,), dtype=int64, numpy=array([14, 17,  0, 12, 11])>,\n",
       " 'user_occupation_text': <tf.Tensor: shape=(5,), dtype=string, numpy=\n",
       " array([b'marketing', b'student', b'educator', b'programmer', b'other'],\n",
       "       dtype=object)>,\n",
       " 'user_rating': <tf.Tensor: shape=(5,), dtype=float32, numpy=array([4., 2., 5., 5., 4.], dtype=float32)>,\n",
       " 'user_zip_code': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'97208', b'85282', b'06437', b'03869', b'37212'], dtype=object)>}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "557c2d7a-bac0-405b-904c-f05731abb8a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.04985065, -0.00532871, -0.03634857, -0.04782307, -0.0151373 ,\n",
       "          0.01437653,  0.03545219,  0.03968345,  0.02484528, -0.0112708 ,\n",
       "          0.02281231, -0.02392597, -0.01318774, -0.00431702,  0.00012762,\n",
       "          0.03880258,  0.0498643 ,  0.01750484,  0.02067177,  0.04393334,\n",
       "         -0.04336467,  0.03129146, -0.01701912,  0.01351896, -0.01740777,\n",
       "         -0.04474656, -0.00899174, -0.02451527, -0.01704979,  0.03550223,\n",
       "         -0.02412467, -0.04029829, -0.04159627,  0.02417859, -0.04973073,\n",
       "          0.04730998,  0.02376128, -0.03412268, -0.00291198,  0.02347748,\n",
       "         -0.03014418, -0.01471244,  0.00205895,  0.03073821,  0.00395476,\n",
       "         -0.03008027,  0.0374867 , -0.00221273,  0.04824615, -0.03723484,\n",
       "         -0.02526428, -0.02786946,  0.01017333, -0.04271851,  0.04245594,\n",
       "         -0.02367212, -0.00820632,  0.04160209,  0.03692377, -0.00322026,\n",
       "         -0.04952119,  0.01209617, -0.02420617, -0.00394206],\n",
       "        [-0.03852405,  0.01466588, -0.04401129,  0.00246976,  0.00756371,\n",
       "         -0.03482337,  0.04759622, -0.02156109, -0.02475225, -0.03971888,\n",
       "          0.01379016,  0.02881435, -0.03080667, -0.00182773, -0.02155071,\n",
       "          0.04032321, -0.01025771,  0.01210256, -0.04517112,  0.00238149,\n",
       "         -0.04288596, -0.02613628,  0.00459609,  0.00407928, -0.04845097,\n",
       "          0.00047473, -0.02402033,  0.01439426, -0.03262012,  0.02898801,\n",
       "          0.03789322,  0.02611493, -0.01791229,  0.00543711,  0.02495328,\n",
       "          0.00256958, -0.0364456 , -0.00091095,  0.00123105, -0.00596   ,\n",
       "          0.01954344,  0.01637001, -0.03641511,  0.04309333, -0.00163959,\n",
       "         -0.03350413,  0.0329016 , -0.02720757, -0.01292083,  0.00201822,\n",
       "          0.03886363,  0.03920505,  0.03584233,  0.00154425, -0.0180468 ,\n",
       "          0.0464264 , -0.01728251,  0.04101117, -0.0355057 , -0.02544568,\n",
       "          0.01845438,  0.04742913, -0.00952412, -0.03257851],\n",
       "        [ 0.04845859, -0.02855843, -0.04795165, -0.04734367, -0.00064979,\n",
       "          0.00814765,  0.00487792,  0.00487243,  0.01019948, -0.0495773 ,\n",
       "          0.03986951, -0.01959532, -0.03408401,  0.0415067 , -0.02718357,\n",
       "          0.03415135, -0.00638341,  0.01007401,  0.00288787,  0.03582806,\n",
       "         -0.0313473 , -0.02099731, -0.02645789,  0.00829835, -0.03940836,\n",
       "         -0.03700713, -0.01915226,  0.04217314, -0.03193076, -0.00257618,\n",
       "          0.03536398, -0.00550926,  0.00290332, -0.01771532,  0.02317834,\n",
       "         -0.01974843, -0.04874021, -0.01188976, -0.03809088, -0.00786446,\n",
       "         -0.02839402,  0.00899611, -0.0280146 , -0.04076687, -0.04894255,\n",
       "          0.03370048,  0.01001941, -0.02880886, -0.00449206, -0.02772111,\n",
       "          0.01574457, -0.0093164 ,  0.02675733, -0.00139965,  0.01599151,\n",
       "         -0.01282706, -0.02252403, -0.03034755,  0.01829783, -0.0338226 ,\n",
       "         -0.00455034,  0.03506866,  0.00580387, -0.02605851],\n",
       "        [-0.0453648 ,  0.02211399,  0.0129041 , -0.02547433, -0.04855413,\n",
       "          0.01795221, -0.04088949,  0.04865005,  0.01843208, -0.02932111,\n",
       "          0.02989138, -0.04054134, -0.02828985,  0.04550501,  0.03790433,\n",
       "         -0.01126831, -0.00076009,  0.04221991, -0.0125234 , -0.01391996,\n",
       "          0.04706538, -0.0405818 , -0.01789991,  0.01434041,  0.02449653,\n",
       "          0.04186649,  0.01709832, -0.01807569, -0.04043119,  0.04086259,\n",
       "          0.04713858,  0.00193592, -0.00102665, -0.02936018, -0.0225837 ,\n",
       "          0.04433825,  0.0457649 , -0.01224693, -0.0420877 ,  0.00081193,\n",
       "         -0.03496169, -0.02706989,  0.03452848,  0.00124437, -0.02663483,\n",
       "         -0.02664814, -0.02917241,  0.02438906, -0.03674452, -0.04021002,\n",
       "          0.00982107,  0.02137102, -0.02614566,  0.04937042,  0.03162966,\n",
       "         -0.04651126, -0.03400164, -0.01710983,  0.03112015,  0.04165016,\n",
       "         -0.04664546,  0.04847838,  0.04925395,  0.02106376],\n",
       "        [-0.02707192, -0.03256691,  0.00873141,  0.03230784, -0.03808073,\n",
       "          0.00374643,  0.04836104,  0.04937788, -0.01871274, -0.02208563,\n",
       "          0.0233943 ,  0.02494098,  0.04897375,  0.03410964,  0.00771443,\n",
       "          0.04502415,  0.0498643 ,  0.01750484,  0.02067177,  0.04393334,\n",
       "         -0.04336467,  0.03129146, -0.01701912,  0.01351896, -0.01740777,\n",
       "         -0.04474656, -0.00899174, -0.02451527, -0.01704979,  0.03550223,\n",
       "         -0.02412467, -0.04029829, -0.01107533, -0.02614181,  0.00410501,\n",
       "          0.00744363, -0.04641273, -0.0051573 , -0.0334182 , -0.00215967,\n",
       "          0.01644446, -0.01811438, -0.04675919,  0.03248898, -0.04326432,\n",
       "          0.00018121,  0.03810035,  0.04432011,  0.04956925, -0.03455042,\n",
       "         -0.01693392,  0.00074134, -0.00693083, -0.04097334, -0.0221943 ,\n",
       "         -0.04809237, -0.00913674,  0.00421583, -0.01954091, -0.03267448,\n",
       "          0.03809902, -0.02958568, -0.02352936, -0.01121277]],\n",
       "       dtype=float32),\n",
       " [array([35., 18., 56., 45., 35.], dtype=float32),\n",
       "  array([b'marketing', b'student', b'educator', b'programmer', b'other'],\n",
       "        dtype=object),\n",
       "  array([885409515, 883388887, 891249586, 878044851, 880130613]),\n",
       "  array([b'97208', b'85282', b'06437', b'03869', b'37212'], dtype=object),\n",
       "  array([b'False', b'True', b'True', b'True', b'False'], dtype=object),\n",
       "  array([b'Postman, The (1997)', b'Clueless (1995)',\n",
       "         b'Maltese Falcon, The (1941)', b'His Girl Friday (1940)',\n",
       "         b'Quiz Show (1994)'], dtype=object),\n",
       "  array([4., 2., 5., 5., 4.], dtype=float32)])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_get_global_context_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c9f64a0-a713-49bc-9043-d6e9598ecc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #check how this works with batches - new JW\n",
    "\n",
    "# batch_elem = train_dataset.batch(4)\n",
    "# _get_global_context_features(batch_elem)\n",
    "_get_global_context_features(data)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bba133ab-bf12-4b3b-926d-6d1dba940837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04985065, -0.00532871, -0.03634857, -0.04782307, -0.0151373 ,\n",
       "         0.01437653,  0.03545219,  0.03968345,  0.02484528, -0.0112708 ,\n",
       "         0.02281231, -0.02392597, -0.01318774, -0.00431702,  0.00012762,\n",
       "         0.03880258,  0.0498643 ,  0.01750484,  0.02067177,  0.04393334,\n",
       "        -0.04336467,  0.03129146, -0.01701912,  0.01351896, -0.01740777,\n",
       "        -0.04474656, -0.00899174, -0.02451527, -0.01704979,  0.03550223,\n",
       "        -0.02412467, -0.04029829, -0.04159627,  0.02417859, -0.04973073,\n",
       "         0.04730998,  0.02376128, -0.03412268, -0.00291198,  0.02347748,\n",
       "        -0.03014418, -0.01471244,  0.00205895,  0.03073821,  0.00395476,\n",
       "        -0.03008027,  0.0374867 , -0.00221273,  0.04824615, -0.03723484,\n",
       "        -0.02526428, -0.02786946,  0.01017333, -0.04271851,  0.04245594,\n",
       "        -0.02367212, -0.00820632,  0.04160209,  0.03692377, -0.00322026,\n",
       "        -0.04952119,  0.01209617, -0.02420617, -0.00394206]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in train_dataset.batch(1).take(1):\n",
    "    test_globals = _get_global_context_features(x)[0]\n",
    "\n",
    "\n",
    "test_globals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249fa771-35d7-4d04-ab68-2b70911bac17",
   "metadata": {},
   "source": [
    "### arm preprocessing layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534b3bf1-a2ea-4bfb-8c77-efa057f4e391",
   "metadata": {},
   "source": [
    "#### movie ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa53cbe9-2616-4da4-90dc-dc5616258af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_id_input_layer = tf.keras.Input(\n",
    "    name=\"movie_id\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.string\n",
    ")\n",
    "\n",
    "mv_id_lookup = tf.keras.layers.StringLookup(\n",
    "    max_tokens=len(vocab_dict['movie_id']) + NUM_OOV_BUCKETS,\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    mask_token=None,\n",
    "    vocabulary=vocab_dict['movie_id'],\n",
    ")(mv_id_input_layer)\n",
    "\n",
    "mv_id_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['movie_id']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=MV_EMBEDDING_SIZE\n",
    ")(mv_id_lookup)\n",
    "\n",
    "mv_id_embedding = tf.reduce_sum(mv_id_embedding, axis=-2)\n",
    "\n",
    "# arm_inputs.append(mv_id_input_layer)\n",
    "# arm_features.append(mv_id_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9bd19f09-a12e-4a21-a1a1-5ec5bc116559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'898'], shape=(1,), dtype=string)\n",
      "tf.Tensor(\n",
      "[[ 2.9839065e-02  4.3478463e-02  3.3711139e-02 -5.3103343e-03\n",
      "   2.5926497e-02  3.2517876e-02  3.1127620e-02  3.8917433e-02\n",
      "  -1.2352146e-02  4.5045502e-03  3.7784401e-02 -4.0707566e-02\n",
      "  -3.7679397e-02  2.7542163e-02 -4.3932654e-02  2.8583873e-02\n",
      "  -1.1236202e-02 -1.9827032e-02  2.6680529e-05 -4.4116866e-02\n",
      "  -3.3988833e-02 -2.6035989e-02 -3.2419205e-02 -2.6791383e-02\n",
      "  -4.0899467e-02  4.3474678e-02 -4.6743657e-02 -9.1361403e-03\n",
      "  -1.3182662e-02 -3.7597846e-02 -4.4649877e-02 -3.3789419e-02]], shape=(1, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_mv_id_model = tf.keras.Model(inputs=mv_id_input_layer, outputs=mv_id_embedding)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(x[\"movie_id\"])\n",
    "    print(test_mv_id_model(x[\"movie_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4a0e97-c477-4042-b9c0-fcb0f428de0d",
   "metadata": {},
   "source": [
    "#### movie genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f04a0091-d7b0-4f90-ba7c-3eb41dd0b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_genre_input_layer = tf.keras.Input(\n",
    "    name=\"movie_genres\",\n",
    "    shape=(1,),\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "mv_genre_lookup = tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=vocab_dict['movie_genres'],\n",
    "    num_oov_indices=NUM_OOV_BUCKETS,\n",
    "    oov_value=0,\n",
    ")(mv_genre_input_layer)\n",
    "\n",
    "mv_genre_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=len(vocab_dict['movie_genres']) + NUM_OOV_BUCKETS,\n",
    "    output_dim=MV_EMBEDDING_SIZE\n",
    ")(mv_genre_lookup)\n",
    "\n",
    "mv_genre_embedding = tf.reduce_sum(mv_genre_embedding, axis=-2)\n",
    "\n",
    "# arm_inputs.append(mv_genre_input_layer)\n",
    "# arm_features.append(mv_genre_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51701f0a-9b3e-461c-a9d9-a0c146e310ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[7]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([b'898'], shape=(1,), dtype=string)\n",
      "tf.Tensor(\n",
      "[[ 0.02208023 -0.01955887 -0.04026396  0.01497472 -0.02997371  0.01104837\n",
      "   0.03397714  0.03898871  0.0022672  -0.01143551  0.01823893  0.034534\n",
      "   0.02520943 -0.03739471  0.003416    0.01997819 -0.03580929  0.0044561\n",
      "   0.01427997 -0.01928221  0.0200863   0.00109242  0.01242606 -0.03740204\n",
      "  -0.02423847 -0.01556424  0.02208086 -0.00347357  0.02771068  0.04412636\n",
      "  -0.04575131 -0.04112302]], shape=(1, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_mv_gen_model = tf.keras.Model(inputs=mv_genre_input_layer, outputs=mv_genre_embedding)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    print(x[\"movie_genres\"])\n",
    "    print(x[\"movie_id\"])\n",
    "    print(test_mv_gen_model(x[\"movie_genres\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b41cc9-63f5-4559-a943-1288be9c0892",
   "metadata": {},
   "source": [
    "#### define sampling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8727904e-e9b6-4005-8cf3-9da461ca88b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_per_arm_features(x):\n",
    "    \"\"\"\n",
    "    This function generates a single per-arm observation vector\n",
    "    \"\"\"\n",
    "    mv_id_value = x['movie_id']\n",
    "    mv_gen_value = x['movie_genres']\n",
    "\n",
    "    _mid = test_mv_id_model(mv_id_value)\n",
    "    _mgen = test_mv_gen_model(mv_gen_value)\n",
    "\n",
    "    # to numpy array\n",
    "    _mid = np.array(_mid.numpy())\n",
    "    _mgen = np.array(_mgen.numpy())\n",
    "\n",
    "    # print(_mid)\n",
    "    # print(_mgen)\n",
    "\n",
    "    concat = np.concatenate(\n",
    "        [_mid, _mgen], axis=-1 # -1\n",
    "    ).astype(np.float32)\n",
    "    # concat = tf.concat([_mid, _mgen], axis=-1).astype(np.float32)\n",
    "\n",
    "    return concat #this is special to this example - there is only one action dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78d3c6bb-e525-4408-b321-34ac9684f881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_get_per_arm_features(data).shape #shape checks out at batchdim, nactions, arm feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ff5764-25de-4f4c-ada3-3a417bdf22b5",
   "metadata": {},
   "source": [
    "### Create a moive lookup Table 🆕\n",
    "\n",
    "This will be used in our trajectories to randomly select a movie. Using the produced embeddings, we will also have a reward function for each combination by taking the inner product via `tf_agents.bandits.networks.global_and_arm_feature_network.create_feed_forward_dot_product_network` [link](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/create_feed_forward_dot_product_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "770c3473-622f-44eb-b512-e96c4b08a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_lookup_table = {'id': [],\n",
    "                      'movie_features': [],\n",
    "                      'movie_title': [],\n",
    "                      'movie_genres': []\n",
    "                     }\n",
    "    \n",
    "iterator = iter(train_dataset.batch(1000))\n",
    "for data in iterator:\n",
    "    _get_per_arm_features(data)\n",
    "    movie_lookup_table['id'].extend(data['movie_id'].numpy())\n",
    "    movie_lookup_table['movie_title'].extend(data['movie_title'].numpy())\n",
    "    movie_lookup_table['movie_genres'].extend(data['movie_genres'].numpy())\n",
    "    movie_lookup_table['movie_features'].extend(_get_per_arm_features(data))\n",
    "    \n",
    "#fix string ids to integers for random lookup later\n",
    "movie_lookup_table['id'] = [int(x) for x in movie_lookup_table['id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66eed76c-79c2-415e-8dd9-e4ee85b5e769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "movie_lookup_table = pd.DataFrame(movie_lookup_table)\n",
    "movie_lookup_table.set_index(['id'])\n",
    "\n",
    "unique_table = movie_lookup_table.groupby(['id'])[['movie_features', 'movie_title', 'movie_genres']].first().reset_index() #resetting index to get consecutive counts from min-max (no gaps)\n",
    "# unique_table = unique_table['movie_features']\n",
    "MAX_ARM_ID = len(unique_table)-1\n",
    "MIN_ARM_ID = 0\n",
    "\n",
    "# unique_table\n",
    "# print(f\"Max movie id is: {MAX_ARM_ID} \\nMin movie id is: {MIN_ARM_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8184ea44-5ae0-4986-922b-57ee76cc4783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04199721, -0.01619434,  0.04603427, -0.04955646, -0.00389193,\n",
       "        0.02242848, -0.00715657, -0.01680515, -0.02460772,  0.01151638,\n",
       "       -0.02413342, -0.03370956,  0.04893183,  0.04284496, -0.03869026,\n",
       "       -0.03878802,  0.00801231, -0.00828094, -0.00230019,  0.00795852,\n",
       "        0.01847408, -0.03179461,  0.01945977,  0.04064328,  0.04443154,\n",
       "        0.00373792,  0.04830568,  0.00381659,  0.02832551,  0.00730548,\n",
       "        0.00994366,  0.03522381,  0.03278095, -0.04140655,  0.01985857,\n",
       "        0.03007633,  0.01269777,  0.04643209, -0.00660162,  0.02340465,\n",
       "       -0.03996553, -0.0346284 , -0.04106172,  0.0351813 ,  0.04791807,\n",
       "       -0.03364198, -0.01633372,  0.01626501, -0.01038989,  0.02794788,\n",
       "        0.01873789, -0.03610713, -0.00898061, -0.0485724 , -0.01319156,\n",
       "       -0.04487716, -0.04154819,  0.02125347, -0.02685132, -0.04695855,\n",
       "       -0.0213308 , -0.02232081,  0.0395064 ,  0.03194532], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_table.iloc[2,:]['movie_features'] #example of getting a ra movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6284375d-410c-4cd5-be8b-3889d39f98b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 64), dtype=float32, numpy=\n",
       " array([[ 0.02970613,  0.04528726,  0.01751051, -0.02838322, -0.04812825,\n",
       "          0.0426867 , -0.00959599, -0.01610552,  0.01713183, -0.04932121,\n",
       "          0.04996418,  0.00654826, -0.04804268, -0.01668183, -0.03752805,\n",
       "         -0.02543222, -0.01497787, -0.02868832,  0.04612055,  0.02590767,\n",
       "          0.02387318,  0.03753884,  0.03263697,  0.03906978, -0.03457846,\n",
       "          0.042194  , -0.04130067,  0.04848139, -0.02717181,  0.03452963,\n",
       "          0.03038082,  0.03437102,  0.02208023, -0.01955887, -0.04026396,\n",
       "          0.01497472, -0.02997371,  0.01104837,  0.03397714,  0.03898871,\n",
       "          0.0022672 , -0.01143551,  0.01823893,  0.034534  ,  0.02520943,\n",
       "         -0.03739471,  0.003416  ,  0.01997819, -0.03580929,  0.0044561 ,\n",
       "          0.01427997, -0.01928221,  0.0200863 ,  0.00109242,  0.01242606,\n",
       "         -0.03740204, -0.02423847, -0.01556424,  0.02208086, -0.00347357,\n",
       "          0.02771068,  0.04412636, -0.04575131, -0.04112302]],\n",
       "       dtype=float32)>,\n",
       " [b'Sling Blade (1996)', array([7])])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_random_arm_features(movie_id):\n",
    "    movie_info = unique_table.iloc[movie_id]\n",
    "    tensor = tf.constant(movie_info['movie_features'], dtype=tf.float32)\n",
    "    return tf.reshape(tensor, [1, tensor.shape[0]]), [movie_info['movie_title'],\n",
    "                                                     movie_info['movie_genres']]\n",
    "\n",
    "get_random_arm_features(222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "4502fdb6-26ff-46d2-8bb4-1bcf5a06eff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_random_set_of_arm_features(n_actions, batch_size):\n",
    "#     random_arm_ids = list(np.random.randint(MIN_ARM_ID, MAX_ARM_ID, [n_actions, batch_size]))\n",
    "#     features = [[get_random_arm_features(y)for  y in x] for x in random_arm_ids]\n",
    "\n",
    "\n",
    "#     just_features = []\n",
    "#     movie_info = []\n",
    "\n",
    "#     for batch in features:\n",
    "#         mv_batch = []\n",
    "#         ft_batch = []\n",
    "#         for movie in batch:\n",
    "#             mv_batch.append(movie[1])\n",
    "#             ft_batch.append(movie[0])\n",
    "\n",
    "#         just_features.append(ft_batch)\n",
    "#         movie_info.append(mv_batch)\n",
    "        \n",
    "#     return tf.concat(just_features, axis=1), movie_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "56f020a5-9ac8-46b7-b4b5-257a5cd03398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_set_of_arm_features(n_actions):\n",
    "    random_arm_ids = list(np.random.randint(MIN_ARM_ID, MAX_ARM_ID, n_actions))\n",
    "    features = [get_random_arm_features(x) for x in random_arm_ids]\n",
    "    just_features = [x[0] for x in features]\n",
    "    movie_info = [x[1] for x in features]\n",
    "    return tf.concat(just_features, axis=0), movie_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a334c538-6dab-4db3-9593-8621d5ef060c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 64), dtype=float32, numpy=\n",
       "array([[-3.77837047e-02, -4.44305800e-02, -3.77738103e-02,\n",
       "         3.26050632e-02,  4.35559489e-02, -3.45671773e-02,\n",
       "        -9.97591764e-04, -2.47161631e-02,  1.78802498e-02,\n",
       "         3.07814218e-02,  1.67111307e-03, -4.77316044e-02,\n",
       "        -4.88835238e-02, -1.76937506e-03, -2.44718678e-02,\n",
       "        -4.48186770e-02,  3.44013609e-02,  3.34247090e-02,\n",
       "         4.56397794e-02,  3.46958078e-02, -4.23412211e-02,\n",
       "         2.42480151e-02, -4.24454324e-02,  3.90671976e-02,\n",
       "         8.40470940e-03, -3.58206853e-02, -1.95907000e-02,\n",
       "         3.70730199e-02, -4.89797257e-02, -1.63216107e-02,\n",
       "        -1.30703077e-02, -3.31087857e-02, -2.19113827e-02,\n",
       "        -4.60078977e-02,  6.49236143e-04, -8.34643841e-04,\n",
       "        -1.07753277e-02, -1.55765936e-03,  2.17966102e-02,\n",
       "         3.59028243e-02,  9.99056175e-03, -1.03803053e-02,\n",
       "         2.19280608e-02,  1.40321963e-02, -4.64068316e-02,\n",
       "         2.38215923e-03,  4.04522568e-03,  3.82455103e-02,\n",
       "         5.16420603e-03, -5.45924902e-03,  2.39966623e-02,\n",
       "        -1.98230036e-02, -1.23313442e-02, -2.97714472e-02,\n",
       "         9.86405462e-03, -2.04735044e-02, -3.30743678e-02,\n",
       "        -2.97914147e-02,  2.38320269e-02, -4.17267159e-03,\n",
       "        -1.65139921e-02, -3.82941961e-03, -2.07507610e-03,\n",
       "         4.69048060e-02],\n",
       "       [ 1.41745247e-02, -4.11628373e-02,  1.90627910e-02,\n",
       "        -4.98624817e-02,  3.61863114e-02, -4.86616008e-02,\n",
       "         3.14583816e-02,  3.19011100e-02, -2.58619674e-02,\n",
       "        -3.66501696e-02, -7.82382488e-03,  1.37804262e-02,\n",
       "         2.31360272e-03, -1.45661831e-02,  2.48091333e-02,\n",
       "         3.76112200e-02,  6.41158968e-03,  1.20218769e-02,\n",
       "         3.18477862e-02, -2.09214091e-02,  2.16303356e-02,\n",
       "        -4.34433594e-02,  2.13232748e-02, -4.47572358e-02,\n",
       "         4.92288135e-02, -1.57046318e-03, -2.50770450e-02,\n",
       "        -2.03746092e-02,  9.71071422e-05,  1.79037564e-02,\n",
       "        -1.28924474e-02, -2.06876639e-02,  2.20802315e-02,\n",
       "        -1.95588712e-02, -4.02639620e-02,  1.49747245e-02,\n",
       "        -2.99737100e-02,  1.10483654e-02,  3.39771397e-02,\n",
       "         3.89887132e-02,  2.26720423e-03, -1.14355087e-02,\n",
       "         1.82389282e-02,  3.45340036e-02,  2.52094306e-02,\n",
       "        -3.73947136e-02,  3.41600180e-03,  1.99781917e-02,\n",
       "        -3.58092897e-02,  4.45610285e-03,  1.42799728e-02,\n",
       "        -1.92822106e-02,  2.00862996e-02,  1.09242275e-03,\n",
       "         1.24260560e-02, -3.74020450e-02, -2.42384672e-02,\n",
       "        -1.55642405e-02,  2.20808648e-02, -3.47356871e-03,\n",
       "         2.77106799e-02,  4.41263579e-02, -4.57513109e-02,\n",
       "        -4.11230214e-02]], dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_set_of_arm_features(n_actions=2)[0] #NEW - there's a tuple returned with the movies we will use for PALM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a52c9f62-04f9-4f50-912c-d2f75b5f6986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([35., 18., 56., 45., 35.], dtype=float32), array([b'marketing', b'student', b'educator', b'programmer', b'other'],\n",
      "      dtype=object), array([885409515, 883388887, 891249586, 878044851, 880130613]), array([b'97208', b'85282', b'06437', b'03869', b'37212'], dtype=object), array([b'False', b'True', b'True', b'True', b'False'], dtype=object), array([b'Postman, The (1997)', b'Clueless (1995)',\n",
      "       b'Maltese Falcon, The (1941)', b'His Girl Friday (1940)',\n",
      "       b'Quiz Show (1994)'], dtype=object), array([4., 2., 5., 5., 4.], dtype=float32)] [[b'Kim (1950)', array([3])], [b'Some Kind of Wonderful (1987)', array([7])], [b'Senseless (1998)', array([4])]]\n"
     ]
    }
   ],
   "source": [
    "### Look at the raw input features to format a good prompt for ranking movies\n",
    "NUM_ACTIONS = 3\n",
    "batch_size = 5\n",
    "iterator = iter(train_dataset.batch(batch_size))\n",
    "data = next(iterator)\n",
    "\n",
    "_, user_info = _get_global_context_features(data) #new - user info passes on the raw user features for prompting with PALM\n",
    "###NEW - we are getting the arm features here\n",
    "_, movie_info = get_random_set_of_arm_features(n_actions=NUM_ACTIONS)\n",
    "\n",
    "print(user_info, movie_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1f331390-f23b-4f41-a218-2a9211fba9c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wed Jan 21 19:05:15 1998'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "dt = datetime.utcfromtimestamp(885409515)\n",
    "dt.ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ce9675e3-1a41-4533-b9fa-7fd02bba84c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[b'Kim (1950)', array([3])],\n",
       " [b'Some Kind of Wonderful (1987)', array([7])],\n",
       " [b'Senseless (1998)', array([4])]]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf81d87-00c0-40f6-ae0e-0fa9a1e7aa7a",
   "metadata": {},
   "source": [
    "### Feature formats info\n",
    "https://www.tensorflow.org/datasets/catalog/movielens\n",
    "BUCKETIZED AGE\n",
    "```python\n",
    "{\n",
    "'1': \"Under 18\"\n",
    "'18': \"18-24\"\n",
    "'25': \"25-34\"\n",
    "'35': \"35-44\"\n",
    "'45': \"45-49\"\n",
    "'50': \"50-55\"\n",
    "'56': \"56+\"\n",
    "}\n",
    "```\n",
    "\n",
    "https://files.grouplens.org/datasets/movielens/ml-10m-README.html\n",
    "\n",
    "```python\n",
    "genre_list = \n",
    "[\n",
    "\"Action\",\n",
    "\"Adventure\",\n",
    "\"Animation\",\n",
    "\"Children's\",\n",
    "\"Comedy\",\n",
    "\"Crime\",\n",
    "\"Documentary\",\n",
    "\"Drama\",\n",
    "\"Fantasy\",\n",
    "\"Film-Noir\",\n",
    "\"Horror\",\n",
    "\"Musical\",\n",
    "\"Mystery\",\n",
    "\"Romance\",\n",
    "\"Sci-Fi\",\n",
    "\"Thriller\",\n",
    "\"War\",\n",
    "\"Western\",\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "a804c78a-40b3-4b4c-85ff-b8810e93192d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You are looking to watch a movie and need to rate each movie based on user '\n",
      " 'demographics \\n'\n",
      " 'Here are some info on this the user: \\n'\n",
      " 'the user is age is 35-44, n\\n'\n",
      " 'and lives in zipcode 97208\\n'\n",
      " \"the user's occupation is marketing \\n\"\n",
      " 'the user previously reviewed Postman, The (1997), \\n'\n",
      " 'giving it a 4 out five star review during Wed Jan 21 19:05:15 1998\\n'\n",
      " '    \\n'\n",
      " 'Please rate these movies below using using \\n'\n",
      " '5 - highly recomended movie\\n'\n",
      " '4 - somewhat recommend movie\\n'\n",
      " '3 - maybe watch movie\\n'\n",
      " '2 - not a good movie\\n'\n",
      " '1 - really bad movie\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " \"1. Kansas City (1996), ['Crime']\\n\"\n",
      " \"2. Some Like It Hot (1959), ['Comedy']\\n\"\n",
      " \"3. Walking and Talking (1996), ['Sci-Fi']\\n\"\n",
      " \"4. Awfully Big Adventure, An (1995), ['Drama']\\n\"\n",
      " ' please rate the 4 movies\\n'\n",
      " ' ensure you return the ratings as a python list of just the ratings for 4 '\n",
      " 'movies')\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "age_text_lookup = {\n",
    "'1': \"Under 18\",\n",
    "'18': \"18-24\",\n",
    "'25': \"25-34\",\n",
    "'35': \"35-44\",\n",
    "'45': \"45-49\",\n",
    "'50': \"50-55\",\n",
    "'56': \"56+\"\n",
    "}\n",
    "\n",
    "genre_list = [\n",
    "    \"Action\",\n",
    "    \"Adventure\",\n",
    "    \"Animation\",\n",
    "    \"Children's\",\n",
    "    \"Comedy\",\n",
    "    \"Crime\",\n",
    "    \"Documentary\",\n",
    "    \"Drama\",\n",
    "    \"Fantasy\",\n",
    "    \"Film-Noir\",\n",
    "    \"Horror\",\n",
    "    \"Musical\",\n",
    "    \"Mystery\",\n",
    "    \"Romance\",\n",
    "    \"Sci-Fi\",\n",
    "    \"Thriller\",\n",
    "    \"War\",\n",
    "    \"Western\",\n",
    "] #use this to lookup genres\n",
    "\n",
    "def gender_movielens_translator(elem):\n",
    "    if elem==\"True\":\n",
    "        return \"male\" \n",
    "    else:\n",
    "        return \"non-male\"\n",
    "\n",
    "rating_scale = '''\n",
    "5 - highly recomended movie\n",
    "4 - somewhat recommend movie\n",
    "3 - maybe watch movie\n",
    "2 - not a good movie\n",
    "1 - really bad movie\n",
    "'''\n",
    "\n",
    "age, occ, time, zipcode, gender, ex_movie, ex_movie_rating = user_info[0], user_info[1], user_info[2], user_info[3], user_info[4], user_info[5], user_info[6]\n",
    "\n",
    "prompts = []\n",
    "for i in range(len(age)):\n",
    "    formatted_datetime = datetime.utcfromtimestamp(time[i]).ctime()\n",
    "    gender = gender_movielens_translator(gender[i])\n",
    "    prompt = f\"\"\"You are looking to watch a movie and need to rate each movie based on user demographics \n",
    "Here are some info on this the user: \n",
    "the user is age is {age_text_lookup[str(int(age[i]))]}, {gender[i]}\n",
    "and lives in zipcode {zipcode[i].decode(\"utf-8\")}\n",
    "the user's occupation is {occ[i].decode(\"utf-8\")} \n",
    "the user previously reviewed {ex_movie[i].decode(\"utf-8\")}, \n",
    "giving it a {int(ex_movie_rating[i])} out five star review during {formatted_datetime}\n",
    "    \n",
    "Please rate these movies below using using {rating_scale}\n",
    "\"\"\"\n",
    "    \n",
    "    for i, movie in enumerate(movie_info):\n",
    "        prompt += f\"\\n{i+1}. {movie[0].decode('utf-8')}, {[genre_list[i] for i in movie[1]]}\"\n",
    "        total_movies = i+1\n",
    "    prompt += f\"\\n please rate the {total_movies} movies\"\n",
    "    prompt += f\"\\n ensure you return the ratings as a python list of just the ratings for {total_movies} movies\"\n",
    "        \n",
    "    ## next add in the movie selections\n",
    "    prompts.append(prompt)\n",
    "pprint(prompts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "fb050b77-ede5-4745-a166-6ade8e401c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RL_prompt(user_info, movie_info):\n",
    "    \n",
    "    age, occ, time, zipcode, gender, ex_movie, ex_movie_rating = user_info[0], user_info[1], user_info[2], user_info[3], user_info[4], user_info[5], user_info[6]\n",
    "\n",
    "    prompts = []\n",
    "    for i in range(len(age)):\n",
    "        formatted_datetime = datetime.utcfromtimestamp(time[i]).ctime()\n",
    "        gender = gender_movielens_translator(gender[i])\n",
    "        prompt = f\"\"\"You are looking to watch a movie and need to rate each movie based on user demographics \n",
    "    Here are some info on this the user: \n",
    "    the user is age is {age_text_lookup[str(int(age[i]))]}, {gender[i]}\n",
    "    and lives in zipcode {zipcode[i].decode(\"utf-8\")}\n",
    "    the user's occupation is {occ[i].decode(\"utf-8\")} \n",
    "    the user previously reviewed {ex_movie[i].decode(\"utf-8\")}, \n",
    "    giving it a {int(ex_movie_rating[i])} out five star review during {formatted_datetime}\n",
    "\n",
    "    Please rate these movies below using using {rating_scale}\n",
    "    \"\"\"\n",
    "\n",
    "        for i, movie in enumerate(movie_info):\n",
    "            prompt += f\"\\n{i+1}. {movie[0].decode('utf-8')}, {[genre_list[i] for i in movie[1]]}\"\n",
    "            total_movies = i+1\n",
    "        prompt += f\"\\n please rate the {total_movies} movies\"\n",
    "        prompt += f\"\\n ensure you return the ratings as a python list of just the ratings for {total_movies} movies\"\n",
    "\n",
    "        ## next add in the movie selections\n",
    "        prompts.append(prompt)\n",
    "    return prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "697199de-e949-4533-affb-a8c96563c55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are looking to watch a movie and need to rate each movie based on user demographics \\n    Here are some info on this the user: \\n    the user is age is 35-44, n\\n    and lives in zipcode 97208\\n    the user's occupation is marketing \\n    the user previously reviewed Postman, The (1997), \\n    giving it a 4 out five star review during Wed Jan 21 19:05:15 1998\\n\\n    Please rate these movies below using using \\n5 - highly recomended movie\\n4 - somewhat recommend movie\\n3 - maybe watch movie\\n2 - not a good movie\\n1 - really bad movie\\n\\n    \\n1. Kansas City (1996), ['Crime']\\n2. Some Like It Hot (1959), ['Comedy']\\n3. Walking and Talking (1996), ['Sci-Fi']\\n4. Awfully Big Adventure, An (1995), ['Drama']\\n please rate the 4 movies\\n ensure you return the ratings as a python list of just the ratings for 4 movies\""
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts = RL_prompt(user_info, movie_info)\n",
    "\n",
    "len(prompts)\n",
    "prompts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3458f058-6346-4636-97db-f8fa02e89984",
   "metadata": {},
   "source": [
    "## Adding in reward function with PALM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "a1526b43-e69e-4d35-9145-05d0c2aaee18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am doing well today, thank you for asking! I am excited to be learning more about natural language processing and how it can be used to improve the customer experience.'"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Adding in reward function with PALM!\n",
    "\n",
    "import vertexai\n",
    "from vertexai.language_models import TextGenerationModel\n",
    "\n",
    "vertexai.init(project=\"wortz-project-352116\", location=\"us-central1\")\n",
    "parameters = {\n",
    "    \"temperature\": 0.4,\n",
    "    \"max_output_tokens\": 1000,\n",
    "    \"top_p\": 0.8,\n",
    "    \"top_k\": 40\n",
    "}\n",
    "llm = TextGenerationModel.from_pretrained(\"text-bison\")\n",
    "response = llm.predict(\n",
    "    \"How are you today?\",\n",
    "    **parameters\n",
    ")\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "b7223dca-5b0a-42a4-bea8-857e14649535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3, 4, 2'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "### Test prompt!\n",
    "# pprint(prompts[0])\n",
    "rating = llm.predict(prompts[0], **parameters)\n",
    "extraction_prompt = \"extract the ratings in order in a simple comma seperated list:\"\n",
    "ratings = llm.predict(f\"{rating.text} {extraction_prompt}\", **parameters)\n",
    "ratings.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f88e860c-b1c2-403b-8b15-6d8d8ca51a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.0, 4.0, 2.0]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[float(x) for x in ratings.text.split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "b4911b38-0cec-4f9f-874b-b37040e7f678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_call(prompts):\n",
    "    ratings_list = []\n",
    "    for prompt in prompts:\n",
    "        rating = llm.predict(prompts[0], **parameters)\n",
    "        extraction_prompt = \"extract the ratings a comma seperated list:\"\n",
    "        ratings = llm.predict(f\"{rating.text} {extraction_prompt}\", **parameters)\n",
    "        ratings_list.append(ratings.text)\n",
    "    return ratings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "39574548-f50e-437f-a2af-fddc565e23fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 3\n"
     ]
    }
   ],
   "source": [
    "#now try to put it together by getting ratings for a batch with multiple arms\n",
    "\n",
    "print(batch_size, NUM_ACTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "a267366d-6f6e-4b28-a4da-85dc4b3538c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unvalidated_llm_response = llm_call(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "d0e6b0b2-f0ba-46bb-a7d9-1648e6a099ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4, 4, 3, 3',\n",
       " '3, 4, 3, 4',\n",
       " '4, 3, 3, 3',\n",
       " '4, 4, 3, 4',\n",
       " '4, 5, 3, 4',\n",
       " '4, 5, 3, 4',\n",
       " '4, 5, 3, 4',\n",
       " '4, 4, 3, 3']"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unvalidated_llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "56487957-39af-43e6-bc52-9bae34bfc6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def validate_llm_response(llm_response):\n",
    "    \"this formats the text lists into a list of floats and also\"\n",
    "    \"TODO - handles when LLM has poor output\"\n",
    "    str_list =  [[y for y in x.split(',')] for x in llm_response]\n",
    "    re_clean_list = [[re.findall(r'\\d+', y) for y in x] for x in str_list]\n",
    "    return [[float(y[-1]) for y in x] for x in re_clean_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "9e656d8f-63f2-4855-bdae-711b933ed9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4.0, 4.0, 3.0, 3.0],\n",
       " [3.0, 4.0, 3.0, 4.0],\n",
       " [4.0, 3.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 3.0, 4.0],\n",
       " [4.0, 5.0, 3.0, 4.0],\n",
       " [4.0, 5.0, 3.0, 4.0],\n",
       " [4.0, 5.0, 3.0, 4.0],\n",
       " [4.0, 4.0, 3.0, 3.0]]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_rewards = validate_llm_response(unvalidated_llm_response)\n",
    "llm_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3e01ba-8d4f-4d18-b07e-e4183dddd48e",
   "metadata": {},
   "source": [
    "## Finally, put it together into the LLM reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "3a08075a-4cae-45d1-b0fc-cb6418cd338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_reward(user_info, movie_info):\n",
    "    prompts = RL_prompt(user_info, movie_info)\n",
    "    unvalidated_llm_response = llm_call(prompts)\n",
    "    return validate_llm_response(unvalidated_llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "03de09e2-5ce4-4158-8185-e7635e6be7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4.0, 4.0, 3.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 3.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 4.0, 3.0, 3.0],\n",
       " [4.0, 3.0, 4.0, 3.0, 3.0],\n",
       " [4.0, 3.0, 4.0, 3.0, 3.0],\n",
       " [3.0, 4.0, 4.0, 3.0, 4.0],\n",
       " [3.0, 4.0, 4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 3.0, 4.0, 3.0]]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Look at the raw input features to format a good prompt for ranking movies\n",
    "NUM_ACTIONS = 5\n",
    "batch_size = 8\n",
    "iterator = iter(train_dataset.batch(batch_size))\n",
    "data = next(iterator)\n",
    "\n",
    "_, user_info = _get_global_context_features(data) #new - user info passes on the raw user features for prompting with PALM\n",
    "###NEW - we are getting the arm features here\n",
    "_, movie_info = get_random_set_of_arm_features(n_actions=NUM_ACTIONS)\n",
    "\n",
    "llm_reward(user_info, movie_info) #batch size by n_actions/arms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac6836c-67b7-4fd4-917a-24ddad708edd",
   "metadata": {},
   "source": [
    "## TF-Agents implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1877c79c-b6c8-4048-b1ce-05f011e8d69e",
   "metadata": {},
   "source": [
    "In TF-Agents, the *per-arm features* implementation differs from the *global-only* feature examples in the following aspects:\n",
    "* Reward is modeled not per-arm, but globally.\n",
    "* The arms are permutation invariant: it doesn’t matter which arm is arm 1 or arm 2, only their features.\n",
    "* One can have a different number of arms to choose from in every step (note that unspecified/dynamically changing number of arms will have a problem with XLA compatibility).\n",
    "\n",
    "When implementing per-arm features in TF-Bandits, the following details have to be discussed:\n",
    "* Observation spec and observations,\n",
    "* Action spec and actions,\n",
    "* Implementation of specific policies and agents.\n",
    "\n",
    "\n",
    "**TODO:**\n",
    "* outline the components and highlight their interactions, dependencies on eachother, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "7ff9baaf-987d-448d-a981-742a79b581e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE  : 8\n",
      "NUM_ACTIONS : 10\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE  = 8\n",
    "NUM_ACTIONS = 10 \n",
    "\n",
    "# GLOBAL_EMBEDDING_SIZE  = 16\n",
    "# MV_EMBEDDING_SIZE      = 32 #32\n",
    "\n",
    "GLOBAL_DIM = GLOBAL_EMBEDDING_SIZE * 4 # 4 global features in this example\n",
    "PER_ARM_DIM = MV_EMBEDDING_SIZE * 2 # 2 movie features\n",
    "\n",
    "print(f\"BATCH_SIZE  : {BATCH_SIZE}\")\n",
    "print(f\"NUM_ACTIONS : {NUM_ACTIONS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeb4902-5bb9-4587-8d29-c01d78b006be",
   "metadata": {},
   "source": [
    "## Tensor Specs\n",
    "\n",
    "**TODO:**\n",
    "* explain relationship between Tensor Specs and their Tensor counterparts\n",
    "* highlight the errors, lessons learned, and utility functions to address these"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f68ebe8-116d-43b3-a6e1-4f5a5c7f4741",
   "metadata": {},
   "source": [
    "### Observation spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9c4746-d01b-4ca4-aa53-ab68da54d37a",
   "metadata": {},
   "source": [
    "**This observation spec allows the user to have a global observation of fixed dimension**, and an unspecified number of *per-arm* features (also of fixed dimension)\n",
    "* The actions output by the policy are still integers as usual, and they indicate which row of the arm-features it has chosen \n",
    "* The action spec must be a single integer value without boundaries:\n",
    "\n",
    "```python\n",
    "global_spec = tensor_spec.TensorSpec([GLOBAL_DIM], tf.float32)\n",
    "per_arm_spec = tensor_spec.TensorSpec([None, PER_ARM_DIM], tf.float32)\n",
    "observation_spec = {'global': global_spec, 'per_arm': per_arm_spec}\n",
    "\n",
    "action_spec = tensor_spec.TensorSpec((), tf.int32)\n",
    "```\n",
    "> Here the only difference compared to the action spec with global features only is that the tensor spec is not bounded, as we don’t know how many arms there will be at any time step\n",
    "\n",
    "**XLA compatibility:**\n",
    "* Since dynamic tensor shapes are not compatible with XLA, the number of arm features (and consequently, number of arms for a step) cannot be dynamic. \n",
    "* One workaround is to fix the maximum number of arms for a problem, then pad the arm features in steps with fewer arms, and use action masking to indicate how many arms are actually active.\n",
    "\n",
    "```python\n",
    "per_arm_spec = tensor_spec.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32)\n",
    "\n",
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=(), dtype=tf.int32, minimum = 0, maximum = NUM_ACTIONS - 1\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "36bd3b33-635a-4274-8b9e-7172696ebb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(10, 64), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_spec = {\n",
    "    'global': tf.TensorSpec([GLOBAL_DIM], tf.float32),\n",
    "    'per_arm': tf.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32) #excluding action dim here\n",
    "}\n",
    "observation_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a2da92-7db2-4f42-94a7-b7bad1c8fc42",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Action spec\n",
    "\n",
    "> The time_step_spec and action_spec are specifications for the input time step and the output action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5af42c7-18d7-480f-a7f3-d7da3f4840eb",
   "metadata": {},
   "source": [
    "```python\n",
    "    if (\n",
    "        not tensor_spec.is_bounded(action_spec)\n",
    "        or not tensor_spec.is_discrete(action_spec)\n",
    "        or action_spec.shape.rank > 1\n",
    "        or action_spec.shape.num_elements() != 1\n",
    "    ):\n",
    "      raise NotImplementedError(\n",
    "          'action_spec must be a BoundedTensorSpec of type int32 and shape (). '\n",
    "          'Found {}.'.format(action_spec)\n",
    "      )\n",
    "```\n",
    "\n",
    "* [src](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_base_policy.py#L97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "549a123c-349a-4103-b39a-4502f47d1e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(9, dtype=int32))"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=[], \n",
    "    dtype=tf.int32,\n",
    "    minimum=tf.constant(0),            \n",
    "    maximum=NUM_ACTIONS-1, #n degrees of freedom and will dictate the expected mean reward spec shape\n",
    "    name=\"action_spec\"\n",
    ")\n",
    "\n",
    "action_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a51efce-9f1b-42d1-bec4-7b788e3fd7e0",
   "metadata": {},
   "source": [
    "### TimeStep spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "95f05860-0fbf-4a5a-8273-9c81761e0ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
       "                 'per_arm': TensorSpec(shape=(10, 64), dtype=tf.float32, name=None)},\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec = ts.time_step_spec(observation_spec)#, reward_spec=tf.TensorSpec([1, NUM_ACTIONS]))\n",
    "time_step_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9c197-ae9b-461d-8956-f078b929ac12",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The Agent\n",
    "\n",
    "**Note** that contextual bandits form a special case of RL, where the actions taken by the agent do not alter the state of the environment \n",
    "\n",
    "> “Contextual” refers to the fact that the agent chooses among a set of actions while having knowledge of the context (environment observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aadb01-eb5c-4870-ae14-9e66624ba594",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Agent types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d075e8a6-11a9-4346-8725-3653fba4bac4",
   "metadata": {},
   "source": [
    "**Possible Agent Types:**\n",
    "\n",
    "```\n",
    "AGENT_TYPE = ['LinUCB', 'LinTS', 'epsGreedy', 'NeuralLinUCB']\n",
    "```\n",
    "\n",
    "**LinearUCBAgent:** (`LinUCB`)\n",
    "* An agent implementing the Linear UCB bandit algorithm\n",
    "* (whitepaper) [A contextual bandit approach to personalized news recommendation](https://arxiv.org/abs/1003.0146)\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/lin_ucb_agent/LinearUCBAgent)\n",
    "\n",
    "**LinearThompsonSamplingAgent:** (`LinTS`)\n",
    "* Implements the Linear Thompson Sampling Agent from the paper: [Thompson Sampling for Contextual Bandits with Linear Payoffs](https://arxiv.org/abs/1209.3352)\n",
    "* the agent maintains two parameters `weight_covariances` and `parameter_estimators`, and updates them based on experience.\n",
    "* The inverse of the weight covariance parameters are updated with the outer product of the observations using the Woodbury inverse matrix update, while the parameter estimators are updated by the reward-weighted observation vectors for every action\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/linear_thompson_sampling_agent/LinearThompsonSamplingAgent)\n",
    "\n",
    "**NeuralEpsilonGreedyAgent:** (`epsGreedy`) \n",
    "* A neural network based epsilon greedy agent\n",
    "* This agent receives a neural network that it trains to predict rewards\n",
    "* The action is chosen greedily with respect to the prediction with probability `1 - epsilon`, and uniformly randomly with probability epsilon\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_epsilon_greedy_agent/NeuralEpsilonGreedyAgent)\n",
    "\n",
    "**NeuralLinUCBAgent:** (`NeuralLinUCB`)\n",
    "* An agent implementing the LinUCB algorithm on top of a neural network\n",
    "* `ENCODING_DIM` is the output dimension of the encoding network \n",
    "> * This output will be used by either a linear reward layer and epsilon greedy exploration, or by a LinUCB logic, depending on the number of training steps executed so far\n",
    "* `EPS_PHASE_STEPS` is the number training steps to run for training the encoding network before switching to `LinUCB`\n",
    "> * If negative, the encoding network is assumed to be already trained\n",
    "> * If the number of steps is less than or equal to `EPS_PHASE_STEPS`, `epsilon greedy` is used, otherwise `LinUCB`\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/agents/neural_linucb_agent/NeuralLinUCBAgent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b8e88e-c8ea-4193-a911-0d974ef3b1a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### network types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f547087d-5fad-4521-a584-cb46ce52897d",
   "metadata": {},
   "source": [
    "Which network architecture to use for the `epsGreedy` or `NeuralLinUCB` agents\n",
    "\n",
    "```\n",
    "NETWORK_TYPE = ['commontower', 'dotproduct']\n",
    "```\n",
    "\n",
    "**GlobalAndArmCommonTowerNetwork:** (`commontower`)\n",
    "* This network takes the output of the global and per-arm networks, and leads them through a common network, that in turn outputs reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "> * `COMMON_LAYERS` - Iterable of ints. Specifies the layers of the common tower\n",
    "* The network produced by this function can be used either in `GreedyRewardPredictionPolicy`, or `NeuralLinUCBPolicy`\n",
    "> * In the former case, the network must have `output_dim=1`, it is going to be an instance of `QNetwork`, and used in the policy as a reward prediction network\n",
    "> * In the latter case, the network will be an encoding network with its output consumed by a reward layer or a `LinUCB` method. The specified `output_dim` will be the encoding dimension\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmCommonTowerNetwork)\n",
    "\n",
    "**GlobalAndArmDotProductNetwork:** (`dotproduct`)\n",
    "* This network calculates the **dot product** of the output of the global and per-arm networks and returns them as reward estimates\n",
    "> * `GLOBAL_LAYERS` - Iterable of ints. Specifies the layers of the global tower\n",
    "> * `ARM_LAYERS` - Iterable of ints. Specifies the layers of the arm tower\n",
    "* [docs](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmDotProductNetwork)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3dc270-deb5-4e96-8276-74759a06c318",
   "metadata": {},
   "source": [
    "### define agent and network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "6d817bf2-1fa6-4bae-af90-745fad996b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 8,\n",
      " 'common_layers': [100],\n",
      " 'epsilon': 0.4,\n",
      " 'global_layers': [50, 50, 50],\n",
      " 'learning_rate': 0.005,\n",
      " 'model_type': 'epsGreedy',\n",
      " 'network_type': 'dotproduct',\n",
      " 'num_actions': 10,\n",
      " 'per_arm_layers': [50, 50, 50]}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Agents\n",
    "# ================================\n",
    "AGENT_TYPE      = 'epsGreedy' # 'LinUCB' | 'LinTS |, 'epsGreedy' | 'NeuralLinUCB'\n",
    "\n",
    "# Parameters for linear agents (LinUCB and LinTS).\n",
    "AGENT_ALPHA     = 0.1\n",
    "\n",
    "# Parameters for neural agents (NeuralEpsGreedy and NerualLinUCB).\n",
    "EPSILON         = 0.4\n",
    "LR              = 0.005\n",
    "\n",
    "# Parameters for NeuralLinUCB\n",
    "ENCODING_DIM    = 1\n",
    "EPS_PHASE_STEPS = 1000\n",
    "\n",
    "# ================================\n",
    "# Agent's Preprocess Network\n",
    "# ================================\n",
    "NETWORK_TYPE    = \"dotproduct\" # 'commontower' | 'dotproduct'\n",
    "\n",
    "if AGENT_TYPE == 'NeuralLinUCB':\n",
    "    NETWORK_TYPE = 'commontower'\n",
    "    \n",
    "\n",
    "GLOBAL_LAYERS   = [50, 50, 50]\n",
    "ARM_LAYERS      = [50, 50, 50]\n",
    "COMMON_LAYERS   = [100]\n",
    "\n",
    "observation_and_action_constraint_splitter = None\n",
    "\n",
    "HPARAMS = {  # TODO - streamline and consolidate\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"num_actions\": NUM_ACTIONS,\n",
    "    \"model_type\": AGENT_TYPE,\n",
    "    \"network_type\": NETWORK_TYPE,\n",
    "    \"global_layers\": GLOBAL_LAYERS,\n",
    "    \"per_arm_layers\": ARM_LAYERS,\n",
    "    \"common_layers\": COMMON_LAYERS,\n",
    "    \"learning_rate\": LR,\n",
    "    \"epsilon\": EPSILON,\n",
    "}\n",
    "pprint(HPARAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db165067-6e9d-4b79-b675-bae69ec98c10",
   "metadata": {},
   "source": [
    "### Agent Factory\n",
    "\n",
    "**TODO:**\n",
    "* consolidate agent, network, and hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "e7c79df4-f975-49fc-b598-d6fd2f6be125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\n",
      "\n",
      "time_step_spec:  TimeStep(\n",
      "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'observation': {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None),\n",
      "                 'per_arm': TensorSpec(shape=(10, 64), dtype=tf.float32, name=None)},\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n",
      "\n",
      "action_spec:  BoundedTensorSpec(shape=(), dtype=tf.int32, name='action_spec', minimum=array(0, dtype=int32), maximum=array(9, dtype=int32))\n",
      "\n",
      "observation_spec:  {'global': TensorSpec(shape=(64,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(10, 64), dtype=tf.float32, name=None)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Quick check on the inputs of the agent - this can be used to diagnose spec shape inputs\")\n",
    "print(\"\\ntime_step_spec: \", time_step_spec)\n",
    "print(\"\\naction_spec: \", action_spec)\n",
    "print(\"\\nobservation_spec: \", observation_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "6cb60f0b-90b7-49ab-9c41-046ea00ab750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: OffpolicyNeuralEpsGreedyAgent\n",
      "\n",
      "Network: GlobalAndArmDotProductNetwork\n"
     ]
    }
   ],
   "source": [
    "# from tf_agents.bandits.policies import policy_utilities\n",
    "# from tf_agents.bandits.agents import greedy_reward_prediction_agent\n",
    "\n",
    "network = None\n",
    "observation_and_action_constraint_splitter = None\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "if AGENT_TYPE == 'LinUCB':\n",
    "    agent = lin_ucb_agent.LinearUCBAgent(\n",
    "        time_step_spec=time_step_spec,\n",
    "        action_spec=action_spec,\n",
    "        alpha=AGENT_ALPHA,\n",
    "        accepts_per_arm_features=True,\n",
    "        dtype=tf.float32,\n",
    "    )\n",
    "elif AGENT_TYPE == 'LinTS':\n",
    "    agent = lin_ts_agent.LinearThompsonSamplingAgent(\n",
    "        time_step_spec=time_step_spec,\n",
    "        action_spec=action_spec,\n",
    "        alpha=AGENT_ALPHA,\n",
    "        observation_and_action_constraint_splitter=(\n",
    "            observation_and_action_constraint_splitter\n",
    "        ),\n",
    "        accepts_per_arm_features=True,\n",
    "        dtype=tf.float32,\n",
    "    )\n",
    "elif AGENT_TYPE == 'epsGreedy':\n",
    "    # obs_spec = per_arm_tf_env.observation_spec()\n",
    "    if NETWORK_TYPE == 'commontower':\n",
    "        network = global_and_arm_feature_network.create_feed_forward_common_tower_network(\n",
    "            observation_spec = observation_spec, \n",
    "            global_layers = GLOBAL_LAYERS, \n",
    "            arm_layers = ARM_LAYERS, \n",
    "            common_layers = COMMON_LAYERS,\n",
    "            # output_dim = 1\n",
    "        )\n",
    "    elif NETWORK_TYPE == 'dotproduct':\n",
    "        network = global_and_arm_feature_network.create_feed_forward_dot_product_network(\n",
    "            observation_spec = observation_spec, \n",
    "            global_layers = GLOBAL_LAYERS, \n",
    "            arm_layers = ARM_LAYERS\n",
    "        )\n",
    "    agent = neural_epsilon_greedy_agent.NeuralEpsilonGreedyAgent(\n",
    "        time_step_spec=time_step_spec,\n",
    "        action_spec=action_spec,\n",
    "        reward_network=network,\n",
    "        optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=HPARAMS['learning_rate']),\n",
    "        epsilon=HPARAMS['epsilon'],\n",
    "        observation_and_action_constraint_splitter=(\n",
    "            observation_and_action_constraint_splitter\n",
    "        ),\n",
    "        accepts_per_arm_features=True,\n",
    "        emit_policy_info=policy_utilities.InfoFields.PREDICTED_REWARDS_MEAN,\n",
    "        train_step_counter=global_step,\n",
    "        # info_fields_to_inherit_from_greedy=['predicted_rewards_mean'],\n",
    "        name='OffpolicyNeuralEpsGreedyAgent'\n",
    "    )\n",
    "\n",
    "elif AGENT_TYPE == 'NeuralLinUCB':\n",
    "    # obs_spec = per_arm_tf_env.observation_spec()\n",
    "    network = (\n",
    "        global_and_arm_feature_network.create_feed_forward_common_tower_network(\n",
    "            observation_spec = observation_spec, \n",
    "            global_layers = GLOBAL_LAYERS, \n",
    "            arm_layers = ARM_LAYERS, \n",
    "            common_layers = COMMON_LAYERS,\n",
    "            output_dim = ENCODING_DIM\n",
    "        )\n",
    "    )\n",
    "    agent = neural_linucb_agent.NeuralLinUCBAgent(\n",
    "        time_step_spec=per_arm_tf_env.time_step_spec(),\n",
    "        action_spec=per_arm_tf_env.action_spec(),\n",
    "        encoding_network=network,\n",
    "        encoding_network_num_train_steps=EPS_PHASE_STEPS,\n",
    "        encoding_dim=ENCODING_DIM,\n",
    "        optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=LR),\n",
    "        alpha=1.0,\n",
    "        gamma=1.0,\n",
    "        epsilon_greedy=EPSILON,\n",
    "        accepts_per_arm_features=True,\n",
    "        debug_summaries=True,\n",
    "        summarize_grads_and_vars=True,\n",
    "        emit_policy_info=policy_utilities.InfoFields.PREDICTED_REWARDS_MEAN,\n",
    "    )\n",
    "    \n",
    "agent.initialize() # TODO - does this go here?\n",
    "    \n",
    "print(f\"Agent: {agent.name}\\n\")\n",
    "if network:\n",
    "    print(f\"Network: {network.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d404dae-3cc3-4f81-962b-4641455ca4f2",
   "metadata": {},
   "source": [
    "## Reward function\n",
    "\n",
    "**TODO:**\n",
    "* explain how to translate reward to this common recommendation objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "df9aecd6-d20a-48a7-9ead-4da3bbcfdae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _get_rewards(element):\n",
    "#     \"\"\"Calculates reward for the actions.\"\"\"\n",
    "\n",
    "#     def _calc_reward(x):\n",
    "#         \"\"\"Calculates reward for a single action.\"\"\"\n",
    "#         r0 = lambda: tf.constant(0.0)\n",
    "#         r1 = lambda: tf.constant(-10.0)\n",
    "#         r2 = lambda: tf.constant(2.0)\n",
    "#         r3 = lambda: tf.constant(3.0)\n",
    "#         r4 = lambda: tf.constant(4.0)\n",
    "#         r5 = lambda: tf.constant(10.0)\n",
    "#         c1 = tf.equal(x, 1.0)\n",
    "#         c2 = tf.equal(x, 2.0)\n",
    "#         c3 = tf.equal(x, 3.0)\n",
    "#         c4 = tf.equal(x, 4.0)\n",
    "#         c5 = tf.equal(x, 5.0)\n",
    "#         return tf.case(\n",
    "#             [(c1, r1), (c2, r2), (c3, r3),(c4, r4),(c5, r5)], \n",
    "#             default=r0, exclusive=True\n",
    "#         )\n",
    "\n",
    "#     return tf.map_fn(\n",
    "#         fn=_calc_reward, \n",
    "#         elems=element['user_rating'], \n",
    "#         dtype=tf.float32\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a18218-5062-470d-a715-86020e6a2f51",
   "metadata": {},
   "source": [
    "### New - exploring the dot product network\n",
    "\n",
    "Let's get the dot proudcut of arm/global features for the trajectories\n",
    "\n",
    "Looking at source [code](https://github.com/tensorflow/agents/blob/v0.17.0/tf_agents/bandits/networks/global_and_arm_feature_network.py#L54-L138)\n",
    "\n",
    "```python\n",
    "return GlobalAndArmDotProductNetwork(obs_spec_no_num_actions, global_network,\n",
    "                                       arm_network)\n",
    "```\n",
    "\n",
    "Leads to [here](https://www.tensorflow.org/agents/api_docs/python/tf_agents/bandits/networks/global_and_arm_feature_network/GlobalAndArmDotProductNetwork#get_initial_state)\n",
    "\n",
    "Also member the config\n",
    "\n",
    "- GLOBAL_LAYERS   = [16, 4]\n",
    "- ARM_LAYERS      = [16, 4]\n",
    "- COMMON_LAYERS   = [4]\n",
    "\n",
    "```python\n",
    "network = global_and_arm_feature_network.create_feed_forward_dot_product_network(\n",
    "            observation_spec = observation_spec, \n",
    "            global_layers = GLOBAL_LAYERS, \n",
    "            arm_layers = ARM_LAYERS\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac59703a-9a00-4eba-a3b7-45b21b738dd4",
   "metadata": {},
   "source": [
    "## Trajectory function\n",
    "\n",
    "**parking lot**\n",
    "* does trajectory fn need concept of `dummy_chosen_arm_features`, similar to [this](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/policies/reward_prediction_base_policy.py#L297)\n",
    "\n",
    "```python\n",
    "      dummy_chosen_arm_features = tf.nest.map_structure(\n",
    "          lambda obs: tf.zeros_like(obs[:, 0, ...]),\n",
    "          time_step.observation[bandit_spec_utils.PER_ARM_FEATURE_KEY],\n",
    "      )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "bcb31c7b-f03e-4d9f-a0f8-2f8ad8318d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "\n",
    "def _trajectory_fn(element, batch_size): # hparams\n",
    "        \n",
    "    \"\"\"Converts a dataset element into a trajectory.\"\"\"\n",
    "    global_features, user_info = _get_global_context_features(element) #new - user info passes on the raw user features for prompting with PALM\n",
    "    ###NEW - we are getting the arm features here\n",
    "    arm_features, movie_info = get_random_set_of_arm_features(n_actions=NUM_ACTIONS)\n",
    "    # arm_features = get_random_set_of_arm_features(n_actions=NUM_ACTIONS)\n",
    "    \n",
    "    #get the dot product reward of the feed-forward network\n",
    "    reward = llm_reward(user_info, movie_info)\n",
    "    \n",
    "    #chose an arm\n",
    "    best_arm_ids = tf.argmax(reward, axis=1)\n",
    "    # best_arm_ids = tf.cast(best_arm_ids, dtype=tf.int32)\n",
    "    max_rewards = tf.math.reduce_max(reward, axis=1)\n",
    "    max_rewards = _add_outer_dimension(max_rewards) # add time dim\n",
    "    chosen_arm_feats = tf.gather(arm_features, best_arm_ids) # [batch_size, arm_features]\n",
    "    \n",
    "    chosen_arm_feats = _add_outer_dimension(chosen_arm_feats)\n",
    "    # Adds a time dimension.\n",
    "    arm_features = _add_outer_dimension(arm_features)\n",
    "\n",
    "    # obs spec\n",
    "    observation = {\n",
    "        bandit_spec_utils.GLOBAL_FEATURE_KEY:\n",
    "            _add_outer_dimension(global_features), #timedim bloat\n",
    "    }\n",
    "    \n",
    "    \n",
    "    reward = _add_outer_dimension(reward)\n",
    "    \n",
    "    ###TODO - not sure if this should actually go in the action for trajectory\n",
    "    # best_arm_ids =  _add_outer_dimension(best_arm_ids)\n",
    "    \n",
    "    dummy_rewards = tf.zeros([batch_size, 1, NUM_ACTIONS])\n",
    "    \n",
    "    policy_info = policy_utilities.PerArmPolicyInfo(\n",
    "        chosen_arm_features=chosen_arm_feats,\n",
    "        # Pass dummy mean rewards here to match the model_spec for emitting\n",
    "        # mean rewards in policy info\n",
    "        predicted_rewards_mean=dummy_rewards\n",
    "    )\n",
    "    \n",
    "    if HPARAMS['model_type'] == 'neural_ucb':\n",
    "        policy_info = policy_info._replace(\n",
    "            predicted_rewards_optimistic=dummy_rewards\n",
    "        )\n",
    "        \n",
    "    return trajectory.single_step(\n",
    "        observation=observation,\n",
    "        action=tf.zeros_like(\n",
    "            max_rewards, dtype=tf.int32\n",
    "        ),  # Arm features are copied from policy info, put dummy zeros here\n",
    "        policy_info=policy_info,\n",
    "        reward=max_rewards,\n",
    "        discount=tf.zeros_like(max_rewards)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b3d3c-75f7-46f4-9a1b-6329e419b7f5",
   "metadata": {},
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bb7ffc-00df-4d46-857b-86c87b78f597",
   "metadata": {},
   "source": [
    "`agent.train(experience=...)`\n",
    "\n",
    "where `experience` is a batch of trajectories data in the form of a Trajectory. \n",
    "* The structure of experience must match that of `self.training_data_spec`. \n",
    "* All tensors in experience must be shaped [batch, time, ...] where time must be equal to self.train_step_length if that property is not None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "4cf53ca1-f827-424f-adf4-0edaf863da42",
   "metadata": {},
   "outputs": [],
   "source": [
    "##todo - create a function that selects the best movie features along with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "da4680f3-693b-4530-8e4d-88bc43036c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:26<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Can't convert non-rectangular Python sequence to Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[325], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# print(f\"print data: {data}\")\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m trajectories \u001b[38;5;241m=\u001b[39m \u001b[43m_trajectory_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint trajectories: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrajectories\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# All tensors in experience must be shaped [batch, time, ...] \u001b[39;00m\n",
      "Cell \u001b[0;32mIn[323], line 16\u001b[0m, in \u001b[0;36m_trajectory_fn\u001b[0;34m(element, batch_size)\u001b[0m\n\u001b[1;32m     13\u001b[0m reward \u001b[38;5;241m=\u001b[39m llm_reward(user_info, movie_info)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#chose an arm\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m best_arm_ids \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# best_arm_ids = tf.cast(best_arm_ids, dtype=tf.int32)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m max_rewards \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mreduce_max(reward, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    102\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Can't convert non-rectangular Python sequence to Tensor."
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from tf_agents.utils import common\n",
    "from tqdm import tqdm\n",
    "\n",
    "NUM_EPOCHS = 2\n",
    "\n",
    "\n",
    "# global_step = tf.compat.v1.train.get_global_step()\n",
    "\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "agent.train = common.function(agent.train)\n",
    "\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "train_loss = collections.defaultdict(list)\n",
    "list_o_loss = []\n",
    "\n",
    "\n",
    "iterator = iter(train_dataset.repeat().batch(BATCH_SIZE)) #added repeat here for diagnostics\n",
    "\n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "    \n",
    "    data = next(iterator)\n",
    "    # print(f\"print data: {data}\")\n",
    "    \n",
    "    trajectories = _trajectory_fn(data, BATCH_SIZE)\n",
    "    print(f\"print trajectories: {trajectories}\")\n",
    "    \n",
    "    # All tensors in experience must be shaped [batch, time, ...] \n",
    "    step = agent.train_step_counter.numpy()\n",
    "    loss = agent.train(experience=trajectories)\n",
    "    list_o_loss.append(loss.loss.numpy())\n",
    "    \n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313f23f1-6870-48fb-97fd-1bda065edffc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualize the agent's loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c4dc23-83fe-465b-aff6-c786a0866408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_o_loss)\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "622afa02-3f83-44b6-ac80-2d0fefe5659c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get a spline view to de-nose\n",
    "\n",
    "# https://stackoverflow.com/questions/5283649/plot-smooth-line-with-pyplot\n",
    "\n",
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "\n",
    "# 300 represents number of points to make between T.min and T.max\n",
    "xnew = np.linspace(0, NUM_EPOCHS, 300) \n",
    "\n",
    "spl = make_interp_spline(np.array(range(NUM_EPOCHS)), list_o_loss, k=3)  # type: BSpline\n",
    "power_smooth = spl(xnew)\n",
    "\n",
    "plt.plot(xnew, power_smooth)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m109"
  },
  "kernelspec": {
   "display_name": "TensorFlow 2-11 (Local)",
   "language": "python",
   "name": "local-conda-env-tensorflow-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
