{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7767b603-7035-4fb3-b727-9704383e93a2",
   "metadata": {},
   "source": [
    "# REINFORCE recommender agent\n",
    "\n",
    "```\n",
    "Top-K Off-Policy Correction for a REINFORCE Recommender System\n",
    "Minmin Chen, Alex Beutel, Paul Covington, Sagar Jain, Francois Belletti, Ed Chi\n",
    "https://arxiv.org/pdf/1812.02353.pdf\n",
    "```\n",
    "This notebook steps details how to train and evaluate the REINFORCE Recommender agent from the paper above. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fde96d8-ab7e-4846-8391-1b4603f5df9a",
   "metadata": {},
   "source": [
    "## env setup\n",
    "\n",
    "if implementing a scann index for efficient `action retreival` function, install `scann` (and version):\n",
    "\n",
    "> scann==1.2.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ba60d66-b31e-4250-be7d-00b0736a4eaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "VERSION        = \"v2\"                       # TODO\n",
    "PREFIX         = f'rec-bandits-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dd67236-2dcc-44d1-b633-0a80f2c0ebdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"rec-bandits-v2\"\n",
      "VERSION                  = \"v2\"\n",
      "\n",
      "BUCKET_NAME              = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_NAME    = \"mvlens_rec_bandits_v2\"\n",
      "BIGQUERY_TABLE_NAME      = \"training_dataset\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-rec-bandits-v2\"\n",
      "\n",
      "DOCKERNAME_01            = \"Dockerfile_train_my_perarm_env\"\n",
      "IMAGE_NAME_01            = \"train-my-perarm-env-v2\"\n",
      "IMAGE_URI_01             = \"gcr.io/hybrid-vertex/train-my-perarm-env-v2\"\n",
      "\n",
      "DOCKERNAME_02            = \"Dockerfile_perarm_feats\"\n",
      "IMAGE_NAME_02            = \"train-perarm-feats-v2\"\n",
      "IMAGE_URI_02             = \"gcr.io/hybrid-vertex/train-perarm-feats-v2\"\n",
      "\n",
      "DOCKERNAME_03            = \"Dockerfile_ranking_bandit\"\n",
      "IMAGE_NAME_03            = \"train-rank-bandit-v2\"\n",
      "IMAGE_URI_03             = \"gcr.io/hybrid-vertex/train-rank-bandit-v2\"\n",
      "\n",
      "DOCKERNAME_04            = \"Dockerfile_train_bandit_e2e\"\n",
      "IMAGE_NAME_04            = \"train-mab-e2e-v2\"\n",
      "IMAGE_URI_04             = \"gcr.io/hybrid-vertex/train-mab-e2e-v2\"\n",
      "\n",
      "DOCKERNAME_04_pred       = \"Dockerfile_pred_bandit_e2e\"\n",
      "IMAGE_NAME_04_pred       = \"pred-mab-e2e-v2\"\n",
      "IMAGE_URI_04_pred        = \"gcr.io/hybrid-vertex/pred-mab-e2e-v2\"\n",
      "\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/local_docker_tfa\"\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449a67ff-c853-4ac7-8ddf-37c9c71ee466",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74ec9e9c-73c9-4e3b-bb07-13e8c9cb5241",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "404e8b3c-63bb-453a-8798-729e8ce16d0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import functools\n",
    "import collections\n",
    "import pickle as pkl\n",
    "from pprint import pprint\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# tf-agents\n",
    "from tf_agents.utils import common\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import sequential\n",
    "from tf_agents.metrics import export_utils\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.train.utils import strategy_utils\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "# this repo\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.data import data_utils as data_utils\n",
    "from src.data import data_config as data_config\n",
    "from src.agents import rfa_utils as rfa_utils\n",
    "from src.networks import encoding_network as emb_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e72c8c2-9a8a-487e-8631-17ce5a572894",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "438a50ed-ff68-41f3-b413-d9033425b856",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0161316-88fa-4000-84db-d7ec3a8037ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "print(f\"device: {device.name.decode()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbe5766d-bb05-48b8-9a83-b81536b9e824",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85e9857-6c78-4535-b126-00bed1c8d2ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sequence data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a99e97-7b78-4ada-8a7f-69662197d1fa",
   "metadata": {},
   "source": [
    "For each `user`, we consider a sequence of user historical interactions with the RecSys, recording the actions taken by the recommender (e.g., items recommended), as well as user feedback (e.g.,`ratings`)\n",
    "\n",
    "Given such a sequence, we predict the next `action` to take, i.e., items to recommend, so that user satisfaction metrics, e.g., indicated by `ratings` improve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe910866-2e0a-4386-b923-67c1f1c8b986",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "**MPD definiton**\n",
    "\n",
    "> We translate this setup into a Markov Decision Process (MDP)\n",
    "\n",
    "**{`S`, `A`, `P`, `R`, `p0`, `y`}**\n",
    "\n",
    "* **`S`**: a continuous state space describing the user states\n",
    "* **`A`**: a discrete action space, containing items available for recommendation\n",
    "* **`P`** : S Ã— A Ã— S â†’ R is the state transition probability\n",
    "* **`R`** : S Ã— A â†’ R is the reward function, where ð‘Ÿ(ð‘ , ð‘Ž) is the immediate reward obtained by performing action ð‘Ž at user state `s`\n",
    "* **`p0`** is the initial state distribution\n",
    "* **`y`** is the discount factor for future rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d67f73f-788c-45e3-889b-c74e76dd74b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Trajectories\n",
    "\n",
    "**A `Trajectory` represents a sequence of aligned time steps** \n",
    "\n",
    "It captures:\n",
    "* `observation` and `step_type` from current time step with the computed `action` and `policy_info`\n",
    "* `Discount`, `reward` and `next_step_type` come from the next time step.\n",
    "  \n",
    "We allow `experience` to contain trajectories of different lengths in the *time dimension*, but these have to be padded with dummy values to have a constant size of `T` in the time dimension\n",
    "\n",
    "* Both `trajectory.reward` and `weights` have to be 0 for these dummy values\n",
    "* `experience` can be provided in other formats such as `Transition`'s if they can be converted into Trajectories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f97790-b940-4e16-a1d4-b136ac4973d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TimeSteps\n",
    "\n",
    "**A `TimeStep` contains the data emitted by an environment at each step of interaction**. They include:\n",
    "* a `step_type`, \n",
    "* an `observation` (e.g., NumPy array, dict, or list of arrays), \n",
    "* and an associated `reward` and `discount`\n",
    "\n",
    "**sequential ordering**\n",
    "* first `TimeStep` in a sequence equals `StepType.FIRST`\n",
    "* final `TimeStep` in a sequence equals `StepType.LAST`\n",
    "* All other `TimeStep`s in a sequence equal `StepType.MID`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f46643-cbbf-4995-8d0e-532a1426ca2a",
   "metadata": {},
   "source": [
    "### Discounted rewards\n",
    "\n",
    "> A discounting factor is introduced for:\n",
    "* Reducing variance \n",
    "* Prescribing the effective time horizon we optimize over"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d685e97b-a080-486a-8b50-c486553f3493",
   "metadata": {},
   "source": [
    "## Parse sequence examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d35f041d-26c3-4402-8f6c-ea3bf2960947",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1256d869-df7d-4731-a3f5-0870bcb3991b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCS_DATA_PATH: gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m\n"
     ]
    }
   ],
   "source": [
    "EXAMPLE_GEN_GCS_PATH = data_config.EXAMPLE_GEN_GCS_PATH\n",
    "GCS_DATA_PATH = f\"{BUCKET_URI}/{EXAMPLE_GEN_GCS_PATH}\"\n",
    "\n",
    "print(f\"GCS_DATA_PATH: {GCS_DATA_PATH}\")\n",
    "# !gsutil ls $GCS_DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7435dc7-56c8-4de6-b0c0-1fe8c83c1454",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SPLIT = \"train\" # \"train\" | \"val\"\n",
    "\n",
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{EXAMPLE_GEN_GCS_PATH}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "train_files = train_files #[:3] # subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21b3eeaa-e1fa-4adf-9762-93d43d2ef2f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'context_movie_genre': <tf.Tensor: shape=(10,), dtype=string, numpy=\n",
      "array([b'Crime', b'Drama', b'Action', b'Drama', b'War', b'Crime',\n",
      "       b'Drama', b'Drama', b'Drama', b'Drama'], dtype=object)>,\n",
      "  'context_movie_id': <tf.Tensor: shape=(10,), dtype=string, numpy=\n",
      "array([b'2199', b'108', b'1047', b'837', b'1590', b'504', b'1680', b'258',\n",
      "       b'1632', b'586'], dtype=object)>,\n",
      "  'context_movie_rating': <tf.Tensor: shape=(10,), dtype=float32, numpy=array([3., 4., 3., 4., 3., 3., 4., 3., 4., 5.], dtype=float32)>,\n",
      "  'context_movie_title': <tf.Tensor: shape=(10,), dtype=string, numpy=\n",
      "array([b'Few Good Men, A (1992)', b'Braveheart (1995)',\n",
      "       b'Sleepers (1996)', b'Spitfire Grill, The (1996)',\n",
      "       b\"Ulee's Gold (1997)\", b'Philadelphia (1993)',\n",
      "       b'Jackie Brown (1997)', b'Little Women (1994)',\n",
      "       b'Joy Luck Club, The (1993)', b'Dances with Wolves (1990)'],\n",
      "      dtype=object)>,\n",
      "  'context_movie_year': <tf.Tensor: shape=(10,), dtype=int64, numpy=array([1992, 1995, 1996, 1996, 1997, 1993, 1997, 1994, 1993, 1990])>,\n",
      "  'context_rating_timestamp': <tf.Tensor: shape=(10,), dtype=int64, numpy=\n",
      "array([958964374, 958964438, 958964438, 958964471, 958964511, 958964511,\n",
      "       958964532, 958964546, 958964546, 958964909])>,\n",
      "  'target_movie_genres': <tf.Tensor: shape=(10,), dtype=string, numpy=\n",
      "array([b'Drama', b'Fantasy', b'UNK', b'UNK', b'UNK', b'UNK', b'UNK',\n",
      "       b'UNK', b'UNK', b'UNK'], dtype=object)>,\n",
      "  'target_movie_id': <tf.Tensor: shape=(), dtype=string, numpy=b'2384'>,\n",
      "  'target_movie_rating': <tf.Tensor: shape=(), dtype=float32, numpy=3.0>,\n",
      "  'target_movie_title': <tf.Tensor: shape=(), dtype=string, numpy=b'Boy Who Could Fly, The (1986)'>,\n",
      "  'target_movie_year': <tf.Tensor: shape=(), dtype=int64, numpy=1986>,\n",
      "  'target_rating_timestamp': <tf.Tensor: shape=(), dtype=int64, numpy=958964909>,\n",
      "  'user_age': <tf.Tensor: shape=(), dtype=int64, numpy=18>,\n",
      "  'user_gender': <tf.Tensor: shape=(), dtype=string, numpy=b'M'>,\n",
      "  'user_id': <tf.Tensor: shape=(), dtype=string, numpy=b'5637'>,\n",
      "  'user_occupation_text': <tf.Tensor: shape=(), dtype=string, numpy=b'academic/educator'>,\n",
      "  'user_zip_code': <tf.Tensor: shape=(), dtype=string, numpy=b'32601'>},\n",
      " {})\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "train_seq_dataset = train_dataset.map(data_utils._parse_seq_function)\n",
    "\n",
    "# see train example\n",
    "for x in train_seq_dataset.skip(5).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29291382-c029-45b3-a653-9d6536a2d5c5",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Example: proto to trajectory\n",
    "\n",
    "> Let's inspect the trajectory structure we need for our REINFORCE recommender agent. Specifically, we'll construct a `trajectory` object and its associated *importance weights*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ea44275-d358-452a-8bd2-f6875195522d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_length=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30600e99-8853-4eb0-b646-5ab788313658",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### example proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2c96c24-2ba2-469c-8120-742f15fbe017",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for raw_record in train_dataset.take(1):\n",
    "#     example = tf.train.Example()\n",
    "#     example.ParseFromString(raw_record.numpy())\n",
    "#     print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "711624c1-63ba-4861-965a-19b4104ece39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for raw_seq_record in train_dataset.take(1):\n",
    "#     example = tf.train.SequenceExample()\n",
    "#     example.ParseFromString(raw_seq_record.numpy())\n",
    "#     print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf45eea-a088-4298-9be3-81efb03af4cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### rewards\n",
    "\n",
    "* ratings 1-5\n",
    "* can cast ratings over certain threshold to create binary rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24a429cf-ab4d-4338-8a59-5cb41ffd8faf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 4., 3., 4., 5.], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_seq = x[0]['context_movie_rating'].numpy()[-sequence_length:]\n",
    "ratings_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98feef93-de21-4cb8-b7b8-1c269c9fad08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 4., 3., 4., 5.], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rewards = tf.cast(ratings_seq > 0, dtype=tf.float32) # binary rewards\n",
    "rewards = ratings_seq\n",
    "rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c0e214-bd6e-4f68-92f4-cbd550692941",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### actions and observations\n",
    "\n",
    "For now, we are using the following simplified features:\n",
    "* At every point in time, the `target_movie_id` field in the sequence is the **action** \n",
    "* the `context_movie_id` at the previous time step (previous action(s)) is the observation\n",
    "* each `context_movie_id` has a corresponding `context_movie_rating`\n",
    "> * possible to convert `context_movie_rating` to a binary reward (e.g., clicks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88ccfefc-01ef-4276-9744-eada1c7674d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=string, numpy=\n",
       "array([b'2199', b'108', b'1047', b'837', b'1590', b'504', b'1680', b'258',\n",
       "       b'1632', b'586'], dtype=object)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]['context_movie_id'] #[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdb958c5-0447-463b-99c4-39248c186b31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'504', b'1680', b'258', b'1632', b'586'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = x[0]['context_movie_id'].numpy()[-sequence_length:]\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fb76a0b-2eb6-4dd4-b695-ca6bef686a26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'1590', b'504', b'1680', b'258', b'1632'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations = x[0]['context_movie_id'].numpy()[-(sequence_length+1):-1]\n",
    "observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4b54b7-6eb9-4ecc-be23-71f4cc9267a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### pad trajectory elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee327ca8-332f-4b1c-b73c-0cb808e015e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=5>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_sequence_length = tf.shape(observations)[0]\n",
    "actual_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d939006b-ad42-4d12-977e-38138bc7a7f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'504', b'1680', b'258', b'1632', b'586'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = actions[-actual_sequence_length:]\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64b0ad98-0f30-4eda-83ba-99a200d1e990",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 4., 3., 4., 5.], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards = rewards[-actual_sequence_length:]\n",
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a3610d9-59bc-46b7-8cef-bdc03c22a637",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 0], dtype=int32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paddings = tf.stack([0, sequence_length - actual_sequence_length])\n",
    "paddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd604602-ca41-461a-83d8-df8170cef296",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=int32, numpy=array([[0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paddings = tf.expand_dims(paddings, 0)\n",
    "paddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98c936d8-a370-43e7-a919-8fc64749ab49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([3., 4., 3., 4., 5.], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards = tf.pad(rewards, paddings, 'CONSTANT', constant_values=0)\n",
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a90a8ee-107d-4c49-96c4-781f3f7ef469",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discounts = tf.ones((sequence_length,), dtype=tf.float32)\n",
    "discounts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d3f594-abec-4e29-aae6-6c3be3dd2502",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### step types\n",
    "\n",
    "The time dimension will be equal to `sequence_length` \n",
    "\n",
    "The agent assumes that this trajectory is a single episode, so `trajectory.step_type` and `trajectory.discount` are ignored\n",
    "\n",
    "* `ts.StepType.FIRST` == 0\n",
    "* `ts.StepType.MID` == 1\n",
    "* `ts.StepType.LAST` == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39fed2c0-54fb-4866-a7e7-57e60e92dbbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([1, 1, 1, 1, 1], dtype=int32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_step_types = tf.ones((sequence_length,), dtype=tf.int32) * ts.StepType.MID\n",
    "next_step_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58b00f63-2193-4ad7-ba8b-ad5af75ffc48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 1, 1, 1], dtype=int32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_types = tf.concat([[ts.StepType.FIRST], next_step_types[1:]], axis=0)\n",
    "step_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf7b148-736e-403f-992f-3e63dd66362a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### trajectory object\n",
    "\n",
    "* `Discount` is all ones in the base trajectory. During training, we can apply different discounting values with a `gamma` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f914d2d3-d073-40c4-8d66-00a7d2c4c233",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'action': array([b'504', b'1680', b'258', b'1632', b'586'], dtype=object),\n",
       " 'discount': <tf.Tensor: shape=(5,), dtype=float32, numpy=array([1., 1., 1., 1., 1.], dtype=float32)>,\n",
       " 'next_step_type': <tf.Tensor: shape=(5,), dtype=int32, numpy=array([1, 1, 1, 1, 1], dtype=int32)>,\n",
       " 'observation': array([b'1590', b'504', b'1680', b'258', b'1632'], dtype=object),\n",
       " 'policy_info': (),\n",
       " 'reward': <tf.Tensor: shape=(5,), dtype=float32, numpy=array([3., 4., 3., 4., 5.], dtype=float32)>,\n",
       " 'step_type': <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 1, 1, 1], dtype=int32)>})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj = trajectory.Trajectory(\n",
    "      step_type=step_types,\n",
    "      observation=observations,\n",
    "      action=actions,\n",
    "      policy_info=(),\n",
    "      next_step_type=next_step_types,\n",
    "      reward=rewards,\n",
    "      discount=discounts\n",
    ")\n",
    "\n",
    "traj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92e19fc-260a-4d44-87e0-ca94629f1a37",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### importance weights\n",
    "\n",
    "> divides the trajectory into 3 parts: \n",
    "\n",
    "* The **first** part is used to warm start the state embedding network\n",
    "* The **second** part is used to compute losses\n",
    "* Returns are computed using the **second** and **third** parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "327da947-a547-44e8-a91e-c31f71e9efe7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=1>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_size = tf.cast(actual_sequence_length / 3, tf.int32)\n",
    "section_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54d46f28-7f5f-4589-8eba-cf2bf90aa75a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 1., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = tf.concat([\n",
    "    tf.zeros((section_size,)),\n",
    "    tf.ones((section_size,)),\n",
    "    tf.zeros((sequence_length - 2 * section_size,))\n",
    "], axis=0)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a38495-86e8-4090-a3d8-7caee8e07a88",
   "metadata": {},
   "source": [
    "## Data ops\n",
    "\n",
    "> Now let's create the helper functions for creating data pipelines for trajectories and weights\n",
    "\n",
    "**TODO**\n",
    "* abstract data ops to utils etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66ea5987-346d-42b5-8108-1d4df51d32ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_config.MAX_CONTEXT_LENGTH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24feaba7-034a-4efe-b54a-5591a22c0dcb",
   "metadata": {},
   "source": [
    "### sequence example to trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "13e51673-6ef2-433e-bee5-c5ca0ec5e5e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def example_proto_to_trajectory(\n",
    "    example_proto, # sequence_feature,\n",
    "    sequence_length: int\n",
    "):\n",
    "    \"\"\"\n",
    "    Converts a sequence example to a Trajectory and weights for training.\n",
    "\n",
    "    For now, we are using the following simplified features. At every point in\n",
    "    time, the `context_movie_id` field in the sequence is the action and the `context_movie_id`\n",
    "    at the previous time step (last action) is the observation. The `context_movie_rating` field\n",
    "    is converted to a binary reward.\n",
    "\n",
    "    If the sequence example is longer than than `sequence_length`, we only take\n",
    "    the last part of the sequence example. If it is shorter, we pad it with dummy\n",
    "    values at the end to equal `sequence_length`.\n",
    "\n",
    "    Args:\n",
    "    sequence_feature: A serialized SequenceExample to convert to a\n",
    "      trajectory.\n",
    "    sequence_length: The time dimension of the returned trajectory.\n",
    "\n",
    "    Returns:\n",
    "    trajectory: An unbatched trajectory. The time dimension will be equal to\n",
    "      sequence length. The agent assumes that this trajectory is a single\n",
    "      episode, so `trajectory.step_type` and `trajectory.discount` are ignored.\n",
    "    weights: A [T] float tensor of weights. Each row of `weights`\n",
    "        (along the time dimension) is usually a sequence of 0's, followed by\n",
    "        a sequence of 1's, again followed by a sequence of 0's. This divides\n",
    "        the trajectory into 3 parts. The first part is used to warm start\n",
    "        the state embedding network. The second part is used to compute\n",
    "        losses. Returns are computed using the second and third parts.\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_description = {\n",
    "        'context_movie_id': tf.io.FixedLenFeature(shape=(data_config.MAX_CONTEXT_LENGTH), dtype=tf.string),\n",
    "        'context_movie_rating': tf.io.FixedLenFeature(shape=(data_config.MAX_CONTEXT_LENGTH), dtype=tf.float32),\n",
    "    }\n",
    "    \n",
    "    sequence_feature = tf.io.parse_single_sequence_example(example_proto, feature_description)\n",
    "    # print(f\"sequence_feature: {sequence_feature[0]}\")\n",
    "    \n",
    "    # context_id_string = [z.numpy() for z in sequence_feature[0]['context_movie_id']]\n",
    "    \n",
    "    context_id_int = tf.strings.to_number(\n",
    "        sequence_feature[0]['context_movie_id'],\n",
    "        out_type=tf.dtypes.int64,\n",
    "        name=None\n",
    "    )\n",
    "    # context_id_int = context_id_int.numpy()\n",
    "    \n",
    "    ### TODO: keep or remove: [0] ? \n",
    "    \n",
    "    sequence_feature[0]['context_movie_id'] = context_id_int\n",
    "    actions = sequence_feature[0]['context_movie_id'][-sequence_length:]\n",
    "    rewards = sequence_feature[0]['context_movie_rating'][-sequence_length:]\n",
    "    observations = sequence_feature[0]['context_movie_id'][-(sequence_length+1):-1]\n",
    "    \n",
    "    # sequence_feature['context_movie_id'] = context_id_int\n",
    "    # actions = sequence_feature['context_movie_id'][-sequence_length:]\n",
    "    # rewards = sequence_feature['context_movie_rating'][-sequence_length:]\n",
    "    # observations = sequence_feature['context_movie_id'][-(sequence_length+1):-1]\n",
    "    # print(f\"observations: {observations}\")\n",
    "\n",
    "    # actual length\n",
    "    actual_sequence_length = tf.shape(observations)[0]\n",
    "    # print(f\"actual_sequence_length: {actual_sequence_length}\")\n",
    "    \n",
    "    actions = actions[-actual_sequence_length:]\n",
    "    rewards = rewards[-actual_sequence_length:]\n",
    "\n",
    "    # padding\n",
    "    paddings = tf.stack([0, sequence_length - actual_sequence_length])\n",
    "    paddings = tf.expand_dims(paddings, 0)\n",
    "\n",
    "    rewards = tf.pad(rewards, paddings, 'CONSTANT', constant_values=0)\n",
    "    actions = tf.pad(actions, paddings, 'CONSTANT', constant_values=0)\n",
    "    observations = tf.pad(observations, paddings, 'CONSTANT', constant_values=0)\n",
    "\n",
    "    # steps & discounts\n",
    "    discounts = tf.ones((sequence_length,), dtype=tf.float32)\n",
    "    next_step_types = tf.ones(\n",
    "      (sequence_length,), dtype=tf.int32) * ts.StepType.MID\n",
    "    step_types = tf.concat([[ts.StepType.FIRST], next_step_types[1:]], axis=0)\n",
    "\n",
    "    # build trajectory\n",
    "    traj = trajectory.Trajectory(\n",
    "        step_type=step_types,\n",
    "        observation=observations,\n",
    "        action=actions,\n",
    "        policy_info=(),\n",
    "        next_step_type=next_step_types,\n",
    "        reward=rewards,\n",
    "        discount=discounts\n",
    "    )\n",
    "\n",
    "    # get importance weights\n",
    "    section_size = tf.cast(actual_sequence_length / 3, tf.int32)\n",
    "    # print(f\"section_size: {section_size}\")\n",
    "    \n",
    "    weights = tf.concat(\n",
    "        [\n",
    "            tf.zeros((section_size,)),\n",
    "            tf.ones((section_size,)),\n",
    "            tf.zeros((sequence_length - 2 * section_size,))\n",
    "        ], \n",
    "        axis=0\n",
    "    )\n",
    "    \n",
    "    return traj, weights # sequence_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e2b739-8db2-4062-9473-73483aa7bb59",
   "metadata": {},
   "source": [
    "### create single TF Record dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e701a090-c072-487c-bfb7-cd0957c40ad3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_single_tfrecord_ds(\n",
    "    filename,\n",
    "    process_example_fn,\n",
    "    shuffle_buffer_size = 1,\n",
    "):\n",
    "    raw_ds = tf.data.TFRecordDataset(filename)\n",
    "    \n",
    "    ds = raw_ds.map(\n",
    "        process_example_fn,\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    ds = ds.shuffle(shuffle_buffer_size)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baaecab-e37e-44e6-849f-8bb943ea3d1f",
   "metadata": {},
   "source": [
    "### create interleaved TF Record dataset\n",
    "\n",
    "1. Each element of a TF Record is processed using the `process_example_fn` and converted to Tensors\n",
    "2. A dataset is created for each record file \n",
    "3. These datasets are interleaved together to create the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6b88787-3c46-419d-8882-284f4576f34d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_tfrecord_ds(\n",
    "    filenames,\n",
    "    process_example_fn,\n",
    "    batch_size: int,\n",
    "    shuffle_buffer_size_per_record: int = 1,\n",
    "    shuffle_buffer_size: int = 10000,\n",
    "    num_shards: int = 50,\n",
    "    cycle_length: int = tf.data.AUTOTUNE,\n",
    "    block_length: int = 10,\n",
    "    num_prefetch: int = 10,\n",
    "    num_parallel_calls: int = 10,\n",
    "    repeat: bool = True,\n",
    "    drop_remainder: bool = False\n",
    "):\n",
    "    filenames = list(filenames)\n",
    "    initial_len = len(filenames)\n",
    "    remainder = initial_len % num_shards\n",
    "    \n",
    "    for _ in range(num_shards - remainder):\n",
    "        filenames.append(\n",
    "            filenames[np.random.randint(low=0, high=initial_len)]\n",
    "        )\n",
    "        \n",
    "    filenames = np.array(filenames)\n",
    "    np.random.shuffle(filenames)\n",
    "    filenames = np.array_split(filenames, num_shards)\n",
    "    filename_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "    \n",
    "    if repeat:\n",
    "        filename_ds = filename_ds.repeat()\n",
    "    \n",
    "    filename_ds = filename_ds.shuffle(len(filenames))\n",
    "    \n",
    "    example_ds = filename_ds.interleave(\n",
    "        functools.partial(\n",
    "            create_single_tfrecord_ds,\n",
    "            process_example_fn=process_example_fn,\n",
    "            shuffle_buffer_size=shuffle_buffer_size_per_record,\n",
    "        ),\n",
    "        cycle_length=tf.data.AUTOTUNE,\n",
    "        block_length=block_length,\n",
    "        num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    )\n",
    "    example_ds = example_ds.shuffle(shuffle_buffer_size)\n",
    "    \n",
    "    example_ds = example_ds.batch(\n",
    "        batch_size, drop_remainder=drop_remainder\n",
    "    ).prefetch(num_prefetch)\n",
    "  \n",
    "    return example_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3ae652-4cbe-436d-8b11-b729c0a659ba",
   "metadata": {},
   "source": [
    "**inspect output of helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d5db1afb-276a-4665-a7a4-31c893e2fe4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_length=10\n",
    "\n",
    "process_example_fn = functools.partial(\n",
    "    example_proto_to_trajectory,\n",
    "    sequence_length=sequence_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eb73a2c6-951b-4cce-9415-1e12cc4d8eb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_batch_size=5\n",
    "\n",
    "train_dataset = create_tfrecord_ds(\n",
    "    tf.io.gfile.glob(train_files),\n",
    "    # num_shards = 10,\n",
    "    process_example_fn=process_example_fn,\n",
    "    batch_size=train_batch_size\n",
    ")\n",
    "train_dataset_iterator = iter(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "96be0683-e389-4001-b4d3-bc48b32ee293",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 1., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_test, weights = next(train_dataset_iterator)\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "24b6d417-e95e-4fd1-b515-f0c0522b718d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'action': <tf.Tensor: shape=(5, 10), dtype=int64, numpy=\n",
       "array([[2124, 2074,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [1068, 1892, 2267, 2937,  959, 2063, 2243, 1190, 1248,    0],\n",
       "       [2401, 2559,  642, 1546, 1354, 2036,    9,  313,  325,    0],\n",
       "       [3194, 1119, 3432, 1427, 2193, 1455, 1619, 2059, 2266,    0],\n",
       "       [1951, 3003, 3429, 1239, 1276, 3634, 1022, 1116, 1646,    0]])>,\n",
       " 'discount': <tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)>,\n",
       " 'next_step_type': <tf.Tensor: shape=(5, 10), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>,\n",
       " 'observation': <tf.Tensor: shape=(5, 10), dtype=int64, numpy=\n",
       "array([[1250, 2124, 2074,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [3042, 1068, 1892, 2267, 2937,  959, 2063, 2243, 1190,    0],\n",
       "       [1058, 2401, 2559,  642, 1546, 1354, 2036,    9,  313,    0],\n",
       "       [2026, 3194, 1119, 3432, 1427, 2193, 1455, 1619, 2059,    0],\n",
       "       [1273, 1951, 3003, 3429, 1239, 1276, 3634, 1022, 1116,    0]])>,\n",
       " 'policy_info': (),\n",
       " 'reward': <tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[3., 2., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [4., 4., 4., 4., 3., 4., 4., 3., 3., 0.],\n",
       "       [4., 4., 4., 4., 4., 4., 4., 3., 4., 0.],\n",
       "       [3., 2., 2., 3., 1., 1., 1., 1., 1., 0.],\n",
       "       [4., 2., 5., 4., 3., 3., 5., 4., 3., 0.]], dtype=float32)>,\n",
       " 'step_type': <tf.Tensor: shape=(5, 10), dtype=int32, numpy=\n",
       "array([[0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4192461-b9a8-4f47-8788-bbab2388414b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Policy \n",
    "\n",
    "> The main job of the Policy is to map observations from the user to actions. The action is a set of K recommended items. The policy is created by the Agent and contains a reference to the Network\n",
    "\n",
    "```\n",
    "Policy.__init__(time_step_spec, action_spec, network, ...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1081163d-bba9-4f5d-834a-6c5f17fe3afe",
   "metadata": {},
   "source": [
    "**computing actions**\n",
    "* to compute actions, the policy uses the network to compute the user's latent state (`s_t`)\n",
    "* this state is multiplied by a trainable action embedding (`v_a`) for each action\n",
    "* then apply softmax to compute action probabilities\n",
    "\n",
    "so steps in code, roughly follow:\n",
    "1. `s_{t+1}` <-- network(time_step.observation, state)\n",
    "2. scann index: retreive top M (100s-1000s) actions closest to `s{t+1}`\n",
    "3. compute inner produdct `q_a = v_a * s_{t+1}` for each action embedding `v_a`\n",
    "4. balance explore vs exploit:\n",
    "> * select greedy actions: `A_t` = {Kâ€™ actions with highest `q_a`}\n",
    "> * exploratory actions: actions sampled from softmax(`q_a/T`), where `T` is Boltzmann \n",
    "5. Return action = `A_t` (set of K Actions), state = `s_{t+1}`, info = ()\n",
    "\n",
    "**recomputing states**\n",
    "* Everytime the network weights are updated, the latent state `s_t` should be recomputed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fe5fb9-ad91-43a3-b34d-6649b8346305",
   "metadata": {},
   "source": [
    "# Train agent\n",
    "\n",
    "> Train Top K Off Policy Reinforce from logged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d020d586-a07e-4c74-859a-08107e27fe69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/train/ml-1m-gen-001-of-008.tfrecord',\n",
       " 'gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/train/ml-1m-gen-002-of-008.tfrecord',\n",
       " 'gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/train/ml-1m-gen-003-of-008.tfrecord',\n",
       " 'gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/train/ml-1m-gen-004-of-008.tfrecord',\n",
       " 'gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/train/ml-1m-gen-005-of-008.tfrecord',\n",
       " 'gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/train/ml-1m-gen-006-of-008.tfrecord',\n",
       " 'gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/train/ml-1m-gen-007-of-008.tfrecord',\n",
       " 'gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/train/ml-1m-gen-008-of-008.tfrecord']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_SPLIT = \"train\"\n",
    "VAL_SPLIT = \"val\"\n",
    "\n",
    "train_files = []\n",
    "val_files = []\n",
    "\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{EXAMPLE_GEN_GCS_PATH}/{TRAIN_SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{EXAMPLE_GEN_GCS_PATH}/{VAL_SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        val_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "# train_files = train_files[:3]\n",
    "# train_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78d83e8-5b13-4eec-adfa-732d3d0b2a0d",
   "metadata": {},
   "source": [
    "**get action vocab file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "60ef7298-9d4b-4226-90fb-eb0f7493621d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab...\n",
      "Downloaded vocab from: gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/vocabs/vocab_dict.pkl\n",
      "\n",
      "'movie_id'\n",
      "'movie_year'\n",
      "'movie_genre'\n",
      "'movie_title'\n",
      "'user_id'\n",
      "'user_gender_vocab'\n",
      "'user_age_vocab'\n",
      "'user_occ_vocab'\n",
      "'user_zip_vocab'\n",
      "'min_timestamp'\n",
      "'max_timestamp'\n",
      "'timestamp_buckets'\n"
     ]
    }
   ],
   "source": [
    "EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{EXAMPLE_GEN_GCS_PATH}/vocabs/{VOCAB_FILENAME}'\n",
    "print(f\"Downloading vocab...\")\n",
    "\n",
    "os.system(f'gsutil -q cp {EXISTING_VOCAB_FILE} .')\n",
    "print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "vocab_dict = pkl.load(filehandler)\n",
    "filehandler.close()\n",
    "\n",
    "# for key in vocab_dict.keys():\n",
    "#     pprint(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "97f18b38-cef0-44e9-a963-80e4c1b4069f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vocab_dict['movie_id'][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babf9513-7181-472d-ad29-6a7ec249df90",
   "metadata": {},
   "source": [
    "## Vertex Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5178601f-8ab6-4b1c-b004-cfb34d45692b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VERSION=\"v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a03bbeae-cd49-4a98-ac1e-270f3bee25e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : reinforce-rec-topk-v1\n",
      "RUN_NAME          : run-20241122-184115\n",
      "\n",
      "CHECKPT_DIR       : gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-rec-topk-v1/chkpoint\n",
      "BASE_OUTPUT_DIR   : gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-rec-topk-v1/run-20241122-184115\n",
      "LOG_DIR           : gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-rec-topk-v1/run-20241122-184115/logs\n",
      "ROOT_DIR          : gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-rec-topk-v1/run-20241122-184115/root\n",
      "ARTIFACTS_DIR     : gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-rec-topk-v1/run-20241122-184115/artifacts\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME   = f'reinforce-rec-topk-{VERSION}'\n",
    "\n",
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "CHECKPT_DIR       = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/chkpoint\"\n",
    "BASE_OUTPUT_DIR   = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}\"\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"CHECKPT_DIR       : {CHECKPT_DIR}\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c11ea1-9756-45da-92bb-a9e9da73df12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # # create new TB instance\n",
    "# TENSORBOARD_DISPLAY_NAME=f\"{EXPERIMENT_NAME}-{RUN_NAME}\"\n",
    "\n",
    "# tensorboard = aiplatform.Tensorboard.create(\n",
    "#     display_name=TENSORBOARD_DISPLAY_NAME\n",
    "#     , project=PROJECT_ID\n",
    "#     , location=REGION\n",
    "# )\n",
    "\n",
    "# TB_RESOURCE_NAME = tensorboard.resource_name\n",
    "\n",
    "# TB_ID = TB_RESOURCE_NAME.split('/')[-1]\n",
    "\n",
    "# print(f\"TB_RESOURCE_NAME : {TB_RESOURCE_NAME}\")\n",
    "# print(f\"TB display name  : {tensorboard.display_name}\")\n",
    "# print(f\"TB_ID            : {TB_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56039f7-bd31-4e22-8bae-3b6753c7da4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# aiplatform.init(\n",
    "#     project=PROJECT_ID,\n",
    "#     location=REGION,\n",
    "#     experiment=EXPERIMENT_NAME,\n",
    "#     experiment_tensorboard=TB_ID\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a53827-1f90-4a31-9435-b199a4d61c76",
   "metadata": {},
   "source": [
    "### action vocab lookup\n",
    "\n",
    "1. Need to convert action feature (movie IDs) to numeric (i.e., string --> int64)\n",
    "2. update `vocab_dict`\n",
    "3. create *lookup layers* for Agent; essentially convert real world actions to integer action indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8b2c9b14-ea5b-4f78-a5fb-b1661c8d8e9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab_dict['movie_id']\n",
    "vocab_dict_decoded = [z.decode(\"utf-8\") for z in vocab_dict['movie_id']]\n",
    "vocab_dict_decoded.remove(\"UNK\")\n",
    "\n",
    "vocab_dict_decoded = tf.strings.to_number(\n",
    "    vocab_dict_decoded,\n",
    "    out_type=tf.dtypes.int64,\n",
    "    name=None\n",
    ")\n",
    "vocab_dict_decoded = vocab_dict_decoded.numpy()\n",
    "vocab_dict_decoded[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "39f1e1cd-2444-467f-b002-760700cc3a9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update vocab_dict\n",
    "vocab_dict['movie_id_int'] = vocab_dict_decoded\n",
    "vocab_dict['movie_id_int'][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5a9707-c9b3-4bf0-9ec5-f5493c4caf89",
   "metadata": {},
   "source": [
    "**lookup layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "23257fce-8d57-4cf5-bcfb-94ea623c8e30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "action_lookup_layer = tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=vocab_dict['movie_id_int'], \n",
    "    mask_value=None\n",
    ")\n",
    "\n",
    "inverse_action_lookup_layer = tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=action_lookup_layer.get_vocabulary(), \n",
    "    mask_value=None,\n",
    "    invert=True\n",
    ")\n",
    "\n",
    "# NUM_OOV_BUCKETS = 1\n",
    "\n",
    "# action_lookup_layer = tf.keras.layers.StringLookup(\n",
    "#     max_tokens=len(vocab_dict['movie_id']) + NUM_OOV_BUCKETS,\n",
    "#     num_oov_indices=NUM_OOV_BUCKETS,\n",
    "#     vocabulary=vocab_dict['movie_id'], \n",
    "#     mask_token=None\n",
    "# )\n",
    "\n",
    "# inverse_action_lookup_layer = tf.keras.layers.StringLookup(\n",
    "#     vocabulary=action_lookup_layer.get_vocabulary(), \n",
    "#     mask_token=None,\n",
    "#     invert=True\n",
    "# )\n",
    "\n",
    "action_vocab_size = action_lookup_layer.vocab_size() # 3885"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "40670e77-cba1-41ec-b6df-8347a4c8586a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3884"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # if observations are just past actions:\n",
    "\n",
    "observation_lookup_layer = tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=vocab_dict['movie_id_int'], \n",
    "    mask_value=None\n",
    ")\n",
    "\n",
    "# observation_lookup_layer = tf.keras.layers.StringLookup(\n",
    "#     max_tokens=len(vocab_dict['movie_id']) + NUM_OOV_BUCKETS,\n",
    "#     num_oov_indices=NUM_OOV_BUCKETS,\n",
    "#     vocabulary=vocab_dict['movie_id'], \n",
    "#     mask_token=None\n",
    "# )\n",
    "\n",
    "obs_vocab_size = observation_lookup_layer.vocab_size()\n",
    "obs_vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee28feda-f3b7-478f-a652-56eac45061c9",
   "metadata": {},
   "source": [
    "### tensor specs\n",
    "\n",
    "*Note that the minimum in the spec is 0 and the maximum is bound inclusive* \n",
    "\n",
    "> setting maximum = vocab_size - 1 accounts for all actions in the vocabulary, including OOV items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "36bf62a2-1017-4512-8b28-964f8088366b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_step = tf.compat.v1.train.get_or_create_global_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5a3221b-1394-4e12-a4d0-4d4e952275da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "observation_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=[],\n",
    "    dtype=tf.int64, # tf.string | tf.int64,\n",
    "    minimum=0,\n",
    "    maximum=action_vocab_size - 1,\n",
    "    name='observation'\n",
    ")\n",
    "time_step_spec = ts.time_step_spec(observation_spec=observation_spec)\n",
    "\n",
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=[],\n",
    "    dtype=tf.int64, # tf.string | tf.int64,\n",
    "    minimum=0,\n",
    "    maximum=action_vocab_size - 1,\n",
    "    name='action'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1d0c50-2688-4921-b1bf-866de1b03465",
   "metadata": {},
   "source": [
    "## Network\n",
    "\n",
    "> maps observations to actions (see section 4.1 of the [paper](https://arxiv.org/pdf/1812.02353.pdf))\n",
    "\n",
    "The input to the network is an observation, which includes an embedding of the item selected by the user from the last set of recommendations\n",
    "* TODO: add context features to input\n",
    "\n",
    "To compute actions, the policy uses the network to compute the latent state `s_t`.\n",
    "* The state `s_t` is multiplied by a trainable action embedding `v_a` for each action, followed by a softmax to compute the action probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e3b4a096-cad0-4a57-aefd-f86a6debb922",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int64, name='observation', minimum=array(0), maximum=array(3883))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embedding_size=100\n",
    "input_fc_layer_params=(100, 100)\n",
    "lstm_size=(25,)\n",
    "output_fc_layer_params=(10,)\n",
    "\n",
    "state_embedding_network = rfa_utils.create_state_embedding_network(\n",
    "    observation_lookup_layer=observation_lookup_layer,\n",
    "    input_embedding_size=input_embedding_size,\n",
    "    input_fc_layer_units=input_fc_layer_params,\n",
    "    lstm_size=lstm_size,\n",
    "    output_fc_layer_units=output_fc_layer_params\n",
    ")\n",
    "\n",
    "# state_embedding_spec = state_embedding_network.create_variables(\n",
    "#     time_step_spec.observation\n",
    "# )\n",
    "time_step_spec.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c0b3e5c7-346c-49f3-bedb-77586028f178",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029ec252-c7e0-42f0-b6a1-6f11221424cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create action embedding index (optional)\n",
    "\n",
    "> action_embeddings: A `[num_actions, embedding_size]` float tensor of action embeddings.\n",
    "\n",
    "**Note** - the scann index is built by the Agent/Policy. This section just shows what is happening under the hood "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4c83cb25-7d5e-4947-90e0-05f99a35e12e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_OOV_BUCKETS        = 1\n",
    "GLOBAL_EMBEDDING_SIZE  = 12\n",
    "MV_EMBEDDING_SIZE      = 16\n",
    "\n",
    "# test emb models\n",
    "for i in range(1):\n",
    "    \n",
    "    iterator = iter(train_seq_dataset.batch(1))\n",
    "    data, _ = next(iterator)\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c48a03-5f19-4e1a-ae1e-bc450af54d8a",
   "metadata": {},
   "source": [
    "We have an embedding model we can use for items (`_get_per_arm_features`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "28a00d60-0591-4e95-a753-d99e242b6df4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.networks.encoding_network.EmbeddingModel at 0x7fe31066bac0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs = emb_features.EmbeddingModel(\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    "    max_genre_length = data_config.MAX_GENRE_LENGTH\n",
    ")\n",
    "\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a96e7097-9ee3-4a8d-9d19-0876e822f50b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER_ARM_DIM: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 64), dtype=float32, numpy=\n",
       "array([[ 0.00522338, -0.0492513 , -0.04217166, -0.02676969,  0.00532337,\n",
       "         0.01616928, -0.04328166, -0.02269555, -0.04540516,  0.00852679,\n",
       "         0.03075549,  0.04461614,  0.04575862,  0.03543853, -0.01772305,\n",
       "        -0.03266831, -0.01495897,  0.00659831,  0.01986279, -0.02117376,\n",
       "        -0.02736138,  0.01802956, -0.04142103, -0.01418371,  0.03431284,\n",
       "         0.02025948,  0.01882055,  0.01983524, -0.00092457,  0.02816413,\n",
       "         0.02255264,  0.00341722, -0.04963842,  0.01322391, -0.02595209,\n",
       "         0.03883019, -0.04856459,  0.04120443, -0.01700947,  0.02865665,\n",
       "         0.01443274, -0.04156702, -0.00135241, -0.02927754,  0.00493876,\n",
       "         0.03719561,  0.01297845, -0.01525987, -0.02714867, -0.21839464,\n",
       "        -0.159814  ,  0.22727305, -0.20244312, -0.17102785,  0.19473268,\n",
       "        -0.21610314,  0.18426383,  0.16344523,  0.24170601,  0.18839969,\n",
       "         0.1676284 ,  0.21472023,  0.16254401,  0.05299693]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arms = embs._get_per_arm_features(data)\n",
    "\n",
    "PER_ARM_DIM = test_arms.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"PER_ARM_DIM: {PER_ARM_DIM}\")\n",
    "\n",
    "test_arms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a51f3520-ca22-471d-b749-67e95326960c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# total_movie_count = len(list(train_seq_dataset))\n",
    "# total_movie_count # 335532"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5cdc8c94-45eb-4030-b8e5-09169f4116a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/action-embeddings/action_embs_20240704-141459.json...\n",
      "/ [1 files][  2.7 MiB/  2.7 MiB]                                                \n",
      "Operation completed over 1 objects/2.7 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "# !gsutil cp gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/action-embeddings/action_embs_20240704-141459.json ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8b1b96-7345-418c-ab03-4d57125b1a82",
   "metadata": {
    "tags": []
   },
   "source": [
    "### write index file\n",
    "\n",
    "TODO: get all movie candidates into single dataset, similar to below logic\n",
    "\n",
    "```\n",
    "input_ids = tf.data.Dataset.from_tensor_slices([d['input_ids'] for d in dataset])\n",
    "input_masks = tf.data.Dataset.from_tensor_slices([d['input_mask'] for d in dataset])\n",
    "segment_ids = tf.data.Dataset.from_tensor_slices([d['segment_ids'] for d in dataset])\n",
    "labels = tf.data.Dataset.from_tensor_slices([d['labels'] for d in dataset])\n",
    "\n",
    "ds = tf.data.Dataset.zip((input_ids, input_masks, segment_ids, labels))\n",
    "ds = ds.map(lambda x, y, z, l: {\"input_ids\": x, \"input_masks\": y,\n",
    "                                \"segment_ids\": z, \"labels\": l}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "81ab8f53-4f21-4cd2-b7dc-9914b19b9cd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 0; emb_valid: 1; movie_id_set: 1\n",
      "n: 500; emb_valid: 417; movie_id_set: 417\n",
      "n: 750; emb_valid: 572; movie_id_set: 572\n",
      "n: 2250; emb_valid: 1201; movie_id_set: 1201\n",
      "n: 3500; emb_valid: 1531; movie_id_set: 1531\n",
      "n: 5250; emb_valid: 1823; movie_id_set: 1823\n",
      "n: 8500; emb_valid: 2143; movie_id_set: 2143\n",
      "n: 11500; emb_valid: 2340; movie_id_set: 2340\n",
      "n: 19250; emb_valid: 2658; movie_id_set: 2658\n",
      "n: 20750; emb_valid: 2697; movie_id_set: 2697\n",
      "n: 73500; emb_valid: 3230; movie_id_set: 3230\n",
      "elapsed_time           : 3\n",
      "counter                : 335532\n",
      "Length of movie_id_set : 3550\n",
      "Length of emb_valid    : 3550\n"
     ]
    }
   ],
   "source": [
    "movie_id_set = []\n",
    "emb_valid = []\n",
    "\n",
    "LOG_INTERVAL=250\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "counter = 0\n",
    "for ex_data, _ in train_seq_dataset.batch(1):\n",
    "\n",
    "    ids_ = ex_data['target_movie_id'].numpy()[0] # movie_id_int\n",
    "    if ids_ not in movie_id_set:\n",
    "        movie_id_set.append(ids_)\n",
    "        action_emb = embs._get_per_arm_features(ex_data)\n",
    "        emb_valid.append(action_emb)\n",
    "        \n",
    "        if counter % LOG_INTERVAL == 0:\n",
    "            print(f\"n: {counter}; emb_valid: {len(emb_valid)}; movie_id_set: {len(movie_id_set)}\")\n",
    "        \n",
    "    counter+=1\n",
    "    \n",
    "    # if counter == 100:\n",
    "    #     break\n",
    "\n",
    "    \n",
    "end_time = time.time()\n",
    "elapsed_time = int((end_time - start_time) / 60)\n",
    "\n",
    "print(f\"elapsed_time           : {elapsed_time}\")\n",
    "print(f\"counter                : {counter}\")\n",
    "print(f\"Length of movie_id_set : {len(movie_id_set)}\")\n",
    "print(f\"Length of emb_valid    : {len(emb_valid)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "56221139-a770-4f7d-9e55-9cdca69db3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1775', '2789', '2249', '3104', '142']"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_id_set[0:5]\n",
    "\n",
    "# TODO: shouldn't need these anymore: confirm\n",
    "# movie_id_set_decoded = [z.decode(\"utf-8\") for z in movie_id_set]\n",
    "# movie_id_set_decoded[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "dc95b015-5b4f-42f5-9fd5-35312d64c8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00417863, -0.04035826,  0.03949881,  0.02248106,  0.03972029,\n",
       "       -0.03954465, -0.0078277 , -0.00666126,  0.0240129 ,  0.03367153,\n",
       "       -0.01583817,  0.03204237,  0.04059358, -0.03843267,  0.00045175,\n",
       "        0.00292462, -0.04330502, -0.00924589,  0.04248578,  0.03299932,\n",
       "        0.00611916, -0.03558064, -0.04670314, -0.0222977 , -0.04777682,\n",
       "       -0.03742123, -0.03174067, -0.01043591,  0.04092886, -0.02244899,\n",
       "       -0.03317848, -0.03101618, -0.03086665, -0.03440733, -0.04183024,\n",
       "        0.01905538,  0.02743418,  0.03782295,  0.00370765,  0.04130132,\n",
       "        0.00137607,  0.02548063, -0.02434435, -0.02880038,  0.01019372,\n",
       "       -0.01553645, -0.04996688, -0.0459705 ,  0.24497205, -0.22872275,\n",
       "       -0.12215847, -0.17597657, -0.21268445,  0.10867788, -0.1677419 ,\n",
       "        0.23022158, -0.0225311 ,  0.2358569 ,  0.1154706 ,  0.10946961,\n",
       "        0.20655268, -0.19170517,  0.0794156 ,  0.21880643], dtype=float32)"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# emb_valid[0].numpy()\n",
    "\n",
    "cleaned_emb_valid = [z.numpy()[0] for z in emb_valid]\n",
    "cleaned_emb_valid[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83cad03-0eca-49b2-aba0-f2a301a2e0a7",
   "metadata": {},
   "source": [
    "write index file locally, and save to (remote) cloud storage location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "04d23b3e-9a81-485e-b3c2-ad1bc476f686",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 'local'\n",
    "TIMESTAMP = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "embeddings_index_filename = f'action_embs_{TIMESTAMP}.json'\n",
    "\n",
    "with open(f'{embeddings_index_filename}', 'w') as f:\n",
    "    for prod, emb in zip(movie_id_set_decoded, cleaned_emb_valid):\n",
    "        f.write('{\"id\":\"' + str(prod) + '\",')\n",
    "        f.write('\"embedding\":[' + \",\".join(str(x) for x in list(emb)) + \"]}\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "46146d3a-6d3e-4f49-b39d-ba4771067454",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_GCS_URI = f'{DATA_PATH}/movielens/m1m/action-embeddings'\n",
    "\n",
    "DESTINATION_BLOB_NAME = embeddings_index_filename\n",
    "SOURCE_FILE_NAME = embeddings_index_filename\n",
    "\n",
    "print(f\"INDEX_GCS_URI         : {INDEX_GCS_URI}\")\n",
    "print(f\"DESTINATION_BLOB_NAME : {DESTINATION_BLOB_NAME}\")\n",
    "print(f\"SOURCE_FILE_NAME      : {SOURCE_FILE_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "33d044d7-d577-4cf7-b6f8-9d7733f90829",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://rec-bandits-v2-hybrid-vertex-bucket/data'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "feb0cc3c-9232-42c8-bf5f-ec86bec56efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from google.cloud.storage.bucket import Bucket\n",
    "from google.cloud.storage.blob import Blob\n",
    "\n",
    "blob = Blob.from_string(os.path.join(INDEX_GCS_URI, DESTINATION_BLOB_NAME))\n",
    "blob.bucket._client = storage_client\n",
    "blob.upload_from_filename(SOURCE_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44fb2f9-a099-4d66-944f-de7ad5e280c1",
   "metadata": {},
   "source": [
    "Load json file to validate formatting etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6fd25145-fddb-41db-adcf-7f0dd72fd3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3550"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "action_emb_lines = []\n",
    "\n",
    "embeddings_index_filename = 'action_embs_20240704-141459.json'\n",
    "\n",
    "with open(embeddings_index_filename, 'r') as f:\n",
    "    for line in f:\n",
    "        action_emb_lines.append(json.loads(line))\n",
    "    \n",
    "# action_emb_lines[0]\n",
    "# \"\"\"\n",
    "# {'id': '1775',\n",
    "#  'embedding': [0.004178632,\n",
    "#   -0.040358257,\n",
    "#   0.03949881,\n",
    "#   0.022481058,\n",
    "# \"\"\"\n",
    "\n",
    "len(action_emb_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d756c5d7-4598-421e-8735-c17b2a76c084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 0.00417863 -0.04035826  0.03949881  0.02248106  0.03972029 -0.03954465\n",
      " -0.0078277  -0.00666126  0.0240129   0.03367153 -0.01583817  0.03204237\n",
      "  0.04059358 -0.03843267  0.00045175  0.00292462 -0.04330502 -0.00924589\n",
      "  0.04248578  0.03299932  0.00611916 -0.03558064 -0.04670314 -0.0222977\n",
      " -0.04777682 -0.03742123 -0.03174067 -0.01043591  0.04092886 -0.02244899\n",
      " -0.03317848 -0.03101618 -0.03086665 -0.03440733 -0.04183024  0.01905538\n",
      "  0.02743418  0.03782295  0.00370765  0.04130132  0.00137607  0.02548063\n",
      " -0.02434435 -0.02880038  0.01019372 -0.01553645 -0.04996688 -0.0459705\n",
      "  0.24497205 -0.22872275 -0.12215847 -0.17597657 -0.21268445  0.10867788\n",
      " -0.1677419   0.23022158 -0.0225311   0.2358569   0.1154706   0.10946961\n",
      "  0.20655268 -0.19170517  0.0794156   0.21880643], shape=(64,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# action embeddings\n",
    "action_embs_v1 = tf.data.Dataset.from_tensor_slices([d['embedding'] for d in action_emb_lines])\n",
    "\n",
    "for test_embed in action_embs_v1.take(1):\n",
    "    print(test_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6a8ac015-912a-43f1-a4cb-bea6c800e716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1775, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# action IDs\n",
    "action_id_strs = [d['id'] for d in action_emb_lines]\n",
    "action_ids_ints = tf.strings.to_number(\n",
    "    action_id_strs,\n",
    "    out_type=tf.dtypes.int64,\n",
    "    name=None\n",
    ")\n",
    "action_ids_v1 = tf.data.Dataset.from_tensor_slices([d for d in action_ids_ints])\n",
    "\n",
    "for x in action_ids_v1.take(1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee59e06f-3b66-4ada-87fc-f5af3f709958",
   "metadata": {
    "tags": []
   },
   "source": [
    "### build scann index\n",
    "\n",
    "see ScaNN references:\n",
    "* [documentation](https://www.tensorflow.org/recommenders/api_docs/python/tfrs/layers/factorized_top_k/ScaNN#index_from_dataset)\n",
    "* used in [this tutorial](https://www.tensorflow.org/recommenders/examples/efficient_serving#tuning_scann)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741a1315-d141-4eeb-819f-0b3e6d00e98f",
   "metadata": {},
   "source": [
    "**Understanding ScaNN parameters**\n",
    "\n",
    "Consider:\n",
    "\n",
    "* `num_leaves=100` \n",
    "* `num_leaves_to_search=10` \n",
    "\n",
    "> This means our ScaNN database is partitioned into **100 disjoint subsets**, and the **10 most promising of these partitions** is scored with AH. This means 10/100=10% of the dataset is being searched with AH\n",
    "\n",
    "Now consider:\n",
    "\n",
    "* `num_leaves=1000` \n",
    "* `num_leaves_to_search=100` \n",
    "\n",
    "> still searching 10% of the database with AH. However, in comparison to the previous setting, the 10% we would search will contain higher-quality candidates, because a **higher `num_leaves` allows us to make finer-grained decisions about what parts of the dataset are worth searching**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb71501b-996d-41bc-a55d-52ce402682dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "55228fed-fbe5-483a-9ff3-1aaa1c5e2482",
   "metadata": {},
   "outputs": [],
   "source": [
    "scann = tfrs.layers.factorized_top_k.ScaNN(\n",
    "    k=10,\n",
    "    num_leaves=1000,\n",
    "    num_leaves_to_search=100,\n",
    "    num_reordering_candidates=500,\n",
    ")\n",
    "# scann"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69117309-fd3f-46ef-89ae-263768338e2b",
   "metadata": {},
   "source": [
    "the `candidates` arg in `index_from_dataset`:\n",
    "\n",
    "> Dataset of candidate embeddings or `(candidate identifier, candidate embedding)` pairs. \n",
    "\n",
    "* If the dataset returns tuples, the identifiers will be used as identifiers of top candidates returned when performing searches. \n",
    "* If not given, indices into the candidates dataset will be given instead.\n",
    "\n",
    "Also, `candidates` and `identifiers` have to have the same batch dimension\n",
    "> use `.batch()` when zipping dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "62d4b753-b246-4327-9ebc-25fb30b2c2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.ScaNN at 0x7fbaa06e22f0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scann.index_from_dataset(\n",
    "    candidates=ds_zipped_v2 = tf.data.Dataset.zip(\n",
    "        action_ids_v1.batch(1000), \n",
    "        action_embs_v1.batch(1000)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b63d7c58-cc93-470e-84b1-b5338e847fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00417863, -0.04035826,  0.03949881,  0.02248106,  0.03972029,\n",
       "       -0.03954465, -0.0078277 , -0.00666126,  0.0240129 ,  0.03367153,\n",
       "       -0.01583817,  0.03204237,  0.04059358, -0.03843267,  0.00045175,\n",
       "        0.00292462, -0.04330502, -0.00924589,  0.04248578,  0.03299932,\n",
       "        0.00611916, -0.03558064, -0.04670314, -0.0222977 , -0.04777682,\n",
       "       -0.03742123, -0.03174067, -0.01043591,  0.04092886, -0.02244899,\n",
       "       -0.03317848, -0.03101618, -0.03086665, -0.03440733, -0.04183024,\n",
       "        0.01905538,  0.02743418,  0.03782295,  0.00370765,  0.04130132,\n",
       "        0.00137607,  0.02548063, -0.02434435, -0.02880038,  0.01019372,\n",
       "       -0.01553645, -0.04996688, -0.0459705 ,  0.24497205, -0.22872275,\n",
       "       -0.12215847, -0.17597657, -0.21268445,  0.10867788, -0.1677419 ,\n",
       "        0.23022158, -0.0225311 ,  0.2358569 ,  0.1154706 ,  0.10946961,\n",
       "        0.20655268, -0.19170517,  0.0794156 ,  0.21880643], dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_embed.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0961dc1b-78fc-4dee-87a1-655d113f8f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([  62, 3567, 3817,  740,  464, 3583, 2516, 1286,  783,  359])>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores, action_anns = scann(test_embed.numpy())\n",
    "action_anns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa2b179-04df-4fe4-bdc4-7b3e8efde69b",
   "metadata": {},
   "source": [
    "## Agent\n",
    "\n",
    "`sampled_softmax_num_negatives`\n",
    "* Number of `negative` actions used to compute the sampled_softmax loss. \n",
    "* if None, regular softmax will be used instead of sampled_softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d14d1065-25bf-43e2-809e-6fce77cc162b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "from src.agents import topk_reinforce_agent as topk_reinforce_agent\n",
    "\n",
    "from src.agents import offline_evaluation as offline_evaluation\n",
    "from src.agents import offline_metrics as offline_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5de0fe6b-0596-4299-be11-b6272128fabc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# k actions recommended by policy\n",
    "policy_num_actions=5\n",
    "\n",
    "# number of actions with highest Q value\n",
    "num_greedy_actions=4\n",
    "\n",
    "# Number of actions to retrieve using SCANN in the policy. \n",
    "#   A softmax is computed on this reduced set instead of the whole\n",
    "#   vocabulary to improve efficiency\n",
    "# None == all actions used to compute the softmax\n",
    "scann_num_candidate_actions=None\n",
    "\n",
    "# Number of `negative` actions used to compute the sampled_softmax loss\n",
    "# None == regular softmax\n",
    "sampled_softmax_num_negatives=None\n",
    "\n",
    "# If True, trains main policy using supervised loss equal to \n",
    "# the negative log probability of actions, instead of 'Off Policy REINFORCE loss'\n",
    "# useful for debugging, e.g. can model mimick the dataset behavior?\n",
    "use_supervised_loss_for_main_policy=False\n",
    "\n",
    "# The K used in the off policy correction to compute alpha\n",
    "# (Section 4.3 of paper). None == no off-policy correction applied\n",
    "off_policy_correction_exponent=None\n",
    "\n",
    "GAMMA=0.9\n",
    "SUMMARIZE_GRADS_AND_VARS=True\n",
    "DEBUG_SUMMARIES=False # TODO: error with summary stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "883414de-0bb1-4b4c-b91a-161e18c7f836",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf_agent = topk_reinforce_agent.TopKOffPolicyReinforceAgent(\n",
    "    time_step_spec=time_step_spec,\n",
    "    action_spec=action_spec,\n",
    "    state_embedding_network=state_embedding_network,\n",
    "    optimizer=optimizer,\n",
    "    off_policy_correction_exponent=off_policy_correction_exponent,\n",
    "    action_lookup_layer=action_lookup_layer,                  # action_lookup_layer | None\n",
    "    inverse_action_lookup_layer=inverse_action_lookup_layer,  # inverse_action_lookup_layer | None\n",
    "    policy_num_actions=policy_num_actions,\n",
    "    use_supervised_loss_for_main_policy=use_supervised_loss_for_main_policy,\n",
    "    num_candidate_actions=scann_num_candidate_actions,\n",
    "    num_greedy_actions=policy_num_actions,\n",
    "    sampled_softmax_num_negatives=sampled_softmax_num_negatives,\n",
    "    train_step_counter=global_step,\n",
    "    gamma=GAMMA,\n",
    "    summarize_grads_and_vars=SUMMARIZE_GRADS_AND_VARS,\n",
    "    debug_summaries=DEBUG_SUMMARIES,\n",
    "    name='TopKOffPolicyReinforceAgent'\n",
    ")\n",
    "\n",
    "tf_agent.initialize()\n",
    "\n",
    "train_checkpointer = common.Checkpointer(\n",
    "    ckpt_dir=CHECKPT_DIR,\n",
    "    agent=tf_agent,\n",
    "    global_step=global_step\n",
    ")\n",
    "\n",
    "policy_checkpointer = common.Checkpointer(\n",
    "    ckpt_dir=os.path.join(CHECKPT_DIR, 'policy'),\n",
    "    policy=tf_agent.policy,\n",
    "    global_step=global_step\n",
    ")\n",
    "\n",
    "train_checkpointer.initialize_or_restore()\n",
    "\n",
    "evaluate = offline_evaluation.evaluate\n",
    "# evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a377d673-b8f3-404e-8e93-0ac0173f0923",
   "metadata": {},
   "source": [
    "**summary writers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5531d5b7-be53-4953-9bec-e7ea51c9137c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_dir = os.path.expanduser(LOG_DIR)\n",
    "train_log_dir = os.path.join(log_dir, 'train')\n",
    "eval_log_dir = os.path.join(log_dir, 'eval')\n",
    "\n",
    "# summary writers\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    train_log_dir, flush_millis=10 * 1000\n",
    ")\n",
    "train_summary_writer.set_as_default()\n",
    "\n",
    "eval_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    eval_log_dir, flush_millis=10 * 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4eeb6d-806a-422b-a023-a2f37560ccce",
   "metadata": {},
   "source": [
    "**helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "65b6c35c-9887-433c-b3ca-0d5140af0eea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_tf_functions= True\n",
    "sequence_length=10\n",
    "train_batch_size=64 # 64 | 5\n",
    "eval_batch_size=64 # 64 | 5\n",
    "num_eval_batches=10\n",
    "\n",
    "# if use_tf_functions:\n",
    "#     \"\"\"\n",
    "#     TODO: Currently wrapping evaluate in tf.function does not\n",
    "#       work because creating a new scann index in\n",
    "#       tf_agent.post_process_policy() seems to create new variables.\n",
    "      \n",
    "#     Moving the index() into the tf.function doesn't seem to work either. \n",
    "#       Currently this is not a huge blocker since eval only takes 5 seconds\n",
    "#     \"\"\"\n",
    "#     tf_agent.train = common.function(tf_agent.train)\n",
    "\n",
    "tf_agent.train = common.function(tf_agent.train)\n",
    "# ====================================================\n",
    "# create datasets\n",
    "# ====================================================\n",
    "process_example_fn = functools.partial(\n",
    "    example_proto_to_trajectory,\n",
    "    sequence_length=sequence_length\n",
    ")\n",
    "\n",
    "train_dataset = create_tfrecord_ds(\n",
    "    tf.io.gfile.glob(train_files),\n",
    "    num_shards=len(train_files),\n",
    "    process_example_fn=process_example_fn,\n",
    "    batch_size=train_batch_size\n",
    ")\n",
    "train_dataset_iterator = iter(train_dataset)\n",
    "\n",
    "eval_dataset = create_tfrecord_ds(\n",
    "    tf.io.gfile.glob(val_files),\n",
    "    process_example_fn=process_example_fn,\n",
    "    batch_size=eval_batch_size,\n",
    "    num_shards=len(val_files),\n",
    "    repeat=False,\n",
    "    drop_remainder=True\n",
    ")\n",
    "\n",
    "offline_eval_metrics = [\n",
    "    offline_metrics.AccuracyAtK(),\n",
    "    offline_metrics.AveragePerClassAccuracyAtK(\n",
    "        action_vocab_size, action_lookup=action_lookup_layer\n",
    "    ),\n",
    "    offline_metrics.WeightedReturns(\n",
    "        gamma=1.,\n",
    "        action_lookup=action_lookup_layer,\n",
    "        name='WeightedReturns_gamma_1'\n",
    "    ),\n",
    "    # offline_metrics.LastActionAccuracyAtK(),\n",
    "]\n",
    "        \n",
    "if num_eval_batches is not None:\n",
    "    eval_dataset = eval_dataset.take(num_eval_batches)\n",
    "    \n",
    "# ====================================================\n",
    "# metric summaries\n",
    "# ====================================================\n",
    "\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import export_utils\n",
    "\n",
    "def _export_metrics_and_summaries(step, metrics):\n",
    "    \"\"\"Exports metrics and tf summaries.\"\"\"\n",
    "    metric_utils.log_metrics(metrics)\n",
    "    export_utils.export_metrics(step=step, metrics=metrics)\n",
    "    for metric in metrics:\n",
    "        metric.tf_summaries(train_step=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228bdbed-a927-4b65-a50c-a956b5e41bac",
   "metadata": {},
   "source": [
    "## Train loop\n",
    "\n",
    "**tf_agent.train()**\n",
    "\n",
    "Args:\n",
    "* **experience**: A batch of experience data in the form of a `Trajectory`. \n",
    "  * The structure of `experience` must match that of `self.training_data_spec`. \n",
    "  * All tensors in `experience` must be shaped `[batch, time, ...]` where `time` must be equal to `self.train_step_length` if that property is not `None`.\n",
    "\n",
    "* **weights**: (optional).  A `Tensor`, either `0-D` or shaped `[batch]`, containing weights to be used when calculating the total train loss. \n",
    "  * Weights are typically multiplied elementwise against the per-batch loss, but the implementation is up to the Agent.\n",
    "\n",
    "[src](https://github.com/tensorflow/agents/blob/master/tf_agents/agents/tf_agent.py#L317C1-L326C51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "784111d1-9ab2-45db-9cce-9b5822b1e1af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_iterations=10000\n",
    "\n",
    "eval_interval=num_iterations/4 # 2500\n",
    "log_interval=num_iterations/10 # 1000\n",
    "summary_interval=100\n",
    "\n",
    "train_checkpoint_interval=15000\n",
    "policy_checkpoint_interval=15000\n",
    "\n",
    "distribution_strategy = strategy_utils.get_strategy(\n",
    "    tpu=False, use_gpu=True\n",
    ")\n",
    "\n",
    "# global_step\n",
    "# tf_agent.training_data_spec\n",
    "# tf_agent.train_step_counter\n",
    "# weights.shape\n",
    "\n",
    "tf_agent.train_step_counter.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b47d37d8-e518-49b0-858c-1cf7cc3b3dec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 1000, loss = 97.7967529296875\n",
      "16.153 steps/sec\n",
      "step = 2000, loss = 97.7019271850586\n",
      "24.051 steps/sec\n",
      "Eval at step: 2500\n",
      "step = 3000, loss = 98.43663024902344\n",
      "24.25 steps/sec\n",
      "step = 4000, loss = 94.42931365966797\n",
      "24.705 steps/sec\n",
      "step = 5000, loss = 94.94149017333984\n",
      "24.092 steps/sec\n",
      "Eval at step: 5000\n",
      "step = 6000, loss = 85.7286605834961\n",
      "28.402 steps/sec\n",
      "step = 7000, loss = 87.8939208984375\n",
      "27.163 steps/sec\n",
      "Eval at step: 7500\n",
      "step = 8000, loss = 88.1651382446289\n",
      "27.406 steps/sec\n",
      "step = 9000, loss = 87.25716400146484\n",
      "27.253 steps/sec\n",
      "step = 10000, loss = 86.69618225097656\n",
      "30.344 steps/sec\n",
      "Eval at step: 10000\n",
      "total runtime : 0\n",
      "\n",
      "Offline eval metrics:\n",
      "AccuracyAtK  =  0.0890625\n",
      "\n",
      "Offline eval metrics:\n",
      "AveragePerClassAccuracyAtK  =  0.05576651\n",
      "\n",
      "Offline eval metrics:\n",
      "WeightedReturns_gamma_1  =  -312.88495\n"
     ]
    }
   ],
   "source": [
    "list_o_loss=[]\n",
    "start_time = time.time()\n",
    "\n",
    "with tf.compat.v2.summary.record_if(\n",
    "    lambda: tf.math.equal(global_step % summary_interval, 0)\n",
    "):\n",
    "    timed_at_step = global_step.numpy()\n",
    "    time_acc = 0\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        traj_ex, weights_ex = next(train_dataset_iterator)\n",
    "        train_loss = tf_agent.train(\n",
    "            experience=traj_ex, weights=weights_ex\n",
    "        )\n",
    "        list_o_loss.append(train_loss.loss.numpy())\n",
    "        time_acc += time.time() - start_time\n",
    "\n",
    "        global_step_val = global_step.numpy()\n",
    "        if global_step_val % log_interval == 0:\n",
    "            print(f\"step = {global_step_val}, loss = {train_loss.loss}\")\n",
    "            steps_per_sec = (global_step_val - timed_at_step) / time_acc\n",
    "            \n",
    "            print(f\"{round(steps_per_sec,3)} steps/sec\")\n",
    "            tf.summary.scalar(\n",
    "                name='global_steps_per_sec', \n",
    "                data=steps_per_sec, \n",
    "                step=global_step\n",
    "            )\n",
    "            \n",
    "            timed_at_step = global_step_val\n",
    "            time_acc = 0\n",
    "\n",
    "        if global_step_val % train_checkpoint_interval == 0:\n",
    "            train_checkpointer.save(global_step=global_step_val)\n",
    "\n",
    "        if global_step_val % policy_checkpoint_interval == 0:\n",
    "            tf_agent.post_process_policy()\n",
    "            policy_checkpointer.save(global_step=global_step_val)\n",
    "\n",
    "        if global_step_val % eval_interval == 0:\n",
    "            tf_agent.post_process_policy()\n",
    "            print(f\"Eval at step: {global_step_val}\")\n",
    "            evaluate(\n",
    "                tf_agent.policy,\n",
    "                eval_dataset,\n",
    "                offline_eval_metrics=offline_eval_metrics,\n",
    "                train_step=global_step,\n",
    "                summary_writer=eval_summary_writer,\n",
    "                summary_prefix='Metrics',\n",
    "            )\n",
    "            metric_utils.log_metrics(offline_eval_metrics)\n",
    "                \n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"total runtime : {runtime_mins}\")\n",
    "\n",
    "for metric in offline_eval_metrics:\n",
    "    print(f\"\\nOffline eval metrics:\")\n",
    "    print(metric.name, ' = ', metric.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f44095ed-1624-4cd3-9b43-5754c173312a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<src.agents.offline_metrics.AccuracyAtK at 0x7fe31063ac50>,\n",
       " <src.agents.offline_metrics.AveragePerClassAccuracyAtK at 0x7fe324204e20>,\n",
       " <src.agents.offline_metrics.WeightedReturns at 0x7fe310067280>]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offline_eval_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5597142e-fbbe-4a65-a016-79d8f5ae275d",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "notes:\n",
    "* Accuracy metrics are suspicious, since the RNN model is trained to maximize Accuracy\n",
    "* Offline metrics may not be very reliable for `Top-K Off-Policy Correction`\n",
    "\n",
    "**TODO**\n",
    "* adding a small positive reward for time steps without clicks: will help REINFORCE accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "72f0a0ae-2767-4998-b6e1-8296031f671f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_o_loss)\n",
    "# plt.ylim([0, 10])\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd4c511-6b36-4984-af2d-45e1f6928883",
   "metadata": {},
   "source": [
    "## TensorBoard\n",
    "\n",
    "**TODO:**\n",
    "* investigate `Losses/regularization_loss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e5af3972-33b5-4569-92f3-173d67799bf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "74b756de-aad5-4a46-a192-45412ecb8c7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-92d5403984dde082\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-92d5403984dde082\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %tensorboard --logdir=$train_log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af75b469-dc5c-4611-b312-29468af5403e",
   "metadata": {},
   "source": [
    "**Gradient summaries**\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src='imgs/summary_gradients_tb.png' width='1200'/>\n",
    "</p>\n",
    "\n",
    "\n",
    "**Var histograms**\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src='imgs/histograms_tb.png' width='1200'/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6165aeb5-810a-4154-a6ea-91a96bea291e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-rec-topk-v1/run-20241122-184115/logs/eval'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eval_log_dir\n",
    "\n",
    "# %tensorboard --logdir=$eval_log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "881587d7-ad7e-4915-8b53-ed78bf66fe2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorboard import notebook\n",
    "notebook.list() # View open TensorBoard instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc73fdb-c649-42fb-8eb9-e5baed7dbbd8",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac247f6-8722-4851-a49f-da4fe88543d3",
   "metadata": {},
   "source": [
    "Create an inference dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a3be02d2-e4b8-4525-98f0-7c3beaa3f8ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'action': <tf.Tensor: shape=(1, 10), dtype=int64, numpy=array([[  95, 3107,  290, 2847,    5, 2502,  476, 3045, 2326,    0]])>,\n",
       " 'discount': <tf.Tensor: shape=(1, 10), dtype=float32, numpy=array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)>,\n",
       " 'next_step_type': <tf.Tensor: shape=(1, 10), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>,\n",
       " 'observation': <tf.Tensor: shape=(1, 10), dtype=int64, numpy=array([[ 293,   95, 3107,  290, 2847,    5, 2502,  476, 3045,    0]])>,\n",
       " 'policy_info': (),\n",
       " 'reward': <tf.Tensor: shape=(1, 10), dtype=float32, numpy=array([[5., 3., 5., 4., 3., 4., 2., 4., 3., 0.]], dtype=float32)>,\n",
       " 'step_type': <tf.Tensor: shape=(1, 10), dtype=int32, numpy=array([[0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_dataset = create_tfrecord_ds(\n",
    "    tf.io.gfile.glob(val_files),\n",
    "    process_example_fn=process_example_fn,\n",
    "    batch_size=1,\n",
    "    num_shards=len(val_files),\n",
    "    repeat=False,\n",
    "    drop_remainder=True\n",
    ")\n",
    "infer_batch = list(inference_dataset.take(1))[0]\n",
    "traj_infer, weights_infer = infer_batch\n",
    "\n",
    "traj_infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ce4f94d4-400c-4dd4-9283-268edc9d4b0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=array([[0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_infer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c315bd46-4da1-4d95-a8f9-c9ade00981de",
   "metadata": {},
   "source": [
    "Check initial policy state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4d1c4795-a5bc-472f-814a-94f4b29e91c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((ListWrapper([<tf.Tensor: shape=(1, 25), dtype=float32, numpy=\n",
       "  array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>, <tf.Tensor: shape=(1, 25), dtype=float32, numpy=\n",
       "  array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>]),),)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_state = tf_agent.policy.get_initial_state(traj_infer.step_type.shape[0])\n",
    "policy_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf84f80b-e200-4755-a0f3-c6bbfc60362c",
   "metadata": {},
   "source": [
    "Generate predictions for each step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ac80d4bb-e6ce-44e4-a765-3934eb6013c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_infer.step_type.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c892c1bc-897b-4add-86cb-2af45276ed54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_actions = []\n",
    "\n",
    "for i in tf.range(traj_infer.step_type.shape[1]):\n",
    "\n",
    "    observation = traj_infer.observation[:, i, tf.newaxis]\n",
    "    step_type = traj_infer.step_type[:, i, tf.newaxis]\n",
    "    time_step = ts.TimeStep(\n",
    "        step_type=step_type,\n",
    "        observation=observation,\n",
    "        reward=tf.zeros_like(step_type, tf.float32),\n",
    "        discount=tf.ones_like(step_type, tf.float32)\n",
    "    )\n",
    "\n",
    "    action_step = tf_agent.policy.action(time_step, policy_state)\n",
    "    policy_state = action_step.state\n",
    "    predicted_actions.append(action_step.action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bf4c18e3-49bf-4674-ad65-6df448d7fd8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[ 604,  293, 1195,  589, 2693]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[1656,  604,  293, 1195,   24]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[ 293,  604, 2693, 3078,   49]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[ 453, 1568,  108, 3078, 2502]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[1568,  453, 3349,  373,    5]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[1568,  453, 3349,  373,    5]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[1568,  453, 3349,  470,    5]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[2847, 1568,  373, 3187,  724]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[3107, 3078, 2693, 2928, 2614]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[2693,  220, 2928, 1245,   33]])>]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0a09e2-40b1-4987-956e-15a813ba51ad",
   "metadata": {},
   "source": [
    "Check policy state now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4fd950cc-9141-4667-a6f4-6921b86aaf62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((ListWrapper([<tf.Tensor: shape=(1, 25), dtype=float32, numpy=\n",
       "  array([[ 0.3267586 , -0.7355204 , -0.9962924 , -0.9961593 ,  0.6748876 ,\n",
       "           0.3188045 , -0.7840215 ,  0.18547933,  0.20696203,  0.7223773 ,\n",
       "          -0.9750901 ,  0.21134734, -0.13331994, -0.7303762 , -0.79875267,\n",
       "           0.48667616,  0.11983376, -0.8934608 , -0.98590976,  0.5425591 ,\n",
       "           0.02740378, -0.72694683,  0.73088706,  0.23428164, -0.78795624]],\n",
       "        dtype=float32)>, <tf.Tensor: shape=(1, 25), dtype=float32, numpy=\n",
       "  array([[ 0.36044252, -0.9428246 , -3.2312407 , -4.798354  ,  0.8309968 ,\n",
       "           0.3362579 , -1.0557446 ,  0.19161415,  0.2100969 ,  0.91275525,\n",
       "          -2.1877503 ,  0.21458471, -0.13415602, -0.947164  , -1.0981687 ,\n",
       "           0.53183675,  0.12049197, -1.4534069 , -2.5966597 ,  5.8159447 ,\n",
       "           0.02741293, -1.1071931 ,  0.9378762 ,  0.23871554, -1.1059433 ]],\n",
       "        dtype=float32)>]),),)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_step.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "39d44c29-5671-42ed-af28-a066e6007350",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10, 1), dtype=int64, numpy=\n",
       "array([[[  95],\n",
       "        [3107],\n",
       "        [ 290],\n",
       "        [2847],\n",
       "        [   5],\n",
       "        [2502],\n",
       "        [ 476],\n",
       "        [3045],\n",
       "        [2326],\n",
       "        [   0]]])>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_actions = tf.expand_dims(traj_infer.action, axis=2)\n",
    "observed_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e2d341d0-af98-4d03-b09d-8e165c5ff8a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10, 5), dtype=int64, numpy=\n",
       "array([[[ 604,  293, 1195,  589, 2693],\n",
       "        [1656,  604,  293, 1195,   24],\n",
       "        [ 293,  604, 2693, 3078,   49],\n",
       "        [ 453, 1568,  108, 3078, 2502],\n",
       "        [1568,  453, 3349,  373,    5],\n",
       "        [1568,  453, 3349,  373,    5],\n",
       "        [1568,  453, 3349,  470,    5],\n",
       "        [2847, 1568,  373, 3187,  724],\n",
       "        [3107, 3078, 2693, 2928, 2614],\n",
       "        [2693,  220, 2928, 1245,   33]]])>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_actions_stacked = tf.stack(predicted_actions, axis=1)\n",
    "predicted_actions_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "58dd883e-ef68-45ee-8ead-6278245782ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=bool, numpy=\n",
       "array([[False, False, False, False,  True, False, False, False, False,\n",
       "        False]])>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_predictions = tf.reduce_any(\n",
    "    predicted_actions_stacked == observed_actions, axis=2\n",
    ")\n",
    "correct_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "43e33ae8-1abb-42ae-aa52-4881122ef3a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Predictions:\n",
      "tf.Tensor([[False False False False  True False False False False False]], shape=(1, 10), dtype=bool)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Correct Predictions:')\n",
    "print(correct_predictions)\n",
    "print('-' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "57266671-f235-4d0c-9478-31ea97fffc65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed Actions (vocab):\n",
      "tf.Tensor([[  96 3108  291 2848    6 2503  477 3046 2327    1]], shape=(1, 10), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print('Observed Actions (vocab):')\n",
    "print(action_lookup_layer(traj_infer.action))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ad96878b-0843-4f8b-b98e-bed238ddaab6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Actions (vocab):\n",
      "tf.Tensor(\n",
      "[[[ 605  294 1196  590 2694]]\n",
      "\n",
      " [[1657  605  294 1196   25]]\n",
      "\n",
      " [[ 294  605 2694 3079   50]]\n",
      "\n",
      " [[ 454 1569  109 3079 2503]]\n",
      "\n",
      " [[1569  454 3350  374    6]]\n",
      "\n",
      " [[1569  454 3350  374    6]]\n",
      "\n",
      " [[1569  454 3350  471    6]]\n",
      "\n",
      " [[2848 1569  374 3188  725]]\n",
      "\n",
      " [[3108 3079 2694 2929 2615]]\n",
      "\n",
      " [[2694  221 2929 1246   34]]], shape=(10, 1, 5), dtype=int64)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Predicted Actions (vocab):')\n",
    "print(action_lookup_layer(predicted_actions))\n",
    "print('-' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b3965378-17d6-44c9-a57e-ccb8eeca029c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed Actions (raw):\n",
      "tf.Tensor([[  95 3107  290 2847    5 2502  476 3045 2326    0]], shape=(1, 10), dtype=int64)\n",
      "--------------------------------------------------------------------------------\n",
      "Predicted Actions (raw):\n",
      "[<tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[ 604,  293, 1195,  589, 2693]])>, <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[1656,  604,  293, 1195,   24]])>, <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[ 293,  604, 2693, 3078,   49]])>, <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[ 453, 1568,  108, 3078, 2502]])>, <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[1568,  453, 3349,  373,    5]])>, <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[1568,  453, 3349,  373,    5]])>, <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[1568,  453, 3349,  470,    5]])>, <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[2847, 1568,  373, 3187,  724]])>, <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[3107, 3078, 2693, 2928, 2614]])>, <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[2693,  220, 2928, 1245,   33]])>]\n"
     ]
    }
   ],
   "source": [
    "print('Observed Actions (raw):')\n",
    "print(traj_infer.action)\n",
    "print('-' * 80)\n",
    "print('Predicted Actions (raw):')\n",
    "print(predicted_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4a220b-60f5-4376-83fa-9efc0b1bb1e1",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Notes n stash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39b3f3a-c564-4e3e-94b3-311c6a386926",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Experiment ideas\n",
    "\n",
    "**Create experiment comparing:**\n",
    "\n",
    "[1] rnn\n",
    "* off_policy_correction_exponent = None\n",
    "* use_supervised_loss_for_main_policy = True\n",
    "\n",
    "[2] REINFORCE\n",
    "* off_policy_correction_exponent = None\n",
    "* use_supervised_loss_for_main_policy = False\n",
    "\n",
    "[3] topk REINFORCE\n",
    "* off_policy_correction_exponent = ~16\n",
    "* use_supervised_loss_for_main_policy = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7752fb7-2134-47ef-9013-3a2797b1e98c",
   "metadata": {},
   "source": [
    "## synthetic data for tutorial/demo\n",
    "\n",
    "Create dummy item IDs and embeddings like [src](https://www.tensorflow.org/recommenders/examples/efficient_serving#tuning_scann)\n",
    "\n",
    "```\n",
    "# Construct a dataset of movies that's 1,000 times larger. We \n",
    "# do this by adding several million dummy movie titles to the dataset.\n",
    "lots_of_movies = tf.data.Dataset.concatenate(\n",
    "    movies.batch(4096),\n",
    "    movies.batch(4096).repeat(1_000).map(lambda x: tf.zeros_like(x))\n",
    ")\n",
    "\n",
    "# We also add lots of dummy embeddings by randomly perturbing\n",
    "# the estimated embeddings for real movies.\n",
    "lots_of_movies_embeddings = tf.data.Dataset.concatenate(\n",
    "    movies.batch(4096).map(model.movie_model),\n",
    "    movies.batch(4096).repeat(1_000)\n",
    "      .map(lambda x: model.movie_model(x))\n",
    "      .map(lambda x: x * tf.random.uniform(tf.shape(x)))\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4fdf9e-25fa-463e-ae4a-f30f59ef29ae",
   "metadata": {},
   "source": [
    "#### TODO: optimize train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f856c61-bf1f-49a7-8139-726dda59a8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@common.function(autograph=False)\n",
    "def _train_step_fn(data):\n",
    "    \n",
    "    # trajectory, weights = data\n",
    "\n",
    "    def replicated_train_step(experience):\n",
    "        return tf_agent.train(experience).loss\n",
    "\n",
    "    per_replica_losses = distribution_strategy.run(\n",
    "        replicated_train_step, \n",
    "        args=(data,)\n",
    "    )\n",
    "\n",
    "    # return agent.train(experience=trajectories).loss\n",
    "    return distribution_strategy.reduce(\n",
    "        tf.distribute.ReduceOp.MEAN, \n",
    "        per_replica_losses, # loss, \n",
    "        axis=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b5bd54-b113-4b99-84ad-9890dcc14b2e",
   "metadata": {},
   "source": [
    "#### TODO: record summary within scope?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c279d482-177e-480f-80b0-44370ddbfa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.compat.v2.summary.record_if(\n",
    "#     lambda: tf.math.equal(global_step % summary_interval, 0)):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6974c692-c031-4bfb-905c-6e3ab4265097",
   "metadata": {},
   "source": [
    "```\n",
    "    @common.function(autograph=False)\n",
    "    def _train_step_fn(data):\n",
    "        \n",
    "        def replicated_train_step(experience):\n",
    "            return agent.train(experience).loss\n",
    "        \n",
    "        trajectories = _trajectory_fn(data)\n",
    "\n",
    "        per_replica_losses = distribution_strategy.run(\n",
    "            replicated_train_step, \n",
    "            args=(trajectories,)\n",
    "        )\n",
    "\n",
    "        # return agent.train(experience=trajectories).loss\n",
    "        return distribution_strategy.reduce(\n",
    "            tf.distribute.ReduceOp.MEAN, \n",
    "            per_replica_losses, # loss, \n",
    "            axis=None\n",
    "        )\n",
    "        \n",
    "    ...\n",
    "    \n",
    "    loss = _train_step_fn(data)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7f3d1f-9268-4a9a-9a9f-f906e1352502",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
