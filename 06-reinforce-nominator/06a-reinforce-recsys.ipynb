{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7767b603-7035-4fb3-b727-9704383e93a2",
   "metadata": {},
   "source": [
    "# REINFORCE recommender agent\n",
    "\n",
    "```\n",
    "Top-K Off-Policy Correction for a REINFORCE Recommender System\n",
    "Minmin Chen, Alex Beutel, Paul Covington, Sagar Jain, Francois Belletti, Ed Chi\n",
    "https://arxiv.org/pdf/1812.02353.pdf\n",
    "```\n",
    "This notebook steps details how to train and evaluate the REINFORCE Recommender agent from the paper above. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fde96d8-ab7e-4846-8391-1b4603f5df9a",
   "metadata": {},
   "source": [
    "## env setup\n",
    "\n",
    "if implementing a scann index for efficient `action retreival` function, install `scann` (and version):\n",
    "\n",
    "> scann==1.2.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ba60d66-b31e-4250-be7d-00b0736a4eaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "VERSION        = \"v2\"                       # TODO\n",
    "PREFIX         = f'rec-bandits-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dd67236-2dcc-44d1-b633-0a80f2c0ebdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"rec-bandits-v2\"\n",
      "VERSION                  = \"v2\"\n",
      "\n",
      "BUCKET_NAME              = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_NAME    = \"mvlens_rec_bandits_v2\"\n",
      "BIGQUERY_TABLE_NAME      = \"training_dataset\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-rec-bandits-v2\"\n",
      "\n",
      "DOCKERNAME_01            = \"Dockerfile_train_my_perarm_env\"\n",
      "IMAGE_NAME_01            = \"train-my-perarm-env-v2\"\n",
      "IMAGE_URI_01             = \"gcr.io/hybrid-vertex/train-my-perarm-env-v2\"\n",
      "\n",
      "DOCKERNAME_02            = \"Dockerfile_perarm_feats\"\n",
      "IMAGE_NAME_02            = \"train-perarm-feats-v2\"\n",
      "IMAGE_URI_02             = \"gcr.io/hybrid-vertex/train-perarm-feats-v2\"\n",
      "\n",
      "DOCKERNAME_03            = \"Dockerfile_ranking_bandit\"\n",
      "IMAGE_NAME_03            = \"train-rank-bandit-v2\"\n",
      "IMAGE_URI_03             = \"gcr.io/hybrid-vertex/train-rank-bandit-v2\"\n",
      "\n",
      "DOCKERNAME_04            = \"Dockerfile_train_bandit_e2e\"\n",
      "IMAGE_NAME_04            = \"train-mab-e2e-v2\"\n",
      "IMAGE_URI_04             = \"gcr.io/hybrid-vertex/train-mab-e2e-v2\"\n",
      "\n",
      "DOCKERNAME_04_pred       = \"Dockerfile_pred_bandit_e2e\"\n",
      "IMAGE_NAME_04_pred       = \"pred-mab-e2e-v2\"\n",
      "IMAGE_URI_04_pred        = \"gcr.io/hybrid-vertex/pred-mab-e2e-v2\"\n",
      "\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/local_docker_tfa\"\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449a67ff-c853-4ac7-8ddf-37c9c71ee466",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74ec9e9c-73c9-4e3b-bb07-13e8c9cb5241",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "404e8b3c-63bb-453a-8798-729e8ce16d0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import functools\n",
    "import collections\n",
    "import pickle as pkl\n",
    "from pprint import pprint\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# tf-agents\n",
    "from tf_agents.utils import common\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import sequential\n",
    "from tf_agents.metrics import export_utils\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.train.utils import strategy_utils\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "# this repo\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.utils import rfa_utils as rfa_utils\n",
    "from src.utils import train_utils as train_utils\n",
    "from src.data import data_utils as data_utils\n",
    "from src.data import data_config as data_config\n",
    "from src.networks import encoding_network as emb_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e72c8c2-9a8a-487e-8631-17ce5a572894",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "438a50ed-ff68-41f3-b413-d9033425b856",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0161316-88fa-4000-84db-d7ec3a8037ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "print(f\"device: {device.name.decode()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbe5766d-bb05-48b8-9a83-b81536b9e824",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85e9857-6c78-4535-b126-00bed1c8d2ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sequence data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a99e97-7b78-4ada-8a7f-69662197d1fa",
   "metadata": {},
   "source": [
    "For each `user`, we consider a sequence of user historical interactions with the RecSys, recording the actions taken by the recommender (e.g., items recommended), as well as user feedback (e.g.,`ratings`)\n",
    "\n",
    "Given such a sequence, we predict the next `action` to take, i.e., items to recommend, so that user satisfaction metrics, e.g., indicated by `ratings` improve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d685e97b-a080-486a-8b50-c486553f3493",
   "metadata": {},
   "source": [
    "## Parse sequence examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d35f041d-26c3-4402-8f6c-ea3bf2960947",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1256d869-df7d-4731-a3f5-0870bcb3991b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCS_DATA_PATH: gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m\n"
     ]
    }
   ],
   "source": [
    "EXAMPLE_GEN_GCS_PATH = data_config.EXAMPLE_GEN_GCS_PATH\n",
    "GCS_DATA_PATH = f\"{BUCKET_URI}/{EXAMPLE_GEN_GCS_PATH}\"\n",
    "\n",
    "print(f\"GCS_DATA_PATH: {GCS_DATA_PATH}\")\n",
    "# !gsutil ls $GCS_DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7435dc7-56c8-4de6-b0c0-1fe8c83c1454",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SPLIT = \"train\" # \"train\" | \"val\"\n",
    "\n",
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{EXAMPLE_GEN_GCS_PATH}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "train_files = train_files #[:3] # subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21b3eeaa-e1fa-4adf-9762-93d43d2ef2f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "# train_seq_dataset = train_dataset.map(data_utils._parse_seq_function)\n",
    "\n",
    "# # see train example\n",
    "# for x in train_seq_dataset.skip(5).take(1):\n",
    "#     pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29291382-c029-45b3-a653-9d6536a2d5c5",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Example: proto to trajectory\n",
    "\n",
    "> Let's inspect the trajectory structure we need for our REINFORCE recommender agent. Specifically, we'll construct a `trajectory` object and its associated *importance weights*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ea44275-d358-452a-8bd2-f6875195522d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_length=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30600e99-8853-4eb0-b646-5ab788313658",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### example proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2c96c24-2ba2-469c-8120-742f15fbe017",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for raw_record in train_dataset.take(1):\n",
    "#     example = tf.train.Example()\n",
    "#     example.ParseFromString(raw_record.numpy())\n",
    "#     print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "711624c1-63ba-4861-965a-19b4104ece39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for raw_seq_record in train_dataset.take(1):\n",
    "#     example = tf.train.SequenceExample()\n",
    "#     example.ParseFromString(raw_seq_record.numpy())\n",
    "#     print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf45eea-a088-4298-9be3-81efb03af4cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### rewards\n",
    "\n",
    "* ratings 1-5\n",
    "* can cast ratings over certain threshold to create binary rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24a429cf-ab4d-4338-8a59-5cb41ffd8faf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 4., 3., 4., 5.], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_seq = x[0]['context_movie_rating'].numpy()[-sequence_length:]\n",
    "ratings_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98feef93-de21-4cb8-b7b8-1c269c9fad08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 4., 3., 4., 5.], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rewards = tf.cast(ratings_seq > 0, dtype=tf.float32) # binary rewards\n",
    "rewards = ratings_seq\n",
    "rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c0e214-bd6e-4f68-92f4-cbd550692941",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### actions and observations\n",
    "\n",
    "For now, we are using the following simplified features:\n",
    "* At every point in time, the `target_movie_id` field in the sequence is the **action** \n",
    "* the `context_movie_id` at the previous time step (previous action(s)) is the observation\n",
    "* each `context_movie_id` has a corresponding `context_movie_rating`\n",
    "> * possible to convert `context_movie_rating` to a binary reward (e.g., clicks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88ccfefc-01ef-4276-9744-eada1c7674d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=string, numpy=\n",
       "array([b'2199', b'108', b'1047', b'837', b'1590', b'504', b'1680', b'258',\n",
       "       b'1632', b'586'], dtype=object)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]['context_movie_id'] #[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdb958c5-0447-463b-99c4-39248c186b31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'504', b'1680', b'258', b'1632', b'586'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = x[0]['context_movie_id'].numpy()[-sequence_length:]\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fb76a0b-2eb6-4dd4-b695-ca6bef686a26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'1590', b'504', b'1680', b'258', b'1632'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations = x[0]['context_movie_id'].numpy()[-(sequence_length+1):-1]\n",
    "observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4b54b7-6eb9-4ecc-be23-71f4cc9267a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### pad trajectory elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee327ca8-332f-4b1c-b73c-0cb808e015e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=5>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_sequence_length = tf.shape(observations)[0]\n",
    "actual_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d939006b-ad42-4d12-977e-38138bc7a7f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'504', b'1680', b'258', b'1632', b'586'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = actions[-actual_sequence_length:]\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64b0ad98-0f30-4eda-83ba-99a200d1e990",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 4., 3., 4., 5.], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards = rewards[-actual_sequence_length:]\n",
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a3610d9-59bc-46b7-8cef-bdc03c22a637",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 0], dtype=int32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paddings = tf.stack([0, sequence_length - actual_sequence_length])\n",
    "paddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd604602-ca41-461a-83d8-df8170cef296",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=int32, numpy=array([[0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paddings = tf.expand_dims(paddings, 0)\n",
    "paddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98c936d8-a370-43e7-a919-8fc64749ab49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([3., 4., 3., 4., 5.], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards = tf.pad(rewards, paddings, 'CONSTANT', constant_values=0)\n",
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a90a8ee-107d-4c49-96c4-781f3f7ef469",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discounts = tf.ones((sequence_length,), dtype=tf.float32)\n",
    "discounts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d3f594-abec-4e29-aae6-6c3be3dd2502",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### step types\n",
    "\n",
    "The time dimension will be equal to `sequence_length` \n",
    "\n",
    "The agent assumes that this trajectory is a single episode, so `trajectory.step_type` and `trajectory.discount` are ignored\n",
    "\n",
    "* `ts.StepType.FIRST` == 0\n",
    "* `ts.StepType.MID` == 1\n",
    "* `ts.StepType.LAST` == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39fed2c0-54fb-4866-a7e7-57e60e92dbbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([1, 1, 1, 1, 1], dtype=int32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_step_types = tf.ones((sequence_length,), dtype=tf.int32) * ts.StepType.MID\n",
    "next_step_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58b00f63-2193-4ad7-ba8b-ad5af75ffc48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 1, 1, 1], dtype=int32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_types = tf.concat([[ts.StepType.FIRST], next_step_types[1:]], axis=0)\n",
    "step_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf7b148-736e-403f-992f-3e63dd66362a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### trajectory object\n",
    "\n",
    "* `Discount` is all ones in the base trajectory. During training, we can apply different discounting values with a `gamma` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f914d2d3-d073-40c4-8d66-00a7d2c4c233",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'action': array([b'504', b'1680', b'258', b'1632', b'586'], dtype=object),\n",
       " 'discount': <tf.Tensor: shape=(5,), dtype=float32, numpy=array([1., 1., 1., 1., 1.], dtype=float32)>,\n",
       " 'next_step_type': <tf.Tensor: shape=(5,), dtype=int32, numpy=array([1, 1, 1, 1, 1], dtype=int32)>,\n",
       " 'observation': array([b'1590', b'504', b'1680', b'258', b'1632'], dtype=object),\n",
       " 'policy_info': (),\n",
       " 'reward': <tf.Tensor: shape=(5,), dtype=float32, numpy=array([3., 4., 3., 4., 5.], dtype=float32)>,\n",
       " 'step_type': <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 1, 1, 1], dtype=int32)>})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj = trajectory.Trajectory(\n",
    "      step_type=step_types,\n",
    "      observation=observations,\n",
    "      action=actions,\n",
    "      policy_info=(),\n",
    "      next_step_type=next_step_types,\n",
    "      reward=rewards,\n",
    "      discount=discounts\n",
    ")\n",
    "\n",
    "traj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92e19fc-260a-4d44-87e0-ca94629f1a37",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### importance weights\n",
    "\n",
    "> divides the trajectory into 3 parts: \n",
    "\n",
    "* The **first** part is used to warm start the state embedding network\n",
    "* The **second** part is used to compute losses\n",
    "* Returns are computed using the **second** and **third** parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "327da947-a547-44e8-a91e-c31f71e9efe7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=1>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_size = tf.cast(actual_sequence_length / 3, tf.int32)\n",
    "section_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54d46f28-7f5f-4589-8eba-cf2bf90aa75a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 1., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = tf.concat([\n",
    "    tf.zeros((section_size,)),\n",
    "    tf.ones((section_size,)),\n",
    "    tf.zeros((sequence_length - 2 * section_size,))\n",
    "], axis=0)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a38495-86e8-4090-a3d8-7caee8e07a88",
   "metadata": {},
   "source": [
    "# Data utils\n",
    "\n",
    "> Now let's create the helper functions for creating data pipelines for trajectories and weights\n",
    "\n",
    "**TODO**\n",
    "* abstract data ops to utils etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66ea5987-346d-42b5-8108-1d4df51d32ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_config.MAX_CONTEXT_LENGTH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6857680-6d67-48e8-9fb4-e60b6fb8b8a5",
   "metadata": {},
   "source": [
    "## utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24feaba7-034a-4efe-b54a-5591a22c0dcb",
   "metadata": {},
   "source": [
    "### sequence example to trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13e51673-6ef2-433e-bee5-c5ca0ec5e5e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def example_proto_to_trajectory(\n",
    "    example_proto, # sequence_feature,\n",
    "    sequence_length: int\n",
    "):\n",
    "    \"\"\"\n",
    "    Converts a sequence example to a Trajectory and weights for training.\n",
    "\n",
    "    For now, we are using the following simplified features. At every point in\n",
    "    time, the `context_movie_id` field in the sequence is the action and the `context_movie_id`\n",
    "    at the previous time step (last action) is the observation. The `context_movie_rating` field\n",
    "    is converted to a binary reward.\n",
    "\n",
    "    If the sequence example is longer than than `sequence_length`, we only take\n",
    "    the last part of the sequence example. If it is shorter, we pad it with dummy\n",
    "    values at the end to equal `sequence_length`.\n",
    "\n",
    "    Args:\n",
    "    sequence_feature: A serialized SequenceExample to convert to a\n",
    "      trajectory.\n",
    "    sequence_length: The time dimension of the returned trajectory.\n",
    "\n",
    "    Returns:\n",
    "    trajectory: An unbatched trajectory. The time dimension will be equal to\n",
    "      sequence length. The agent assumes that this trajectory is a single\n",
    "      episode, so `trajectory.step_type` and `trajectory.discount` are ignored.\n",
    "    weights: A [T] float tensor of weights. Each row of `weights`\n",
    "        (along the time dimension) is usually a sequence of 0's, followed by\n",
    "        a sequence of 1's, again followed by a sequence of 0's. This divides\n",
    "        the trajectory into 3 parts. The first part is used to warm start\n",
    "        the state embedding network. The second part is used to compute\n",
    "        losses. Returns are computed using the second and third parts.\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_description = {\n",
    "        'context_movie_id': tf.io.FixedLenFeature(shape=(data_config.MAX_CONTEXT_LENGTH), dtype=tf.string),\n",
    "        'context_movie_rating': tf.io.FixedLenFeature(shape=(data_config.MAX_CONTEXT_LENGTH), dtype=tf.float32),\n",
    "    }\n",
    "    \n",
    "    sequence_feature = tf.io.parse_single_sequence_example(example_proto, feature_description)\n",
    "    \n",
    "    context_id_int = tf.strings.to_number(\n",
    "        sequence_feature[0]['context_movie_id'],\n",
    "        out_type=tf.dtypes.int64,\n",
    "        name=None\n",
    "    )\n",
    "    \n",
    "    sequence_feature[0]['context_movie_id'] = context_id_int\n",
    "    actions = sequence_feature[0]['context_movie_id'][-sequence_length:]\n",
    "    rewards = sequence_feature[0]['context_movie_rating'][-sequence_length:]\n",
    "    observations = sequence_feature[0]['context_movie_id'][-(sequence_length+1):-1]\n",
    "\n",
    "    # actual length\n",
    "    actual_sequence_length = tf.shape(observations)[0]\n",
    "    \n",
    "    actions = actions[-actual_sequence_length:]\n",
    "    rewards = rewards[-actual_sequence_length:]\n",
    "\n",
    "    # padding\n",
    "    paddings = tf.stack([0, sequence_length - actual_sequence_length])\n",
    "    paddings = tf.expand_dims(paddings, 0)\n",
    "\n",
    "    rewards = tf.pad(rewards, paddings, 'CONSTANT', constant_values=0)\n",
    "    actions = tf.pad(actions, paddings, 'CONSTANT', constant_values=0)\n",
    "    observations = tf.pad(observations, paddings, 'CONSTANT', constant_values=0)\n",
    "\n",
    "    # steps & discounts\n",
    "    discounts = tf.ones((sequence_length,), dtype=tf.float32)\n",
    "    next_step_types = tf.ones(\n",
    "      (sequence_length,), dtype=tf.int32) * ts.StepType.MID\n",
    "    step_types = tf.concat([[ts.StepType.FIRST], next_step_types[1:]], axis=0)\n",
    "\n",
    "    # build trajectory\n",
    "    traj = trajectory.Trajectory(\n",
    "        step_type=step_types,\n",
    "        observation=observations,\n",
    "        action=actions,\n",
    "        policy_info=(),\n",
    "        next_step_type=next_step_types,\n",
    "        reward=rewards,\n",
    "        discount=discounts\n",
    "    )\n",
    "\n",
    "    # get importance weights\n",
    "    section_size = tf.cast(actual_sequence_length / 3, tf.int32)\n",
    "    # print(f\"section_size: {section_size}\")\n",
    "    \n",
    "    weights = tf.concat(\n",
    "        [\n",
    "            tf.zeros((section_size,)),\n",
    "            tf.ones((section_size,)),\n",
    "            tf.zeros((sequence_length - 2 * section_size,))\n",
    "        ], \n",
    "        axis=0\n",
    "    )\n",
    "    \n",
    "    return traj, weights # sequence_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e2b739-8db2-4062-9473-73483aa7bb59",
   "metadata": {},
   "source": [
    "### create single TF Record dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e701a090-c072-487c-bfb7-cd0957c40ad3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_single_tfrecord_ds(\n",
    "    filename,\n",
    "    process_example_fn,\n",
    "    shuffle_buffer_size = 1,\n",
    "):\n",
    "    raw_ds = tf.data.TFRecordDataset(filename)\n",
    "    \n",
    "    ds = raw_ds.map(\n",
    "        process_example_fn,\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    ds = ds.shuffle(shuffle_buffer_size)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baaecab-e37e-44e6-849f-8bb943ea3d1f",
   "metadata": {},
   "source": [
    "### create interleaved TF Record dataset\n",
    "\n",
    "1. Each element of a TF Record is processed using the `process_example_fn` and converted to Tensors\n",
    "2. A dataset is created for each record file \n",
    "3. These datasets are interleaved together to create the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6b88787-3c46-419d-8882-284f4576f34d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_tfrecord_ds(\n",
    "    filenames,\n",
    "    process_example_fn,\n",
    "    batch_size: int,\n",
    "    shuffle_buffer_size_per_record: int = 1,\n",
    "    shuffle_buffer_size: int = 10000,\n",
    "    num_shards: int = 50,\n",
    "    cycle_length: int = tf.data.AUTOTUNE,\n",
    "    block_length: int = 10,\n",
    "    num_prefetch: int = 10,\n",
    "    num_parallel_calls: int = 10,\n",
    "    repeat: bool = True,\n",
    "    drop_remainder: bool = False\n",
    "):\n",
    "    filenames = list(filenames)\n",
    "    initial_len = len(filenames)\n",
    "    remainder = initial_len % num_shards\n",
    "    \n",
    "    for _ in range(num_shards - remainder):\n",
    "        filenames.append(\n",
    "            filenames[np.random.randint(low=0, high=initial_len)]\n",
    "        )\n",
    "        \n",
    "    filenames = np.array(filenames)\n",
    "    np.random.shuffle(filenames)\n",
    "    filenames = np.array_split(filenames, num_shards)\n",
    "    filename_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "    \n",
    "    if repeat:\n",
    "        filename_ds = filename_ds.repeat()\n",
    "    \n",
    "    filename_ds = filename_ds.shuffle(len(filenames))\n",
    "    \n",
    "    example_ds = filename_ds.interleave(\n",
    "        functools.partial(\n",
    "            create_single_tfrecord_ds,\n",
    "            process_example_fn=process_example_fn,\n",
    "            shuffle_buffer_size=shuffle_buffer_size_per_record,\n",
    "        ),\n",
    "        cycle_length=tf.data.AUTOTUNE,\n",
    "        block_length=block_length,\n",
    "        num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    )\n",
    "    example_ds = example_ds.shuffle(shuffle_buffer_size)\n",
    "    \n",
    "    example_ds = example_ds.batch(\n",
    "        batch_size, drop_remainder=drop_remainder\n",
    "    ).prefetch(num_prefetch)\n",
    "  \n",
    "    return example_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3ae652-4cbe-436d-8b11-b729c0a659ba",
   "metadata": {},
   "source": [
    "#### inspect output of helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5db1afb-276a-4665-a7a4-31c893e2fe4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_length=10\n",
    "\n",
    "process_example_fn = functools.partial(\n",
    "    example_proto_to_trajectory,\n",
    "    sequence_length=sequence_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb73a2c6-951b-4cce-9415-1e12cc4d8eb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_batch_size=5\n",
    "\n",
    "train_dataset = create_tfrecord_ds(\n",
    "    tf.io.gfile.glob(train_files),\n",
    "    # num_shards = 10,\n",
    "    process_example_fn=process_example_fn,\n",
    "    batch_size=train_batch_size\n",
    ")\n",
    "train_dataset_iterator = iter(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96be0683-e389-4001-b4d3-bc48b32ee293",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 1., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_test, weights = next(train_dataset_iterator)\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24b6d417-e95e-4fd1-b515-f0c0522b718d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'action': <tf.Tensor: shape=(5, 10), dtype=int64, numpy=\n",
       "array([[3003,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [3192, 1359,  228,  593, 2602,  335, 2355, 3381, 3545,    0],\n",
       "       [2802, 3439,  612, 1109, 3175, 2710, 2963, 3429, 2459,    0],\n",
       "       [ 453, 1220, 1179, 1255, 2993, 1023, 3585, 1284, 2125,    0],\n",
       "       [2388, 1483, 3450, 2921, 3038, 2920,  776,  163, 1035,    0]])>,\n",
       " 'discount': <tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)>,\n",
       " 'next_step_type': <tf.Tensor: shape=(5, 10), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>,\n",
       " 'observation': <tf.Tensor: shape=(5, 10), dtype=int64, numpy=\n",
       "array([[2985, 3003,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [ 583, 3192, 1359,  228,  593, 2602,  335, 2355, 3381,    0],\n",
       "       [1190, 2802, 3439,  612, 1109, 3175, 2710, 2963, 3429,    0],\n",
       "       [3634,  453, 1220, 1179, 1255, 2993, 1023, 3585, 1284,    0],\n",
       "       [1405, 2388, 1483, 3450, 2921, 3038, 2920,  776,  163,    0]])>,\n",
       " 'policy_info': (),\n",
       " 'reward': <tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[3., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [3., 4., 2., 5., 5., 4., 2., 2., 2., 0.],\n",
       "       [5., 2., 4., 4., 3., 3., 1., 3., 1., 0.],\n",
       "       [5., 5., 5., 4., 5., 5., 4., 4., 5., 0.],\n",
       "       [4., 4., 4., 4., 4., 4., 4., 4., 4., 0.]], dtype=float32)>,\n",
       " 'step_type': <tf.Tensor: shape=(5, 10), dtype=int32, numpy=\n",
       "array([[0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4192461-b9a8-4f47-8788-bbab2388414b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Policy \n",
    "\n",
    "> The main job of the Policy is to map observations from the user to actions. The action is a set of K recommended items. The policy is created by the Agent and contains a reference to the Network\n",
    "\n",
    "```\n",
    "Policy.__init__(time_step_spec, action_spec, network, ...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1081163d-bba9-4f5d-834a-6c5f17fe3afe",
   "metadata": {},
   "source": [
    "**computing actions**\n",
    "* to compute actions, the policy uses the network to compute the user's latent state (`s_t`)\n",
    "* this state is multiplied by a trainable action embedding (`v_a`) for each action\n",
    "* then apply softmax to compute action probabilities\n",
    "\n",
    "so steps in code, roughly follow:\n",
    "1. `s_{t+1}` <-- network(time_step.observation, state)\n",
    "2. scann index: retreive top M (100s-1000s) actions closest to `s{t+1}`\n",
    "3. compute inner produdct `q_a = v_a * s_{t+1}` for each action embedding `v_a`\n",
    "4. balance explore vs exploit:\n",
    "> * select greedy actions: `A_t` = {Kâ€™ actions with highest `q_a`}\n",
    "> * exploratory actions: actions sampled from softmax(`q_a/T`), where `T` is Boltzmann \n",
    "5. Return action = `A_t` (set of K Actions), state = `s_{t+1}`, info = ()\n",
    "\n",
    "**recomputing states**\n",
    "* Everytime the network weights are updated, the latent state `s_t` should be recomputed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fe5fb9-ad91-43a3-b34d-6649b8346305",
   "metadata": {},
   "source": [
    "# Train agent\n",
    "\n",
    "> Train Top K Off Policy Reinforce from logged data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78d83e8-5b13-4eec-adfa-732d3d0b2a0d",
   "metadata": {},
   "source": [
    "**get action vocab file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60ef7298-9d4b-4226-90fb-eb0f7493621d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab...\n",
      "Downloaded vocab from: gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/vocabs/vocab_dict.pkl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{EXAMPLE_GEN_GCS_PATH}/vocabs/{VOCAB_FILENAME}'\n",
    "print(f\"Downloading vocab...\")\n",
    "\n",
    "os.system(f'gsutil -q cp {EXISTING_VOCAB_FILE} .')\n",
    "print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "vocab_dict = pkl.load(filehandler)\n",
    "filehandler.close()\n",
    "\n",
    "# for key in vocab_dict.keys():\n",
    "#     pprint(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97f18b38-cef0-44e9-a963-80e4c1b4069f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vocab_dict['movie_id'][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babf9513-7181-472d-ad29-6a7ec249df90",
   "metadata": {},
   "source": [
    "## Vertex Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5178601f-8ab6-4b1c-b004-cfb34d45692b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VERSION=\"v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a03bbeae-cd49-4a98-ac1e-270f3bee25e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : reinforce-recsys-v1\n",
      "RUN_NAME          : run-20241126-102438\n",
      "\n",
      "CHECKPT_DIR       : gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-recsys-v1/chkpoint\n",
      "BASE_OUTPUT_DIR   : gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-recsys-v1/run-20241126-102438\n",
      "LOG_DIR           : gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-recsys-v1/run-20241126-102438/logs\n",
      "ROOT_DIR          : gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-recsys-v1/run-20241126-102438/root\n",
      "ARTIFACTS_DIR     : gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-recsys-v1/run-20241126-102438/artifacts\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME   = f'reinforce-recsys-{VERSION}'\n",
    "\n",
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "CHECKPT_DIR       = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/chkpoint\"\n",
    "BASE_OUTPUT_DIR   = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}\"\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"CHECKPT_DIR       : {CHECKPT_DIR}\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a53827-1f90-4a31-9435-b199a4d61c76",
   "metadata": {},
   "source": [
    "### action vocab lookup\n",
    "\n",
    "1. Need to convert action feature (movie IDs) to numeric (i.e., string --> int64)\n",
    "2. update `vocab_dict`\n",
    "3. create *lookup layers* for Agent; essentially convert real world actions to integer action indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b2c9b14-ea5b-4f78-a5fb-b1661c8d8e9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab_dict['movie_id']\n",
    "vocab_dict_decoded = [z.decode(\"utf-8\") for z in vocab_dict['movie_id']]\n",
    "vocab_dict_decoded.remove(\"UNK\")\n",
    "\n",
    "vocab_dict_decoded = tf.strings.to_number(\n",
    "    vocab_dict_decoded,\n",
    "    out_type=tf.dtypes.int64,\n",
    "    name=None\n",
    ")\n",
    "vocab_dict_decoded = vocab_dict_decoded.numpy()\n",
    "vocab_dict_decoded[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "39f1e1cd-2444-467f-b002-760700cc3a9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update vocab_dict\n",
    "vocab_dict['movie_id_int'] = vocab_dict_decoded\n",
    "vocab_dict['movie_id_int'][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5a9707-c9b3-4bf0-9ec5-f5493c4caf89",
   "metadata": {},
   "source": [
    "**lookup layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "23257fce-8d57-4cf5-bcfb-94ea623c8e30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "action_lookup_layer = tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=vocab_dict['movie_id_int'], \n",
    "    mask_value=None\n",
    ")\n",
    "\n",
    "inverse_action_lookup_layer = tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=action_lookup_layer.get_vocabulary(), \n",
    "    mask_value=None,\n",
    "    invert=True\n",
    ")\n",
    "\n",
    "action_vocab_size = action_lookup_layer.vocab_size() # 3885"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "40670e77-cba1-41ec-b6df-8347a4c8586a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3884"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # if observations are just past actions:\n",
    "\n",
    "observation_lookup_layer = tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=vocab_dict['movie_id_int'], \n",
    "    mask_value=None\n",
    ")\n",
    "\n",
    "obs_vocab_size = observation_lookup_layer.vocab_size()\n",
    "obs_vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee28feda-f3b7-478f-a652-56eac45061c9",
   "metadata": {},
   "source": [
    "### tensor specs\n",
    "\n",
    "*Note that the minimum in the spec is 0 and the maximum is bound inclusive* \n",
    "\n",
    "> setting maximum = vocab_size - 1 accounts for all actions in the vocabulary, including OOV items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "36bf62a2-1017-4512-8b28-964f8088366b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_step = tf.compat.v1.train.get_or_create_global_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e5a3221b-1394-4e12-a4d0-4d4e952275da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "observation_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=[],\n",
    "    dtype=tf.int64, # tf.string | tf.int64,\n",
    "    minimum=0,\n",
    "    maximum=action_vocab_size - 1,\n",
    "    name='observation'\n",
    ")\n",
    "time_step_spec = ts.time_step_spec(observation_spec=observation_spec)\n",
    "\n",
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=[],\n",
    "    dtype=tf.int64, # tf.string | tf.int64,\n",
    "    minimum=0,\n",
    "    maximum=action_vocab_size - 1,\n",
    "    name='action'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1d0c50-2688-4921-b1bf-866de1b03465",
   "metadata": {},
   "source": [
    "## Network\n",
    "\n",
    "> maps observations to actions (see section 4.1 of the [paper](https://arxiv.org/pdf/1812.02353.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fa420d-bb8b-4b70-84ee-0737fa1a47a7",
   "metadata": {},
   "source": [
    "The input to the network is an observation, which includes an embedding of the item selected by the user from the last set of recommendations\n",
    "* TODO: add context features to input\n",
    "\n",
    "To compute actions, the policy uses the network to compute the latent state `s_t`.\n",
    "* The state `s_t` is multiplied by a trainable action embedding `v_a` for each action, followed by a softmax to compute the action probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e3b4a096-cad0-4a57-aefd-f86a6debb922",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int64, name='observation', minimum=array(0), maximum=array(3883))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embedding_size=100\n",
    "input_fc_layer_params=(100, 100)\n",
    "lstm_size=(25,)\n",
    "output_fc_layer_params=(10,)\n",
    "\n",
    "state_embedding_network = rfa_utils.create_state_embedding_network(\n",
    "    observation_lookup_layer=observation_lookup_layer,\n",
    "    input_embedding_size=input_embedding_size,\n",
    "    input_fc_layer_units=input_fc_layer_params,\n",
    "    lstm_size=lstm_size,\n",
    "    output_fc_layer_units=output_fc_layer_params\n",
    ")\n",
    "\n",
    "time_step_spec.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c0b3e5c7-346c-49f3-bedb-77586028f178",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029ec252-c7e0-42f0-b6a1-6f11221424cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create action embedding index (optional)\n",
    "\n",
    "> action_embeddings: A `[num_actions, embedding_size]` float tensor of action embeddings.\n",
    "\n",
    "**Note** - the scann index is built by the Agent/Policy. This section just shows what is happening under the hood "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c83cb25-7d5e-4947-90e0-05f99a35e12e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_OOV_BUCKETS        = 1\n",
    "GLOBAL_EMBEDDING_SIZE  = 12\n",
    "MV_EMBEDDING_SIZE      = 16\n",
    "\n",
    "# test emb models\n",
    "for i in range(1):\n",
    "    \n",
    "    iterator = iter(train_seq_dataset.batch(1))\n",
    "    data, _ = next(iterator)\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c48a03-5f19-4e1a-ae1e-bc450af54d8a",
   "metadata": {},
   "source": [
    "We have an embedding model we can use for items (`_get_per_arm_features`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28a00d60-0591-4e95-a753-d99e242b6df4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.networks.encoding_network.EmbeddingModel at 0x7f915039b8e0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs = emb_features.EmbeddingModel(\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    "    max_genre_length = data_config.MAX_GENRE_LENGTH\n",
    ")\n",
    "\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a96e7097-9ee3-4a8d-9d19-0876e822f50b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER_ARM_DIM: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 64), dtype=float32, numpy=\n",
       "array([[ 0.00522338, -0.0492513 , -0.04217166, -0.02676969,  0.00532337,\n",
       "         0.01616928, -0.04328166, -0.02269555, -0.04540516,  0.00852679,\n",
       "         0.03075549,  0.04461614,  0.04575862,  0.03543853, -0.01772305,\n",
       "        -0.03266831, -0.01495897,  0.00659831,  0.01986279, -0.02117376,\n",
       "        -0.02736138,  0.01802956, -0.04142103, -0.01418371,  0.03431284,\n",
       "         0.02025948,  0.01882055,  0.01983524, -0.00092457,  0.02816413,\n",
       "         0.02255264,  0.00341722, -0.04963842,  0.01322391, -0.02595209,\n",
       "         0.03883019, -0.04856459,  0.04120443, -0.01700947,  0.02865665,\n",
       "         0.01443274, -0.04156702, -0.00135241, -0.02927754,  0.00493876,\n",
       "         0.03719561,  0.01297845, -0.01525987, -0.02714867, -0.21839464,\n",
       "        -0.159814  ,  0.22727305, -0.20244312, -0.17102785,  0.19473268,\n",
       "        -0.21610314,  0.18426383,  0.16344523,  0.24170601,  0.18839969,\n",
       "         0.1676284 ,  0.21472023,  0.16254401,  0.05299693]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arms = embs._get_per_arm_features(data)\n",
    "\n",
    "PER_ARM_DIM = test_arms.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"PER_ARM_DIM: {PER_ARM_DIM}\")\n",
    "\n",
    "test_arms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a51f3520-ca22-471d-b749-67e95326960c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# total_movie_count = len(list(train_seq_dataset))\n",
    "# total_movie_count # 335532"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5cdc8c94-45eb-4030-b8e5-09169f4116a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/action-embeddings/action_embs_20240704-141459.json...\n",
      "/ [1 files][  2.7 MiB/  2.7 MiB]                                                \n",
      "Operation completed over 1 objects/2.7 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "# !gsutil cp gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/action-embeddings/action_embs_20240704-141459.json ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8b1b96-7345-418c-ab03-4d57125b1a82",
   "metadata": {
    "tags": []
   },
   "source": [
    "### write index file\n",
    "\n",
    "TODO: get all movie candidates into single dataset, similar to below logic\n",
    "\n",
    "```\n",
    "input_ids = tf.data.Dataset.from_tensor_slices([d['input_ids'] for d in dataset])\n",
    "input_masks = tf.data.Dataset.from_tensor_slices([d['input_mask'] for d in dataset])\n",
    "segment_ids = tf.data.Dataset.from_tensor_slices([d['segment_ids'] for d in dataset])\n",
    "labels = tf.data.Dataset.from_tensor_slices([d['labels'] for d in dataset])\n",
    "\n",
    "ds = tf.data.Dataset.zip((input_ids, input_masks, segment_ids, labels))\n",
    "ds = ds.map(lambda x, y, z, l: {\"input_ids\": x, \"input_masks\": y,\n",
    "                                \"segment_ids\": z, \"labels\": l}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "81ab8f53-4f21-4cd2-b7dc-9914b19b9cd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 0; emb_valid: 1; movie_id_set: 1\n",
      "n: 500; emb_valid: 417; movie_id_set: 417\n",
      "n: 750; emb_valid: 572; movie_id_set: 572\n",
      "n: 2250; emb_valid: 1201; movie_id_set: 1201\n",
      "n: 3500; emb_valid: 1531; movie_id_set: 1531\n",
      "n: 5250; emb_valid: 1823; movie_id_set: 1823\n",
      "n: 8500; emb_valid: 2143; movie_id_set: 2143\n",
      "n: 11500; emb_valid: 2340; movie_id_set: 2340\n",
      "n: 19250; emb_valid: 2658; movie_id_set: 2658\n",
      "n: 20750; emb_valid: 2697; movie_id_set: 2697\n",
      "n: 73500; emb_valid: 3230; movie_id_set: 3230\n",
      "elapsed_time           : 3\n",
      "counter                : 335532\n",
      "Length of movie_id_set : 3550\n",
      "Length of emb_valid    : 3550\n"
     ]
    }
   ],
   "source": [
    "movie_id_set = []\n",
    "emb_valid = []\n",
    "\n",
    "LOG_INTERVAL=250\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "counter = 0\n",
    "for ex_data, _ in train_seq_dataset.batch(1):\n",
    "\n",
    "    ids_ = ex_data['target_movie_id'].numpy()[0] # movie_id_int\n",
    "    if ids_ not in movie_id_set:\n",
    "        movie_id_set.append(ids_)\n",
    "        action_emb = embs._get_per_arm_features(ex_data)\n",
    "        emb_valid.append(action_emb)\n",
    "        \n",
    "        if counter % LOG_INTERVAL == 0:\n",
    "            print(f\"n: {counter}; emb_valid: {len(emb_valid)}; movie_id_set: {len(movie_id_set)}\")\n",
    "        \n",
    "    counter+=1\n",
    "    \n",
    "    # if counter == 100:\n",
    "    #     break\n",
    "\n",
    "    \n",
    "end_time = time.time()\n",
    "elapsed_time = int((end_time - start_time) / 60)\n",
    "\n",
    "print(f\"elapsed_time           : {elapsed_time}\")\n",
    "print(f\"counter                : {counter}\")\n",
    "print(f\"Length of movie_id_set : {len(movie_id_set)}\")\n",
    "print(f\"Length of emb_valid    : {len(emb_valid)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "56221139-a770-4f7d-9e55-9cdca69db3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1775', '2789', '2249', '3104', '142']"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_id_set[0:5]\n",
    "\n",
    "# TODO: shouldn't need these anymore: confirm\n",
    "# movie_id_set_decoded = [z.decode(\"utf-8\") for z in movie_id_set]\n",
    "# movie_id_set_decoded[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "dc95b015-5b4f-42f5-9fd5-35312d64c8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00417863, -0.04035826,  0.03949881,  0.02248106,  0.03972029,\n",
       "       -0.03954465, -0.0078277 , -0.00666126,  0.0240129 ,  0.03367153,\n",
       "       -0.01583817,  0.03204237,  0.04059358, -0.03843267,  0.00045175,\n",
       "        0.00292462, -0.04330502, -0.00924589,  0.04248578,  0.03299932,\n",
       "        0.00611916, -0.03558064, -0.04670314, -0.0222977 , -0.04777682,\n",
       "       -0.03742123, -0.03174067, -0.01043591,  0.04092886, -0.02244899,\n",
       "       -0.03317848, -0.03101618, -0.03086665, -0.03440733, -0.04183024,\n",
       "        0.01905538,  0.02743418,  0.03782295,  0.00370765,  0.04130132,\n",
       "        0.00137607,  0.02548063, -0.02434435, -0.02880038,  0.01019372,\n",
       "       -0.01553645, -0.04996688, -0.0459705 ,  0.24497205, -0.22872275,\n",
       "       -0.12215847, -0.17597657, -0.21268445,  0.10867788, -0.1677419 ,\n",
       "        0.23022158, -0.0225311 ,  0.2358569 ,  0.1154706 ,  0.10946961,\n",
       "        0.20655268, -0.19170517,  0.0794156 ,  0.21880643], dtype=float32)"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# emb_valid[0].numpy()\n",
    "\n",
    "cleaned_emb_valid = [z.numpy()[0] for z in emb_valid]\n",
    "cleaned_emb_valid[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83cad03-0eca-49b2-aba0-f2a301a2e0a7",
   "metadata": {},
   "source": [
    "write index file locally, and save to (remote) cloud storage location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "04d23b3e-9a81-485e-b3c2-ad1bc476f686",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 'local'\n",
    "TIMESTAMP = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "embeddings_index_filename = f'action_embs_{TIMESTAMP}.json'\n",
    "\n",
    "with open(f'{embeddings_index_filename}', 'w') as f:\n",
    "    for prod, emb in zip(movie_id_set_decoded, cleaned_emb_valid):\n",
    "        f.write('{\"id\":\"' + str(prod) + '\",')\n",
    "        f.write('\"embedding\":[' + \",\".join(str(x) for x in list(emb)) + \"]}\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "46146d3a-6d3e-4f49-b39d-ba4771067454",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_GCS_URI = f'{DATA_PATH}/movielens/m1m/action-embeddings'\n",
    "\n",
    "DESTINATION_BLOB_NAME = embeddings_index_filename\n",
    "SOURCE_FILE_NAME = embeddings_index_filename\n",
    "\n",
    "print(f\"INDEX_GCS_URI         : {INDEX_GCS_URI}\")\n",
    "print(f\"DESTINATION_BLOB_NAME : {DESTINATION_BLOB_NAME}\")\n",
    "print(f\"SOURCE_FILE_NAME      : {SOURCE_FILE_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "33d044d7-d577-4cf7-b6f8-9d7733f90829",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://rec-bandits-v2-hybrid-vertex-bucket/data'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "feb0cc3c-9232-42c8-bf5f-ec86bec56efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from google.cloud.storage.bucket import Bucket\n",
    "from google.cloud.storage.blob import Blob\n",
    "\n",
    "blob = Blob.from_string(os.path.join(INDEX_GCS_URI, DESTINATION_BLOB_NAME))\n",
    "blob.bucket._client = storage_client\n",
    "blob.upload_from_filename(SOURCE_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44fb2f9-a099-4d66-944f-de7ad5e280c1",
   "metadata": {},
   "source": [
    "Load json file to validate formatting etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6fd25145-fddb-41db-adcf-7f0dd72fd3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3550"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "action_emb_lines = []\n",
    "\n",
    "embeddings_index_filename = 'action_embs_20240704-141459.json'\n",
    "\n",
    "with open(embeddings_index_filename, 'r') as f:\n",
    "    for line in f:\n",
    "        action_emb_lines.append(json.loads(line))\n",
    "    \n",
    "# action_emb_lines[0]\n",
    "# \"\"\"\n",
    "# {'id': '1775',\n",
    "#  'embedding': [0.004178632,\n",
    "#   -0.040358257,\n",
    "#   0.03949881,\n",
    "#   0.022481058,\n",
    "# \"\"\"\n",
    "\n",
    "len(action_emb_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d756c5d7-4598-421e-8735-c17b2a76c084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 0.00417863 -0.04035826  0.03949881  0.02248106  0.03972029 -0.03954465\n",
      " -0.0078277  -0.00666126  0.0240129   0.03367153 -0.01583817  0.03204237\n",
      "  0.04059358 -0.03843267  0.00045175  0.00292462 -0.04330502 -0.00924589\n",
      "  0.04248578  0.03299932  0.00611916 -0.03558064 -0.04670314 -0.0222977\n",
      " -0.04777682 -0.03742123 -0.03174067 -0.01043591  0.04092886 -0.02244899\n",
      " -0.03317848 -0.03101618 -0.03086665 -0.03440733 -0.04183024  0.01905538\n",
      "  0.02743418  0.03782295  0.00370765  0.04130132  0.00137607  0.02548063\n",
      " -0.02434435 -0.02880038  0.01019372 -0.01553645 -0.04996688 -0.0459705\n",
      "  0.24497205 -0.22872275 -0.12215847 -0.17597657 -0.21268445  0.10867788\n",
      " -0.1677419   0.23022158 -0.0225311   0.2358569   0.1154706   0.10946961\n",
      "  0.20655268 -0.19170517  0.0794156   0.21880643], shape=(64,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# action embeddings\n",
    "action_embs_v1 = tf.data.Dataset.from_tensor_slices([d['embedding'] for d in action_emb_lines])\n",
    "\n",
    "for test_embed in action_embs_v1.take(1):\n",
    "    print(test_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6a8ac015-912a-43f1-a4cb-bea6c800e716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1775, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# action IDs\n",
    "action_id_strs = [d['id'] for d in action_emb_lines]\n",
    "action_ids_ints = tf.strings.to_number(\n",
    "    action_id_strs,\n",
    "    out_type=tf.dtypes.int64,\n",
    "    name=None\n",
    ")\n",
    "action_ids_v1 = tf.data.Dataset.from_tensor_slices([d for d in action_ids_ints])\n",
    "\n",
    "for x in action_ids_v1.take(1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee59e06f-3b66-4ada-87fc-f5af3f709958",
   "metadata": {
    "tags": []
   },
   "source": [
    "### build scann index\n",
    "\n",
    "see ScaNN references:\n",
    "* [documentation](https://www.tensorflow.org/recommenders/api_docs/python/tfrs/layers/factorized_top_k/ScaNN#index_from_dataset)\n",
    "* used in [this tutorial](https://www.tensorflow.org/recommenders/examples/efficient_serving#tuning_scann)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741a1315-d141-4eeb-819f-0b3e6d00e98f",
   "metadata": {},
   "source": [
    "**Understanding ScaNN parameters**\n",
    "\n",
    "Consider:\n",
    "\n",
    "* `num_leaves=100` \n",
    "* `num_leaves_to_search=10` \n",
    "\n",
    "> This means our ScaNN database is partitioned into **100 disjoint subsets**, and the **10 most promising of these partitions** is scored with AH. This means 10/100=10% of the dataset is being searched with AH\n",
    "\n",
    "Now consider:\n",
    "\n",
    "* `num_leaves=1000` \n",
    "* `num_leaves_to_search=100` \n",
    "\n",
    "> still searching 10% of the database with AH. However, in comparison to the previous setting, the 10% we would search will contain higher-quality candidates, because a **higher `num_leaves` allows us to make finer-grained decisions about what parts of the dataset are worth searching**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb71501b-996d-41bc-a55d-52ce402682dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "55228fed-fbe5-483a-9ff3-1aaa1c5e2482",
   "metadata": {},
   "outputs": [],
   "source": [
    "scann = tfrs.layers.factorized_top_k.ScaNN(\n",
    "    k=10,\n",
    "    num_leaves=1000,\n",
    "    num_leaves_to_search=100,\n",
    "    num_reordering_candidates=500,\n",
    ")\n",
    "# scann"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69117309-fd3f-46ef-89ae-263768338e2b",
   "metadata": {},
   "source": [
    "the `candidates` arg in `index_from_dataset`:\n",
    "\n",
    "> Dataset of candidate embeddings or `(candidate identifier, candidate embedding)` pairs. \n",
    "\n",
    "* If the dataset returns tuples, the identifiers will be used as identifiers of top candidates returned when performing searches. \n",
    "* If not given, indices into the candidates dataset will be given instead.\n",
    "\n",
    "Also, `candidates` and `identifiers` have to have the same batch dimension\n",
    "> use `.batch()` when zipping dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "62d4b753-b246-4327-9ebc-25fb30b2c2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.ScaNN at 0x7fbaa06e22f0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scann.index_from_dataset(\n",
    "    candidates=ds_zipped_v2 = tf.data.Dataset.zip(\n",
    "        action_ids_v1.batch(1000), \n",
    "        action_embs_v1.batch(1000)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b63d7c58-cc93-470e-84b1-b5338e847fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00417863, -0.04035826,  0.03949881,  0.02248106,  0.03972029,\n",
       "       -0.03954465, -0.0078277 , -0.00666126,  0.0240129 ,  0.03367153,\n",
       "       -0.01583817,  0.03204237,  0.04059358, -0.03843267,  0.00045175,\n",
       "        0.00292462, -0.04330502, -0.00924589,  0.04248578,  0.03299932,\n",
       "        0.00611916, -0.03558064, -0.04670314, -0.0222977 , -0.04777682,\n",
       "       -0.03742123, -0.03174067, -0.01043591,  0.04092886, -0.02244899,\n",
       "       -0.03317848, -0.03101618, -0.03086665, -0.03440733, -0.04183024,\n",
       "        0.01905538,  0.02743418,  0.03782295,  0.00370765,  0.04130132,\n",
       "        0.00137607,  0.02548063, -0.02434435, -0.02880038,  0.01019372,\n",
       "       -0.01553645, -0.04996688, -0.0459705 ,  0.24497205, -0.22872275,\n",
       "       -0.12215847, -0.17597657, -0.21268445,  0.10867788, -0.1677419 ,\n",
       "        0.23022158, -0.0225311 ,  0.2358569 ,  0.1154706 ,  0.10946961,\n",
       "        0.20655268, -0.19170517,  0.0794156 ,  0.21880643], dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_embed.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0961dc1b-78fc-4dee-87a1-655d113f8f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([  62, 3567, 3817,  740,  464, 3583, 2516, 1286,  783,  359])>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores, action_anns = scann(test_embed.numpy())\n",
    "action_anns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa2b179-04df-4fe4-bdc4-7b3e8efde69b",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f584af-09c1-4e21-a13e-da12de2231eb",
   "metadata": {},
   "source": [
    "**TODO:** implement `model_type`\n",
    "\n",
    "```python\n",
    "model_type = 'reinforce'\n",
    "\n",
    "if model_type == 'rnn':\n",
    "  off_policy_correction_exponent = None\n",
    "  use_supervised_loss_for_main_policy = True\n",
    "elif model_type == 'reinforce':\n",
    "  off_policy_correction_exponent = None\n",
    "  use_supervised_loss_for_main_policy = False\n",
    "elif model_type == 'topk':\n",
    "  off_policy_correction_exponent = 16\n",
    "  use_supervised_loss_for_main_policy = False\n",
    "else:\n",
    "  raise ValueError('Model type not supported: ' + model_type)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d14d1065-25bf-43e2-809e-6fce77cc162b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "from src.agents import topk_reinforce_agent as topk_reinforce_agent\n",
    "\n",
    "from src.trainer import offline_evaluation as offline_evaluation\n",
    "from src.trainer import offline_metrics as offline_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa199af-2846-45af-a239-6633c951d025",
   "metadata": {},
   "source": [
    "### agent config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a1edde-7293-4d5c-a8a5-769730a94ce0",
   "metadata": {},
   "source": [
    "`policy_num_actions` \n",
    "* k actions recommended by policy\n",
    "\n",
    "`num_greedy_actions`\n",
    "* number of actions with highest Q value\n",
    "\n",
    "`sampled_softmax_num_negatives`\n",
    "* Number of `negative` actions used to compute the sampled_softmax loss. \n",
    "* if None, regular softmax will be used instead of sampled_softmax.\n",
    "\n",
    "`scann_num_candidate_actions`\n",
    "* Number of actions to retrieve using SCANN in the policy. \n",
    "* A softmax is computed on this reduced set instead of the whole vocabulary to improve efficiency\n",
    "* if None, all actions used to compute the softmax\n",
    "\n",
    "`use_supervised_loss_for_main_policy`\n",
    "* If True, trains main policy using supervised loss equal to the negative log probability of actions, instead of 'Off Policy REINFORCE loss'\n",
    "* useful for debugging, e.g. can model mimick the dataset behavior?\n",
    "\n",
    "`off_policy_correction_exponent`\n",
    "* The K used in the off policy correction to compute alpha (Section 4.3 of paper)\n",
    "* if `None`, no off-policy correction applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5de0fe6b-0596-4299-be11-b6272128fabc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# k actions recommended by policy\n",
    "policy_num_actions=5\n",
    "\n",
    "# number of actions with highest Q value\n",
    "num_greedy_actions=4\n",
    "\n",
    "scann_num_candidate_actions=None\n",
    "sampled_softmax_num_negatives=None\n",
    "use_supervised_loss_for_main_policy=False\n",
    "off_policy_correction_exponent=None # None | 16\n",
    "\n",
    "GAMMA=0.5 # 0.9 | 0.5\n",
    "SUMMARIZE_GRADS_AND_VARS=True\n",
    "DEBUG_SUMMARIES=False # TODO: error with summary stats\n",
    "\n",
    "distribution_strategy = strategy_utils.get_strategy(\n",
    "    tpu=False, use_gpu=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "883414de-0bb1-4b4c-b91a-161e18c7f836",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step: 0\n"
     ]
    }
   ],
   "source": [
    "# TODO: create agents variables under strategy.scope()\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "tf_agent = topk_reinforce_agent.TopKOffPolicyReinforceAgent(\n",
    "    time_step_spec=time_step_spec,\n",
    "    action_spec=action_spec,\n",
    "    state_embedding_network=state_embedding_network,\n",
    "    optimizer=optimizer,\n",
    "    off_policy_correction_exponent=off_policy_correction_exponent,\n",
    "    action_lookup_layer=action_lookup_layer,                  # action_lookup_layer | None\n",
    "    inverse_action_lookup_layer=inverse_action_lookup_layer,  # inverse_action_lookup_layer | None\n",
    "    policy_num_actions=policy_num_actions,\n",
    "    use_supervised_loss_for_main_policy=use_supervised_loss_for_main_policy,\n",
    "    num_candidate_actions=scann_num_candidate_actions,\n",
    "    num_greedy_actions=policy_num_actions,\n",
    "    sampled_softmax_num_negatives=sampled_softmax_num_negatives,\n",
    "    train_step_counter=global_step,\n",
    "    gamma=GAMMA,\n",
    "    summarize_grads_and_vars=SUMMARIZE_GRADS_AND_VARS,\n",
    "    debug_summaries=DEBUG_SUMMARIES,\n",
    "    name='TopKOffPolicyReinforceAgent'\n",
    ")\n",
    "\n",
    "tf_agent.initialize()\n",
    "\n",
    "print(f\"global step: {global_step.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a377d673-b8f3-404e-8e93-0ac0173f0923",
   "metadata": {},
   "source": [
    "**summary writers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5531d5b7-be53-4953-9bec-e7ea51c9137c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_log_dir : gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-recsys-v1/run-20241126-102438/logs/train\n",
      "eval_log_dir  : gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-recsys-v1/run-20241126-102438/logs/eval\n"
     ]
    }
   ],
   "source": [
    "log_dir = os.path.expanduser(LOG_DIR)\n",
    "train_log_dir = os.path.join(log_dir, 'train')\n",
    "eval_log_dir = os.path.join(log_dir, 'eval')\n",
    "\n",
    "# summary writers\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    train_log_dir, flush_millis=10 * 1000\n",
    ")\n",
    "train_summary_writer.set_as_default()\n",
    "\n",
    "eval_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    eval_log_dir, flush_millis=10 * 1000\n",
    ")\n",
    "\n",
    "print(f\"train_log_dir : {train_log_dir}\")\n",
    "print(f\"eval_log_dir  : {eval_log_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4eeb6d-806a-422b-a023-a2f37560ccce",
   "metadata": {},
   "source": [
    "## Train and eval datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffd2fdf-be2b-429f-8a2e-34428ad0b040",
   "metadata": {
    "tags": []
   },
   "source": [
    "```\n",
    "if use_tf_functions:\n",
    "    \"\"\"\n",
    "    TODO: Currently wrapping evaluate in tf.function does not\n",
    "      work because creating a new scann index in\n",
    "      tf_agent.post_process_policy() seems to create new variables.\n",
    "      \n",
    "    Moving the index() into the tf.function doesn't seem to work either. \n",
    "      Currently this is not a huge blocker since eval only takes 5 seconds\n",
    "    \"\"\"\n",
    "    tf_agent.train = common.function(tf_agent.train)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c89acc2a-13de-4d6d-a7c3-2b07279ed1eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_SPLIT = \"train\"\n",
    "VAL_SPLIT = \"val\"\n",
    "\n",
    "train_files = []\n",
    "val_files = []\n",
    "\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{EXAMPLE_GEN_GCS_PATH}/{TRAIN_SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{EXAMPLE_GEN_GCS_PATH}/{VAL_SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        val_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "# train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3e9ad954-d54f-4461-a881-6d9d8d4f5403",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_tf_functions= True\n",
    "sequence_length=10\n",
    "train_batch_size=128  # 64 | 5 | 128\n",
    "eval_batch_size=128   # 64 | 5 | 128\n",
    "num_eval_batches=50 # 10 | 1200\n",
    "\n",
    "tf_agent.train = common.function(tf_agent.train)\n",
    "# ====================================================\n",
    "# create datasets\n",
    "# ====================================================\n",
    "process_example_fn = functools.partial(\n",
    "    example_proto_to_trajectory,\n",
    "    sequence_length=sequence_length\n",
    ")\n",
    "\n",
    "train_dataset = create_tfrecord_ds(\n",
    "    tf.io.gfile.glob(train_files),\n",
    "    num_shards=len(train_files),\n",
    "    process_example_fn=process_example_fn,\n",
    "    batch_size=train_batch_size\n",
    ")\n",
    "train_dataset_iterator = iter(train_dataset)\n",
    "\n",
    "eval_dataset = create_tfrecord_ds(\n",
    "    tf.io.gfile.glob(val_files),\n",
    "    process_example_fn=process_example_fn,\n",
    "    batch_size=eval_batch_size,\n",
    "    num_shards=len(val_files),\n",
    "    repeat=False,\n",
    "    drop_remainder=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94223ac4-65c1-47e6-805e-b47a7be9feb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(f\"train data size: {len(list(train_dataset))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9d063465-42a3-4365-9552-056a724e5f72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval data size: 50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if num_eval_batches is not None:\n",
    "    eval_dataset = eval_dataset.take(num_eval_batches)\n",
    "    \n",
    "print(f\"eval data size: {len(list(eval_dataset))}\\n\")\n",
    "\n",
    "# for x in eval_dataset.take(1):\n",
    "#     print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90893c14-d2c4-4ed2-bbe9-07d225638893",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d5d48e84-2162-4b6f-87ea-4caa895c798e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluate = offline_evaluation.evaluate\n",
    "# evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "65b6c35c-9887-433c-b3ca-0d5140af0eea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<src.agents.offline_metrics.AccuracyAtK at 0x7fb3c0465ae0>,\n",
       " <src.agents.offline_metrics.AveragePerClassAccuracyAtK at 0x7faff6c3ec80>,\n",
       " <src.agents.offline_metrics.WeightedReturns at 0x7fafbee9f580>]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offline_eval_metrics = [\n",
    "    offline_metrics.AccuracyAtK(),\n",
    "    offline_metrics.AveragePerClassAccuracyAtK(\n",
    "        action_vocab_size, action_lookup=action_lookup_layer\n",
    "    ),\n",
    "    offline_metrics.WeightedReturns(\n",
    "        gamma=1.,\n",
    "        action_lookup=action_lookup_layer,\n",
    "        name='WeightedReturns_gamma_1'\n",
    "    ),\n",
    "    # offline_metrics.LastActionAccuracyAtK(),\n",
    "]\n",
    "\n",
    "offline_eval_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ede12a9-7342-48d2-aa28-9d2875fb4ad5",
   "metadata": {},
   "source": [
    "## Checkpointer and Policy Saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7d96b21b-fd04-4e25-bdfd-73277c875e78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting checkpoint_manager: gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-rec-topk-v7/chkpoint\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# get checkpoint manager\n",
    "# ====================================================\n",
    "print(f\"setting checkpoint_manager: {CHECKPT_DIR}\\n\")\n",
    "\n",
    "train_checkpointer = train_utils.restore_and_get_checkpoint_manager(\n",
    "    root_dir=CHECKPT_DIR, \n",
    "    agent=tf_agent, \n",
    "    metrics=offline_eval_metrics, \n",
    "    step_metric=global_step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7c07c6fc-fe10-4d2e-a091-f5b915a19d6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.utils.common.Checkpointer at 0x7fb37c0d96f0>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_checkpointer = common.Checkpointer(\n",
    "    ckpt_dir=os.path.join(CHECKPT_DIR, 'policy'),\n",
    "    policy=tf_agent.policy,\n",
    "    global_step=global_step\n",
    ")\n",
    "\n",
    "policy_checkpointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3bf88ab4-2b5b-4485-bfd7-e6118b77acba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ====================================================\n",
    "# # policy saver\n",
    "# # ====================================================\n",
    "# saver = policy_saver.PolicySaver(\n",
    "#     tf_agent.policy, \n",
    "#     train_step=global_step\n",
    "# )\n",
    "# saver.signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228bdbed-a927-4b65-a50c-a956b5e41bac",
   "metadata": {},
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9a102f-15d6-4133-95a3-3ad3301d7405",
   "metadata": {},
   "source": [
    "**tf_agent.train()**\n",
    "\n",
    "Args:\n",
    "* **experience**: A batch of experience data in the form of a `Trajectory`. \n",
    "  * The structure of `experience` must match that of `self.training_data_spec`. \n",
    "  * All tensors in `experience` must be shaped `[batch, time, ...]` where `time` must be equal to `self.train_step_length` if that property is not `None`.\n",
    "\n",
    "* **weights**: (optional).  A `Tensor`, either `0-D` or shaped `[batch]`, containing weights to be used when calculating the total train loss. \n",
    "  * Weights are typically multiplied elementwise against the per-batch loss, but the implementation is up to the Agent.\n",
    "\n",
    "[src](https://github.com/tensorflow/agents/blob/master/tf_agents/agents/tf_agent.py#L317C1-L326C51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "784111d1-9ab2-45db-9cce-9b5822b1e1af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_iterations   : 50000\n",
      "eval_interval    : 10000\n",
      "log_interval     : 5000\n",
      "summary_interval : 100\n",
      "\n",
      "train_checkpoint_interval : 25000\n",
      "policy_checkpoint_interval : 100000\n"
     ]
    }
   ],
   "source": [
    "num_iterations=50_000  # 10000\n",
    "\n",
    "eval_interval=int(num_iterations/5)      # 2500\n",
    "log_interval=int(num_iterations/10)      # 1000\n",
    "summary_interval=100 # int(num_iterations/400) # 100\n",
    "\n",
    "train_checkpoint_interval=int(num_iterations/2)\n",
    "policy_checkpoint_interval=int(num_iterations*2)\n",
    "\n",
    "# global_step\n",
    "# tf_agent.training_data_spec\n",
    "# tf_agent.train_step_counter\n",
    "# weights.shape\n",
    "\n",
    "tf_agent.train_step_counter.assign(0)\n",
    "\n",
    "print(f\"num_iterations   : {num_iterations}\")\n",
    "print(f\"eval_interval    : {eval_interval}\")\n",
    "print(f\"log_interval     : {log_interval}\")\n",
    "print(f\"summary_interval : {summary_interval}\\n\")\n",
    "print(f\"train_checkpoint_interval : {train_checkpoint_interval}\")\n",
    "print(f\"policy_checkpoint_interval : {policy_checkpoint_interval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b47d37d8-e518-49b0-858c-1cf7cc3b3dec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5000, loss = 42.23079299926758\n",
      "23.755 steps/sec\n",
      "step = 10000, loss = 42.04261016845703\n",
      "25.486 steps/sec\n",
      "\n",
      "Eval at step: 10000\n",
      "AccuracyAtK  =  0.10265625\n",
      "AveragePerClassAccuracyAtK  =  0.036268745\n",
      "WeightedReturns_gamma_1  =  -315.02667\n",
      "------\n",
      "\n",
      "step = 15000, loss = 38.76954650878906\n",
      "28.151 steps/sec\n",
      "step = 20000, loss = 39.575069427490234\n",
      "28.03 steps/sec\n",
      "\n",
      "Eval at step: 20000\n",
      "AccuracyAtK  =  0.11015625\n",
      "AveragePerClassAccuracyAtK  =  0.04892495\n",
      "WeightedReturns_gamma_1  =  -305.24207\n",
      "------\n",
      "\n",
      "step = 25000, loss = 36.554561614990234\n",
      "26.682 steps/sec\n",
      "step = 30000, loss = 36.5287971496582\n",
      "27.422 steps/sec\n",
      "\n",
      "Eval at step: 30000\n",
      "AccuracyAtK  =  0.100260414\n",
      "AveragePerClassAccuracyAtK  =  0.05062973\n",
      "WeightedReturns_gamma_1  =  -302.1055\n",
      "------\n",
      "\n",
      "step = 35000, loss = 38.5662841796875\n",
      "26.239 steps/sec\n",
      "step = 40000, loss = 35.8140983581543\n",
      "27.23 steps/sec\n",
      "\n",
      "Eval at step: 40000\n",
      "AccuracyAtK  =  0.11177083\n",
      "AveragePerClassAccuracyAtK  =  0.048993226\n",
      "WeightedReturns_gamma_1  =  -305.19025\n",
      "------\n",
      "\n",
      "step = 45000, loss = 40.41646194458008\n",
      "24.976 steps/sec\n",
      "step = 50000, loss = 38.634525299072266\n",
      "26.125 steps/sec\n",
      "\n",
      "Eval at step: 50000\n",
      "AccuracyAtK  =  0.09859375\n",
      "AveragePerClassAccuracyAtK  =  0.04744617\n",
      "WeightedReturns_gamma_1  =  -304.36295\n",
      "------\n",
      "\n",
      "total runtime : 50\n"
     ]
    }
   ],
   "source": [
    "list_o_loss=[]\n",
    "start_train = time.time()\n",
    "\n",
    "with tf.compat.v2.summary.record_if(\n",
    "    lambda: tf.math.equal(global_step % summary_interval, 0)\n",
    "):\n",
    "    timed_at_step = global_step.numpy()\n",
    "    time_acc = 0\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        traj_ex, weights_ex = next(train_dataset_iterator)\n",
    "        train_loss = tf_agent.train(\n",
    "            experience=traj_ex, weights=weights_ex\n",
    "        )\n",
    "        list_o_loss.append(train_loss.loss.numpy())\n",
    "        time_acc += time.time() - start_time\n",
    "        \n",
    "        # metric_utils.log_metrics(offline_eval_metrics)\n",
    "        train_utils._export_metrics_and_summaries(\n",
    "            step=i, \n",
    "            metrics=offline_eval_metrics\n",
    "        )\n",
    "\n",
    "        global_step_val = global_step.numpy()\n",
    "        if global_step_val % log_interval == 0:\n",
    "            print(f\"step = {global_step_val}, loss = {train_loss.loss}\")\n",
    "            steps_per_sec = (global_step_val - timed_at_step) / time_acc\n",
    "            \n",
    "            print(f\"{round(steps_per_sec,3)} steps/sec\")\n",
    "            tf.summary.scalar(\n",
    "                name='global_steps_per_sec', \n",
    "                data=steps_per_sec, \n",
    "                step=global_step\n",
    "            )\n",
    "            \n",
    "            timed_at_step = global_step_val\n",
    "            time_acc = 0\n",
    "\n",
    "        if global_step_val % train_checkpoint_interval == 0:\n",
    "            train_checkpointer.save(global_step_val)\n",
    "\n",
    "        # if global_step_val % policy_checkpoint_interval == 0:\n",
    "        #     tf_agent.post_process_policy()\n",
    "        #     policy_checkpointer.save(global_step_val)\n",
    "\n",
    "        if global_step_val % eval_interval == 0:\n",
    "            tf_agent.post_process_policy()\n",
    "            print(f\"\\nEval at step: {global_step_val}\")\n",
    "            evaluate(\n",
    "                tf_agent.policy,\n",
    "                eval_dataset,\n",
    "                offline_eval_metrics=offline_eval_metrics,\n",
    "                train_step=global_step,\n",
    "                summary_writer=eval_summary_writer,\n",
    "                summary_prefix='Metrics',\n",
    "            )\n",
    "            metric_utils.log_metrics(offline_eval_metrics)\n",
    "            for metric in offline_eval_metrics:\n",
    "                print(metric.name, ' = ', metric.result().numpy())\n",
    "            print(\"------\\n\")\n",
    "                \n",
    "runtime_mins = int((time.time() - start_train) / 60)\n",
    "print(f\"total runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "46793c4a-a59c-41fd-8a47-07d706324abe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Offline eval metrics:\n",
      "AccuracyAtK  =  0.09859375\n",
      "\n",
      "Offline eval metrics:\n",
      "AveragePerClassAccuracyAtK  =  0.04744617\n",
      "\n",
      "Offline eval metrics:\n",
      "WeightedReturns_gamma_1  =  -304.36295\n"
     ]
    }
   ],
   "source": [
    "for metric in offline_eval_metrics:\n",
    "    print(f\"\\nOffline eval metrics:\")\n",
    "    print(metric.name, ' = ', metric.result().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5597142e-fbbe-4a65-a016-79d8f5ae275d",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "notes:\n",
    "* Accuracy metrics are suspicious, since the RNN model is trained to maximize Accuracy\n",
    "* Offline metrics may not be very reliable for `Top-K Off-Policy Correction`\n",
    "\n",
    "**TODO**\n",
    "* adding a small positive reward for time steps without clicks: will help REINFORCE accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "72f0a0ae-2767-4998-b6e1-8296031f671f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_o_loss)\n",
    "# plt.ylim([0, 10])\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd4c511-6b36-4984-af2d-45e1f6928883",
   "metadata": {},
   "source": [
    "## TensorBoard\n",
    "\n",
    "**TODO:**\n",
    "* investigate `Losses/regularization_loss`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af75b469-dc5c-4611-b312-29468af5403e",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Gradient summaries**\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src='imgs/summary_gradients_tb.png' width='1200'/>\n",
    "</p>\n",
    "\n",
    "\n",
    "**Var histograms**\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src='imgs/histograms_tb.png' width='1200'/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e5af3972-33b5-4569-92f3-173d67799bf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "74b756de-aad5-4a46-a192-45412ecb8c7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a2472091a657f673\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a2472091a657f673\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=$train_log_dir\n",
    "\n",
    "# %tensorboard --logdir=$eval_log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "881587d7-ad7e-4915-8b53-ed78bf66fe2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorboard import notebook\n",
    "notebook.list() # View open TensorBoard instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc73fdb-c649-42fb-8eb9-e5baed7dbbd8",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac247f6-8722-4851-a49f-da4fe88543d3",
   "metadata": {},
   "source": [
    "Create an inference dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a3be02d2-e4b8-4525-98f0-7c3beaa3f8ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'action': <tf.Tensor: shape=(1, 10), dtype=int64, numpy=array([[3474, 1077, 2530, 2792, 2647, 3509, 2432, 3724, 1928,    0]])>,\n",
       " 'discount': <tf.Tensor: shape=(1, 10), dtype=float32, numpy=array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)>,\n",
       " 'next_step_type': <tf.Tensor: shape=(1, 10), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>,\n",
       " 'observation': <tf.Tensor: shape=(1, 10), dtype=int64, numpy=array([[2300, 3474, 1077, 2530, 2792, 2647, 3509, 2432, 3724,    0]])>,\n",
       " 'policy_info': (),\n",
       " 'reward': <tf.Tensor: shape=(1, 10), dtype=float32, numpy=array([[4., 4., 4., 3., 4., 4., 4., 3., 4., 0.]], dtype=float32)>,\n",
       " 'step_type': <tf.Tensor: shape=(1, 10), dtype=int32, numpy=array([[0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>})"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_dataset = create_tfrecord_ds(\n",
    "    tf.io.gfile.glob(val_files),\n",
    "    process_example_fn=process_example_fn,\n",
    "    batch_size=1,\n",
    "    num_shards=len(val_files),\n",
    "    repeat=False,\n",
    "    drop_remainder=True\n",
    ")\n",
    "infer_batch = list(inference_dataset.take(1))[0]\n",
    "traj_infer, weights_infer = infer_batch\n",
    "\n",
    "traj_infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ce4f94d4-400c-4dd4-9283-268edc9d4b0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=array([[0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_infer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c315bd46-4da1-4d95-a8f9-c9ade00981de",
   "metadata": {},
   "source": [
    "Check initial policy state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4d1c4795-a5bc-472f-814a-94f4b29e91c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((ListWrapper([<tf.Tensor: shape=(1, 25), dtype=float32, numpy=\n",
       "  array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>, <tf.Tensor: shape=(1, 25), dtype=float32, numpy=\n",
       "  array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>]),),)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_state = tf_agent.policy.get_initial_state(traj_infer.step_type.shape[0])\n",
    "policy_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf84f80b-e200-4755-a0f3-c6bbfc60362c",
   "metadata": {},
   "source": [
    "Generate predictions for each step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ac80d4bb-e6ce-44e4-a765-3934eb6013c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_infer.step_type.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c892c1bc-897b-4add-86cb-2af45276ed54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_actions = []\n",
    "\n",
    "for i in tf.range(traj_infer.step_type.shape[1]):\n",
    "\n",
    "    observation = traj_infer.observation[:, i, tf.newaxis]\n",
    "    step_type = traj_infer.step_type[:, i, tf.newaxis]\n",
    "    time_step = ts.TimeStep(\n",
    "        step_type=step_type,\n",
    "        observation=observation,\n",
    "        reward=tf.zeros_like(step_type, tf.float32),\n",
    "        discount=tf.ones_like(step_type, tf.float32)\n",
    "    )\n",
    "\n",
    "    action_step = tf_agent.policy.action(time_step, policy_state)\n",
    "    policy_state = action_step.state\n",
    "    predicted_actions.append(action_step.action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "bf4c18e3-49bf-4674-ad65-6df448d7fd8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[2300, 2647, 2041,  899, 2812]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[2647, 2300, 3474, 2286, 2947]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[2647, 2530, 2643, 2267, 2536]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[2647, 2643, 2267, 2530, 2890]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[3106, 2647, 2890, 2511, 3509]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[2647,  775, 3509, 2926, 2511]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[ 775, 2323, 2918, 2647, 2537]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[ 453, 2502, 3045, 2693, 1568]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[3509, 2918, 2502, 1180,  585]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[3045, 2918,  591, 1180,    0]])>]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0a09e2-40b1-4987-956e-15a813ba51ad",
   "metadata": {},
   "source": [
    "Check policy state now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4fd950cc-9141-4667-a6f4-6921b86aaf62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((ListWrapper([<tf.Tensor: shape=(1, 25), dtype=float32, numpy=\n",
       "  array([[ 0.05241432,  0.98600686, -0.36687565, -0.71111214, -0.5876302 ,\n",
       "          -0.6540603 , -0.637168  ,  0.39069363, -0.3162704 ,  0.6793068 ,\n",
       "           0.1797616 , -0.2710971 ,  0.8407467 ,  0.03705798,  0.6595919 ,\n",
       "           0.3617188 ,  0.31870654, -0.74525344,  0.2698641 ,  0.55854094,\n",
       "           0.6419451 ,  0.7010983 , -0.52764374, -0.4863269 ,  0.16866025]],\n",
       "        dtype=float32)>, <tf.Tensor: shape=(1, 25), dtype=float32, numpy=\n",
       "  array([[ 0.05479869,  4.6145096 , -0.4631493 , -1.0606203 , -0.67411655,\n",
       "          -0.82005626, -0.9816607 ,  0.43978333, -0.33884057,  0.8743038 ,\n",
       "           0.18329965, -0.2792249 ,  1.2403457 ,  0.03711957,  1.016073  ,\n",
       "           0.37892285,  0.38792324, -0.99184835,  0.29707712,  1.6848669 ,\n",
       "           0.9849992 ,  0.8877889 , -0.5966963 , -0.5336373 ,  0.17028773]],\n",
       "        dtype=float32)>]),),)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_step.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "39d44c29-5671-42ed-af28-a066e6007350",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10, 1), dtype=int64, numpy=\n",
       "array([[[3474],\n",
       "        [1077],\n",
       "        [2530],\n",
       "        [2792],\n",
       "        [2647],\n",
       "        [3509],\n",
       "        [2432],\n",
       "        [3724],\n",
       "        [1928],\n",
       "        [   0]]])>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_actions = tf.expand_dims(traj_infer.action, axis=2)\n",
    "observed_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e2d341d0-af98-4d03-b09d-8e165c5ff8a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10, 5), dtype=int64, numpy=\n",
       "array([[[2300, 2647, 2041,  899, 2812],\n",
       "        [2647, 2300, 3474, 2286, 2947],\n",
       "        [2647, 2530, 2643, 2267, 2536],\n",
       "        [2647, 2643, 2267, 2530, 2890],\n",
       "        [3106, 2647, 2890, 2511, 3509],\n",
       "        [2647,  775, 3509, 2926, 2511],\n",
       "        [ 775, 2323, 2918, 2647, 2537],\n",
       "        [ 453, 2502, 3045, 2693, 1568],\n",
       "        [3509, 2918, 2502, 1180,  585],\n",
       "        [3045, 2918,  591, 1180,    0]]])>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_actions_stacked = tf.stack(predicted_actions, axis=1)\n",
    "predicted_actions_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "58dd883e-ef68-45ee-8ead-6278245782ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=bool, numpy=\n",
       "array([[False, False,  True, False,  True,  True, False, False, False,\n",
       "         True]])>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_predictions = tf.reduce_any(\n",
    "    predicted_actions_stacked == observed_actions, axis=2\n",
    ")\n",
    "correct_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "43e33ae8-1abb-42ae-aa52-4881122ef3a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Predictions:\n",
      "tf.Tensor([[False False  True False  True  True False False False  True]], shape=(1, 10), dtype=bool)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Correct Predictions:')\n",
    "print(correct_predictions)\n",
    "print('-' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "57266671-f235-4d0c-9478-31ea97fffc65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed Actions (vocab):\n",
      "tf.Tensor([[3475 1078 2531 2793 2648 3510 2433 3725 1929    1]], shape=(1, 10), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print('Observed Actions (vocab):')\n",
    "print(action_lookup_layer(traj_infer.action))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ad96878b-0843-4f8b-b98e-bed238ddaab6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Actions (vocab):\n",
      "tf.Tensor(\n",
      "[[[2301 2648 2042  900 2813]]\n",
      "\n",
      " [[2648 2301 3475 2287 2948]]\n",
      "\n",
      " [[2648 2531 2644 2268 2537]]\n",
      "\n",
      " [[2648 2644 2268 2531 2891]]\n",
      "\n",
      " [[3107 2648 2891 2512 3510]]\n",
      "\n",
      " [[2648  776 3510 2927 2512]]\n",
      "\n",
      " [[ 776 2324 2919 2648 2538]]\n",
      "\n",
      " [[ 454 2503 3046 2694 1569]]\n",
      "\n",
      " [[3510 2919 2503 1181  586]]\n",
      "\n",
      " [[3046 2919  592 1181    1]]], shape=(10, 1, 5), dtype=int64)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Predicted Actions (vocab):')\n",
    "print(action_lookup_layer(predicted_actions))\n",
    "print('-' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "b3965378-17d6-44c9-a57e-ccb8eeca029c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed Actions (raw):\n",
      "tf.Tensor([[3474 1077 2530 2792 2647 3509 2432 3724 1928    0]], shape=(1, 10), dtype=int64)\n",
      "--------------------------------------------------------------------------------\n",
      "Predicted Actions (raw):\n",
      "[<tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[2300, 2647, 2041,  899, 2812]])>, <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[2647, 2300, 3474, 2286, 2947]])>, <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[2647, 2530, 2643, 2267, 2536]])>, <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[2647, 2643, 2267, 2530, 2890]])>, <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[3106, 2647, 2890, 2511, 3509]])>, <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[2647,  775, 3509, 2926, 2511]])>, <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[ 775, 2323, 2918, 2647, 2537]])>, <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[ 453, 2502, 3045, 2693, 1568]])>, <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[3509, 2918, 2502, 1180,  585]])>, <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[3045, 2918,  591, 1180,    0]])>]\n"
     ]
    }
   ],
   "source": [
    "print('Observed Actions (raw):')\n",
    "print(traj_infer.action)\n",
    "print('-' * 80)\n",
    "print('Predicted Actions (raw):')\n",
    "print(predicted_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4a220b-60f5-4376-83fa-9efc0b1bb1e1",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Notes n stash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39b3f3a-c564-4e3e-94b3-311c6a386926",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Experiment ideas\n",
    "\n",
    "**Create experiment comparing:**\n",
    "\n",
    "[1] rnn\n",
    "* off_policy_correction_exponent = None\n",
    "* use_supervised_loss_for_main_policy = True\n",
    "\n",
    "[2] REINFORCE\n",
    "* off_policy_correction_exponent = None\n",
    "* use_supervised_loss_for_main_policy = False\n",
    "\n",
    "[3] topk REINFORCE\n",
    "* off_policy_correction_exponent = ~16\n",
    "* use_supervised_loss_for_main_policy = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7752fb7-2134-47ef-9013-3a2797b1e98c",
   "metadata": {},
   "source": [
    "## synthetic data for tutorial/demo\n",
    "\n",
    "Create dummy item IDs and embeddings like [src](https://www.tensorflow.org/recommenders/examples/efficient_serving#tuning_scann)\n",
    "\n",
    "```\n",
    "# Construct a dataset of movies that's 1,000 times larger. We \n",
    "# do this by adding several million dummy movie titles to the dataset.\n",
    "lots_of_movies = tf.data.Dataset.concatenate(\n",
    "    movies.batch(4096),\n",
    "    movies.batch(4096).repeat(1_000).map(lambda x: tf.zeros_like(x))\n",
    ")\n",
    "\n",
    "# We also add lots of dummy embeddings by randomly perturbing\n",
    "# the estimated embeddings for real movies.\n",
    "lots_of_movies_embeddings = tf.data.Dataset.concatenate(\n",
    "    movies.batch(4096).map(model.movie_model),\n",
    "    movies.batch(4096).repeat(1_000)\n",
    "      .map(lambda x: model.movie_model(x))\n",
    "      .map(lambda x: x * tf.random.uniform(tf.shape(x)))\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4fdf9e-25fa-463e-ae4a-f30f59ef29ae",
   "metadata": {},
   "source": [
    "#### TODO: optimize train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f856c61-bf1f-49a7-8139-726dda59a8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@common.function(autograph=False)\n",
    "def _train_step_fn(data):\n",
    "    \n",
    "    # trajectory, weights = data\n",
    "\n",
    "    def replicated_train_step(experience):\n",
    "        return tf_agent.train(experience).loss\n",
    "\n",
    "    per_replica_losses = distribution_strategy.run(\n",
    "        replicated_train_step, \n",
    "        args=(data,)\n",
    "    )\n",
    "\n",
    "    # return agent.train(experience=trajectories).loss\n",
    "    return distribution_strategy.reduce(\n",
    "        tf.distribute.ReduceOp.MEAN, \n",
    "        per_replica_losses, # loss, \n",
    "        axis=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b5bd54-b113-4b99-84ad-9890dcc14b2e",
   "metadata": {},
   "source": [
    "#### TODO: record summary within scope?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c279d482-177e-480f-80b0-44370ddbfa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.compat.v2.summary.record_if(\n",
    "#     lambda: tf.math.equal(global_step % summary_interval, 0)):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6974c692-c031-4bfb-905c-6e3ab4265097",
   "metadata": {},
   "source": [
    "```\n",
    "    @common.function(autograph=False)\n",
    "    def _train_step_fn(data):\n",
    "        \n",
    "        def replicated_train_step(experience):\n",
    "            return agent.train(experience).loss\n",
    "        \n",
    "        trajectories = _trajectory_fn(data)\n",
    "\n",
    "        per_replica_losses = distribution_strategy.run(\n",
    "            replicated_train_step, \n",
    "            args=(trajectories,)\n",
    "        )\n",
    "\n",
    "        # return agent.train(experience=trajectories).loss\n",
    "        return distribution_strategy.reduce(\n",
    "            tf.distribute.ReduceOp.MEAN, \n",
    "            per_replica_losses, # loss, \n",
    "            axis=None\n",
    "        )\n",
    "        \n",
    "    ...\n",
    "    \n",
    "    loss = _train_step_fn(data)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
