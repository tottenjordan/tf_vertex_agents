{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7767b603-7035-4fb3-b727-9704383e93a2",
   "metadata": {},
   "source": [
    "# REINFORCE recommender agent\n",
    "\n",
    "```\n",
    "Top-K Off-Policy Correction for a REINFORCE Recommender System\n",
    "Minmin Chen, Alex Beutel, Paul Covington, Sagar Jain, Francois Belletti, Ed Chi\n",
    "https://arxiv.org/pdf/1812.02353.pdf\n",
    "```\n",
    "This notebook steps details how to train and evaluate the REINFORCE Recommender agent from the paper above. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fde96d8-ab7e-4846-8391-1b4603f5df9a",
   "metadata": {},
   "source": [
    "### env setup\n",
    "\n",
    "if implementing a scann index for efficient `action retreival` function, install `scann` (and version):\n",
    "\n",
    "> scann==1.2.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ba60d66-b31e-4250-be7d-00b0736a4eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "VERSION        = \"v2\"                       # TODO\n",
    "PREFIX         = f'rec-bandits-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dd67236-2dcc-44d1-b633-0a80f2c0ebdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"rec-bandits-v2\"\n",
      "VERSION                  = \"v2\"\n",
      "\n",
      "BUCKET_NAME              = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_NAME    = \"mvlens_rec_bandits_v2\"\n",
      "BIGQUERY_TABLE_NAME      = \"training_dataset\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-rec-bandits-v2\"\n",
      "\n",
      "DOCKERNAME_01            = \"Dockerfile_train_my_perarm_env\"\n",
      "IMAGE_NAME_01            = \"train-my-perarm-env-v2\"\n",
      "IMAGE_URI_01             = \"gcr.io/hybrid-vertex/train-my-perarm-env-v2\"\n",
      "\n",
      "DOCKERNAME_02            = \"Dockerfile_perarm_feats\"\n",
      "IMAGE_NAME_02            = \"train-perarm-feats-v2\"\n",
      "IMAGE_URI_02             = \"gcr.io/hybrid-vertex/train-perarm-feats-v2\"\n",
      "\n",
      "DOCKERNAME_03            = \"Dockerfile_ranking_bandit\"\n",
      "IMAGE_NAME_03            = \"train-rank-bandit-v2\"\n",
      "IMAGE_URI_03             = \"gcr.io/hybrid-vertex/train-rank-bandit-v2\"\n",
      "\n",
      "DOCKERNAME_04            = \"Dockerfile_train_bandit_e2e\"\n",
      "IMAGE_NAME_04            = \"train-mab-e2e-v2\"\n",
      "IMAGE_URI_04             = \"gcr.io/hybrid-vertex/train-mab-e2e-v2\"\n",
      "\n",
      "DOCKERNAME_04_pred       = \"Dockerfile_pred_bandit_e2e\"\n",
      "IMAGE_NAME_04_pred       = \"pred-mab-e2e-v2\"\n",
      "IMAGE_URI_04_pred        = \"gcr.io/hybrid-vertex/pred-mab-e2e-v2\"\n",
      "\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/local_docker_tfa\"\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449a67ff-c853-4ac7-8ddf-37c9c71ee466",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74ec9e9c-73c9-4e3b-bb07-13e8c9cb5241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "404e8b3c-63bb-453a-8798-729e8ce16d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import functools\n",
    "import collections\n",
    "import pickle as pkl\n",
    "from pprint import pprint\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# tf-agents\n",
    "from tf_agents.utils import common\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import sequential\n",
    "from tf_agents.metrics import export_utils\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.train.utils import strategy_utils\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "# this repo\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.data import data_utils as data_utils\n",
    "from src.data import data_config as data_config\n",
    "from src.agents import rfa_utils as rfa_utils\n",
    "from src.networks import encoding_network as emb_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e72c8c2-9a8a-487e-8631-17ce5a572894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "438a50ed-ff68-41f3-b413-d9033425b856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = cuda.get_current_device()\n",
    "# device.reset()\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbe5766d-bb05-48b8-9a83-b81536b9e824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89516f4c-c5a5-4aa7-86da-ffc0d317f906",
   "metadata": {},
   "source": [
    "# Sequence data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85e9857-6c78-4535-b126-00bed1c8d2ec",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a99e97-7b78-4ada-8a7f-69662197d1fa",
   "metadata": {},
   "source": [
    "For each `user`, we consider a sequence of user historical interactions with the RecSys, recording the actions taken by the recommender (e.g., items recommended), as well as user feedback (e.g.,`ratings`)\n",
    "\n",
    "Given such a sequence, we predict the next `action` to take, i.e., items to recommend, so that user satisfaction metrics, e.g., indicated by `ratings` improve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe910866-2e0a-4386-b923-67c1f1c8b986",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "**MPD definiton**\n",
    "\n",
    "> We translate this setup into a Markov Decision Process (MDP)\n",
    "\n",
    "**{`S`, `A`, `P`, `R`, `p0`, `y`}**\n",
    "\n",
    "* **`S`**: a continuous state space describing the user states\n",
    "* **`A`**: a discrete action space, containing items available for recommendation\n",
    "* **`P`** : S × A × S → R is the state transition probability\n",
    "* **`R`** : S × A → R is the reward function, where 𝑟(𝑠, 𝑎) is the immediate reward obtained by performing action 𝑎 at user state `s`\n",
    "* **`p0`** is the initial state distribution\n",
    "* **`y`** is the discount factor for future rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d67f73f-788c-45e3-889b-c74e76dd74b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Trajectories\n",
    "\n",
    "**A `Trajectory` represents a sequence of aligned time steps** \n",
    "\n",
    "It captures:\n",
    "* `observation` and `step_type` from current time step with the computed `action` and `policy_info`\n",
    "* `Discount`, `reward` and `next_step_type` come from the next time step.\n",
    "  \n",
    "We allow `experience` to contain trajectories of different lengths in the *time dimension*, but these have to be padded with dummy values to have a constant size of `T` in the time dimension\n",
    "\n",
    "* Both `trajectory.reward` and `weights` have to be 0 for these dummy values\n",
    "* `experience` can be provided in other formats such as `Transition`'s if they can be converted into Trajectories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f97790-b940-4e16-a1d4-b136ac4973d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### TimeSteps\n",
    "\n",
    "**A `TimeStep` contains the data emitted by an environment at each step of interaction**. They include:\n",
    "* a `step_type`, \n",
    "* an `observation` (e.g., NumPy array, dict, or list of arrays), \n",
    "* and an associated `reward` and `discount`\n",
    "\n",
    "**sequential ordering**\n",
    "* first `TimeStep` in a sequence equals `StepType.FIRST`\n",
    "* final `TimeStep` in a sequence equals `StepType.LAST`\n",
    "* All other `TimeStep`s in a sequence equal `StepType.MID`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f46643-cbbf-4995-8d0e-532a1426ca2a",
   "metadata": {},
   "source": [
    "#### Discounted rewards\n",
    "\n",
    "> A discounting factor is introduced for:\n",
    "* Reducing variance \n",
    "* Prescribing the effective time horizon we optimize over"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d685e97b-a080-486a-8b50-c486553f3493",
   "metadata": {},
   "source": [
    "## Parse sequence examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d35f041d-26c3-4402-8f6c-ea3bf2960947",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1256d869-df7d-4731-a3f5-0870bcb3991b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCS_DATA_PATH: gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m\n"
     ]
    }
   ],
   "source": [
    "EXAMPLE_GEN_GCS_PATH = data_config.EXAMPLE_GEN_GCS_PATH\n",
    "GCS_DATA_PATH = f\"{BUCKET_URI}/{EXAMPLE_GEN_GCS_PATH}\"\n",
    "\n",
    "print(f\"GCS_DATA_PATH: {GCS_DATA_PATH}\")\n",
    "# !gsutil ls $GCS_DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7435dc7-56c8-4de6-b0c0-1fe8c83c1454",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = \"train\" # \"train\" | \"val\"\n",
    "\n",
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{EXAMPLE_GEN_GCS_PATH}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "train_files = train_files #[:3] # subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21b3eeaa-e1fa-4adf-9762-93d43d2ef2f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'context_movie_genre': <tf.Tensor: shape=(10,), dtype=string, numpy=\n",
      "array([b'Crime', b'Drama', b'Action', b'Drama', b'War', b'Crime',\n",
      "       b'Drama', b'Drama', b'Drama', b'Drama'], dtype=object)>,\n",
      "  'context_movie_id': <tf.Tensor: shape=(10,), dtype=string, numpy=\n",
      "array([b'2199', b'108', b'1047', b'837', b'1590', b'504', b'1680', b'258',\n",
      "       b'1632', b'586'], dtype=object)>,\n",
      "  'context_movie_rating': <tf.Tensor: shape=(10,), dtype=float32, numpy=array([3., 4., 3., 4., 3., 3., 4., 3., 4., 5.], dtype=float32)>,\n",
      "  'context_movie_title': <tf.Tensor: shape=(10,), dtype=string, numpy=\n",
      "array([b'Few Good Men, A (1992)', b'Braveheart (1995)',\n",
      "       b'Sleepers (1996)', b'Spitfire Grill, The (1996)',\n",
      "       b\"Ulee's Gold (1997)\", b'Philadelphia (1993)',\n",
      "       b'Jackie Brown (1997)', b'Little Women (1994)',\n",
      "       b'Joy Luck Club, The (1993)', b'Dances with Wolves (1990)'],\n",
      "      dtype=object)>,\n",
      "  'context_movie_year': <tf.Tensor: shape=(10,), dtype=int64, numpy=array([1992, 1995, 1996, 1996, 1997, 1993, 1997, 1994, 1993, 1990])>,\n",
      "  'context_rating_timestamp': <tf.Tensor: shape=(10,), dtype=int64, numpy=\n",
      "array([958964374, 958964438, 958964438, 958964471, 958964511, 958964511,\n",
      "       958964532, 958964546, 958964546, 958964909])>,\n",
      "  'target_movie_genres': <tf.Tensor: shape=(10,), dtype=string, numpy=\n",
      "array([b'Drama', b'Fantasy', b'UNK', b'UNK', b'UNK', b'UNK', b'UNK',\n",
      "       b'UNK', b'UNK', b'UNK'], dtype=object)>,\n",
      "  'target_movie_id': <tf.Tensor: shape=(), dtype=string, numpy=b'2384'>,\n",
      "  'target_movie_rating': <tf.Tensor: shape=(), dtype=float32, numpy=3.0>,\n",
      "  'target_movie_title': <tf.Tensor: shape=(), dtype=string, numpy=b'Boy Who Could Fly, The (1986)'>,\n",
      "  'target_movie_year': <tf.Tensor: shape=(), dtype=int64, numpy=1986>,\n",
      "  'target_rating_timestamp': <tf.Tensor: shape=(), dtype=int64, numpy=958964909>,\n",
      "  'user_age': <tf.Tensor: shape=(), dtype=int64, numpy=18>,\n",
      "  'user_gender': <tf.Tensor: shape=(), dtype=string, numpy=b'M'>,\n",
      "  'user_id': <tf.Tensor: shape=(), dtype=string, numpy=b'5637'>,\n",
      "  'user_occupation_text': <tf.Tensor: shape=(), dtype=string, numpy=b'academic/educator'>,\n",
      "  'user_zip_code': <tf.Tensor: shape=(), dtype=string, numpy=b'32601'>},\n",
      " {})\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "train_seq_dataset = train_dataset.map(data_utils._parse_seq_function)\n",
    "\n",
    "# see train example\n",
    "for x in train_seq_dataset.skip(5).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29291382-c029-45b3-a653-9d6536a2d5c5",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Example: proto to trajectory\n",
    "\n",
    "> Let's inspect the trajectory structure we need for our REINFORCE recommender agent. Specifically, we'll construct a `trajectory` object and its associated *importance weights*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ea44275-d358-452a-8bd2-f6875195522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30600e99-8853-4eb0-b646-5ab788313658",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### example proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2c96c24-2ba2-469c-8120-742f15fbe017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for raw_record in train_dataset.take(1):\n",
    "#     example = tf.train.Example()\n",
    "#     example.ParseFromString(raw_record.numpy())\n",
    "#     print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711624c1-63ba-4861-965a-19b4104ece39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for raw_seq_record in train_dataset.take(1):\n",
    "#     example = tf.train.SequenceExample()\n",
    "#     example.ParseFromString(raw_seq_record.numpy())\n",
    "#     print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf45eea-a088-4298-9be3-81efb03af4cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### rewards\n",
    "\n",
    "* ratings 1-5\n",
    "* can cast ratings over certain threshold to create binary rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24a429cf-ab4d-4338-8a59-5cb41ffd8faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 4., 3., 4., 5.], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_seq = x[0]['context_movie_rating'].numpy()[-sequence_length:]\n",
    "ratings_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98feef93-de21-4cb8-b7b8-1c269c9fad08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 4., 3., 4., 5.], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rewards = tf.cast(ratings_seq > 0, dtype=tf.float32) # binary rewards\n",
    "rewards = ratings_seq\n",
    "rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c0e214-bd6e-4f68-92f4-cbd550692941",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### actions and observations\n",
    "\n",
    "For now, we are using the following simplified features:\n",
    "* At every point in time, the `target_movie_id` field in the sequence is the **action** \n",
    "* the `context_movie_id` at the previous time step (previous action(s)) is the observation\n",
    "* each `context_movie_id` has a corresponding `context_movie_rating`\n",
    "> * possible to convert `context_movie_rating` to a binary reward (e.g., clicks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88ccfefc-01ef-4276-9744-eada1c7674d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=string, numpy=\n",
       "array([b'2199', b'108', b'1047', b'837', b'1590', b'504', b'1680', b'258',\n",
       "       b'1632', b'586'], dtype=object)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]['context_movie_id'] #[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdb958c5-0447-463b-99c4-39248c186b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'504', b'1680', b'258', b'1632', b'586'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = x[0]['context_movie_id'].numpy()[-sequence_length:]\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fb76a0b-2eb6-4dd4-b695-ca6bef686a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'1590', b'504', b'1680', b'258', b'1632'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations = x[0]['context_movie_id'].numpy()[-(sequence_length+1):-1]\n",
    "observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4b54b7-6eb9-4ecc-be23-71f4cc9267a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### pad trajectory elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee327ca8-332f-4b1c-b73c-0cb808e015e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=5>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_sequence_length = tf.shape(observations)[0]\n",
    "actual_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d939006b-ad42-4d12-977e-38138bc7a7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'504', b'1680', b'258', b'1632', b'586'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = actions[-actual_sequence_length:]\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64b0ad98-0f30-4eda-83ba-99a200d1e990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 4., 3., 4., 5.], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards = rewards[-actual_sequence_length:]\n",
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a3610d9-59bc-46b7-8cef-bdc03c22a637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 0], dtype=int32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paddings = tf.stack([0, sequence_length - actual_sequence_length])\n",
    "paddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd604602-ca41-461a-83d8-df8170cef296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=int32, numpy=array([[0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paddings = tf.expand_dims(paddings, 0)\n",
    "paddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98c936d8-a370-43e7-a919-8fc64749ab49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([3., 4., 3., 4., 5.], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards = tf.pad(rewards, paddings, 'CONSTANT', constant_values=0)\n",
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a90a8ee-107d-4c49-96c4-781f3f7ef469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discounts = tf.ones((sequence_length,), dtype=tf.float32)\n",
    "discounts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d3f594-abec-4e29-aae6-6c3be3dd2502",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### step types\n",
    "\n",
    "The time dimension will be equal to `sequence_length` \n",
    "\n",
    "The agent assumes that this trajectory is a single episode, so `trajectory.step_type` and `trajectory.discount` are ignored\n",
    "\n",
    "* `ts.StepType.FIRST` == 0\n",
    "* `ts.StepType.MID` == 1\n",
    "* `ts.StepType.LAST` == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39fed2c0-54fb-4866-a7e7-57e60e92dbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([1, 1, 1, 1, 1], dtype=int32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_step_types = tf.ones((sequence_length,), dtype=tf.int32) * ts.StepType.MID\n",
    "next_step_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58b00f63-2193-4ad7-ba8b-ad5af75ffc48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 1, 1, 1], dtype=int32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_types = tf.concat([[ts.StepType.FIRST], next_step_types[1:]], axis=0)\n",
    "step_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf7b148-736e-403f-992f-3e63dd66362a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### trajectory object\n",
    "\n",
    "* `Discount` is all ones in the base trajectory. During training, we can apply different discounting values with a `gamma` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f914d2d3-d073-40c4-8d66-00a7d2c4c233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'action': array([b'504', b'1680', b'258', b'1632', b'586'], dtype=object),\n",
       " 'discount': <tf.Tensor: shape=(5,), dtype=float32, numpy=array([1., 1., 1., 1., 1.], dtype=float32)>,\n",
       " 'next_step_type': <tf.Tensor: shape=(5,), dtype=int32, numpy=array([1, 1, 1, 1, 1], dtype=int32)>,\n",
       " 'observation': array([b'1590', b'504', b'1680', b'258', b'1632'], dtype=object),\n",
       " 'policy_info': (),\n",
       " 'reward': <tf.Tensor: shape=(5,), dtype=float32, numpy=array([3., 4., 3., 4., 5.], dtype=float32)>,\n",
       " 'step_type': <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 1, 1, 1], dtype=int32)>})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj = trajectory.Trajectory(\n",
    "      step_type=step_types,\n",
    "      observation=observations,\n",
    "      action=actions,\n",
    "      policy_info=(),\n",
    "      next_step_type=next_step_types,\n",
    "      reward=rewards,\n",
    "      discount=discounts\n",
    ")\n",
    "\n",
    "traj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92e19fc-260a-4d44-87e0-ca94629f1a37",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### importance weights\n",
    "\n",
    "> divides the trajectory into 3 parts: \n",
    "\n",
    "* The **first** part is used to warm start the state embedding network\n",
    "* The **second** part is used to compute losses\n",
    "* Returns are computed using the **second** and **third** parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "327da947-a547-44e8-a91e-c31f71e9efe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=1>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_size = tf.cast(actual_sequence_length / 3, tf.int32)\n",
    "section_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54d46f28-7f5f-4589-8eba-cf2bf90aa75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 1., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = tf.concat([\n",
    "    tf.zeros((section_size,)),\n",
    "    tf.ones((section_size,)),\n",
    "    tf.zeros((sequence_length - 2 * section_size,))\n",
    "], axis=0)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a38495-86e8-4090-a3d8-7caee8e07a88",
   "metadata": {},
   "source": [
    "## Data ops\n",
    "\n",
    "> Now let's create the helper functions for creating data pipelines for trajectories and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66ea5987-346d-42b5-8108-1d4df51d32ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_config.MAX_CONTEXT_LENGTH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775101af-c42c-4ad4-93c4-e71a27ca6fc0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### tmp debugging - START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15daa20-baa3-4f0c-bc97-d439829eb843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for raw_seq_record in train_seq_dataset.take(1):\n",
    "#     # example = tf.train.Example()\n",
    "#     # example.ParseFromString(raw_record.numpy())\n",
    "#     print(raw_seq_record)\n",
    "\n",
    "# # raw_seq_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d89fcc6f-f370-44c4-a8c4-965be90be3cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for x in train_seq_dataset.take(1):\n",
    "    \n",
    "#     # target_movie_id\n",
    "#     id_string = x[0]['target_movie_id'].numpy().decode(\"utf-8\")\n",
    "#     id_int_test = tf.strings.to_number(\n",
    "#         id_string,\n",
    "#         out_type=tf.dtypes.int64,\n",
    "#         name=None\n",
    "#     )\n",
    "#     # id_int_test = id_int_test.numpy()\n",
    "#     x[0]['target_movie_id'] = id_int_test\n",
    "    \n",
    "#     # context_movie_id (list)\n",
    "#     # context_id_string = x[0]['target_movie_id'].numpy().decode(\"utf-8\")\n",
    "    \n",
    "#     context_id_string = [z.numpy() for z in x[0]['context_movie_id']] # .decode(\"utf-8\")\n",
    "#     context_id_int = tf.strings.to_number(\n",
    "#         context_id_string,\n",
    "#         out_type=tf.dtypes.int64,\n",
    "#         name=None\n",
    "#     )\n",
    "#     # context_id_int = context_id_int.numpy()\n",
    "#     x[0]['context_movie_id'] = context_id_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "61569748-dc07-4dac-b4b0-0cdb5851f4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# context_id_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "573a3814-19e3-4228-94f4-84e6d6251e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# context_id_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08e5bf1c-08d1-4c5c-92be-6930c06146ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x[0]['context_movie_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711ab969-df92-4837-8a5a-171ab1f38ab0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### tmp debugging - END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24feaba7-034a-4efe-b54a-5591a22c0dcb",
   "metadata": {},
   "source": [
    "### function: sequence example to trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13e51673-6ef2-433e-bee5-c5ca0ec5e5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_proto_to_trajectory(\n",
    "    example_proto, # sequence_feature,\n",
    "    sequence_length: int\n",
    "):\n",
    "    \"\"\"\n",
    "    Converts a sequence example to a Trajectory and weights for training.\n",
    "\n",
    "    For now, we are using the following simplified features. At every point in\n",
    "    time, the `context_movie_id` field in the sequence is the action and the `context_movie_id`\n",
    "    at the previous time step (last action) is the observation. The `context_movie_rating` field\n",
    "    is converted to a binary reward.\n",
    "\n",
    "    If the sequence example is longer than than `sequence_length`, we only take\n",
    "    the last part of the sequence example. If it is shorter, we pad it with dummy\n",
    "    values at the end to equal `sequence_length`.\n",
    "\n",
    "    Args:\n",
    "    sequence_feature: A serialized SequenceExample to convert to a\n",
    "      trajectory.\n",
    "    sequence_length: The time dimension of the returned trajectory.\n",
    "\n",
    "    Returns:\n",
    "    trajectory: An unbatched trajectory. The time dimension will be equal to\n",
    "      sequence length. The agent assumes that this trajectory is a single\n",
    "      episode, so `trajectory.step_type` and `trajectory.discount` are ignored.\n",
    "    weights: A [T] float tensor of weights. Each row of `weights`\n",
    "        (along the time dimension) is usually a sequence of 0's, followed by\n",
    "        a sequence of 1's, again followed by a sequence of 0's. This divides\n",
    "        the trajectory into 3 parts. The first part is used to warm start\n",
    "        the state embedding network. The second part is used to compute\n",
    "        losses. Returns are computed using the second and third parts.\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_description = {\n",
    "        'context_movie_id': tf.io.FixedLenFeature(shape=(data_config.MAX_CONTEXT_LENGTH), dtype=tf.string),\n",
    "        'context_movie_rating': tf.io.FixedLenFeature(shape=(data_config.MAX_CONTEXT_LENGTH), dtype=tf.float32),\n",
    "    }\n",
    "    \n",
    "    sequence_feature = tf.io.parse_single_sequence_example(example_proto, feature_description)\n",
    "    # print(f\"sequence_feature: {sequence_feature[0]}\")\n",
    "    \n",
    "    # context_id_string = [z.numpy() for z in sequence_feature[0]['context_movie_id']]\n",
    "    \n",
    "    context_id_int = tf.strings.to_number(\n",
    "        sequence_feature[0]['context_movie_id'],\n",
    "        out_type=tf.dtypes.int64,\n",
    "        name=None\n",
    "    )\n",
    "    # context_id_int = context_id_int.numpy()\n",
    "    \n",
    "    ### TODO: keep or remove: [0] ? \n",
    "    \n",
    "    sequence_feature[0]['context_movie_id'] = context_id_int\n",
    "    actions = sequence_feature[0]['context_movie_id'][-sequence_length:]\n",
    "    rewards = sequence_feature[0]['context_movie_rating'][-sequence_length:]\n",
    "    observations = sequence_feature[0]['context_movie_id'][-(sequence_length+1):-1]\n",
    "    \n",
    "    # sequence_feature['context_movie_id'] = context_id_int\n",
    "    # actions = sequence_feature['context_movie_id'][-sequence_length:]\n",
    "    # rewards = sequence_feature['context_movie_rating'][-sequence_length:]\n",
    "    # observations = sequence_feature['context_movie_id'][-(sequence_length+1):-1]\n",
    "    # print(f\"observations: {observations}\")\n",
    "\n",
    "    # actual length\n",
    "    actual_sequence_length = tf.shape(observations)[0]\n",
    "    # print(f\"actual_sequence_length: {actual_sequence_length}\")\n",
    "    \n",
    "    actions = actions[-actual_sequence_length:]\n",
    "    rewards = rewards[-actual_sequence_length:]\n",
    "\n",
    "    # padding\n",
    "    paddings = tf.stack([0, sequence_length - actual_sequence_length])\n",
    "    paddings = tf.expand_dims(paddings, 0)\n",
    "\n",
    "    rewards = tf.pad(rewards, paddings, 'CONSTANT', constant_values=0)\n",
    "    actions = tf.pad(actions, paddings, 'CONSTANT', constant_values=0)\n",
    "    observations = tf.pad(observations, paddings, 'CONSTANT', constant_values=0)\n",
    "\n",
    "    # steps & discounts\n",
    "    discounts = tf.ones((sequence_length,), dtype=tf.float32)\n",
    "    next_step_types = tf.ones(\n",
    "      (sequence_length,), dtype=tf.int32) * ts.StepType.MID\n",
    "    step_types = tf.concat([[ts.StepType.FIRST], next_step_types[1:]], axis=0)\n",
    "\n",
    "    # build trajectory\n",
    "    traj = trajectory.Trajectory(\n",
    "        step_type=step_types,\n",
    "        observation=observations,\n",
    "        action=actions,\n",
    "        policy_info=(),\n",
    "        next_step_type=next_step_types,\n",
    "        reward=rewards,\n",
    "        discount=discounts\n",
    "    )\n",
    "\n",
    "    # get importance weights\n",
    "    section_size = tf.cast(actual_sequence_length / 3, tf.int32)\n",
    "    # print(f\"section_size: {section_size}\")\n",
    "    \n",
    "    weights = tf.concat(\n",
    "        [\n",
    "            tf.zeros((section_size,)),\n",
    "            tf.ones((section_size,)),\n",
    "            tf.zeros((sequence_length - 2 * section_size,))\n",
    "        ], \n",
    "        axis=0\n",
    "    )\n",
    "    \n",
    "    return traj, weights # sequence_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e2b739-8db2-4062-9473-73483aa7bb59",
   "metadata": {},
   "source": [
    "### function: create single TF Record dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e701a090-c072-487c-bfb7-cd0957c40ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_single_tfrecord_ds(\n",
    "    filename,\n",
    "    process_example_fn,\n",
    "    shuffle_buffer_size = 1,\n",
    "):\n",
    "    raw_ds = tf.data.TFRecordDataset(filename)\n",
    "    \n",
    "    ds = raw_ds.map(\n",
    "        process_example_fn,\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    ds = ds.shuffle(shuffle_buffer_size)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baaecab-e37e-44e6-849f-8bb943ea3d1f",
   "metadata": {},
   "source": [
    "### function: create interleaved TF Record dataset\n",
    "\n",
    "1. Each element of a TF Record is processed using the `process_example_fn` and converted to Tensors\n",
    "2. A dataset is created for each record file \n",
    "3. These datasets are interleaved together to create the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6b88787-3c46-419d-8882-284f4576f34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfrecord_ds(\n",
    "    filenames,\n",
    "    process_example_fn,\n",
    "    batch_size: int,\n",
    "    shuffle_buffer_size_per_record: int = 1,\n",
    "    shuffle_buffer_size: int = 10000,\n",
    "    num_shards: int = 50,\n",
    "    cycle_length: int = tf.data.AUTOTUNE,\n",
    "    block_length: int = 10,\n",
    "    num_prefetch: int = 10,\n",
    "    num_parallel_calls: int = 10,\n",
    "    repeat: bool = True,\n",
    "    drop_remainder: bool = False\n",
    "):\n",
    "    filenames = list(filenames)\n",
    "    initial_len = len(filenames)\n",
    "    remainder = initial_len % num_shards\n",
    "    \n",
    "    for _ in range(num_shards - remainder):\n",
    "        filenames.append(\n",
    "            filenames[np.random.randint(low=0, high=initial_len)]\n",
    "        )\n",
    "        \n",
    "    filenames = np.array(filenames)\n",
    "    np.random.shuffle(filenames)\n",
    "    filenames = np.array_split(filenames, num_shards)\n",
    "    filename_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "    \n",
    "    if repeat:\n",
    "        filename_ds = filename_ds.repeat()\n",
    "    \n",
    "    filename_ds = filename_ds.shuffle(len(filenames))\n",
    "    \n",
    "    example_ds = filename_ds.interleave(\n",
    "        functools.partial(\n",
    "            create_single_tfrecord_ds,\n",
    "            process_example_fn=process_example_fn,\n",
    "            shuffle_buffer_size=shuffle_buffer_size_per_record,\n",
    "        ),\n",
    "        cycle_length=tf.data.AUTOTUNE,\n",
    "        block_length=block_length,\n",
    "        num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    )\n",
    "    example_ds = example_ds.shuffle(shuffle_buffer_size)\n",
    "    \n",
    "    example_ds = example_ds.batch(\n",
    "        batch_size, drop_remainder=drop_remainder\n",
    "    ).prefetch(num_prefetch)\n",
    "  \n",
    "    return example_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3ae652-4cbe-436d-8b11-b729c0a659ba",
   "metadata": {},
   "source": [
    "#### inspect output of helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5db1afb-276a-4665-a7a4-31c893e2fe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length=10\n",
    "\n",
    "process_example_fn = functools.partial(\n",
    "    example_proto_to_trajectory,\n",
    "    sequence_length=sequence_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb73a2c6-951b-4cce-9415-1e12cc4d8eb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_batch_size=5\n",
    "\n",
    "train_dataset = create_tfrecord_ds(\n",
    "    tf.io.gfile.glob(train_files),\n",
    "    # num_shards = 10,\n",
    "    process_example_fn=process_example_fn,\n",
    "    batch_size=train_batch_size\n",
    ")\n",
    "train_dataset_iterator = iter(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96be0683-e389-4001-b4d3-bc48b32ee293",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 1., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_test, weights = next(train_dataset_iterator)\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24b6d417-e95e-4fd1-b515-f0c0522b718d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'action': <tf.Tensor: shape=(5, 10), dtype=int64, numpy=\n",
       "array([[1982, 1402,  370, 2794, 1216, 1995,  898, 1171, 2524,    0],\n",
       "       [3718, 2847,    8, 3180, 3036,  585, 1413, 2204, 1480,    0],\n",
       "       [ 907,  941, 3294, 2637, 2614, 2630, 2638, 2641, 3229,    0],\n",
       "       [3682, 3086, 3087, 3107,  464, 3684, 3686, 1083, 1686,    0],\n",
       "       [ 353, 2846, 2857, 1391, 3141, 1287, 3474, 1899, 2726,    0]])>,\n",
       " 'discount': <tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)>,\n",
       " 'next_step_type': <tf.Tensor: shape=(5, 10), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>,\n",
       " 'observation': <tf.Tensor: shape=(5, 10), dtype=int64, numpy=\n",
       "array([[ 582, 1982, 1402,  370, 2794, 1216, 1995,  898, 1171,    0],\n",
       "       [3680, 3718, 2847,    8, 3180, 3036,  585, 1413, 2204,    0],\n",
       "       [2950,  907,  941, 3294, 2637, 2614, 2630, 2638, 2641,    0],\n",
       "       [3554, 3682, 3086, 3087, 3107,  464, 3684, 3686, 1083,    0],\n",
       "       [ 341,  353, 2846, 2857, 1391, 3141, 1287, 3474, 1899,    0]])>,\n",
       " 'policy_info': (),\n",
       " 'reward': <tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[3., 3., 2., 4., 5., 4., 5., 3., 4., 0.],\n",
       "       [1., 3., 4., 4., 3., 4., 4., 4., 4., 0.],\n",
       "       [5., 4., 5., 3., 4., 2., 4., 4., 4., 0.],\n",
       "       [5., 5., 5., 1., 5., 5., 3., 4., 1., 0.],\n",
       "       [4., 4., 4., 4., 4., 4., 4., 3., 4., 0.]], dtype=float32)>,\n",
       " 'step_type': <tf.Tensor: shape=(5, 10), dtype=int32, numpy=\n",
       "array([[0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4192461-b9a8-4f47-8788-bbab2388414b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Policy \n",
    "\n",
    "> The main job of the Policy is to map observations from the user to actions. The action is a set of K recommended items. The policy is created by the Agent and contains a reference to the Network\n",
    "\n",
    "```\n",
    "Policy.__init__(time_step_spec, action_spec, network, ...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1081163d-bba9-4f5d-834a-6c5f17fe3afe",
   "metadata": {},
   "source": [
    "**computing actions**\n",
    "* to compute actions, the policy uses the network to compute the user's latent state (`s_t`)\n",
    "* this state is multiplied by a trainable action embedding (`v_a`) for each action\n",
    "* then apply softmax to compute action probabilities\n",
    "\n",
    "so steps in code, roughly follow:\n",
    "1. `s_{t+1}` <-- network(time_step.observation, state)\n",
    "2. scann index: retreive top M (100s-1000s) actions closest to `s{t+1}`\n",
    "3. compute inner produdct `q_a = v_a * s_{t+1}` for each action embedding `v_a`\n",
    "4. balance explore vs exploit:\n",
    "> * select greedy actions: `A_t` = {K’ actions with highest `q_a`}\n",
    "> * exploratory actions: actions sampled from softmax(`q_a/T`), where `T` is Boltzmann \n",
    "5. Return action = `A_t` (set of K Actions), state = `s_{t+1}`, info = ()\n",
    "\n",
    "**recomputing states**\n",
    "* Everytime the network weights are updated, the latent state `s_t` should be recomputed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fe5fb9-ad91-43a3-b34d-6649b8346305",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "> Train Top K Off Policy Reinforce from logged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d020d586-a07e-4c74-859a-08107e27fe69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/train/ml-1m-gen-001-of-008.tfrecord',\n",
       " 'gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/train/ml-1m-gen-002-of-008.tfrecord',\n",
       " 'gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/train/ml-1m-gen-003-of-008.tfrecord',\n",
       " 'gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/train/ml-1m-gen-004-of-008.tfrecord',\n",
       " 'gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/train/ml-1m-gen-005-of-008.tfrecord',\n",
       " 'gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/train/ml-1m-gen-006-of-008.tfrecord',\n",
       " 'gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/train/ml-1m-gen-007-of-008.tfrecord',\n",
       " 'gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/train/ml-1m-gen-008-of-008.tfrecord']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_SPLIT = \"train\"\n",
    "VAL_SPLIT = \"val\"\n",
    "\n",
    "train_files = []\n",
    "val_files = []\n",
    "\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{EXAMPLE_GEN_GCS_PATH}/{TRAIN_SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{EXAMPLE_GEN_GCS_PATH}/{VAL_SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        val_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "# train_files = train_files[:3]\n",
    "train_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78d83e8-5b13-4eec-adfa-732d3d0b2a0d",
   "metadata": {},
   "source": [
    "**get action vocab file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60ef7298-9d4b-4226-90fb-eb0f7493621d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab...\n",
      "Downloaded vocab from: gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/vocabs/vocab_dict.pkl\n",
      "\n",
      "'movie_id'\n",
      "'movie_year'\n",
      "'movie_genre'\n",
      "'movie_title'\n",
      "'user_id'\n",
      "'user_gender_vocab'\n",
      "'user_age_vocab'\n",
      "'user_occ_vocab'\n",
      "'user_zip_vocab'\n",
      "'min_timestamp'\n",
      "'max_timestamp'\n",
      "'timestamp_buckets'\n"
     ]
    }
   ],
   "source": [
    "EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{EXAMPLE_GEN_GCS_PATH}/vocabs/{VOCAB_FILENAME}'\n",
    "print(f\"Downloading vocab...\")\n",
    "\n",
    "os.system(f'gsutil -q cp {EXISTING_VOCAB_FILE} .')\n",
    "print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "vocab_dict = pkl.load(filehandler)\n",
    "filehandler.close()\n",
    "\n",
    "for key in vocab_dict.keys():\n",
    "    pprint(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97f18b38-cef0-44e9-a963-80e4c1b4069f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_dict['movie_id'][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babf9513-7181-472d-ad29-6a7ec249df90",
   "metadata": {},
   "source": [
    "## Vertex Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a03bbeae-cd49-4a98-ac1e-270f3bee25e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : topk-op-reinforce-v5\n",
      "RUN_NAME          : run-20240719-192039\n",
      "\n",
      "CHECKPT_DIR       : gs://rec-bandits-v2-hybrid-vertex-bucket/topk-op-reinforce-v5/chkpoint\n",
      "BASE_OUTPUT_DIR   : gs://rec-bandits-v2-hybrid-vertex-bucket/topk-op-reinforce-v5/run-20240719-192039\n",
      "LOG_DIR           : gs://rec-bandits-v2-hybrid-vertex-bucket/topk-op-reinforce-v5/run-20240719-192039/logs\n",
      "ROOT_DIR          : gs://rec-bandits-v2-hybrid-vertex-bucket/topk-op-reinforce-v5/run-20240719-192039/root\n",
      "ARTIFACTS_DIR     : gs://rec-bandits-v2-hybrid-vertex-bucket/topk-op-reinforce-v5/run-20240719-192039/artifacts\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME   = f'topk-op-reinforce-v5'\n",
    "\n",
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "CHECKPT_DIR       = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/chkpoint\"\n",
    "BASE_OUTPUT_DIR   = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}\"\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"CHECKPT_DIR       : {CHECKPT_DIR}\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c11ea1-9756-45da-92bb-a9e9da73df12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # # create new TB instance\n",
    "# TENSORBOARD_DISPLAY_NAME=f\"{EXPERIMENT_NAME}-{RUN_NAME}\"\n",
    "\n",
    "# tensorboard = aiplatform.Tensorboard.create(\n",
    "#     display_name=TENSORBOARD_DISPLAY_NAME\n",
    "#     , project=PROJECT_ID\n",
    "#     , location=REGION\n",
    "# )\n",
    "\n",
    "# TB_RESOURCE_NAME = tensorboard.resource_name\n",
    "\n",
    "# TB_ID = TB_RESOURCE_NAME.split('/')[-1]\n",
    "\n",
    "# print(f\"TB_RESOURCE_NAME : {TB_RESOURCE_NAME}\")\n",
    "# print(f\"TB display name  : {tensorboard.display_name}\")\n",
    "# print(f\"TB_ID            : {TB_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56039f7-bd31-4e22-8bae-3b6753c7da4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# aiplatform.init(\n",
    "#     project=PROJECT_ID,\n",
    "#     location=REGION,\n",
    "#     experiment=EXPERIMENT_NAME,\n",
    "#     experiment_tensorboard=TB_ID\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a53827-1f90-4a31-9435-b199a4d61c76",
   "metadata": {},
   "source": [
    "### action vocab lookup\n",
    "\n",
    "1. Need to convert action feature (movie IDs) to numeric (i.e., string --> int64)\n",
    "2. update `vocab_dict`\n",
    "3. create *lookup layers* for Agent; essentially convert real world actions to integer action indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b2c9b14-ea5b-4f78-a5fb-b1661c8d8e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab_dict['movie_id']\n",
    "vocab_dict_decoded = [z.decode(\"utf-8\") for z in vocab_dict['movie_id']]\n",
    "vocab_dict_decoded.remove(\"UNK\")\n",
    "\n",
    "vocab_dict_decoded = tf.strings.to_number(\n",
    "    vocab_dict_decoded,\n",
    "    out_type=tf.dtypes.int64,\n",
    "    name=None\n",
    ")\n",
    "vocab_dict_decoded = vocab_dict_decoded.numpy()\n",
    "vocab_dict_decoded[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "39f1e1cd-2444-467f-b002-760700cc3a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update vocab_dict\n",
    "vocab_dict['movie_id_int'] = vocab_dict_decoded\n",
    "vocab_dict['movie_id_int'][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5a9707-c9b3-4bf0-9ec5-f5493c4caf89",
   "metadata": {},
   "source": [
    "**lookup layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "23257fce-8d57-4cf5-bcfb-94ea623c8e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_lookup_layer = tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=vocab_dict['movie_id_int'], \n",
    "    mask_value=None\n",
    ")\n",
    "\n",
    "inverse_action_lookup_layer = tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=action_lookup_layer.get_vocabulary(), \n",
    "    mask_value=None,\n",
    "    invert=True\n",
    ")\n",
    "\n",
    "# NUM_OOV_BUCKETS = 1\n",
    "\n",
    "# action_lookup_layer = tf.keras.layers.StringLookup(\n",
    "#     max_tokens=len(vocab_dict['movie_id']) + NUM_OOV_BUCKETS,\n",
    "#     num_oov_indices=NUM_OOV_BUCKETS,\n",
    "#     vocabulary=vocab_dict['movie_id'], \n",
    "#     mask_token=None\n",
    "# )\n",
    "\n",
    "# inverse_action_lookup_layer = tf.keras.layers.StringLookup(\n",
    "#     vocabulary=action_lookup_layer.get_vocabulary(), \n",
    "#     mask_token=None,\n",
    "#     invert=True\n",
    "# )\n",
    "\n",
    "action_vocab_size = action_lookup_layer.vocab_size() # 3885"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "40670e77-cba1-41ec-b6df-8347a4c8586a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3884"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # if observations are just past actions:\n",
    "\n",
    "observation_lookup_layer = tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=vocab_dict['movie_id_int'], \n",
    "    mask_value=None\n",
    ")\n",
    "\n",
    "# observation_lookup_layer = tf.keras.layers.StringLookup(\n",
    "#     max_tokens=len(vocab_dict['movie_id']) + NUM_OOV_BUCKETS,\n",
    "#     num_oov_indices=NUM_OOV_BUCKETS,\n",
    "#     vocabulary=vocab_dict['movie_id'], \n",
    "#     mask_token=None\n",
    "# )\n",
    "\n",
    "obs_vocab_size = observation_lookup_layer.vocab_size()\n",
    "obs_vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee28feda-f3b7-478f-a652-56eac45061c9",
   "metadata": {},
   "source": [
    "### tensor specs\n",
    "\n",
    "*Note that the minimum in the spec is 0 and the maximum is bound inclusive* \n",
    "\n",
    "> setting maximum = vocab_size - 1 accounts for all actions in the vocabulary, including OOV items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "36bf62a2-1017-4512-8b28-964f8088366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.compat.v1.train.get_or_create_global_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e5a3221b-1394-4e12-a4d0-4d4e952275da",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=[],\n",
    "    dtype=tf.int64, # tf.string | tf.int64,\n",
    "    minimum=0,\n",
    "    maximum=action_vocab_size - 1,\n",
    "    name='observation'\n",
    ")\n",
    "time_step_spec = ts.time_step_spec(observation_spec=observation_spec)\n",
    "\n",
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=[],\n",
    "    dtype=tf.int64, # tf.string | tf.int64,\n",
    "    minimum=0,\n",
    "    maximum=action_vocab_size - 1,\n",
    "    name='action'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1d0c50-2688-4921-b1bf-866de1b03465",
   "metadata": {},
   "source": [
    "## Network\n",
    "\n",
    "> maps observations to actions (see section 4.1 of the [paper](https://arxiv.org/pdf/1812.02353.pdf))\n",
    "\n",
    "The input to the network is an observation, which includes an embedding of the item selected by the user from the last set of recommendations\n",
    "* TODO: add context features to input\n",
    "\n",
    "To compute actions, the policy uses the network to compute the latent state `s_t`.\n",
    "* The state `s_t` is multiplied by a trainable action embedding `v_a` for each action, followed by a softmax to compute the action probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e3b4a096-cad0-4a57-aefd-f86a6debb922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int64, name='observation', minimum=array(0), maximum=array(3883))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embedding_size=100\n",
    "input_fc_layer_params=(100, 100)\n",
    "lstm_size=(25,)\n",
    "output_fc_layer_params=(10,)\n",
    "\n",
    "state_embedding_network = rfa_utils.create_state_embedding_network(\n",
    "    observation_lookup_layer=observation_lookup_layer,\n",
    "    input_embedding_size=input_embedding_size,\n",
    "    input_fc_layer_units=input_fc_layer_params,\n",
    "    lstm_size=lstm_size,\n",
    "    output_fc_layer_units=output_fc_layer_params\n",
    ")\n",
    "\n",
    "# state_embedding_spec = state_embedding_network.create_variables(\n",
    "#     time_step_spec.observation\n",
    "# )\n",
    "time_step_spec.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c0b3e5c7-346c-49f3-bedb-77586028f178",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029ec252-c7e0-42f0-b6a1-6f11221424cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (optional) Create action embedding index\n",
    "\n",
    "> action_embeddings: A `[num_actions, embedding_size]` float tensor of action embeddings.\n",
    "\n",
    "**Note** - the scann index is built by the Agent/Policy. This section just shows what is happening under the hood "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4c83cb25-7d5e-4947-90e0-05f99a35e12e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_OOV_BUCKETS        = 1\n",
    "GLOBAL_EMBEDDING_SIZE  = 12\n",
    "MV_EMBEDDING_SIZE      = 16\n",
    "\n",
    "# test emb models\n",
    "for i in range(1):\n",
    "    \n",
    "    iterator = iter(train_seq_dataset.batch(1))\n",
    "    data, _ = next(iterator)\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c48a03-5f19-4e1a-ae1e-bc450af54d8a",
   "metadata": {},
   "source": [
    "We have an embedding model we can use for items (`_get_per_arm_features`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28a00d60-0591-4e95-a753-d99e242b6df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.networks.encoding_network.EmbeddingModel at 0x7fbb8a55d300>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs = emb_features.EmbeddingModel(\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    "    max_genre_length = data_config.MAX_GENRE_LENGTH\n",
    ")\n",
    "\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a96e7097-9ee3-4a8d-9d19-0876e822f50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER_ARM_DIM: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 64), dtype=float32, numpy=\n",
       "array([[ 0.00618007,  0.04223475,  0.04033829,  0.02605522,  0.02353697,\n",
       "         0.00541567, -0.00060334, -0.01873553, -0.03896024, -0.00292424,\n",
       "        -0.0196142 ,  0.04794569,  0.01833396, -0.00677056, -0.0068749 ,\n",
       "        -0.0011702 ,  0.0071869 , -0.00506984,  0.04053466, -0.00089424,\n",
       "         0.01711792, -0.02256914, -0.01644466, -0.03165853, -0.04084092,\n",
       "         0.00819138, -0.02780376, -0.02449497,  0.02752819, -0.00866682,\n",
       "        -0.02077021, -0.04401029,  0.00973874, -0.02984439, -0.01657657,\n",
       "         0.04763849,  0.03399022, -0.01405852, -0.04277661, -0.03703167,\n",
       "         0.00231399,  0.0373469 ,  0.01538438,  0.009982  , -0.00487207,\n",
       "         0.02183754, -0.03926927,  0.02063805, -0.20340121,  0.07250404,\n",
       "         0.1488992 , -0.20001775,  0.1811173 ,  0.10193603,  0.24488391,\n",
       "         0.19118758, -0.22738798,  0.22803845,  0.22569782, -0.20963532,\n",
       "         0.19154592,  0.2269026 , -0.00287658, -0.04753834]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arms = embs._get_per_arm_features(data)\n",
    "\n",
    "PER_ARM_DIM = test_arms.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"PER_ARM_DIM: {PER_ARM_DIM}\")\n",
    "\n",
    "test_arms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a51f3520-ca22-471d-b749-67e95326960c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# total_movie_count = len(list(train_seq_dataset))\n",
    "# total_movie_count # 335532"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8b1b96-7345-418c-ab03-4d57125b1a82",
   "metadata": {
    "tags": []
   },
   "source": [
    "### create action index file\n",
    "\n",
    "TODO: get all movie candidates into single dataset, similar to below logic\n",
    "\n",
    "```\n",
    "input_ids = tf.data.Dataset.from_tensor_slices([d['input_ids'] for d in dataset])\n",
    "input_masks = tf.data.Dataset.from_tensor_slices([d['input_mask'] for d in dataset])\n",
    "segment_ids = tf.data.Dataset.from_tensor_slices([d['segment_ids'] for d in dataset])\n",
    "labels = tf.data.Dataset.from_tensor_slices([d['labels'] for d in dataset])\n",
    "\n",
    "ds = tf.data.Dataset.zip((input_ids, input_masks, segment_ids, labels))\n",
    "ds = ds.map(lambda x, y, z, l: {\"input_ids\": x, \"input_masks\": y,\n",
    "                                \"segment_ids\": z, \"labels\": l}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "81ab8f53-4f21-4cd2-b7dc-9914b19b9cd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 0; emb_valid: 1; movie_id_set: 1\n",
      "n: 500; emb_valid: 417; movie_id_set: 417\n",
      "n: 750; emb_valid: 572; movie_id_set: 572\n",
      "n: 2250; emb_valid: 1201; movie_id_set: 1201\n",
      "n: 3500; emb_valid: 1531; movie_id_set: 1531\n",
      "n: 5250; emb_valid: 1823; movie_id_set: 1823\n",
      "n: 8500; emb_valid: 2143; movie_id_set: 2143\n",
      "n: 11500; emb_valid: 2340; movie_id_set: 2340\n",
      "n: 19250; emb_valid: 2658; movie_id_set: 2658\n",
      "n: 20750; emb_valid: 2697; movie_id_set: 2697\n",
      "n: 73500; emb_valid: 3230; movie_id_set: 3230\n",
      "elapsed_time           : 3\n",
      "counter                : 335532\n",
      "Length of movie_id_set : 3550\n",
      "Length of emb_valid    : 3550\n"
     ]
    }
   ],
   "source": [
    "movie_id_set = []\n",
    "emb_valid = []\n",
    "\n",
    "LOG_INTERVAL=250\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "counter = 0\n",
    "for ex_data, _ in train_seq_dataset.batch(1):\n",
    "\n",
    "    ids_ = ex_data['target_movie_id'].numpy()[0] # movie_id_int\n",
    "    if ids_ not in movie_id_set:\n",
    "        movie_id_set.append(ids_)\n",
    "        action_emb = embs._get_per_arm_features(ex_data)\n",
    "        emb_valid.append(action_emb)\n",
    "        \n",
    "        if counter % LOG_INTERVAL == 0:\n",
    "            print(f\"n: {counter}; emb_valid: {len(emb_valid)}; movie_id_set: {len(movie_id_set)}\")\n",
    "        \n",
    "    counter+=1\n",
    "    \n",
    "    # if counter == 100:\n",
    "    #     break\n",
    "\n",
    "    \n",
    "end_time = time.time()\n",
    "elapsed_time = int((end_time - start_time) / 60)\n",
    "\n",
    "print(f\"elapsed_time           : {elapsed_time}\")\n",
    "print(f\"counter                : {counter}\")\n",
    "print(f\"Length of movie_id_set : {len(movie_id_set)}\")\n",
    "print(f\"Length of emb_valid    : {len(emb_valid)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "56221139-a770-4f7d-9e55-9cdca69db3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1775', '2789', '2249', '3104', '142']"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_id_set[0:5]\n",
    "\n",
    "# TODO: shouldn't need these anymore: confirm\n",
    "# movie_id_set_decoded = [z.decode(\"utf-8\") for z in movie_id_set]\n",
    "# movie_id_set_decoded[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "dc95b015-5b4f-42f5-9fd5-35312d64c8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00417863, -0.04035826,  0.03949881,  0.02248106,  0.03972029,\n",
       "       -0.03954465, -0.0078277 , -0.00666126,  0.0240129 ,  0.03367153,\n",
       "       -0.01583817,  0.03204237,  0.04059358, -0.03843267,  0.00045175,\n",
       "        0.00292462, -0.04330502, -0.00924589,  0.04248578,  0.03299932,\n",
       "        0.00611916, -0.03558064, -0.04670314, -0.0222977 , -0.04777682,\n",
       "       -0.03742123, -0.03174067, -0.01043591,  0.04092886, -0.02244899,\n",
       "       -0.03317848, -0.03101618, -0.03086665, -0.03440733, -0.04183024,\n",
       "        0.01905538,  0.02743418,  0.03782295,  0.00370765,  0.04130132,\n",
       "        0.00137607,  0.02548063, -0.02434435, -0.02880038,  0.01019372,\n",
       "       -0.01553645, -0.04996688, -0.0459705 ,  0.24497205, -0.22872275,\n",
       "       -0.12215847, -0.17597657, -0.21268445,  0.10867788, -0.1677419 ,\n",
       "        0.23022158, -0.0225311 ,  0.2358569 ,  0.1154706 ,  0.10946961,\n",
       "        0.20655268, -0.19170517,  0.0794156 ,  0.21880643], dtype=float32)"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# emb_valid[0].numpy()\n",
    "\n",
    "cleaned_emb_valid = [z.numpy()[0] for z in emb_valid]\n",
    "cleaned_emb_valid[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83cad03-0eca-49b2-aba0-f2a301a2e0a7",
   "metadata": {},
   "source": [
    "write index file locally, and save to (remote) cloud storage location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "04d23b3e-9a81-485e-b3c2-ad1bc476f686",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 'local'\n",
    "TIMESTAMP = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "embeddings_index_filename = f'action_embs_{TIMESTAMP}.json'\n",
    "\n",
    "with open(f'{embeddings_index_filename}', 'w') as f:\n",
    "    for prod, emb in zip(movie_id_set_decoded, cleaned_emb_valid):\n",
    "        f.write('{\"id\":\"' + str(prod) + '\",')\n",
    "        f.write('\"embedding\":[' + \",\".join(str(x) for x in list(emb)) + \"]}\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "46146d3a-6d3e-4f49-b39d-ba4771067454",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_GCS_URI = f'{DATA_PATH}/movielens/m1m/action-embeddings'\n",
    "\n",
    "DESTINATION_BLOB_NAME = embeddings_index_filename\n",
    "SOURCE_FILE_NAME = embeddings_index_filename\n",
    "\n",
    "print(f\"INDEX_GCS_URI         : {INDEX_GCS_URI}\")\n",
    "print(f\"DESTINATION_BLOB_NAME : {DESTINATION_BLOB_NAME}\")\n",
    "print(f\"SOURCE_FILE_NAME      : {SOURCE_FILE_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "feb0cc3c-9232-42c8-bf5f-ec86bec56efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from google.cloud.storage.bucket import Bucket\n",
    "from google.cloud.storage.blob import Blob\n",
    "\n",
    "blob = Blob.from_string(os.path.join(INDEX_GCS_URI, DESTINATION_BLOB_NAME))\n",
    "blob.bucket._client = storage_client\n",
    "blob.upload_from_filename(SOURCE_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44fb2f9-a099-4d66-944f-de7ad5e280c1",
   "metadata": {},
   "source": [
    "Load json file to validate formatting etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6fd25145-fddb-41db-adcf-7f0dd72fd3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3550"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "action_emb_lines = []\n",
    "\n",
    "embeddings_index_filename = 'action_embs_20240704-141459.json'\n",
    "\n",
    "with open(embeddings_index_filename, 'r') as f:\n",
    "    for line in f:\n",
    "        action_emb_lines.append(json.loads(line))\n",
    "    \n",
    "# action_emb_lines[0]\n",
    "# \"\"\"\n",
    "# {'id': '1775',\n",
    "#  'embedding': [0.004178632,\n",
    "#   -0.040358257,\n",
    "#   0.03949881,\n",
    "#   0.022481058,\n",
    "# \"\"\"\n",
    "\n",
    "len(action_emb_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d756c5d7-4598-421e-8735-c17b2a76c084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 0.00417863 -0.04035826  0.03949881  0.02248106  0.03972029 -0.03954465\n",
      " -0.0078277  -0.00666126  0.0240129   0.03367153 -0.01583817  0.03204237\n",
      "  0.04059358 -0.03843267  0.00045175  0.00292462 -0.04330502 -0.00924589\n",
      "  0.04248578  0.03299932  0.00611916 -0.03558064 -0.04670314 -0.0222977\n",
      " -0.04777682 -0.03742123 -0.03174067 -0.01043591  0.04092886 -0.02244899\n",
      " -0.03317848 -0.03101618 -0.03086665 -0.03440733 -0.04183024  0.01905538\n",
      "  0.02743418  0.03782295  0.00370765  0.04130132  0.00137607  0.02548063\n",
      " -0.02434435 -0.02880038  0.01019372 -0.01553645 -0.04996688 -0.0459705\n",
      "  0.24497205 -0.22872275 -0.12215847 -0.17597657 -0.21268445  0.10867788\n",
      " -0.1677419   0.23022158 -0.0225311   0.2358569   0.1154706   0.10946961\n",
      "  0.20655268 -0.19170517  0.0794156   0.21880643], shape=(64,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# action embeddings\n",
    "action_embs_v1 = tf.data.Dataset.from_tensor_slices([d['embedding'] for d in action_emb_lines])\n",
    "\n",
    "for test_embed in action_embs_v1.take(1):\n",
    "    print(test_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6a8ac015-912a-43f1-a4cb-bea6c800e716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1775, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# action IDs\n",
    "action_id_strs = [d['id'] for d in action_emb_lines]\n",
    "action_ids_ints = tf.strings.to_number(\n",
    "    action_id_strs,\n",
    "    out_type=tf.dtypes.int64,\n",
    "    name=None\n",
    ")\n",
    "action_ids_v1 = tf.data.Dataset.from_tensor_slices([d for d in action_ids_ints])\n",
    "\n",
    "for x in action_ids_v1.take(1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee59e06f-3b66-4ada-87fc-f5af3f709958",
   "metadata": {
    "tags": []
   },
   "source": [
    "### build scann index\n",
    "\n",
    "see ScaNN references:\n",
    "* [documentation](https://www.tensorflow.org/recommenders/api_docs/python/tfrs/layers/factorized_top_k/ScaNN#index_from_dataset)\n",
    "* used in [this tutorial](https://www.tensorflow.org/recommenders/examples/efficient_serving#tuning_scann)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741a1315-d141-4eeb-819f-0b3e6d00e98f",
   "metadata": {},
   "source": [
    "**Understanding ScaNN parameters**\n",
    "\n",
    "Consider:\n",
    "\n",
    "* `num_leaves=100` \n",
    "* `num_leaves_to_search=10` \n",
    "\n",
    "> This means our ScaNN database is partitioned into **100 disjoint subsets**, and the **10 most promising of these partitions** is scored with AH. This means 10/100=10% of the dataset is being searched with AH\n",
    "\n",
    "Now consider:\n",
    "\n",
    "* `num_leaves=1000` \n",
    "* `num_leaves_to_search=100` \n",
    "\n",
    "> still searching 10% of the database with AH. However, in comparison to the previous setting, the 10% we would search will contain higher-quality candidates, because a **higher `num_leaves` allows us to make finer-grained decisions about what parts of the dataset are worth searching**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb71501b-996d-41bc-a55d-52ce402682dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "55228fed-fbe5-483a-9ff3-1aaa1c5e2482",
   "metadata": {},
   "outputs": [],
   "source": [
    "scann = tfrs.layers.factorized_top_k.ScaNN(\n",
    "    k=10,\n",
    "    num_leaves=1000,\n",
    "    num_leaves_to_search=100,\n",
    "    num_reordering_candidates=500,\n",
    ")\n",
    "# scann"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69117309-fd3f-46ef-89ae-263768338e2b",
   "metadata": {},
   "source": [
    "the `candidates` arg in `index_from_dataset`:\n",
    "\n",
    "> Dataset of candidate embeddings or `(candidate identifier, candidate embedding)` pairs. \n",
    "\n",
    "* If the dataset returns tuples, the identifiers will be used as identifiers of top candidates returned when performing searches. \n",
    "* If not given, indices into the candidates dataset will be given instead.\n",
    "\n",
    "Also, `candidates` and `identifiers` have to have the same batch dimension\n",
    "> use `.batch()` when zipping dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "62d4b753-b246-4327-9ebc-25fb30b2c2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.ScaNN at 0x7fbaa06e22f0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scann.index_from_dataset(\n",
    "    candidates=ds_zipped_v2 = tf.data.Dataset.zip(\n",
    "        action_ids_v1.batch(1000), \n",
    "        action_embs_v1.batch(1000)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b63d7c58-cc93-470e-84b1-b5338e847fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00417863, -0.04035826,  0.03949881,  0.02248106,  0.03972029,\n",
       "       -0.03954465, -0.0078277 , -0.00666126,  0.0240129 ,  0.03367153,\n",
       "       -0.01583817,  0.03204237,  0.04059358, -0.03843267,  0.00045175,\n",
       "        0.00292462, -0.04330502, -0.00924589,  0.04248578,  0.03299932,\n",
       "        0.00611916, -0.03558064, -0.04670314, -0.0222977 , -0.04777682,\n",
       "       -0.03742123, -0.03174067, -0.01043591,  0.04092886, -0.02244899,\n",
       "       -0.03317848, -0.03101618, -0.03086665, -0.03440733, -0.04183024,\n",
       "        0.01905538,  0.02743418,  0.03782295,  0.00370765,  0.04130132,\n",
       "        0.00137607,  0.02548063, -0.02434435, -0.02880038,  0.01019372,\n",
       "       -0.01553645, -0.04996688, -0.0459705 ,  0.24497205, -0.22872275,\n",
       "       -0.12215847, -0.17597657, -0.21268445,  0.10867788, -0.1677419 ,\n",
       "        0.23022158, -0.0225311 ,  0.2358569 ,  0.1154706 ,  0.10946961,\n",
       "        0.20655268, -0.19170517,  0.0794156 ,  0.21880643], dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_embed.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0961dc1b-78fc-4dee-87a1-655d113f8f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([  62, 3567, 3817,  740,  464, 3583, 2516, 1286,  783,  359])>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores, action_anns = scann(test_embed.numpy())\n",
    "action_anns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa2b179-04df-4fe4-bdc4-7b3e8efde69b",
   "metadata": {},
   "source": [
    "## Agent\n",
    "\n",
    "`sampled_softmax_num_negatives`\n",
    "* Number of `negative` actions used to compute the sampled_softmax loss. \n",
    "* if None, regular softmax will be used instead of sampled_softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d14d1065-25bf-43e2-809e-6fce77cc162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "from src.agents import topk_reinforce_agent as topk_reinforce_agent\n",
    "\n",
    "from src.agents import offline_evaluation as offline_evaluation\n",
    "from src.agents import offline_metrics as offline_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5de0fe6b-0596-4299-be11-b6272128fabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k actions recommended by policy\n",
    "policy_num_actions=5\n",
    "\n",
    "# number of actions with highest Q value\n",
    "num_greedy_actions=4\n",
    "\n",
    "# Number of actions to retrieve using SCANN in the policy. \n",
    "#   A softmax is computed on this reduced set instead of the whole\n",
    "#   vocabulary to improve efficiency\n",
    "# None == all actions used to compute the softmax\n",
    "scann_num_candidate_actions=None\n",
    "\n",
    "# Number of `negative` actions used to compute the sampled_softmax loss\n",
    "# None == regular softmax\n",
    "sampled_softmax_num_negatives=None\n",
    "\n",
    "# If True, trains main policy using supervised loss equal to \n",
    "# the negative log probability of actions, instead of 'Off Policy REINFORCE loss'\n",
    "# useful for debugging, e.g. can model mimick the dataset behavior?\n",
    "use_supervised_loss_for_main_policy=False\n",
    "\n",
    "# The K used in the off policy correction to compute alpha\n",
    "# (Section 4.3 of paper). None == no off-policy correction applied\n",
    "off_policy_correction_exponent=None\n",
    "\n",
    "GAMMA=0.9\n",
    "SUMMARIZE_GRADS_AND_VARS=True\n",
    "DEBUG_SUMMARIES=False # TODO: error with summary stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "883414de-0bb1-4b4c-b91a-161e18c7f836",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_agent = topk_reinforce_agent.TopKOffPolicyReinforceAgent(\n",
    "    time_step_spec=time_step_spec,\n",
    "    action_spec=action_spec,\n",
    "    state_embedding_network=state_embedding_network,\n",
    "    optimizer=optimizer,\n",
    "    off_policy_correction_exponent=off_policy_correction_exponent,\n",
    "    action_lookup_layer=action_lookup_layer,                  # action_lookup_layer | None\n",
    "    inverse_action_lookup_layer=inverse_action_lookup_layer,  # inverse_action_lookup_layer | None\n",
    "    policy_num_actions=policy_num_actions,\n",
    "    use_supervised_loss_for_main_policy=use_supervised_loss_for_main_policy,\n",
    "    num_candidate_actions=scann_num_candidate_actions,\n",
    "    num_greedy_actions=policy_num_actions,\n",
    "    sampled_softmax_num_negatives=sampled_softmax_num_negatives,\n",
    "    train_step_counter=global_step,\n",
    "    gamma=GAMMA,\n",
    "    summarize_grads_and_vars=SUMMARIZE_GRADS_AND_VARS,\n",
    "    debug_summaries=DEBUG_SUMMARIES,\n",
    "    name='TopKOffPolicyReinforceAgent'\n",
    ")\n",
    "\n",
    "tf_agent.initialize()\n",
    "\n",
    "train_checkpointer = common.Checkpointer(\n",
    "    ckpt_dir=CHECKPT_DIR,\n",
    "    agent=tf_agent,\n",
    "    global_step=global_step\n",
    ")\n",
    "\n",
    "policy_checkpointer = common.Checkpointer(\n",
    "    ckpt_dir=os.path.join(CHECKPT_DIR, 'policy'),\n",
    "    policy=tf_agent.policy,\n",
    "    global_step=global_step\n",
    ")\n",
    "\n",
    "train_checkpointer.initialize_or_restore()\n",
    "\n",
    "evaluate = offline_evaluation.evaluate\n",
    "# evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a377d673-b8f3-404e-8e93-0ac0173f0923",
   "metadata": {},
   "source": [
    "**summary writers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5531d5b7-be53-4953-9bec-e7ea51c9137c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.expanduser(LOG_DIR)\n",
    "train_log_dir = os.path.join(log_dir, 'train')\n",
    "eval_log_dir = os.path.join(log_dir, 'eval')\n",
    "\n",
    "# summary writers\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    train_log_dir, flush_millis=10 * 1000\n",
    ")\n",
    "train_summary_writer.set_as_default()\n",
    "\n",
    "eval_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    eval_log_dir, flush_millis=10 * 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4eeb6d-806a-422b-a023-a2f37560ccce",
   "metadata": {},
   "source": [
    "**helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "65b6c35c-9887-433c-b3ca-0d5140af0eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_tf_functions= True\n",
    "sequence_length=10\n",
    "train_batch_size=64 # 64 | 5\n",
    "eval_batch_size=64 # 64 | 5\n",
    "num_eval_batches=10\n",
    "\n",
    "# if use_tf_functions:\n",
    "#     \"\"\"\n",
    "#     TODO: Currently wrapping evaluate in tf.function does not\n",
    "#       work because creating a new scann index in\n",
    "#       tf_agent.post_process_policy() seems to create new variables.\n",
    "      \n",
    "#     Moving the index() into the tf.function doesn't seem to work either. \n",
    "#       Currently this is not a huge blocker since eval only takes 5 seconds\n",
    "#     \"\"\"\n",
    "#     tf_agent.train = common.function(tf_agent.train)\n",
    "\n",
    "tf_agent.train = common.function(tf_agent.train)\n",
    "# ====================================================\n",
    "# create datasets\n",
    "# ====================================================\n",
    "process_example_fn = functools.partial(\n",
    "    example_proto_to_trajectory,\n",
    "    sequence_length=sequence_length\n",
    ")\n",
    "\n",
    "train_dataset = create_tfrecord_ds(\n",
    "    tf.io.gfile.glob(train_files),\n",
    "    num_shards=len(train_files),\n",
    "    process_example_fn=process_example_fn,\n",
    "    batch_size=train_batch_size\n",
    ")\n",
    "train_dataset_iterator = iter(train_dataset)\n",
    "\n",
    "eval_dataset = create_tfrecord_ds(\n",
    "    tf.io.gfile.glob(val_files),\n",
    "    process_example_fn=process_example_fn,\n",
    "    batch_size=eval_batch_size,\n",
    "    num_shards=len(val_files),\n",
    "    repeat=False,\n",
    "    drop_remainder=True\n",
    ")\n",
    "\n",
    "offline_eval_metrics = [\n",
    "    offline_metrics.AccuracyAtK(),\n",
    "    offline_metrics.AveragePerClassAccuracyAtK(\n",
    "        action_vocab_size, action_lookup=action_lookup_layer\n",
    "    ),\n",
    "    offline_metrics.WeightedReturns(\n",
    "        gamma=1.,\n",
    "        action_lookup=action_lookup_layer,\n",
    "        name='WeightedReturns_gamma_1'\n",
    "    ),\n",
    "    # offline_metrics.LastActionAccuracyAtK(),\n",
    "]\n",
    "        \n",
    "if num_eval_batches is not None:\n",
    "    eval_dataset = eval_dataset.take(num_eval_batches)\n",
    "    \n",
    "# ====================================================\n",
    "# metric summaries\n",
    "# ====================================================\n",
    "\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import export_utils\n",
    "\n",
    "def _export_metrics_and_summaries(step, metrics):\n",
    "    \"\"\"Exports metrics and tf summaries.\"\"\"\n",
    "    metric_utils.log_metrics(metrics)\n",
    "    export_utils.export_metrics(step=step, metrics=metrics)\n",
    "    for metric in metrics:\n",
    "        metric.tf_summaries(train_step=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228bdbed-a927-4b65-a50c-a956b5e41bac",
   "metadata": {},
   "source": [
    "## Train loop\n",
    "\n",
    "**tf_agent.train()**\n",
    "\n",
    "Args:\n",
    "* **experience**: A batch of experience data in the form of a `Trajectory`. The structure of `experience` must match that of `self.training_data_spec`. All tensors in `experience` must be shaped `[batch, time, ...]` where `time` must be equal to `self.train_step_length` if that property is not `None`.\n",
    "\n",
    "* **weights**: (optional).  A `Tensor`, either `0-D` or shaped `[batch]`, containing weights to be used when calculating the total train loss. Weights are typically multiplied elementwise against the per-batch loss, but the implementation is up to the Agent.\n",
    "\n",
    "[src](https://github.com/tensorflow/agents/blob/master/tf_agents/agents/tf_agent.py#L317C1-L326C51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "784111d1-9ab2-45db-9cce-9b5822b1e1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_iterations=10000\n",
    "\n",
    "eval_interval=num_iterations/4 # 2500\n",
    "log_interval=num_iterations/10 # 1000\n",
    "summary_interval=100\n",
    "\n",
    "train_checkpoint_interval=15000\n",
    "policy_checkpoint_interval=15000\n",
    "\n",
    "distribution_strategy = strategy_utils.get_strategy(\n",
    "    tpu=False, use_gpu=False\n",
    ")\n",
    "\n",
    "# global_step\n",
    "# tf_agent.training_data_spec\n",
    "# tf_agent.train_step_counter\n",
    "# weights.shape\n",
    "\n",
    "tf_agent.train_step_counter.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b47d37d8-e518-49b0-858c-1cf7cc3b3dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 1000, loss = 101.20748138427734\n",
      "20.579 steps/sec\n",
      "step = 2000, loss = 100.63838195800781\n",
      "23.989 steps/sec\n",
      "Eval at step: 2500\n",
      "step = 3000, loss = 93.31059265136719\n",
      "24.639 steps/sec\n",
      "step = 4000, loss = 88.78363800048828\n",
      "21.327 steps/sec\n",
      "step = 5000, loss = 87.5472640991211\n",
      "28.082 steps/sec\n",
      "Eval at step: 5000\n",
      "step = 6000, loss = 90.53057861328125\n",
      "17.946 steps/sec\n",
      "step = 7000, loss = 85.6369857788086\n",
      "25.409 steps/sec\n",
      "Eval at step: 7500\n",
      "step = 8000, loss = 82.14510345458984\n",
      "23.562 steps/sec\n",
      "step = 9000, loss = 87.95433807373047\n",
      "25.57 steps/sec\n",
      "step = 10000, loss = 88.5186538696289\n",
      "25.126 steps/sec\n",
      "Eval at step: 10000\n",
      "total runtime : 0\n",
      "\n",
      "Offline eval metrics:\n",
      "AccuracyAtK  =  0.077083334\n",
      "\n",
      "Offline eval metrics:\n",
      "AveragePerClassAccuracyAtK  =  0.053954\n",
      "\n",
      "Offline eval metrics:\n",
      "WeightedReturns_gamma_1  =  -326.05273\n"
     ]
    }
   ],
   "source": [
    "list_o_loss=[]\n",
    "start_time = time.time()\n",
    "\n",
    "with tf.compat.v2.summary.record_if(\n",
    "    lambda: tf.math.equal(global_step % summary_interval, 0)\n",
    "):\n",
    "    timed_at_step = global_step.numpy()\n",
    "    time_acc = 0\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        traj_ex, weights_ex = next(train_dataset_iterator)\n",
    "        train_loss = tf_agent.train(\n",
    "            experience=traj_ex, weights=weights_ex\n",
    "        )\n",
    "        list_o_loss.append(train_loss.loss.numpy())\n",
    "        time_acc += time.time() - start_time\n",
    "\n",
    "        global_step_val = global_step.numpy()\n",
    "        if global_step_val % log_interval == 0:\n",
    "            print(f\"step = {global_step_val}, loss = {train_loss.loss}\")\n",
    "            steps_per_sec = (global_step_val - timed_at_step) / time_acc\n",
    "            \n",
    "            print(f\"{round(steps_per_sec,3)} steps/sec\")\n",
    "            tf.summary.scalar(\n",
    "                name='global_steps_per_sec', \n",
    "                data=steps_per_sec, \n",
    "                step=global_step\n",
    "            )\n",
    "            \n",
    "            timed_at_step = global_step_val\n",
    "            time_acc = 0\n",
    "\n",
    "        if global_step_val % train_checkpoint_interval == 0:\n",
    "            train_checkpointer.save(global_step=global_step_val)\n",
    "\n",
    "        if global_step_val % policy_checkpoint_interval == 0:\n",
    "            tf_agent.post_process_policy()\n",
    "            policy_checkpointer.save(global_step=global_step_val)\n",
    "\n",
    "        if global_step_val % eval_interval == 0:\n",
    "            tf_agent.post_process_policy()\n",
    "            print(f\"Eval at step: {global_step_val}\")\n",
    "            evaluate(\n",
    "                tf_agent.policy,\n",
    "                eval_dataset,\n",
    "                offline_eval_metrics=offline_eval_metrics,\n",
    "                train_step=global_step,\n",
    "                summary_writer=eval_summary_writer,\n",
    "                summary_prefix='Metrics',\n",
    "            )\n",
    "            metric_utils.log_metrics(offline_eval_metrics)\n",
    "                \n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"total runtime : {runtime_mins}\")\n",
    "\n",
    "for metric in offline_eval_metrics:\n",
    "    print(f\"\\nOffline eval metrics:\")\n",
    "    print(metric.name, ' = ', metric.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f44095ed-1624-4cd3-9b43-5754c173312a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<src.agents.offline_metrics.AccuracyAtK at 0x7f86318ff220>,\n",
       " <src.agents.offline_metrics.AveragePerClassAccuracyAtK at 0x7f86e7917100>,\n",
       " <src.agents.offline_metrics.WeightedReturns at 0x7f8633356c50>]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offline_eval_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5597142e-fbbe-4a65-a016-79d8f5ae275d",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "notes:\n",
    "* Accuracy metrics are suspicious, since the RNN model is trained to maximize Accuracy\n",
    "* Offline metrics may not be very reliable for `Top-K Off-Policy Correction`\n",
    "\n",
    "**TODO**\n",
    "* adding a small positive reward for time steps without clicks: will help REINFORCE accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "72f0a0ae-2767-4998-b6e1-8296031f671f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_o_loss)\n",
    "# plt.ylim([0, 10])\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd4c511-6b36-4984-af2d-45e1f6928883",
   "metadata": {},
   "source": [
    "## TensorBoard\n",
    "\n",
    "**TODO:**\n",
    "* investigate `Losses/regularization_loss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e5af3972-33b5-4569-92f3-173d67799bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "74b756de-aad5-4a46-a192-45412ecb8c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7cb6f478671da8c7\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7cb6f478671da8c7\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=$train_log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "02d816e9-ac13-4448-8fa5-1adb7aa0b73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cf5cf6f9fc615d06\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cf5cf6f9fc615d06\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %tensorboard --logdir=$eval_log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "6165aeb5-810a-4154-a6ea-91a96bea291e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://rec-bandits-v2-hybrid-vertex-bucket/topk-op-reinforce-v3/run-20240705-183532/logs/eval'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "881587d7-ad7e-4915-8b53-ed78bf66fe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard import notebook\n",
    "# notebook.list() # View open TensorBoard instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc73fdb-c649-42fb-8eb9-e5baed7dbbd8",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac247f6-8722-4851-a49f-da4fe88543d3",
   "metadata": {},
   "source": [
    "Create an inference dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a3be02d2-e4b8-4525-98f0-7c3beaa3f8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'action': <tf.Tensor: shape=(1, 10), dtype=int64, numpy=array([[2162, 2356, 1599, 2043, 1683,   21, 3178, 1629, 2536,    0]])>,\n",
       " 'discount': <tf.Tensor: shape=(1, 10), dtype=float32, numpy=array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)>,\n",
       " 'next_step_type': <tf.Tensor: shape=(1, 10), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>,\n",
       " 'observation': <tf.Tensor: shape=(1, 10), dtype=int64, numpy=array([[2883, 2162, 2356, 1599, 2043, 1683,   21, 3178, 1629,    0]])>,\n",
       " 'policy_info': (),\n",
       " 'reward': <tf.Tensor: shape=(1, 10), dtype=float32, numpy=array([[3., 2., 3., 3., 2., 3., 3., 3., 3., 0.]], dtype=float32)>,\n",
       " 'step_type': <tf.Tensor: shape=(1, 10), dtype=int32, numpy=array([[0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_dataset = create_tfrecord_ds(\n",
    "    tf.io.gfile.glob(val_files),\n",
    "    process_example_fn=process_example_fn,\n",
    "    batch_size=1,\n",
    "    num_shards=len(val_files),\n",
    "    repeat=False,\n",
    "    drop_remainder=True\n",
    ")\n",
    "infer_batch = list(inference_dataset.take(1))[0]\n",
    "traj_infer, weights_infer = infer_batch\n",
    "\n",
    "traj_infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ce4f94d4-400c-4dd4-9283-268edc9d4b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=array([[0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_infer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c315bd46-4da1-4d95-a8f9-c9ade00981de",
   "metadata": {},
   "source": [
    "Check initial policy state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4d1c4795-a5bc-472f-814a-94f4b29e91c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((ListWrapper([<tf.Tensor: shape=(1, 25), dtype=float32, numpy=\n",
       "  array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>, <tf.Tensor: shape=(1, 25), dtype=float32, numpy=\n",
       "  array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>]),),)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_state = tf_agent.policy.get_initial_state(traj_infer.step_type.shape[0])\n",
    "policy_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf84f80b-e200-4755-a0f3-c6bbfc60362c",
   "metadata": {},
   "source": [
    "Generate predictions for each step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ac80d4bb-e6ce-44e4-a765-3934eb6013c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_infer.step_type.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c892c1bc-897b-4add-86cb-2af45276ed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_actions = []\n",
    "\n",
    "for i in tf.range(traj_infer.step_type.shape[1]):\n",
    "\n",
    "    observation = traj_infer.observation[:, i, tf.newaxis]\n",
    "    step_type = traj_infer.step_type[:, i, tf.newaxis]\n",
    "    time_step = ts.TimeStep(\n",
    "        step_type=step_type,\n",
    "        observation=observation,\n",
    "        reward=tf.zeros_like(step_type, tf.float32),\n",
    "        discount=tf.ones_like(step_type, tf.float32)\n",
    "    )\n",
    "\n",
    "    action_step = tf_agent.policy.action(time_step, policy_state)\n",
    "    policy_state = action_step.state\n",
    "    predicted_actions.append(action_step.action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bf4c18e3-49bf-4674-ad65-6df448d7fd8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[2693, 2789,   49,  315,  604]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[ 583, 2433, 3105,  373,  450]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[ 450,  583, 1349,  373, 2284]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[1349,  450, 1076,  821, 2284]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[1349,  450, 1556, 1076,  821]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[1349,  450,  821, 1556, 2284]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[1349,  450, 1076, 1556,  821]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[1556,  289,  642, 2548,  163]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[1556,  289,  163,  642,  349]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[2789, 2693,  315,  604, 2637]])>]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0a09e2-40b1-4987-956e-15a813ba51ad",
   "metadata": {},
   "source": [
    "Check policy state now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4fd950cc-9141-4667-a6f4-6921b86aaf62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((ListWrapper([<tf.Tensor: shape=(1, 25), dtype=float32, numpy=\n",
       "  array([[-0.7484138 ,  0.19372712,  0.5921234 , -0.57588005, -0.6844855 ,\n",
       "          -0.79630375, -0.5653781 ,  0.24615856, -0.6151467 , -0.56063604,\n",
       "           0.01741177,  0.48123392, -0.82364273,  0.98732215, -0.8676344 ,\n",
       "          -0.27626175, -0.7467131 ,  0.6265718 , -0.25906453,  0.37298143,\n",
       "          -0.9261556 ,  0.98191893, -0.6693175 , -0.04156195,  0.33841226]],\n",
       "        dtype=float32)>, <tf.Tensor: shape=(1, 25), dtype=float32, numpy=\n",
       "  array([[-0.97043747,  0.19622353,  0.76474845, -0.6599766 , -0.8375094 ,\n",
       "          -1.0965753 , -0.6407037 ,  0.25140598, -0.7176708 , -1.6798137 ,\n",
       "           0.02337722,  0.52549624, -1.4815497 ,  2.5278895 , -1.3242636 ,\n",
       "          -0.30144513, -0.9660466 ,  0.73578143, -0.26525006,  0.39432064,\n",
       "          -1.6311901 ,  6.822153  , -0.81009424, -0.0415861 ,  0.3523361 ]],\n",
       "        dtype=float32)>]),),)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_step.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "39d44c29-5671-42ed-af28-a066e6007350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10, 1), dtype=int64, numpy=\n",
       "array([[[2162],\n",
       "        [2356],\n",
       "        [1599],\n",
       "        [2043],\n",
       "        [1683],\n",
       "        [  21],\n",
       "        [3178],\n",
       "        [1629],\n",
       "        [2536],\n",
       "        [   0]]])>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_actions = tf.expand_dims(traj_infer.action, axis=2)\n",
    "observed_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e2d341d0-af98-4d03-b09d-8e165c5ff8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10, 5), dtype=int64, numpy=\n",
       "array([[[2693, 2789,   49,  315,  604],\n",
       "        [ 583, 2433, 3105,  373,  450],\n",
       "        [ 450,  583, 1349,  373, 2284],\n",
       "        [1349,  450, 1076,  821, 2284],\n",
       "        [1349,  450, 1556, 1076,  821],\n",
       "        [1349,  450,  821, 1556, 2284],\n",
       "        [1349,  450, 1076, 1556,  821],\n",
       "        [1556,  289,  642, 2548,  163],\n",
       "        [1556,  289,  163,  642,  349],\n",
       "        [2789, 2693,  315,  604, 2637]]])>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_actions_stacked = tf.stack(predicted_actions, axis=1)\n",
    "predicted_actions_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "58dd883e-ef68-45ee-8ead-6278245782ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=bool, numpy=\n",
       "array([[False, False, False, False, False, False, False, False, False,\n",
       "        False]])>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_predictions = tf.reduce_any(\n",
    "    predicted_actions_stacked == observed_actions, axis=2\n",
    ")\n",
    "correct_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "43e33ae8-1abb-42ae-aa52-4881122ef3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Predictions:\n",
      "tf.Tensor([[False False False False False False False False False False]], shape=(1, 10), dtype=bool)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Correct Predictions:')\n",
    "print(correct_predictions)\n",
    "print('-' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "57266671-f235-4d0c-9478-31ea97fffc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed Actions (vocab):\n",
      "tf.Tensor([[2163 2357 1600 2044 1684   22 3179 1630 2537    1]], shape=(1, 10), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print('Observed Actions (vocab):')\n",
    "print(action_lookup_layer(traj_infer.action))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ad96878b-0843-4f8b-b98e-bed238ddaab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Actions (vocab):\n",
      "tf.Tensor(\n",
      "[[[2694 2790   50  316  605]]\n",
      "\n",
      " [[ 584 2434 3106  374  451]]\n",
      "\n",
      " [[ 451  584 1350  374 2285]]\n",
      "\n",
      " [[1350  451 1077  822 2285]]\n",
      "\n",
      " [[1350  451 1557 1077  822]]\n",
      "\n",
      " [[1350  451  822 1557 2285]]\n",
      "\n",
      " [[1350  451 1077 1557  822]]\n",
      "\n",
      " [[1557  290  643 2549  164]]\n",
      "\n",
      " [[1557  290  164  643  350]]\n",
      "\n",
      " [[2790 2694  316  605 2638]]], shape=(10, 1, 5), dtype=int64)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Predicted Actions (vocab):')\n",
    "print(action_lookup_layer(predicted_actions))\n",
    "print('-' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b3965378-17d6-44c9-a57e-ccb8eeca029c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed Actions (raw):\n",
      "tf.Tensor([[2162 2356 1599 2043 1683   21 3178 1629 2536    0]], shape=(1, 10), dtype=int64)\n",
      "--------------------------------------------------------------------------------\n",
      "Predicted Actions (raw):\n",
      "[<tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[2693, 2789,   49,  315,  604]])>, <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[ 583, 2433, 3105,  373,  450]])>, <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[ 450,  583, 1349,  373, 2284]])>, <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[1349,  450, 1076,  821, 2284]])>, <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[1349,  450, 1556, 1076,  821]])>, <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[1349,  450,  821, 1556, 2284]])>, <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[1349,  450, 1076, 1556,  821]])>, <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[1556,  289,  642, 2548,  163]])>, <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[1556,  289,  163,  642,  349]])>, <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[2789, 2693,  315,  604, 2637]])>]\n"
     ]
    }
   ],
   "source": [
    "print('Observed Actions (raw):')\n",
    "print(traj_infer.action)\n",
    "print('-' * 80)\n",
    "print('Predicted Actions (raw):')\n",
    "print(predicted_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4a220b-60f5-4376-83fa-9efc0b1bb1e1",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Notes n stash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39b3f3a-c564-4e3e-94b3-311c6a386926",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Experiment ideas\n",
    "\n",
    "**Create experiment comparing:**\n",
    "\n",
    "[1] rnn\n",
    "* off_policy_correction_exponent = None\n",
    "* use_supervised_loss_for_main_policy = True\n",
    "\n",
    "[2] REINFORCE\n",
    "* off_policy_correction_exponent = None\n",
    "* use_supervised_loss_for_main_policy = False\n",
    "\n",
    "[3] topk REINFORCE\n",
    "* off_policy_correction_exponent = ~16\n",
    "* use_supervised_loss_for_main_policy = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7752fb7-2134-47ef-9013-3a2797b1e98c",
   "metadata": {},
   "source": [
    "## synthetic data for tutorial/demo\n",
    "\n",
    "Create dummy item IDs and embeddings like [src](https://www.tensorflow.org/recommenders/examples/efficient_serving#tuning_scann)\n",
    "\n",
    "```\n",
    "# Construct a dataset of movies that's 1,000 times larger. We \n",
    "# do this by adding several million dummy movie titles to the dataset.\n",
    "lots_of_movies = tf.data.Dataset.concatenate(\n",
    "    movies.batch(4096),\n",
    "    movies.batch(4096).repeat(1_000).map(lambda x: tf.zeros_like(x))\n",
    ")\n",
    "\n",
    "# We also add lots of dummy embeddings by randomly perturbing\n",
    "# the estimated embeddings for real movies.\n",
    "lots_of_movies_embeddings = tf.data.Dataset.concatenate(\n",
    "    movies.batch(4096).map(model.movie_model),\n",
    "    movies.batch(4096).repeat(1_000)\n",
    "      .map(lambda x: model.movie_model(x))\n",
    "      .map(lambda x: x * tf.random.uniform(tf.shape(x)))\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4fdf9e-25fa-463e-ae4a-f30f59ef29ae",
   "metadata": {},
   "source": [
    "#### TODO: optimize train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f856c61-bf1f-49a7-8139-726dda59a8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@common.function(autograph=False)\n",
    "def _train_step_fn(data):\n",
    "    \n",
    "    # trajectory, weights = data\n",
    "\n",
    "    def replicated_train_step(experience):\n",
    "        return tf_agent.train(experience).loss\n",
    "\n",
    "    per_replica_losses = distribution_strategy.run(\n",
    "        replicated_train_step, \n",
    "        args=(data,)\n",
    "    )\n",
    "\n",
    "    # return agent.train(experience=trajectories).loss\n",
    "    return distribution_strategy.reduce(\n",
    "        tf.distribute.ReduceOp.MEAN, \n",
    "        per_replica_losses, # loss, \n",
    "        axis=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b5bd54-b113-4b99-84ad-9890dcc14b2e",
   "metadata": {},
   "source": [
    "#### TODO: record summary within scope?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c279d482-177e-480f-80b0-44370ddbfa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.compat.v2.summary.record_if(\n",
    "#     lambda: tf.math.equal(global_step % summary_interval, 0)):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6974c692-c031-4bfb-905c-6e3ab4265097",
   "metadata": {},
   "source": [
    "```\n",
    "    @common.function(autograph=False)\n",
    "    def _train_step_fn(data):\n",
    "        \n",
    "        def replicated_train_step(experience):\n",
    "            return agent.train(experience).loss\n",
    "        \n",
    "        trajectories = _trajectory_fn(data)\n",
    "\n",
    "        per_replica_losses = distribution_strategy.run(\n",
    "            replicated_train_step, \n",
    "            args=(trajectories,)\n",
    "        )\n",
    "\n",
    "        # return agent.train(experience=trajectories).loss\n",
    "        return distribution_strategy.reduce(\n",
    "            tf.distribute.ReduceOp.MEAN, \n",
    "            per_replica_losses, # loss, \n",
    "            axis=None\n",
    "        )\n",
    "        \n",
    "    ...\n",
    "    \n",
    "    loss = _train_step_fn(data)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7f3d1f-9268-4a9a-9a9f-f906e1352502",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
