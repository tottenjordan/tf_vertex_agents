{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cd3a873-bb85-40a2-882b-56fb85d74985",
   "metadata": {},
   "source": [
    "# REINFORCE agent for Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0a67cad-2c4a-47d2-942b-e5d9918316ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "VERSION        = \"v2\"                       # TODO\n",
    "PREFIX         = f'rec-bandits-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d211d666-4aae-4a2b-a94f-c3a5c99ac226",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"rec-bandits-v2\"\n",
      "VERSION                  = \"v2\"\n",
      "\n",
      "BUCKET_NAME              = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_NAME    = \"mvlens_rec_bandits_v2\"\n",
      "BIGQUERY_TABLE_NAME      = \"training_dataset\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-rec-bandits-v2\"\n",
      "\n",
      "DOCKERNAME_01            = \"Dockerfile_train_my_perarm_env\"\n",
      "IMAGE_NAME_01            = \"train-my-perarm-env-v2\"\n",
      "IMAGE_URI_01             = \"gcr.io/hybrid-vertex/train-my-perarm-env-v2\"\n",
      "\n",
      "DOCKERNAME_02            = \"Dockerfile_perarm_feats\"\n",
      "IMAGE_NAME_02            = \"train-perarm-feats-v2\"\n",
      "IMAGE_URI_02             = \"gcr.io/hybrid-vertex/train-perarm-feats-v2\"\n",
      "\n",
      "DOCKERNAME_03            = \"Dockerfile_ranking_bandit\"\n",
      "IMAGE_NAME_03            = \"train-rank-bandit-v2\"\n",
      "IMAGE_URI_03             = \"gcr.io/hybrid-vertex/train-rank-bandit-v2\"\n",
      "\n",
      "DOCKERNAME_04            = \"Dockerfile_train_bandit_e2e\"\n",
      "IMAGE_NAME_04            = \"train-mab-e2e-v2\"\n",
      "IMAGE_URI_04             = \"gcr.io/hybrid-vertex/train-mab-e2e-v2\"\n",
      "\n",
      "DOCKERNAME_04_pred       = \"Dockerfile_pred_bandit_e2e\"\n",
      "IMAGE_NAME_04_pred       = \"pred-mab-e2e-v2\"\n",
      "IMAGE_URI_04_pred        = \"gcr.io/hybrid-vertex/pred-mab-e2e-v2\"\n",
      "\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/local_docker_tfa\"\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8cf4a8-4564-46b7-8dc2-6b004804b62a",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb611af7-59b7-444c-9955-73359bb52764",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8899897-b685-417e-91f2-fcfa9f109cba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cudnn version      : 8\n",
      "cuda version       : 11.8\n",
      "Num GPUs Available : 1\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import functools\n",
    "import collections\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from pprint import pprint\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import build_info\n",
    "\n",
    "# tf-agents\n",
    "from tf_agents.utils import common\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import sequential\n",
    "from tf_agents.metrics import export_utils\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.train.utils import strategy_utils\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "from tensorflow.python.platform import build_info\n",
    "print(f\"cudnn version      : {build_info.build_info['cudnn_version']}\")\n",
    "print(f\"cuda version       : {build_info.build_info['cuda_version']}\")\n",
    "print(f\"Num GPUs Available : {len(tf.config.list_physical_devices('GPU'))}\")\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "# this repo\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.utils import rfa_utils as rfa_utils\n",
    "from src.utils import train_utils as train_utils\n",
    "from src.data import data_utils as data_utils\n",
    "from src.data import data_config as data_config\n",
    "from src.networks import encoding_network as emb_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8972994-122c-45cc-8d2a-8af049d63ac8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49cd2f04-e8dd-4fa9-bf51-4c789fa3c692",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "print(f\"device: {device.name.decode()}\")\n",
    "\n",
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75586449-2060-4f19-ab34-7430d1ad4ba7",
   "metadata": {},
   "source": [
    "# Data utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58b4ae26-dd0c-4297-8efa-e40bc52d8cb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_CONTEXT_LENGTH: 10\n",
      "GCS_DATA_PATH: gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m\n"
     ]
    }
   ],
   "source": [
    "data_config.MAX_CONTEXT_LENGTH\n",
    "print(f\"MAX_CONTEXT_LENGTH: {data_config.MAX_CONTEXT_LENGTH}\")\n",
    "\n",
    "EXAMPLE_GEN_GCS_PATH = data_config.EXAMPLE_GEN_GCS_PATH\n",
    "GCS_DATA_PATH = f\"{BUCKET_URI}/{EXAMPLE_GEN_GCS_PATH}\"\n",
    "\n",
    "print(f\"GCS_DATA_PATH: {GCS_DATA_PATH}\")\n",
    "# !gsutil ls $GCS_DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7761500-f394-40b8-97b5-2c10179ce10e",
   "metadata": {},
   "source": [
    "## TF Example to Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b4dbcc1-429e-4125-a741-e9e473521b65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def example_proto_to_trajectory(\n",
    "    example_proto, # sequence_feature,\n",
    "    sequence_length: int\n",
    "):\n",
    "    \"\"\"\n",
    "    Converts a sequence example to a Trajectory and weights for training.\n",
    "\n",
    "    For now, we are using the following simplified features. At every point in\n",
    "    time, the `context_movie_id` field in the sequence is the action and the `context_movie_id`\n",
    "    at the previous time step (last action) is the observation. The `context_movie_rating` field\n",
    "    is converted to a binary reward.\n",
    "\n",
    "    If the sequence example is longer than than `sequence_length`, we only take\n",
    "    the last part of the sequence example. If it is shorter, we pad it with dummy\n",
    "    values at the end to equal `sequence_length`.\n",
    "\n",
    "    Args:\n",
    "    sequence_feature: A serialized SequenceExample to convert to a\n",
    "      trajectory.\n",
    "    sequence_length: The time dimension of the returned trajectory.\n",
    "\n",
    "    Returns:\n",
    "    trajectory: An unbatched trajectory. The time dimension will be equal to\n",
    "      sequence length. The agent assumes that this trajectory is a single\n",
    "      episode, so `trajectory.step_type` and `trajectory.discount` are ignored.\n",
    "    weights: A [T] float tensor of weights. Each row of `weights`\n",
    "        (along the time dimension) is usually a sequence of 0's, followed by\n",
    "        a sequence of 1's, again followed by a sequence of 0's. This divides\n",
    "        the trajectory into 3 parts. The first part is used to warm start\n",
    "        the state embedding network. The second part is used to compute\n",
    "        losses. Returns are computed using the second and third parts.\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_description = {\n",
    "        'context_movie_id': tf.io.FixedLenFeature(shape=(data_config.MAX_CONTEXT_LENGTH), dtype=tf.string),\n",
    "        'context_movie_rating': tf.io.FixedLenFeature(shape=(data_config.MAX_CONTEXT_LENGTH), dtype=tf.float32),\n",
    "    }\n",
    "    \n",
    "    sequence_feature = tf.io.parse_single_sequence_example(example_proto, feature_description)\n",
    "    \n",
    "    context_id_int = tf.strings.to_number(\n",
    "        sequence_feature[0]['context_movie_id'],\n",
    "        out_type=tf.dtypes.int64,\n",
    "        name=None\n",
    "    )\n",
    "    \n",
    "    sequence_feature[0]['context_movie_id'] = context_id_int\n",
    "    actions = sequence_feature[0]['context_movie_id'][-sequence_length:]\n",
    "    rewards = sequence_feature[0]['context_movie_rating'][-sequence_length:]\n",
    "    observations = sequence_feature[0]['context_movie_id'][-(sequence_length+1):-1]\n",
    "\n",
    "    # actual length\n",
    "    actual_sequence_length = tf.shape(observations)[0]\n",
    "    \n",
    "    actions = actions[-actual_sequence_length:]\n",
    "    rewards = rewards[-actual_sequence_length:]\n",
    "\n",
    "    # padding\n",
    "    paddings = tf.stack([0, sequence_length - actual_sequence_length])\n",
    "    paddings = tf.expand_dims(paddings, 0)\n",
    "\n",
    "    rewards = tf.pad(rewards, paddings, 'CONSTANT', constant_values=0)\n",
    "    actions = tf.pad(actions, paddings, 'CONSTANT', constant_values=0)\n",
    "    observations = tf.pad(observations, paddings, 'CONSTANT', constant_values=0)\n",
    "\n",
    "    # steps & discounts\n",
    "    discounts = tf.ones((sequence_length,), dtype=tf.float32)\n",
    "    next_step_types = tf.ones(\n",
    "      (sequence_length,), dtype=tf.int32) * ts.StepType.MID\n",
    "    step_types = tf.concat([[ts.StepType.FIRST], next_step_types[1:]], axis=0)\n",
    "\n",
    "    # build trajectory\n",
    "    traj = trajectory.Trajectory(\n",
    "        step_type=step_types,\n",
    "        observation=observations,\n",
    "        action=actions,\n",
    "        policy_info=(),\n",
    "        next_step_type=next_step_types,\n",
    "        reward=rewards,\n",
    "        discount=discounts\n",
    "    )\n",
    "\n",
    "    # get importance weights\n",
    "    section_size = tf.cast(actual_sequence_length / 3, tf.int32)\n",
    "    # print(f\"section_size: {section_size}\")\n",
    "    \n",
    "    weights = tf.concat(\n",
    "        [\n",
    "            tf.zeros((section_size,)),\n",
    "            tf.ones((section_size,)),\n",
    "            tf.zeros((sequence_length - 2 * section_size,))\n",
    "        ], \n",
    "        axis=0\n",
    "    )\n",
    "    \n",
    "    return traj, weights # sequence_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcefdbe-e7dd-4e77-8ae7-ee0c92a3ea5d",
   "metadata": {},
   "source": [
    "## Create TF Record Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c601729-0a08-4832-b743-163611b64934",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_single_tfrecord_ds(\n",
    "    filename,\n",
    "    process_example_fn,\n",
    "    shuffle_buffer_size = 1,\n",
    "):\n",
    "    raw_ds = tf.data.TFRecordDataset(filename)\n",
    "    \n",
    "    ds = raw_ds.map(\n",
    "        process_example_fn,\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    ds = ds.shuffle(shuffle_buffer_size)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acabf6e4-0f2d-4b4c-ad98-863b22962f49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_tfrecord_ds(\n",
    "    filenames,\n",
    "    process_example_fn,\n",
    "    batch_size: int,\n",
    "    shuffle_buffer_size_per_record: int = 1,\n",
    "    shuffle_buffer_size: int = 10000,\n",
    "    num_shards: int = 50,\n",
    "    cycle_length: int = tf.data.AUTOTUNE,\n",
    "    block_length: int = 10,\n",
    "    num_prefetch: int = 10,\n",
    "    num_parallel_calls: int = 10,\n",
    "    repeat: bool = True,\n",
    "    drop_remainder: bool = False\n",
    "):\n",
    "    filenames = list(filenames)\n",
    "    initial_len = len(filenames)\n",
    "    remainder = initial_len % num_shards\n",
    "    \n",
    "    for _ in range(num_shards - remainder):\n",
    "        filenames.append(\n",
    "            filenames[np.random.randint(low=0, high=initial_len)]\n",
    "        )\n",
    "        \n",
    "    filenames = np.array(filenames)\n",
    "    np.random.shuffle(filenames)\n",
    "    filenames = np.array_split(filenames, num_shards)\n",
    "    filename_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "    \n",
    "    if repeat:\n",
    "        filename_ds = filename_ds.repeat()\n",
    "    \n",
    "    filename_ds = filename_ds.shuffle(len(filenames))\n",
    "    \n",
    "    example_ds = filename_ds.interleave(\n",
    "        functools.partial(\n",
    "            create_single_tfrecord_ds,\n",
    "            process_example_fn=process_example_fn,\n",
    "            shuffle_buffer_size=shuffle_buffer_size_per_record,\n",
    "        ),\n",
    "        cycle_length=tf.data.AUTOTUNE,\n",
    "        block_length=block_length,\n",
    "        num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    )\n",
    "    example_ds = example_ds.shuffle(shuffle_buffer_size)\n",
    "    \n",
    "    example_ds = example_ds.batch(\n",
    "        batch_size, drop_remainder=drop_remainder\n",
    "    ).prefetch(num_prefetch)\n",
    "  \n",
    "    return example_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21500739-1321-47ab-b168-d648773755ad",
   "metadata": {},
   "source": [
    "## Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a87c02ee-3551-40aa-93dc-56a9db4d1d8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab...\n",
      "Downloaded vocab from: gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/vocabs/vocab_dict.pkl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Downloading vocab...\")\n",
    "EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{EXAMPLE_GEN_GCS_PATH}/vocabs/{VOCAB_FILENAME}'\n",
    "os.system(f'gsutil -q cp {EXISTING_VOCAB_FILE} .')\n",
    "print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "vocab_dict = pkl.load(filehandler)\n",
    "filehandler.close()\n",
    "\n",
    "# for key in vocab_dict.keys():\n",
    "#     pprint(key)\n",
    "\n",
    "# vocab_dict['movie_id']\n",
    "vocab_dict_decoded = [z.decode(\"utf-8\") for z in vocab_dict['movie_id']]\n",
    "vocab_dict_decoded.remove(\"UNK\")\n",
    "vocab_dict_decoded = tf.strings.to_number(\n",
    "    vocab_dict_decoded,\n",
    "    out_type=tf.dtypes.int64,\n",
    "    name=None\n",
    ")\n",
    "vocab_dict_decoded = vocab_dict_decoded.numpy()\n",
    "\n",
    "# update vocab_dict\n",
    "vocab_dict['movie_id_int'] = vocab_dict_decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ef3114-ffc2-47ba-ae4c-29994fc42324",
   "metadata": {},
   "source": [
    "## Lookup layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60fe8e15-877d-4995-9929-ff74255c2136",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_vocab_size : 3884\n",
      "obs_vocab_size    : 3884\n"
     ]
    }
   ],
   "source": [
    "action_lookup_layer = tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=vocab_dict['movie_id_int'], \n",
    "    mask_value=None\n",
    ")\n",
    "\n",
    "inverse_action_lookup_layer = tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=action_lookup_layer.get_vocabulary(), \n",
    "    mask_value=None,\n",
    "    invert=True\n",
    ")\n",
    "\n",
    "action_vocab_size = action_lookup_layer.vocab_size() # 3885\n",
    "\n",
    "# if observations are just past actions:\n",
    "observation_lookup_layer = tf.keras.layers.IntegerLookup(\n",
    "    vocabulary=vocab_dict['movie_id_int'], \n",
    "    mask_value=None\n",
    ")\n",
    "\n",
    "obs_vocab_size = observation_lookup_layer.vocab_size()\n",
    "\n",
    "print(f\"action_vocab_size : {action_vocab_size}\")\n",
    "print(f\"obs_vocab_size    : {obs_vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68abee01-bfb5-49dd-a00c-8fa1a2337162",
   "metadata": {},
   "source": [
    "# Agent Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceb881c-9af1-4d57-abeb-df224d19f8a8",
   "metadata": {},
   "source": [
    "## TensorSpecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "785ba1e1-3bbe-46b3-8e3e-c404b8e52d08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "observation_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=[],\n",
    "    dtype=tf.int64, # tf.string | tf.int64,\n",
    "    minimum=0,\n",
    "    maximum=action_vocab_size - 1,\n",
    "    name='observation'\n",
    ")\n",
    "time_step_spec = ts.time_step_spec(observation_spec=observation_spec)\n",
    "\n",
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=[],\n",
    "    dtype=tf.int64, # tf.string | tf.int64,\n",
    "    minimum=0,\n",
    "    maximum=action_vocab_size - 1,\n",
    "    name='action'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc60779-91b7-4d54-8a81-236b5158b944",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21b742d4-3eca-45f8-9333-1fdf4e0002e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int64, name='observation', minimum=array(0), maximum=array(3883))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embedding_size=100\n",
    "input_fc_layer_params=(100, 100)\n",
    "lstm_size=(25,)\n",
    "output_fc_layer_params=(10,)\n",
    "\n",
    "state_embedding_network = rfa_utils.create_state_embedding_network(\n",
    "    observation_lookup_layer=observation_lookup_layer,\n",
    "    input_embedding_size=input_embedding_size,\n",
    "    input_fc_layer_units=input_fc_layer_params,\n",
    "    lstm_size=lstm_size,\n",
    "    output_fc_layer_units=output_fc_layer_params\n",
    ")\n",
    "\n",
    "time_step_spec.observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6617eba-2f76-4d90-a8a5-1b4d5a9f0a41",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e4ff23e-ac85-4bc0-a587-70f9cbd7bd53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "from src.agents import topk_reinforce_agent as topk_reinforce_agent\n",
    "\n",
    "from src.trainer import offline_evaluation as offline_evaluation\n",
    "from src.trainer import offline_metrics as offline_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e832f8a-3f65-45b6-9bc7-3eeaf7052dfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# k actions recommended by policy\n",
    "policy_num_actions=5\n",
    "\n",
    "# number of actions with highest Q value\n",
    "num_greedy_actions=4\n",
    "\n",
    "scann_num_candidate_actions=None\n",
    "sampled_softmax_num_negatives=None\n",
    "use_supervised_loss_for_main_policy=False\n",
    "off_policy_correction_exponent=None # None | 16\n",
    "\n",
    "GAMMA=0.5 # 0.9 | 0.5\n",
    "SUMMARIZE_GRADS_AND_VARS=False\n",
    "DEBUG_SUMMARIES=False # TODO: error with summary stats\n",
    "\n",
    "distribution_strategy = strategy_utils.get_strategy(\n",
    "    tpu=False, use_gpu=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b78a3744-ffce-4d47-b174-46c2cd81d375",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step: 0\n"
     ]
    }
   ],
   "source": [
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "tf_agent = topk_reinforce_agent.TopKOffPolicyReinforceAgent(\n",
    "    time_step_spec=time_step_spec,\n",
    "    action_spec=action_spec,\n",
    "    state_embedding_network=state_embedding_network,\n",
    "    optimizer=optimizer,\n",
    "    off_policy_correction_exponent=off_policy_correction_exponent,\n",
    "    action_lookup_layer=action_lookup_layer,                  # action_lookup_layer | None\n",
    "    inverse_action_lookup_layer=inverse_action_lookup_layer,  # inverse_action_lookup_layer | None\n",
    "    policy_num_actions=policy_num_actions,\n",
    "    use_supervised_loss_for_main_policy=use_supervised_loss_for_main_policy,\n",
    "    num_candidate_actions=scann_num_candidate_actions,\n",
    "    num_greedy_actions=policy_num_actions,\n",
    "    sampled_softmax_num_negatives=sampled_softmax_num_negatives,\n",
    "    train_step_counter=global_step,\n",
    "    gamma=GAMMA,\n",
    "    summarize_grads_and_vars=SUMMARIZE_GRADS_AND_VARS,\n",
    "    debug_summaries=DEBUG_SUMMARIES,\n",
    "    name='TopKOffPolicyReinforceAgent'\n",
    ")\n",
    "\n",
    "tf_agent.initialize()\n",
    "\n",
    "print(f\"global step: {global_step.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f43ccf8e-8eb5-48d9-816b-95996dc1500e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " integer_lookup_2 (IntegerL  multiple                  0         \n",
      " ookup)                                                          \n",
      "                                                                 \n",
      " embedding (Embedding)       multiple                  388400    \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  10100     \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  10100     \n",
      "                                                                 \n",
      " dynamic_unroll (DynamicUnr  multiple                  12600     \n",
      " oll)                                                            \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 421460 (1.61 MB)\n",
      "Trainable params: 421460 (1.61 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "state_embedding_network.summary()\n",
    "\n",
    "# embedding = 3884 (obs vocab size) * INPUT_EMBEDDING_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7148025-b72a-4334-9d5c-8b62ff5b7f90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num train_files : 8\n",
      "num val_files   : 3\n"
     ]
    }
   ],
   "source": [
    "def get_filenames(\n",
    "    bucket_name,\n",
    "    prefix,\n",
    "    split,\n",
    "):\n",
    "    file_list = []\n",
    "    for blob in storage_client.list_blobs(\n",
    "        f\"{bucket_name}\", \n",
    "        prefix=f'{prefix}/{split}'\n",
    "    ):\n",
    "        if '.tfrecord' in blob.name:\n",
    "            file_list.append(\n",
    "                blob.public_url.replace(\n",
    "                    \"https://storage.googleapis.com/\", \"gs://\"\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    return file_list\n",
    "\n",
    "train_files = get_filenames(\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    prefix=EXAMPLE_GEN_GCS_PATH,\n",
    "    split=\"train\",\n",
    ")\n",
    "val_files = get_filenames(\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    prefix=EXAMPLE_GEN_GCS_PATH,\n",
    "    split=\"val\",\n",
    ")\n",
    "\n",
    "print(f'num train_files : {len(train_files)}')\n",
    "print(f'num val_files   : {len(val_files)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3ad26d5-8711-4f80-8dbf-79f088e5008b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval data size: 50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sequence_length  = data_config.MAX_CONTEXT_LENGTH # 10\n",
    "\n",
    "train_batch_size = 64  # 64 | 5 | 128\n",
    "eval_batch_size  = 64  # 64 | 5 | 128\n",
    "num_eval_batches = 50  # 10 | 1200\n",
    "\n",
    "# tf_agent.train = common.function(tf_agent.train)\n",
    "# ====================================================\n",
    "# create datasets\n",
    "# ====================================================\n",
    "process_example_fn = functools.partial(\n",
    "    example_proto_to_trajectory,\n",
    "    sequence_length=sequence_length\n",
    ")\n",
    "\n",
    "train_dataset = create_tfrecord_ds(\n",
    "    tf.io.gfile.glob(train_files),\n",
    "    num_shards=len(train_files),\n",
    "    process_example_fn=process_example_fn,\n",
    "    batch_size=train_batch_size\n",
    ")\n",
    "train_dataset_iterator = iter(train_dataset)\n",
    "\n",
    "eval_dataset = create_tfrecord_ds(\n",
    "    tf.io.gfile.glob(val_files),\n",
    "    process_example_fn=process_example_fn,\n",
    "    batch_size=eval_batch_size,\n",
    "    num_shards=len(val_files),\n",
    "    repeat=False,\n",
    "    drop_remainder=True\n",
    ")\n",
    "\n",
    "if num_eval_batches is not None:\n",
    "    eval_dataset = eval_dataset.take(num_eval_batches)\n",
    "    \n",
    "print(f\"eval data size: {len(list(eval_dataset))}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7032de7d-cef1-40e7-9745-482aac122a1c",
   "metadata": {},
   "source": [
    "### Eval metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7065764-5a33-46bf-8e2e-e96b1d36891d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<src.agents.offline_metrics.AccuracyAtK at 0x7eff3062b250>,\n",
       " <src.agents.offline_metrics.AveragePerClassAccuracyAtK at 0x7eff30629210>,\n",
       " <src.agents.offline_metrics.WeightedReturns at 0x7eff46027a90>,\n",
       " <src.agents.offline_metrics.WeightedReturns at 0x7eff46027520>,\n",
       " <src.agents.offline_metrics.AccuracyAtK at 0x7eff3062be80>,\n",
       " <src.agents.offline_metrics.AccuracyAtK at 0x7eff46027d00>,\n",
       " <src.agents.offline_metrics.AccuracyAtK at 0x7eff44385d20>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate = offline_evaluation.evaluate\n",
    "\n",
    "def non_oov_filter(trajectory):\n",
    "    \"\"\"Returns True for non OOV actions.\"\"\"\n",
    "    return action_lookup_layer(trajectory.action) != 0\n",
    "\n",
    "offline_eval_metrics = [\n",
    "    offline_metrics.AccuracyAtK(),\n",
    "    offline_metrics.AveragePerClassAccuracyAtK(\n",
    "        action_vocab_size, action_lookup=action_lookup_layer\n",
    "    ),\n",
    "    offline_metrics.WeightedReturns(\n",
    "        gamma=1.,\n",
    "        action_lookup=action_lookup_layer,\n",
    "        weight_by_probabilities=False,\n",
    "        name='WeightedReturnsLogProb_gamma_1'),\n",
    "    offline_metrics.WeightedReturns(\n",
    "        gamma=1.,\n",
    "        action_lookup=action_lookup_layer,\n",
    "        weight_by_probabilities=True,\n",
    "        name='WeightedReturnsProb_gamma_1'),\n",
    "    # offline_metrics.LastActionAccuracyAtK(),\n",
    "]\n",
    "\n",
    "for k in [1, 5, 10]: # policy_num_actions\n",
    "    offline_eval_metrics.append(\n",
    "        offline_metrics.AccuracyAtK(\n",
    "            trajectory_filter=non_oov_filter,\n",
    "            name='AccuracyAtK_' + str(k),\n",
    "            k=k\n",
    "        )\n",
    "    )\n",
    "#     offline_eval_metrics.append(\n",
    "#         offline_metrics.AveragePerClassAccuracyAtK(\n",
    "#             action_vocab_size,\n",
    "#             action_lookup=action_lookup_layer,\n",
    "#             trajectory_filter=non_oov_filter,\n",
    "#             name='AveragePerClassAccuracyAtK_' + str(k),\n",
    "#             k=k)\n",
    "#     )\n",
    "#     offline_eval_metrics.append(\n",
    "#         offline_metrics.LastActionAccuracyAtK(\n",
    "#             trajectory_filter=non_oov_filter,\n",
    "#             name='LastActionAccuracyAtK_' + str(k),\n",
    "#             k=k)\n",
    "#     )\n",
    "\n",
    "offline_eval_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e37c1d2-47ae-4ac3-8625-e6af8b449200",
   "metadata": {},
   "source": [
    "## Vertex Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c434c30-2353-4d80-ab37-f7d251f7d22f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EXP_VERSION=\"v16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27a66115-ae50-4b5e-8b38-5dad0272aba7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME : reinforce-local-v16\n",
      "RUN_NAME        : run-20241211-215732\n",
      "\n",
      "EXPERIMENT_DIR  : gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-local-v16\n",
      "CHECKPT_DIR     : gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-local-v16/chkpoint\n",
      "BASE_OUTPUT_DIR : gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-local-v16/run-20241211-215732\n",
      "LOG_DIR         : gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-local-v16/run-20241211-215732/logs\n",
      "ROOT_DIR        : gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-local-v16/run-20241211-215732/root\n",
      "ARTIFACTS_DIR   : gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-local-v16/run-20241211-215732/artifacts\n",
      "\n",
      "TRAIN_LOG_DIR   : gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-local-v16/run-20241211-215732/logs/train\n",
      "EVAL_LOG_DIR    : gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-local-v16/run-20241211-215732/logs/eval\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME   = f'reinforce-local-{EXP_VERSION}'\n",
    "\n",
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "EXPERIMENT_DIR    = os.path.join(BUCKET_URI, EXPERIMENT_NAME)\n",
    "CHECKPT_DIR       = os.path.join(EXPERIMENT_DIR, \"chkpoint\")\n",
    "BASE_OUTPUT_DIR   = os.path.join(EXPERIMENT_DIR, RUN_NAME)\n",
    "LOG_DIR           = os.path.join(BASE_OUTPUT_DIR, \"logs\")\n",
    "ROOT_DIR          = os.path.join(BASE_OUTPUT_DIR, \"root\")\n",
    "ARTIFACTS_DIR     = os.path.join(BASE_OUTPUT_DIR, \"artifacts\")\n",
    "\n",
    "TRAIN_LOG_DIR     = os.path.join(LOG_DIR, 'train')\n",
    "EVAL_LOG_DIR      = os.path.join(LOG_DIR, 'eval')\n",
    "\n",
    "print(f\"EXPERIMENT_NAME : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME        : {RUN_NAME}\\n\")\n",
    "print(f\"EXPERIMENT_DIR  : {EXPERIMENT_DIR}\")\n",
    "print(f\"CHECKPT_DIR     : {CHECKPT_DIR}\")\n",
    "print(f\"BASE_OUTPUT_DIR : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR         : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR        : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR   : {ARTIFACTS_DIR}\\n\")\n",
    "print(f\"TRAIN_LOG_DIR   : {TRAIN_LOG_DIR}\")\n",
    "print(f\"EVAL_LOG_DIR    : {EVAL_LOG_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c628e73c-34c4-4b6e-b639-b6ebbcae8453",
   "metadata": {},
   "source": [
    "### Checkpointer and Policy Saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14b5fee7-3c99-4cbb-9f39-99d51e5c3675",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check for existing checkpoint(s)...\n",
    "! gsutil ls $CHECKPT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "615ffdec-e52d-403d-a217-5e711ca8dd55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting train_checkpointer: gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-local-v16/chkpoint\n",
      "Did not find a pre-existing checkpoint. Starting from scratch.\n",
      "setting policy_checkpointer: gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-local-v16/chkpoint/policy\n",
      "\n",
      "saver signatures:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'action': <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x7eff3057f7f0>,\n",
       " 'get_initial_state': <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x7eff3057c370>,\n",
       " 'get_train_step': <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x7eff3057e470>,\n",
       " 'get_metadata': <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x7eff3057c2b0>}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `step_metric` records the number of individual rounds of bandit interaction;\n",
    "# that is, (number of trajectories) * batch_size.\n",
    "# step_metric = tf_metrics.EnvironmentSteps()\n",
    "\n",
    "# ====================================================\n",
    "# get checkpoint manager\n",
    "# ====================================================\n",
    "print(f\"setting train_checkpointer: {CHECKPT_DIR}\")\n",
    "train_checkpointer = train_utils.restore_and_get_checkpoint_manager(\n",
    "    root_dir=CHECKPT_DIR, \n",
    "    agent=tf_agent, \n",
    "    metrics=offline_eval_metrics, \n",
    "    step_metric=global_step\n",
    ")\n",
    "POLICY_CHEKPT_DIR = os.path.join(CHECKPT_DIR, 'policy')\n",
    "print(f\"setting policy_checkpointer: {POLICY_CHEKPT_DIR}\")\n",
    "policy_checkpointer = common.Checkpointer(\n",
    "    ckpt_dir=POLICY_CHEKPT_DIR,\n",
    "    policy=tf_agent.policy,\n",
    "    global_step=global_step\n",
    ")\n",
    "# ====================================================\n",
    "# saver\n",
    "# ====================================================\n",
    "topk_policy = tf_agent.policy\n",
    "time_step_spec_with_time_dim = tf.nest.map_structure(\n",
    "    lambda spec: policy_saver.add_batch_dim(spec, [None]),\n",
    "    topk_policy.time_step_spec,\n",
    ")\n",
    "input_fn_and_spec = (\n",
    "    lambda x: x,\n",
    "    (time_step_spec_with_time_dim, topk_policy.policy_state_spec),\n",
    ")\n",
    "saver = policy_saver.PolicySaver(\n",
    "    policy = tf_agent.policy, \n",
    "    train_step=global_step,\n",
    "    input_fn_and_spec = input_fn_and_spec,\n",
    ")\n",
    "print(f\"\\nsaver signatures:\")\n",
    "saver.signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbf3ac9-3e8b-40f1-8abc-8ddfeeaa964c",
   "metadata": {},
   "source": [
    "### summary writers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40dc3c6d-74ff-4be6-a6f5-ead40d5dbfa1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent.train_step_counter: 0\n",
      "global_step             : 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"agent.train_step_counter: {tf_agent.train_step_counter.value().numpy()}\")\n",
    "print(f\"global_step             : {global_step.numpy()}\")\n",
    "\n",
    "# ====================================================\n",
    "# summary writers\n",
    "# ====================================================\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    TRAIN_LOG_DIR, flush_millis=10 * 1000\n",
    ")\n",
    "train_summary_writer.set_as_default()\n",
    "\n",
    "eval_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "    EVAL_LOG_DIR, flush_millis=10 * 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27971809-23a3-4e03-ae50-56a1dcbb370e",
   "metadata": {},
   "source": [
    "# Train Loop\n",
    "\n",
    "* `tf_agent.post_process_policy()` only used with ScaNN index. see [src code](https://github.com/tottenjordan/tf_vertex_agents/blob/main/src/agents/topk_reinforce_agent.py#L340)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d31d9878-6691-42ec-8b4a-e318e6c05de2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_ITERATIONS       : 20000\n",
      "EVAL_INTERVAL        : 10000\n",
      "LOG_INTERVAL         : 1000\n",
      "SUMMARY_INTERVAL     : 100\n",
      "USE_TF_FUNCTIONS     : True\n",
      "\n",
      "TRAIN_CHKPT_INTERVAL : 80000\n",
      "POLICY_CHKPT_INTERVAL: 80000\n"
     ]
    }
   ],
   "source": [
    "NUM_ITERATIONS   = 20_000\n",
    "\n",
    "EVAL_INTERVAL    = int(NUM_ITERATIONS/2)\n",
    "LOG_INTERVAL     = int(NUM_ITERATIONS/20)\n",
    "SUMMARY_INTERVAL = 100\n",
    "\n",
    "TRAIN_CHKPT_INTERVAL = int(NUM_ITERATIONS*4)\n",
    "POLICY_CHKPT_INTERVAL= int(NUM_ITERATIONS*4)\n",
    "\n",
    "USE_TF_FUNCTIONS = True\n",
    "\n",
    "print(f\"NUM_ITERATIONS       : {NUM_ITERATIONS}\")\n",
    "print(f\"EVAL_INTERVAL        : {EVAL_INTERVAL}\")\n",
    "print(f\"LOG_INTERVAL         : {LOG_INTERVAL}\")\n",
    "print(f\"SUMMARY_INTERVAL     : {SUMMARY_INTERVAL}\")\n",
    "print(f\"USE_TF_FUNCTIONS     : {USE_TF_FUNCTIONS}\\n\")\n",
    "print(f\"TRAIN_CHKPT_INTERVAL : {TRAIN_CHKPT_INTERVAL}\")\n",
    "print(f\"POLICY_CHKPT_INTERVAL: {POLICY_CHKPT_INTERVAL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c090e2ca-f6d8-41d1-a2f5-35f7173b2906",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting train loop...\n",
      "step = 1000: loss = 46.714630126953125\n",
      "step = 2000: loss = 46.480064392089844\n",
      "step = 3000: loss = 46.12771224975586\n",
      "step = 4000: loss = 42.37116241455078\n",
      "step = 5000: loss = 40.556949615478516\n",
      "step = 6000: loss = 40.574310302734375\n",
      "step = 7000: loss = 45.21169662475586\n",
      "step = 8000: loss = 37.84819030761719\n",
      "step = 9000: loss = 42.34241485595703\n",
      "step = 10000: loss = 41.61832809448242\n",
      "\n",
      "48.145 steps/sec\n",
      "\n",
      "Eval at step: 10000...\n",
      "AccuracyAtK  =  0.086666666\n",
      "AveragePerClassAccuracyAtK  =  0.03240545\n",
      "WeightedReturnsLogProb_gamma_1  =  -326.8962\n",
      "WeightedReturnsProb_gamma_1  =  0.27652916\n",
      "AccuracyAtK_1  =  0.018645834\n",
      "AccuracyAtK_5  =  0.086666666\n",
      "AccuracyAtK_10  =  0.086666666\n",
      "========================================\n",
      "\n",
      "step = 11000: loss = 41.8713493347168\n",
      "step = 12000: loss = 40.231956481933594\n",
      "step = 13000: loss = 42.69541931152344\n",
      "step = 14000: loss = 39.9033088684082\n",
      "step = 15000: loss = 40.51089859008789\n",
      "step = 16000: loss = 41.831642150878906\n",
      "step = 17000: loss = 42.61149597167969\n",
      "step = 18000: loss = 40.95901870727539\n",
      "step = 19000: loss = 36.308876037597656\n",
      "step = 20000: loss = 42.93049240112305\n",
      "\n",
      "24.045 steps/sec\n",
      "\n",
      "Eval at step: 20000...\n",
      "AccuracyAtK  =  0.09708333\n",
      "AveragePerClassAccuracyAtK  =  0.046075832\n",
      "WeightedReturnsLogProb_gamma_1  =  -309.0151\n",
      "WeightedReturnsProb_gamma_1  =  0.4016139\n",
      "AccuracyAtK_1  =  0.022083333\n",
      "AccuracyAtK_5  =  0.09708333\n",
      "AccuracyAtK_10  =  0.09708333\n",
      "========================================\n",
      "\n",
      "total runtime : 7\n",
      "saved train_checkpointer to: gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-local-v16/chkpoint\n",
      "saved policy_checkpointer to: gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-local-v16/chkpoint/policy\n",
      "saved trained policy to: gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-local-v16/run-20241211-215732/artifacts\n"
     ]
    }
   ],
   "source": [
    "if USE_TF_FUNCTIONS:\n",
    "    tf_agent.train = common.function(tf_agent.train)\n",
    "\n",
    "def train_step():\n",
    "    trajectory, weights = next(train_dataset_iterator)\n",
    "    return tf_agent.train(trajectory, weights).loss\n",
    "\n",
    "if USE_TF_FUNCTIONS:\n",
    "    train_step = common.function(train_step)\n",
    "\n",
    "# start the timer and training\n",
    "with tf.compat.v2.summary.record_if(\n",
    "    lambda: tf.math.equal(global_step % SUMMARY_INTERVAL, 0)\n",
    "):\n",
    "    print(f\"starting train loop...\")\n",
    "    list_o_loss=[]\n",
    "    time_acc = 0\n",
    "    timed_at_step = global_step.numpy()\n",
    "\n",
    "    start_train = time.time()\n",
    "    \n",
    "    for i in range(NUM_ITERATIONS):\n",
    "        train_loss = train_step()\n",
    "        list_o_loss.append(train_loss.numpy())\n",
    "        \n",
    "        if global_step.numpy() % LOG_INTERVAL == 0:\n",
    "            print(f'step = {global_step.numpy()}: loss = {train_loss.numpy()}')\n",
    "        \n",
    "        if global_step.numpy() % EVAL_INTERVAL == 0:\n",
    "            # steps/sec\n",
    "            time_acc += time.time() - start_train\n",
    "            steps_per_sec = (global_step.numpy() - timed_at_step) / time_acc\n",
    "            print(f\"\\n{round(steps_per_sec,3)} steps/sec\")\n",
    "            timed_at_step = global_step.numpy()\n",
    "            time_acc = 0\n",
    "            \n",
    "            print(f\"\\nEval at step: {global_step.numpy()}...\")\n",
    "            # tf_agent.post_process_policy()\n",
    "            evaluate(\n",
    "                tf_agent.policy,\n",
    "                eval_dataset,\n",
    "                offline_eval_metrics=offline_eval_metrics,\n",
    "                train_step=global_step,\n",
    "                summary_writer=eval_summary_writer,\n",
    "                summary_prefix='Metrics',\n",
    "            )\n",
    "            metric_utils.log_metrics(offline_eval_metrics)\n",
    "            for metric in offline_eval_metrics:\n",
    "                print(metric.name, ' = ', metric.result().numpy())\n",
    "            \n",
    "            print(\"=\"*40 + \"\\n\")\n",
    "        \n",
    "        if global_step.numpy() % TRAIN_CHKPT_INTERVAL == 0:\n",
    "            train_checkpointer.save(global_step)\n",
    "            print(f\"saved train_checkpointer step {global_step.numpy()} to {CHECKPT_DIR}\")\n",
    "            \n",
    "        if global_step.numpy() % POLICY_CHKPT_INTERVAL == 0:\n",
    "            # print(f\"post processing policy...\")\n",
    "            # tf_agent.post_process_policy()\n",
    "            policy_checkpointer.save(global_step)\n",
    "            print(f\"saved policy_checkpointer step {global_step.numpy()} to {POLICY_CHEKPT_DIR}\")\n",
    "            \n",
    "runtime_mins = int((time.time() - start_train) / 60)\n",
    "print(f\"total runtime : {runtime_mins}\")\n",
    "\n",
    "train_checkpointer.save(global_step)\n",
    "print(f\"saved train_checkpointer to: {CHECKPT_DIR}\")\n",
    "\n",
    "# print(f\"post processing policy...\")\n",
    "# tf_agent.post_process_policy()\n",
    "policy_checkpointer.save(global_step)\n",
    "print(f\"saved policy_checkpointer to: {POLICY_CHEKPT_DIR}\")\n",
    "\n",
    "saver.save(ARTIFACTS_DIR) # options=tf.saved_model.SaveOptions(save_debug_info=True)\n",
    "print(f\"saved trained policy to: {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e0c897c-f401-438a-a7e8-966fbefc9719",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-local-v16/run-20241211-215732/artifacts/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-local-v16/run-20241211-215732/artifacts/fingerprint.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-local-v16/run-20241211-215732/artifacts/policy_specs.pbtxt\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-local-v16/run-20241211-215732/artifacts/saved_model.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-local-v16/run-20241211-215732/artifacts/assets/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-local-v16/run-20241211-215732/artifacts/variables/\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls $ARTIFACTS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2a5c0df-52e0-4ae2-a61c-1cb1eb87a467",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-local-v16/chkpoint/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-local-v16/chkpoint/checkpoint\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-local-v16/chkpoint/ckpt-20000.data-00000-of-00001\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-local-v16/chkpoint/ckpt-20000.index\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-local-v16/chkpoint/policy/\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls $CHECKPT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "687473d9-280b-46f3-8da3-da9534f342ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Offline eval metrics:\n",
      "AccuracyAtK  =  0.09708\n",
      "\n",
      "Offline eval metrics:\n",
      "AveragePerClassAccuracyAtK  =  0.04608\n",
      "\n",
      "Offline eval metrics:\n",
      "WeightedReturnsLogProb_gamma_1  =  -309.01511\n",
      "\n",
      "Offline eval metrics:\n",
      "WeightedReturnsProb_gamma_1  =  0.40161\n",
      "\n",
      "Offline eval metrics:\n",
      "AccuracyAtK_1  =  0.02208\n",
      "\n",
      "Offline eval metrics:\n",
      "AccuracyAtK_5  =  0.09708\n",
      "\n",
      "Offline eval metrics:\n",
      "AccuracyAtK_10  =  0.09708\n"
     ]
    }
   ],
   "source": [
    "for metric in offline_eval_metrics:\n",
    "    print(f\"\\nOffline eval metrics:\")\n",
    "    print(metric.name, ' = ', round(float(metric.result().numpy()), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d334f8c8-2913-471a-bc89-9bc1ee8cca78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAGgCAYAAABL3XhTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA6RElEQVR4nO3de3QU9d3H8c/uJrtJSHZzgSQEAkaoXBRRUONWpV5SgsaqlT71QpUqSrVBC7TIQ2vx0h6h+CjVitg+WvGc1mvrpYKIEQSrBNBolItGwGgikASB7CaQ+/6ePzDzsIJyaWAW5v06Z85JZr47+f0yZOfDb2Z+6zLGGAEAADiY2+4GAAAA2I1ABAAAHI9ABAAAHI9ABAAAHI9ABAAAHI9ABAAAHI9ABAAAHI9ABAAAHI9ABAAAHI9ABAAAHM/2QLRp0yb95Cc/UUZGhhITEzVkyBC9++671nZjjKZPn66ePXsqMTFRBQUFWr9+fdQ+tm/frjFjxsjv9ys1NVXjxo1TY2NjVM2HH36oc845RwkJCcrNzdWsWbOOSP8AAEDsi7Pzh+/YsUNnnXWWzjvvPC1cuFA9evTQ+vXrlZaWZtXMmjVLDz74oJ544gnl5eXpt7/9rQoLC7Vu3TolJCRIksaMGaMtW7aopKREbW1tuu666zR+/Hg9+eSTkqRwOKyRI0eqoKBAjzzyiFavXq3rr79eqampGj9+/H7bGYlEtHnzZqWkpMjlch2eXwYAAOhSxhg1NDQoJydHbvd+xoCMjaZOnWrOPvvsb9weiURMdna2uffee6119fX1xufzmaeeesoYY8y6deuMJPPOO+9YNQsXLjQul8ts2rTJGGPMww8/bNLS0kxLS0vUzx4wYMABtbO6utpIYmFhYWFhYTkKl+rq6v2e620dIfrXv/6lwsJC/dd//ZeWLVumXr166ec//7luvPFGSVJlZaVqampUUFBgvSYQCCg/P1+lpaW68sorVVpaqtTUVJ122mlWTUFBgdxut1auXKkf/vCHKi0t1YgRI+T1eq2awsJC/eEPf9COHTuiRqQkqaWlRS0tLdb3xhhJUnV1tfx+/2H5XQAAgK4VDoeVm5urlJSU/dbaGog+/fRTzZ07V5MnT9avf/1rvfPOO7r11lvl9Xo1duxY1dTUSJKysrKiXpeVlWVtq6mpUWZmZtT2uLg4paenR9Xk5eXttY/ObV8PRDNmzNBdd921V3v9fj+BCACAo8yB3O5i603VkUhEw4YN0z333KNTTz1V48eP14033qhHHnnEzmZp2rRpCoVC1lJdXW1rewAAwOFlayDq2bOnBg8eHLVu0KBBqqqqkiRlZ2dLkmpra6NqamtrrW3Z2dmqq6uL2t7e3q7t27dH1exrH3v+jD35fD5rNIhRIQAAjn22BqKzzjpLFRUVUes++eQT9e3bV5KUl5en7OxsLV682NoeDoe1cuVKBYNBSVIwGFR9fb3KysqsmiVLligSiSg/P9+qefPNN9XW1mbVlJSUaMCAAXtdLgMAAM5jayCaNGmSVqxYoXvuuUcbNmzQk08+qb/85S8qLi6WtPua38SJE/X73/9e//rXv7R69Wpde+21ysnJ0WWXXSZp94jSqFGjdOONN2rVqlV6++23NWHCBF155ZXKycmRJF199dXyer0aN26c1q5dq2eeeUYPPPCAJk+ebFfXAQBALDmg584Po5dfftmcdNJJxufzmYEDB5q//OUvUdsjkYj57W9/a7KysozP5zMXXHCBqaioiKrZtm2bueqqq0xycrLx+/3muuuuMw0NDVE1H3zwgTn77LONz+czvXr1MjNnzjzgNoZCISPJhEKhQ+8oAAA4og7m/O0y5qtnyvGNwuGwAoGAQqEQ9xMBAHCUOJjzt+0f3QEAAGA3AhEAAHA8AhEAAHA8AhEAAHA8AhEAAHA8AhEAAHA8Wz/c1ekamtt0f8kncsml6T8YvP8XAACAw4IRIhs1tXXo8bc/07zllXY3BQAARyMQAQAAxyMQAQAAxyMQAQAAxyMQAQAAxyMQAQAAxyMQAQAAxyMQxQBjdwMAAHA4ApGNXHLZ3QQAACACEQAAAIEIAACAQAQAAByPQAQAAByPQAQAAByPQAQAAByPQAQAAByPQBQDDDMzAgBgKwKRjVzMywgAQEwgEAEAAMcjEAEAAMcjEAEAAMcjEAEAAMcjEAEAAMcjEAEAAMcjEAEAAMcjENmIaYgAAIgNBCIAAOB4BCIAAOB4BCIAAOB4BCIAAOB4BCIAAOB4BCIAAOB4BKIYYYyxuwkAADgWgchGLhczEQEAEAsIRAAAwPEIRAAAwPEIRAAAwPEIRAAAwPEIRAAAwPEIRAAAwPEIRAAAwPFsDUR33nmnXC5X1DJw4EBre3Nzs4qLi5WRkaHk5GSNHj1atbW1UfuoqqpSUVGRkpKSlJmZqSlTpqi9vT2qZunSpRo2bJh8Pp/69++vefPmHYnuHRTmZQQAwD62jxCdeOKJ2rJli7W89dZb1rZJkybp5Zdf1nPPPadly5Zp8+bNuvzyy63tHR0dKioqUmtrq5YvX64nnnhC8+bN0/Tp062ayspKFRUV6bzzzlN5ebkmTpyoG264QYsWLTqi/dwXpmUEACA2xNnegLg4ZWdn77U+FArpscce05NPPqnzzz9fkvT4449r0KBBWrFihc4880y99tprWrdunV5//XVlZWXplFNO0e9+9ztNnTpVd955p7xerx555BHl5eXpvvvukyQNGjRIb731lmbPnq3CwsJ9tqmlpUUtLS3W9+Fw+DD0HAAAxArbR4jWr1+vnJwcHX/88RozZoyqqqokSWVlZWpra1NBQYFVO3DgQPXp00elpaWSpNLSUg0ZMkRZWVlWTWFhocLhsNauXWvV7LmPzprOfezLjBkzFAgErCU3N7fL+gsAAGKPrYEoPz9f8+bN06uvvqq5c+eqsrJS55xzjhoaGlRTUyOv16vU1NSo12RlZammpkaSVFNTExWGOrd3bvu2mnA4rKampn22a9q0aQqFQtZSXV3dFd0FAAAxytZLZhdeeKH19cknn6z8/Hz17dtXzz77rBITE21rl8/nk8/ns+3nAwCAI8v2S2Z7Sk1N1QknnKANGzYoOztbra2tqq+vj6qpra217jnKzs7e66mzzu/3V+P3+20NXQAAIHbEVCBqbGzUxo0b1bNnTw0fPlzx8fFavHixtb2iokJVVVUKBoOSpGAwqNWrV6uurs6qKSkpkd/v1+DBg62aPffRWdO5DwAAAFsD0a9+9SstW7ZMn332mZYvX64f/vCH8ng8uuqqqxQIBDRu3DhNnjxZb7zxhsrKynTdddcpGAzqzDPPlCSNHDlSgwcP1jXXXKMPPvhAixYt0u23367i4mLrktdNN92kTz/9VLfddps+/vhjPfzww3r22Wc1adIkO7u+F6YhAgDAPrbeQ/TFF1/oqquu0rZt29SjRw+dffbZWrFihXr06CFJmj17ttxut0aPHq2WlhYVFhbq4Ycftl7v8Xg0f/583XzzzQoGg+rWrZvGjh2ru+++26rJy8vTggULNGnSJD3wwAPq3bu3Hn300W985P5IcjEREQAAMcFlDHMk7084HFYgEFAoFJLf7++y/dbvatUpd5dIkjbec5E8bhISAABd5WDO3zF1DxEAAIAdCEQAAMDxCEQAAMDxCEQAAMDxCEQAAMDxCEQxgof9AACwD4HIRi7xmD0AALGAQAQAAByPQAQAAByPQAQAAByPQAQAAByPQAQAAByPQAQAAByPQAQAAByPQBQjmJYRAAD7EIjsxLyMAADEBAIRAABwPAIRAABwPAIRAABwPAIRAABwPAIRAABwPAIRAABwPAJRjDBMRAQAgG0IRDZyMQ8RAAAxgUAEAAAcj0AEAAAcj0AEAAAcj0AEAAAcj0AEAAAcj0AEAAAcj0AUI4yYiAgAALsQiGzENEQAAMQGAhEAAHA8AhEAAHA8AhEAAHA8AhEAAHA8AhEAAHA8AhEAAHA8AhEAAHA8AlGMMMzLCACAbQhENnK5mJoRAIBYQCACAACORyACAACORyACAACORyACAACORyACAACORyACAACORyACAACOFzOBaObMmXK5XJo4caK1rrm5WcXFxcrIyFBycrJGjx6t2traqNdVVVWpqKhISUlJyszM1JQpU9Te3h5Vs3TpUg0bNkw+n0/9+/fXvHnzjkCP9o9ZiAAAiA0xEYjeeecd/fnPf9bJJ58ctX7SpEl6+eWX9dxzz2nZsmXavHmzLr/8cmt7R0eHioqK1NraquXLl+uJJ57QvHnzNH36dKumsrJSRUVFOu+881ReXq6JEyfqhhtu0KJFi45Y/wAAQGyzPRA1NjZqzJgx+t///V+lpaVZ60OhkB577DHdf//9Ov/88zV8+HA9/vjjWr58uVasWCFJeu2117Ru3Tr97W9/0ymnnKILL7xQv/vd7zRnzhy1trZKkh555BHl5eXpvvvu06BBgzRhwgT96Ec/0uzZs7+xTS0tLQqHw1ELAAA4dtkeiIqLi1VUVKSCgoKo9WVlZWpra4taP3DgQPXp00elpaWSpNLSUg0ZMkRZWVlWTWFhocLhsNauXWvVfH3fhYWF1j72ZcaMGQoEAtaSm5v7H/cTAADELlsD0dNPP6333ntPM2bM2GtbTU2NvF6vUlNTo9ZnZWWppqbGqtkzDHVu79z2bTXhcFhNTU37bNe0adMUCoWspbq6+pD6BwAAjg5xdv3g6upq/eIXv1BJSYkSEhLsasY++Xw++Xw+u5sBAACOENtGiMrKylRXV6dhw4YpLi5OcXFxWrZsmR588EHFxcUpKytLra2tqq+vj3pdbW2tsrOzJUnZ2dl7PXXW+f3+avx+vxITEw9T7wAAwNHEtkB0wQUXaPXq1SovL7eW0047TWPGjLG+jo+P1+LFi63XVFRUqKqqSsFgUJIUDAa1evVq1dXVWTUlJSXy+/0aPHiwVbPnPjprOvcRK4yxuwUAADiXbZfMUlJSdNJJJ0Wt69atmzIyMqz148aN0+TJk5Weni6/369bbrlFwWBQZ555piRp5MiRGjx4sK655hrNmjVLNTU1uv3221VcXGxd8rrpppv00EMP6bbbbtP111+vJUuW6Nlnn9WCBQuObIf3wcVERAAAxATbAtGBmD17ttxut0aPHq2WlhYVFhbq4YcftrZ7PB7Nnz9fN998s4LBoLp166axY8fq7rvvtmry8vK0YMECTZo0SQ888IB69+6tRx99VIWFhXZ0CQAAxCCXMVys2Z9wOKxAIKBQKCS/399l+93V2q7B03dPEPnR3aOU6PV02b4BAHC6gzl/2z4PEQAAgN0IRAAAwPEIRAAAwPEIRAAAwPEIRAAAwPEIRDHCiIf9AACwC4HIRi4xMyMAALGAQAQAAByPQAQAAByPQAQAAByPQAQAAByPQAQAAByPQAQAAByPQBQjDNMQAQBgGwKRjVxMQwQAQEwgEAEAAMcjEAEAAMcjEAEAAMcjEAEAAMcjEAEAAMcjEAEAAMcjEMUIpiECAMA+BCIAAOB4BCIAAOB4BCIAAOB4BCIAAOB4BCIAAOB4BCIAAOB4BCIAAOB4BCIAAOB4BKIYYQxTMwIAYBcCkY1cLrtbAAAAJAIRAAAAgQgAAIBABAAAHI9ABAAAHI9ABAAAHI9ABAAAHI9AFCOYhQgAAPsQiGzkEhMRAQAQCwhEAADA8QhEAADA8QhEAADA8QhEAADA8QhEAADA8QhEAADA8QhEMcIwEREAALaxNRDNnTtXJ598svx+v/x+v4LBoBYuXGhtb25uVnFxsTIyMpScnKzRo0ertrY2ah9VVVUqKipSUlKSMjMzNWXKFLW3t0fVLF26VMOGDZPP51P//v01b968I9G9/XIxDREAADHB1kDUu3dvzZw5U2VlZXr33Xd1/vnn69JLL9XatWslSZMmTdLLL7+s5557TsuWLdPmzZt1+eWXW6/v6OhQUVGRWltbtXz5cj3xxBOaN2+epk+fbtVUVlaqqKhI5513nsrLyzVx4kTdcMMNWrRo0RHvLwAAiFHmEMybN8/Mnz/f+n7KlCkmEAiYYDBoPvvss0PZpSUtLc08+uijpr6+3sTHx5vnnnvO2vbRRx8ZSaa0tNQYY8wrr7xi3G63qampsWrmzp1r/H6/aWlpMcYYc9ttt5kTTzwx6mdcccUVprCw8IDbFAqFjCQTCoX+k67tpbW9w/SdOt/0nTrf1O9q7dJ9AwDgdAdz/j6kEaJ77rlHiYmJkqTS0lLNmTNHs2bNUvfu3TVp0qRDCmYdHR16+umntXPnTgWDQZWVlamtrU0FBQVWzcCBA9WnTx+VlpZaP3vIkCHKysqyagoLCxUOh61RptLS0qh9dNZ07mNfWlpaFA6HoxYAAHDsijuUF1VXV6t///6SpBdffFGjR4/W+PHjddZZZ+ncc889qH2tXr1awWBQzc3NSk5O1gsvvKDBgwervLxcXq9XqampUfVZWVmqqamRJNXU1ESFoc7tndu+rSYcDqupqckKdnuaMWOG7rrrroPqBwAAOHod0ghRcnKytm3bJkl67bXX9P3vf1+SlJCQoKampoPa14ABA1ReXq6VK1fq5ptv1tixY7Vu3bpDaVaXmTZtmkKhkLVUV1fb2h4AAHB4HdII0fe//33dcMMNOvXUU/XJJ5/ooosukiStXbtWxx133EHty+v1WqNNw4cP1zvvvKMHHnhAV1xxhVpbW1VfXx81SlRbW6vs7GxJUnZ2tlatWhW1v86n0Pas+fqTabW1tfL7/fscHZIkn88nn893UP0AAABHr0MaIZozZ46CwaC2bt2qf/7zn8rIyJAklZWV6aqrrvqPGhSJRNTS0qLhw4crPj5eixcvtrZVVFSoqqpKwWBQkhQMBrV69WrV1dVZNSUlJfL7/Ro8eLBVs+c+Oms69wEAAHBII0Spqal66KGH9lp/sPfdTJs2TRdeeKH69OmjhoYGPfnkk1q6dKkWLVqkQCCgcePGafLkyUpPT5ff79ctt9yiYDCoM888U5I0cuRIDR48WNdcc41mzZqlmpoa3X777SouLrZGeG666SY99NBDuu2223T99ddryZIlevbZZ7VgwYJD6frhw8SMAADY5pBGiF599VW99dZb1vdz5szRKaecoquvvlo7duw44P3U1dXp2muv1YABA3TBBRfonXfe0aJFi6x7kmbPnq2LL75Yo0eP1ogRI5Sdna3nn3/eer3H49H8+fPl8XgUDAb1k5/8RNdee63uvvtuqyYvL08LFixQSUmJhg4dqvvuu0+PPvqoCgsLD6XrXYp5GQEAiA0uYw7+QyOGDBmiP/zhD7rooou0evVqnX766Zo8ebLeeOMNDRw4UI8//vjhaKttwuGwAoGAQqGQ/H5/l+23vSOi/r/ZPTP3B9NHKpAU32X7BgDA6Q7m/H1Il8wqKyute3T++c9/6uKLL9Y999yj9957z7rBGgAA4GhxSJfMvF6vdu3aJUl6/fXXNXLkSElSeno6kxgCAICjziGNEJ199tmaPHmyzjrrLK1atUrPPPOMJOmTTz5R7969u7SBAAAAh9shjRA99NBDiouL0z/+8Q/NnTtXvXr1kiQtXLhQo0aN6tIGAgAAHG6HNELUp08fzZ8/f6/1s2fP/o8bBAAAcKQdUiCSdn8Y64svvqiPPvpIknTiiSfqkksukcfj6bLGOYlhIiIAAGxzSIFow4YNuuiii7Rp0yYNGDBA0u4PRM3NzdWCBQvUr1+/Lm3kscrlYiYiAABiwSHdQ3TrrbeqX79+qq6u1nvvvaf33ntPVVVVysvL06233trVbQQAADisDmmEaNmyZVqxYoXS09OtdRkZGZo5c6bOOuusLmscAADAkXBII0Q+n08NDQ17rW9sbJTX6/2PGwUAAHAkHVIguvjiizV+/HitXLlSxhgZY7RixQrddNNNuuSSS7q6jQAAAIfVIQWiBx98UP369VMwGFRCQoISEhL03e9+V/3799cf//jHLm4iAADA4XVI9xClpqbqpZde0oYNG6zH7gcNGqT+/ft3aeMAAACOhAMORJMnT/7W7W+88Yb19f3333/oLXIowzREAADY5oAD0fvvv39Adcytc+D4TQEAEBsOOBDtOQIEAABwLDmkm6oBAACOJQQiAADgeAQiAADgeAQiAADgeAQiAADgeAQiAADgeASiGMG8jAAA2IdAZCPmsAQAIDYQiAAAgOMRiAAAgOMRiAAAgOMRiAAAgOMRiAAAgOMRiAAAgOMRiGKEMcxEBACAXQhENnIxEREAADGBQAQAAByPQAQAAByPQAQAAByPQAQAAByPQAQAAByPQAQAAByPQBQjmIUIAAD7EIgAAIDjEYgAAIDjEYgAAIDjEYgAAIDjEYgAAIDjEYgAAIDjEYgAAIDjEYgAAIDjEYhihGFmRgAAbGNrIJoxY4ZOP/10paSkKDMzU5dddpkqKiqiapqbm1VcXKyMjAwlJydr9OjRqq2tjaqpqqpSUVGRkpKSlJmZqSlTpqi9vT2qZunSpRo2bJh8Pp/69++vefPmHe7uHRCXy+4WAAAAWwPRsmXLVFxcrBUrVqikpERtbW0aOXKkdu7cadVMmjRJL7/8sp577jktW7ZMmzdv1uWXX25t7+joUFFRkVpbW7V8+XI98cQTmjdvnqZPn27VVFZWqqioSOedd57Ky8s1ceJE3XDDDVq0aNER7S8AAIhNLmNi52LN1q1blZmZqWXLlmnEiBEKhULq0aOHnnzySf3oRz+SJH388ccaNGiQSktLdeaZZ2rhwoW6+OKLtXnzZmVlZUmSHnnkEU2dOlVbt26V1+vV1KlTtWDBAq1Zs8b6WVdeeaXq6+v16quv7rdd4XBYgUBAoVBIfr+/S/ucN22BjJHe+U2BeqT4unTfAAA42cGcv2PqHqJQKCRJSk9PlySVlZWpra1NBQUFVs3AgQPVp08flZaWSpJKS0s1ZMgQKwxJUmFhocLhsNauXWvV7LmPzprOfXxdS0uLwuFw1AIAAI5dMROIIpGIJk6cqLPOOksnnXSSJKmmpkZer1epqalRtVlZWaqpqbFq9gxDnds7t31bTTgcVlNT015tmTFjhgKBgLXk5uZ2SR8BAEBsiplAVFxcrDVr1ujpp5+2uymaNm2aQqGQtVRXV9vdJAAAcBjF2d0ASZowYYLmz5+vN998U71797bWZ2dnq7W1VfX19VGjRLW1tcrOzrZqVq1aFbW/zqfQ9qz5+pNptbW18vv9SkxM3Ks9Pp9PPh/38wAA4BS2jhAZYzRhwgS98MILWrJkifLy8qK2Dx8+XPHx8Vq8eLG1rqKiQlVVVQoGg5KkYDCo1atXq66uzqopKSmR3+/X4MGDrZo999FZ07mPWGAUM/e2AwDgOLaOEBUXF+vJJ5/USy+9pJSUFOuen0AgoMTERAUCAY0bN06TJ09Wenq6/H6/brnlFgWDQZ155pmSpJEjR2rw4MG65pprNGvWLNXU1Oj2229XcXGxNcpz00036aGHHtJtt92m66+/XkuWLNGzzz6rBQsW2Nb3Ti6JKAQAgM1sHSGaO3euQqGQzj33XPXs2dNannnmGatm9uzZuvjiizV69GiNGDFC2dnZev75563tHo9H8+fPl8fjUTAY1E9+8hNde+21uvvuu62avLw8LViwQCUlJRo6dKjuu+8+PfrooyosLDyi/QUAALEppuYhilWHcx6i46ctUMRIq35zgTJTErp03wAAONlROw8RAACAHQhEAADA8QhEAADA8QhEAADA8QhEsYJb2wEAsA2ByGYul8vuJgAA4HgEIgAA4HgEIgAA4HgEIgAA4HgEIgAA4HgEIgAA4HgEIgAA4HgEIgAA4HgEohjBvIwAANiHQGQzpmUEAMB+BCIAAOB4BCIAAOB4BCIAAOB4BCIAAOB4BCIAAOB4BCIAAOB4BKIYYZiICAAA2xCIbOZiIiIAAGxHIAIAAI5HIAIAAI5HIAIAAI5HIAIAAI5HIAIAAI5HIAIAAI5HIIoRRkxEBACAXQhENnOJiYgAALAbgQgAADgegQgAADgegQgAADgegQgAADgegQgAADgegQgAADgegQgAADgegShGGOZlBADANgQiuzEvIwAAtiMQAQAAxyMQAQAAxyMQAQAAxyMQAQAAxyMQAQAAxyMQAQAAxyMQxQimIQIAwD4EIpsxDREAAPazNRC9+eab+sEPfqCcnBy5XC69+OKLUduNMZo+fbp69uypxMREFRQUaP369VE127dv15gxY+T3+5Wamqpx48apsbExqubDDz/UOeeco4SEBOXm5mrWrFmHu2sAAOAoYmsg2rlzp4YOHao5c+bsc/usWbP04IMP6pFHHtHKlSvVrVs3FRYWqrm52aoZM2aM1q5dq5KSEs2fP19vvvmmxo8fb20Ph8MaOXKk+vbtq7KyMt17772688479Ze//OWw9w8AABwlTIyQZF544QXr+0gkYrKzs829995rrauvrzc+n8889dRTxhhj1q1bZySZd955x6pZuHChcblcZtOmTcYYYx5++GGTlpZmWlparJqpU6eaAQMGHHDbQqGQkWRCodChdu8bnfCbV0zfqfPNFzt2dfm+AQBwsoM5f8fsPUSVlZWqqalRQUGBtS4QCCg/P1+lpaWSpNLSUqWmpuq0006zagoKCuR2u7Vy5UqrZsSIEfJ6vVZNYWGhKioqtGPHjn3+7JaWFoXD4agFAAAcu2I2ENXU1EiSsrKyotZnZWVZ22pqapSZmRm1PS4uTunp6VE1+9rHnj/j62bMmKFAIGAtubm5/3mHAABAzIrZQGSnadOmKRQKWUt1dbXdTQIAAIdRzAai7OxsSVJtbW3U+traWmtbdna26urqora3t7dr+/btUTX72seeP+PrfD6f/H5/1AIAAI5dMRuI8vLylJ2drcWLF1vrwuGwVq5cqWAwKEkKBoOqr69XWVmZVbNkyRJFIhHl5+dbNW+++aba2tqsmpKSEg0YMEBpaWlHqDf7ZwxTMwIAYBdbA1FjY6PKy8tVXl4uafeN1OXl5aqqqpLL5dLEiRP1+9//Xv/617+0evVqXXvttcrJydFll10mSRo0aJBGjRqlG2+8UatWrdLbb7+tCRMm6Morr1ROTo4k6eqrr5bX69W4ceO0du1aPfPMM3rggQc0efJkm3odzcXMjAAA2C7Ozh/+7rvv6rzzzrO+7wwpY8eO1bx583Tbbbdp586dGj9+vOrr63X22Wfr1VdfVUJCgvWav//975owYYIuuOACud1ujR49Wg8++KC1PRAI6LXXXlNxcbGGDx+u7t27a/r06VFzFQEAAGdzGa7V7Fc4HFYgEFAoFOry+4kG/nahmtsiemvqeeqdltSl+wYAwMkO5vwds/cQAQAAHCkEIgAA4HgEIgAA4HgEIgAA4HgEIpu5tPu5e25tBwDAPgQim3XOQ0QgAgDAPgQim7m/SkRGJCIAAOxCILJZ5whRhDwEAIBtCEQ26xwhinDNDAAA2xCIbOa27iEiEAEAYBcCkc1c1giRzQ0BAMDBCEQ2c/OUGQAAtiMQ2czFPUQAANiOQGQzt/WUGYEIAAC7EIhsZs1DRB4CAMA2BCKbfTVAxAgRAAA2IhDZzMUIEQAAtiMQ2cz91RFghAgAAPsQiGzmZh4iAABsRyCy2f/fVE0iAgDALgQim/3/TdW2NgMAAEcjENnMxWeZAQBgOwKRzbiHCAAA+xGIbMY9RAAA2I9AZDOX9dEd9rYDAAAnIxDZjA93BQDAfgQim/HhrgAA2I9AZLM4z+5D0N5BIAIAwC4EIpvFfzVE1B6J2NwSAACci0BkszjP7kDUxggRAAC2IRDZLP6rS2ZtHYwQAQBgFwKRzeK5hwgAANsRiGzm+eoeojbuIQIAwDYEIpuVrKuVJD21qsrmlgAA4FwEohixZlPY7iYAAOBYBCKb/fi03pKkG8/Js7klAAA4F4HIZundfJL4LDMAAOxEILJZc1uHJOmT2gabWwIAgHMRiGw2b/lnkqR/r//S3oYAAOBgBCKbjQ32lSR99aH3AADABgQimw3rmyZJ4sPuAQCwD4HIZis+3W53EwAAcDwCkc1+fm4/62vDMBEAALYgENksNSne+vq9qh02tgQAAOciENksJeH/A9HouaU2tgQAAOciEMWYDmZoBADgiCMQxYCTewesr/v9+hXrA18BAMCR4TLcybtf4XBYgUBAoVBIfr//sPyM4/57wWHZL2JXii9OvniPvmxskSSlJcVrx662qJpAYrySvB6lJnn1xY5dive4tX1nqyTpnO90V0t7RKsq9/2kYrzHpexAglxyqWr7Lo04oYda2ztUv6tNyb44edwundW/u55Y/plGnNBDG7c2yuVyqaG5TXXhFp12XJraO4ze2hA9aejpx6XJG+fWB9Uhfe+EHlpaUafUJK8ixqhgUJZWbwpp49ZGjR7WW9t2tqojEtHn23apZyBB53ynh3bsalVtuFm14Ra9+9l2pSTE69wBPVTX0KKW9oiyUnxK7+ZV9Y5dOjEnoCSvR26XS+GmNm2qb1JaN68+qWnQiTl+vV9dL0lK7+ZVamK8Tu2TpjWbQlq3JSxjpI1bGzXihB4amJ2itg6j7TtbdNpx6dqxs1X1TW1qa4/ohOwUfbGjSdn+BFV+2ajeaUmKGKPacIuOy0iSkbStsUW+OI/CzW1atyWsS0/ppZ0t7Wr56vdZG25Rvx7d1D3Fp7b2iGYs/FijTspW/x7JSoj3qK0jorc2fKkBWSka1jdV4aZ2bd/ZqkSvR6s3hXT6cWnK6ObTzpZ2BZLi9fm2XWpp71DCVz/zhKwUPVf2hX763eO0vrZRcR6Xkn1x2rSjScf36KZdrR2K87jU0haRJG3f2arN9U06d0CmfPFutbZHtG1nq5pa29U7LUlNbR3K/aqfHRGjna3t2tXaoZc/2KzT+qYr0+9TvMetXS3t8sa51c0Xp4gx2rSjSdmBBG3b2aoeyT6Fm9vUETHyxXnkdknxHrea2jqU5PWod1qSdra0a9HaGgX7ZaibN05JPo+SfXEqr6rXkN4BLVxTI2OM8vMy9Nm2ncpMSZAk1Te1qn5Xm07KCcj11X4jxlj/9vv1SNaazSH1zUjS2s1hDeuTJmOMmtp2/846vuqX2+VSxBhFvjrNba5v1rotYQ3umSJfnEdJXo+a2jrkdrnU3mHkckntEaPN9U3q1yNZDc1tao8Y5QQSVbltpzK6eeVySZGI9OXOFqUnefXhF/U6d0CmdrXu7vem+iblBBLV0t6hrQ0tSk6IU7zHrWRfnNo6Impui6h/5u59b9/ZKm+cW2ndvDJG2lzfpIR4j9K7edXY0q6tDS3K6OZVN1+c2iO7j21jc7t2tnTI7d49XYvH7ZI/MV6Nze2qCTfr1D6pqqhp0JBeATU0t2vj1kZl+ROU5feprd189TcUr3BTu9K6xavssx06ITtF3bxx8ifG6fNtu9QRMfK4XeqTnqRtja0KNbUpI9mr5IQ47djZKpdcCiTFqyNi9NGWsHqk+BTndine41aoqU3p3bzyuF0KNbUpMd6jjGSvvmxoVbi5TblpSYqPc8kYqa6hRe0dEW3c2qjPt+3S2O8ep4R4z3/4zhrtYM7fjgpEc+bM0b333quamhoNHTpUf/rTn3TGGWfs93VHIhBt39mqYb8rOSz7BgDgaLDxnovkcXfdTMUHc/52zCWzZ555RpMnT9Ydd9yh9957T0OHDlVhYaHq6ursbpqk3f/D/WxmkaYUDrC7KQAA2KIrw9DBcswIUX5+vk4//XQ99NBDkqRIJKLc3Fzdcsst+u///u+o2paWFrW0tFjfh8Nh5ebmHtYRolhkjJHra58p8vV1bR0RxXvcqt/VKpfLJX9CnLXdGKOW9ogS4j1q74goYnZfxomY3ds8bpdcLpc1/1JrR2T38H1LhzVknBDvltfjlsvlUnNbh9ojRr44t+LcLrVHjFyS2jqM4j0uNTS3fzU8LqUkxKkm1KwOY+T1uJWSEKetDS1yuXYPA3vj3NoSapI/IV7eOLc8Lpc+/bJRvVKT5Itzq7G1Xe0du4fOe6Umykjq5vOoJtQst8ul9G5euV0uud3S+tpGpSTEye1yyftV2+Lj3HK7XNrV2q5wU7tcLiktyav2jog2h5rVJz1Jm+ub1NLeocyUBAWS4hXa1aatjS2q3LpTg3P8Wl/XaNX1zUiSPyFeLe0RNTS36fNtu6yPe+mR4lPv1CRrCL28ul7dfB5Vbdul3PQkNba0q6G5XSkJcdq+s1VLPq5Tktejq87o89WwdbPiPW6t2xzWCdkpOjMvQ1/U71JDc7t2trQrId6jNZtC6pWWKI/LJV+8W+VV9TqpV0DG7P7YmZb2iLwet1o6Itq0o0kRYxTn3n2se6UmKCPZpzc+rtPJuamSpI6OiLY2tmhny+4PN/70y51K8cXpeyf00Bf1TVpaUaf0bl7VhJr10+8ep5J1tVr2yVb9/Nx++nz7LvVOS1Sce/dllJN7p+rdz7dr8Ud16p7sVUayT744t9KTvFq+cZvyuneTL96txuZ2fbZtp3LTkrRjV6s+27ZL6d286p7s1enHpavyy52q3tGk4X3S9MWOXdYbc1Nbh2pCzQokxuu8gZkKN7WpZ2qiXl9Xq74ZSdq0o0lJvjgt+ahWvdOSVFHboJ6BBLV1GH3ZuPuSR05qohpbdv8+6xp2v7cM6RWQx737UuCnX+7Ufw3vrbaOiDKSfVpZuU1rNoU1uKdfuemJ8sZ59N7nO7Spvsn628vy+xRualdTW4d6pPi0teH/37MkyRu3+1LZt+mfmazN9U3a1drxrXUFg7L0+kfffG9jsi9OcR6Xmlo7lJuepA11jd+6v2+T5PWoI7L7vePrPG7XPh88yQkkaHOoeZ/76+b1aOd++negfHHufbbrcIn3uNTWceCnaH9CnMLN7YexRQenV2qivmxsOeDf2ZJffk/H90ju0jZwyexrWltblZSUpH/84x+67LLLrPVjx45VfX29Xnrppaj6O++8U3fdddde+3FaIAIA4GjGJbOv+fLLL9XR0aGsrKyo9VlZWaqpqdmrftq0aQqFQtZSXV19pJoKAABsEGd3A2KRz+eTz+ezuxkAAOAIccQIUffu3eXxeFRbG30NvLa2VtnZ2Ta1CgAAxApHBCKv16vhw4dr8eLF1rpIJKLFixcrGAza2DIAABALHHPJbPLkyRo7dqxOO+00nXHGGfrjH/+onTt36rrrrrO7aQAAwGaOCURXXHGFtm7dqunTp6umpkannHKKXn311b1utAYAAM7jiMfu/1NHYqZqAADQtXjsHgAA4CAQiAAAgOMRiAAAgOMRiAAAgOMRiAAAgOMRiAAAgOM5Zh6i/0TnzAThcNjmlgAAgAPVed4+kBmGCEQHoKGhQZKUm5trc0sAAMDBamhoUCAQ+NYaJmY8AJFIRJs3b1ZKSopcLleX7jscDis3N1fV1dXH5KSPx3r/pGO/j/Tv6Hes9/FY75907PfxcPXPGKOGhgbl5OTI7f72u4QYIToAbrdbvXv3Pqw/w+/3H5P/yDsd6/2Tjv0+0r+j37Hex2O9f9Kx38fD0b/9jQx14qZqAADgeAQiAADgeAQim/l8Pt1xxx3y+Xx2N+WwONb7Jx37faR/R79jvY/Hev+kY7+PsdA/bqoGAACOxwgRAABwPAIRAABwPAIRAABwPAIRAABwPAIRAABwPAKRjebMmaPjjjtOCQkJys/P16pVq+xu0j7NmDFDp59+ulJSUpSZmanLLrtMFRUVUTXnnnuuXC5X1HLTTTdF1VRVVamoqEhJSUnKzMzUlClT1N7eHlWzdOlSDRs2TD6fT/3799e8efMOd/d055137tX2gQMHWtubm5tVXFysjIwMJScna/To0aqtrT0q+tbpuOOO26uPLpdLxcXFko6+4/fmm2/qBz/4gXJycuRyufTiiy9GbTfGaPr06erZs6cSExNVUFCg9evXR9Vs375dY8aMkd/vV2pqqsaNG6fGxsaomg8//FDnnHOOEhISlJubq1mzZu3Vlueee04DBw5UQkKChgwZoldeeeWw9q+trU1Tp07VkCFD1K1bN+Xk5Ojaa6/V5s2bo/axr2M+c+bMmOjf/vooST/96U/3av+oUaOiao7WYyhpn3+PLpdL9957r1UTy8fwQM4LR/K9s0vOpwa2ePrpp43X6zV//etfzdq1a82NN95oUlNTTW1trd1N20thYaF5/PHHzZo1a0x5ebm56KKLTJ8+fUxjY6NV873vfc/ceOONZsuWLdYSCoWs7e3t7eakk04yBQUF5v333zevvPKK6d69u5k2bZpV8+mnn5qkpCQzefJks27dOvOnP/3JeDwe8+qrrx7W/t1xxx3mxBNPjGr71q1bre033XSTyc3NNYsXLzbvvvuuOfPMM813v/vdo6Jvnerq6qL6V1JSYiSZN954wxhz9B2/V155xfzmN78xzz//vJFkXnjhhajtM2fONIFAwLz44ovmgw8+MJdcconJy8szTU1NVs2oUaPM0KFDzYoVK8y///1v079/f3PVVVdZ20OhkMnKyjJjxowxa9asMU899ZRJTEw0f/7zn62at99+23g8HjNr1iyzbt06c/vtt5v4+HizevXqw9a/+vp6U1BQYJ555hnz8ccfm9LSUnPGGWeY4cOHR+2jb9++5u677446pnv+zdrZv/310Rhjxo4da0aNGhXV/u3bt0fVHK3H0BgT1a8tW7aYv/71r8blcpmNGzdaNbF8DA/kvHCk3ju76nxKILLJGWecYYqLi63vOzo6TE5OjpkxY4aNrTowdXV1RpJZtmyZte573/ue+cUvfvGNr3nllVeM2+02NTU11rq5c+cav99vWlpajDHG3HbbbebEE0+Met0VV1xhCgsLu7YDX3PHHXeYoUOH7nNbfX29iY+PN88995y17qOPPjKSTGlpqTEmtvv2TX7xi1+Yfv36mUgkYow5uo/f1082kUjEZGdnm3vvvddaV19fb3w+n3nqqaeMMcasW7fOSDLvvPOOVbNw4ULjcrnMpk2bjDHGPPzwwyYtLc3qnzHGTJ061QwYMMD6/sc//rEpKiqKak9+fr752c9+dtj6ty+rVq0yksznn39urevbt6+ZPXv2N74mVvpnzL77OHbsWHPppZd+42uOtWN46aWXmvPPPz9q3dF0DL9+XjiS751ddT7lkpkNWltbVVZWpoKCAmud2+1WQUGBSktLbWzZgQmFQpKk9PT0qPV///vf1b17d5100kmaNm2adu3aZW0rLS3VkCFDlJWVZa0rLCxUOBzW2rVrrZo9fyedNUfid7J+/Xrl5OTo+OOP15gxY1RVVSVJKisrU1tbW1S7Bg4cqD59+ljtivW+fV1ra6v+9re/6frrr5fL5bLWH83Hb0+VlZWqqamJaksgEFB+fn7UMUtNTdVpp51m1RQUFMjtdmvlypVWzYgRI+T1eq2awsJCVVRUaMeOHVZNLPQ5FArJ5XIpNTU1av3MmTOVkZGhU089Vffee2/UpYijoX9Lly5VZmamBgwYoJtvvlnbtm2Lav+xcgxra2u1YMECjRs3bq9tR8sx/Pp54Ui9d3bl+ZRPu7fBl19+qY6Ojqh/BJKUlZWljz/+2KZWHZhIJKKJEyfqrLPO0kknnWStv/rqq9W3b1/l5OToww8/1NSpU1VRUaHnn39eklRTU7PP/nZu+7aacDispqYmJSYmHpY+5efna968eRowYIC2bNmiu+66S+ecc47WrFmjmpoaeb3evU40WVlZ+213LPRtX1588UXV19frpz/9qbXuaD5+X9fZnn21Zc+2ZmZmRm2Pi4tTenp6VE1eXt5e++jclpaW9o197tzHkdDc3KypU6fqqquuivqU8FtvvVXDhg1Tenq6li9frmnTpmnLli26//77rT7Ecv9GjRqlyy+/XHl5edq4caN+/etf68ILL1Rpaak8Hs8xdQyfeOIJpaSk6PLLL49af7Qcw32dF47Ue+eOHTu67HxKIMJBKS4u1po1a/TWW29FrR8/frz19ZAhQ9SzZ09dcMEF2rhxo/r163ekm3lQLrzwQuvrk08+Wfn5+erbt6+effbZIxpUjpTHHntMF154oXJycqx1R/Pxc7K2tjb9+Mc/ljFGc+fOjdo2efJk6+uTTz5ZXq9XP/vZzzRjxoyj4vOwrrzySuvrIUOG6OSTT1a/fv20dOlSXXDBBTa2rOv99a9/1ZgxY5SQkBC1/mg5ht90XjjacMnMBt27d5fH49nrbvva2lplZ2fb1Kr9mzBhgubPn6833nhDvXv3/tba/Px8SdKGDRskSdnZ2fvsb+e2b6vx+/1HNJikpqbqhBNO0IYNG5Sdna3W1lbV19fv1a79tbtz27fVHOm+ff7553r99dd1ww03fGvd0Xz8OtvzbX9f2dnZqquri9re3t6u7du3d8lxPRJ/x51h6PPPP1dJSUnU6NC+5Ofnq729XZ999pmk2O/f1x1//PHq3r171L/Jo/0YStK///1vVVRU7PdvUorNY/hN54Uj9d7ZledTApENvF6vhg8frsWLF1vrIpGIFi9erGAwaGPL9s0YowkTJuiFF17QkiVL9hqi3Zfy8nJJUs+ePSVJwWBQq1evjnoD63wTHzx4sFWz5++ks+ZI/04aGxu1ceNG9ezZU8OHD1d8fHxUuyoqKlRVVWW162jq2+OPP67MzEwVFRV9a93RfPzy8vKUnZ0d1ZZwOKyVK1dGHbP6+nqVlZVZNUuWLFEkErHCYDAY1Jtvvqm2tjarpqSkRAMGDFBaWppVY0efO8PQ+vXr9frrrysjI2O/rykvL5fb7bYuM8Vy//bliy++0LZt26L+TR7Nx7DTY489puHDh2vo0KH7rY2lY7i/88KReu/s0vPpQd2CjS7z9NNPG5/PZ+bNm2fWrVtnxo8fb1JTU6Puto8VN998swkEAmbp0qVRj3/u2rXLGGPMhg0bzN13323effddU1lZaV566SVz/PHHmxEjRlj76Hy8cuTIkaa8vNy8+uqrpkePHvt8vHLKlCnmo48+MnPmzDkij6b/8pe/NEuXLjWVlZXm7bffNgUFBaZ79+6mrq7OGLP70dE+ffqYJUuWmHfffdcEg0ETDAaPir7tqaOjw/Tp08dMnTo1av3RePwaGhrM+++/b95//30jydx///3m/ffft56ymjlzpklNTTUvvfSS+fDDD82ll166z8fuTz31VLNy5Urz1ltvme985ztRj2zX19ebrKwsc80115g1a9aYp59+2iQlJe31SHNcXJz5n//5H/PRRx+ZO+64o0seaf62/rW2tppLLrnE9O7d25SXl0f9TXY+mbN8+XIze/ZsU15ebjZu3Gj+9re/mR49ephrr702Jvq3vz42NDSYX/3qV6a0tNRUVlaa119/3QwbNsx85zvfMc3NzdY+jtZj2CkUCpmkpCQzd+7cvV4f68dwf+cFY47ce2dXnU8JRDb605/+ZPr06WO8Xq8544wzzIoVK+xu0j5J2ufy+OOPG2OMqaqqMiNGjDDp6enG5/OZ/v37mylTpkTNY2OMMZ999pm58MILTWJiounevbv55S9/adra2qJq3njjDXPKKacYr9drjj/+eOtnHE5XXHGF6dmzp/F6vaZXr17miiuuMBs2bLC2NzU1mZ///OcmLS3NJCUlmR/+8Idmy5YtR0Xf9rRo0SIjyVRUVEStPxqP3xtvvLHPf5Njx441xux+9P63v/2tycrKMj6fz1xwwQV79Xvbtm3mqquuMsnJycbv95vrrrvONDQ0RNV88MEH5uyzzzY+n8/06tXLzJw5c6+2PPvss+aEE04wXq/XnHjiiWbBggWHtX+VlZXf+DfZOa9UWVmZyc/PN4FAwCQkJJhBgwaZe+65JypM2Nm//fVx165dZuTIkaZHjx4mPj7e9O3b19x44417neCO1mPY6c9//rNJTEw09fX1e70+1o/h/s4LxhzZ986uOJ+6vuoYAACAY3EPEQAAcDwCEQAAcDwCEQAAcDwCEQAAcDwCEQAAcDwCEQAAcDwCEQAAcDwCEQAAcDwCEQAAcDwCEQAAcDwCEQAAcLz/A+njCFjxUKR/AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_o_loss)\n",
    "# plt.ylim([0, 10])\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810e340e-df91-49e7-af28-4a359986bb6c",
   "metadata": {},
   "source": [
    "## TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b21ac355-4335-4b04-95d8-74fe9c517118",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorboard import notebook\n",
    "# notebook.list() # View open TensorBoard instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5804160-c516-4e93-81b6-a099f164e5aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "afe901b0-fd41-4c3b-a1d4-3c3b2df97873",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %tensorboard --logdir=$TRAIN_LOG_DIR\n",
    "# %tensorboard --logdir=$EVAL_LOG_DIR\n",
    "# %tensorboard --logdir=$LOG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2019e4-2b6a-427b-bf14-1f9c679834d4",
   "metadata": {},
   "source": [
    "# Serve saved policy\n",
    "\n",
    "\n",
    "`input_fn_and_spec` is a tuple of (`input_fn`, `tensor_spec`)\n",
    "* When `input_fn_and_spec` is set, `tensor_spec` is the input for the action signature. \n",
    "* When `input_fn_and_spec == None`, the action signature takes as input `(time_step, policy_state)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db848ff-9973-4cd3-8d38-8cabe7da1a98",
   "metadata": {},
   "source": [
    "**TODOs**\n",
    "* register functions: `saver.register_function('q_network', network, self._time_step_spec.observation)`\n",
    "* specify input signature for `tf.function`: `@tf.function(input_signature=[tf.TensorSpec([], tf.float32)])`\n",
    "* write eval datasets to BQ table? see docs re: [load BQ table from dataframe](https://cloud.google.com/bigquery/docs/samples/bigquery-load-table-dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b62080d-e218-4e79-aa22-d8c7097cfa16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-local-v16/run-20241211-215732/artifacts/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-local-v16/run-20241211-215732/artifacts/fingerprint.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-local-v16/run-20241211-215732/artifacts/policy_specs.pbtxt\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-local-v16/run-20241211-215732/artifacts/saved_model.pb\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-local-v16/run-20241211-215732/artifacts/assets/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/reinforce-local-v16/run-20241211-215732/artifacts/variables/\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls $ARTIFACTS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72c30b1f-1db4-4093-b835-4850e847d8a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! gsutil ls $POLICY_CHEKPT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac536673-b48a-47d3-9867-3397ec83f0f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject at 0x7f008948e770>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "def get_slice_tensor_fn(i):\n",
    "    def slice_tensor(tensor):\n",
    "        return tensor[:, i, tf.newaxis]\n",
    "    return slice_tensor\n",
    "\n",
    "def _build_infer_dict(\n",
    "    observed_action: int,\n",
    "    pred_actions: List,\n",
    "    pred_probs: List,\n",
    "    sequence_id: int,\n",
    ") -> Dict[str, Any]:\n",
    "    \n",
    "    dict_entry = {\n",
    "        \"sequence_id\": sequence_id,\n",
    "        \"observed_action_id\": observed_action,\n",
    "        \"top_k_pred_actions\": pred_actions,\n",
    "        \"top_k_pred_probs\": pred_probs,\n",
    "    }\n",
    "    return dict_entry\n",
    "\n",
    "trained_policy = tf.compat.v2.saved_model.load(ARTIFACTS_DIR)\n",
    "trained_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996104a1-ebc0-40b5-90f0-b7ad5b932000",
   "metadata": {},
   "source": [
    "### config bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5818e66c-9d7e-4488-8d5e-bdacf854fba2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables contained in hybrid-vertex.mvlens_rec_bandits_v2:\n",
      "infer_rfa_v15\n",
      "mv_b128_g12_a16\n",
      "mv_b128_g12_a16_v4\n",
      "mv_b128_g12_a16_v5\n",
      "mv_b128_g12_a16_v6\n",
      "mv_b128_g12_a16_v7\n",
      "mv_b256_g12_a16_v7\n",
      "mv_b256_g12_a16_v8\n",
      "mv_b256_g36_a48_v9\n",
      "training_dataset\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "bqclient = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "BIGQUERY_TMP_FILE   = \"tmp_infer_to_bq.json\"\n",
    "BQ_DATASET_ID       = f\"{PROJECT_ID}.{BIGQUERY_DATASET_NAME}\"\n",
    "BIGQUERY_TABLE_NAME = f\"infer_rfa_{EXP_VERSION}\"\n",
    "BQ_TABLE_REF        = f\"{PROJECT_ID}.{BIGQUERY_DATASET_NAME}.{BIGQUERY_TABLE_NAME}\"\n",
    "\n",
    "tables = bqclient.list_tables(BQ_DATASET_ID)\n",
    "print(f\"Tables contained in {BQ_DATASET_ID}:\")\n",
    "for table in tables:\n",
    "    print(f\"{table.table_id}\")\n",
    "    \n",
    "print(f\"\\nBQ_TABLE_REF {BQ_TABLE_REF}:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1eccd7dc-d2d3-421a-ac48-bb3c8572496d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! rm -rf $BIGQUERY_TMP_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9ac12f-c42b-4309-84dd-d97a5aabba20",
   "metadata": {},
   "source": [
    "### create infer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "831d0ee0-21b2-4346-a183-7e89da43d29d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference_dataset size: 198834\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_INFER_BATCHES = 50\n",
    "\n",
    "inference_dataset = create_tfrecord_ds(\n",
    "    tf.io.gfile.glob(val_files),\n",
    "    process_example_fn=process_example_fn,\n",
    "    batch_size=1,\n",
    "    num_shards=len(val_files),\n",
    "    repeat=False,\n",
    "    drop_remainder=True\n",
    ")\n",
    "\n",
    "if NUM_INFER_BATCHES is not None:\n",
    "    inference_dataset = inference_dataset.take(NUM_INFER_BATCHES)\n",
    "    \n",
    "print(f\"inference_dataset size: {len(list(inference_dataset))}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214465a5-9eda-4445-a909-f507422316ab",
   "metadata": {},
   "source": [
    "## Write to local file\n",
    "\n",
    "**TODOs**\n",
    "* fix formatting of `< input sequence, output prediction >` pairs\n",
    "* optimize this.. only utilizing ~7% of instance CPU :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb833e20-4619-4eca-9e88-a25708525e45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict_list = []\n",
    "\n",
    "with open(BIGQUERY_TMP_FILE, \"w\") as f:\n",
    "    \n",
    "    for batch in inference_dataset:\n",
    "\n",
    "        infer_trajectory, _ = batch\n",
    "        policy_state = trained_policy.get_initial_state(batch_size=1)\n",
    "        for i in tf.range(infer_trajectory.step_type.shape[1]): # 10\n",
    "            slice_tensor = get_slice_tensor_fn(i)\n",
    "            step_type = slice_tensor(infer_trajectory.step_type)    \n",
    "            if step_type == ts.StepType.LAST:\n",
    "                break\n",
    "            observation = tf.nest.map_structure(slice_tensor, infer_trajectory.observation)\n",
    "            time_step = ts.TimeStep(\n",
    "                step_type=step_type,\n",
    "                observation=observation,\n",
    "                reward=tf.zeros_like(step_type, tf.float32),\n",
    "                discount=tf.ones_like(step_type, tf.float32))\n",
    "\n",
    "            action_step = trained_policy.action((time_step, policy_state))\n",
    "            policy_state = action_step.state\n",
    "\n",
    "            # Remove singleton batch dim.\n",
    "            observed_action = tf.squeeze(slice_tensor(infer_trajectory.action), axis=0)\n",
    "            predicted_action = tf.squeeze(action_step.action, axis=0)\n",
    "            logits = tf.squeeze(action_step.info, axis=0)\n",
    "\n",
    "            predicted_action_logits = tf.gather(\n",
    "                logits, action_lookup_layer(predicted_action)\n",
    "            )\n",
    "            predicted_action_log_probs = (\n",
    "                tf.math.exp(predicted_action_logits) /\n",
    "                tf.math.exp(tf.reduce_logsumexp(logits))\n",
    "            )\n",
    "            # action_prob_list = [round(prob, 4) for prob in predicted_action_log_probs.numpy()]\n",
    "            \n",
    "            infer_dict = _build_infer_dict(\n",
    "                sequence_id = str(i.numpy()),\n",
    "                observed_action = int(observed_action.numpy()[0]),\n",
    "                pred_actions = predicted_action.numpy().tolist(),\n",
    "                pred_probs = predicted_action_log_probs.numpy().tolist(),\n",
    "            )\n",
    "            # dict_list.append(test_dict)\n",
    "            f.write(json.dumps(infer_dict) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bba3f75e-4dd0-49a4-acee-8ea20bbf165c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence_id': '9',\n",
       " 'observed_action_id': 0,\n",
       " 'top_k_pred_actions': [0, 3045, 33, 591, 1132],\n",
       " 'top_k_pred_probs': [0.05052383989095688,\n",
       "  0.0380273275077343,\n",
       "  0.03791634365916252,\n",
       "  0.03497983515262604,\n",
       "  0.028388403356075287]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25a92c3-b597-4119-ad5c-08a7f605e0e2",
   "metadata": {},
   "source": [
    "## Load BigQuery table from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3fd9fbfc-34f6-40f7-ade1-13cdd2aff8e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoadJob<project=hybrid-vertex, location=US, id=bca78b29-19b0-4715-bdbb-f904d4e4554e>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=[\n",
    "        bigquery.SchemaField(\"sequence_id\", \"INT64\"),\n",
    "        bigquery.SchemaField(\"observed_action_id\", \"INT64\"),\n",
    "        bigquery.SchemaField(\"top_k_pred_actions\", \"INT64\", mode=\"REPEATED\"),\n",
    "        bigquery.SchemaField(\"top_k_pred_probs\", \"FLOAT64\", mode=\"REPEATED\"),\n",
    "    ],\n",
    "    source_format=bigquery.SourceFormat.NEWLINE_DELIMITED_JSON,\n",
    ")\n",
    "\n",
    "with open(BIGQUERY_TMP_FILE, \"rb\") as source_file:\n",
    "    load_job = bqclient.load_table_from_file(\n",
    "        source_file, \n",
    "        BQ_TABLE_REF, \n",
    "        job_config=job_config\n",
    "    )\n",
    "\n",
    "load_job.result()  # Wait for the job to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbb1a89-f94f-4704-89f3-d4ba0ae7de29",
   "metadata": {
    "tags": []
   },
   "source": [
    "### check BigQuery table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "6a587cc4-e39a-4f0d-b73b-65b26daf3e63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>observed_action_id</th>\n",
       "      <th>top_k_pred_actions</th>\n",
       "      <th>top_k_pred_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1272</td>\n",
       "      <td>[1245, 1854, 1816, 344, 2326]</td>\n",
       "      <td>[0.014563368633389473, 0.012623777613043785, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2044</td>\n",
       "      <td>[1908, 1917, 2884, 2310, 1907]</td>\n",
       "      <td>[0.005249397829174995, 0.00501882191747427, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3633</td>\n",
       "      <td>[1178, 2502, 1220, 1196, 537]</td>\n",
       "      <td>[0.05298368260264397, 0.03260182589292526, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2645</td>\n",
       "      <td>[1372, 1726, 148, 1245, 505]</td>\n",
       "      <td>[0.002528125885874033, 0.002159023191779852, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2330</td>\n",
       "      <td>[1245, 174, 1287, 3292, 2220]</td>\n",
       "      <td>[0.009872911497950554, 0.007305745035409927, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence_id  observed_action_id              top_k_pred_actions  \\\n",
       "0            0                1272   [1245, 1854, 1816, 344, 2326]   \n",
       "1            0                2044  [1908, 1917, 2884, 2310, 1907]   \n",
       "2            0                3633   [1178, 2502, 1220, 1196, 537]   \n",
       "3            0                2645    [1372, 1726, 148, 1245, 505]   \n",
       "4            0                2330   [1245, 174, 1287, 3292, 2220]   \n",
       "\n",
       "                                    top_k_pred_probs  \n",
       "0  [0.014563368633389473, 0.012623777613043785, 0...  \n",
       "1  [0.005249397829174995, 0.00501882191747427, 0....  \n",
       "2  [0.05298368260264397, 0.03260182589292526, 0.0...  \n",
       "3  [0.002528125885874033, 0.002159023191779852, 0...  \n",
       "4  [0.009872911497950554, 0.007305745035409927, 0...  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "    SELECT * \n",
    "    FROM `{BQ_TABLE_REF}`\n",
    "    LIMIT 5\n",
    "\"\"\"\n",
    "bqclient.query(query).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3171238b-8c8d-4425-baad-b163bb5f28a1",
   "metadata": {},
   "source": [
    "### tmp - original agent eval works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d4153dfc-29af-43a1-9440-9362b10210a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AccuracyAtK  =  0.08798958\n",
      "AveragePerClassAccuracyAtK  =  0.033557743\n",
      "WeightedReturns_gamma_1  =  -311.1016\n"
     ]
    }
   ],
   "source": [
    "eval_metric_results = evaluate(\n",
    "    policy=tf_agent.policy,\n",
    "    dataset=eval_dataset,\n",
    "    offline_eval_metrics=offline_eval_metrics,\n",
    "    train_step=global_step,\n",
    "    summary_writer=eval_summary_writer,\n",
    "    summary_prefix='Metrics',\n",
    ")\n",
    "metric_utils.log_metrics(offline_eval_metrics)\n",
    "for metric in offline_eval_metrics:\n",
    "    print(f\"{metric.name} = {metric.result().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d75f30b7-d3ee-4a9d-985d-990e812ab23a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('AccuracyAtK',\n",
       "              <tf.Tensor: shape=(), dtype=float32, numpy=0.08798958>),\n",
       "             ('AveragePerClassAccuracyAtK',\n",
       "              <tf.Tensor: shape=(), dtype=float32, numpy=0.033557743>),\n",
       "             ('WeightedReturns_gamma_1',\n",
       "              <tf.Tensor: shape=(), dtype=float32, numpy=-311.1016>)])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_metric_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471ee879-596b-469c-bee7-a6df54e9679b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7bcb7f1b-a868-4463-bda1-3318c2d18c63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'action': <tf.Tensor: shape=(1, 10), dtype=int64, numpy=array([[1575, 1189,  257, 1373, 1222, 1179,  293, 1959, 2255,    0]])>,\n",
       " 'discount': <tf.Tensor: shape=(1, 10), dtype=float32, numpy=array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)>,\n",
       " 'next_step_type': <tf.Tensor: shape=(1, 10), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>,\n",
       " 'observation': <tf.Tensor: shape=(1, 10), dtype=int64, numpy=array([[1178, 1575, 1189,  257, 1373, 1222, 1179,  293, 1959,    0]])>,\n",
       " 'policy_info': (),\n",
       " 'reward': <tf.Tensor: shape=(1, 10), dtype=float32, numpy=array([[4., 4., 5., 3., 4., 5., 4., 4., 4., 0.]], dtype=float32)>,\n",
       " 'step_type': <tf.Tensor: shape=(1, 10), dtype=int32, numpy=array([[0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_dataset = create_tfrecord_ds(\n",
    "    tf.io.gfile.glob(val_files),\n",
    "    process_example_fn=process_example_fn,\n",
    "    batch_size=1,\n",
    "    num_shards=len(val_files),\n",
    "    repeat=False,\n",
    "    drop_remainder=True\n",
    ")\n",
    "infer_batch = list(inference_dataset.take(1))[0]\n",
    "traj_infer, weights_infer = infer_batch\n",
    "\n",
    "traj_infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3ec5552-c7f6-48b3-9429-744c71f58251",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((ListWrapper([<tf.Tensor: shape=(1, 25), dtype=float32, numpy=\n",
       "  array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>, <tf.Tensor: shape=(1, 25), dtype=float32, numpy=\n",
       "  array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>]),),)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_state = tf_agent.policy.get_initial_state(traj_infer.step_type.shape[0])\n",
    "policy_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b15530b0-a828-4e11-b48d-478064261328",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_infer.step_type.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8b171322-ce3a-4b4d-b9a7-a00f054b1d31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_actions = []\n",
    "predicted_info = []\n",
    "\n",
    "for i in tf.range(traj_infer.step_type.shape[1]):\n",
    "\n",
    "    observation = traj_infer.observation[:, i, tf.newaxis]\n",
    "    step_type = traj_infer.step_type[:, i, tf.newaxis]\n",
    "    time_step = ts.TimeStep(\n",
    "        step_type=step_type,\n",
    "        observation=observation,\n",
    "        reward=tf.zeros_like(step_type, tf.float32),\n",
    "        discount=tf.ones_like(step_type, tf.float32)\n",
    "    )\n",
    "\n",
    "    action_step = tf_agent.policy.action(time_step, policy_state)\n",
    "    policy_state = action_step.state\n",
    "    predicted_actions.append(action_step.action)\n",
    "    predicted_info.append(action_step.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "66272dee-0d6f-41ee-a2f7-eac71b79349f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[2286, 2327, 2693, 2643, 2890]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[ 604,  293,  589, 1203, 1178]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[ 740,  537, 1203, 1176, 1201]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[ 604, 1203,  589,  293, 1575]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[ 604, 1203, 1575,  589,  523]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[ 604, 1575, 1203,  523, 1176]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[ 604, 1575, 1203,  523,  293]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[ 604, 1203, 1575, 1186,  896]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[ 604,  293, 1203, 1073, 1227]])>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[1239, 2327,    0, 3045,  604]])>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "75f7e9ce-8192-4b06-b65a-fd9a08028bca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tf_agents.trajectories import policy_step\n",
    "\n",
    "predicted_policy_steps = policy_step.PolicyStep(\n",
    "    action=tf.stack(predicted_actions, axis=1),\n",
    "    info=tf.stack(predicted_info, axis=1),\n",
    "    state=(),\n",
    ")\n",
    "# predicted_policy_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "44b37554-7206-428e-80c4-49c5409e3cde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((ListWrapper([<tf.Tensor: shape=(1, 25), dtype=float32, numpy=\n",
       "  array([[-0.9924962 , -0.43294802, -0.13293791, -0.98814684, -0.95580554,\n",
       "          -0.75280285, -0.3342112 ,  0.04315013, -0.22813249, -0.48958498,\n",
       "           0.36431283, -0.05004348,  0.269563  ,  0.80608946, -0.75890887,\n",
       "           0.88578224,  0.5588108 ,  0.9820511 , -0.9309011 ,  0.25365648,\n",
       "           0.15573905, -0.25155395, -0.6851974 ,  0.58167934, -0.9428432 ]],\n",
       "        dtype=float32)>, <tf.Tensor: shape=(1, 25), dtype=float32, numpy=\n",
       "  array([[-3.8534534 , -0.58873487, -0.13497807, -3.422552  , -1.930584  ,\n",
       "          -0.9811599 , -0.34769666,  0.0431806 , -0.23406102, -0.5355571 ,\n",
       "           0.38509816, -0.0511927 ,  0.27639252,  1.1330612 , -1.0014565 ,\n",
       "           1.402878  ,  0.6784168 ,  2.3521845 , -1.6693163 ,  0.26190168,\n",
       "           0.15705466, -0.2570712 , -0.8388488 ,  0.9551589 , -1.8594316 ]],\n",
       "        dtype=float32)>]),),)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_step.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0707b51a-5feb-4a77-b010-c1c34e284414",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10, 1), dtype=int64, numpy=\n",
       "array([[[1230],\n",
       "        [ 740],\n",
       "        [2937],\n",
       "        [1203],\n",
       "        [ 911],\n",
       "        [1284],\n",
       "        [ 907],\n",
       "        [  33],\n",
       "        [ 220],\n",
       "        [   0]]])>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_actions = tf.expand_dims(traj_infer.action, axis=2)\n",
    "observed_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5913da67-976c-4f93-8d2b-fa3970969cfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10, 5), dtype=int64, numpy=\n",
       "array([[[2286, 2327, 2693, 2643, 2890],\n",
       "        [ 604,  293,  589, 1203, 1178],\n",
       "        [ 740,  537, 1203, 1176, 1201],\n",
       "        [ 604, 1203,  589,  293, 1575],\n",
       "        [ 604, 1203, 1575,  589,  523],\n",
       "        [ 604, 1575, 1203,  523, 1176],\n",
       "        [ 604, 1575, 1203,  523,  293],\n",
       "        [ 604, 1203, 1575, 1186,  896],\n",
       "        [ 604,  293, 1203, 1073, 1227],\n",
       "        [1239, 2327,    0, 3045,  604]]])>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_actions_stacked = tf.stack(predicted_actions, axis=1)\n",
    "predicted_actions_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2af98342-9ad3-4864-9fd7-e7de5fede10c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=bool, numpy=\n",
       "array([[False, False, False,  True, False, False, False, False, False,\n",
       "         True]])>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_predictions = tf.reduce_any(\n",
    "    predicted_actions_stacked == observed_actions, axis=2\n",
    ")\n",
    "correct_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f9f046cc-75b3-4316-b81a-f0951ca0cade",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Predictions:\n",
      "tf.Tensor([[False False False  True False False False False False  True]], shape=(1, 10), dtype=bool)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Correct Predictions:')\n",
    "print(correct_predictions)\n",
    "print('-' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cf5169b8-7086-430b-9caa-aefca67ff7d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed Actions (vocab):\n",
      "tf.Tensor([[1231  741 2938 1204  912 1285  908   34  221    1]], shape=(1, 10), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print('Observed Actions (vocab):')\n",
    "print(action_lookup_layer(traj_infer.action))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0cf39639-5aa7-4120-817a-2b4a411110df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Actions (vocab):\n",
      "tf.Tensor(\n",
      "[[[2287 2328 2694 2644 2891]]\n",
      "\n",
      " [[ 605  294  590 1204 1179]]\n",
      "\n",
      " [[ 741  538 1204 1177 1202]]\n",
      "\n",
      " [[ 605 1204  590  294 1576]]\n",
      "\n",
      " [[ 605 1204 1576  590  524]]\n",
      "\n",
      " [[ 605 1576 1204  524 1177]]\n",
      "\n",
      " [[ 605 1576 1204  524  294]]\n",
      "\n",
      " [[ 605 1204 1576 1187  897]]\n",
      "\n",
      " [[ 605  294 1204 1074 1228]]\n",
      "\n",
      " [[1240 2328    1 3046  605]]], shape=(10, 1, 5), dtype=int64)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Predicted Actions (vocab):')\n",
    "print(action_lookup_layer(predicted_actions))\n",
    "print('-' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7add3359-2591-4eb5-ae4f-ba2edf5efc50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
