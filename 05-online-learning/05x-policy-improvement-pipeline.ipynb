{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db5e34bc-48df-40d1-a51f-7fe7325b6c5d",
   "metadata": {},
   "source": [
    "# Simulate Generalized Policy Iteration (GPI) for Contextual Bandits\n",
    "\n",
    "> Orchestrate GPI jobs with Vertex Pipelines to simulate iterative policy evaluation and improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff6d628-1697-4bb4-80bc-ad3849057302",
   "metadata": {
    "tags": []
   },
   "source": [
    "### GPI for Contextual Bandits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feaf8b5-30cb-4a0f-8989-c074bb210818",
   "metadata": {},
   "source": [
    "**Generalized Policy Iteration (GPI)** consists of two simultaneous, interacting processes that eventually converge to the optimal policy and value functions as the environment is interacted with:\n",
    "\n",
    "1. **Policy evaluation** updates the value function to make it more consistent with the current policy and environment\n",
    "2. **Policy improvement** updates the policy to make it more greedy with respect to the current value function\n",
    "\n",
    "<img src=\"imgs/gpi.png\" \n",
    "     align=\"center\" \n",
    "     width=\"850\"\n",
    "     height=\"850\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fff4943-0163-45d3-90e9-d5b85147f675",
   "metadata": {},
   "source": [
    "**Relationship between model and policy:**\n",
    "* Model: estimate value of a particular item (or slate)\n",
    "* Policy: use the model to generate a decision response (e.g., recommendation, ranking)\n",
    "\n",
    "In the diagram below, not pushing the \"model\" itself, but rather a *policy* based on the model. \n",
    "\n",
    "RL Agent's include:\n",
    "* **policy**: mapping function determing agent's behavior\n",
    "* **value function**: Tells agent how “good” each state is\n",
    "* **model**: Agent’s representation of the environment\n",
    "\n",
    "<img src=\"imgs/policy_improvement_and_eval.png\" \n",
    "     align=\"center\" \n",
    "     width=\"850\"\n",
    "     height=\"850\"/>\n",
    "     \n",
    "*As duration of the GPI cycle decreases, we approach fully continuous, online learning*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b5b8e6-fbd6-4fe4-a201-17907ea3fe2d",
   "metadata": {},
   "source": [
    "## Notebook config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f9bf5b1-ffb5-47c1-8323-65ceadb4a470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "VERSION        = \"v2\"                       # TODO\n",
    "PREFIX         = f'rec-bandits-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5b85c6e-0d53-4cea-8d94-9e8cff370974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"rec-bandits-v2\"\n",
      "VERSION                  = \"v2\"\n",
      "\n",
      "BUCKET_NAME              = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_NAME    = \"mvlens_rec_bandits_v2\"\n",
      "BIGQUERY_TABLE_NAME      = \"training_dataset\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-rec-bandits-v2\"\n",
      "\n",
      "DOCKERNAME_01            = \"Dockerfile_train_my_perarm_env\"\n",
      "IMAGE_NAME_01            = \"train-my-perarm-env-v2\"\n",
      "IMAGE_URI_01             = \"gcr.io/hybrid-vertex/train-my-perarm-env-v2\"\n",
      "\n",
      "DOCKERNAME_02            = \"Dockerfile_perarm_feats\"\n",
      "IMAGE_NAME_02            = \"train-perarm-feats-v2\"\n",
      "IMAGE_URI_02             = \"gcr.io/hybrid-vertex/train-perarm-feats-v2\"\n",
      "\n",
      "DOCKERNAME_03            = \"Dockerfile_ranking_bandit\"\n",
      "IMAGE_NAME_03            = \"train-rank-bandit-v2\"\n",
      "IMAGE_URI_03             = \"gcr.io/hybrid-vertex/train-rank-bandit-v2\"\n",
      "\n",
      "DOCKERNAME_04            = \"Dockerfile_train_bandit_e2e\"\n",
      "IMAGE_NAME_04            = \"train-mab-e2e-v2\"\n",
      "IMAGE_URI_04             = \"gcr.io/hybrid-vertex/train-mab-e2e-v2\"\n",
      "\n",
      "DOCKERNAME_04_pred       = \"Dockerfile_pred_bandit_e2e\"\n",
      "IMAGE_NAME_04_pred       = \"pred-mab-e2e-v2\"\n",
      "IMAGE_URI_04_pred        = \"gcr.io/hybrid-vertex/pred-mab-e2e-v2\"\n",
      "\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/local_docker_tfa\"\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bb57e5a-a7de-4d63-96be-66c46c7c7164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version : 2.13.0\n",
      "tf-agents version  : 0.17.0\n",
      "kfp version           : 2.3.0\n",
      "storage SDK version   : 2.16.0\n",
      "bigquery SDK version  : 3.11.4\n",
      "vertex_ai SDK version : 1.46.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Callable, Dict, List, Optional, TypeVar, Any\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "### pipelines\n",
    "import kfp\n",
    "from kfp import compiler, dsl, components\n",
    "from kfp.dsl import component, Metrics\n",
    "from google_cloud_pipeline_components.types import artifact_types\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "#python warning \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")\n",
    "import tf_agents\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.bandits.policies import policy_utilities\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents import trajectories\n",
    "\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.metrics import export_utils\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.utils import common\n",
    "\n",
    "TF_VERSION = tf.__version__\n",
    "TFA_VERSION = tf_agents.__version__\n",
    "print(f'tensorflow version : {TF_VERSION}')\n",
    "print(f'tf-agents version  : {TFA_VERSION}')\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform, storage, bigquery\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "# bigquery client\n",
    "bqclient = bigquery.Client(project=PROJECT_ID,)\n",
    "\n",
    "KFP_SDK_VERSION = kfp.__version__\n",
    "GCS_SDK_VERSION = storage.__version__\n",
    "BQ_SDK_VERSION  = bigquery.__version__\n",
    "AIP_SDK_VERSION = aiplatform.__version__\n",
    "print(f'kfp version           : {KFP_SDK_VERSION}')\n",
    "print(f'storage SDK version   : {GCS_SDK_VERSION}')\n",
    "print(f'bigquery SDK version  : {BQ_SDK_VERSION}')\n",
    "print(f'vertex_ai SDK version : {AIP_SDK_VERSION}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbebaf30-c406-4179-856a-6e99f344a15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade requests-toolbelt\n",
    "# pip install --force-reinstall -v \"requests-toolbelt==0.10.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55cf87b8-20d7-4a98-aeb9-7bc40874019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this repo\n",
    "sys.path.append(\"..\")\n",
    "# from src.utils import train_utils\n",
    "from src.data import data_utils, data_config\n",
    "# from src.trainer import train_batched_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6911089-1218-4a0a-a049-098ca444d084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GPU\n",
    "# from numba import cuda \n",
    "# import gc\n",
    "\n",
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# device = cuda.get_current_device()\n",
    "# device.reset()\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe90e89a-ad3f-4998-938d-2e5c8a9d7894",
   "metadata": {},
   "source": [
    "# Policy improvement pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fd564e7-4941-4e38-bbda-39045e4e47c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/05-online-learning\n"
     ]
    }
   ],
   "source": [
    "REPO_SRC  = \"src\"\n",
    "POLICY_PIPE_DIR = \"policy_pipeline\"\n",
    "POLICY_PIPE_SUBDIR = \"components\"\n",
    "\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f46a115-8138-441e-b2f8-cded57696401",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf ../$REPO_SRC/$POLICY_PIPE_DIR/$POLICY_PIPE_SUBDIR\n",
    "# ! mkdir ../$REPO_SRC/$POLICY_PIPE_DIR\n",
    "! mkdir ../$REPO_SRC/$POLICY_PIPE_DIR/$POLICY_PIPE_SUBDIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "767166f6-aaf7-4438-afb3-c52d27eada43",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../$REPO_SRC/$POLICY_PIPE_DIR/$POLICY_PIPE_SUBDIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455a7bc8-7edb-4628-a9ad-514ff21f6296",
   "metadata": {},
   "source": [
    "## custom components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69d800b7-dabb-422e-a3ae-fdedb8c9961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "POLICY_PIPE_IMAGE = f\"gcr.io/{PROJECT_ID}/mv-gpi-pipeline\"\n",
    "DOCKERNAME_GPI_PIPE  = \"Dockerfile_gpi_pipe\"\n",
    "\n",
    "POLICY_TRAIN_IMAGE = f\"gcr.io/{PROJECT_ID}/mv-gpi-train\"\n",
    "DOCKERNAME_GPI_TRAIN  = \"Dockerfile_gpi_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c98714d4-60d2-4f13-a088-2502ddda97d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ID          = \"hybrid-vertex\"\n",
      "REGION              = \"us-central1\"\n",
      "PREFIX              = \"rec-bandits-v2\"\n",
      "BUCKET_NAME         = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "POLICY_PIPE_IMAGE   = \"gcr.io/hybrid-vertex/mv-gpi-pipeline\"\n",
      "POLICY_TRAIN_IMAGE  = \"gcr.io/hybrid-vertex/mv-gpi-train\"\n",
      "KFP_SDK_VERSION     = \"2.3.0\"\n",
      "GCS_SDK_VERSION     = \"2.16.0\"\n",
      "BQ_SDK_VERSION      = \"3.11.4\"\n",
      "AIP_SDK_VERSION     = \"1.46.0\"\n",
      "TF_VERSION          = \"2.13.0\"\n",
      "TFA_VERSION         = \"0.17.0\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe_config = f'''PROJECT_ID          = \\\"{PROJECT_ID}\\\"\n",
    "REGION              = \\\"{REGION}\\\"\n",
    "PREFIX              = \\\"{PREFIX}\\\"\n",
    "BUCKET_NAME         = \\\"{BUCKET_NAME}\\\"\n",
    "POLICY_PIPE_IMAGE   = \\\"{POLICY_PIPE_IMAGE}\"\n",
    "POLICY_TRAIN_IMAGE  = \\\"{POLICY_TRAIN_IMAGE}\"\n",
    "KFP_SDK_VERSION     = \\\"{KFP_SDK_VERSION}\\\"\n",
    "GCS_SDK_VERSION     = \\\"{GCS_SDK_VERSION}\\\"\n",
    "BQ_SDK_VERSION      = \\\"{BQ_SDK_VERSION}\\\"\n",
    "AIP_SDK_VERSION     = \\\"{AIP_SDK_VERSION}\\\"\n",
    "TF_VERSION          = \\\"{TF_VERSION}\\\"\n",
    "TFA_VERSION         = \\\"{TFA_VERSION}\\\"\n",
    "'''\n",
    "print(pipe_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "290cde03-fa8e-4ce8-8f32-6e2535e4a66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../{REPO_SRC}/{POLICY_PIPE_DIR}/{POLICY_PIPE_SUBDIR}/pipeline_config.py', 'w') as f:\n",
    "    f.write(pipe_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "578a470a-296a-48e4-842e-47cc6b54be46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline_config.py\n"
     ]
    }
   ],
   "source": [
    "!ls ../$REPO_SRC/$POLICY_PIPE_DIR/$POLICY_PIPE_SUBDIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2b454d-b551-451f-b41a-5ddcd850c170",
   "metadata": {},
   "source": [
    "### prepare eval dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ac449fc-3bf0-4600-b44a-8da23b57e1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../src/policy_pipeline/components/prep_eval_ds.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../{REPO_SRC}/{POLICY_PIPE_DIR}/{POLICY_PIPE_SUBDIR}/prep_eval_ds.py\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp import dsl\n",
    "from . import pipeline_config\n",
    "\n",
    "@dsl.component(\n",
    "    base_image=pipeline_config.POLICY_PIPE_IMAGE,\n",
    "    install_kfp_package=False\n",
    ")\n",
    "def prep_eval_ds(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    pipeline_version: str,\n",
    "    bucket_name: str,\n",
    "    example_gen_gcs_path: str,\n",
    "    eval_ds: dsl.Output[dsl.Dataset],\n",
    "    ds_skip: int = 0,\n",
    "    ds_take: int = 0,\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('num_eval_samples', int),\n",
    "    ('total_eval_rewards', float),\n",
    "    ('ds_skip', int),\n",
    "    ('ds_take', int),\n",
    "]):\n",
    "    \n",
    "    import os\n",
    "    import json\n",
    "    import logging\n",
    "    import numpy as np\n",
    "    import pickle as pkl\n",
    "    from google.cloud import aiplatform, bigquery, storage\n",
    "    from typing import Callable, Dict, List, Optional, TypeVar, Any\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    \n",
    "    # this repo\n",
    "    from src.data import data_utils\n",
    "    \n",
    "    # set client SDKs\n",
    "    aiplatform.init(\n",
    "        project=project_id,\n",
    "        location=location,\n",
    "        # experiment=experiment_name,\n",
    "    )\n",
    "    storage_client = storage.Client(project=project_id)\n",
    "    \n",
    "    # get eval tf-records\n",
    "    val_files = []\n",
    "    for blob in storage_client.list_blobs(f\"{bucket_name}\", prefix=f'{example_gen_gcs_path}/val'):\n",
    "        if '.tfrecord' in blob.name:\n",
    "            val_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "            \n",
    "    val_dataset = tf.data.TFRecordDataset(val_files)\n",
    "    val_dataset = val_dataset.map(data_utils._parse_function, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    eval_ds = val_dataset.batch(1)\n",
    "    \n",
    "    if ds_skip > 0:\n",
    "        eval_ds = eval_ds.skip(ds_skip)\n",
    "        logging.info(f\"setting dataset skip: {ds_skip}\")\n",
    "    \n",
    "    if ds_take > 0:\n",
    "        eval_ds = eval_ds.take(ds_take)\n",
    "        logging.info(f\"setting dataset take: {ds_take}\")\n",
    "        \n",
    "    # get length (size) of eval ds\n",
    "    NUM_EVAL_SAMPLES = len(list(eval_ds))\n",
    "    logging.info(f\"NUM_EVAL_SAMPLES : {NUM_EVAL_SAMPLES}\")\n",
    "    \n",
    "    # get total rewards from eval slice\n",
    "    val_rewards = []\n",
    "    for x in eval_ds:\n",
    "        val_rewards.append(x[f\"{data_utils.TARGET_FEATURE_NAME}\"][0].numpy())\n",
    "    \n",
    "    TOTAL_EVAL_REWARD = tf.reduce_sum(val_rewards).numpy().tolist()\n",
    "    logging.info(f\"TOTAL_EVAL_REWARD : {TOTAL_EVAL_REWARD}\")\n",
    "    \n",
    "    return (\n",
    "        NUM_EVAL_SAMPLES,\n",
    "        TOTAL_EVAL_REWARD,\n",
    "        ds_skip,\n",
    "        ds_take,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbc4747-79f3-4889-8fc9-3a589dcb43a0",
   "metadata": {},
   "source": [
    "### Train agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df3a1b3f-9ef1-4d66-9ad2-c95ecc28bce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../src/policy_pipeline/components/train_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../{REPO_SRC}/{POLICY_PIPE_DIR}/{POLICY_PIPE_SUBDIR}/train_agent.py\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp import dsl\n",
    "from . import pipeline_config\n",
    "\n",
    "@dsl.component(\n",
    "    base_image=pipeline_config.POLICY_PIPE_IMAGE,\n",
    "    install_kfp_package=False\n",
    ")\n",
    "def train_agent(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    pipeline_version: str,\n",
    "    bucket_name: str,\n",
    "    example_gen_gcs_path: str,\n",
    "    tfrecord_name: str,\n",
    "    hparams: str,\n",
    "    experiment_name: str,\n",
    "    experiment_run_tag: str,\n",
    "    tensorboard_resource_name: str,\n",
    "    service_account: str,\n",
    "    # train job\n",
    "    num_epochs: int,\n",
    "    log_interval: int,\n",
    "    total_train_take: int,\n",
    "    total_train_skip: int,\n",
    "    gpi_image_name: str, # TODO\n",
    "    # train compute\n",
    "    replica_count: int,\n",
    "    machine_type: str,\n",
    "    accelerator_count: int, \n",
    "    accelerator_type: str,\n",
    "    # train_ds: dsl.Input[google.VertexDataset], # google.VertexDataset\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('base_output_dir', str),\n",
    "    ('log_dir', str),\n",
    "    ('artifacts_dir', str),\n",
    "]):\n",
    "    # imports\n",
    "    import os\n",
    "    import time\n",
    "    import logging\n",
    "    logging.disable(logging.WARNING)\n",
    "    \n",
    "    # this repo\n",
    "    from src.utils import train_utils\n",
    "    \n",
    "    from google.cloud import aiplatform, storage\n",
    "    \n",
    "    # GCP clients\n",
    "    aiplatform.init(\n",
    "        project=project_id, \n",
    "        location=location,\n",
    "        experiment=experiment_name\n",
    "    )\n",
    "    storage_client = storage.Client(project=project_id)\n",
    "    \n",
    "    # dataset\n",
    "    TFRECORD_FILE = (\n",
    "        f\"gs://{bucket_name}/{example_gen_gcs_path}/{tfrecord_name}/{tfrecord_name}.tfrecord\"\n",
    "    )\n",
    "    # experiment\n",
    "    invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    RUN_NAME          = f'{experiment_run_tag}-{invoke_time}'\n",
    "    CHECKPT_DIR       = f\"gs://{bucket_name}/{experiment_name}/chkpoint\"\n",
    "    BASE_OUTPUT_DIR   = f\"gs://{bucket_name}/{experiment_name}/{RUN_NAME}\"\n",
    "    LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "    ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"\n",
    "    \n",
    "    # job config \n",
    "    JOB_NAME = f'train-{experiment_name}-{experiment_run_tag}'\n",
    "    logging.info(f'JOB_NAME: {JOB_NAME}')\n",
    "    \n",
    "    TF_GPU_THREAD_COUNT   = '4'      # '1' | '4' | '8'\n",
    "    \n",
    "    WORKER_ARGS = [\n",
    "        f\"--project={project_id}\"\n",
    "        , f\"--location={location}\"\n",
    "        , f\"--bucket_name={bucket_name}\"\n",
    "        , f\"--experiment_name={experiment_name}\"\n",
    "        , f\"--experiment_run={RUN_NAME}\"\n",
    "        , f\"--log_dir={LOG_DIR}\"\n",
    "        , f\"--artifacts_dir={ARTIFACTS_DIR}\"\n",
    "        , f\"--chkpoint_dir={CHECKPT_DIR}\"\n",
    "        , f\"--hparams={hparams}\"\n",
    "        ### job config\n",
    "        , f\"--num_epochs={num_epochs}\"\n",
    "        , f\"--tf_record_file={TFRECORD_FILE}\"\n",
    "        , f\"--log_interval={log_interval}\"\n",
    "        , f\"--total_train_take={total_train_take}\"\n",
    "        , f\"--total_train_skip={total_train_skip}\"\n",
    "        ### performance\n",
    "        , f\"--tf_gpu_thread_count={TF_GPU_THREAD_COUNT}\"\n",
    "        , f\"--use_gpu\"\n",
    "        # , f\"--use_tpu\"\n",
    "        , f\"--cache_train_data\"\n",
    "    ]\n",
    "    \n",
    "    WORKER_POOL_SPECS = train_utils.prepare_worker_pool_specs(\n",
    "        image_uri=f\"{gpi_image_name}:latest\",\n",
    "        args=WORKER_ARGS,\n",
    "        replica_count=replica_count,\n",
    "        machine_type=machine_type,\n",
    "        accelerator_count=accelerator_count,\n",
    "        accelerator_type=accelerator_type,\n",
    "        reduction_server_count=0,\n",
    "        reduction_server_machine_type=\"n1-highcpu-16\",\n",
    "    )\n",
    "    logging.info(f'WORKER_POOL_SPECS: {WORKER_POOL_SPECS}')\n",
    "    \n",
    "    #start the timer and training\n",
    "    job = aiplatform.CustomJob(\n",
    "        display_name=JOB_NAME,\n",
    "        worker_pool_specs=WORKER_POOL_SPECS,\n",
    "        base_output_dir=BASE_OUTPUT_DIR,\n",
    "        staging_bucket=f\"{BASE_OUTPUT_DIR}/staging\",\n",
    "    )\n",
    "    logging.info(f'Submitting train job to Vertex AI...')\n",
    "    job.run(\n",
    "        tensorboard=tensorboard_resource_name,\n",
    "        service_account=f'{service_account}',\n",
    "        restart_job_on_worker_restart=False,\n",
    "        enable_web_access=True,\n",
    "        sync=False,\n",
    "    )\n",
    "    # wait for job to complete\n",
    "    job.wait()\n",
    "    \n",
    "    train_job_dict = job.to_dict()\n",
    "    logging.info(f'train_job_dict: {train_job_dict}')\n",
    "    \n",
    "    return (\n",
    "        f'{BASE_OUTPUT_DIR}',\n",
    "        f'{LOG_DIR}',\n",
    "        f'{ARTIFACTS_DIR}',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89602cb8-f7ac-4d7d-83bd-035dacc39ed2",
   "metadata": {},
   "source": [
    "### Eval agent policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83f59d22-057e-448f-93e6-3f13114b28d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../src/policy_pipeline/components/eval_agent_policy.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../{REPO_SRC}/{POLICY_PIPE_DIR}/{POLICY_PIPE_SUBDIR}/eval_agent_policy.py\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp import dsl\n",
    "from . import pipeline_config\n",
    "\n",
    "@dsl.component(\n",
    "    base_image=pipeline_config.POLICY_PIPE_IMAGE,\n",
    "    install_kfp_package=False\n",
    ")\n",
    "def eval_agent_policy(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    pipeline_version: str,\n",
    "    bucket_name: str,\n",
    "    example_gen_gcs_path: str,\n",
    "    # agent\n",
    "    hparams: str,\n",
    "    arftifacts_dir: str,\n",
    "    # data\n",
    "    ds_skip: int,\n",
    "    ds_take: int,\n",
    "    num_eval_samples: int, \n",
    "    total_eval_rewards: float,\n",
    "    eval_ds: dsl.Input[dsl.Dataset],\n",
    "    metrics: dsl.Output[dsl.Metrics]\n",
    "):\n",
    "    # imports\n",
    "    import os\n",
    "    import json\n",
    "    import time\n",
    "    import logging\n",
    "    import numpy as np\n",
    "    import pickle as pkl\n",
    "    from pprint import pprint\n",
    "    from google.cloud import aiplatform, storage\n",
    "    from typing import Callable, Dict, List, Optional, TypeVar, Any\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "    \n",
    "    # tf\n",
    "    import tensorflow as tf\n",
    "    from tf_agents.policies import py_tf_eager_policy\n",
    "    \n",
    "    # this repo\n",
    "    from src.trainer import eval_perarm\n",
    "    from src.data import data_utils\n",
    "    \n",
    "    # convert hparam dict\n",
    "    HPARAMS = json.loads(hparams)\n",
    "    pprint(HPARAMS)\n",
    "    \n",
    "    # set client SDKs\n",
    "    aiplatform.init(\n",
    "        project=project_id,\n",
    "        location=location,\n",
    "    )\n",
    "    storage_client = storage.Client(project=project_id)\n",
    "    # =========================================================\n",
    "    # download vocabs\n",
    "    # =========================================================\n",
    "    LOCAL_VOCAB_FILENAME = 'vocab_dict.pkl'\n",
    "    print(f\"Downloading vocab...\")\n",
    "    data_utils.download_blob(\n",
    "        project_id = project_id,\n",
    "        bucket_name = bucket_name, \n",
    "        source_blob_name = f'{example_gen_gcs_path}/vocabs/{LOCAL_VOCAB_FILENAME}', \n",
    "        destination_file_name= LOCAL_VOCAB_FILENAME\n",
    "    )\n",
    "    filehandler = open(f\"{LOCAL_VOCAB_FILENAME}\", 'rb')\n",
    "    vocab_dict = pkl.load(filehandler)\n",
    "    filehandler.close()\n",
    "    \n",
    "    # =========================================================\n",
    "    # get eval tf-records\n",
    "    # =========================================================\n",
    "    val_files = []\n",
    "    for blob in storage_client.list_blobs(f\"{bucket_name}\", prefix=f'{example_gen_gcs_path}/val'):\n",
    "        if '.tfrecord' in blob.name:\n",
    "            val_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "    val_dataset = tf.data.TFRecordDataset(val_files)\n",
    "    val_dataset = val_dataset.map(data_utils._parse_function, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    eval_ds = val_dataset.batch(1)\n",
    "    \n",
    "    if ds_skip > 0:\n",
    "        eval_ds = eval_ds.skip(ds_skip)\n",
    "        logging.info(f\"setting dataset skip: {ds_skip}\")\n",
    "    \n",
    "    if ds_take > 0:\n",
    "        eval_ds = eval_ds.take(ds_take)\n",
    "        logging.info(f\"setting dataset take: {ds_take}\")\n",
    "        \n",
    "    # =========================================================\n",
    "    # load policy\n",
    "    # =========================================================\n",
    "    my_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "        arftifacts_dir, load_specs_from_pbtxt=True\n",
    "    )\n",
    "    \n",
    "    # =========================================================\n",
    "    # run policy eval on val dataset\n",
    "    # =========================================================\n",
    "    print(f\"evaluating loaded policy...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    val_loss, preds, tr_rewards = eval_perarm._run_bandit_eval(\n",
    "        policy = my_policy,\n",
    "        data = eval_ds,\n",
    "        eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "        per_arm_dim = HPARAMS['per_arm_dim'],\n",
    "        global_dim = HPARAMS['global_dim'],\n",
    "        vocab_dict = vocab_dict,\n",
    "        num_oov_buckets = 1,\n",
    "        global_emb_size = HPARAMS['global_emb_size'],\n",
    "        mv_emb_size = HPARAMS['arm_emb_size'],\n",
    "    )\n",
    "    runtime_mins = int((time.time() - start_time) / 60)\n",
    "    print(f\"post-train val_loss     : {val_loss}\")\n",
    "    print(f\"post-train eval runtime : {runtime_mins}\")\n",
    "    \n",
    "    # =========================================================\n",
    "    # log metrics\n",
    "    # =========================================================\n",
    "    total_pred_rewards = round(tf.reduce_sum(preds).numpy().tolist(), 2)\n",
    "    reward_diff = round(abs(total_eval_rewards - total_pred_rewards), 2)\n",
    "    avg_reward_vals = np.average([total_pred_rewards, total_eval_rewards])\n",
    "    reward_percentage_diff = round((reward_diff / avg_reward_vals) * 100.0, 2)\n",
    "    \n",
    "    print(f\"total_eval_rewards : {total_eval_rewards}\")\n",
    "    print(f\"total_pred_rewards : {total_pred_rewards}\")\n",
    "    print(f\"reward_diff        : {reward_diff}\")\n",
    "    print(f\"avg_reward_vals    : {avg_reward_vals}\")\n",
    "    print(f\"reward % diff      : {reward_percentage_diff}%\")\n",
    "    \n",
    "    metrics.log_metric(\"total_eval_ds_rewards\", total_eval_rewards)\n",
    "    metrics.log_metric(\"total_predicted_rewards\", total_pred_rewards)\n",
    "    metrics.log_metric(\"reward_%_diff\", reward_percentage_diff)\n",
    "    metrics.log_metric(\"val_loss\", round(val_loss.numpy().tolist(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb89a94-eb63-4ca1-9db7-c5149e372435",
   "metadata": {},
   "source": [
    "# Create Vertex Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ff5f37d-11bd-43e4-88fe-bacafd955792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get eval tf-records\n",
    "BUCKET_NAME = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
    "example_gen_gcs_path = \"data/movielens/m1m\"\n",
    "\n",
    "val_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{example_gen_gcs_path}/val'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        val_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "val_dataset = tf.data.TFRecordDataset(val_files)\n",
    "val_dataset = val_dataset.map(data_utils._parse_function, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "eval_ds = val_dataset.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b03819cb-05c5-46f6-974a-75da3d587725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99417"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(eval_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92cb471b-fbe0-4dd7-9b3b-ee381a584b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src.policy_pipeline.components import (\n",
    "    prep_eval_ds,\n",
    "    train_agent,\n",
    "    eval_agent_policy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d0796f2-b5f5-4f2a-a13e-a5085519ddd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISPLAY_NAME: gpi-simulation-pipe-v2\n"
     ]
    }
   ],
   "source": [
    "PIPE_VERSION = \"v2\"\n",
    "EXPERIMENT_NAME = \"gpi-simulation-pipe\"\n",
    "\n",
    "DISPLAY_NAME = f\"{EXPERIMENT_NAME}-{PIPE_VERSION}\".replace(\"_\",\"-\")\n",
    "print(f\"DISPLAY_NAME: {DISPLAY_NAME}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "282ab9a1-d2ae-4f31-9f7f-0975f29963fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=f\"{DISPLAY_NAME}\",\n",
    ")\n",
    "def gpi_pipeline(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    pipeline_version: str,\n",
    "    bucket_name: str,\n",
    "    example_gen_gcs_path: str,\n",
    "    tfrecord_name: str,\n",
    "    hparams: str,\n",
    "    experiment_name: str,\n",
    "    experiment_run_tag: str,\n",
    "    tensorboard_resource_name: str,\n",
    "    service_account: str,\n",
    "    # train job\n",
    "    num_epochs: int,\n",
    "    gpi_image_name: str, # TODO\n",
    "    replica_count: int,\n",
    "    machine_type: str,\n",
    "    accelerator_count: int, \n",
    "    accelerator_type: str,\n",
    "):\n",
    "    import logging\n",
    "    # from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "    from google_cloud_pipeline_components.v1.dataset.create_tabular_dataset.component import tabular_dataset_create as TabularDatasetCreateOp\n",
    "    \n",
    "    # train_dataset_op = TabularDatasetCreateOp(\n",
    "    #     project=project_id,\n",
    "    #     display_name=\"movielens-gpi-train\",\n",
    "    #     gcs_source=tfrecord_name,\n",
    "    #     labels={\"pipeline_version\": pipeline_version},\n",
    "    # )\n",
    "    \n",
    "    prepare_eval_data_op = (\n",
    "        prep_eval_ds.prep_eval_ds(\n",
    "            project_id=project_id,\n",
    "            location=location,\n",
    "            pipeline_version=pipeline_version,\n",
    "            bucket_name=bucket_name,\n",
    "            example_gen_gcs_path=example_gen_gcs_path,\n",
    "            ds_skip = 0,\n",
    "            ds_take = 50_000,\n",
    "        )\n",
    "        .set_display_name(\"Prepare eval slice\")\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "    \n",
    "    train_agent_policy_op = (\n",
    "        train_agent.train_agent(\n",
    "            project_id=project_id,\n",
    "            location=location,\n",
    "            pipeline_version=pipeline_version,\n",
    "            bucket_name=bucket_name,\n",
    "            example_gen_gcs_path=example_gen_gcs_path,\n",
    "            tfrecord_name=tfrecord_name,\n",
    "            hparams=hparams,\n",
    "            experiment_name=experiment_name,\n",
    "            experiment_run_tag=experiment_run_tag,\n",
    "            tensorboard_resource_name=tensorboard_resource_name,\n",
    "            service_account=service_account,\n",
    "            #train job\n",
    "            num_epochs=num_epochs,\n",
    "            log_interval=100,\n",
    "            total_train_take=2_000,\n",
    "            total_train_skip=0,\n",
    "            gpi_image_name=gpi_image_name,\n",
    "            # train compute\n",
    "            replica_count = 1,\n",
    "            machine_type = 'n1-highmem-16',\n",
    "            accelerator_count = 1, \n",
    "            accelerator_type = \"NVIDIA_TESLA_T4\",\n",
    "            # train_ds=train_dataset_op.outputs[\"dataset\"],\n",
    "        )\n",
    "        .set_display_name(\"Train policy v1\")\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "    \n",
    "    eval_policy_op = (\n",
    "        eval_agent_policy.eval_agent_policy(\n",
    "            project_id=project_id,\n",
    "            location=location,\n",
    "            pipeline_version=pipeline_version,\n",
    "            bucket_name=bucket_name,\n",
    "            example_gen_gcs_path=example_gen_gcs_path,\n",
    "            hparams=hparams,\n",
    "            arftifacts_dir=train_agent_policy_op.outputs[\"artifacts_dir\"],\n",
    "            ds_skip = prepare_eval_data_op.outputs[\"ds_skip\"], # 0\n",
    "            ds_take = prepare_eval_data_op.outputs[\"ds_take\"], # 50_000\n",
    "            num_eval_samples=prepare_eval_data_op.outputs[\"num_eval_samples\"],\n",
    "            total_eval_rewards=prepare_eval_data_op.outputs[\"total_eval_rewards\"],\n",
    "            eval_ds=prepare_eval_data_op.outputs[\"eval_ds\"],\n",
    "        )\n",
    "        .set_display_name(\"Eval policy v1\")\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "    \n",
    "    # retraining on next slice\n",
    "    train_agent_policy_op_2 = (\n",
    "        train_agent.train_agent(\n",
    "            project_id=project_id,\n",
    "            location=location,\n",
    "            pipeline_version=pipeline_version,\n",
    "            bucket_name=bucket_name,\n",
    "            example_gen_gcs_path=example_gen_gcs_path,\n",
    "            tfrecord_name=tfrecord_name,\n",
    "            hparams=hparams,\n",
    "            experiment_name=experiment_name,\n",
    "            experiment_run_tag=experiment_run_tag,\n",
    "            tensorboard_resource_name=tensorboard_resource_name,\n",
    "            service_account=service_account,\n",
    "            #train job\n",
    "            num_epochs=num_epochs,\n",
    "            log_interval=100,\n",
    "            total_train_take=2_000,\n",
    "            total_train_skip=2_000,\n",
    "            gpi_image_name=gpi_image_name,\n",
    "            # train compute\n",
    "            replica_count = 1,\n",
    "            machine_type = 'n1-highmem-16',\n",
    "            accelerator_count = 1, \n",
    "            accelerator_type = \"NVIDIA_TESLA_T4\",\n",
    "            # train_ds=train_dataset_op.outputs[\"dataset\"],\n",
    "        )\n",
    "        .set_display_name(\"Train policy v2\")\n",
    "        .set_caching_options(True)\n",
    "        # .after(eval_policy_op)\n",
    "    )\n",
    "    \n",
    "    eval_policy_op_2 = (\n",
    "        eval_agent_policy.eval_agent_policy(\n",
    "            project_id=project_id,\n",
    "            location=location,\n",
    "            pipeline_version=pipeline_version,\n",
    "            bucket_name=bucket_name,\n",
    "            example_gen_gcs_path=example_gen_gcs_path,\n",
    "            hparams=hparams,\n",
    "            arftifacts_dir=train_agent_policy_op_2.outputs[\"artifacts_dir\"],\n",
    "            ds_skip = prepare_eval_data_op.outputs[\"ds_skip\"], # 0\n",
    "            ds_take = prepare_eval_data_op.outputs[\"ds_take\"], # 50_000\n",
    "            num_eval_samples=prepare_eval_data_op.outputs[\"num_eval_samples\"],\n",
    "            total_eval_rewards=prepare_eval_data_op.outputs[\"total_eval_rewards\"],\n",
    "            eval_ds=prepare_eval_data_op.outputs[\"eval_ds\"],\n",
    "        )\n",
    "        .set_display_name(\"Eval policy v2\")\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "    \n",
    "    # retraining on next slice\n",
    "    train_agent_policy_op_3 = (\n",
    "        train_agent.train_agent(\n",
    "            project_id=project_id,\n",
    "            location=location,\n",
    "            pipeline_version=pipeline_version,\n",
    "            bucket_name=bucket_name,\n",
    "            example_gen_gcs_path=example_gen_gcs_path,\n",
    "            tfrecord_name=tfrecord_name,\n",
    "            hparams=hparams,\n",
    "            experiment_name=experiment_name,\n",
    "            experiment_run_tag=experiment_run_tag,\n",
    "            tensorboard_resource_name=tensorboard_resource_name,\n",
    "            service_account=service_account,\n",
    "            #train job\n",
    "            num_epochs=num_epochs,\n",
    "            log_interval=100,\n",
    "            total_train_take=2_000,\n",
    "            total_train_skip=4_000,\n",
    "            gpi_image_name=gpi_image_name,\n",
    "            # train compute\n",
    "            replica_count = 1,\n",
    "            machine_type = 'n1-highmem-16',\n",
    "            accelerator_count = 1, \n",
    "            accelerator_type = \"NVIDIA_TESLA_T4\",\n",
    "            # train_ds=train_dataset_op.outputs[\"dataset\"],\n",
    "        )\n",
    "        .set_display_name(\"Train policy v3\")\n",
    "        .set_caching_options(True)\n",
    "        # .after(eval_policy_op_2)\n",
    "    )\n",
    "    \n",
    "    eval_policy_op_3 = (\n",
    "        eval_agent_policy.eval_agent_policy(\n",
    "            project_id=project_id,\n",
    "            location=location,\n",
    "            pipeline_version=pipeline_version,\n",
    "            bucket_name=bucket_name,\n",
    "            example_gen_gcs_path=example_gen_gcs_path,\n",
    "            hparams=hparams,\n",
    "            arftifacts_dir=train_agent_policy_op_3.outputs[\"artifacts_dir\"],\n",
    "            ds_skip = prepare_eval_data_op.outputs[\"ds_skip\"], # 0\n",
    "            ds_take = prepare_eval_data_op.outputs[\"ds_take\"], # 50_000\n",
    "            num_eval_samples=prepare_eval_data_op.outputs[\"num_eval_samples\"],\n",
    "            total_eval_rewards=prepare_eval_data_op.outputs[\"total_eval_rewards\"],\n",
    "            eval_ds=prepare_eval_data_op.outputs[\"eval_ds\"],\n",
    "        )\n",
    "        .set_display_name(\"Eval policy v3\")\n",
    "        .set_caching_options(True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a34545-19e8-437b-b907-3673f74c155f",
   "metadata": {},
   "source": [
    "## Compile Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "500a8544-68dc-433b-ae47-1fb01cf87613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://gpi_pipeline.yaml [Content-Type=application/octet-stream]...\n",
      "/ [1 files][ 59.5 KiB/ 59.5 KiB]                                                \n",
      "Operation completed over 1 objects/59.5 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "PIPELINE_YAML_FILENAME = \"gpi_pipeline.yaml\"\n",
    "\n",
    "! rm -f $PIPELINE_YAML_FILENAME\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=gpi_pipeline, \n",
    "    package_path=PIPELINE_YAML_FILENAME\n",
    ")\n",
    "PIPELINE_ROOT = f\"gs://{BUCKET_NAME}/gpi-pipelines/{DISPLAY_NAME}\"\n",
    "PIPELINES_FILEPATH = f\"{PIPELINE_ROOT}/{PIPELINE_YAML_FILENAME}\"\n",
    "\n",
    "!gsutil cp $PIPELINE_YAML_FILENAME $PIPELINES_FILEPATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3691e13e-b77c-4b93-903a-427ae0f42aca",
   "metadata": {},
   "source": [
    "## Define pipeline params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b9761e5-808c-44b0-a241-8cf76328f17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Record : gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/mv_b128_g12_a16_v6/mv_b128_g12_a16_v6.tfrecord\n",
      "GLOBAL_DIM : 72\n",
      "PER_ARM_DIM : 64\n",
      "TFRECORD_FILE : gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/mv_b128_g12_a16_v6/mv_b128_g12_a16_v6.tfrecord\n"
     ]
    }
   ],
   "source": [
    "EXAMPLE_GEN_GCS_PATH = data_config.EXAMPLE_GEN_GCS_PATH\n",
    "\n",
    "TFRECORD_NAME = \"mv_b128_g12_a16_v6\"\n",
    "TFRECORD_FILE = (\n",
    "    f\"{BUCKET_URI}/{EXAMPLE_GEN_GCS_PATH}/{TFRECORD_NAME}/{TFRECORD_NAME}.tfrecord\"\n",
    ")\n",
    "\n",
    "GLOBAL_EMBEDDING_SIZE = 12\n",
    "MV_EMBEDDING_SIZE = 16\n",
    "\n",
    "# sanity check\n",
    "N_GLOBAL_FEATURES = len(data_utils.USER_FEATURE_NAMES)\n",
    "N_ARM_FEATURES    = len(data_utils.MOVIE_FEATURE_NAMES)\n",
    "GLOBAL_DIM        = GLOBAL_EMBEDDING_SIZE * N_GLOBAL_FEATURES\n",
    "PER_ARM_DIM       = MV_EMBEDDING_SIZE * N_ARM_FEATURES\n",
    "\n",
    "print(f\"TF Record : {TFRECORD_FILE}\")\n",
    "print(f\"GLOBAL_DIM : {GLOBAL_DIM}\")\n",
    "print(f\"PER_ARM_DIM : {PER_ARM_DIM}\")\n",
    "\n",
    "print(f\"TFRECORD_FILE : {TFRECORD_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc6a7d76-46a7-455d-99c4-d91af23f461f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_alpha': 0.1,\n",
      " 'agent_type': 'epsGreedy',\n",
      " 'arm_emb_size': 16,\n",
      " 'batch_size': 128,\n",
      " 'common_layers': [34, 8],\n",
      " 'debug_summaries': True,\n",
      " 'encoding_dim': 1,\n",
      " 'eps_phase_steps': 1000,\n",
      " 'epsilon': 0.01,\n",
      " 'eval_batch_size': 1,\n",
      " 'global_dim': 72,\n",
      " 'global_emb_size': 12,\n",
      " 'global_layers': [72, 36, 18],\n",
      " 'learning_rate': 0.05,\n",
      " 'network_type': 'commontower',\n",
      " 'num_actions': 2,\n",
      " 'per_arm_dim': 64,\n",
      " 'per_arm_layers': [64, 32, 16],\n",
      " 'summarize_grads_and_vars': True}\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE      = 128\n",
    "NUM_ACTIONS     = 2\n",
    "\n",
    "EVAL_BATCH_SIZE = 1\n",
    "\n",
    "AGENT_TYPE      = 'epsGreedy' # 'LinUCB' | 'LinTS |, 'epsGreedy' | 'NeuralLinUCB'\n",
    "AGENT_ALPHA     = 0.1\n",
    "EPSILON         = 0.01\n",
    "LR              = 0.05\n",
    "ENCODING_DIM    = 1\n",
    "EPS_PHASE_STEPS = 1000\n",
    "\n",
    "GLOBAL_LAYERS   = [GLOBAL_DIM, int(GLOBAL_DIM/2), int(GLOBAL_DIM/4)]\n",
    "ARM_LAYERS      = [PER_ARM_DIM, int(PER_ARM_DIM/2), int(PER_ARM_DIM/4)]\n",
    "FIRST_COMMON_LAYER = GLOBAL_LAYERS[-1] + ARM_LAYERS[-1] # min(GLOBAL_LAYERS[-1], ARM_LAYERS[-1])\n",
    "COMMON_LAYERS = [\n",
    "    int(FIRST_COMMON_LAYER),\n",
    "    # int(FIRST_COMMON_LAYER/2),\n",
    "    int(FIRST_COMMON_LAYER/4)\n",
    "]\n",
    "\n",
    "NETWORK_TYPE = \"commontower\" # 'commontower' | 'dotproduct'\n",
    "if AGENT_TYPE == 'NeuralLinUCB':\n",
    "    NETWORK_TYPE = 'commontower'\n",
    "    ENCODING_DIM = COMMON_LAYERS[-1] \n",
    "if NETWORK_TYPE == 'dotproduct':\n",
    "    assert GLOBAL_LAYERS[0] == ARM_LAYERS[0]\n",
    "\n",
    "HPARAMS = {\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"eval_batch_size\" : EVAL_BATCH_SIZE,\n",
    "    \"num_actions\": NUM_ACTIONS,\n",
    "    \"agent_type\": AGENT_TYPE,\n",
    "    \"network_type\": NETWORK_TYPE,\n",
    "    \"global_emb_size\": GLOBAL_EMBEDDING_SIZE,\n",
    "    \"arm_emb_size\": MV_EMBEDDING_SIZE,\n",
    "    \"global_dim\": GLOBAL_DIM,\n",
    "    \"per_arm_dim\": PER_ARM_DIM,\n",
    "    \"agent_alpha\": AGENT_ALPHA,\n",
    "    \"global_layers\": GLOBAL_LAYERS,\n",
    "    \"per_arm_layers\": ARM_LAYERS,\n",
    "    \"common_layers\": COMMON_LAYERS,\n",
    "    \"learning_rate\": LR,\n",
    "    \"epsilon\": EPSILON,\n",
    "    \"encoding_dim\": ENCODING_DIM,\n",
    "    \"eps_phase_steps\": EPS_PHASE_STEPS,\n",
    "    \"summarize_grads_and_vars\" : True,\n",
    "    \"debug_summaries\": True,\n",
    "}\n",
    "pprint(HPARAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9f6f50-7393-4a2b-81f1-4e9716d6e731",
   "metadata": {},
   "source": [
    "### Create Managed TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "852fb541-f61d-4a25-bc33-4a917529d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_TENSORBOARD = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07e04069-1762-4225-b3c0-4c14c2ba39e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TB_RESOURCE_NAME: projects/934903580331/locations/us-central1/tensorboards/6306398474690625536\n",
      "TB display name: gpi-simulation-pipe\n"
     ]
    }
   ],
   "source": [
    "if NEW_TENSORBOARD:\n",
    "    # # create new TB instance\n",
    "    TENSORBOARD_DISPLAY_NAME=f\"{EXPERIMENT_NAME}\"\n",
    "    tensorboard = aiplatform.Tensorboard.create(\n",
    "        display_name=TENSORBOARD_DISPLAY_NAME\n",
    "        , project=PROJECT_ID\n",
    "        , location=REGION\n",
    "    )\n",
    "    TB_RESOURCE_NAME = tensorboard.resource_name\n",
    "else:\n",
    "    # use existing TB instance\n",
    "    TB_RESOURCE_NAME = 'projects/934903580331/locations/us-central1/tensorboards/7845855491065380864' # TODO\n",
    "    tensorboard = aiplatform.Tensorboard(\n",
    "        tensorboard_name=TB_RESOURCE_NAME\n",
    "    )\n",
    "print(f\"TB_RESOURCE_NAME: {TB_RESOURCE_NAME}\")\n",
    "print(f\"TB display name: {tensorboard.display_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9030bf1b-b1d7-41fb-8255-d38e9b006e31",
   "metadata": {},
   "source": [
    "### Vertex Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3de5456e-dacc-4548-bfd2-d6cb3d07a32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : gpi-simulation-pipe\n",
      "RUN_NAME          : run-v2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RUN_NAME          = f'run-{PIPE_VERSION}'\n",
    "\n",
    "# CHECKPT_DIR       = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/chkpoint\"\n",
    "# BASE_OUTPUT_DIR   = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}\"\n",
    "# LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "# ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "# print(f\"CHECKPT_DIR       : {CHECKPT_DIR}\")\n",
    "# print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "# print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "# print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0844aacd-ba56-418d-ae3f-bd51ea71ade5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"batch_size\": 128, \"eval_batch_size\": 1, \"num_actions\": 2, \"agent_type\": \"epsGreedy\", \"network_type\": \"commontower\", \"global_emb_size\": 12, \"arm_emb_size\": 16, \"global_dim\": 72, \"per_arm_dim\": 64, \"agent_alpha\": 0.1, \"global_layers\": [72, 36, 18], \"per_arm_layers\": [64, 32, 16], \"common_layers\": [34, 8], \"learning_rate\": 0.05, \"epsilon\": 0.01, \"encoding_dim\": 1, \"eps_phase_steps\": 1000, \"summarize_grads_and_vars\": true, \"debug_summaries\": true}'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "dumped_hparams = json.dumps(HPARAMS)\n",
    "dumped_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f12f2d2-a0ef-42e6-8702-4cc60694e134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 128,\n",
       " 'eval_batch_size': 1,\n",
       " 'num_actions': 2,\n",
       " 'agent_type': 'epsGreedy',\n",
       " 'network_type': 'commontower',\n",
       " 'global_emb_size': 12,\n",
       " 'arm_emb_size': 16,\n",
       " 'global_dim': 72,\n",
       " 'per_arm_dim': 64,\n",
       " 'agent_alpha': 0.1,\n",
       " 'global_layers': [72, 36, 18],\n",
       " 'per_arm_layers': [64, 32, 16],\n",
       " 'common_layers': [34, 8],\n",
       " 'learning_rate': 0.05,\n",
       " 'epsilon': 0.01,\n",
       " 'encoding_dim': 1,\n",
       " 'eps_phase_steps': 1000,\n",
       " 'summarize_grads_and_vars': True,\n",
       " 'debug_summaries': True}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_hparams = json.loads(dumped_hparams)\n",
    "loaded_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1976c093-3af8-4560-8dc1-ea6355c29312",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = aiplatform.PipelineJob(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    location=LOCATION,\n",
    "    template_path=PIPELINE_YAML_FILENAME,\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    failure_policy='fast',\n",
    "    parameter_values={\n",
    "        \"project_id\": PROJECT_ID,\n",
    "        \"location\": LOCATION,\n",
    "        \"pipeline_version\": PIPE_VERSION,\n",
    "        \"bucket_name\": BUCKET_NAME,\n",
    "        \"example_gen_gcs_path\": EXAMPLE_GEN_GCS_PATH,\n",
    "        \"tfrecord_name\": TFRECORD_NAME, # TFRECORD_FILE,\n",
    "        \"hparams\": dumped_hparams, # HPARAMS,\n",
    "        \"experiment_name\": EXPERIMENT_NAME,\n",
    "        \"experiment_run_tag\": RUN_NAME,\n",
    "        \"tensorboard_resource_name\": TB_RESOURCE_NAME,\n",
    "        \"service_account\": VERTEX_SA,\n",
    "        # train job\n",
    "        \"num_epochs\" : 3,\n",
    "        \"gpi_image_name\": POLICY_TRAIN_IMAGE,\n",
    "        \"replica_count\" : 1,\n",
    "        \"machine_type\" : \"n1-highmem-16\",\n",
    "        \"accelerator_count\" : 1, \n",
    "        \"accelerator_type\" : \"NVIDIA_TESLA_T4\",\n",
    "        \n",
    "    },\n",
    "    enable_caching=True,\n",
    ")\n",
    "\n",
    "job.submit(\n",
    "    # experiment=EXPERIMENT_NAME,\n",
    "    # sync=False,\n",
    "    service_account=VERTEX_SA,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4899ea5c-5f7f-42a6-a44b-f9834423e46c",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439795aa-b327-4c9f-a066-4758ccbaf387",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Stash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9be72e-6b47-4189-97db-f7aa173f4f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile ../{REPO_SRC}/{POLICY_PIPE_DIR}/{POLICY_PIPE_SUBDIR}/define_agent_specs.py\n",
    "# import kfp\n",
    "# from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "# from kfp import dsl\n",
    "# from . import pipeline_config\n",
    "\n",
    "# @dsl.component(\n",
    "#     base_image=pipeline_config.POLICY_PIPE_IMAGE,\n",
    "#     install_kfp_package=False\n",
    "# )\n",
    "# def define_agent_specs(\n",
    "#     project_id: str,\n",
    "#     location: str,\n",
    "#     pipeline_version: str,\n",
    "#     bucket_name: str,\n",
    "#     example_gen_gcs_path: str,\n",
    "#     hparams: dict,\n",
    "# ) -> NamedTuple('Outputs', [\n",
    "#     ('agent_spec_dict', dict),\n",
    "# ]):\n",
    "#     # imports\n",
    "#     import os\n",
    "#     os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "    \n",
    "#     import tensorflow as tf\n",
    "    \n",
    "#     # tf-agents\n",
    "#     from tf_agents.specs import array_spec\n",
    "#     from tf_agents.specs import tensor_spec\n",
    "#     from tf_agents.trajectories import time_step as ts\n",
    "    \n",
    "#     # this repo\n",
    "#     from src.utils import train_utils as train_utils\n",
    "    \n",
    "#     # ====================================================\n",
    "#     # define agent\n",
    "#     # ====================================================\n",
    "#     observation_spec = {\n",
    "#         'global': tf.TensorSpec([hparams['global_dim']], tf.float32),\n",
    "#         'per_arm': tf.TensorSpec([hparams['num_actions'], hparams['per_arm_dim']], tf.float32)\n",
    "#     }\n",
    "#     action_spec = tensor_spec.BoundedTensorSpec(\n",
    "#         shape=[], \n",
    "#         dtype=tf.int32,\n",
    "#         minimum=tf.constant(0),            \n",
    "#         maximum=hparams['num_actions']-1,\n",
    "#         name=\"action_spec\"\n",
    "#     )\n",
    "#     time_step_spec = ts.time_step_spec(observation_spec = observation_spec)\n",
    "#     reward_spec = {\n",
    "#         \"reward\": array_spec.ArraySpec(\n",
    "#             shape=[hparams['batch_size']], \n",
    "#             dtype=np.float32, \n",
    "#             name=\"reward\"\n",
    "#         )\n",
    "#     }\n",
    "#     reward_tensor_spec = train_utils.from_spec(reward_spec)\n",
    "    \n",
    "#     agent_spec_dict = {}\n",
    "#     agent_spec_dict['observation_spec'] = observation_spec\n",
    "#     agent_spec_dict['action_spec'] = action_spec\n",
    "#     agent_spec_dict['time_step_spec'] = time_step_spec\n",
    "#     agent_spec_dict['reward_spec'] = reward_spec\n",
    "#     agent_spec_dict['reward_tensor_spec'] = reward_tensor_spec\n",
    "    \n",
    "#     return (\n",
    "#         agent_spec_dict\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
