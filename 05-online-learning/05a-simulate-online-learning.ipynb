{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bbe739b-44f2-444f-989d-b1d289b1817e",
   "metadata": {},
   "source": [
    "# Simulate Online Learning with Contextual Bandits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e150cd8-8e32-4c44-8d6b-0d0050e8a463",
   "metadata": {},
   "source": [
    "For \"online learning\" to take place, the agent's policy needs to be updated, where \"updated\" is conceptually similar to retraining a traditional supervised learning model (with latest training examples) and deploying the newly trained model\n",
    "* the bandit agent's policy is updated (i.e., learns) when it receives (e.g., `agent.train(...)`) a trajectory that includes the prediction/action AND the delayed feedback\n",
    "* once `agent.train(...)` takes place, the policy is updated (e.g., weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39d04854-4b70-4529-9609-9de643461979",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/05-online-learning\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0431346f-3097-4ca3-890e-9927d7b2d4f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "VERSION        = \"v2\"                       # TODO\n",
    "PREFIX         = f'rec-bandits-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d76b584-5d0d-4b04-80b9-c97916ba4686",
   "metadata": {},
   "source": [
    "## Load notebook config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdc0e11b-d3fd-4140-86a7-459585be71c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"rec-bandits-v2\"\n",
      "VERSION                  = \"v2\"\n",
      "\n",
      "BUCKET_NAME              = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_NAME    = \"mvlens_rec_bandits_v2\"\n",
      "BIGQUERY_TABLE_NAME      = \"training_dataset\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-rec-bandits-v2\"\n",
      "\n",
      "DOCKERNAME_01            = \"Dockerfile_train_my_perarm_env\"\n",
      "IMAGE_NAME_01            = \"train-my-perarm-env-v2\"\n",
      "IMAGE_URI_01             = \"gcr.io/hybrid-vertex/train-my-perarm-env-v2\"\n",
      "\n",
      "DOCKERNAME_02            = \"Dockerfile_perarm_feats\"\n",
      "IMAGE_NAME_02            = \"train-perarm-feats-v2\"\n",
      "IMAGE_URI_02             = \"gcr.io/hybrid-vertex/train-perarm-feats-v2\"\n",
      "\n",
      "DOCKERNAME_03            = \"Dockerfile_ranking_bandit\"\n",
      "IMAGE_NAME_03            = \"train-rank-bandit-v2\"\n",
      "IMAGE_URI_03             = \"gcr.io/hybrid-vertex/train-rank-bandit-v2\"\n",
      "\n",
      "DOCKERNAME_04            = \"Dockerfile_train_bandit_e2e\"\n",
      "IMAGE_NAME_04            = \"train-mab-e2e-v2\"\n",
      "IMAGE_URI_04             = \"gcr.io/hybrid-vertex/train-mab-e2e-v2\"\n",
      "\n",
      "DOCKERNAME_04_pred       = \"Dockerfile_pred_bandit_e2e\"\n",
      "IMAGE_NAME_04_pred       = \"pred-mab-e2e-v2\"\n",
      "IMAGE_URI_04_pred        = \"gcr.io/hybrid-vertex/pred-mab-e2e-v2\"\n",
      "\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/local_docker_tfa\"\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bd0378-3650-4cc5-bc05-4f407f200c9c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fab51a15-b189-4159-919c-04f2d81ce741",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25dcc25d-030e-4d39-920b-2187e70fcdf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "from collections import defaultdict\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pickle as pkl\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.metrics import tf_metrics\n",
    "\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent\n",
    "from tf_agents.bandits.agents import neural_linucb_agent\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.bandits.policies import policy_utilities\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.policies import policy_saver\n",
    "\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.train.utils import spec_utils\n",
    "from tf_agents.train.utils import strategy_utils\n",
    "from tf_agents.train.utils import train_utils as tfa_train_utils\n",
    "from tf_agents.utils import common\n",
    "\n",
    "from tf_agents.metrics import export_utils\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.eval import metric_utils\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df137505-958f-48f3-9159-2e0b01df6146",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_agents version: 0.17.0\n",
      "tensorflow version: 2.13.0\n"
     ]
    }
   ],
   "source": [
    "# import tf_agents\n",
    "\n",
    "# print(f\"tf_agents version: {tf_agents.__version__}\")\n",
    "# print(f\"tensorflow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f664a98-df2e-4190-8c67-e8f4b970f639",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# this repo\n",
    "from src.data import data_utils as data_utils\n",
    "from src.data import data_config as data_config\n",
    "from src.utils import train_utils, reward_factory\n",
    "\n",
    "from src.agents import agent_factory as agent_factory\n",
    "from src.trainer import eval_perarm as eval_perarm, train_perarm\n",
    "from src.networks import encoding_network as emb_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15ccc299-9963-4014-a19f-394a8697d966",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aae8bb01-8147-4586-913e-e02fbbbd4be3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78c953a0-be4d-4859-8bd6-50773502e800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9f4837-9c6b-4b11-b950-ed4fa0fa2804",
   "metadata": {},
   "source": [
    "## Data config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d224ac4-8312-41ee-9616-a27538d8d1b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCS_DATA_PATH: gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m\n"
     ]
    }
   ],
   "source": [
    "EXAMPLE_GEN_GCS_PATH = data_config.EXAMPLE_GEN_GCS_PATH\n",
    "GCS_DATA_PATH = f\"{BUCKET_URI}/{EXAMPLE_GEN_GCS_PATH}\"\n",
    "\n",
    "print(f\"GCS_DATA_PATH: {GCS_DATA_PATH}\")\n",
    "\n",
    "# !gsutil ls $GCS_DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cf10444-f95a-4fbb-b8db-e12a38903639",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SPLIT = \"train\" # \"train\" | \"val\"\n",
    "\n",
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{EXAMPLE_GEN_GCS_PATH}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "train_dataset = train_dataset.map(data_utils._parse_function)\n",
    "\n",
    "# for x in train_dataset.batch(1).take(1):\n",
    "#     pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "615baf44-0b1e-4f79-aac2-f318d6709c5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SPLIT = \"val\"\n",
    "\n",
    "val_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{EXAMPLE_GEN_GCS_PATH}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        val_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "val_dataset = tf.data.TFRecordDataset(val_files)\n",
    "val_dataset = val_dataset.map(data_utils._parse_function, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89788e85-79a0-44a1-b48d-7259e99d241f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target_movie_genres': <tf.Tensor: shape=(1, 10), dtype=string, numpy=\n",
       " array([[b'Drama', b'UNK', b'UNK', b'UNK', b'UNK', b'UNK', b'UNK', b'UNK',\n",
       "         b'UNK', b'UNK']], dtype=object)>,\n",
       " 'target_movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'1775'], dtype=object)>,\n",
       " 'target_movie_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>,\n",
       " 'target_movie_title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Live Flesh (1997)'], dtype=object)>,\n",
       " 'target_movie_year': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1997])>,\n",
       " 'target_rating_timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([974612615])>,\n",
       " 'user_age': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([50])>,\n",
       " 'user_gender': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'M'], dtype=object)>,\n",
       " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'2173'], dtype=object)>,\n",
       " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'programmer'], dtype=object)>,\n",
       " 'user_zip_code': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'87505'], dtype=object)>}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    \n",
    "    iterator = iter(train_dataset.batch(1))\n",
    "    data = next(iterator)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4209c43a-062e-4c5b-a055-c96051caa80f",
   "metadata": {},
   "source": [
    "### Generate Vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fececd5-ebcf-4221-a32e-eb7f7f4b6232",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE_VOCABS: False\n"
     ]
    }
   ],
   "source": [
    "GENERATE_VOCABS = False\n",
    "\n",
    "print(f\"GENERATE_VOCABS: {GENERATE_VOCABS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a509e1c6-df20-4ede-8b63-0a128d49189d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab...\n",
      "Downloaded vocab from: gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/vocabs/vocab_dict.pkl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not GENERATE_VOCABS:\n",
    "\n",
    "    EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{EXAMPLE_GEN_GCS_PATH}/vocabs/{VOCAB_FILENAME}'\n",
    "    print(f\"Downloading vocab...\")\n",
    "\n",
    "    os.system(f'gsutil -q cp {EXISTING_VOCAB_FILE} .')\n",
    "    print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "    filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "    vocab_dict = pkl.load(filehandler)\n",
    "    filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a332a971-b73b-4814-a9d6-c03a72426608",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_OOV_BUCKETS        = 1\n",
    "GLOBAL_EMBEDDING_SIZE  = 16\n",
    "MV_EMBEDDING_SIZE      = 32 #32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "645ccdc6-6ea9-4873-9e4c-12084fbe5c22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.networks.encoding_network.EmbeddingModel at 0x7f04202b66b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs = emb_features.EmbeddingModel(\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    "    max_genre_length = data_config.MAX_GENRE_LENGTH,\n",
    ")\n",
    "\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6782d836-f6bf-43a5-880c-56489bf229e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL_DIM: 96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 96), dtype=float32, numpy=\n",
       "array([[-0.01298127,  0.00900888,  0.01369318, -0.00943478,  0.03220116,\n",
       "        -0.02173761,  0.04556427, -0.0016874 , -0.03589913, -0.03054412,\n",
       "         0.02776753, -0.03189936,  0.02758015, -0.02111412,  0.02047497,\n",
       "        -0.00983988,  0.01738607, -0.04097303, -0.00412111, -0.0038606 ,\n",
       "        -0.02538109,  0.0044826 , -0.01020737,  0.02641901,  0.00174092,\n",
       "        -0.04236165,  0.00611288,  0.02251038,  0.03957856, -0.00575858,\n",
       "        -0.00643916,  0.02104836, -0.01204206, -0.02285316, -0.048277  ,\n",
       "        -0.01115454,  0.00657135,  0.0429962 , -0.04939209, -0.03847098,\n",
       "         0.04898905,  0.00583593, -0.03096107,  0.03776547, -0.00791972,\n",
       "         0.0489365 ,  0.03497683, -0.04020759, -0.0368221 ,  0.00310266,\n",
       "        -0.01223439, -0.02627242, -0.03207506, -0.00582399, -0.00909815,\n",
       "        -0.04167529,  0.01504823, -0.04745865,  0.0191411 ,  0.04085448,\n",
       "         0.01742064,  0.00084819, -0.01201469, -0.00045469,  0.02449038,\n",
       "         0.01667568, -0.03912149,  0.00858856,  0.04886732, -0.0038898 ,\n",
       "        -0.03733238, -0.03490331,  0.00768775,  0.03561446,  0.01632407,\n",
       "         0.02663263,  0.03692872, -0.02840217, -0.00351461,  0.02576301,\n",
       "         0.02171227,  0.0240869 ,  0.03508117, -0.04052025,  0.01040053,\n",
       "        -0.01461612,  0.03371553, -0.01720979,  0.00507315,  0.04193708,\n",
       "        -0.01436452,  0.0169139 , -0.02665391, -0.00569106,  0.02625061,\n",
       "         0.00648182]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_globals = embs._get_global_context_features(data)\n",
    "\n",
    "GLOBAL_DIM = test_globals.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"GLOBAL_DIM: {GLOBAL_DIM}\")\n",
    "\n",
    "test_globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5dfd0e8-6729-4235-a719-5258799ed0d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER_ARM_DIM: 128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 128), dtype=float32, numpy=\n",
       "array([[-4.39269319e-02, -4.89849113e-02,  2.17152722e-02,\n",
       "         4.36156131e-02, -3.02130338e-02, -2.18611602e-02,\n",
       "        -7.64004141e-03,  1.75005309e-02,  3.58592346e-03,\n",
       "        -3.47124934e-02, -5.42150810e-03, -4.91415337e-03,\n",
       "        -4.30205129e-02, -2.52956282e-02, -1.91413406e-02,\n",
       "        -2.79031396e-02, -4.27376293e-02, -2.49722488e-02,\n",
       "        -3.53157893e-02, -3.77936289e-03, -1.85575858e-02,\n",
       "        -3.90958786e-03, -4.35093530e-02, -7.80593604e-04,\n",
       "        -5.75641543e-03,  1.46380775e-02, -3.44017744e-02,\n",
       "         3.40291746e-02,  2.00421698e-02, -2.89894827e-02,\n",
       "         1.67597868e-02,  3.47430594e-02,  2.25553773e-02,\n",
       "        -1.51305273e-03,  3.11938561e-02,  2.37680562e-02,\n",
       "        -4.30034474e-03,  3.87590192e-02,  2.30490230e-02,\n",
       "         8.58616084e-04,  4.00454290e-02, -2.53525618e-02,\n",
       "        -1.62669532e-02, -4.62024808e-02, -1.37146488e-02,\n",
       "         4.06624936e-02,  1.24173537e-02, -1.40851624e-02,\n",
       "         3.50883715e-02,  1.89897306e-02,  2.17622519e-03,\n",
       "        -2.68601533e-02,  4.70424779e-02, -1.36704557e-02,\n",
       "        -1.81292407e-02, -1.81390867e-02,  4.57765348e-02,\n",
       "         3.85605581e-02,  1.48864649e-02, -1.34929903e-02,\n",
       "         3.44138257e-02,  4.73960303e-02, -4.74824086e-02,\n",
       "         2.32468285e-02,  6.81377798e-02, -2.14438871e-01,\n",
       "         9.64709520e-02, -1.82081759e-01,  2.68818811e-02,\n",
       "        -1.09738350e-01,  9.92471352e-03, -2.24028826e-01,\n",
       "        -2.06889272e-01, -1.96021020e-01, -1.93422556e-01,\n",
       "         2.21337393e-01,  2.45649457e-01, -3.75978276e-02,\n",
       "        -1.67127326e-01, -1.81987762e-01,  3.55085172e-02,\n",
       "        -2.45462835e-01,  2.98854709e-02,  8.59454423e-02,\n",
       "         3.19026783e-02, -1.00064576e-01,  2.35167310e-01,\n",
       "        -2.25185931e-01,  3.71977128e-02,  2.07430959e-01,\n",
       "        -2.26089418e-01, -1.73352286e-02,  1.65847555e-01,\n",
       "        -1.13486126e-02,  2.00166345e-01, -1.40964031e-01,\n",
       "        -3.23062763e-02, -2.47113220e-02, -1.63217336e-02,\n",
       "        -2.96741072e-02,  5.44257455e-05,  2.28969883e-02,\n",
       "         2.42839940e-02,  3.80612724e-02,  1.39492871e-02,\n",
       "        -4.07092683e-02, -2.60100178e-02, -3.47218290e-02,\n",
       "         3.86541598e-02, -4.26510200e-02,  2.69370787e-02,\n",
       "        -1.18603706e-02, -2.01153476e-02, -1.19146826e-02,\n",
       "         3.67748663e-02, -1.54554602e-02, -4.17274386e-02,\n",
       "         4.01670262e-02,  1.30712483e-02, -1.52666448e-02,\n",
       "         3.81855816e-02,  2.90001538e-02, -3.40592377e-02,\n",
       "        -1.94054302e-02,  6.34099729e-03, -2.94001382e-02,\n",
       "         2.26273872e-02, -3.04567628e-02]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arms = embs._get_per_arm_features(data)\n",
    "\n",
    "PER_ARM_DIM = test_arms.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"PER_ARM_DIM: {PER_ARM_DIM}\")\n",
    "\n",
    "test_arms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f9a8ec-829c-4032-aa6b-f845afb7cc89",
   "metadata": {},
   "source": [
    "### TensorSpecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38d560e6-56dc-454d-a409-fd307dcb7ac9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE      = 128\n",
    "EVAL_BATCH_SIZE = 1\n",
    "NUM_ACTIONS     = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5196055a-56e6-413f-b3c4-f8a3f8b18f1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(96,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 128), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_spec = {\n",
    "    'global': tf.TensorSpec([GLOBAL_DIM], tf.float32),\n",
    "    'per_arm': tf.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32) #excluding action dim here\n",
    "}\n",
    "observation_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36dcb7a9-c589-44d0-a5e8-3960aca6a243",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=[], \n",
    "    dtype=tf.int32,\n",
    "    minimum=tf.constant(0),            \n",
    "    maximum=NUM_ACTIONS-1, # n degrees of freedom and will dictate the expected mean reward spec shape\n",
    "    # name=\"action_spec\"\n",
    ")\n",
    "\n",
    "action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9207d05f-72b2-42f3-bc41-089fc2aaba38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'global': TensorSpec(shape=(96,), dtype=tf.float32, name=None),\n",
       "                 'per_arm': TensorSpec(shape=(2, 128), dtype=tf.float32, name=None)},\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec = ts.time_step_spec(\n",
    "    observation_spec = observation_spec, \n",
    "    # reward_spec = _reward_spec\n",
    ")\n",
    "time_step_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "169f3e07-0c0a-4e18-b620-756f9419ccb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(96,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 128), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5e78dfd-b96d-48d6-8b17-353536485d1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reward': TensorSpec(shape=(128,), dtype=tf.float32, name='reward')}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.specs import array_spec\n",
    "\n",
    "reward_spec = {\n",
    "    \"reward\": array_spec.ArraySpec(shape=[BATCH_SIZE], dtype=np.float32, name=\"reward\")\n",
    "}\n",
    "\n",
    "reward_tensor_spec = train_utils.from_spec(reward_spec)\n",
    "reward_tensor_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9515c0f4-f01b-4ffa-968d-4d6e3ff599ef",
   "metadata": {},
   "source": [
    "### Distribution strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29f198a2-a945-49c2-a58d-6663b1cf0eb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.distribute.mirrored_strategy.MirroredStrategy at 0x7f04106235b0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_gpu = True\n",
    "use_tpu = False\n",
    "\n",
    "distribution_strategy = strategy_utils.get_strategy(tpu=use_tpu, use_gpu=use_gpu)\n",
    "distribution_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f85a3cb-0cbd-43fe-805d-a7c1047b0f55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_REPLICAS = distribution_strategy.num_replicas_in_sync\n",
    "NUM_REPLICAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd87d58a-9273-4fa1-a9c3-bfd97554cf01",
   "metadata": {},
   "source": [
    "## Agent & Policy config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12d6a9d1-dcc6-4205-9996-c08751d032a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'common_layers': [16, 8],\n",
      " 'encoding_dim': 1,\n",
      " 'epsilon': 0.01,\n",
      " 'eval_batch_size': 1,\n",
      " 'global_layers': [64, 32, 16],\n",
      " 'learning_rate': 0.05,\n",
      " 'model_type': 'epsGreedy',\n",
      " 'network_type': 'commontower',\n",
      " 'num_actions': 2,\n",
      " 'per_arm_layers': [64, 32, 16]}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Agents\n",
    "# ================================\n",
    "AGENT_TYPE      = 'epsGreedy' # 'LinUCB' | 'LinTS |, 'epsGreedy' | 'NeuralLinUCB'\n",
    "\n",
    "# Parameters for linear agents (LinUCB and LinTS).\n",
    "AGENT_ALPHA     = 0.1\n",
    "\n",
    "# Parameters for neural agents (NeuralEpsGreedy and NerualLinUCB).\n",
    "EPSILON         = 0.01\n",
    "LR              = 0.05\n",
    "\n",
    "# Parameters for NeuralLinUCB\n",
    "ENCODING_DIM    = 1\n",
    "EPS_PHASE_STEPS = 1000\n",
    "\n",
    "# ================================\n",
    "# Agent's Preprocess Network\n",
    "# ================================\n",
    "GLOBAL_LAYERS   = [64, 32, 16] # beginning should be of size: GLOBAL_DIM\n",
    "ARM_LAYERS      = [64, 32, 16] # beginning should be of size: PER_ARM_DIM\n",
    "COMMON_LAYERS   = [16, 8]\n",
    "\n",
    "NETWORK_TYPE    = \"commontower\" # 'commontower' | 'dotproduct'\n",
    "\n",
    "if AGENT_TYPE == 'NeuralLinUCB':\n",
    "    NETWORK_TYPE = 'commontower'\n",
    "    ENCODING_DIM = COMMON_LAYERS[-1]\n",
    "\n",
    "\n",
    "HPARAMS = {  # TODO - streamline and consolidate\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"eval_batch_size\" : EVAL_BATCH_SIZE,\n",
    "    \"num_actions\": NUM_ACTIONS,\n",
    "    \"model_type\": AGENT_TYPE,\n",
    "    \"network_type\": NETWORK_TYPE,\n",
    "    \"global_layers\": GLOBAL_LAYERS,\n",
    "    \"per_arm_layers\": ARM_LAYERS,\n",
    "    \"common_layers\": COMMON_LAYERS,\n",
    "    \"learning_rate\": LR,\n",
    "    \"epsilon\": EPSILON,\n",
    "    \"encoding_dim\": ENCODING_DIM\n",
    "}\n",
    "pprint(HPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99d9d36c-fb72-4859-91a7-c0c52672702a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent: NeuralEpsGreedyAgent\n",
      "Network: commontower\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with distribution_strategy.scope():\n",
    "\n",
    "    global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "    agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "        agent_type = AGENT_TYPE,\n",
    "        network_type = NETWORK_TYPE,\n",
    "        time_step_spec = time_step_spec,\n",
    "        action_spec = action_spec,\n",
    "        observation_spec=observation_spec,\n",
    "        global_layers = GLOBAL_LAYERS,\n",
    "        arm_layers = ARM_LAYERS,\n",
    "        common_layers = COMMON_LAYERS,\n",
    "        agent_alpha = AGENT_ALPHA,\n",
    "        learning_rate = LR,\n",
    "        epsilon = EPSILON,\n",
    "        train_step_counter = global_step,\n",
    "        output_dim = ENCODING_DIM,\n",
    "        eps_phase_steps = EPS_PHASE_STEPS,\n",
    "        summarize_grads_and_vars = True,\n",
    "        debug_summaries = True\n",
    "    )\n",
    "      \n",
    "agent.initialize()\n",
    "print(f'agent: {agent.name}')\n",
    "\n",
    "# if network:\n",
    "#     print(f\"Network: {network}\")\n",
    "\n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {NETWORK_TYPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385ff479-af1d-4437-93c5-1635fed4ee66",
   "metadata": {},
   "source": [
    "### Inspect the specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a755a4e1-84c6-40d9-972c-706188a95c98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50c9e9c3-3965-4aba-8141-c6b114c089e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(96,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 128), dtype=tf.float32, name=None)}),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.time_step_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b277541-4429-4e11-993b-759b665a9188",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(Trajectory(\n",
       "{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(1, dtype=int32)),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(96,), dtype=tf.float32, name=None)}),\n",
       " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), chosen_arm_features=TensorSpec(shape=(128,), dtype=tf.float32, name=None)),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.training_data_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511e3977-eca9-427c-a7cd-2762f36c623d",
   "metadata": {},
   "source": [
    "## Trajectory function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed9ba099-7fc9-46d7-8558-610adf56b669",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _trajectory_fn(element): # hparams\n",
    "    \n",
    "    \"\"\"Converts a dataset element into a trajectory.\"\"\"\n",
    "    # global_features = _get_global_context_features(element)\n",
    "    # arm_features = _get_per_arm_features(element)\n",
    "    \n",
    "    global_features = embs._get_global_context_features(element)\n",
    "    arm_features = embs._get_per_arm_features(element)\n",
    "    \n",
    "    # Adds a time dimension.\n",
    "    arm_features = train_utils._add_outer_dimension(arm_features)\n",
    "\n",
    "    # obs spec\n",
    "    observation = {\n",
    "        bandit_spec_utils.GLOBAL_FEATURE_KEY:\n",
    "            train_utils._add_outer_dimension(global_features),\n",
    "    }\n",
    "\n",
    "    # reward = train_utils._add_outer_dimension(_get_rewards(element))\n",
    "    reward = train_utils._add_outer_dimension(reward_factory._get_rewards(element))\n",
    "\n",
    "    # To emit the predicted rewards in policy_info, we need to create dummy\n",
    "    # rewards to match the definition in TensorSpec for the ones specified in\n",
    "    # emit_policy_info set.\n",
    "    dummy_rewards = tf.zeros([HPARAMS['batch_size'], 1, HPARAMS['num_actions']])\n",
    "    policy_info = policy_utilities.PerArmPolicyInfo(\n",
    "        chosen_arm_features=arm_features,\n",
    "        # Pass dummy mean rewards here to match the model_spec for emitting\n",
    "        # mean rewards in policy info\n",
    "        predicted_rewards_mean=dummy_rewards,\n",
    "        bandit_policy_type=tf.zeros([HPARAMS['batch_size'], 1, 1], dtype=tf.int32)\n",
    "        # policy_utilities.create_bandit_policy_type_tensor_spec(shape=[1]) # policy_utilities.BanditPolicyType.GREEDY\n",
    "        # tf.zeros([batch_size, 1, 1], dtype=tf.int32)\n",
    "    )\n",
    "    \n",
    "    if HPARAMS['model_type'] == 'neural_ucb':\n",
    "        policy_info = policy_info._replace(\n",
    "            predicted_rewards_optimistic=dummy_rewards\n",
    "        )\n",
    "        \n",
    "    return trajectory.single_step(\n",
    "        observation=observation,\n",
    "        action=tf.zeros_like(\n",
    "            reward, dtype=tf.int32\n",
    "        ),  # Arm features are copied from policy info, put dummy zeros here\n",
    "        policy_info=policy_info,\n",
    "        reward=reward,\n",
    "        discount=tf.zeros_like(reward)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffb7e89-794d-4547-80eb-ea40aefc7a30",
   "metadata": {},
   "source": [
    "# Create train & eval loop for demonstration\n",
    "\n",
    "> TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ebbca5-754b-4ffd-91d9-6c0480a78c06",
   "metadata": {},
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e507e412-31e5-4fa1-9fe6-e6dbe26b4bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agent(\n",
    "    iterations: int,\n",
    "):\n",
    "    # train agent for X iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7136d213-77bb-47b0-b96d-5237b9562e66",
   "metadata": {},
   "source": [
    "# (1) Offline training \n",
    "\n",
    "> TODO: add environment simulation for first iteration?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c456249-8299-4df6-8c25-fa8477c5963c",
   "metadata": {},
   "source": [
    "## Set Vertex Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dfbb5004-396d-4b1c-8557-4e8c95597dec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_VERSION = \"v4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5207887c-bf58-421e-9b27-6a41dbf23c0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : 05a-online-v4-rec-bandits-v2\n",
      "RUN_NAME          : run-20241210-030845\n",
      "\n",
      "BASE_OUTPUT_DIR   : gs://rec-bandits-v2-hybrid-vertex-bucket/05a-online-v4-rec-bandits-v2/run-20241210-030845\n",
      "LOG_DIR           : gs://rec-bandits-v2-hybrid-vertex-bucket/05a-online-v4-rec-bandits-v2/run-20241210-030845/logs\n",
      "ROOT_DIR          : gs://rec-bandits-v2-hybrid-vertex-bucket/05a-online-v4-rec-bandits-v2/run-20241210-030845/root\n",
      "ARTIFACTS_DIR     : gs://rec-bandits-v2-hybrid-vertex-bucket/05a-online-v4-rec-bandits-v2/run-20241210-030845/artifacts\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME   = f'05a-online-{EXPERIMENT_VERSION}-{PREFIX}'\n",
    "\n",
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "# aiplatform.init(\n",
    "#     project=PROJECT_ID,\n",
    "#     location=REGION,\n",
    "#     experiment=EXPERIMENT_NAME\n",
    "# )\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0e89ef-bd3f-4fb8-bbe5-8a1a3f5c0275",
   "metadata": {},
   "source": [
    "### Create TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "513f5eb4-3b16-47cc-b2ad-6ba7fcb4a320",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TB_RESOURCE_NAME : projects/934903580331/locations/us-central1/tensorboards/3689235345141923840\n",
      "TB display name  : 05a-online-v4-rec-bandits-v2-run-20241210-030845\n",
      "TB_ID            : 3689235345141923840\n"
     ]
    }
   ],
   "source": [
    "# # create new TB instance\n",
    "TENSORBOARD_DISPLAY_NAME=f\"{EXPERIMENT_NAME}-{RUN_NAME}\"\n",
    "\n",
    "tensorboard = aiplatform.Tensorboard.create(\n",
    "    display_name=TENSORBOARD_DISPLAY_NAME\n",
    "    , project=PROJECT_ID\n",
    "    , location=REGION\n",
    ")\n",
    "\n",
    "TB_RESOURCE_NAME = tensorboard.resource_name\n",
    "\n",
    "TB_ID = TB_RESOURCE_NAME.split('/')[-1]\n",
    "\n",
    "print(f\"TB_RESOURCE_NAME : {TB_RESOURCE_NAME}\")\n",
    "print(f\"TB display name  : {tensorboard.display_name}\")\n",
    "print(f\"TB_ID            : {TB_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "286ceb96-cdf6-4a99-8092-e4988829a489",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-b8bee5ff-73cd-4908-b57f-24a75a8f1fe2\" href=\"#view-view-vertex-resource-b8bee5ff-73cd-4908-b57f-24a75a8f1fe2\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-b8bee5ff-73cd-4908-b57f-24a75a8f1fe2');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/05a-online-v4-rec-bandits-v2/runs?project=hybrid-vertex');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/05a-online-v4-rec-bandits-v2/runs?project=hybrid-vertex', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME,\n",
    "    # experiment_tensorboard=TB_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5505865a-006a-4159-9a47-65ad3e09dd5b",
   "metadata": {},
   "source": [
    "### Saver & Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f6d27959-3d5a-43a2-a9ec-38301535107e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04b07870-2c24-4c8a-bb6d-79980323174d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TMP_DIR = f\"tmp_dir_{EXPERIMENT_VERSION}\"\n",
    "\n",
    "# !rm -rf {TMP_DIR}\n",
    "# !mkdir -p {TMP_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a5fdc1d-3404-43aa-99ea-5d5741d3a0f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMP_DIR     : tmp_dir_v4\n",
      "global_step : MirroredVariable:{\n",
      "  0: <tf.Variable 'global_step:0' shape=() dtype=int64, numpy=0>\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# tempdir = os.getenv(f\"tmp_dir_{EXPERIMENT_VERSION}\", tempfile.gettempdir())\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "print(f\"TMP_DIR     : {TMP_DIR}\")\n",
    "print(f\"global_step : {global_step}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7fd3daf7-b1ba-44a0-851c-3ecbd2dae325",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('metrics: [<tf_agents.metrics.tf_metrics.AverageReturnMetric object at '\n",
      " '0x7f04106218a0>]')\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "with distribution_strategy.scope():\n",
    "    train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "        f\"{LOG_DIR}\", flush_millis=10 * 1000\n",
    "    )\n",
    "\n",
    "    train_summary_writer.set_as_default()\n",
    "\n",
    "# ====================================================\n",
    "# metrics\n",
    "# ====================================================\n",
    "step_metric = tf_metrics.EnvironmentSteps()\n",
    "metrics = [\n",
    "    # tf_metrics.NumberOfEpisodes(),\n",
    "    # tf_metrics.AverageEpisodeLengthMetric(batch_size=HPARAMS['batch_size']),\n",
    "    tf_metrics.AverageReturnMetric(batch_size=HPARAMS['batch_size'])\n",
    "]\n",
    "\n",
    "pprint(f\"metrics: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "48ffc4e7-ae79-409b-9c71-8edba8bbc6d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting checkpoint_manager: tmp_dir_v4/checkpoint\n",
      "\n",
      "setting POLICY_DIR: tmp_dir_v4/policy\n",
      "\n",
      "saver: <tf_agents.policies.policy_saver.PolicySaver object at 0x7f0410622e60>\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# get checkpoint manager\n",
    "# ====================================================\n",
    "# CHKPOINT_DIR = f\"{ROOT_DIR}/chkpoint\"\n",
    "CHKPOINT_DIR = os.path.join(TMP_DIR, 'checkpoint')\n",
    "print(f\"setting checkpoint_manager: {CHKPOINT_DIR}\\n\")\n",
    "\n",
    "checkpoint_manager = train_utils.restore_and_get_checkpoint_manager(\n",
    "    root_dir=CHKPOINT_DIR, \n",
    "    agent=agent, \n",
    "    metrics=metrics, \n",
    "    step_metric=step_metric\n",
    ")\n",
    "# ====================================================\n",
    "# policy saver\n",
    "# ====================================================\n",
    "POLICY_DIR = os.path.join(TMP_DIR, 'policy')\n",
    "print(f\"setting POLICY_DIR: {POLICY_DIR}\\n\")\n",
    "saver = policy_saver.PolicySaver(\n",
    "    agent.policy, \n",
    "    train_step=global_step\n",
    ")\n",
    "print(f\"saver: {saver}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9957cc5-0e9f-4f68-bcf5-4ffb1dc32f2a",
   "metadata": {},
   "source": [
    "## Train & Eval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cfc930f9-f430-45e5-8b5e-42cd4cf6b6c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_TRAIN_STEPS : 50\n",
      "EVAL_DATA_SIZE : 1000\n",
      "NUM_EVAL_STEPS : 1000\n",
      "CHKPT_INTERVAL: 50\n",
      "LOG_INTERVAL : 10\n"
     ]
    }
   ],
   "source": [
    "# TRAIN_DATA_SIZE = 80000          # len(list(train_dataset))\n",
    "NUM_TRAIN_STEPS = 50            # TRAIN_DATA_SIZE // HPARAMS['batch_size']\n",
    "\n",
    "EVAL_DATA_SIZE  = 1000          # len(list(val_dataset))\n",
    "NUM_EVAL_STEPS  = 1000           # EVAL_DATA_SIZE // HPARAMS['eval_batch_size']\n",
    "\n",
    "CHKPT_INTERVAL  = NUM_TRAIN_STEPS # // 5\n",
    "LOG_INTERVAL    = 10\n",
    "# EVAL_INTERVAL = NUM_TRAIN_STEPS // 2\n",
    "\n",
    "# print(f\"TRAIN_DATA_SIZE : {TRAIN_DATA_SIZE}\")\n",
    "print(f\"NUM_TRAIN_STEPS : {NUM_TRAIN_STEPS}\")\n",
    "print(f\"EVAL_DATA_SIZE : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS : {NUM_EVAL_STEPS}\")\n",
    "print(f\"CHKPT_INTERVAL: {CHKPT_INTERVAL}\")\n",
    "print(f\"LOG_INTERVAL : {LOG_INTERVAL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3dde5dfb-e6cf-4b39-8cc8-64b667885d1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec={'target_movie_genres': TensorSpec(shape=(None, 10), dtype=tf.string, name=None), 'target_movie_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'target_movie_rating': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'target_movie_title': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'target_movie_year': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'target_rating_timestamp': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'user_age': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'user_gender': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_occupation_text': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_zip_code': TensorSpec(shape=(None,), dtype=tf.string, name=None)}>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data\n",
    "train_ds_iterator = iter(train_dataset.batch(HPARAMS['batch_size']).repeat())\n",
    "\n",
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS[\"eval_batch_size\"])\n",
    "\n",
    "if NUM_EVAL_STEPS > 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)\n",
    "\n",
    "# eval_ds = eval_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "eval_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b2c67a-5822-48f0-ab6b-51f8fe6e38fa",
   "metadata": {},
   "source": [
    "### evaluate pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "01a87a44-cd04-47c7-8e8a-e4fd34e4c877",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating pre-trained Agent...\n",
      "pre-train val_loss     : 15.003067016601562\n",
      "pre-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Evaluate the agent's policy once before training\n",
    "# ====================================================\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "pre_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "\n",
    "print(f\"evaluating pre-trained Agent...\")\n",
    "start_time = time.time()\n",
    "\n",
    "pre_val_loss, pre_preds, pre_tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = pre_policy_tf,\n",
    "    data = eval_ds,\n",
    "    embs = embs,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    # vocab_dict = vocab_dict,\n",
    "    # num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    # global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    # mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"pre-train val_loss     : {pre_val_loss}\")\n",
    "print(f\"pre-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677fb309-e72f-44ce-b601-e5a70e6f6c16",
   "metadata": {},
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e33216ae-76eb-4cba-a658-f3649f1b070c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting train loop...\n",
      "step = 0: train loss = 16.329999923706055\n",
      "step = 10: train loss = 10.15999984741211\n",
      "step = 20: train loss = 9.220000267028809\n",
      "step = 30: train loss = 1.340000033378601\n",
      "step = 40: train loss = 1.5099999904632568\n",
      "train runtime_mins: 0\n"
     ]
    }
   ],
   "source": [
    "list_o_loss = []\n",
    "\n",
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "print(f\"starting train loop...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Continuous monitoring\n",
    "aiplatform.start_upload_tb_log(\n",
    "    # tensorboard_id=TB_RESOURCE_NAME,\n",
    "    tensorboard_experiment_name=EXPERIMENT_NAME,\n",
    "    logdir=LOG_DIR,\n",
    "    experiment_display_name=EXPERIMENT_NAME,\n",
    "    run_name_prefix=RUN_NAME,\n",
    "    # description=description,\n",
    ")\n",
    "\n",
    "# # start the timer and training\n",
    "with tf.compat.v2.summary.record_if(\n",
    "    lambda: tf.math.equal(global_step % LOG_INTERVAL, 0)\n",
    "):\n",
    "\n",
    "    for i in range(NUM_TRAIN_STEPS):\n",
    "    \n",
    "    # with train_summary_writer.as_default():\n",
    "\n",
    "        data = next(train_ds_iterator)\n",
    "        trajectories = _trajectory_fn(data)\n",
    "\n",
    "        # All tensors in experience must be shaped [batch, time, ...] \n",
    "        step = agent.train_step_counter.numpy()\n",
    "        loss = agent.train(experience=trajectories)\n",
    "        list_o_loss.append(loss.loss.numpy())\n",
    "\n",
    "        # train_utils._export_metrics_and_summaries(\n",
    "        #     step=i, \n",
    "        #     metrics=metrics\n",
    "        # )\n",
    "\n",
    "        # print step loss\n",
    "        if step % LOG_INTERVAL == 0:\n",
    "            print(\n",
    "                'step = {0}: train loss = {1}'.format(\n",
    "                    step, round(loss.loss.numpy(), 2)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if i > 0 and i % CHKPT_INTERVAL == 0:\n",
    "            # saver.save(os.path.join(CHKPOINT_DIR, 'policy_%d' % step_metric.result()))\n",
    "            checkpoint_manager.save(global_step)\n",
    "            print(f\"saved policy to: {CHKPOINT_DIR}\")\n",
    "            \n",
    "aiplatform.end_upload_tb_log()\n",
    "   \n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"train runtime_mins: {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d164ebc-ca0a-46b6-beca-695836dae067",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tmp_dir_v4/checkpoint/ckpt-50'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_manager.save(global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d2d96210-282b-4f7a-8d27-f265f7c5e45c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MirroredVariable:{\n",
       "  0: <tf.Variable 'global_step:0' shape=() dtype=int64, numpy=50>\n",
       "}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkpoint_manager.initialize_or_restore()\n",
    "global_step = tf.compat.v1.train.get_global_step()\n",
    "global_step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b9a721-d9f4-4ba6-a385-3001d58a9ed5",
   "metadata": {},
   "source": [
    "Alternatively, you can save the policy (model) and restore it. Unlike checkpointer, you cannot continue with the training, but you can still deploy the model. Note that the downloaded file is much smaller than that of the checkpointer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "69ab6d4a-8323-46ba-bf3c-6abd716c7f8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_metric.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "177a6e01-1fe5-4db8-be4c-8ed4510aa068",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tmp_dir_v4/policy/policy_0'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVE_POLICY_DIR = os.path.join(POLICY_DIR, 'policy_%d' % step_metric.result())\n",
    "SAVE_POLICY_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6b2db70c-760b-40f7-8b86-26454846adb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved trained policy to: tmp_dir_v4/policy/policy_0\n"
     ]
    }
   ],
   "source": [
    "saver.save(SAVE_POLICY_DIR)\n",
    "print(f\"saved trained policy to: {SAVE_POLICY_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cc16bdc3-a401-4a36-95e0-d7ccef1680cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list_o_loss)\n",
    "# plt.ylim([0, 10])\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5cc1d463-f5ed-4478-b9c1-2ae87e1096b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e9224b2b-44d5-4792-b5d4-c0688c86743e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %tensorboard --logdir=$LOG_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "42a851f1-e362-4286-838b-1f16f7dbe324",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorboard import notebook\n",
    "# notebook.list() # View open TensorBoard instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bb393f-b785-459c-97fa-5e8c221d3e93",
   "metadata": {},
   "source": [
    "### evaluate post-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9a5c6af1-24ac-4a68-9d5e-e3a2156db18d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating trained Agent...\n",
      "post-train val_loss     : 1.6797388792037964\n",
      "post-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = post_policy_tf,\n",
    "    data = eval_ds,\n",
    "    embs = embs,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5627ba05-392d-44a3-8a74-49cb71e683bb",
   "metadata": {},
   "source": [
    "# (2) Serving Trained Policy v1\n",
    "\n",
    "* Can't load with `tf.saved_model.load(SAVE_POLICY_DIR)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "246f2693-a34d-444a-a18f-5c83f6484c3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tmp_dir_v4/policy/policy_0'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVE_POLICY_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "14d14189-50c7-4ca6-8ea9-33a1f93bcaf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f041078ab90>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    SAVE_POLICY_DIR, load_specs_from_pbtxt=True\n",
    ")\n",
    "\n",
    "saved_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7070c76b-38e8-40e9-9d31-d6713cba6fb4",
   "metadata": {},
   "source": [
    "### Generate predictions (actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1ab7322e-5dfa-44b7-aa94-5161078a586b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "SKIP_NUM = 10\n",
    "\n",
    "for x in eval_ds.skip(SKIP_NUM).take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    \n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "    \n",
    "    # rewards = _get_rewards(x)\n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = saved_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d112c061-598b-460e-9693-0c42f79574e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([2.781375 , 2.7069664], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([ 2.27096193e-02,  3.29837464e-02, -8.87728855e-03,  4.59509157e-02,\n",
       "       -1.28353760e-03, -4.36612368e-02, -2.66308784e-02, -4.60116155e-02,\n",
       "       -3.14931273e-02, -4.46862243e-02,  1.85825936e-02, -4.09654491e-02,\n",
       "        2.60904320e-02,  1.55217089e-02,  2.21093334e-02, -5.09849936e-03,\n",
       "       -3.34761031e-02,  4.32716869e-02, -2.10958365e-02,  3.79182212e-02,\n",
       "        2.17372067e-02, -3.07971723e-02,  1.64008476e-02, -1.70343034e-02,\n",
       "       -8.24905559e-03, -1.60623081e-02, -1.83885694e-02, -3.08714155e-02,\n",
       "       -3.43089849e-02, -1.29944086e-03, -1.47675164e-02,  1.80485360e-02,\n",
       "       -1.40281767e-03,  3.19379456e-02, -2.41078492e-02,  2.05108039e-02,\n",
       "       -3.65560763e-02,  3.44129838e-02,  2.39289291e-02,  2.38182396e-03,\n",
       "        2.57031359e-02, -2.89220214e-02, -3.45984213e-02, -1.20566115e-02,\n",
       "       -1.29612684e-02, -6.42249733e-03, -1.74042210e-02, -3.17854285e-02,\n",
       "       -4.12099138e-02,  3.88840921e-02,  1.11993663e-02, -1.62936226e-02,\n",
       "       -4.70794812e-02, -3.29086669e-02,  2.49796771e-02, -1.34046078e-02,\n",
       "       -3.72971408e-02,  2.91075818e-02, -1.58086903e-02,  1.94237493e-02,\n",
       "        4.44667414e-03, -2.61714347e-02,  3.77268828e-02, -8.24292749e-03,\n",
       "        4.08826657e-02, -1.28663316e-01,  5.78825735e-02, -1.09249055e-01,\n",
       "        1.61291286e-02, -6.58430159e-02,  5.95482811e-03, -1.34417295e-01,\n",
       "       -1.24133557e-01, -1.17612608e-01, -1.16053529e-01,  1.32802442e-01,\n",
       "        1.47389680e-01, -2.25586966e-02, -1.00276396e-01, -1.09192662e-01,\n",
       "        2.13051103e-02, -1.47277713e-01,  1.79312825e-02,  5.15672676e-02,\n",
       "        1.91416070e-02, -6.00387454e-02,  1.41100392e-01, -1.35111570e-01,\n",
       "        2.23186277e-02,  1.24458581e-01, -1.35653645e-01, -1.04011372e-02,\n",
       "        9.95085388e-02, -6.80916756e-03,  1.20099813e-01, -8.45784247e-02,\n",
       "       -3.23062763e-02, -2.47113220e-02, -1.63217336e-02, -2.96741072e-02,\n",
       "        5.44257455e-05,  2.28969883e-02,  2.42839940e-02,  3.80612724e-02,\n",
       "        1.39492871e-02, -4.07092683e-02, -2.60100178e-02, -3.47218290e-02,\n",
       "        3.86541598e-02, -4.26510200e-02,  2.69370787e-02, -1.18603706e-02,\n",
       "       -2.01153476e-02, -1.19146826e-02,  3.67748663e-02, -1.54554602e-02,\n",
       "       -4.17274386e-02,  4.01670262e-02,  1.30712483e-02, -1.52666448e-02,\n",
       "        3.81855816e-02,  2.90001538e-02, -3.40592377e-02, -1.94054302e-02,\n",
       "        6.34099729e-03, -2.94001382e-02,  2.26273872e-02, -3.04567628e-02],\n",
       "      dtype=float32)))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3e8d3a-e68b-43a8-bedd-19c30dcd1d1e",
   "metadata": {},
   "source": [
    "# (3) Online learning\n",
    "\n",
    "> Here we'll simulate all the actions that need to happen on an online endpoint\n",
    "\n",
    "For \"online learning\" to take place, the agent's policy needs to be updated, where \"updated\" is conceptually similar to retraining a traditional supervised learning model (with latest training examples) and deploying the newly trained model\n",
    "* the bandit agent's policy is updated (i.e., learns) when it receives (e.g., `agent.train(...)`) a trajectory that includes the prediction/action AND the delayed feedback\n",
    "* once `agent.train(...)` takes place, the policy is updated (e.g., weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78edfb6a-05cf-4445-babe-e5b50ae45c84",
   "metadata": {},
   "source": [
    "### Load agent checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eae177d0-1e62-414d-99e8-98e6e5799c9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('deployed_metrics: [<tf_agents.metrics.tf_metrics.AverageReturnMetric object '\n",
      " 'at 0x7efef80d6860>]')\n"
     ]
    }
   ],
   "source": [
    "deployed_step_metric = tf_metrics.EnvironmentSteps()\n",
    "deployed_metrics = [\n",
    "    # tf_metrics.NumberOfEpisodes(),\n",
    "    # tf_metrics.AverageEpisodeLengthMetric(batch_size=HPARAMS['batch_size']),\n",
    "    tf_metrics.AverageReturnMetric(batch_size=HPARAMS['batch_size'])\n",
    "]\n",
    "\n",
    "pprint(f\"deployed_metrics: {deployed_metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "077b3059-538a-4c7c-a7cd-0d9d8d800001",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent: NeuralEpsGreedyAgent\n"
     ]
    }
   ],
   "source": [
    "deployed_agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "    agent_type = AGENT_TYPE,\n",
    "    network_type = NETWORK_TYPE,\n",
    "    time_step_spec = time_step_spec,\n",
    "    action_spec = action_spec,\n",
    "    observation_spec=observation_spec,\n",
    "    global_layers = GLOBAL_LAYERS,\n",
    "    arm_layers = ARM_LAYERS,\n",
    "    common_layers = COMMON_LAYERS,\n",
    "    agent_alpha = AGENT_ALPHA,\n",
    "    learning_rate = LR,\n",
    "    epsilon = EPSILON,\n",
    "    # train_step_counter = global_step,\n",
    "    output_dim = ENCODING_DIM,\n",
    "    eps_phase_steps = EPS_PHASE_STEPS,\n",
    "    # summarize_grads_and_vars = True,\n",
    "    debug_summaries = True\n",
    ")\n",
    "      \n",
    "deployed_agent.initialize()\n",
    "print(f'agent: {deployed_agent.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ab5f7094-fabb-478e-9ba4-fbb1e9e4638f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MirroredVariable:{\n",
       "  0: <tf.Variable 'global_step:0' shape=() dtype=int64, numpy=50>\n",
       "}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6ecc624c-3496-43cf-bab5-52911ecaf634",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tmp_dir_v4/checkpoint'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHKPOINT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8123c4cc-05ed-4828-a5ca-111ae32bd516",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MirroredVariable:{\n",
       "  0: <tf.Variable 'global_step:0' shape=() dtype=int64, numpy=50>\n",
       "}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployed_agent.train_step_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a8649dc9-c485-4044-8e42-d1cbe5d212d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deployed_checkpoint_manager = train_utils.restore_and_get_checkpoint_manager(\n",
    "    root_dir=CHKPOINT_DIR, \n",
    "    agent=deployed_agent, \n",
    "    metrics=deployed_metrics, \n",
    "    step_metric=deployed_step_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "531764a5-6c54-466d-b364-2d1cb3214b89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MirroredVariable:{\n",
       "  0: <tf.Variable 'global_step:0' shape=() dtype=int64, numpy=50>\n",
       "}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm train step counter\n",
    "deployed_agent.train_step_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66690d05-879e-4cc2-b364-208852cb9e8a",
   "metadata": {},
   "source": [
    "#### eval deployed agent\n",
    "\n",
    "> validate metrics on eval set reflect trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f248d047-fb3e-4a5f-a387-53e168977a25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating pre-trained Agent...\n",
      "pre-train val_loss     : 1.67861008644104\n",
      "pre-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Evaluate the agent's policy once before training\n",
    "# ====================================================\n",
    "deployed_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(deployed_agent.policy, use_tf_function=True)\n",
    "\n",
    "print(f\"evaluating pre-trained Agent...\")\n",
    "start_time = time.time()\n",
    "\n",
    "pre_val_loss, pre_preds, pre_tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = deployed_policy_tf,\n",
    "    data = eval_ds,\n",
    "    embs = embs,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    # vocab_dict = vocab_dict,\n",
    "    # num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    # global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    # mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"pre-train val_loss     : {pre_val_loss}\")\n",
    "print(f\"pre-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1839e39-b1a8-45d2-be78-5f694e78820b",
   "metadata": {},
   "source": [
    "#### Train loop on endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "79a1c276-4773-4e93-91fc-1a5eca957f60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_TRAIN_STEPS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6439c628-a905-43ca-8e4f-bd2febdfe781",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting train loop...\n",
      "step = 50: train loss = 1.2699999809265137\n",
      "step = 60: train loss = 1.190000057220459\n",
      "step = 70: train loss = 1.2400000095367432\n",
      "step = 80: train loss = 1.2599999904632568\n",
      "step = 90: train loss = 1.3700000047683716\n",
      "step = 100: train loss = 1.4199999570846558\n",
      "step = 110: train loss = 1.1399999856948853\n",
      "step = 120: train loss = 1.7000000476837158\n",
      "step = 130: train loss = 1.2100000381469727\n",
      "step = 140: train loss = 1.190000057220459\n",
      "step = 150: train loss = 1.2100000381469727\n",
      "step = 160: train loss = 1.3200000524520874\n",
      "step = 170: train loss = 1.399999976158142\n",
      "step = 180: train loss = 1.340000033378601\n",
      "step = 190: train loss = 1.1799999475479126\n",
      "step = 200: train loss = 1.0800000429153442\n",
      "step = 210: train loss = 1.309999942779541\n",
      "step = 220: train loss = 1.4800000190734863\n",
      "step = 230: train loss = 1.4800000190734863\n",
      "step = 240: train loss = 1.309999942779541\n",
      "train runtime_mins: 1\n"
     ]
    }
   ],
   "source": [
    "list_o_loss = []\n",
    "\n",
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "print(f\"starting train loop...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# start the timer and training\n",
    "with tf.compat.v2.summary.record_if(\n",
    "    lambda: tf.math.equal(global_step % LOG_INTERVAL, 0)\n",
    "):\n",
    "\n",
    "    for i in range(NUM_TRAIN_STEPS):\n",
    "\n",
    "    # with train_summary_writer.as_default():\n",
    "\n",
    "        data = next(train_ds_iterator)\n",
    "        trajectories = _trajectory_fn(data)\n",
    "\n",
    "        # All tensors in experience must be shaped [batch, time, ...] \n",
    "        step = deployed_agent.train_step_counter.numpy()\n",
    "        loss = deployed_agent.train(experience=trajectories)\n",
    "        list_o_loss.append(loss.loss.numpy())\n",
    "\n",
    "        # train_utils._export_metrics_and_summaries(\n",
    "        #     step=i, \n",
    "        #     metrics=deployed_metrics\n",
    "        # )\n",
    "\n",
    "        # print step loss\n",
    "        if step % LOG_INTERVAL == 0:\n",
    "            print(\n",
    "                'step = {0}: train loss = {1}'.format(\n",
    "                    step, round(loss.loss.numpy(), 2)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # if i > 0 and i % CHKPT_INTERVAL == 0:\n",
    "            # saver.save(os.path.join(CHKPOINT_DIR, 'policy_%d' % step_metric.result()))\n",
    "            # deployed_checkpoint_manager.save(global_step)\n",
    "            # print(f\"saved policy to: {CHKPOINT_DIR}\")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"train runtime_mins: {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2f826ce9-a6c3-49aa-951a-6c2b5eb58794",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint  ckpt-50.data-00000-of-00001  ckpt-50.index\n"
     ]
    }
   ],
   "source": [
    "!ls $CHKPOINT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7e498034-5104-4ab6-9805-394f82e8ff59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tmp_dir_v4/checkpoint/ckpt-250'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployed_checkpoint_manager.save(global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f7e73061-aadb-42d3-a9f5-27067d150c10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\t\t      ckpt-250.index\t\t   ckpt-50.index\n",
      "ckpt-250.data-00000-of-00001  ckpt-50.data-00000-of-00001\n"
     ]
    }
   ],
   "source": [
    "!ls $CHKPOINT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17978e3-12f1-4421-916d-6d880592ec53",
   "metadata": {},
   "source": [
    "### save newly trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "490fbb88-dc29-4992-ae41-b164a0e081ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deployed_step_metric.result()\n",
    "deployed_agent.train_step_counter.value().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "71917a67-8429-4329-958f-e7fdd187b0db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tmp_dir_v4/policy/policy_250'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEW_SAVE_POLICY_DIR = os.path.join(POLICY_DIR, 'policy_%d' % deployed_agent.train_step_counter.value().numpy())\n",
    "NEW_SAVE_POLICY_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5116acf0-446d-4e3c-a54c-7111e94e3151",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved trained policy to: tmp_dir_v4/policy/policy_250\n"
     ]
    }
   ],
   "source": [
    "# saver.save(POLICY_DIR)\n",
    "saver.save(NEW_SAVE_POLICY_DIR)\n",
    "print(f\"saved trained policy to: {NEW_SAVE_POLICY_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a345a1d3-7beb-43c4-b8c5-b20a63352b0f",
   "metadata": {},
   "source": [
    "### Create zip file and upload zip file\n",
    "\n",
    "> export / import checkpointer and policy directories such that you can continue training at a later point and deploy the model without having to train again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8c213d61-f4cd-49b8-b014-9e6663ca56f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def create_zip_file(dirname, base_filename):\n",
    "#     return shutil.make_archive(base_filename, 'zip', dirname)\n",
    "\n",
    "# def upload_and_unzip_file_to(dirname):\n",
    "#     if files is None:\n",
    "#         return\n",
    "#     uploaded = files.upload()\n",
    "#     for fn in uploaded.keys():\n",
    "#         print(\n",
    "#             'User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "#                 name=fn, length=len(uploaded[fn])\n",
    "#             )\n",
    "#         )\n",
    "#         shutil.rmtree(dirname)\n",
    "#         zip_files = zipfile.ZipFile(io.BytesIO(uploaded[fn]), 'r')\n",
    "#         zip_files.extractall(dirname)\n",
    "#         zip_files.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "57e495e1-4a48-46d4-9444-4244a8906ab5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# checkpoint_zip_filename = create_zip_file(CHKPOINT_DIR, os.path.join(tempdir, 'exported_cp'))\n",
    "# checkpoint_zip_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e28d64b3-4d31-4a83-b813-6c18ef235361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # download zip file\n",
    "# if files is not None:\n",
    "#     files.download(checkpoint_zip_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c46d59d2-1e56-479f-b294-a0966bfee1ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# upload_and_unzip_file_to(CHKPOINT_DIR)\n",
    "# checkpoint_manager.initialize_or_restore()\n",
    "# global_step = tf.compat.v1.train.get_global_step()\n",
    "# print(f\"global_step : {global_step}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c265ea-7951-4825-bdc3-e448633a4b6e",
   "metadata": {},
   "source": [
    "# (4) Serving Trained Policy v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "55151d77-0f3e-4996-a50e-8e621f3b3e67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tmp_dir_v4/policy/policy_250'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEW_SAVE_POLICY_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c699b4f3-c01d-44e4-87b6-a0833ef057cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f02a025d660>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_policy_v2 = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    NEW_SAVE_POLICY_DIR, load_specs_from_pbtxt=True\n",
    ")\n",
    "\n",
    "saved_policy_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ead0516b-aeac-4cd5-aa79-0081fe12505a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "SKIP_NUM = 10\n",
    "\n",
    "for x in eval_ds.skip(SKIP_NUM).take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    \n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "    \n",
    "    # rewards = _get_rewards(x)\n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = saved_policy_v2.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "954e834e-d5d6-4b60-89fa-badbd8c13bda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([2.781375 , 2.7069664], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([ 2.27096193e-02,  3.29837464e-02, -8.87728855e-03,  4.59509157e-02,\n",
       "       -1.28353760e-03, -4.36612368e-02, -2.66308784e-02, -4.60116155e-02,\n",
       "       -3.14931273e-02, -4.46862243e-02,  1.85825936e-02, -4.09654491e-02,\n",
       "        2.60904320e-02,  1.55217089e-02,  2.21093334e-02, -5.09849936e-03,\n",
       "       -3.34761031e-02,  4.32716869e-02, -2.10958365e-02,  3.79182212e-02,\n",
       "        2.17372067e-02, -3.07971723e-02,  1.64008476e-02, -1.70343034e-02,\n",
       "       -8.24905559e-03, -1.60623081e-02, -1.83885694e-02, -3.08714155e-02,\n",
       "       -3.43089849e-02, -1.29944086e-03, -1.47675164e-02,  1.80485360e-02,\n",
       "       -1.40281767e-03,  3.19379456e-02, -2.41078492e-02,  2.05108039e-02,\n",
       "       -3.65560763e-02,  3.44129838e-02,  2.39289291e-02,  2.38182396e-03,\n",
       "        2.57031359e-02, -2.89220214e-02, -3.45984213e-02, -1.20566115e-02,\n",
       "       -1.29612684e-02, -6.42249733e-03, -1.74042210e-02, -3.17854285e-02,\n",
       "       -4.12099138e-02,  3.88840921e-02,  1.11993663e-02, -1.62936226e-02,\n",
       "       -4.70794812e-02, -3.29086669e-02,  2.49796771e-02, -1.34046078e-02,\n",
       "       -3.72971408e-02,  2.91075818e-02, -1.58086903e-02,  1.94237493e-02,\n",
       "        4.44667414e-03, -2.61714347e-02,  3.77268828e-02, -8.24292749e-03,\n",
       "        4.08826657e-02, -1.28663316e-01,  5.78825735e-02, -1.09249055e-01,\n",
       "        1.61291286e-02, -6.58430159e-02,  5.95482811e-03, -1.34417295e-01,\n",
       "       -1.24133557e-01, -1.17612608e-01, -1.16053529e-01,  1.32802442e-01,\n",
       "        1.47389680e-01, -2.25586966e-02, -1.00276396e-01, -1.09192662e-01,\n",
       "        2.13051103e-02, -1.47277713e-01,  1.79312825e-02,  5.15672676e-02,\n",
       "        1.91416070e-02, -6.00387454e-02,  1.41100392e-01, -1.35111570e-01,\n",
       "        2.23186277e-02,  1.24458581e-01, -1.35653645e-01, -1.04011372e-02,\n",
       "        9.95085388e-02, -6.80916756e-03,  1.20099813e-01, -8.45784247e-02,\n",
       "       -3.23062763e-02, -2.47113220e-02, -1.63217336e-02, -2.96741072e-02,\n",
       "        5.44257455e-05,  2.28969883e-02,  2.42839940e-02,  3.80612724e-02,\n",
       "        1.39492871e-02, -4.07092683e-02, -2.60100178e-02, -3.47218290e-02,\n",
       "        3.86541598e-02, -4.26510200e-02,  2.69370787e-02, -1.18603706e-02,\n",
       "       -2.01153476e-02, -1.19146826e-02,  3.67748663e-02, -1.54554602e-02,\n",
       "       -4.17274386e-02,  4.01670262e-02,  1.30712483e-02, -1.52666448e-02,\n",
       "        3.81855816e-02,  2.90001538e-02, -3.40592377e-02, -1.94054302e-02,\n",
       "        6.34099729e-03, -2.94001382e-02,  2.26273872e-02, -3.04567628e-02],\n",
       "      dtype=float32)))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5f2c1332-74c3-4753-b28b-c025f1918aca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bandit_policy_type': 1,\n",
       " 'chosen_arm_features': [0.022709619253873825,\n",
       "  0.032983746379613876,\n",
       "  -0.008877288550138474,\n",
       "  0.04595091566443443,\n",
       "  -0.001283537596464157,\n",
       "  -0.04366123676300049,\n",
       "  -0.026630878448486328,\n",
       "  -0.04601161554455757,\n",
       "  -0.03149312734603882,\n",
       "  -0.044686224311590195,\n",
       "  0.018582593649625778,\n",
       "  -0.040965449064970016,\n",
       "  0.026090431958436966,\n",
       "  0.015521708875894547,\n",
       "  0.02210933342576027,\n",
       "  -0.005098499357700348,\n",
       "  -0.033476103097200394,\n",
       "  0.043271686881780624,\n",
       "  -0.02109583653509617,\n",
       "  0.037918221205472946,\n",
       "  0.02173720672726631,\n",
       "  -0.030797172337770462,\n",
       "  0.01640084758400917,\n",
       "  -0.01703430339694023,\n",
       "  -0.008249055594205856,\n",
       "  -0.016062308102846146,\n",
       "  -0.018388569355010986,\n",
       "  -0.03087141551077366,\n",
       "  -0.034308984875679016,\n",
       "  -0.001299440860748291,\n",
       "  -0.014767516404390335,\n",
       "  0.018048536032438278,\n",
       "  -0.0014028176665306091,\n",
       "  0.03193794563412666,\n",
       "  -0.02410784922540188,\n",
       "  0.020510803908109665,\n",
       "  -0.036556076258420944,\n",
       "  0.03441298380494118,\n",
       "  0.0239289291203022,\n",
       "  0.0023818239569664,\n",
       "  0.02570313587784767,\n",
       "  -0.02892202138900757,\n",
       "  -0.034598421305418015,\n",
       "  -0.012056611478328705,\n",
       "  -0.012961268424987793,\n",
       "  -0.0064224973320961,\n",
       "  -0.0174042209982872,\n",
       "  -0.031785428524017334,\n",
       "  -0.04120991379022598,\n",
       "  0.03888409212231636,\n",
       "  0.011199366301298141,\n",
       "  -0.01629362255334854,\n",
       "  -0.047079481184482574,\n",
       "  -0.032908666878938675,\n",
       "  0.02497967705130577,\n",
       "  -0.013404607772827148,\n",
       "  -0.037297140806913376,\n",
       "  0.029107581824064255,\n",
       "  -0.01580869033932686,\n",
       "  0.019423749297857285,\n",
       "  0.004446674138307571,\n",
       "  -0.026171434670686722,\n",
       "  0.037726882845163345,\n",
       "  -0.008242927491664886,\n",
       "  0.040882665663957596,\n",
       "  -0.1286633163690567,\n",
       "  0.05788257345557213,\n",
       "  -0.1092490553855896,\n",
       "  0.016129128634929657,\n",
       "  -0.06584301590919495,\n",
       "  0.00595482811331749,\n",
       "  -0.13441729545593262,\n",
       "  -0.12413355708122253,\n",
       "  -0.11761260777711868,\n",
       "  -0.11605352908372879,\n",
       "  0.13280244171619415,\n",
       "  0.14738968014717102,\n",
       "  -0.022558696568012238,\n",
       "  -0.1002763956785202,\n",
       "  -0.10919266194105148,\n",
       "  0.021305110305547714,\n",
       "  -0.14727771282196045,\n",
       "  0.01793128252029419,\n",
       "  0.05156726762652397,\n",
       "  0.019141606986522675,\n",
       "  -0.060038745403289795,\n",
       "  0.14110039174556732,\n",
       "  -0.13511157035827637,\n",
       "  0.022318627685308456,\n",
       "  0.12445858120918274,\n",
       "  -0.13565364480018616,\n",
       "  -0.010401137173175812,\n",
       "  0.09950853884220123,\n",
       "  -0.006809167563915253,\n",
       "  0.12009981274604797,\n",
       "  -0.08457842469215393,\n",
       "  -0.03230627626180649,\n",
       "  -0.02471132203936577,\n",
       "  -0.016321733593940735,\n",
       "  -0.029674107208848,\n",
       "  5.442574547487311e-05,\n",
       "  0.022896988317370415,\n",
       "  0.024283993989229202,\n",
       "  0.038061272352933884,\n",
       "  0.013949287123978138,\n",
       "  -0.04070926830172539,\n",
       "  -0.026010017842054367,\n",
       "  -0.03472182899713516,\n",
       "  0.038654159754514694,\n",
       "  -0.04265101999044418,\n",
       "  0.026937078684568405,\n",
       "  -0.011860370635986328,\n",
       "  -0.02011534757912159,\n",
       "  -0.011914682574570179,\n",
       "  0.03677486628293991,\n",
       "  -0.015455460175871849,\n",
       "  -0.04172743856906891,\n",
       "  0.04016702622175217,\n",
       "  0.013071248307824135,\n",
       "  -0.015266644768416882,\n",
       "  0.03818558156490326,\n",
       "  0.02900015376508236,\n",
       "  -0.03405923768877983,\n",
       "  -0.019405430182814598,\n",
       "  0.006340997293591499,\n",
       "  -0.029400138184428215,\n",
       "  0.022627387195825577,\n",
       "  -0.03045676276087761],\n",
       " 'predicted_rewards_mean': [2.781374931335449, 2.7069664001464844],\n",
       " 'action': 0}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_pred_dict = {\n",
    "    \"bandit_policy_type\" : int(prediction.info.bandit_policy_type[0]),\n",
    "    \"chosen_arm_features\" : prediction.info.chosen_arm_features.tolist(),\n",
    "    \"predicted_rewards_mean\" : prediction.info.predicted_rewards_mean.tolist(),\n",
    "    \"action\" : int(prediction.action.tolist()),\n",
    "}\n",
    "\n",
    "processed_pred_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347eb5ee-669b-4942-9428-9fb979fad3ce",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
