{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bbe739b-44f2-444f-989d-b1d289b1817e",
   "metadata": {},
   "source": [
    "# Simulate Online Learning with Contextual Bandits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e150cd8-8e32-4c44-8d6b-0d0050e8a463",
   "metadata": {},
   "source": [
    "For \"online learning\" to take place, the agent's policy needs to be updated, where \"updated\" is conceptually similar to retraining a traditional supervised learning model (with latest training examples) and deploying the newly trained model\n",
    "* the bandit agent's policy is updated (i.e., learns) when it receives (e.g., `agent.train(...)`) a trajectory that includes the prediction/action AND the delayed feedback\n",
    "* once `agent.train(...)` takes place, the policy is updated (e.g., weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39d04854-4b70-4529-9609-9de643461979",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/05-online-learning\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0431346f-3097-4ca3-890e-9927d7b2d4f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "# PREFIX = 'mabv1'\n",
    "VERSION        = \"v2\"                       # TODO\n",
    "PREFIX         = f'rec-bandits-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d76b584-5d0d-4b04-80b9-c97916ba4686",
   "metadata": {},
   "source": [
    "## Load notebook config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdc0e11b-d3fd-4140-86a7-459585be71c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"rec-bandits-v2\"\n",
      "VERSION                  = \"v2\"\n",
      "\n",
      "BUCKET_NAME              = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_NAME    = \"mvlens_rec_bandits_v2\"\n",
      "BIGQUERY_TABLE_NAME      = \"training_dataset\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-rec-bandits-v2\"\n",
      "\n",
      "DOCKERNAME_01            = \"Dockerfile_train_my_perarm_env\"\n",
      "IMAGE_NAME_01            = \"train-my-perarm-env-v2\"\n",
      "IMAGE_URI_01             = \"gcr.io/hybrid-vertex/train-my-perarm-env-v2\"\n",
      "\n",
      "DOCKERNAME_02            = \"Dockerfile_perarm_feats\"\n",
      "IMAGE_NAME_02            = \"train-perarm-feats-v2\"\n",
      "IMAGE_URI_02             = \"gcr.io/hybrid-vertex/train-perarm-feats-v2\"\n",
      "\n",
      "DOCKERNAME_03            = \"Dockerfile_ranking_bandit\"\n",
      "IMAGE_NAME_03            = \"train-rank-bandit-v2\"\n",
      "IMAGE_URI_03             = \"gcr.io/hybrid-vertex/train-rank-bandit-v2\"\n",
      "\n",
      "DOCKERNAME_04            = \"Dockerfile_train_bandit_e2e\"\n",
      "IMAGE_NAME_04            = \"train-mab-e2e-v2\"\n",
      "IMAGE_URI_04             = \"gcr.io/hybrid-vertex/train-mab-e2e-v2\"\n",
      "\n",
      "DOCKERNAME_04_pred       = \"Dockerfile_pred_bandit_e2e\"\n",
      "IMAGE_NAME_04_pred       = \"pred-mab-e2e-v2\"\n",
      "IMAGE_URI_04_pred        = \"gcr.io/hybrid-vertex/pred-mab-e2e-v2\"\n",
      "\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/local_docker_tfa\"\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bd0378-3650-4cc5-bc05-4f407f200c9c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fab51a15-b189-4159-919c-04f2d81ce741",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25dcc25d-030e-4d39-920b-2187e70fcdf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "from collections import defaultdict\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pickle as pkl\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# google cloud\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.metrics import tf_metrics\n",
    "\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent\n",
    "from tf_agents.bandits.agents import neural_linucb_agent\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.bandits.policies import policy_utilities\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.policies import policy_saver\n",
    "\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.train.utils import spec_utils\n",
    "from tf_agents.train.utils import strategy_utils\n",
    "from tf_agents.train.utils import train_utils as tfa_train_utils\n",
    "from tf_agents.utils import common\n",
    "\n",
    "from tf_agents.metrics import export_utils\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.eval import metric_utils\n",
    "\n",
    "# GPU\n",
    "from numba import cuda \n",
    "import gc\n",
    "\n",
    "# tf exceptions and vars\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df137505-958f-48f3-9159-2e0b01df6146",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_agents version: 0.17.0\n",
      "tensorflow version: 2.13.0\n"
     ]
    }
   ],
   "source": [
    "import tf_agents\n",
    "\n",
    "print(f\"tf_agents version: {tf_agents.__version__}\")\n",
    "print(f\"tensorflow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f664a98-df2e-4190-8c67-e8f4b970f639",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# this repo\n",
    "from src.data import data_utils as data_utils\n",
    "from src.data import data_config as data_config\n",
    "from src.utils import train_utils, reward_factory\n",
    "\n",
    "from src.agents import agent_factory as agent_factory\n",
    "from src.trainer import eval_perarm as eval_perarm, train_perarm\n",
    "from src.networks import encoding_network as emb_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15ccc299-9963-4014-a19f-394a8697d966",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aae8bb01-8147-4586-913e-e02fbbbd4be3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78c953a0-be4d-4859-8bd6-50773502e800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc337cb0-aef5-4709-b341-6b6d186cffbf",
   "metadata": {},
   "source": [
    "### Generate Vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bd57537-79f2-449d-a7eb-97b2325a2569",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE_VOCABS: False\n"
     ]
    }
   ],
   "source": [
    "GENERATE_VOCABS = False\n",
    "\n",
    "print(f\"GENERATE_VOCABS: {GENERATE_VOCABS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "177c2b16-71ab-4d11-9259-b19c3b978550",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab...\n",
      "Downloaded vocab from: gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/vocabs/vocab_dict.pkl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not GENERATE_VOCABS:\n",
    "\n",
    "    EXISTING_VOCAB_FILE = f'gs://{BUCKET_NAME}/{EXAMPLE_GEN_GCS_PATH}/vocabs/{VOCAB_FILENAME}'\n",
    "    print(f\"Downloading vocab...\")\n",
    "\n",
    "    os.system(f'gsutil -q cp {EXISTING_VOCAB_FILE} .')\n",
    "    print(f\"Downloaded vocab from: {EXISTING_VOCAB_FILE}\\n\")\n",
    "\n",
    "    filehandler = open(VOCAB_FILENAME, 'rb')\n",
    "    vocab_dict = pkl.load(filehandler)\n",
    "    filehandler.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9f4837-9c6b-4b11-b950-ed4fa0fa2804",
   "metadata": {},
   "source": [
    "## Data config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d224ac4-8312-41ee-9616-a27538d8d1b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCS_DATA_PATH: gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/action-embeddings/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/mv_b128_g12_a16/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/mv_b128_g12_a16_v4/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/mv_b128_g12_a16_v5/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/mv_b128_g12_a16_v6/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/mv_b128_g12_a16_v7/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/train/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/val/\n",
      "gs://rec-bandits-v2-hybrid-vertex-bucket/data/movielens/m1m/vocabs/\n"
     ]
    }
   ],
   "source": [
    "EXAMPLE_GEN_GCS_PATH = data_config.EXAMPLE_GEN_GCS_PATH\n",
    "GCS_DATA_PATH = f\"{BUCKET_URI}/{EXAMPLE_GEN_GCS_PATH}\"\n",
    "\n",
    "print(f\"GCS_DATA_PATH: {GCS_DATA_PATH}\")\n",
    "\n",
    "!gsutil ls $GCS_DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1cf10444-f95a-4fbb-b8db-e12a38903639",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target_movie_genres': <tf.Tensor: shape=(1, 10), dtype=string, numpy=\n",
      "array([[b'Drama', b'UNK', b'UNK', b'UNK', b'UNK', b'UNK', b'UNK', b'UNK',\n",
      "        b'UNK', b'UNK']], dtype=object)>,\n",
      " 'target_movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'1775'], dtype=object)>,\n",
      " 'target_movie_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>,\n",
      " 'target_movie_title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Live Flesh (1997)'], dtype=object)>,\n",
      " 'target_movie_year': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1997])>,\n",
      " 'target_rating_timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([974612615])>,\n",
      " 'user_age': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([50])>,\n",
      " 'user_gender': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'M'], dtype=object)>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'2173'], dtype=object)>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'programmer'], dtype=object)>,\n",
      " 'user_zip_code': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'87505'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "SPLIT = \"train\" # \"train\" | \"val\"\n",
    "\n",
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{EXAMPLE_GEN_GCS_PATH}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "train_dataset = train_dataset.map(data_utils._parse_function)\n",
    "\n",
    "for x in train_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "615baf44-0b1e-4f79-aac2-f318d6709c5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SPLIT = \"val\"\n",
    "\n",
    "val_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{EXAMPLE_GEN_GCS_PATH}/{SPLIT}'):\n",
    "    if '.tfrecord' in blob.name:\n",
    "        val_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "val_dataset = tf.data.TFRecordDataset(val_files)\n",
    "val_dataset = val_dataset.map(data_utils._parse_function, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89788e85-79a0-44a1-b48d-7259e99d241f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target_movie_genres': <tf.Tensor: shape=(1, 10), dtype=string, numpy=\n",
       " array([[b'Drama', b'UNK', b'UNK', b'UNK', b'UNK', b'UNK', b'UNK', b'UNK',\n",
       "         b'UNK', b'UNK']], dtype=object)>,\n",
       " 'target_movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'1775'], dtype=object)>,\n",
       " 'target_movie_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>,\n",
       " 'target_movie_title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Live Flesh (1997)'], dtype=object)>,\n",
       " 'target_movie_year': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1997])>,\n",
       " 'target_rating_timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([974612615])>,\n",
       " 'user_age': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([50])>,\n",
       " 'user_gender': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'M'], dtype=object)>,\n",
       " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'2173'], dtype=object)>,\n",
       " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'programmer'], dtype=object)>,\n",
       " 'user_zip_code': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'87505'], dtype=object)>}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    \n",
    "    iterator = iter(train_dataset.batch(1))\n",
    "    data = next(iterator)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a332a971-b73b-4814-a9d6-c03a72426608",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_OOV_BUCKETS        = 1\n",
    "GLOBAL_EMBEDDING_SIZE  = 16\n",
    "MV_EMBEDDING_SIZE      = 32 #32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "645ccdc6-6ea9-4873-9e4c-12084fbe5c22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.networks.encoding_network.EmbeddingModel at 0x7f86e7dddb10>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs = emb_features.EmbeddingModel(\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    "    max_genre_length = data_config.MAX_GENRE_LENGTH,\n",
    ")\n",
    "\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6782d836-f6bf-43a5-880c-56489bf229e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL_DIM: 96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 96), dtype=float32, numpy=\n",
       "array([[-0.04248917, -0.00244291, -0.00468583,  0.00488365, -0.01843913,\n",
       "        -0.04119545, -0.03639992, -0.0453807 ,  0.02518505, -0.02787866,\n",
       "        -0.03912802, -0.03023648,  0.01043503, -0.04058257, -0.01104143,\n",
       "         0.01585637,  0.04362693,  0.04520465, -0.04814446,  0.03550676,\n",
       "         0.03441838, -0.04004429,  0.01600799, -0.03513419, -0.02309402,\n",
       "        -0.04117162,  0.04714474,  0.01591766, -0.03542628,  0.04018589,\n",
       "        -0.02039327,  0.01969014, -0.00068216,  0.00423536,  0.04134227,\n",
       "        -0.01702636,  0.02291906, -0.02697235, -0.02332007, -0.04730145,\n",
       "        -0.01630211, -0.02262505, -0.00046211, -0.0405523 , -0.03976578,\n",
       "         0.01553256, -0.04659147, -0.00756719,  0.0238643 ,  0.02740547,\n",
       "        -0.01678984, -0.02433689, -0.03717647, -0.03033655, -0.00725366,\n",
       "        -0.02659317, -0.00387419,  0.01490171, -0.01480445,  0.03176199,\n",
       "        -0.03249303,  0.03111586, -0.02061023,  0.00570988, -0.01139556,\n",
       "         0.0465506 ,  0.01646003,  0.04772569, -0.00675315,  0.04237583,\n",
       "         0.02697125, -0.01615611,  0.03549608, -0.02477245,  0.00841   ,\n",
       "         0.04569521,  0.04158039,  0.00083616,  0.0198135 ,  0.0226616 ,\n",
       "         0.02047898, -0.02308753,  0.04113329, -0.01896607, -0.0488502 ,\n",
       "         0.01879153, -0.02085043, -0.00209535,  0.01966581, -0.04716757,\n",
       "        -0.04142942, -0.04277792,  0.04557246, -0.04771211,  0.00472033,\n",
       "        -0.01396507]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_globals = embs._get_global_context_features(data)\n",
    "\n",
    "GLOBAL_DIM = test_globals.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"GLOBAL_DIM: {GLOBAL_DIM}\")\n",
    "\n",
    "test_globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5dfd0e8-6729-4235-a719-5258799ed0d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER_ARM_DIM: 128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 128), dtype=float32, numpy=\n",
       "array([[-1.91109069e-02,  2.79033668e-02, -4.11643162e-02,\n",
       "        -8.38395208e-03, -6.10239804e-05, -1.80522203e-02,\n",
       "        -3.80287655e-02, -3.60810757e-03,  3.80150229e-03,\n",
       "         3.12509388e-03,  2.33409144e-02,  4.58323248e-02,\n",
       "        -1.35038011e-02,  4.75832559e-02,  2.43731588e-03,\n",
       "         4.96984236e-02,  3.97842415e-02,  2.22083218e-02,\n",
       "         1.43576004e-02, -3.80734578e-02,  4.80973013e-02,\n",
       "        -5.72137907e-03, -8.76675919e-03, -1.56960264e-02,\n",
       "        -1.70983188e-02,  6.20190054e-03,  3.47256698e-02,\n",
       "        -3.81654277e-02, -2.61028856e-03,  2.53044032e-02,\n",
       "        -9.02209431e-03,  4.27762531e-02,  2.47772448e-02,\n",
       "        -2.13482380e-02,  2.02559493e-02,  3.66101302e-02,\n",
       "         5.82654402e-03,  7.25182146e-03,  8.15529749e-03,\n",
       "        -1.28622651e-02, -1.79622769e-02,  4.94290516e-03,\n",
       "        -1.85484998e-02, -1.07875355e-02, -2.66215950e-03,\n",
       "        -3.41920741e-02, -3.15079242e-02,  2.19079144e-02,\n",
       "         1.18870661e-03, -1.01233646e-03,  3.28499936e-02,\n",
       "        -3.92742530e-02,  2.28418037e-03,  4.05228250e-02,\n",
       "        -4.97940071e-02,  2.32686065e-02,  4.81463186e-02,\n",
       "        -3.97061817e-02,  3.29706110e-02,  4.50443104e-03,\n",
       "         1.61664970e-02, -2.67294291e-02,  1.77524947e-02,\n",
       "         2.40135938e-04, -5.67337312e-02, -1.25769615e-01,\n",
       "        -1.03855014e-01, -2.34582484e-01,  8.45222026e-02,\n",
       "        -6.58169389e-02,  1.72723398e-01,  3.19802202e-02,\n",
       "        -2.26452947e-01, -1.81630254e-01, -6.37222454e-02,\n",
       "         7.88474455e-03, -1.91020608e-01, -1.03280187e-01,\n",
       "        -2.02667892e-01, -1.40399218e-01, -1.15188599e-01,\n",
       "        -1.11685164e-01,  2.37262413e-01, -2.33521998e-01,\n",
       "        -8.29654336e-02, -1.38168335e-01, -2.17218459e-01,\n",
       "         1.30206905e-02,  3.60531732e-02, -3.53370979e-02,\n",
       "        -5.02990559e-02, -1.07266672e-01, -1.92986667e-01,\n",
       "        -2.08199680e-01, -4.79326211e-02,  4.97512519e-04,\n",
       "         1.67556852e-02,  9.72394366e-03,  1.69593152e-02,\n",
       "        -2.88595036e-02, -4.13923822e-02, -1.14254449e-02,\n",
       "        -8.45520478e-03, -6.69585867e-03,  1.17770601e-02,\n",
       "        -2.23977249e-02, -4.42572013e-02,  6.61255466e-03,\n",
       "         1.12398723e-02, -1.78461301e-03,  3.79798710e-02,\n",
       "         1.53246690e-02,  1.62076242e-02,  1.24608288e-02,\n",
       "         2.18824819e-02,  1.27397208e-02,  1.48861101e-02,\n",
       "         3.47378291e-02, -4.40940000e-02,  4.45610620e-02,\n",
       "        -2.07889602e-02,  3.71715166e-02, -1.56308580e-02,\n",
       "         5.98730333e-03,  3.41320373e-02, -1.69210676e-02,\n",
       "         4.64163534e-02,  1.14212297e-02]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arms = embs._get_per_arm_features(data)\n",
    "\n",
    "PER_ARM_DIM = test_arms.shape[1]            \n",
    "# shape checks out at batch_dim, nactions, arm feats\n",
    "print(f\"PER_ARM_DIM: {PER_ARM_DIM}\")\n",
    "\n",
    "test_arms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f9a8ec-829c-4032-aa6b-f845afb7cc89",
   "metadata": {},
   "source": [
    "### TensorSpecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38d560e6-56dc-454d-a409-fd307dcb7ac9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE      = 128\n",
    "EVAL_BATCH_SIZE = 1\n",
    "NUM_ACTIONS     = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5196055a-56e6-413f-b3c4-f8a3f8b18f1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(96,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 128), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_spec = {\n",
    "    'global': tf.TensorSpec([GLOBAL_DIM], tf.float32),\n",
    "    'per_arm': tf.TensorSpec([NUM_ACTIONS, PER_ARM_DIM], tf.float32) #excluding action dim here\n",
    "}\n",
    "observation_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36dcb7a9-c589-44d0-a5e8-3960aca6a243",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec = tensor_spec.BoundedTensorSpec(\n",
    "    shape=[], \n",
    "    dtype=tf.int32,\n",
    "    minimum=tf.constant(0),            \n",
    "    maximum=NUM_ACTIONS-1, # n degrees of freedom and will dictate the expected mean reward spec shape\n",
    "    # name=\"action_spec\"\n",
    ")\n",
    "\n",
    "action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9207d05f-72b2-42f3-bc41-089fc2aaba38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'global': TensorSpec(shape=(96,), dtype=tf.float32, name=None),\n",
       "                 'per_arm': TensorSpec(shape=(2, 128), dtype=tf.float32, name=None)},\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec = ts.time_step_spec(\n",
    "    observation_spec = observation_spec, \n",
    "    # reward_spec = _reward_spec\n",
    ")\n",
    "time_step_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "169f3e07-0c0a-4e18-b620-756f9419ccb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(96,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(2, 128), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step_spec.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5e78dfd-b96d-48d6-8b17-353536485d1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reward': TensorSpec(shape=(128,), dtype=tf.float32, name='reward')}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.specs import array_spec\n",
    "\n",
    "reward_spec = {\n",
    "    \"reward\": array_spec.ArraySpec(shape=[BATCH_SIZE], dtype=np.float32, name=\"reward\")\n",
    "}\n",
    "\n",
    "reward_tensor_spec = train_utils.from_spec(reward_spec)\n",
    "reward_tensor_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9515c0f4-f01b-4ffa-968d-4d6e3ff599ef",
   "metadata": {},
   "source": [
    "### Distribution strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29f198a2-a945-49c2-a58d-6663b1cf0eb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.distribute.mirrored_strategy.MirroredStrategy at 0x7f86e7a4b670>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_gpu = True\n",
    "use_tpu = False\n",
    "\n",
    "distribution_strategy = strategy_utils.get_strategy(tpu=use_tpu, use_gpu=use_gpu)\n",
    "distribution_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f85a3cb-0cbd-43fe-805d-a7c1047b0f55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_REPLICAS = distribution_strategy.num_replicas_in_sync\n",
    "NUM_REPLICAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd87d58a-9273-4fa1-a9c3-bfd97554cf01",
   "metadata": {},
   "source": [
    "## Agent & Policy config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "12d6a9d1-dcc6-4205-9996-c08751d032a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'common_layers': [16, 8],\n",
      " 'encoding_dim': 1,\n",
      " 'epsilon': 0.01,\n",
      " 'eval_batch_size': 1,\n",
      " 'global_layers': [64, 32, 16],\n",
      " 'learning_rate': 0.05,\n",
      " 'model_type': 'epsGreedy',\n",
      " 'network_type': 'commontower',\n",
      " 'num_actions': 2,\n",
      " 'per_arm_layers': [64, 32, 16]}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Agents\n",
    "# ================================\n",
    "AGENT_TYPE      = 'epsGreedy' # 'LinUCB' | 'LinTS |, 'epsGreedy' | 'NeuralLinUCB'\n",
    "\n",
    "# Parameters for linear agents (LinUCB and LinTS).\n",
    "AGENT_ALPHA     = 0.1\n",
    "\n",
    "# Parameters for neural agents (NeuralEpsGreedy and NerualLinUCB).\n",
    "EPSILON         = 0.01\n",
    "LR              = 0.05\n",
    "\n",
    "# Parameters for NeuralLinUCB\n",
    "ENCODING_DIM    = 1\n",
    "EPS_PHASE_STEPS = 1000\n",
    "\n",
    "# ================================\n",
    "# Agent's Preprocess Network\n",
    "# ================================\n",
    "GLOBAL_LAYERS   = [64, 32, 16] # beginning should be of size: GLOBAL_DIM\n",
    "ARM_LAYERS      = [64, 32, 16] # beginning should be of size: PER_ARM_DIM\n",
    "COMMON_LAYERS   = [16, 8]\n",
    "\n",
    "NETWORK_TYPE    = \"commontower\" # 'commontower' | 'dotproduct'\n",
    "\n",
    "if AGENT_TYPE == 'NeuralLinUCB':\n",
    "    NETWORK_TYPE = 'commontower'\n",
    "    ENCODING_DIM = COMMON_LAYERS[-1]\n",
    "\n",
    "\n",
    "HPARAMS = {  # TODO - streamline and consolidate\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"eval_batch_size\" : EVAL_BATCH_SIZE,\n",
    "    \"num_actions\": NUM_ACTIONS,\n",
    "    \"model_type\": AGENT_TYPE,\n",
    "    \"network_type\": NETWORK_TYPE,\n",
    "    \"global_layers\": GLOBAL_LAYERS,\n",
    "    \"per_arm_layers\": ARM_LAYERS,\n",
    "    \"common_layers\": COMMON_LAYERS,\n",
    "    \"learning_rate\": LR,\n",
    "    \"epsilon\": EPSILON,\n",
    "    \"encoding_dim\": ENCODING_DIM\n",
    "}\n",
    "pprint(HPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "99d9d36c-fb72-4859-91a7-c0c52672702a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent: NeuralEpsGreedyAgent\n",
      "Network: commontower\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with distribution_strategy.scope():\n",
    "\n",
    "    global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "    agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "        agent_type = AGENT_TYPE,\n",
    "        network_type = NETWORK_TYPE,\n",
    "        time_step_spec = time_step_spec,\n",
    "        action_spec = action_spec,\n",
    "        observation_spec=observation_spec,\n",
    "        global_layers = GLOBAL_LAYERS,\n",
    "        arm_layers = ARM_LAYERS,\n",
    "        common_layers = COMMON_LAYERS,\n",
    "        agent_alpha = AGENT_ALPHA,\n",
    "        learning_rate = LR,\n",
    "        epsilon = EPSILON,\n",
    "        train_step_counter = global_step,\n",
    "        output_dim = ENCODING_DIM,\n",
    "        eps_phase_steps = EPS_PHASE_STEPS,\n",
    "        summarize_grads_and_vars = True,\n",
    "        debug_summaries = True\n",
    "    )\n",
    "      \n",
    "agent.initialize()\n",
    "print(f'agent: {agent.name}')\n",
    "\n",
    "# if network:\n",
    "#     print(f\"Network: {network}\")\n",
    "\n",
    "if NETWORK_TYPE:\n",
    "    print(f\"Network: {NETWORK_TYPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385ff479-af1d-4437-93c5-1635fed4ee66",
   "metadata": {},
   "source": [
    "### Inspect the specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a755a4e1-84c6-40d9-972c-706188a95c98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50c9e9c3-3965-4aba-8141-c6b114c089e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(96,), dtype=tf.float32, name=None), 'per_arm': TensorSpec(shape=(2, 128), dtype=tf.float32, name=None)}),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.time_step_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b277541-4429-4e11-993b-759b665a9188",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(Trajectory(\n",
       "{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(1, dtype=int32)),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': DictWrapper({'global': TensorSpec(shape=(96,), dtype=tf.float32, name=None)}),\n",
       " 'policy_info': PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=TensorSpec(shape=(2,), dtype=tf.float32, name=None), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=BoundedTensorSpec(shape=(1,), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(4, dtype=int32)), chosen_arm_features=TensorSpec(shape=(128,), dtype=tf.float32, name=None)),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.training_data_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511e3977-eca9-427c-a7cd-2762f36c623d",
   "metadata": {},
   "source": [
    "## Trajectory function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ed9ba099-7fc9-46d7-8558-610adf56b669",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _trajectory_fn(element): # hparams\n",
    "    \n",
    "    \"\"\"Converts a dataset element into a trajectory.\"\"\"\n",
    "    # global_features = _get_global_context_features(element)\n",
    "    # arm_features = _get_per_arm_features(element)\n",
    "    \n",
    "    global_features = embs._get_global_context_features(element)\n",
    "    arm_features = embs._get_per_arm_features(element)\n",
    "    \n",
    "    # Adds a time dimension.\n",
    "    arm_features = train_utils._add_outer_dimension(arm_features)\n",
    "\n",
    "    # obs spec\n",
    "    observation = {\n",
    "        bandit_spec_utils.GLOBAL_FEATURE_KEY:\n",
    "            train_utils._add_outer_dimension(global_features),\n",
    "    }\n",
    "\n",
    "    # reward = train_utils._add_outer_dimension(_get_rewards(element))\n",
    "    reward = train_utils._add_outer_dimension(reward_factory._get_rewards(element))\n",
    "\n",
    "    # To emit the predicted rewards in policy_info, we need to create dummy\n",
    "    # rewards to match the definition in TensorSpec for the ones specified in\n",
    "    # emit_policy_info set.\n",
    "    dummy_rewards = tf.zeros([HPARAMS['batch_size'], 1, HPARAMS['num_actions']])\n",
    "    policy_info = policy_utilities.PerArmPolicyInfo(\n",
    "        chosen_arm_features=arm_features,\n",
    "        # Pass dummy mean rewards here to match the model_spec for emitting\n",
    "        # mean rewards in policy info\n",
    "        predicted_rewards_mean=dummy_rewards,\n",
    "        bandit_policy_type=tf.zeros([HPARAMS['batch_size'], 1, 1], dtype=tf.int32)\n",
    "        # policy_utilities.create_bandit_policy_type_tensor_spec(shape=[1]) # policy_utilities.BanditPolicyType.GREEDY\n",
    "        # tf.zeros([batch_size, 1, 1], dtype=tf.int32)\n",
    "    )\n",
    "    \n",
    "    if HPARAMS['model_type'] == 'neural_ucb':\n",
    "        policy_info = policy_info._replace(\n",
    "            predicted_rewards_optimistic=dummy_rewards\n",
    "        )\n",
    "        \n",
    "    return trajectory.single_step(\n",
    "        observation=observation,\n",
    "        action=tf.zeros_like(\n",
    "            reward, dtype=tf.int32\n",
    "        ),  # Arm features are copied from policy info, put dummy zeros here\n",
    "        policy_info=policy_info,\n",
    "        reward=reward,\n",
    "        discount=tf.zeros_like(reward)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffb7e89-794d-4547-80eb-ea40aefc7a30",
   "metadata": {},
   "source": [
    "# Create train & eval loop for demonstration\n",
    "\n",
    "> TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ebbca5-754b-4ffd-91d9-6c0480a78c06",
   "metadata": {},
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e507e412-31e5-4fa1-9fe6-e6dbe26b4bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agent(\n",
    "    iterations: int,\n",
    "):\n",
    "    # train agent for X iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7136d213-77bb-47b0-b96d-5237b9562e66",
   "metadata": {},
   "source": [
    "# (1) Offline training \n",
    "\n",
    "> TODO: add environment simulation for first iteration?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c456249-8299-4df6-8c25-fa8477c5963c",
   "metadata": {},
   "source": [
    "## Set Vertex Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dfbb5004-396d-4b1c-8557-4e8c95597dec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_VERSION = \"v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5207887c-bf58-421e-9b27-6a41dbf23c0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : 05a-online-v2-rec-bandits-v2\n",
      "RUN_NAME          : run-20241127-190406\n",
      "\n",
      "BASE_OUTPUT_DIR   : gs://rec-bandits-v2-hybrid-vertex-bucket/05a-online-v2-rec-bandits-v2/run-20241127-190406\n",
      "LOG_DIR           : gs://rec-bandits-v2-hybrid-vertex-bucket/05a-online-v2-rec-bandits-v2/run-20241127-190406/logs\n",
      "ROOT_DIR          : gs://rec-bandits-v2-hybrid-vertex-bucket/05a-online-v2-rec-bandits-v2/run-20241127-190406/root\n",
      "ARTIFACTS_DIR     : gs://rec-bandits-v2-hybrid-vertex-bucket/05a-online-v2-rec-bandits-v2/run-20241127-190406/artifacts\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME   = f'05a-online-{EXPERIMENT_VERSION}-{PREFIX}'\n",
    "\n",
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "BASE_OUTPUT_DIR   = f'{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "ROOT_DIR          = f\"{BASE_OUTPUT_DIR}/root\"       # Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"  # Where the trained model will be saved and restored.\n",
    "\n",
    "# aiplatform.init(\n",
    "#     project=PROJECT_ID,\n",
    "#     location=REGION,\n",
    "#     experiment=EXPERIMENT_NAME\n",
    "# )\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"ROOT_DIR          : {ROOT_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0e89ef-bd3f-4fb8-bbe5-8a1a3f5c0275",
   "metadata": {},
   "source": [
    "### Create TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "513f5eb4-3b16-47cc-b2ad-6ba7fcb4a320",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TB_RESOURCE_NAME : projects/934903580331/locations/us-central1/tensorboards/2171100058253000704\n",
      "TB display name  : 05a-online-v2-rec-bandits-v2-run-20241127-190406\n",
      "TB_ID            : 2171100058253000704\n"
     ]
    }
   ],
   "source": [
    "# # create new TB instance\n",
    "TENSORBOARD_DISPLAY_NAME=f\"{EXPERIMENT_NAME}-{RUN_NAME}\"\n",
    "\n",
    "tensorboard = aiplatform.Tensorboard.create(\n",
    "    display_name=TENSORBOARD_DISPLAY_NAME\n",
    "    , project=PROJECT_ID\n",
    "    , location=REGION\n",
    ")\n",
    "\n",
    "TB_RESOURCE_NAME = tensorboard.resource_name\n",
    "\n",
    "TB_ID = TB_RESOURCE_NAME.split('/')[-1]\n",
    "\n",
    "print(f\"TB_RESOURCE_NAME : {TB_RESOURCE_NAME}\")\n",
    "print(f\"TB display name  : {tensorboard.display_name}\")\n",
    "print(f\"TB_ID            : {TB_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "286ceb96-cdf6-4a99-8092-e4988829a489",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-1109e69f-9a6e-4a41-98ee-950dbe114373\" href=\"#view-view-vertex-resource-1109e69f-9a6e-4a41-98ee-950dbe114373\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-1109e69f-9a6e-4a41-98ee-950dbe114373');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/05a-online-v2-rec-bandits-v2/runs?project=hybrid-vertex');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/05a-online-v2-rec-bandits-v2/runs?project=hybrid-vertex', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME,\n",
    "    # experiment_tensorboard=TB_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5505865a-006a-4159-9a47-65ad3e09dd5b",
   "metadata": {},
   "source": [
    "### Saver & Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f6d27959-3d5a-43a2-a9ec-38301535107e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "04b07870-2c24-4c8a-bb6d-79980323174d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TMP_DIR = f\"tmp_dir_{EXPERIMENT_VERSION}\"\n",
    "\n",
    "# !rm -rf {TMP_DIR}\n",
    "# !mkdir -p {TMP_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6a5fdc1d-3404-43aa-99ea-5d5741d3a0f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMP_DIR     : tmp_dir_v2\n",
      "global_step : MirroredVariable:{\n",
      "  0: <tf.Variable 'global_step:0' shape=() dtype=int64, numpy=0>\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# tempdir = os.getenv(f\"tmp_dir_{EXPERIMENT_VERSION}\", tempfile.gettempdir())\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "print(f\"TMP_DIR     : {TMP_DIR}\")\n",
    "print(f\"global_step : {global_step}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7fd3daf7-b1ba-44a0-851c-3ecbd2dae325",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('metrics: [<tf_agents.metrics.tf_metrics.AverageReturnMetric object at '\n",
      " '0x7f86e7a48b80>]')\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# TB summary writer\n",
    "# ====================================================\n",
    "with distribution_strategy.scope():\n",
    "    train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "        f\"{LOG_DIR}\", flush_millis=10 * 1000\n",
    "    )\n",
    "\n",
    "    train_summary_writer.set_as_default()\n",
    "\n",
    "# ====================================================\n",
    "# metrics\n",
    "# ====================================================\n",
    "step_metric = tf_metrics.EnvironmentSteps()\n",
    "metrics = [\n",
    "    # tf_metrics.NumberOfEpisodes(),\n",
    "    # tf_metrics.AverageEpisodeLengthMetric(batch_size=HPARAMS['batch_size']),\n",
    "    tf_metrics.AverageReturnMetric(batch_size=HPARAMS['batch_size'])\n",
    "]\n",
    "\n",
    "pprint(f\"metrics: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "48ffc4e7-ae79-409b-9c71-8edba8bbc6d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting checkpoint_manager: tmp_dir_v2/checkpoint\n",
      "\n",
      "setting POLICY_DIR: tmp_dir_v2/policy\n",
      "\n",
      "saver: <tf_agents.policies.policy_saver.PolicySaver object at 0x7f86e7a0a860>\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# get checkpoint manager\n",
    "# ====================================================\n",
    "# CHKPOINT_DIR = f\"{ROOT_DIR}/chkpoint\"\n",
    "CHKPOINT_DIR = os.path.join(TMP_DIR, 'checkpoint')\n",
    "print(f\"setting checkpoint_manager: {CHKPOINT_DIR}\\n\")\n",
    "\n",
    "checkpoint_manager = train_utils.restore_and_get_checkpoint_manager(\n",
    "    root_dir=CHKPOINT_DIR, \n",
    "    agent=agent, \n",
    "    metrics=metrics, \n",
    "    step_metric=step_metric\n",
    ")\n",
    "# ====================================================\n",
    "# policy saver\n",
    "# ====================================================\n",
    "POLICY_DIR = os.path.join(TMP_DIR, 'policy')\n",
    "print(f\"setting POLICY_DIR: {POLICY_DIR}\\n\")\n",
    "saver = policy_saver.PolicySaver(\n",
    "    agent.policy, \n",
    "    train_step=global_step\n",
    ")\n",
    "print(f\"saver: {saver}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9957cc5-0e9f-4f68-bcf5-4ffb1dc32f2a",
   "metadata": {},
   "source": [
    "## Train & Eval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cfc930f9-f430-45e5-8b5e-42cd4cf6b6c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_TRAIN_STEPS : 50\n",
      "EVAL_DATA_SIZE : 1000\n",
      "NUM_EVAL_STEPS : 1000\n",
      "CHKPT_INTERVAL: 50\n",
      "LOG_INTERVAL : 10\n"
     ]
    }
   ],
   "source": [
    "# TRAIN_DATA_SIZE = 80000          # len(list(train_dataset))\n",
    "NUM_TRAIN_STEPS = 50            # TRAIN_DATA_SIZE // HPARAMS['batch_size']\n",
    "\n",
    "EVAL_DATA_SIZE  = 1000          # len(list(val_dataset))\n",
    "NUM_EVAL_STEPS  = 1000           # EVAL_DATA_SIZE // HPARAMS['eval_batch_size']\n",
    "\n",
    "CHKPT_INTERVAL  = NUM_TRAIN_STEPS # // 5\n",
    "LOG_INTERVAL    = 10\n",
    "# EVAL_INTERVAL = NUM_TRAIN_STEPS // 2\n",
    "\n",
    "# print(f\"TRAIN_DATA_SIZE : {TRAIN_DATA_SIZE}\")\n",
    "print(f\"NUM_TRAIN_STEPS : {NUM_TRAIN_STEPS}\")\n",
    "print(f\"EVAL_DATA_SIZE : {EVAL_DATA_SIZE}\")\n",
    "print(f\"NUM_EVAL_STEPS : {NUM_EVAL_STEPS}\")\n",
    "print(f\"CHKPT_INTERVAL: {CHKPT_INTERVAL}\")\n",
    "print(f\"LOG_INTERVAL : {LOG_INTERVAL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3dde5dfb-e6cf-4b39-8cc8-64b667885d1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec={'target_movie_genres': TensorSpec(shape=(None, 10), dtype=tf.string, name=None), 'target_movie_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'target_movie_rating': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'target_movie_title': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'target_movie_year': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'target_rating_timestamp': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'user_age': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'user_gender': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_occupation_text': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_zip_code': TensorSpec(shape=(None,), dtype=tf.string, name=None)}>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data\n",
    "train_ds_iterator = iter(train_dataset.batch(HPARAMS['batch_size']).repeat())\n",
    "\n",
    "# eval dataset\n",
    "eval_ds = val_dataset.batch(HPARAMS[\"eval_batch_size\"])\n",
    "\n",
    "if NUM_EVAL_STEPS > 0:\n",
    "    eval_ds = eval_ds.take(NUM_EVAL_STEPS)\n",
    "\n",
    "# eval_ds = eval_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "eval_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b2c67a-5822-48f0-ab6b-51f8fe6e38fa",
   "metadata": {},
   "source": [
    "### evaluate pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "01a87a44-cd04-47c7-8e8a-e4fd34e4c877",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating pre-trained Agent...\n",
      "pre-train val_loss     : 15.014501571655273\n",
      "pre-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Evaluate the agent's policy once before training\n",
    "# ====================================================\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "pre_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "\n",
    "print(f\"evaluating pre-trained Agent...\")\n",
    "start_time = time.time()\n",
    "\n",
    "pre_val_loss, pre_preds, pre_tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = pre_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"pre-train val_loss     : {pre_val_loss}\")\n",
    "print(f\"pre-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677fb309-e72f-44ce-b601-e5a70e6f6c16",
   "metadata": {},
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e33216ae-76eb-4cba-a658-f3649f1b070c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting train loop...\n",
      "View your Tensorboard at https://us-central1.tensorboard.googleusercontent.com/experiment/projects+934903580331+locations+us-central1+tensorboards+257140585364717568+experiments+05a-online-v2-rec-bandits-v2\n",
      "step = 0: train loss = 16.059999465942383\n",
      "step = 10: train loss = 15.630000114440918\n",
      "step = 20: train loss = 12.899999618530273\n",
      "step = 30: train loss = 9.100000381469727\n",
      "step = 40: train loss = 2.5899999141693115\n",
      "train runtime_mins: 4\n"
     ]
    }
   ],
   "source": [
    "list_o_loss = []\n",
    "\n",
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "print(f\"starting train loop...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Continuous monitoring\n",
    "aiplatform.start_upload_tb_log(\n",
    "    # tensorboard_id=TB_RESOURCE_NAME,\n",
    "    tensorboard_experiment_name=EXPERIMENT_NAME,\n",
    "    logdir=LOG_DIR,\n",
    "    experiment_display_name=EXPERIMENT_NAME,\n",
    "    run_name_prefix=RUN_NAME,\n",
    "    # description=description,\n",
    ")\n",
    "\n",
    "# for i in tqdm(range(NUM_TRAIN_STEPS)):\n",
    "for i in range(NUM_TRAIN_STEPS):\n",
    "    \n",
    "    with train_summary_writer.as_default():\n",
    "\n",
    "        data = next(train_ds_iterator)\n",
    "        trajectories = _trajectory_fn(data)\n",
    "\n",
    "        # All tensors in experience must be shaped [batch, time, ...] \n",
    "        step = agent.train_step_counter.numpy()\n",
    "        loss = agent.train(experience=trajectories)\n",
    "        list_o_loss.append(loss.loss.numpy())\n",
    "\n",
    "        train_utils._export_metrics_and_summaries(\n",
    "            step=i, \n",
    "            metrics=metrics\n",
    "        )\n",
    "\n",
    "        # print step loss\n",
    "        if step % LOG_INTERVAL == 0:\n",
    "            print(\n",
    "                'step = {0}: train loss = {1}'.format(\n",
    "                    step, round(loss.loss.numpy(), 2)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if i > 0 and i % CHKPT_INTERVAL == 0:\n",
    "            # saver.save(os.path.join(CHKPOINT_DIR, 'policy_%d' % step_metric.result()))\n",
    "            checkpoint_manager.save(global_step)\n",
    "            print(f\"saved policy to: {CHKPOINT_DIR}\")\n",
    "            \n",
    "aiplatform.end_upload_tb_log()\n",
    "   \n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"train runtime_mins: {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9d164ebc-ca0a-46b6-beca-695836dae067",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tmp_dir_v2/checkpoint/ckpt-50'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_manager.save(global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d2d96210-282b-4f7a-8d27-f265f7c5e45c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MirroredVariable:{\n",
       "  0: <tf.Variable 'global_step:0' shape=() dtype=int64, numpy=50>\n",
       "}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkpoint_manager.initialize_or_restore()\n",
    "global_step = tf.compat.v1.train.get_global_step()\n",
    "global_step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b9a721-d9f4-4ba6-a385-3001d58a9ed5",
   "metadata": {},
   "source": [
    "Alternatively, you can save the policy (model) and restore it. Unlike checkpointer, you cannot continue with the training, but you can still deploy the model. Note that the downloaded file is much smaller than that of the checkpointer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "69ab6d4a-8323-46ba-bf3c-6abd716c7f8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_metric.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "177a6e01-1fe5-4db8-be4c-8ed4510aa068",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tmp_dir_v2/policy/policy_0'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVE_POLICY_DIR = os.path.join(POLICY_DIR, 'policy_%d' % step_metric.result())\n",
    "SAVE_POLICY_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6b2db70c-760b-40f7-8b86-26454846adb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved trained policy to: tmp_dir_v2/policy/policy_0\n"
     ]
    }
   ],
   "source": [
    "saver.save(SAVE_POLICY_DIR)\n",
    "print(f\"saved trained policy to: {SAVE_POLICY_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cc16bdc3-a401-4a36-95e0-d7ccef1680cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAGdCAYAAAD0e7I1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABBwUlEQVR4nO3deXxU9b3/8fcsmcmekIQkBAKERRFRUEAIuBvFrcXKrXprW2tb6YK2aFuv/n5qr9aKta1yURRr69Zf3Vux1SuVIoYqmwRQVGSNJCxZIGRPZpKZ8/tjMpOMJJB95sy8no/HPDI558zJlyOat9/l87UYhmEIAAAgQllD3QAAAICBRNgBAAARjbADAAAiGmEHAABENMIOAACIaIQdAAAQ0Qg7AAAgohF2AABARLOHugHhwOv16uDBg0pKSpLFYgl1cwAAQDcYhqG6ujrl5OTIau26/4awI+ngwYPKzc0NdTMAAEAvlJaWasSIEV2eJ+xISkpKkuR7WMnJySFuDQAA6I7a2lrl5uYGfo93hbAjBYaukpOTCTsAAJjMiaagMEEZAABENMIOAACIaIQdAAAQ0Qg7AAAgohF2AABARCPsAACAiEbYAQAAEY2wAwAAIhphBwAARDTCDgAAiGiEHQAAENEIOwAAIKIRdiKEYRh6bu0X2lxyNNRNAQAgrBB2IsQnB2r1y79/qrte/yTUTQEAIKwQdiJEdZNbklTT1BLilgAAEF4IOxHC3eqVJLnavgIAAB/CToTwhx13qyfELQEAILwQdiKEi54dAAA6RdiJEIGeHY9XhmGEuDUAAIQPwk6EcHl8YccwpFYvYQcAAD/CToRwdxi+YigLAIB2hJ0I0THsuAk7AAAEEHYiBGEHAIDOEXYihNvTvuScsAMAQDvCToQInrNDrR0AAPwIOxGCCcoAAHSOsBMh3B5vp+8BAIh2hJ0I0bE3x9VC2AEAwI+wEyGCVmPRswMAQABhJ0Kw9BwAgM4RdiJEx94cVmMBANCOsBMh6NkBAKBzhJ0IQdgBAKBzhJ0IETyMRdgBAMCPsBMh6NkBAKBzhJ0IwdJzAAA6R9iJEMFFBVmNBQCAH2EnQgTN2aFnBwCAAMJOhOjYm8OcHQAA2hF2IgSrsQAA6BxhJ0KwGgsAgM4RdiJAq8crr9H+PWEHAIB2hJ0I8OWl5uyNBQBAO8JOBPhyTw49OwAAtAtp2FmzZo2+8pWvKCcnRxaLRcuXLw86bxiG7rnnHg0bNkxxcXEqKCjQrl27gq6pqqrS9ddfr+TkZKWmpup73/ue6uvrB/FPEXrHhB2WngMAEBDSsNPQ0KDJkydr6dKlnZ5/6KGHtGTJEi1btkwbNmxQQkKC5syZo+bm5sA1119/vT799FOtXLlSb775ptasWaP58+cP1h8hLHx59ZWrhbADAICfPZQ//LLLLtNll13W6TnDMLR48WLdddddmjt3riTp+eefV1ZWlpYvX67rrrtO27dv14oVK/Thhx9q2rRpkqRHH31Ul19+uX73u98pJydn0P4sofTlnhx6dgAAaBe2c3aKi4tVVlamgoKCwLGUlBTNmDFD69atkyStW7dOqampgaAjSQUFBbJardqwYUOX93a5XKqtrQ16mRlzdgAA6FrYhp2ysjJJUlZWVtDxrKyswLmysjJlZmYGnbfb7UpLSwtc05lFixYpJSUl8MrNze3n1g+uL4cbigoCANAubMPOQLrzzjtVU1MTeJWWloa6SX1yzDAWYQcAgICwDTvZ2dmSpPLy8qDj5eXlgXPZ2dmqqKgIOt/a2qqqqqrANZ1xOp1KTk4OepkZPTsAAHQtbMNOXl6esrOztWrVqsCx2tpabdiwQfn5+ZKk/Px8VVdXq6ioKHDNu+++K6/XqxkzZgx6m0PFH3YSHDZJFBUEAKCjkK7Gqq+v1+7duwPfFxcXa+vWrUpLS9PIkSO1cOFC3X///Ro/frzy8vJ09913KycnR1dddZUk6ZRTTtGll16qm266ScuWLVNLS4tuvvlmXXfddVGzEktq78lJjLWrwe1hGAsAgA5CGnY2bdqkCy64IPD9bbfdJkm64YYb9Oyzz+r2229XQ0OD5s+fr+rqap199tlasWKFYmNjA5/5y1/+optvvlkXXXSRrFar5s2bpyVLlgz6nyWU/HN2kmJjVF7rktvjlWEYslgsIW4ZAAChZzEMwzjxZZGttrZWKSkpqqmpMeX8ndeK9uvnr36kM0amaktJtSRp5/2XyWEP21FKAAD6rLu/v/ltGAH8w1aJzvaOOgoLAgDgQ9iJAO62CclJsR3CDvN2AACQRNiJCP5enFi7TXarb54OK7IAAPAh7EQAfy+Ow24NzNOhZwcAAB/CTgToGHachB0AAIIQdiKAv86Ow9bes0MVZQAAfAg7EcDVyTAWYQcAAB/CTgTwT1D2DWP5toxgGAsAAB/CTgQImqBs8/fssBoLAACJsBMR3J3M2aFnBwAAH8JOBPAHG2fH1VhUUAYAQBJhJyJ0nLMTmKDcQtgBAEAi7ESETuvs0LMDAIAkwk5EaJ+zY2M1FgAAX0LYiQCuzoaxWI0FAIAkwk5E6GzpOT07AAD4EHYigLutF4el5wAAHIuwEwH8k5GdMe0TlNkuAgAAH8JOBOisqCBhBwAAH8JOBOhYVNDB0nMAAIIQdiJAcJ0d39JzigoCAOBD2IkAnVVQpmcHAAAfwo7Jeb2GWjyGpC+vxqLODgAAEmHH9Dr24HTcLoIJygAA+BB2TK6rsEOdHQAAfAg7Jtcx1DhsVFAGAODLCDsm5+pQY8discgZwzAWAAAdEXZMruOyc8m383nH4wAARDvCjskdE3ZYeg4AQBDCjsl13CpCUvtqrBaWngMAIBF2TM/tadvxnJ4dAAA6RdgxOVcXw1hMUAYAwIewY3JdDmMRdgAAkETYMb0uJyi3emUYRsjaBQBAuCDsmFzHTUAlydm29FxSYM8sAACiGWHH5Pw9O/7hK39RQUlysRkoAACEHbP78pwd/9eO5wAAiGaEHZP78jCW1WqR3WoJOgcAQDQj7Jjcl4exOr53tRB2AAAg7Jjcl+vsdHxPzw4AAIQd0/vy0vOO75mzAwAAYcf0AnN2Oiw5d9p97yksCAAAYcf0jtezw9JzAAAIO6bXadixMYwFAIAfYcfkOl2NFUPYAQDAj7Bjcu1zdo7t2WHODgAAhB3TYzUWAADHR9gxOf8kZEdQUUHfaizq7AAAQNgxPVfrscNY7RWUWY0FAABhx+SOO4xFzw4AAOEddjwej+6++27l5eUpLi5OY8eO1a9+9SsZhhG4xjAM3XPPPRo2bJji4uJUUFCgXbt2hbDVg+vLG4FK7T07zNkBACDMw85vfvMbPfHEE3rssce0fft2/eY3v9FDDz2kRx99NHDNQw89pCVLlmjZsmXasGGDEhISNGfOHDU3N4ew5YPn+EUFCTsAANhD3YDjWbt2rebOnasrrrhCkjR69Gi9+OKL2rhxoyRfr87ixYt11113ae7cuZKk559/XllZWVq+fLmuu+66kLV9sATq7HSy9JyeHQAAwrxnZ9asWVq1apV27twpSfroo4/0/vvv67LLLpMkFRcXq6ysTAUFBYHPpKSkaMaMGVq3bl2X93W5XKqtrQ16mVWnw1gx9OwAAOAX1j07d9xxh2prazVhwgTZbDZ5PB79+te/1vXXXy9JKisrkyRlZWUFfS4rKytwrjOLFi3SvffeO3ANH0SdbxfBRqAAAPiFdc/OK6+8or/85S964YUXtHnzZj333HP63e9+p+eee65P973zzjtVU1MTeJWWlvZTiwcfRQUBADi+sO7Z+cUvfqE77rgjMPfmtNNO0759+7Ro0SLdcMMNys7OliSVl5dr2LBhgc+Vl5drypQpXd7X6XTK6XQOaNsHi/s4dXZYeg4AQJj37DQ2NspqDW6izWaT1+v7JZ6Xl6fs7GytWrUqcL62tlYbNmxQfn7+oLY1VFydzNlxUFQQAICAsO7Z+cpXvqJf//rXGjlypE499VRt2bJFDz/8sL773e9KkiwWixYuXKj7779f48ePV15enu6++27l5OToqquuCm3jB4FhGBQVBADgBMI67Dz66KO6++679eMf/1gVFRXKycnRD37wA91zzz2Ba26//XY1NDRo/vz5qq6u1tlnn60VK1YoNjY2hC0fHC2e9uKK/v2wfO+ZswMAgF9Yh52kpCQtXrxYixcv7vIai8Wi++67T/fdd9/gNSxMdOy5cXZSQZnVWAAAhPmcHRxfx56bjhOUWY0FAEA7wo6J+cOM3WqR1WoJHPcPaRF2AAAg7JhaZ5OTO37vamU1FgAAhB0Tc3t8YeaYsMPeWAAABBB2TMzVSUFBqX1vLJaeAwBA2DG1LoexbP6igoQdAAAIOyZ2wjk79OwAAEDYMbMuh7E6rMYyDOOYzwEAEE0IOybm79lxdtGzIzFvBwAAwo6JuTvZBFQKDj+syAIARDvCjomdaIJyx2sAAIhWhB0Tc3cxZ8dqtSjG5quozP5YAIBoR9gxMVcXw1gShQUBAPAj7JhY+zCW7Zhzzpi2FVlMUAYARDnCjol1NYzV8RiFBQEA0Y6wY2JdTVDueMy/fxYAANGKsGNi/iDz5To7HY8xQRkAEO0IOybWnZ4dwg4AINoRdkzsuHN27KzGAgBAIuyYmn+l1fGGsQg7AIBoR9gxMddxh7FsQdcAABCtCDsmdtw5OxQVBABAEmHH1I4Xdpwx/rDD0nMAQHQj7JhYYNfzTiYoO22sxgIAQCLsmFq3igoSdgAAUY6wY2L+IHPc1VjsjQUAiHKEHRNzH2/Xc4oKAgAgibBjau1FBY/d9ZxhLAAAfAg7Jnbc1VjU2QEAQBJhx9SOX1TQP4zF0nMAQHQj7JiY63h7Y1FUEAAASYQdU/MXDDx+UUHCDgAguhF2TOx4G4E6KCoIAIAkwo6pUVQQAIATI+yYVKvHK6/he9/pdhFtq7EoKggAiHaEHZPqGGI6X3rOaiwAACTCjml1HJ5iGAsAgK4RdkzKH2IsFslutRxz3knYAQBAEmHHtDrW2LFYjg077I0FAIAPYcekjrfsXGIYCwAAP8KOSbUvOz92E1Cpw2oswg4AIMoRdkzKH2JO1LPDMBYAINoRdkzKP4zV2UosqcPeWB6vDMMYtHYBABBuCDsm5T7OJqBS+95YEoUFAQDRjbBjUsfbKkIKDkEMZQEAohlhx6RcPQg7TFIGAEQzwo5JBebsdDGMZbVa2uftEHYAAFGMsGNSJxrG6niOYSwAQDQj7JhUT8IOPTsAgGhG2DEpd9tu5scLO+yPBQCACcLOgQMH9M1vflPp6emKi4vTaaedpk2bNgXOG4ahe+65R8OGDVNcXJwKCgq0a9euELZ4cPiHppxdzNmROg5jeQalTQAAhKOwDjtHjx7V7NmzFRMTo7ffflufffaZfv/732vIkCGBax566CEtWbJEy5Yt04YNG5SQkKA5c+aoubk5hC0feN0axmKCMgAAsoe6Acfzm9/8Rrm5uXrmmWcCx/Ly8gLvDcPQ4sWLddddd2nu3LmSpOeff15ZWVlavny5rrvuukFv82A5UQVlqb2woIuiggCAKBbWPTt///vfNW3aNH39619XZmamzjjjDD311FOB88XFxSorK1NBQUHgWEpKimbMmKF169Z1eV+Xy6Xa2tqgl9mcqIJyx3OuFsIOACB6hXXY2bt3r5544gmNHz9e//znP/WjH/1IP/nJT/Tcc89JksrKyiRJWVlZQZ/LysoKnOvMokWLlJKSEnjl5uYO3B9igJyoqGDHc2wXAQCIZmEddrxer84880w98MADOuOMMzR//nzddNNNWrZsWZ/ue+edd6qmpibwKi0t7acWD55uDWPZbb5rmbMDAIhivQo7zz33nN56663A97fffrtSU1M1a9Ys7du3r98aN2zYME2cODHo2CmnnKKSkhJJUnZ2tiSpvLw86Jry8vLAuc44nU4lJycHvcyGOjsAAHRPr8LOAw88oLi4OEnSunXrtHTpUj300EPKyMjQrbfe2m+Nmz17tnbs2BF0bOfOnRo1apQk32Tl7OxsrVq1KnC+trZWGzZsUH5+fr+1Ixx1a84OS88BAOjdaqzS0lKNGzdOkrR8+XLNmzdP8+fP1+zZs3X++ef3W+NuvfVWzZo1Sw888ICuueYabdy4UX/4wx/0hz/8QZJksVi0cOFC3X///Ro/frzy8vJ09913KycnR1dddVW/tSMc+cOOk6KCAAAcV696dhITE3XkyBFJ0jvvvKOLL75YkhQbG6umpqZ+a9z06dP1+uuv68UXX9SkSZP0q1/9SosXL9b1118fuOb222/XLbfcovnz52v69Omqr6/XihUrFBsb22/tCEfdm7ND2AEAoFc9OxdffLG+//3v64wzztDOnTt1+eWXS5I+/fRTjR49uj/bpyuvvFJXXnlll+ctFovuu+8+3Xffff36c8Nde8+OrctrAkvPCTsAgCjWq56dpUuXKj8/X5WVlfrrX/+q9PR0SVJRUZH+8z//s18biM71aIIyS88BAFGsVz07qampeuyxx445fu+99/a5Qegef1Xk401QZuk5AAC97NlZsWKF3n///cD3S5cu1ZQpU/SNb3xDR48e7bfGoWs96dlhNRYAIJr1Kuz84he/CGyxsG3bNv3sZz/T5ZdfruLiYt1222392kB0zt0WYLoXdujZAQBEr14NYxUXFweK/f31r3/VlVdeqQceeECbN28OTFbGwGI1FgAA3dOrnh2Hw6HGxkZJ0r/+9S9dcsklkqS0tDRTbqppRj0rKkjYAQBEr1717Jx99tm67bbbNHv2bG3cuFEvv/yyJF914xEjRvRrA9G57hQV9AchenYAANGsVz07jz32mOx2u1577TU98cQTGj58uCTp7bff1qWXXtqvDUTnujNB2RnDaiwAAHrVszNy5Ei9+eabxxx/5JFH+twgdE935uy0FxVkNRYAIHr1KuxIksfj0fLly7V9+3ZJ0qmnnqqvfvWrstm6ruiL/uH1GmrxGJJOVGeHooIAAPQq7OzevVuXX365Dhw4oJNPPlmStGjRIuXm5uqtt97S2LFj+7WRCNYxvLAaCwCA4+vVnJ2f/OQnGjt2rEpLS7V582Zt3rxZJSUlysvL009+8pP+biO+pOPqKursAABwfL3q2SksLNT69euVlpYWOJaenq4HH3xQs2fP7rfGoXMde2q6s/Scnh0AQDTrVc+O0+lUXV3dMcfr6+vlcDj63Cgcn7vDvlgWi6XL69gbCwCAXoadK6+8UvPnz9eGDRtkGIYMw9D69ev1wx/+UF/96lf7u434ku4sO+94nmEsAEA061XYWbJkicaOHav8/HzFxsYqNjZWs2bN0rhx47R48eJ+biK+rKdhh54dAEA069WcndTUVL3xxhvavXt3YOn5KaeconHjxvVr49C57mwVIQUvPTcM47hDXgAARKpuh50T7Wa+evXqwPuHH3649y3CCbk9J97x/MvnXa1excZQAwkAEH26HXa2bNnSrevoPRh4ru4OY3Xo+XF7CDsAgOjU7bDTsecGodXTYayOnwEAINr0aoIyQiuw43nM8f/xWSyWDvtjEXYAANGJsGNCHevsnAgrsgAA0Y6wY0LdXXousT8WAACEHRMKDGN1I+y0Fxb0DGibAAAIV4QdEwoMY/Ug7NCzAwCIVoQdE+ruaiyJYSwAAAg7JtTdOjsdr2E1FgAgWhF2TKgnE5RZeg4AiHaEHRNqX3p+4orITrst6DMAAEQbwo4J9ahnxz+M1cJqLABAdCLsmFBvwg49OwCAaEXYMSF/zZzu1NlhNRYAINoRdkyoJ0vPWY0FAIh2hB0T6klRQXp2AADRjrBjQj3bG8sW9BkAAKINYceEXL0axmI1FgAgOhF2TKg3RQXp2QEARCvCjgn1as4OS88BAFGKsGNCvSsqSNgBAEQnwo4J+cOOsydzdujZAQBEKcKOCfVsGIvVWACA6EbYMaFAz479xBuBUlQQABDtCDsm1Ku9sVh6DgCIUoQdE+pZUUGWngMAohthx4RcPZizwzAWACDaEXZMxjCMHm0E6qSoIAAgyhF2TKbFYwTed2sYK4aiggCA6EbYMZmOocXZre0ifCu2KCoIAIhWhB2T6Tgc1ZONQOnZAQBEK8KOyfjDjt1qkdVqOeH1rMYCAEQ7U4WdBx98UBaLRQsXLgwca25u1oIFC5Senq7ExETNmzdP5eXloWvkAOvJsvOO17moswMAiFKmCTsffvihnnzySZ1++ulBx2+99Vb94x//0KuvvqrCwkIdPHhQV199dYhaOfDcHl9o6WnYafEY8nqNE1wNAEDkMUXYqa+v1/XXX6+nnnpKQ4YMCRyvqanRn/70Jz388MO68MILNXXqVD3zzDNau3at1q9fH8IWDxxXD5adS8GTmJm3AwCIRqYIOwsWLNAVV1yhgoKCoONFRUVqaWkJOj5hwgSNHDlS69at6/J+LpdLtbW1QS+zcPVyGKvjZwEAiCb2UDfgRF566SVt3rxZH3744THnysrK5HA4lJqaGnQ8KytLZWVlXd5z0aJFuvfee/u7qYOix3N2OvQAMUkZABCNwrpnp7S0VD/96U/1l7/8RbGxsf123zvvvFM1NTWBV2lpab/de6D1pHqyJFksFpafAwCiWliHnaKiIlVUVOjMM8+U3W6X3W5XYWGhlixZIrvdrqysLLndblVXVwd9rry8XNnZ2V3e1+l0Kjk5OehlFv6w052Cgn7+LSNcLazIAgBEn7Aexrrooou0bdu2oGM33nijJkyYoP/6r/9Sbm6uYmJitGrVKs2bN0+StGPHDpWUlCg/Pz8UTR5w7h5sAurnsFslFz07AIDoFNZhJykpSZMmTQo6lpCQoPT09MDx733ve7rtttuUlpam5ORk3XLLLcrPz9fMmTND0eQB19M5OxKFBQEA0S2sw053PPLII7JarZo3b55cLpfmzJmjxx9/PNTNGjA9nbMjdSwsSNgBAEQf04Wd9957L+j72NhYLV26VEuXLg1NgwaZq7fDWKJnBwAQncJ6gjKO1T5B2dbtz/ivJewAAKIRYcdkejNnh/2xAADRjLBjMr0KOzbm7AAAohdhx2QCG4H2YIKyM4Y5OwCA6EXYMZneFBWkZwcAEM0IOybTlzk79OwAAKIRYcdkAhWUezKM5V+NRQVlAEAUIuyYjIueHQAAeoSwYzJ92S6CpecAgGhE2DEZ9sYCAKBnCDsm05s5OwxjAQCiGWHHZCgqCABAzxB2TKY3dXYoKggAiGaEHZPp1Wosf88OS88BAFGIsGMygWEsW/d3PXe01dlxtRB2AADRh7BjMoEJyr1ZjUXPDgAgChF2TKZv20VQZwcAEH0IOyYTmLPTi6XnrMYCAEQjwo7J+HtnKCoIAED3EHZMxj/vpidLzykqCACIZoQdk+nb3liEHQBA9CHsmEirxyuv4Xvfo6KCbUvP6dkBAEQjwo6JdFw63qvVWCw9BwBEIcKOiXTsmenRaix/BeUWlp4DAKIPYcdE/GHHapHsPQg7gb2x6NkBAEQhwo6J9GZfLKm9Z6fFY8jrn/QDAECUIOyYSGCriB706kjB4YjeHQBAtCHsmEj7svPubwIqta/Gklh+DgCIPoQdE/GHnZ4sO5ekGJvlmHsAABAtCDsm0psdzyXJYrF02B+LFVkAgOhC2DERdy82AfVjfywAQLQi7JhIb7aK8HNSWBAAEKUIOybS26XnUsfCgoQdAEB0IeyYSG+XnkuSM8YWdA8AAKIFYcdE/Ns99KVnhzk7AIBoQ9gxkd6uxur4GVZjAQCiDWHHRPplgjI9OwCAKEPYMZFAUcFezNlp79kh7AAAogthx0T60rND2AEARCvCjon0Zc4Ow1gAgGhF2DGRvlRQ9m8eStgBAEQbwo6J9EtRQcIOACDKEHZMxD+M5WzrpekJZwzDWACA6ETYMZE+TVD2FxX0UGcHABBdCDsm0h91dtgbCwAQbQg7JtIfS8/ZGwsAEG0IOyYSmLPTm41AWXoOAIhShB0ToaggAAA9R9gxkX6ZoEzYAQBEGcKOibg8vS8q6IzxLVenZwcAEG3COuwsWrRI06dPV1JSkjIzM3XVVVdpx44dQdc0NzdrwYIFSk9PV2JioubNm6fy8vIQtXhg9UfPjquVpecAgOgS1mGnsLBQCxYs0Pr167Vy5Uq1tLTokksuUUNDQ+CaW2+9Vf/4xz/06quvqrCwUAcPHtTVV18dwlYPHHdbUOnTaix6dgAAUcYe6gYcz4oVK4K+f/bZZ5WZmamioiKde+65qqmp0Z/+9Ce98MILuvDCCyVJzzzzjE455RStX79eM2fODEWzB0y/bATK0nMAQJQJ656dL6upqZEkpaWlSZKKiorU0tKigoKCwDUTJkzQyJEjtW7dui7v43K5VFtbG/Qyg75tBEpRQQBAdDJN2PF6vVq4cKFmz56tSZMmSZLKysrkcDiUmpoadG1WVpbKysq6vNeiRYuUkpISeOXm5g5k0/uNP+w4KSoIAEC3mSbsLFiwQJ988oleeumlPt/rzjvvVE1NTeBVWlraDy0ceH3Z9dy/eShzdgAA0Sas5+z43XzzzXrzzTe1Zs0ajRgxInA8Oztbbrdb1dXVQb075eXlys7O7vJ+TqdTTqdzIJs8IPplbyxWYwEAokxY9+wYhqGbb75Zr7/+ut59913l5eUFnZ86dapiYmK0atWqwLEdO3aopKRE+fn5g93cAeX1Gmr1GpL6NmeHnh0AQLQJ656dBQsW6IUXXtAbb7yhpKSkwDyclJQUxcXFKSUlRd/73vd02223KS0tTcnJybrllluUn58fsSuxpD6uxiLsAACiTFiHnSeeeEKSdP755wcdf+aZZ/Sd73xHkvTII4/IarVq3rx5crlcmjNnjh5//PFBbunA61j5mL2xAADovrAOO4ZhnPCa2NhYLV26VEuXLh2EFoVOxx6ZXg1jtX2m1WvI6zVktVr6rW0AAISzsJ6zg3buDvtiWSw9Dyr+vbE63gsAgGhA2DGJvqzEkoJ7gygsCACIJoQdk+hLQUFJirG19wa5PCw/BwBED8LOAKqoa9b6vUf65V597dmxWCysyAIARCXCzgCpd7Xqxmc+1Lf+tEFvbD3Q5/u5Pb3f8dyPFVkAgGgU1quxzCzGZtHojAR9erBWP31pq8prm3XTOWN6NblY6rBVRC9WYvk57VbVKfJ6dmqaWvTejgr9a3uFDlU36dScZJ0xcoim5KZqVHp8r585ACAyEHYGiNNu06PXnaGspFg9/UGxHvjfz3Wopll3XzGxV8u++zqM5W9Tx3uZ2f6jjfrXZ+X61/YKrd97JFBdWpI27Tuq59btkyQNiY/RlNxUTckdojNGpmpybqpS4mJC1WwAQAgQdgaQ1WrRPV+ZqJzUWN3/1nY988EXqqh16ffXTFZsh6Xg3dEfYSdchrEa3a0qPtzge1U2qPhIgyyyKDU+RkPiY5Qa79CQeIdS42Pajvne761s0DuflWvlZ+Xafqg26J7jMhN18cQsjc9M1CcHarWl9Kg+PVCro40tWr2jUqt3VAZde/5JQ1UwMUvTRg2RvQ+9ZQCA8EfYGQTfP2eMMpNj9bNXtuqtbYdUWe/SU9+appT47vcwdKyz01v+zw5Wz47Xa2jtniP6vKxWxYcbtLfSF3DKapv7fG+rRZo2Kk0XT8xSwcQs5WUkBM5dfabvq6vVo+2H6rS15Ki2llZrS2m19h1p1O6Keu2uqNcf3y9WanyMLjw5UxdPzNI5Jw1VopN/JQAg0vBf9kHy1ck5ykhw6Ad/LtLG4ip9/cm1evbGs5STGtetz/fLMFZMW9gZhKXnZTXN+tmrW/XB7s5Xo6UlOJSXkaAxGQkanZEgq8Wi6ka3jja6dbSxRTWNLYH31Y1utXoNxcXYdO5JGbp4YrYuOHmo0hOPv3O9025rG8JKDRw7Uu/SxuIqrdxernc/r1B1Y4v+tuWA/rblgBw2q/LHpuviiVm6cEKmkuNi1OT2qLnF92pq8ai5xaumFk/geIvHK4/XkMcwfF87vPzVqpNi7RqflaTxmYkamuRkDhEADDLCziCaNS5Dr/wwX995ZqN2ltfr6sfX6rnvnqWTs5NO+Nm+1tmR2nt2Brqo4NvbDumOv21TTVOL4mJsumDCUI3JSNSYoQnKy/C9UuMd3b6fYRiqd7XKabf1KexJUnqiU5edNkyXnTZMrR6vivYd1b+2+4bGvjjSqMKdlSrcWXniG/VSUqxd4zMTNT4zSeMyEzUuK1HjMxOVkxLHFh4AMEAIO4PslGHJ+tuPZ+uGpzdqd0W9/mPZWj317WmaOSb9uJ8LDGP1w5ydgdouot7Vqnv//qleLdovSTp9RIoWXztFY4Ym9um+FotFSbH9P6nYbrNqxph0zRiTrv9z+SnaU1mvlZ9VaOVnZdpSWi3/1myxMVbFxdgUF2NTrMOmWLtNcQ6bYmOsirFZZbdaZLVYZLf5vtqsba+291UNbu2uqNcXRxpU19yqzSXV2lxSHdSWtASHvjljpL49a7QyTtBjNZDcrV4t33JAT39QrOrGFs0ck6Zzxg/V2eMzlJUcG7J2AUBfEHZCYHhqnF77Yb5uen6TPvziqL79p4165Yf5QcMtX+bup6Xn0sBMUN5cclS3vrxV+440ymKRFpw/Tj8tGK8Yk0z+tVgsGpeZpHGZSfrR+WPV5PbIYvE9s/4adnK1elR8uEG7K+q1q7w+MHdo7+F6VTW4teTd3XpyzV59fdoIff/sMRrdYR7SQGtwterFjSX647+Lg+ZULd96UMu3HpQknZSVqLPHDdU54zM0Y0ya4h3B//lodLdqb2WD9lTWa09Fvfa0vW9wt+qWC8frmmm5g/bnAYCOCDshkhrv0J+/N0M3Pb9J/951WH8t2n/csOMK09VYrR6vlq7eoyXv7pLHa2h4apweuXaKzspL67efEQpxjp6tlusOp92mCdnJmpCdHHS8xePVqu3leqJwrz4qrdb/W1+iFzaU6LJJwzT/3DGafJy/F311tMGtZ9d+oefWfaHqxhZJUlayU98/e4xOzUnWB3sO6/1dh/XxgRrtLK/XzvJ6Pf1BsWJsFk0dNUTjM5O0r6pReyrqdaC6qcufc/trH+uLww36+SUnM1wHYNARdkIoNsamb84cpX/vOqy1ew4f99r+WXrev3V2SqsatfDlrSrad1SSNHdKju6bO4k6Nj0UY7Pq0knDNOfUbG0ortKThXu0ekel3tp2SG9tO6SZY9L0g/PG6vyThspisai5xaP9RxtVWtWkkqpGlVY1+r4ebVJZTZPSEhwanZ6gUekJGpUer1Hp8RqdnqDhQ+ICPW2Hapr01JpivbixRE0tvgnro9Pj9cPzxuprZw4P1GSaNS5Dv5jjC0Vr9xzR+7sr9e9dh7X/aJPW763S+r1VQX+WtASHxg5N0LjMRI0d6ntt2lelpav36PH39mhfVaN+//Wel14AgL4g7ITYzDHpslqkPZUNKqtpVnZK5/Mi2pee9/6XRH/ujbV292HN/3OR6l2tSnLa9aurJumqM4b3+b7RzGKxaOaYdM0ck67Py2r1hzV79fetBwOhYsSQOLlbvaqocx33PkcbW7SnsuGY4zarRcNT45SdEqstJUfV4vFNSjo1J1k/Pn+cLp2ULVsXvS5DEhy64vRhuuL0YTIMQ/uONOrfuw/rwNEmjU6P17jMRI0Zmqi0hGMnnl8wIVN5GYm6828f662PD+lQdZOe+va0E66m66jB1ap/flqm1PgYnX9SJr1DAHqEsBNiKXExmjQ8RR/vr9G6vYf1tTNGdHqdfwVV/wxj9W3puddr6K43PlG9q1XTRg3RI9dOUW5afJ/uiWATspP18DVT9PNLTtbT7/t6YPYfbR8mSnTalZsWr9whccpNi9fItHjlpsUpOzlOVQ1u7atq0L4jjfrisO/rvqoGNbd4VdLWCyRJM8ek6cfnj9M54zN6NC/JYvFthdKTOUX/MXWEhqfG6Qd/3qTNJdX62uNr9fR3pmtc5vEnr9c0tejP677Qn94v1tG2Yba8jAR99+w8/ceZIwZkuBFA5CHshIH8sen6eH+N1u4+0mXY6ZeNQPupqODK7eXaW9mg5Fi7nrlx+oCslIJPTmqc7rpyom65cLyKSqqUnuDUyLR4pcbHHDegnK2MoO8Nw1BFnUtfHG5Q6dEmjc9MHNC5QJ3JH5uuv/14tr777IcqqWrU1Y9/oCe/NU35Y49diVjV4NbT7xfrubVfqM7VKknKTYtTTWOLig836O7ln+jhd3bomzNH6Vv5o5SZxEoxAF0j7ISBWWMz9GThXq3dc0SGYXT6S6w/6uwEigr2IewYhqEn3tsjSfpW/iiCziBJiY/RhROyev15i8WirORYZSXHakY/tqunxmUm6vUfz9JNz/t6eL799AYtuvp0/cdUX8ivqG3WU//eq/+3vn0u0fjMRN184ThdcdowuVq9emVTqZ7+oFilVU169N3derJwr646I0ffP2eMTso6cc0qANGHsBMGpo8eohibRQeqfRNOR6UfOzzQL0vPbX2vs7OhuEpbS6vltFv1nVl5vb4Pold6olMv3DRTP3/1I7358SH9/NWPtKuiTk1uj176sDTwd33S8GTdfME4XTIxOzBHx26z6sbZefp2/mj989MyPfXvvdpSUq1XNu3XK5v267yThqrglEw1uj2qbW5RXXOrapvavnb4XpJOyk7SxGHJmpiTrInDkjU6PeG4c4HcrV7tLK/TZwdr9enBGn1ysFZ7Kus1dmiiLjh5qM4/OVMThyUznwgIQ4SdMBDvsOuM3CHa+EWV1u450nnY6ceign2poOzv1blmWq6GJoWu+B3MLTbGpiXXnaFR6fFaunqPnizcGzg3ddQQ3XzhuMDqs87YrBZdftowXX7aMBXtq9JTa4r1z8/KelQB+2BNs97rsEFsvMOmU4YlBwJQ7pB47T1cr08O1OjTg7XaWV4XmNTdUdG+oyrad1S/e2enhiY5df5JvuBz9vgMViYCYYKwEybyx6YHws5/njXymPP9sjeWf+l5L3t2Pj1Yo8KdlbJapJvOGdPrdgCSZLVa9Is5EzQqLUH3vfmZJuem6OYLxmvmmLQeTZieOipNU7+Vpn1HGvT8un3ad6RRyXF2JcfGKDnWrqTYmMD3/vfuVq+2l/l6aT47VKvPD9Wq0e0JBJeuJMfadWpOik7NSdapw5M1dmiiPjlQq9U7KvTB7sOqrHPp1aL9erVov2xWi6aOHKLzTh6q00ekKCPRqaFJTqXFO+j9AQYZYSdMzBqbrv9ZtUvr9hzudN6Oqz/2xurj0nP//31feXqORqaz+gr945rpufr6tBF9rlQ9Kj1Bd185sdvXTxvdXviy1ePVF0ca9OnB2kAAKq1qVF5Ggk7NSdGk4ck6NSdFI4bEHdPO00ek6hszRsrV6tGmL47qvR0VWr2jUrsr6rXxiypt/CK4FpHNalFagkND28KPPwSNTo/X2eMzNGII/24B/Y2wEyamjExVbIxVh+vd2llef8zmoP1TVLD3S89LjjTqzY992wb84Dx6ddC/Qr0TvN1mDWwXMndK7+pFOe02zR6XodnjMvR/r/AV3XxvZ6XW7KxUaVWjKutcqmp0y+M1VFnnUmWdSzp07H3GDE3QueOH6ryThna6LQeAnuPfojDhtNs0fXRaoJryMWHHE9q9sZ769155Dem8k4bq1JyUXrcBiBa5afH61sxR+tbMUYFjrR6vqhrcqqx3BQLP4Xq3KuqatW1/jbaUVmtvZYP2Vjbo2bVfyGGzatroITr3pKE6d/xQnTIsKeTBEDAjwk4YmTU2oy3sHNGNs4NXOvVnz05Ph7Eq61x6ZVOpJOlH54/t9c8Hop3dZlVmcqwyu9hBvqapRev2HNaaXYe1Zmel9h9t0to9R7R2zxE9+PbnSnTalRRrV1yMTbExNsU5bEHvY+1WJcXG6Ozx6Zo9LiMwTw+IdoSdMDKrrbja+r1H5PEaQaX7+yXs2HrXs/Ps2mK5Wr2akpuqGSbf4BMIZylxMbp00jBdOsm3LUfx4Qat2VmpNbsOa92eI6p3taq+rcji8Tz9QbGSnHYVTMzS5acN0znjM9iPDFGNsBNGJg1PUVKsXXXNrfrkQE1QhVv/MFbfigr2fCPQuuYW/XndPkm+Xh260IHBYbFYNGaob8+x78zOk6vVo9KqRjW5vWpq8fhebo+aO7xvavHoYHWTVn5Wroo6l17fckCvbzmgBIdNF52SpctPy9b5J2cSfBB1CDthxGb1bQS58rNyrd1zJDjstPZ9I1BHL4oKvrixRLXNrRo7NEEXn9L7Cr4A+sZpt2lcZvcqRP9q7iQVlRzV/247pLe3lamstll//+ig/v7RQcU7bLpgQqamjxqik7KTdFJWkjJ6sCkrYEaEnTAza6w/7BwOmh8TitVYrlaP/vR+sSTpB+eNpTYIYBJWq0XTR6dp+ug03X3FRG3dX623tx3S/24r04HqJr318SG99XH7UrD0BIfGZyXqpKykDq9EpcYfu4s9YEaEnTAza6xvA8cPv6iSu9V7zKTivhUV7NkE5eVbDqi81qXs5Fhd1cvluABCy2q16MyRQ3TmyCH6P5efoo/31+hf28u1/VCddpbXqfRoo440uHVkb5XW7w2uCZSW4FDukDiNSItX7pB45abFtX2N1/DUuD799wgYTISdMHNSVqLSExw60uDW1tJqndU2IdjVD9tF9CTseLyGnlzjKyL4/XPy+I8aEAEsFosm56YGDZE3ulu1p6JBO8rrtKu8ru1rvQ5UN6mqwa2qBrc+2l/Tyb2kYcmxGpEWr1Fp8RqZFq+R6b4gNCotXmkJDub4IWwQdsKMxWJR/th0vfnxIX2w+7DOykuTYRj9shGoowd1dlZ+Vqa9lQ1KiYvRdZ1sXwEgMsQ77DptRIpOGxFcP6uuuUUlVY0qrWrS/qONKq1qVOnRpravjWpu8epgTbMO1jRrY3HVMfdNcNiU2xaCJmQn6duzRjM3CCFD2AlDs8dl6M2PD2ndniO69WIFbT7YL3tjnSDsGIYR2PDz2/mjlOjkrwkQbZJiY9r2ATu2iKhhGDpc71ZJVaP2H21UyZFGlVQ1al+VLxSV1Tarwe3R52V1+rysTu98Vq6nP/hCCy4Ypxtnj2Y1GAYdv8XCkL/ezpbSo2p0t8rbYaPl/tgbq9Vr6POyWtmtVtmsFtksFlmtkt1qldUqbdtfo4/21yg2xqrvzBrdlz8KgAhksVg0NMm3p9fUUUOOOd/c4tGB6iaVVPmC0GtF+7XtQI1+s+JzvbBxn+649BRdflo2w1wYNISdMDSybfLfgeombfriqCYNb/8/q/7YLkKSLl387xNef820XKXT7Qygh2JjbBo7NFFjhyZKkr41c5Re33JAD/3zc5VWNWnBC5s1bdQQ3X3lxKD5Q8BAYdZpGPLP25GkD/YcDgw72a2WPi3/TnDaNe/MEcpIdCotwaGUuBglOe2Kd9jktFsVY7PI/z9aWclO/eA8toYA0HdWq0Xzpo7Q6p+fr4UF4xUXY9OmfUc1d+kHuvXlrTpU0xTqJiLC0bMTpmaPS9drRfu1bs8RfaNtgnB/rIj6/TWTT3iNYfjGzehiBtCf4h12LSw4SddNH6mH/vm5/rbZV+H57U8Oaf65YzX/3DHMEcSAoGcnTOWP8dXb+eRAjQ7XuyT1T9jpDovFQtABMGCyU2L18DVT9PebZ2v66CFqbvFqyapdOveh1XpqzV41ubtX+BToLsJOmMpOidWYoQnyGtKanYcl9W2+DgCEm9NHpOqVH+Tr8evP1Oj0eFU1uPXr/92uc3+7Ws9+UNztau/AifDbM4z5V2W9t7NS0uD17ADAYLFYLLr8tGH6123n6aH/OF3DU+NUWefSf//jM13w2/f04sYStfRgPz+gM/z2DGOz27aO+Hh/tSTCDoDIZbdZdc20XK3++fm6/6pJyk6O1cGaZt35t2266PeF+mvRfnk61uEAeoDfnmFs5hhfz07bfGGGsQBEPIfdqm/OHKX3fnG+7rlyojISHSqpatTPXv1IFz9SqNWfV4S6iTAhfnuGsSEJDk0clhz43knVUQBRIjbGpu+enac1t1+gOy6boNT4GO2tbNCNz36o21/7SHXNLaFuIkyEsBPm/PN2JMlJzw6AKBPvsOuH543Vv2+/QN8/O08Wi/TKpv26dPG/tXb34QH92f4yHDA/fnuGudnjMgLvmbMDIFolxcborisn6uX5+RqZFq8D1U36xh836L///mm/LlXff7RRS1fv1iWPFOrku1boP/+wXssK92j7oVrCj4lZDP7pqba2VikpKaqpqVFycvKJPzCI6l2tmnzvO/J4DV04IVNPf2d6qJsEACHV4GrVA/+7XX/ZUCJJystI0O++PrnTfbq642iDW29uO6Q3thzQpn1Hu7wuM8mp804aqvNOHqqzx2UoNd7Rq5/3ZTWNLfr0UI1kSJnJscpOiaW4Yjd19/c3YUfhHXYk6erHP9Dmkmpdemq2ln1raqibAwBhoXBnpf7rtY9VVtssq0X6wXljtbBgvJz2E89vbHJ7tHJ7ud7YckCFOyvV6vVXjpdm5qXrqjNyNDk3VRv2VqlwZ6XW7jms5pb2JfBWizQlN1XnjB+qMUMTlN0WUrKSY4+7q3tdc4s+OVCrbQeq9fH+Gn1yoEZfHGk85roEh01ZKbHKSvLdNzPZqezkWGUmxWpoklMZiQ4NTXIq0WmP6iKwhJ0eCPew87t/7tBjq3fr6jOH6+FrpoS6OQAQNmqaWnTv3z/V37YckCSdnJWkb84cKVerV41ujxrdHjW5W9Xg9qjJ7VFj2/tPD9SoocPw16k5ybpqynB9ZXKOslNij/k5zS0effhFlQp3VKpwZ6V2VdR32aa0BIeykmM1LMUXVDISHNpX1aht+2u093BDp5/JTYuT025TeW2z6ppbu/3nj42xKiPR2RaA2r4mOJQUG6PEWLuSYu1Kio3xfXW2v4932PockgzDUIvH6PO+jX1B2OmBcA87h+td+v07O3T9jFFBO6ADAHxWfFKm//v6Nh1pcHf7M7lpcZo7ebiuOiNH4zKTevTzDlQ3ac3OSn1YXKWDNU0qr3XpUE1TUO9PV4anxum04Sk6bUSKTh+Rokk5KRqS0D4k1uhuVXmtS2U1zSqv9b3K2r5W1Lp0uN6lyjpXUFjrKYvFV87EYbfKYbMqxmZVjN2iGJs1cNxutcjjNeRq9crd6pWr7eVu9fi+eryB0ijxDpviHXYlOm1KcNqV4LQrMfDVpgSHXfPPHaPM5GODZF9EXdhZunSpfvvb36qsrEyTJ0/Wo48+qrPOOqtbnw33sAMAOLEj9S79z6pdOlTT3PbL16a4GLsSnDbFOWyKj7Ep3unr1RgxJF6TR6T06xCQYRiqaWrRoRpfOCmradahmmZV1rmUkxKr00ak6LThKUpPdPbLz2t0t+pwnVuVbeHHH4KqGtyqa25RvatVtc2tqmtuDXxf19wasuKM7/7sPI0Zmtiv94yqsPPyyy/r29/+tpYtW6YZM2Zo8eLFevXVV7Vjxw5lZmae8POEHQBANDAMQ00tHtU3t8rt8arFY8jd6lWLx9dT43/f4vHK3eobonLG+Hp7nDG2tq/WwFenzaYWr1cNrlbVu1rV4PIE3je6W1Xf9n2Dq1U/vmCcUuJi+vXPE1VhZ8aMGZo+fboee+wxSZLX61Vubq5uueUW3XHHHSf8PGEHAADz6e7vb9MXbnG73SoqKlJBQUHgmNVqVUFBgdatW9fpZ1wul2pra4NeAAAgMpk+7Bw+fFgej0dZWVlBx7OyslRWVtbpZxYtWqSUlJTAKzc3dzCaCgAAQsD0Yac37rzzTtXU1ARepaWloW4SAAAYIKYv0ZiRkSGbzaby8vKg4+Xl5crOzu70M06nU05n/8yGBwAA4c30PTsOh0NTp07VqlWrAse8Xq9WrVql/Pz8ELYMAACEA9P37EjSbbfdphtuuEHTpk3TWWedpcWLF6uhoUE33nhjqJsGAABCLCLCzrXXXqvKykrdc889Kisr05QpU7RixYpjJi0DAIDoExF1dvqKOjsAAJhP1NTZAQAAOB7CDgAAiGiEHQAAENEIOwAAIKIRdgAAQESLiKXnfeVfkMaGoAAAmIf/9/aJFpYTdiTV1dVJEhuCAgBgQnV1dUpJSenyPHV25Nte4uDBg0pKSpLFYum3+9bW1io3N1elpaXU7xkEPO/BxfMeXDzvwcXzHly9fd6GYaiurk45OTmyWruemUPPjiSr1aoRI0YM2P2Tk5P5l2UQ8bwHF897cPG8BxfPe3D15nkfr0fHjwnKAAAgohF2AABARCPsDCCn06lf/vKXcjqdoW5KVOB5Dy6e9+DieQ8unvfgGujnzQRlAAAQ0ejZAQAAEY2wAwAAIhphBwAARDTCDgAAiGiEnQG0dOlSjR49WrGxsZoxY4Y2btwY6iZFhDVr1ugrX/mKcnJyZLFYtHz58qDzhmHonnvu0bBhwxQXF6eCggLt2rUrNI01uUWLFmn69OlKSkpSZmamrrrqKu3YsSPomubmZi1YsEDp6elKTEzUvHnzVF5eHqIWm98TTzyh008/PVBcLT8/X2+//XbgPM974Dz44IOyWCxauHBh4BjPu3/993//tywWS9BrwoQJgfMD9bwJOwPk5Zdf1m233aZf/vKX2rx5syZPnqw5c+aooqIi1E0zvYaGBk2ePFlLly7t9PxDDz2kJUuWaNmyZdqwYYMSEhI0Z84cNTc3D3JLza+wsFALFizQ+vXrtXLlSrW0tOiSSy5RQ0ND4Jpbb71V//jHP/Tqq6+qsLBQBw8e1NVXXx3CVpvbiBEj9OCDD6qoqEibNm3ShRdeqLlz5+rTTz+VxPMeKB9++KGefPJJnX766UHHed7979RTT9WhQ4cCr/fffz9wbsCet4EBcdZZZxkLFiwIfO/xeIycnBxj0aJFIWxV5JFkvP7664HvvV6vkZ2dbfz2t78NHKuurjacTqfx4osvhqCFkaWiosKQZBQWFhqG4Xu2MTExxquvvhq4Zvv27YYkY926daFqZsQZMmSI8cc//pHnPUDq6uqM8ePHGytXrjTOO+8846c//alhGPz9Hgi//OUvjcmTJ3d6biCfNz07A8DtdquoqEgFBQWBY1arVQUFBVq3bl0IWxb5iouLVVZWFvTsU1JSNGPGDJ59P6ipqZEkpaWlSZKKiorU0tIS9LwnTJigkSNH8rz7gcfj0UsvvaSGhgbl5+fzvAfIggULdMUVVwQ9V4m/3wNl165dysnJ0ZgxY3T99derpKRE0sA+bzYCHQCHDx+Wx+NRVlZW0PGsrCx9/vnnIWpVdCgrK5OkTp+9/xx6x+v1auHChZo9e7YmTZokyfe8HQ6HUlNTg67leffNtm3blJ+fr+bmZiUmJur111/XxIkTtXXrVp53P3vppZe0efNmffjhh8ec4+93/5sxY4aeffZZnXzyyTp06JDuvfdenXPOOfrkk08G9HkTdgB0y4IFC/TJJ58Eja9jYJx88snaunWrampq9Nprr+mGG25QYWFhqJsVcUpLS/XTn/5UK1euVGxsbKibExUuu+yywPvTTz9dM2bM0KhRo/TKK68oLi5uwH4uw1gDICMjQzab7ZgZ5OXl5crOzg5Rq6KD//ny7PvXzTffrDfffFOrV6/WiBEjAsezs7PldrtVXV0ddD3Pu28cDofGjRunqVOnatGiRZo8ebL+53/+h+fdz4qKilRRUaEzzzxTdrtddrtdhYWFWrJkiex2u7KysnjeAyw1NVUnnXSSdu/ePaB/vwk7A8DhcGjq1KlatWpV4JjX69WqVauUn58fwpZFvry8PGVnZwc9+9raWm3YsIFn3wuGYejmm2/W66+/rnfffVd5eXlB56dOnaqYmJig571jxw6VlJTwvPuR1+uVy+Xiefeziy66SNu2bdPWrVsDr2nTpun6668PvOd5D6z6+nrt2bNHw4YNG9i/332a3owuvfTSS4bT6TSeffZZ47PPPjPmz59vpKamGmVlZaFumunV1dUZW7ZsMbZs2WJIMh5++GFjy5Ytxr59+wzDMIwHH3zQSE1NNd544w3j448/NubOnWvk5eUZTU1NIW65+fzoRz8yUlJSjPfee884dOhQ4NXY2Bi45oc//KExcuRI49133zU2bdpk5OfnG/n5+SFstbndcccdRmFhoVFcXGx8/PHHxh133GFYLBbjnXfeMQyD5z3QOq7GMgyed3/72c9+Zrz33ntGcXGx8cEHHxgFBQVGRkaGUVFRYRjGwD1vws4AevTRR42RI0caDofDOOuss4z169eHukkRYfXq1YakY1433HCDYRi+5ed33323kZWVZTidTuOiiy4yduzYEdpGm1Rnz1mS8cwzzwSuaWpqMn784x8bQ4YMMeLj442vfe1rxqFDh0LXaJP77ne/a4waNcpwOBzG0KFDjYsuuigQdAyD5z3Qvhx2eN7969prrzWGDRtmOBwOY/jw4ca1115r7N69O3B+oJ63xTAMo299QwAAAOGLOTsAACCiEXYAAEBEI+wAAICIRtgBAAARjbADAAAiGmEHAABENMIOAACIaIQdAAAQ0Qg7AAAgohF2AABARCPsAACAiEbYAQAAEe3/AxCJiWTIvz6ZAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list_o_loss)\n",
    "# plt.ylim([0, 10])\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5cc1d463-f5ed-4478-b9c1-2ae87e1096b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e9224b2b-44d5-4792-b5d4-c0688c86743e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %tensorboard --logdir=$LOG_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "42a851f1-e362-4286-838b-1f16f7dbe324",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorboard import notebook\n",
    "# notebook.list() # View open TensorBoard instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bb393f-b785-459c-97fa-5e8c221d3e93",
   "metadata": {},
   "source": [
    "### evaluate post-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9a5c6af1-24ac-4a68-9d5e-e3a2156db18d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating trained Agent...\n",
      "post-train val_loss     : 1.360245704650879\n",
      "post-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Evaluate the agent's policy once after training\n",
    "# ====================================================\n",
    "print(f\"evaluating trained Agent...\")\n",
    "\n",
    "post_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(agent.policy, use_tf_function=True)\n",
    "start_time = time.time()\n",
    "\n",
    "val_loss, preds, tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = post_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"post-train val_loss     : {val_loss}\")\n",
    "print(f\"post-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5627ba05-392d-44a3-8a74-49cb71e683bb",
   "metadata": {},
   "source": [
    "# (2) Serving Trained Policy v1\n",
    "\n",
    "* Can't load with `tf.saved_model.load(SAVE_POLICY_DIR)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "246f2693-a34d-444a-a18f-5c83f6484c3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tmp_dir_v2/policy/policy_0'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVE_POLICY_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "14d14189-50c7-4ca6-8ea9-33a1f93bcaf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f85086206a0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_policy = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    SAVE_POLICY_DIR, load_specs_from_pbtxt=True\n",
    ")\n",
    "\n",
    "saved_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7070c76b-38e8-40e9-9d31-d6713cba6fb4",
   "metadata": {},
   "source": [
    "### Generate predictions (actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1ab7322e-5dfa-44b7-aa94-5161078a586b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "SKIP_NUM = 10\n",
    "\n",
    "for x in eval_ds.skip(SKIP_NUM).take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    \n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "    \n",
    "    # rewards = _get_rewards(x)\n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = saved_policy.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d112c061-598b-460e-9693-0c42f79574e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.5370426, 3.505157 ], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([-0.03448497,  0.03443425, -0.03569386,  0.0249017 , -0.03724889,\n",
       "        0.0121792 , -0.02208771, -0.02623422, -0.00153558, -0.0293952 ,\n",
       "        0.01577351,  0.00283194, -0.0350805 ,  0.01143283, -0.01114243,\n",
       "        0.03436551, -0.0311391 ,  0.00595906,  0.02155383,  0.02172602,\n",
       "       -0.02438439,  0.02550265, -0.03570784,  0.00574202, -0.00017049,\n",
       "        0.04581029, -0.02660173,  0.0111019 , -0.01275384, -0.04183756,\n",
       "        0.01779671, -0.01785945, -0.02765822,  0.0448723 ,  0.02216739,\n",
       "       -0.04961209,  0.04105605,  0.02901837,  0.01829001, -0.00485901,\n",
       "       -0.03431391,  0.0229525 , -0.0265712 ,  0.03899829,  0.0320099 ,\n",
       "        0.0087988 ,  0.04111424,  0.03444147,  0.01933551,  0.03367814,\n",
       "       -0.0190846 ,  0.03554935,  0.01258056,  0.01543904, -0.03057469,\n",
       "        0.00032811,  0.01229043,  0.01398826,  0.02798625, -0.03828893,\n",
       "        0.04346745, -0.0259532 , -0.0353047 ,  0.0444386 , -0.03404024,\n",
       "       -0.07546178, -0.06231301, -0.14074948,  0.05071332, -0.03949016,\n",
       "        0.10363404,  0.01918813, -0.13587177, -0.10897815, -0.03823335,\n",
       "        0.00473085, -0.11461237, -0.06196811, -0.12160074, -0.08423953,\n",
       "       -0.06911317, -0.0670111 ,  0.14235745, -0.1401132 , -0.04977926,\n",
       "       -0.082901  , -0.13033107,  0.00781241,  0.0216319 , -0.02120226,\n",
       "       -0.03017943, -0.06436   , -0.11579201, -0.1249198 , -0.02875957,\n",
       "        0.00029851,  0.01675569,  0.00972394,  0.01695932, -0.0288595 ,\n",
       "       -0.04139238, -0.01142544, -0.0084552 , -0.00669586,  0.01177706,\n",
       "       -0.02239772, -0.0442572 ,  0.00661255,  0.01123987, -0.00178461,\n",
       "        0.03797987,  0.01532467,  0.01620762,  0.01246083,  0.02188248,\n",
       "        0.01273972,  0.01488611,  0.03473783, -0.044094  ,  0.04456106,\n",
       "       -0.02078896,  0.03717152, -0.01563086,  0.0059873 ,  0.03413204,\n",
       "       -0.01692107,  0.04641635,  0.01142123], dtype=float32)))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3e8d3a-e68b-43a8-bedd-19c30dcd1d1e",
   "metadata": {},
   "source": [
    "# (3) Online learning\n",
    "\n",
    "> Here we'll simulate all the actions that need to happen on an online endpoint\n",
    "\n",
    "For \"online learning\" to take place, the agent's policy needs to be updated, where \"updated\" is conceptually similar to retraining a traditional supervised learning model (with latest training examples) and deploying the newly trained model\n",
    "* the bandit agent's policy is updated (i.e., learns) when it receives (e.g., `agent.train(...)`) a trajectory that includes the prediction/action AND the delayed feedback\n",
    "* once `agent.train(...)` takes place, the policy is updated (e.g., weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78edfb6a-05cf-4445-babe-e5b50ae45c84",
   "metadata": {},
   "source": [
    "### Load agent checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eae177d0-1e62-414d-99e8-98e6e5799c9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('deployed_metrics: [<tf_agents.metrics.tf_metrics.AverageReturnMetric object '\n",
      " 'at 0x7f8508498a00>]')\n"
     ]
    }
   ],
   "source": [
    "deployed_step_metric = tf_metrics.EnvironmentSteps()\n",
    "deployed_metrics = [\n",
    "    # tf_metrics.NumberOfEpisodes(),\n",
    "    # tf_metrics.AverageEpisodeLengthMetric(batch_size=HPARAMS['batch_size']),\n",
    "    tf_metrics.AverageReturnMetric(batch_size=HPARAMS['batch_size'])\n",
    "]\n",
    "\n",
    "pprint(f\"deployed_metrics: {deployed_metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "077b3059-538a-4c7c-a7cd-0d9d8d800001",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent: NeuralEpsGreedyAgent\n"
     ]
    }
   ],
   "source": [
    "deployed_agent = agent_factory.PerArmAgentFactory._get_agent(\n",
    "    agent_type = AGENT_TYPE,\n",
    "    network_type = NETWORK_TYPE,\n",
    "    time_step_spec = time_step_spec,\n",
    "    action_spec = action_spec,\n",
    "    observation_spec=observation_spec,\n",
    "    global_layers = GLOBAL_LAYERS,\n",
    "    arm_layers = ARM_LAYERS,\n",
    "    common_layers = COMMON_LAYERS,\n",
    "    agent_alpha = AGENT_ALPHA,\n",
    "    learning_rate = LR,\n",
    "    epsilon = EPSILON,\n",
    "    # train_step_counter = global_step,\n",
    "    output_dim = ENCODING_DIM,\n",
    "    eps_phase_steps = EPS_PHASE_STEPS,\n",
    "    # summarize_grads_and_vars = True,\n",
    "    debug_summaries = True\n",
    ")\n",
    "      \n",
    "deployed_agent.initialize()\n",
    "print(f'agent: {deployed_agent.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ab5f7094-fabb-478e-9ba4-fbb1e9e4638f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MirroredVariable:{\n",
       "  0: <tf.Variable 'global_step:0' shape=() dtype=int64, numpy=50>\n",
       "}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6ecc624c-3496-43cf-bab5-52911ecaf634",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tmp_dir_v2/checkpoint'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHKPOINT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8123c4cc-05ed-4828-a5ca-111ae32bd516",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MirroredVariable:{\n",
       "  0: <tf.Variable 'global_step:0' shape=() dtype=int64, numpy=50>\n",
       "}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployed_agent.train_step_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a8649dc9-c485-4044-8e42-d1cbe5d212d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deployed_checkpoint_manager = train_utils.restore_and_get_checkpoint_manager(\n",
    "    root_dir=CHKPOINT_DIR, \n",
    "    agent=deployed_agent, \n",
    "    metrics=deployed_metrics, \n",
    "    step_metric=deployed_step_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "531764a5-6c54-466d-b364-2d1cb3214b89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MirroredVariable:{\n",
       "  0: <tf.Variable 'global_step:0' shape=() dtype=int64, numpy=50>\n",
       "}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm train step counter\n",
    "deployed_agent.train_step_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66690d05-879e-4cc2-b364-208852cb9e8a",
   "metadata": {},
   "source": [
    "#### eval deployed agent\n",
    "\n",
    "> validate metrics on eval set reflect trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f248d047-fb3e-4a5f-a387-53e168977a25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating pre-trained Agent...\n",
      "pre-train val_loss     : 1.3523424863815308\n",
      "pre-train eval runtime : 0\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Evaluate the agent's policy once before training\n",
    "# ====================================================\n",
    "deployed_policy_tf = py_tf_eager_policy.PyTFEagerPolicy(deployed_agent.policy, use_tf_function=True)\n",
    "\n",
    "print(f\"evaluating pre-trained Agent...\")\n",
    "start_time = time.time()\n",
    "\n",
    "pre_val_loss, pre_preds, pre_tr_rewards = eval_perarm._run_bandit_eval(\n",
    "    policy = deployed_policy_tf,\n",
    "    data = eval_ds,\n",
    "    eval_batch_size = HPARAMS['eval_batch_size'],\n",
    "    per_arm_dim = PER_ARM_DIM,\n",
    "    global_dim = GLOBAL_DIM,\n",
    "    vocab_dict = vocab_dict,\n",
    "    num_oov_buckets = NUM_OOV_BUCKETS,\n",
    "    global_emb_size = GLOBAL_EMBEDDING_SIZE,\n",
    "    mv_emb_size = MV_EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"pre-train val_loss     : {pre_val_loss}\")\n",
    "print(f\"pre-train eval runtime : {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1839e39-b1a8-45d2-be78-5f694e78820b",
   "metadata": {},
   "source": [
    "#### Train loop on endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "79a1c276-4773-4e93-91fc-1a5eca957f60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_TRAIN_STEPS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6439c628-a905-43ca-8e4f-bd2febdfe781",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting train loop...\n",
      "step = 50: train loss = 1.3799999952316284\n",
      "step = 60: train loss = 1.350000023841858\n",
      "step = 70: train loss = 1.1100000143051147\n",
      "step = 80: train loss = 1.0199999809265137\n",
      "step = 90: train loss = 0.949999988079071\n",
      "step = 100: train loss = 1.1100000143051147\n",
      "step = 110: train loss = 1.100000023841858\n",
      "step = 120: train loss = 1.2699999809265137\n",
      "step = 130: train loss = 1.350000023841858\n",
      "step = 140: train loss = 1.1699999570846558\n",
      "step = 150: train loss = 1.2899999618530273\n",
      "step = 160: train loss = 1.4600000381469727\n",
      "step = 170: train loss = 1.1699999570846558\n",
      "step = 180: train loss = 1.2799999713897705\n",
      "step = 190: train loss = 1.590000033378601\n",
      "step = 200: train loss = 1.3700000047683716\n",
      "step = 210: train loss = 1.5\n",
      "step = 220: train loss = 1.4500000476837158\n",
      "step = 230: train loss = 1.0\n",
      "step = 240: train loss = 1.2599999904632568\n",
      "train runtime_mins: 2\n"
     ]
    }
   ],
   "source": [
    "list_o_loss = []\n",
    "\n",
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "print(f\"starting train loop...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# for i in tqdm(range(NUM_TRAIN_STEPS)):\n",
    "for i in range(NUM_TRAIN_STEPS):\n",
    "\n",
    "    with train_summary_writer.as_default():\n",
    "\n",
    "        data = next(train_ds_iterator)\n",
    "        trajectories = _trajectory_fn(data)\n",
    "\n",
    "        # All tensors in experience must be shaped [batch, time, ...] \n",
    "        step = deployed_agent.train_step_counter.numpy()\n",
    "        loss = deployed_agent.train(experience=trajectories)\n",
    "        list_o_loss.append(loss.loss.numpy())\n",
    "\n",
    "        train_utils._export_metrics_and_summaries(\n",
    "            step=i, \n",
    "            metrics=deployed_metrics\n",
    "        )\n",
    "\n",
    "        # print step loss\n",
    "        if step % LOG_INTERVAL == 0:\n",
    "            print(\n",
    "                'step = {0}: train loss = {1}'.format(\n",
    "                    step, round(loss.loss.numpy(), 2)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # if i > 0 and i % CHKPT_INTERVAL == 0:\n",
    "            # saver.save(os.path.join(CHKPOINT_DIR, 'policy_%d' % step_metric.result()))\n",
    "            # deployed_checkpoint_manager.save(global_step)\n",
    "            # print(f\"saved policy to: {CHKPOINT_DIR}\")\n",
    "\n",
    "runtime_mins = int((time.time() - start_time) / 60)\n",
    "print(f\"train runtime_mins: {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2f826ce9-a6c3-49aa-951a-6c2b5eb58794",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint  ckpt-50.data-00000-of-00001  ckpt-50.index\n"
     ]
    }
   ],
   "source": [
    "!ls $CHKPOINT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7e498034-5104-4ab6-9805-394f82e8ff59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tmp_dir_v2/checkpoint/ckpt-250'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployed_checkpoint_manager.save(global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f7e73061-aadb-42d3-a9f5-27067d150c10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\t\t      ckpt-250.index\t\t   ckpt-50.index\n",
      "ckpt-250.data-00000-of-00001  ckpt-50.data-00000-of-00001\n"
     ]
    }
   ],
   "source": [
    "!ls $CHKPOINT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17978e3-12f1-4421-916d-6d880592ec53",
   "metadata": {},
   "source": [
    "### save newly trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "490fbb88-dc29-4992-ae41-b164a0e081ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deployed_step_metric.result()\n",
    "deployed_agent.train_step_counter.value().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "71917a67-8429-4329-958f-e7fdd187b0db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tmp_dir_v2/policy/policy_250'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEW_SAVE_POLICY_DIR = os.path.join(POLICY_DIR, 'policy_%d' % deployed_agent.train_step_counter.value().numpy())\n",
    "NEW_SAVE_POLICY_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5116acf0-446d-4e3c-a54c-7111e94e3151",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved trained policy to: tmp_dir_v2/policy/policy_250\n"
     ]
    }
   ],
   "source": [
    "# saver.save(POLICY_DIR)\n",
    "saver.save(NEW_SAVE_POLICY_DIR)\n",
    "print(f\"saved trained policy to: {NEW_SAVE_POLICY_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a345a1d3-7beb-43c4-b8c5-b20a63352b0f",
   "metadata": {},
   "source": [
    "### Create zip file and upload zip file\n",
    "\n",
    "> export / import checkpointer and policy directories such that you can continue training at a later point and deploy the model without having to train again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8c213d61-f4cd-49b8-b014-9e6663ca56f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def create_zip_file(dirname, base_filename):\n",
    "#     return shutil.make_archive(base_filename, 'zip', dirname)\n",
    "\n",
    "# def upload_and_unzip_file_to(dirname):\n",
    "#     if files is None:\n",
    "#         return\n",
    "#     uploaded = files.upload()\n",
    "#     for fn in uploaded.keys():\n",
    "#         print(\n",
    "#             'User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "#                 name=fn, length=len(uploaded[fn])\n",
    "#             )\n",
    "#         )\n",
    "#         shutil.rmtree(dirname)\n",
    "#         zip_files = zipfile.ZipFile(io.BytesIO(uploaded[fn]), 'r')\n",
    "#         zip_files.extractall(dirname)\n",
    "#         zip_files.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "57e495e1-4a48-46d4-9444-4244a8906ab5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# checkpoint_zip_filename = create_zip_file(CHKPOINT_DIR, os.path.join(tempdir, 'exported_cp'))\n",
    "# checkpoint_zip_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e28d64b3-4d31-4a83-b813-6c18ef235361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # download zip file\n",
    "# if files is not None:\n",
    "#     files.download(checkpoint_zip_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c46d59d2-1e56-479f-b294-a0966bfee1ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# upload_and_unzip_file_to(CHKPOINT_DIR)\n",
    "# checkpoint_manager.initialize_or_restore()\n",
    "# global_step = tf.compat.v1.train.get_global_step()\n",
    "# print(f\"global_step : {global_step}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c265ea-7951-4825-bdc3-e448633a4b6e",
   "metadata": {},
   "source": [
    "# (4) Serving Trained Policy v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "55151d77-0f3e-4996-a50e-8e621f3b3e67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tmp_dir_v2/policy/policy_250'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEW_SAVE_POLICY_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c699b4f3-c01d-44e4-87b6-a0833ef057cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.py_tf_eager_policy.SavedModelPyTFEagerPolicy at 0x7f850870a5c0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_policy_v2 = py_tf_eager_policy.SavedModelPyTFEagerPolicy(\n",
    "    NEW_SAVE_POLICY_DIR, load_specs_from_pbtxt=True\n",
    ")\n",
    "\n",
    "saved_policy_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ead0516b-aeac-4cd5-aa79-0081fe12505a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INFER_SIZE = 1\n",
    "dummy_arm = tf.zeros([INFER_SIZE, PER_ARM_DIM], dtype=tf.float32)\n",
    "\n",
    "SKIP_NUM = 10\n",
    "\n",
    "for x in eval_ds.skip(SKIP_NUM).take(INFER_SIZE):\n",
    "    # get feature tensors\n",
    "    \n",
    "    global_feat_infer = embs._get_global_context_features(x)\n",
    "    arm_feat_infer = embs._get_per_arm_features(x)\n",
    "    \n",
    "    # rewards = _get_rewards(x)\n",
    "    rewards = reward_factory._get_rewards(x)\n",
    "    \n",
    "    # reshape arm features\n",
    "    arm_feat_infer = tf.reshape(arm_feat_infer, [HPARAMS['eval_batch_size'], PER_ARM_DIM]) # perarm_dim\n",
    "    concat_arm = tf.concat([arm_feat_infer, dummy_arm], axis=0)\n",
    "    \n",
    "    # flatten global\n",
    "    flat_global_infer = tf.reshape(global_feat_infer, [GLOBAL_DIM])\n",
    "    feature = {'global': flat_global_infer, 'per_arm': concat_arm}\n",
    "    \n",
    "    # get actual reward\n",
    "    actual_reward = rewards.numpy()[0]\n",
    "    \n",
    "    # build trajectory step\n",
    "    trajectory_step = train_utils._get_eval_step(feature, actual_reward)\n",
    "    \n",
    "    prediction = saved_policy_v2.action(trajectory_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "954e834e-d5d6-4b60-89fa-badbd8c13bda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=array(0, dtype=int32), state=(), info=PerArmPolicyInfo(log_probability=(), predicted_rewards_mean=array([3.5370426, 3.505157 ], dtype=float32), multiobjective_scalarized_predicted_rewards_mean=(), predicted_rewards_optimistic=(), predicted_rewards_sampled=(), bandit_policy_type=array([1], dtype=int32), chosen_arm_features=array([-0.03448497,  0.03443425, -0.03569386,  0.0249017 , -0.03724889,\n",
       "        0.0121792 , -0.02208771, -0.02623422, -0.00153558, -0.0293952 ,\n",
       "        0.01577351,  0.00283194, -0.0350805 ,  0.01143283, -0.01114243,\n",
       "        0.03436551, -0.0311391 ,  0.00595906,  0.02155383,  0.02172602,\n",
       "       -0.02438439,  0.02550265, -0.03570784,  0.00574202, -0.00017049,\n",
       "        0.04581029, -0.02660173,  0.0111019 , -0.01275384, -0.04183756,\n",
       "        0.01779671, -0.01785945, -0.02765822,  0.0448723 ,  0.02216739,\n",
       "       -0.04961209,  0.04105605,  0.02901837,  0.01829001, -0.00485901,\n",
       "       -0.03431391,  0.0229525 , -0.0265712 ,  0.03899829,  0.0320099 ,\n",
       "        0.0087988 ,  0.04111424,  0.03444147,  0.01933551,  0.03367814,\n",
       "       -0.0190846 ,  0.03554935,  0.01258056,  0.01543904, -0.03057469,\n",
       "        0.00032811,  0.01229043,  0.01398826,  0.02798625, -0.03828893,\n",
       "        0.04346745, -0.0259532 , -0.0353047 ,  0.0444386 , -0.03404024,\n",
       "       -0.07546178, -0.06231301, -0.14074948,  0.05071332, -0.03949016,\n",
       "        0.10363404,  0.01918813, -0.13587177, -0.10897815, -0.03823335,\n",
       "        0.00473085, -0.11461237, -0.06196811, -0.12160074, -0.08423953,\n",
       "       -0.06911317, -0.0670111 ,  0.14235745, -0.1401132 , -0.04977926,\n",
       "       -0.082901  , -0.13033107,  0.00781241,  0.0216319 , -0.02120226,\n",
       "       -0.03017943, -0.06436   , -0.11579201, -0.1249198 , -0.02875957,\n",
       "        0.00029851,  0.01675569,  0.00972394,  0.01695932, -0.0288595 ,\n",
       "       -0.04139238, -0.01142544, -0.0084552 , -0.00669586,  0.01177706,\n",
       "       -0.02239772, -0.0442572 ,  0.00661255,  0.01123987, -0.00178461,\n",
       "        0.03797987,  0.01532467,  0.01620762,  0.01246083,  0.02188248,\n",
       "        0.01273972,  0.01488611,  0.03473783, -0.044094  ,  0.04456106,\n",
       "       -0.02078896,  0.03717152, -0.01563086,  0.0059873 ,  0.03413204,\n",
       "       -0.01692107,  0.04641635,  0.01142123], dtype=float32)))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5f2c1332-74c3-4753-b28b-c025f1918aca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bandit_policy_type': 1,\n",
       " 'chosen_arm_features': [-0.034484971314668655,\n",
       "  0.0344342477619648,\n",
       "  -0.03569386154413223,\n",
       "  0.024901699274778366,\n",
       "  -0.0372488871216774,\n",
       "  0.012179195880889893,\n",
       "  -0.02208770625293255,\n",
       "  -0.026234222576022148,\n",
       "  -0.0015355832874774933,\n",
       "  -0.029395198449492455,\n",
       "  0.015773508697748184,\n",
       "  0.0028319358825683594,\n",
       "  -0.035080503672361374,\n",
       "  0.011432826519012451,\n",
       "  -0.011142432689666748,\n",
       "  0.03436550870537758,\n",
       "  -0.031139099970459938,\n",
       "  0.005959056317806244,\n",
       "  0.021553825587034225,\n",
       "  0.021726015955209732,\n",
       "  -0.0243843924254179,\n",
       "  0.025502648204565048,\n",
       "  -0.03570784255862236,\n",
       "  0.005742024630308151,\n",
       "  -0.00017049163579940796,\n",
       "  0.04581029340624809,\n",
       "  -0.026601731777191162,\n",
       "  0.011101901531219482,\n",
       "  -0.012753844261169434,\n",
       "  -0.04183756187558174,\n",
       "  0.017796706408262253,\n",
       "  -0.01785944774746895,\n",
       "  -0.02765822410583496,\n",
       "  0.04487229511141777,\n",
       "  0.0221673883497715,\n",
       "  -0.04961209371685982,\n",
       "  0.04105604812502861,\n",
       "  0.02901836857199669,\n",
       "  0.01829000934958458,\n",
       "  -0.004859007894992828,\n",
       "  -0.034313905984163284,\n",
       "  0.022952500730752945,\n",
       "  -0.026571203023195267,\n",
       "  0.03899829462170601,\n",
       "  0.032009903341531754,\n",
       "  0.00879880040884018,\n",
       "  0.041114237159490585,\n",
       "  0.034441474825143814,\n",
       "  0.019335512071847916,\n",
       "  0.03367814049124718,\n",
       "  -0.019084597006440163,\n",
       "  0.035549346357584,\n",
       "  0.012580562382936478,\n",
       "  0.01543903723359108,\n",
       "  -0.03057469241321087,\n",
       "  0.00032811239361763,\n",
       "  0.012290429323911667,\n",
       "  0.013988260179758072,\n",
       "  0.027986254543066025,\n",
       "  -0.03828892856836319,\n",
       "  0.0434674508869648,\n",
       "  -0.025953197851777077,\n",
       "  -0.03530470281839371,\n",
       "  0.04443860426545143,\n",
       "  -0.034040238708257675,\n",
       "  -0.07546177506446838,\n",
       "  -0.062313005328178406,\n",
       "  -0.1407494843006134,\n",
       "  0.05071331933140755,\n",
       "  -0.03949016332626343,\n",
       "  0.10363404452800751,\n",
       "  0.019188132137060165,\n",
       "  -0.1358717679977417,\n",
       "  -0.10897815227508545,\n",
       "  -0.03823334723711014,\n",
       "  0.004730846732854843,\n",
       "  -0.11461237072944641,\n",
       "  -0.0619681142270565,\n",
       "  -0.12160073965787888,\n",
       "  -0.08423952758312225,\n",
       "  -0.06911316514015198,\n",
       "  -0.06701109558343887,\n",
       "  0.1423574537038803,\n",
       "  -0.1401132047176361,\n",
       "  -0.049779262393713,\n",
       "  -0.0829010009765625,\n",
       "  -0.13033106923103333,\n",
       "  0.007812414318323135,\n",
       "  0.02163190394639969,\n",
       "  -0.02120225876569748,\n",
       "  -0.030179433524608612,\n",
       "  -0.06436000019311905,\n",
       "  -0.11579200625419617,\n",
       "  -0.12491980195045471,\n",
       "  -0.02875957265496254,\n",
       "  0.0002985075116157532,\n",
       "  0.016755685210227966,\n",
       "  0.009723943658173084,\n",
       "  0.016959315165877342,\n",
       "  -0.02885950356721878,\n",
       "  -0.041392382234334946,\n",
       "  -0.011425444856286049,\n",
       "  -0.008455204777419567,\n",
       "  -0.006695858668535948,\n",
       "  0.011777060106396675,\n",
       "  -0.02239772491157055,\n",
       "  -0.04425720125436783,\n",
       "  0.006612554658204317,\n",
       "  0.011239872314035892,\n",
       "  -0.001784613006748259,\n",
       "  0.03797987103462219,\n",
       "  0.01532466895878315,\n",
       "  0.016207624226808548,\n",
       "  0.012460828758776188,\n",
       "  0.02188248187303543,\n",
       "  0.01273972075432539,\n",
       "  0.014886110089719296,\n",
       "  0.034737829118967056,\n",
       "  -0.04409400001168251,\n",
       "  0.04456106200814247,\n",
       "  -0.02078896015882492,\n",
       "  0.03717151656746864,\n",
       "  -0.01563085801899433,\n",
       "  0.005987303331494331,\n",
       "  0.034132037311792374,\n",
       "  -0.016921067610383034,\n",
       "  0.046416353434324265,\n",
       "  0.01142122969031334],\n",
       " 'predicted_rewards_mean': [3.5370426177978516, 3.505156993865967],\n",
       " 'action': 0}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_pred_dict = {\n",
    "    \"bandit_policy_type\" : int(prediction.info.bandit_policy_type[0]),\n",
    "    \"chosen_arm_features\" : prediction.info.chosen_arm_features.tolist(),\n",
    "    \"predicted_rewards_mean\" : prediction.info.predicted_rewards_mean.tolist(),\n",
    "    \"action\" : int(prediction.action.tolist()),\n",
    "}\n",
    "\n",
    "processed_pred_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347eb5ee-669b-4942-9428-9fb979fad3ce",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
