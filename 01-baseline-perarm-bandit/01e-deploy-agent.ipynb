{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db716467-1521-40ad-878b-0d008217a60f",
   "metadata": {},
   "source": [
    "# Deploying trained Agent to Vertex Endpoint\n",
    "\n",
    "> **TODO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba90402-f882-478e-8bde-f5aacad8a21b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce421ec-2f09-4abc-9383-fa7c4d1d6b60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "284b96ec-a5aa-4bbf-bc46-0bf3920c0135",
   "metadata": {},
   "source": [
    "## Create custom prediction container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cc9a37-fec9-4b62-9177-7f36c966d0c7",
   "metadata": {},
   "source": [
    "As with training, create a custom prediction container. This container handles the TF-Agents specific logic that is different from a regular TensorFlow Model. Specifically, it finds the predicted action using a trained policy. The associated source code is in `src/prediction/`.\n",
    "See other options for Vertex AI predictions [here](https://cloud.google.com/vertex-ai/docs/predictions/getting-predictions).\n",
    "\n",
    "#### Serve predictions:\n",
    "- Use [`tensorflow.saved_model.load`](https://www.tensorflow.org/agents/api_docs/python/tf_agents/policies/PolicySaver#usage), instead of [`tf_agents.policies.policy_loader.load`](https://github.com/tensorflow/agents/blob/r0.8.0/tf_agents/policies/policy_loader.py#L26), to load the trained policy, because the latter produces an object of type [`SavedModelPyTFEagerPolicy`](https://github.com/tensorflow/agents/blob/402b8aa81ca1b578ec1f687725d4ccb4115386d2/tf_agents/policies/py_tf_eager_policy.py#L137) whose `action()` is not compatible for use here.\n",
    "- Note that prediction requests contain only observation data but not reward. This is because: The prediction task is a standalone request that doesn't require prior knowledge of the system state. Meanwhile, end users only know what they observe at the moment. Reward is a piece of information that comes after the action has been made, so the end users would not have knowledge of said reward. In handling prediction requests, you create a [`TimeStep`](https://www.tensorflow.org/agents/api_docs/python/tf_agents/trajectories/TimeStep) object (consisting of `observation`, `reward`, `discount`, `step_type`) using the [`restart()`](https://www.tensorflow.org/agents/api_docs/python/tf_agents/trajectories/restart) function which takes in an `observation`. This function creates the *first* TimeStep in a trajectory of steps, where reward is 0, discount is 1 and step_type is marked as the first timestep. In other words, each prediction request forms the first `TimeStep` in a brand new trajectory.\n",
    "- For the prediction response, avoid using NumPy-typed values; instead, convert them to native Python values using methods such as [`tolist()`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.tolist.html) as opposed to `list()`.\n",
    "- There exists a prestart script in `src/prediction`. FastAPI executes this script before starting up the server. The `PORT` environment variable is set to equal `AIP_HTTP_PORT` in order to run FastAPI on the same port expected by Vertex AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cd60ba-6976-4526-a082-43fcf1c20c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRED_SUBFOLDER = 'prediction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e021dbc4-ba2a-4c86-8583-5fcbcea3d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the training subfolder\n",
    "# ! rm -rf {REPO_DOCKER_PATH_PREFIX}/{PRED_SUBFOLDER}\n",
    "# ! mkdir {REPO_DOCKER_PATH_PREFIX}/{PRED_SUBFOLDER}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1369c5-3066-4791-958f-38cc49b70a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile {REPO_DOCKER_PATH_PREFIX}/{PRED_SUBFOLDER}/main.py\n",
    "# # Copyright 2021 Google LLC\n",
    "# #\n",
    "# # Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# # you may not use this file except in compliance with the License.\n",
    "# # You may obtain a copy of the License at\n",
    "# #\n",
    "# #      http://www.apache.org/licenses/LICENSE-2.0\n",
    "# #\n",
    "# # Unless required by applicable law or agreed to in writing, software\n",
    "# # distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# # See the License for the specific language governing permissions and\n",
    "# # limitations under the License.\n",
    "\n",
    "# \"\"\"Prediction server that uses a trained policy to give predicted actions.\"\"\"\n",
    "# import os\n",
    "\n",
    "# from fastapi import FastAPI\n",
    "# from fastapi import Request\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import tf_agents\n",
    "\n",
    "\n",
    "# app = FastAPI()\n",
    "# _model = tf.compat.v2.saved_model.load(os.environ[\"AIP_STORAGE_URI\"])\n",
    "\n",
    "\n",
    "# @app.get(os.environ[\"AIP_HEALTH_ROUTE\"], status_code=200)\n",
    "# def health():\n",
    "#     \"\"\"\n",
    "#     Handles server health check requests.\n",
    "\n",
    "#     Returns:\n",
    "#       An empty dict.\n",
    "#     \"\"\"\n",
    "#     return {}\n",
    "\n",
    "\n",
    "# @app.post(os.environ[\"AIP_PREDICT_ROUTE\"])\n",
    "# async def predict(request: Request):\n",
    "#     \"\"\"\n",
    "#     Handles prediction requests.\n",
    "\n",
    "#     Unpacks observations in prediction requests and queries the trained policy for\n",
    "#     predicted actions.\n",
    "\n",
    "#     Args:\n",
    "#       request: Incoming prediction requests that contain observations.\n",
    "\n",
    "#     Returns:\n",
    "#       A dict with the key `predictions` mapping to a list of predicted actions\n",
    "#       corresponding to each observation in the prediction request.\n",
    "#     \"\"\"\n",
    "#     body = await request.json()\n",
    "#     instances = body[\"instances\"]\n",
    "\n",
    "#     predictions = []\n",
    "#     for index, instance in enumerate(instances):\n",
    "#         # Unpack request body and reconstruct TimeStep. Rewards default to 0.\n",
    "#         batch_size = len(instance[\"observation\"])\n",
    "        \n",
    "#         time_step = tf_agents.trajectories.restart(\n",
    "#             observation=instance[\"observation\"]\n",
    "#             , batch_size=tf.convert_to_tensor([batch_size])\n",
    "#         )\n",
    "#         policy_step = _model.action(time_step)\n",
    "\n",
    "#         predictions.append(\n",
    "#             {f\"PolicyStep {index}\": policy_step.action.numpy().tolist()}\n",
    "#         )\n",
    "\n",
    "#     return {\n",
    "#         \"predictions\": predictions\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad69885-4cd7-4e95-9863-000627086043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile {REPO_DOCKER_PATH_PREFIX}/{PRED_SUBFOLDER}/prestart.sh\n",
    "# #!/bin/bash\n",
    "# export PORT=$AIP_HTTP_PORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c425faab-c9e6-48b9-b160-37f80ee987ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile pred_requirements.txt\n",
    "# tf-agents==0.17.0\n",
    "# tensorflow==2.12.0\n",
    "# numpy\n",
    "# six\n",
    "# typing-extensions\n",
    "# pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01acee11-2511-47fe-afe3-3f05e2b2b502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOCKERNAME = 'pred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f1eb18-6eee-418f-832d-4514e2142e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile Dockerfile_{DOCKERNAME}\n",
    "\n",
    "# FROM tiangolo/uvicorn-gunicorn-fastapi:python3.10\n",
    "\n",
    "# COPY src/prediction /app\n",
    "# COPY pred_requirements.txt /app/requirements.txt\n",
    "\n",
    "# RUN pip3 install -r /app/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f150f00-c88b-4437-a937-d515eb6aa0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTION_CONTAINER = \"prediction-custom-container\"\n",
    "\n",
    "# # Docker definitions for training\n",
    "# PRED_IMAGE_URI = f'gcr.io/{PROJECT_ID}/{PREDICTION_CONTAINER}'\n",
    "# MACHINE_TYPE ='e2-highcpu-32'\n",
    "# FILE_LOCATION = './'\n",
    "\n",
    "# print(f\"export DOCKERNAME={DOCKERNAME}\")\n",
    "# print(f\"export PRED_IMAGE_URI={PRED_IMAGE_URI}\")\n",
    "# print(f\"export FILE_LOCATION={FILE_LOCATION}\")\n",
    "# print(f\"export MACHINE_TYPE={MACHINE_TYPE}\")\n",
    "# print(f\"export ARTIFACTS_DIR={ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c157f1db-4dff-484c-967e-2fc7f658800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gcloud builds submit --config cloudbuild.yaml \\\n",
    "#     --substitutions _DOCKERNAME=$DOCKERNAME,_IMAGE_URI=$PRED_IMAGE_URI,_FILE_LOCATION=$FILE_LOCATION,_ARTIFACTS_DIR=$ARTIFACTS_DIR \\\n",
    "#     --timeout=2h \\\n",
    "#     --machine-type=$MACHINE_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891a5f51-14b9-41a1-bc13-0f9c87dccad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b5bc8a-f414-4ac2-b594-d82170a38cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4547b04e-cc05-4898-868c-ac406a82aba3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
