{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64583cdb-2502-4f40-a254-8fa68abe7a32",
   "metadata": {},
   "source": [
    "# Build custom container for Vertex training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e1beb37-0c48-4110-8ca0-24ab78c72b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/01-baseline-perarm-bandit\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66298299-d4ad-460e-8ab3-ea9fbc012086",
   "metadata": {},
   "source": [
    "## Load env config\n",
    "\n",
    "* use the prefix from `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1d2542f-d87b-436d-b4bb-08edcbb532ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "# PREFIX = 'mabv1'\n",
    "VERSION        = \"v2\"                       # TODO\n",
    "PREFIX         = f'rec-bandits-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35449112-3c26-4ea9-8c3a-21c283951350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"rec-bandits-v2\"\n",
      "VERSION                  = \"v2\"\n",
      "\n",
      "BUCKET_NAME              = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_ID      = \"hybrid_vertex.movielens_ds_rec_bandits_v2\"\n",
      "BIGQUERY_TABLE_ID        = \"hybrid_vertex.movielens_ds_rec_bandits_v2.training_dataset\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-rec-bandits-v2\"\n",
      "IMAGE_NAME               = \"train-perarm-feats-v2\"\n",
      "DOCKERNAME               = \"Dockerfile_perarm_feats\"\n",
      "\n",
      "IMAGE_URI_01             = \"gcr.io/hybrid-vertex/train-perarm-feats-v2-01\"\n",
      "IMAGE_URI_02             = \"gcr.io/hybrid-vertex/train-perarm-feats-v2-02\"\n",
      "\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/train-perarm-feats-v2\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b16af06-e188-4f4e-a04b-4e0eb8873ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gsutil ls $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be79c652-45c8-4b5f-b410-4908829375a3",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92272ed8-bfb5-4b40-b7f4-cdbe029f3bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261a452d-8ce7-427b-8091-d7d41c57e556",
   "metadata": {},
   "source": [
    "# Build Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d192a4dd-b3e1-4c48-b69f-fd022078e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tree src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9bdef1-ac23-49be-96fd-25795f483643",
   "metadata": {},
   "source": [
    "## Container Image Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4076530-a340-4c57-91af-e2decd035b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCKERNAME_TRAIN_MYENV = \"Dockerfile_train_my_perarm_env\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eedbe408-e2fe-4944-912f-f2b1f6587440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOCKERNAME        = Dockerfile_train_my_perarm_env\n",
      "REPOSITORY        = rl-movielens-rec-bandits-v2\n",
      "IMAGE_NAME        = train-perarm-feats-v2\n",
      "REMOTE_IMAGE_NAME = us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/train-perarm-feats-v2\n",
      "IMAGE_URI_01      = gcr.io/hybrid-vertex/train-perarm-feats-v2-01\n"
     ]
    }
   ],
   "source": [
    "print(f\"DOCKERNAME_TRAIN_MYENV = {DOCKERNAME_TRAIN_MYENV}\")\n",
    "print(f\"REPOSITORY             = {REPOSITORY}\")\n",
    "print(f\"IMAGE_NAME             = {IMAGE_NAME}\")\n",
    "print(f\"REMOTE_IMAGE_NAME      = {REMOTE_IMAGE_NAME}\")\n",
    "print(f\"IMAGE_URI_01           = {IMAGE_URI_01}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf953a8e-d282-4d7b-9a7d-fd0bee28c70a",
   "metadata": {},
   "source": [
    "## Create Artifact Repository\n",
    "\n",
    "If you don't have an existing artifact repository, create one using the gcloud command below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8288932-054a-46e6-90e8-326e015f2115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gcloud artifacts repositories create $REPOSITORY --repository-format=docker --location=$LOCATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1374bc-7b85-4e65-86ab-2721ce4908b3",
   "metadata": {},
   "source": [
    "## Create Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88a8b25d-e55c-4a00-ab0e-1151eae8eaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/tf_vertex_agents'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root_path = '..'\n",
    "os.chdir(root_path)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bffd9bb-6d22-4d4e-9eb8-893472702837",
   "metadata": {},
   "source": [
    "### Create train image\n",
    "\n",
    "* see [example Dockerfile for GPU](https://github.com/GoogleCloudPlatform/cloudml-samples/blob/main/pytorch/containers/quickstart/mnist/Dockerfile-gpu) jobs in Vertex AI\n",
    "* see deep learning container [example here](https://cloud.google.com/deep-learning-containers/docs/derivative-container), and here for [available DL containers](https://cloud.google.com/deep-learning-containers/docs/choosing-container#versions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7022f8d1-43d0-4291-91b8-4cb27491c2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_profiling : True\n"
     ]
    }
   ],
   "source": [
    "gpu_profiling = True # True | False\n",
    "\n",
    "print(f\"gpu_profiling : {gpu_profiling}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4596864b-f059-438d-a04f-7416c436b644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_BASE_IMAGE : gcr.io/deeplearning-platform-release/tf2-gpu.2-13.py310\n",
      "NVTOP_RUN        : RUN apt update && apt -y install nvtop\n",
      "RUN_EXPORT       : RUN export PYTHONPATH=${PYTHONPATH}:${APP_HOME}/\n"
     ]
    }
   ],
   "source": [
    "if gpu_profiling:\n",
    "    # TRAIN_BASE_IMAGE = 'tensorflow/tensorflow:2.13.0-gpu'\n",
    "    TRAIN_BASE_IMAGE = 'gcr.io/deeplearning-platform-release/tf2-gpu.2-13.py310'\n",
    "    NVTOP_RUN = 'RUN apt update && apt -y install nvtop'\n",
    "    # NVTOP_RUN = 'RUN apt-get update && apt-get -y install nvtop'\n",
    "else:\n",
    "    TRAIN_BASE_IMAGE = 'python:3.10'\n",
    "    NVTOP_RUN = None\n",
    "    \n",
    "RUN_EXPORT = \"RUN export PYTHONPATH=${PYTHONPATH}:${APP_HOME}/\"\n",
    "    \n",
    "print(f\"TRAIN_BASE_IMAGE : {TRAIN_BASE_IMAGE}\")\n",
    "print(f\"NVTOP_RUN        : {NVTOP_RUN}\")\n",
    "print(f\"RUN_EXPORT       : {RUN_EXPORT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b1b1fc6-022b-4e56-b62f-673179bab7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FROM gcr.io/deeplearning-platform-release/tf2-gpu.2-13.py310\n",
      "\n",
      "ENV PYTHONUNBUFFERED True\n",
      "\n",
      "ENV APP_HOME /workspace\n",
      "\n",
      "WORKDIR $APP_HOME\n",
      "\n",
      "COPY /requirements.txt $APP_HOME/requirements.txt\n",
      "RUN pip install --upgrade pip\n",
      "RUN pip install --no-cache-dir -r $APP_HOME/requirements.txt\n",
      "RUN pip install cloudml-hypertune\n",
      "\n",
      "RUN apt update && apt -y install nvtop\n",
      "\n",
      "COPY src/per_arm_rl $APP_HOME/src/per_arm_rl\n",
      "\n",
      "RUN export PYTHONPATH=${PYTHONPATH}:${APP_HOME}/\n",
      "\n",
      "# Sets up the entry point to invoke the task.\n",
      "ENTRYPOINT [\"python3\", \"-m\", \"src.per_arm_rl.perarm_task\"]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dockerfile = f'''\n",
    "FROM {TRAIN_BASE_IMAGE}\n",
    "\n",
    "ENV PYTHONUNBUFFERED True\n",
    "\n",
    "ENV APP_HOME /workspace\n",
    "\n",
    "WORKDIR $APP_HOME\n",
    "\n",
    "COPY /requirements.txt $APP_HOME/requirements.txt\n",
    "RUN pip install --upgrade pip\n",
    "RUN pip install --no-cache-dir -r $APP_HOME/requirements.txt\n",
    "RUN pip install cloudml-hypertune\n",
    "\n",
    "{NVTOP_RUN}\n",
    "\n",
    "COPY src/per_arm_rl $APP_HOME/src/per_arm_rl\n",
    "\n",
    "{RUN_EXPORT}\n",
    "\n",
    "# Sets up the entry point to invoke the task.\n",
    "ENTRYPOINT [\"python3\", \"-m\", \"src.per_arm_rl.perarm_task\"]\n",
    "'''\n",
    "print(dockerfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cc6cb35-fcb6-4b4d-a665-b6c038ca6f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DOCKERNAME}', 'w') as f:\n",
    "    f.write(dockerfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04bd12e-c61b-4a5c-b2cb-b7843642ce0e",
   "metadata": {},
   "source": [
    "## Build image with Cloud Build\n",
    "\n",
    "Building images with Cloud Build is best practices\n",
    "* images are centrally stored and better managed for robust CI/CD\n",
    "* building images on local workbench instance can alter notebook image config (base image for notebooks vs train images are different)\n",
    "* if building locally, consider using virutal environments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb3ef36-2cfe-4199-963b-6c65bd0ec621",
   "metadata": {},
   "source": [
    "### Files that will be included in Cloud Build image\n",
    "* to adjust this see the `gcloudignore` section at the end of `00-env-setup.ipynb` notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f9a8891-faa3-4659-a36e-521bf9f186e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockerfile_perarm_feats\n",
      "requirements.txt\n",
      "Dockerfile_train_my_perarm_env\n",
      "Dockerfile_perarm_feats_tpu\n",
      "cloudbuild.yaml\n",
      "src/ranking/ranking_trainer.py\n",
      "src/ranking/stationary_stochastic_repeated_feature_py_environment.py\n",
      "src/ranking/repeated_feature_perarm_network.py\n",
      "src/ranking/jw_perarm_mv_env.py\n",
      "src/ranking/jw_perarm_mv_env_tf.py\n",
      "src/ranking/tmp_cascading_bandit_perarm_env.py\n",
      "src/per_arm_rl/utils_config.py\n",
      "src/per_arm_rl/perarm_task.py\n",
      "src/per_arm_rl/__init__.py\n",
      "src/per_arm_rl/my_per_arm_py_env.py\n",
      "src/per_arm_rl/policy_util.py\n",
      "src/per_arm_rl/train_utils.py\n",
      "src/per_arm_rl/trainer_baseline.py\n",
      "src/per_arm_rl/data_utils.py\n",
      "src/per_arm_rl/data_config.py\n",
      "src/perarm_features/train_perarm.py\n",
      "src/perarm_features/reward_factory.py\n",
      "src/perarm_features/emb_features.py\n",
      "src/perarm_features/agent_factory.py\n",
      "src/perarm_features/__init__.py\n",
      "src/perarm_features/trainer_common.py\n",
      "src/perarm_features/task.py\n",
      "src/perarm_features/eval_perarm.py\n",
      "src/perarm_features/ranking_bandit_policy.py\n",
      "01-baseline-perarm-bandit/result.json\n"
     ]
    }
   ],
   "source": [
    "# check eligble files\n",
    "!gcloud meta list-files-for-upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d830847-8c15-4d85-b344-f79c877aaee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile cloudbuild.yaml\n",
    "\n",
    "# steps:\n",
    "# - name: 'gcr.io/cloud-builders/docker'\n",
    "#   args: ['build', '-t', '$_IMAGE_URI', '$_FILE_LOCATION', '-f', '$_FILE_LOCATION/$_DOCKERNAME']\n",
    "# images:\n",
    "# - '$_IMAGE_URI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e3b8e87-3e4c-410c-a554-3be3b8ed3e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOCKERNAME        : Dockerfile_train_my_perarm_env\n",
      "IMAGE_URI_01      : gcr.io/hybrid-vertex/train-perarm-feats-v2-01\n",
      "FILE_LOCATION     : .\n",
      "MACHINE_TYPE      : e2-highcpu-32\n"
     ]
    }
   ],
   "source": [
    "# image definitions for training\n",
    "MACHINE_TYPE            ='e2-highcpu-32'\n",
    "FILE_LOCATION           = \".\" # './src'\n",
    "\n",
    "DOCKERNAME     = DOCKERNAME_TRAIN_MYENV\n",
    "IMAGE_URI      = IMAGE_URI_01\n",
    "\n",
    "print(f\"DOCKERNAME    : {DOCKERNAME}\")\n",
    "print(f\"IMAGE_URI     : {IMAGE_URI}\")\n",
    "print(f\"FILE_LOCATION : {FILE_LOCATION}\")\n",
    "print(f\"MACHINE_TYPE  : {MACHINE_TYPE}\")\n",
    "\n",
    "print(f\"DOCKERNAME        : {DOCKERNAME}\")\n",
    "print(f\"IMAGE_URI      : {IMAGE_URI}\")\n",
    "print(f\"FILE_LOCATION     : {FILE_LOCATION}\")\n",
    "print(f\"MACHINE_TYPE      : {MACHINE_TYPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d11ac85-16f7-4050-8632-cb6e4337a65a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 30 file(s) totalling 280.8 KiB before compression.\n",
      "Uploading tarball of [.] to [gs://hybrid-vertex_cloudbuild/source/1697660082.826936-df3db4fcdf1a44d4806100dc518d1725.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/hybrid-vertex/locations/global/builds/04489209-8dae-4157-a6fa-1a5f31283fec].\n",
      "Logs are available at [ https://console.cloud.google.com/cloud-build/builds/04489209-8dae-4157-a6fa-1a5f31283fec?project=934903580331 ].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"04489209-8dae-4157-a6fa-1a5f31283fec\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://hybrid-vertex_cloudbuild/source/1697660082.826936-df3db4fcdf1a44d4806100dc518d1725.tgz#1697660083197134\n",
      "Copying gs://hybrid-vertex_cloudbuild/source/1697660082.826936-df3db4fcdf1a44d4806100dc518d1725.tgz#1697660083197134...\n",
      "/ [1 files][ 62.5 KiB/ 62.5 KiB]                                                \n",
      "Operation completed over 1 objects/62.5 KiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  322.6kB\n",
      "Step 1/12 : FROM gcr.io/deeplearning-platform-release/tf2-gpu.2-13.py310\n",
      "latest: Pulling from deeplearning-platform-release/tf2-gpu.2-13.py310\n",
      "6b851dcae6ca: Pulling fs layer\n",
      "4586c00479c6: Pulling fs layer\n",
      "4304fa233a80: Pulling fs layer\n",
      "afa3f70b397f: Pulling fs layer\n",
      "d963a42bc712: Pulling fs layer\n",
      "68cd1e6a2dfe: Pulling fs layer\n",
      "c4a5e6c74f13: Pulling fs layer\n",
      "afec03310895: Pulling fs layer\n",
      "44d8a5c35cf0: Pulling fs layer\n",
      "e1bab5cae66b: Pulling fs layer\n",
      "e5f5c15a6664: Pulling fs layer\n",
      "8171a8ea64b5: Pulling fs layer\n",
      "62a953797b1c: Pulling fs layer\n",
      "899d4bcdc05c: Pulling fs layer\n",
      "4f4fb700ef54: Pulling fs layer\n",
      "30ca64e2860e: Pulling fs layer\n",
      "65fe4b253d36: Pulling fs layer\n",
      "cf6ff63990c9: Pulling fs layer\n",
      "98c496486cb5: Pulling fs layer\n",
      "89e015317d12: Pulling fs layer\n",
      "0d73dcaef634: Pulling fs layer\n",
      "0e753bb4cdca: Pulling fs layer\n",
      "fcd7199f10b4: Pulling fs layer\n",
      "61a65022eab2: Pulling fs layer\n",
      "c4a5e6c74f13: Waiting\n",
      "9d4613b858ae: Pulling fs layer\n",
      "4e15a13e9004: Pulling fs layer\n",
      "afec03310895: Waiting\n",
      "fb979c9a76d1: Pulling fs layer\n",
      "44d8a5c35cf0: Waiting\n",
      "0af71c3d2df0: Pulling fs layer\n",
      "afa3f70b397f: Waiting\n",
      "89111f12ae60: Pulling fs layer\n",
      "e1bab5cae66b: Waiting\n",
      "e5f5c15a6664: Waiting\n",
      "75fd5b15b787: Pulling fs layer\n",
      "4f62627df82d: Pulling fs layer\n",
      "d963a42bc712: Waiting\n",
      "8171a8ea64b5: Waiting\n",
      "68cd1e6a2dfe: Waiting\n",
      "98c496486cb5: Waiting\n",
      "62a953797b1c: Waiting\n",
      "d9b739ba638a: Pulling fs layer\n",
      "89e015317d12: Waiting\n",
      "ca6c11fb22c5: Pulling fs layer\n",
      "0d73dcaef634: Waiting\n",
      "802afda9ddfe: Pulling fs layer\n",
      "30ca64e2860e: Waiting\n",
      "ea04278ce919: Pulling fs layer\n",
      "65fe4b253d36: Waiting\n",
      "47a6cf75bc34: Pulling fs layer\n",
      "e947aa78f022: Pulling fs layer\n",
      "cf6ff63990c9: Waiting\n",
      "0e753bb4cdca: Waiting\n",
      "615bdc6bac79: Pulling fs layer\n",
      "dfd3fe17d2c5: Pulling fs layer\n",
      "61a65022eab2: Waiting\n",
      "4f4fb700ef54: Waiting\n",
      "899d4bcdc05c: Waiting\n",
      "9d4613b858ae: Waiting\n",
      "0af71c3d2df0: Waiting\n",
      "4e15a13e9004: Waiting\n",
      "4f62627df82d: Waiting\n",
      "d9b739ba638a: Waiting\n",
      "89111f12ae60: Waiting\n",
      "47a6cf75bc34: Waiting\n",
      "ca6c11fb22c5: Waiting\n",
      "75fd5b15b787: Waiting\n",
      "e947aa78f022: Waiting\n",
      "802afda9ddfe: Waiting\n",
      "615bdc6bac79: Waiting\n",
      "dfd3fe17d2c5: Waiting\n",
      "fb979c9a76d1: Waiting\n",
      "4586c00479c6: Verifying Checksum\n",
      "4586c00479c6: Download complete\n",
      "afa3f70b397f: Verifying Checksum\n",
      "afa3f70b397f: Download complete\n",
      "d963a42bc712: Verifying Checksum\n",
      "d963a42bc712: Download complete\n",
      "6b851dcae6ca: Verifying Checksum\n",
      "6b851dcae6ca: Download complete\n",
      "c4a5e6c74f13: Verifying Checksum\n",
      "c4a5e6c74f13: Download complete\n",
      "afec03310895: Verifying Checksum\n",
      "afec03310895: Download complete\n",
      "44d8a5c35cf0: Download complete\n",
      "4304fa233a80: Verifying Checksum\n",
      "4304fa233a80: Download complete\n",
      "e5f5c15a6664: Verifying Checksum\n",
      "e5f5c15a6664: Download complete\n",
      "6b851dcae6ca: Pull complete\n",
      "4586c00479c6: Pull complete\n",
      "4304fa233a80: Pull complete\n",
      "afa3f70b397f: Pull complete\n",
      "d963a42bc712: Pull complete\n",
      "68cd1e6a2dfe: Verifying Checksum\n",
      "68cd1e6a2dfe: Download complete\n",
      "62a953797b1c: Verifying Checksum\n",
      "62a953797b1c: Download complete\n",
      "899d4bcdc05c: Verifying Checksum\n",
      "899d4bcdc05c: Download complete\n",
      "4f4fb700ef54: Verifying Checksum\n",
      "4f4fb700ef54: Download complete\n",
      "8171a8ea64b5: Verifying Checksum\n",
      "8171a8ea64b5: Download complete\n",
      "65fe4b253d36: Verifying Checksum\n",
      "65fe4b253d36: Download complete\n",
      "30ca64e2860e: Verifying Checksum\n",
      "30ca64e2860e: Download complete\n",
      "98c496486cb5: Verifying Checksum\n",
      "98c496486cb5: Download complete\n",
      "cf6ff63990c9: Verifying Checksum\n",
      "cf6ff63990c9: Download complete\n",
      "0d73dcaef634: Verifying Checksum\n",
      "0d73dcaef634: Download complete\n",
      "0e753bb4cdca: Download complete\n",
      "89e015317d12: Verifying Checksum\n",
      "89e015317d12: Download complete\n",
      "61a65022eab2: Verifying Checksum\n",
      "61a65022eab2: Download complete\n",
      "9d4613b858ae: Download complete\n",
      "4e15a13e9004: Download complete\n",
      "fb979c9a76d1: Verifying Checksum\n",
      "fb979c9a76d1: Download complete\n",
      "0af71c3d2df0: Verifying Checksum\n",
      "0af71c3d2df0: Download complete\n",
      "89111f12ae60: Verifying Checksum\n",
      "89111f12ae60: Download complete\n",
      "75fd5b15b787: Verifying Checksum\n",
      "75fd5b15b787: Download complete\n",
      "4f62627df82d: Download complete\n",
      "d9b739ba638a: Verifying Checksum\n",
      "d9b739ba638a: Download complete\n",
      "ca6c11fb22c5: Verifying Checksum\n",
      "ca6c11fb22c5: Download complete\n",
      "802afda9ddfe: Verifying Checksum\n",
      "802afda9ddfe: Download complete\n",
      "fcd7199f10b4: Download complete\n",
      "47a6cf75bc34: Verifying Checksum\n",
      "47a6cf75bc34: Download complete\n",
      "e1bab5cae66b: Verifying Checksum\n",
      "e1bab5cae66b: Download complete\n",
      "615bdc6bac79: Verifying Checksum\n",
      "615bdc6bac79: Download complete\n",
      "dfd3fe17d2c5: Verifying Checksum\n",
      "dfd3fe17d2c5: Download complete\n",
      "ea04278ce919: Verifying Checksum\n",
      "ea04278ce919: Download complete\n",
      "e947aa78f022: Verifying Checksum\n",
      "e947aa78f022: Download complete\n",
      "68cd1e6a2dfe: Pull complete\n",
      "c4a5e6c74f13: Pull complete\n",
      "afec03310895: Pull complete\n",
      "44d8a5c35cf0: Pull complete\n",
      "e1bab5cae66b: Pull complete\n",
      "e5f5c15a6664: Pull complete\n",
      "8171a8ea64b5: Pull complete\n",
      "62a953797b1c: Pull complete\n",
      "899d4bcdc05c: Pull complete\n",
      "4f4fb700ef54: Pull complete\n",
      "30ca64e2860e: Pull complete\n",
      "65fe4b253d36: Pull complete\n",
      "cf6ff63990c9: Pull complete\n",
      "98c496486cb5: Pull complete\n",
      "89e015317d12: Pull complete\n",
      "0d73dcaef634: Pull complete\n",
      "0e753bb4cdca: Pull complete\n",
      "fcd7199f10b4: Pull complete\n",
      "61a65022eab2: Pull complete\n",
      "9d4613b858ae: Pull complete\n",
      "4e15a13e9004: Pull complete\n",
      "fb979c9a76d1: Pull complete\n",
      "0af71c3d2df0: Pull complete\n",
      "89111f12ae60: Pull complete\n",
      "75fd5b15b787: Pull complete\n",
      "4f62627df82d: Pull complete\n",
      "d9b739ba638a: Pull complete\n",
      "ca6c11fb22c5: Pull complete\n",
      "802afda9ddfe: Pull complete\n",
      "ea04278ce919: Pull complete\n",
      "47a6cf75bc34: Pull complete\n",
      "e947aa78f022: Pull complete\n",
      "615bdc6bac79: Pull complete\n",
      "dfd3fe17d2c5: Pull complete\n",
      "Digest: sha256:ad03b23fbd6b296236809c2817815639b58b1351fa09cb3ea16ee747e5b37767\n",
      "Status: Downloaded newer image for gcr.io/deeplearning-platform-release/tf2-gpu.2-13.py310:latest\n",
      " ---> 8880876c34d0\n",
      "Step 2/12 : ENV PYTHONUNBUFFERED True\n",
      " ---> Running in 9025c5cdaf3c\n",
      "Removing intermediate container 9025c5cdaf3c\n",
      " ---> e52678ebbb0d\n",
      "Step 3/12 : ENV APP_HOME /workspace\n",
      " ---> Running in 7293f447f6ac\n",
      "Removing intermediate container 7293f447f6ac\n",
      " ---> 02c037d913ec\n",
      "Step 4/12 : WORKDIR $APP_HOME\n",
      " ---> Running in a230d7e2c98c\n",
      "Removing intermediate container a230d7e2c98c\n",
      " ---> ff22b8871fec\n",
      "Step 5/12 : COPY /requirements.txt $APP_HOME/requirements.txt\n",
      " ---> 1efe76058f11\n",
      "Step 6/12 : RUN pip install --upgrade pip\n",
      " ---> Running in 78ce634a73d3\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.2.1)\n",
      "Collecting pip\n",
      "  Obtaining dependency information for pip from https://files.pythonhosted.org/packages/e0/63/b428aaca15fcd98c39b07ca7149e24bc14205ad0f1c80ba2b01835aedde1/pip-23.3-py3-none-any.whl.metadata\n",
      "  Downloading pip-23.3-py3-none-any.whl.metadata (3.5 kB)\n",
      "Downloading pip-23.3-py3-none-any.whl (2.1 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 27.1 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.2.1\n",
      "    Uninstalling pip-23.2.1:\n",
      "      Successfully uninstalled pip-23.2.1\n",
      "Successfully installed pip-23.3\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 78ce634a73d3\n",
      " ---> cd1e85bc1ff8\n",
      "Step 7/12 : RUN pip install --no-cache-dir -r $APP_HOME/requirements.txt\n",
      " ---> Running in dffd7bb83255\n",
      "Requirement already satisfied: google-cloud-aiplatform==1.33.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform[cloud_profiler]==1.33.1->-r /workspace/requirements.txt (line 1)) (1.33.1)\n",
      "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 2)) (2.11.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 3)) (1.23.5)\n",
      "Requirement already satisfied: tensorflow==2.13.0 in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 4)) (2.13.0)\n",
      "Collecting tf-agents==0.17.0 (from -r /workspace/requirements.txt (line 5))\n",
      "  Downloading tf_agents-0.17.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting tensorflow-datasets==4.9.0 (from -r /workspace/requirements.txt (line 6))\n",
      "  Downloading tensorflow_datasets-4.9.0-py3-none-any.whl (5.4 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.4/5.4 MB 66.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 7)) (2.13.0)\n",
      "Requirement already satisfied: tensorboard-plugin-profile in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 8)) (2.13.1)\n",
      "Collecting tensorboard-plugin-wit (from -r /workspace/requirements.txt (line 9))\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.3/781.3 kB 272.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tensorboard-data-server in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 10)) (0.7.1)\n",
      "Requirement already satisfied: tensorflow-io in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 11)) (0.32.0)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 12)) (1.26.16)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 13)) (10.0.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.33.1->google-cloud-aiplatform[cloud_profiler]==1.33.1->-r /workspace/requirements.txt (line 1)) (1.34.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.33.1->google-cloud-aiplatform[cloud_profiler]==1.33.1->-r /workspace/requirements.txt (line 1)) (1.22.3)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.33.1->google-cloud-aiplatform[cloud_profiler]==1.33.1->-r /workspace/requirements.txt (line 1)) (3.20.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.33.1->google-cloud-aiplatform[cloud_profiler]==1.33.1->-r /workspace/requirements.txt (line 1)) (23.1)\n",
      "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.33.1->google-cloud-aiplatform[cloud_profiler]==1.33.1->-r /workspace/requirements.txt (line 1)) (3.11.4)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.33.1->google-cloud-aiplatform[cloud_profiler]==1.33.1->-r /workspace/requirements.txt (line 1)) (1.10.4)\n",
      "Requirement already satisfied: shapely<2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.33.1->google-cloud-aiplatform[cloud_profiler]==1.33.1->-r /workspace/requirements.txt (line 1)) (1.8.5.post1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (1.48.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (3.9.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (2.13.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (16.0.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (0.32.0)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in /opt/conda/lib/python3.10/site-packages (from tf-agents==0.17.0->-r /workspace/requirements.txt (line 5)) (2.2.1)\n",
      "Collecting gin-config>=0.4.0 (from tf-agents==0.17.0->-r /workspace/requirements.txt (line 5))\n",
      "  Downloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.3/61.3 kB 190.3 MB/s eta 0:00:00\n",
      "Collecting gym<=0.23.0,>=0.17.0 (from tf-agents==0.17.0->-r /workspace/requirements.txt (line 5))\n",
      "  Downloading gym-0.23.0.tar.gz (624 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 624.4/624.4 kB 262.4 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pygame==2.1.3 (from tf-agents==0.17.0->-r /workspace/requirements.txt (line 5))\n",
      "  Downloading pygame-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.7/13.7 MB 94.6 MB/s eta 0:00:00\n",
      "Collecting tensorflow-probability~=0.20.1 (from tf-agents==0.17.0->-r /workspace/requirements.txt (line 5))\n",
      "  Downloading tensorflow_probability-0.20.1-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: array-record in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (0.4.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (8.1.7)\n",
      "Requirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (0.1.8)\n",
      "Requirement already satisfied: etils>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (1.5.0)\n",
      "Requirement already satisfied: promise in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (2.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (5.9.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (2.31.0)\n",
      "Requirement already satisfied: tensorflow-metadata in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (0.14.0)\n",
      "Requirement already satisfied: toml in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (4.66.1)\n",
      "\u001b[91mWARNING: google-cloud-aiplatform 1.33.1 does not provide the extra 'cloud-profiler'\n",
      "\u001b[0mCollecting werkzeug<2.1.0dev,>=2.0.0 (from google-cloud-aiplatform[cloud_profiler]==1.33.1->-r /workspace/requirements.txt (line 1))\n",
      "  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 289.2/289.2 kB 266.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->-r /workspace/requirements.txt (line 2)) (2.23.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->-r /workspace/requirements.txt (line 2)) (2.3.3)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->-r /workspace/requirements.txt (line 2)) (2.6.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4))\n",
      "  Downloading grpcio-1.59.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r /workspace/requirements.txt (line 7)) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r /workspace/requirements.txt (line 7)) (3.4.4)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r /workspace/requirements.txt (line 7)) (0.41.2)\n",
      "Requirement already satisfied: gviz-api>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard-plugin-profile->-r /workspace/requirements.txt (line 8)) (1.10.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (2023.9.2)\n",
      "Requirement already satisfied: importlib_resources in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (6.1.0)\n",
      "Requirement already satisfied: zipp in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (3.17.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.33.1->google-cloud-aiplatform[cloud_profiler]==1.33.1->-r /workspace/requirements.txt (line 1)) (1.60.0)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.33.1->google-cloud-aiplatform[cloud_profiler]==1.33.1->-r /workspace/requirements.txt (line 1)) (1.48.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage->-r /workspace/requirements.txt (line 2)) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage->-r /workspace/requirements.txt (line 2)) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage->-r /workspace/requirements.txt (line 2)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->-r /workspace/requirements.txt (line 7)) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.33.1->google-cloud-aiplatform[cloud_profiler]==1.33.1->-r /workspace/requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform==1.33.1->google-cloud-aiplatform[cloud_profiler]==1.33.1->-r /workspace/requirements.txt (line 1)) (0.12.6)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-resumable-media>=2.6.0->google-cloud-storage->-r /workspace/requirements.txt (line 2)) (1.5.0)\n",
      "Collecting gym-notices>=0.0.4 (from gym<=0.23.0,>=0.17.0->tf-agents==0.17.0->-r /workspace/requirements.txt (line 5))\n",
      "  Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (2023.7.22)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from tensorflow-probability~=0.20.1->tf-agents==0.17.0->-r /workspace/requirements.txt (line 5)) (5.1.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage->-r /workspace/requirements.txt (line 2)) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->-r /workspace/requirements.txt (line 7)) (3.2.2)\n",
      "Downloading tf_agents-0.17.0-py3-none-any.whl (1.4 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 272.4 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.59.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.3/5.3 MB 234.0 MB/s eta 0:00:00\n",
      "Downloading tensorflow_probability-0.20.1-py2.py3-none-any.whl (6.9 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.9/6.9 MB 220.9 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (pyproject.toml): started\n",
      "  Building wheel for gym (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for gym: filename=gym-0.23.0-py3-none-any.whl size=697631 sha256=2e535eb0dcb041fe57db7aef35056b3385656dd7a751214bb55b84c407f82f27\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ayph2mhr/wheels/3d/6f/b4/3991d4fae11d0ecb0754c11cc1b4e7745012850da4efaaf0b1\n",
      "Successfully built gym\n",
      "Installing collected packages: tensorboard-plugin-wit, gym-notices, gin-config, werkzeug, tensorflow-probability, pygame, gym, grpcio, tf-agents, tensorflow-datasets\n",
      "  Attempting uninstall: werkzeug\n",
      "    Found existing installation: Werkzeug 2.1.2\n",
      "    Uninstalling Werkzeug-2.1.2:\n",
      "      Successfully uninstalled Werkzeug-2.1.2\n",
      "  Attempting uninstall: tensorflow-probability\n",
      "    Found existing installation: tensorflow-probability 0.21.0\n",
      "    Uninstalling tensorflow-probability-0.21.0:\n",
      "      Successfully uninstalled tensorflow-probability-0.21.0\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.48.0\n",
      "    Uninstalling grpcio-1.48.0:\n",
      "      Successfully uninstalled grpcio-1.48.0\n",
      "  Attempting uninstall: tensorflow-datasets\n",
      "    Found existing installation: tensorflow-datasets 4.9.3\n",
      "    Uninstalling tensorflow-datasets-4.9.3:\n",
      "      Successfully uninstalled tensorflow-datasets-4.9.3\n",
      "Successfully installed gin-config-0.5.0 grpcio-1.58.0 gym-0.23.0 gym-notices-0.0.8 pygame-2.1.3 tensorboard-plugin-wit-1.8.1 tensorflow-datasets-4.9.0 tensorflow-probability-0.20.1 tf-agents-0.17.0 werkzeug-2.0.3\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container dffd7bb83255\n",
      " ---> 57573d6abb20\n",
      "Step 8/12 : RUN pip install cloudml-hypertune\n",
      " ---> Running in fa06dfddf6dc\n",
      "Collecting cloudml-hypertune\n",
      "  Downloading cloudml-hypertune-0.1.0.dev6.tar.gz (3.2 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: cloudml-hypertune\n",
      "  Building wheel for cloudml-hypertune (setup.py): started\n",
      "  Building wheel for cloudml-hypertune (setup.py): finished with status 'done'\n",
      "  Created wheel for cloudml-hypertune: filename=cloudml_hypertune-0.1.0.dev6-py2.py3-none-any.whl size=3973 sha256=09ef87b94289941ea80fafe0c4a700b4c2402652c3a943a10d64051a4d6e75d6\n",
      "  Stored in directory: /root/.cache/pip/wheels/c6/2d/bb/9c72de7c488cd8e60172c4920c09e404c490020162205b64ba\n",
      "Successfully built cloudml-hypertune\n",
      "Installing collected packages: cloudml-hypertune\n",
      "Successfully installed cloudml-hypertune-0.1.0.dev6\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91mWARNING: There was an error checking the latest version of pip.\n",
      "\u001b[0mRemoving intermediate container fa06dfddf6dc\n",
      " ---> 5797f73c964d\n",
      "Step 9/12 : RUN apt update && apt -y install nvtop\n",
      " ---> Running in b0eeb8c46f5e\n",
      "\u001b[91m\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
      "\n",
      "\u001b[0mGet:1 http://packages.cloud.google.com/apt gcsfuse-focal InRelease [1299 B]\n",
      "Get:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
      "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1581 B]\n",
      "Get:4 https://packages.cloud.google.com/apt cloud-sdk InRelease [6361 B]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy InRelease [270 kB]\n",
      "Get:6 http://packages.cloud.google.com/apt gcsfuse-focal/main amd64 Packages [15.7 kB]\n",
      "Get:7 http://packages.cloud.google.com/apt gcsfuse-focal/main all Packages [750 B]\n",
      "Get:8 https://packages.cloud.google.com/apt google-fast-socket InRelease [5015 B]\n",
      "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [518 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
      "Get:11 https://packages.cloud.google.com/apt cloud-sdk/main amd64 Packages [530 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
      "Get:13 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [44.0 kB]\n",
      "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1226 kB]\n",
      "Get:15 https://packages.cloud.google.com/apt google-fast-socket/main amd64 Packages [447 B]\n",
      "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1082 kB]\n",
      "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1005 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 Packages [1792 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 Packages [266 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu jammy/restricted amd64 Packages [164 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu jammy/universe amd64 Packages [17.5 MB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1351 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1271 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1254 kB]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [49.8 kB]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [28.1 kB]\n",
      "Get:27 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [50.4 kB]\n",
      "Fetched 28.7 MB in 2s (12.2 MB/s)\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "22 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "\u001b[91mW: http://packages.cloud.google.com/apt/dists/gcsfuse-focal/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
      "W: https://packages.cloud.google.com/apt/dists/google-fast-socket/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
      "\u001b[0m\u001b[91m\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
      "\u001b[0mReading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following NEW packages will be installed:\n",
      "  nvtop\n",
      "0 upgraded, 1 newly installed, 0 to remove and 22 not upgraded.\n",
      "Need to get 43.9 kB of archives.\n",
      "After this operation, 106 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 nvtop amd64 1.2.2-1 [43.9 kB]\n",
      "\u001b[91mdebconf: unable to initialize frontend: Dialog\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\n",
      "debconf: falling back to frontend: Readline\n",
      "\u001b[0m\u001b[91mdebconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "\u001b[0m\u001b[91mdpkg-preconfigure: unable to re-open stdin: \n",
      "\u001b[0mFetched 43.9 kB in 0s (269 kB/s)\n",
      "Selecting previously unselected package nvtop.\n",
      "(Reading database ... 93562 files and directories currently installed.)\n",
      "Preparing to unpack .../nvtop_1.2.2-1_amd64.deb ...\n",
      "Unpacking nvtop (1.2.2-1) ...\n",
      "Setting up nvtop (1.2.2-1) ...\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "Removing intermediate container b0eeb8c46f5e\n",
      " ---> 844a8c85a6ed\n",
      "Step 10/12 : COPY src/per_arm_rl $APP_HOME/src/per_arm_rl\n",
      " ---> 85d1b0a48751\n",
      "Step 11/12 : RUN export PYTHONPATH=${PYTHONPATH}:${APP_HOME}/\n",
      " ---> Running in 4d272d5ab47b\n",
      "Removing intermediate container 4d272d5ab47b\n",
      " ---> aef01f92b555\n",
      "Step 12/12 : ENTRYPOINT [\"python3\", \"-m\", \"src.per_arm_rl.perarm_task\"]\n",
      " ---> Running in a098a8b2d817\n",
      "Removing intermediate container a098a8b2d817\n",
      " ---> 38bbb77b8378\n",
      "Successfully built 38bbb77b8378\n",
      "Successfully tagged gcr.io/hybrid-vertex/train-perarm-feats-v2-01:latest\n",
      "PUSH\n",
      "Pushing gcr.io/hybrid-vertex/train-perarm-feats-v2-01\n",
      "The push refers to repository [gcr.io/hybrid-vertex/train-perarm-feats-v2-01]\n",
      "4bd6601852e7: Preparing\n",
      "4e19778d881d: Preparing\n",
      "e027909364f0: Preparing\n",
      "3c1801492bdd: Preparing\n",
      "2a3f9626ac19: Preparing\n",
      "facef06b8249: Preparing\n",
      "d06cb4522a62: Preparing\n",
      "facef06b8249: Waiting\n",
      "0e9b0596958e: Preparing\n",
      "37dfaed05757: Preparing\n",
      "52e3925fce91: Preparing\n",
      "0e9b0596958e: Waiting\n",
      "dc15e08d5960: Preparing\n",
      "4aadbc27ec1e: Preparing\n",
      "37dfaed05757: Waiting\n",
      "b78cb0998678: Preparing\n",
      "b890a915c8a5: Preparing\n",
      "dc15e08d5960: Waiting\n",
      "7382c6e2ecf8: Preparing\n",
      "ac46e78bec65: Preparing\n",
      "4aadbc27ec1e: Waiting\n",
      "1266462c996d: Preparing\n",
      "95efa7e2a51f: Preparing\n",
      "7382c6e2ecf8: Waiting\n",
      "ac46e78bec65: Waiting\n",
      "2f0d39d03cb4: Preparing\n",
      "95efa7e2a51f: Waiting\n",
      "b78cb0998678: Waiting\n",
      "e633bd34c9c6: Preparing\n",
      "a0a8fcb3c29d: Preparing\n",
      "2f0d39d03cb4: Waiting\n",
      "f39cdc343f95: Preparing\n",
      "b890a915c8a5: Waiting\n",
      "c5df5bef04cf: Preparing\n",
      "97365e5f5b28: Preparing\n",
      "1266462c996d: Waiting\n",
      "e633bd34c9c6: Waiting\n",
      "a0a8fcb3c29d: Waiting\n",
      "e7647d31e0bf: Preparing\n",
      "5f1d7383305a: Preparing\n",
      "4844d30f7727: Preparing\n",
      "ce171cb8a06c: Preparing\n",
      "8b3dbce3dead: Preparing\n",
      "c622d5d4184e: Preparing\n",
      "69982b09610b: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "25f4219e7120: Preparing\n",
      "a4e299459cbd: Preparing\n",
      "0235cf47cbae: Preparing\n",
      "f39cdc343f95: Waiting\n",
      "c5df5bef04cf: Waiting\n",
      "2971cdbb4b45: Preparing\n",
      "e7647d31e0bf: Waiting\n",
      "8374b2bc65e7: Preparing\n",
      "5f1d7383305a: Waiting\n",
      "3b93a6feba89: Preparing\n",
      "4844d30f7727: Waiting\n",
      "ce171cb8a06c: Waiting\n",
      "b15400eb0fa7: Preparing\n",
      "29ecaf0c2ae0: Preparing\n",
      "8b3dbce3dead: Waiting\n",
      "41e673079fce: Preparing\n",
      "a4e299459cbd: Waiting\n",
      "c622d5d4184e: Waiting\n",
      "0235cf47cbae: Waiting\n",
      "69982b09610b: Waiting\n",
      "cda9215846ee: Preparing\n",
      "2971cdbb4b45: Waiting\n",
      "5f70bf18a086: Waiting\n",
      "c5eafb4bee8f: Preparing\n",
      "25f4219e7120: Waiting\n",
      "81182eb0608d: Preparing\n",
      "8374b2bc65e7: Waiting\n",
      "f2baf76d88ee: Preparing\n",
      "b15400eb0fa7: Waiting\n",
      "cdd7c7392317: Preparing\n",
      "29ecaf0c2ae0: Waiting\n",
      "cda9215846ee: Waiting\n",
      "41e673079fce: Waiting\n",
      "c5eafb4bee8f: Waiting\n",
      "f2baf76d88ee: Waiting\n",
      "81182eb0608d: Waiting\n",
      "cdd7c7392317: Waiting\n",
      "e027909364f0: Pushed\n",
      "4bd6601852e7: Pushed\n",
      "facef06b8249: Pushed\n",
      "0e9b0596958e: Layer already exists\n",
      "d06cb4522a62: Pushed\n",
      "37dfaed05757: Layer already exists\n",
      "52e3925fce91: Layer already exists\n",
      "4aadbc27ec1e: Layer already exists\n",
      "dc15e08d5960: Layer already exists\n",
      "b78cb0998678: Layer already exists\n",
      "b890a915c8a5: Layer already exists\n",
      "ac46e78bec65: Layer already exists\n",
      "7382c6e2ecf8: Layer already exists\n",
      "1266462c996d: Layer already exists\n",
      "95efa7e2a51f: Layer already exists\n",
      "2f0d39d03cb4: Layer already exists\n",
      "e633bd34c9c6: Layer already exists\n",
      "a0a8fcb3c29d: Layer already exists\n",
      "f39cdc343f95: Layer already exists\n",
      "c5df5bef04cf: Layer already exists\n",
      "97365e5f5b28: Layer already exists\n",
      "e7647d31e0bf: Layer already exists\n",
      "5f1d7383305a: Layer already exists\n",
      "4844d30f7727: Layer already exists\n",
      "ce171cb8a06c: Layer already exists\n",
      "8b3dbce3dead: Layer already exists\n",
      "c622d5d4184e: Layer already exists\n",
      "69982b09610b: Layer already exists\n",
      "5f70bf18a086: Layer already exists\n",
      "25f4219e7120: Layer already exists\n",
      "a4e299459cbd: Layer already exists\n",
      "0235cf47cbae: Layer already exists\n",
      "2a3f9626ac19: Pushed\n",
      "2971cdbb4b45: Layer already exists\n",
      "8374b2bc65e7: Layer already exists\n",
      "3b93a6feba89: Layer already exists\n",
      "29ecaf0c2ae0: Layer already exists\n",
      "b15400eb0fa7: Layer already exists\n",
      "41e673079fce: Layer already exists\n",
      "c5eafb4bee8f: Layer already exists\n",
      "cda9215846ee: Layer already exists\n",
      "81182eb0608d: Layer already exists\n",
      "cdd7c7392317: Layer already exists\n",
      "f2baf76d88ee: Layer already exists\n",
      "4e19778d881d: Pushed\n",
      "3c1801492bdd: Pushed\n",
      "latest: digest: sha256:482e88b7ec8b383670b8faebac77e0792f0ec03dbfb88f2d4412c74c46a877d9 size: 9970\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                       IMAGES                                                   STATUS\n",
      "04489209-8dae-4157-a6fa-1a5f31283fec  2023-10-18T20:14:43+00:00  4M40S     gs://hybrid-vertex_cloudbuild/source/1697660082.826936-df3db4fcdf1a44d4806100dc518d1725.tgz  gcr.io/hybrid-vertex/train-perarm-feats-v2-01 (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "! gcloud builds submit --config ./cloudbuild.yaml \\\n",
    "    --substitutions _DOCKERNAME=$DOCKERNAME,_IMAGE_URI=$IMAGE_URI,_FILE_LOCATION=$FILE_LOCATION \\\n",
    "    --timeout=2h \\\n",
    "    --machine-type=$MACHINE_TYPE \\\n",
    "    --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629eb246-f2fc-48a0-8478-4f9c99dddd0b",
   "metadata": {},
   "source": [
    "## (Optional) Build Image Locally\n",
    "\n",
    "Building images with Cloud Build is best practices\n",
    "* images are centrally stored and better managed for robust CI/CD\n",
    "* building images on local workbench instance can alter notebook image config (base image for notebooks vs train images are different)\n",
    "* if building locally, consider using virutal environments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5278eb39-1dbb-48fd-b872-9cd55643a1ed",
   "metadata": {},
   "source": [
    "Provide a name for your dockerfile and make sure you are authenticated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53874306-777f-459f-9250-4a59dbc283a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gcloud auth configure-docker $REGION-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25faef9c-cb5e-425d-9ee6-7ae8003a95af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy these commands into terminal:\n",
      "\n",
      "virtualenv vertex_env\n",
      "source vertex_env/bin/activate\n"
     ]
    }
   ],
   "source": [
    "print(\"copy these commands into terminal:\\n\")\n",
    "print(f\"virtualenv vertex_env\")\n",
    "print(f\"source vertex_env/bin/activate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "027de7fe-dd2a-4be5-80c4-877f7abe4753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy these commands into terminal:\n",
      "\n",
      "export REMOTE_IMAGE_NAME=us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/train-perarm-feats-v2\n",
      "export DOCKERNAME=Dockerfile_perarm_feats\n",
      "docker build -t $REMOTE_IMAGE_NAME -f ./$DOCKERNAME .\n"
     ]
    }
   ],
   "source": [
    "# # set variables if running in terminal\n",
    "print(\"copy these commands into terminal:\\n\")\n",
    "print(f\"export REMOTE_IMAGE_NAME={REMOTE_IMAGE_NAME}\")\n",
    "print(f\"export DOCKERNAME={DOCKERNAME}\")\n",
    "print(f\"docker build -t $REMOTE_IMAGE_NAME -f ./$DOCKERNAME .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a82cbe6-0ed5-478f-a38f-e6dedc114e2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !docker build -t $REMOTE_IMAGE_NAME -f $DOCKERNAME ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6110439-f66a-4d6b-8105-17a08ce9b8da",
   "metadata": {},
   "source": [
    "### Push container to Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54a714cf-053c-4f14-b375-2a42ae2092f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy this command into terminal:\n",
      "\n",
      "docker push $REMOTE_IMAGE_NAME\n"
     ]
    }
   ],
   "source": [
    "# ### push the container to registry\n",
    "\n",
    "print(\"copy this command into terminal:\\n\")\n",
    "print(f\"docker push $REMOTE_IMAGE_NAME\")\n",
    "\n",
    "# !docker push $REMOTE_IMAGE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bc85f6-a86e-48f2-a040-89f35376d57c",
   "metadata": {},
   "source": [
    "### GPU profiling\n",
    "\n",
    "> enter these commands in the Vertex interactive terminal:\n",
    "\n",
    "```bash\n",
    "sudo apt update\n",
    "sudo apt -y install nvtop\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18df8169-e4ed-45fb-9279-85e966bc6f3e",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
