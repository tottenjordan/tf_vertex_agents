{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64583cdb-2502-4f40-a254-8fa68abe7a32",
   "metadata": {},
   "source": [
    "# Build custom container for matrix-factorization-based simulation environment in Vertex AI training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e1beb37-0c48-4110-8ca0-24ab78c72b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents/01-baseline-perarm-bandit\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66298299-d4ad-460e-8ab3-ea9fbc012086",
   "metadata": {},
   "source": [
    "## Load env config\n",
    "\n",
    "* use the prefix from `00-env-setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1d2542f-d87b-436d-b4bb-08edcbb532ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: rec-bandits-v2\n"
     ]
    }
   ],
   "source": [
    "# PREFIX = 'mabv1'\n",
    "VERSION        = \"v2\"                       # TODO\n",
    "PREFIX         = f'rec-bandits-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35449112-3c26-4ea9-8c3a-21c283951350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"rec-bandits-v2\"\n",
      "VERSION                  = \"v2\"\n",
      "\n",
      "BUCKET_NAME              = \"rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://rec-bandits-v2-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "DATA_PATH_KFP_DEMO       = \"gs://rec-bandits-v2-hybrid-vertex-bucket/data/kfp_demo_data/u.data\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BIGQUERY_DATASET_NAME    = \"mvlens_rec_bandits_v2\"\n",
      "BIGQUERY_TABLE_NAME      = \"training_dataset\"\n",
      "\n",
      "REPOSITORY               = \"rl-movielens-rec-bandits-v2\"\n",
      "\n",
      "DOCKERNAME_01            = \"Dockerfile_train_my_perarm_env\"\n",
      "IMAGE_NAME_01            = \"train-my-perarm-env-v2\"\n",
      "IMAGE_URI_01             = \"gcr.io/hybrid-vertex/train-my-perarm-env-v2\"\n",
      "\n",
      "DOCKERNAME_02            = \"Dockerfile_perarm_feats\"\n",
      "IMAGE_NAME_02            = \"train-perarm-feats-v2\"\n",
      "IMAGE_URI_02             = \"gcr.io/hybrid-vertex/train-perarm-feats-v2\"\n",
      "\n",
      "DOCKERNAME_03            = \"Dockerfile_ranking_bandit\"\n",
      "IMAGE_NAME_03            = \"train-rank-bandit-v2\"\n",
      "IMAGE_URI_03             = \"gcr.io/hybrid-vertex/train-rank-bandit-v2\"\n",
      "\n",
      "DOCKERNAME_04            = \"Dockerfile_train_mab_e2e\"\n",
      "IMAGE_NAME_04            = \"train-mab-e2e-v2\"\n",
      "IMAGE_URI_04             = \"gcr.io/hybrid-vertex/train-mab-e2e-v2\"\n",
      "\n",
      "DOCKERNAME_04_pred       = \"Dockerfile_pred_mab_e2e\"\n",
      "IMAGE_NAME_04_pred       = \"pred-mab-e2e-v2\"\n",
      "IMAGE_URI_04_pred        = \"gcr.io/hybrid-vertex/pred-mab-e2e-v2\"\n",
      "\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/local_docker_tfa\"\n",
      "\n",
      "REPO_DOCKER_PATH_PREFIX  = \"src\"\n",
      "RL_SUB_DIR               = \"per_arm_rl\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b16af06-e188-4f4e-a04b-4e0eb8873ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gsutil ls $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be79c652-45c8-4b5f-b410-4908829375a3",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92272ed8-bfb5-4b40-b7f4-cdbe029f3bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261a452d-8ce7-427b-8091-d7d41c57e556",
   "metadata": {},
   "source": [
    "# Build Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d192a4dd-b3e1-4c48-b69f-fd022078e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tree src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9bdef1-ac23-49be-96fd-25795f483643",
   "metadata": {},
   "source": [
    "## Container Image Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4076530-a340-4c57-91af-e2decd035b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOCKERNAME_TRAIN_MYENV = \"Dockerfile_train_my_perarm_env\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eedbe408-e2fe-4944-912f-f2b1f6587440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOCKERNAME_01          = Dockerfile_train_my_perarm_env\n",
      "REPOSITORY             = rl-movielens-rec-bandits-v2\n",
      "IMAGE_NAME_01          = train-my-perarm-env-v2\n",
      "REMOTE_IMAGE_NAME      = us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/local_docker_tfa\n",
      "IMAGE_URI_01           = gcr.io/hybrid-vertex/train-my-perarm-env-v2\n"
     ]
    }
   ],
   "source": [
    "print(f\"DOCKERNAME_01          = {DOCKERNAME_01}\")\n",
    "print(f\"REPOSITORY             = {REPOSITORY}\")\n",
    "print(f\"IMAGE_NAME_01          = {IMAGE_NAME_01}\")\n",
    "print(f\"REMOTE_IMAGE_NAME      = {REMOTE_IMAGE_NAME}\")\n",
    "print(f\"IMAGE_URI_01           = {IMAGE_URI_01}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf953a8e-d282-4d7b-9a7d-fd0bee28c70a",
   "metadata": {},
   "source": [
    "## Create Artifact Repository\n",
    "\n",
    "If you don't have an existing artifact repository, create one using the gcloud command below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8288932-054a-46e6-90e8-326e015f2115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gcloud artifacts repositories create $REPOSITORY --repository-format=docker --location=$LOCATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1374bc-7b85-4e65-86ab-2721ce4908b3",
   "metadata": {},
   "source": [
    "## Create Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88a8b25d-e55c-4a00-ab0e-1151eae8eaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/tf_vertex_agents'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root_path = '..'\n",
    "os.chdir(root_path)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bffd9bb-6d22-4d4e-9eb8-893472702837",
   "metadata": {},
   "source": [
    "### Create train image\n",
    "\n",
    "* see [example Dockerfile for GPU](https://github.com/GoogleCloudPlatform/cloudml-samples/blob/main/pytorch/containers/quickstart/mnist/Dockerfile-gpu) jobs in Vertex AI\n",
    "* see deep learning container [example here](https://cloud.google.com/deep-learning-containers/docs/derivative-container), and here for [available DL containers](https://cloud.google.com/deep-learning-containers/docs/choosing-container#versions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7022f8d1-43d0-4291-91b8-4cb27491c2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_profiling : True\n"
     ]
    }
   ],
   "source": [
    "gpu_profiling = True # True | False\n",
    "\n",
    "print(f\"gpu_profiling : {gpu_profiling}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4596864b-f059-438d-a04f-7416c436b644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_BASE_IMAGE : gcr.io/deeplearning-platform-release/tf2-gpu.2-13.py310\n",
      "NVTOP_RUN        : RUN apt update && apt -y install nvtop\n",
      "RUN_EXPORT       : RUN export PYTHONPATH=${PYTHONPATH}:${APP_HOME}/\n"
     ]
    }
   ],
   "source": [
    "if gpu_profiling:\n",
    "    # TRAIN_BASE_IMAGE = 'tensorflow/tensorflow:2.13.0-gpu'\n",
    "    TRAIN_BASE_IMAGE = 'gcr.io/deeplearning-platform-release/tf2-gpu.2-13.py310'\n",
    "    NVTOP_RUN = 'RUN apt update && apt -y install nvtop'\n",
    "    # NVTOP_RUN = 'RUN apt-get update && apt-get -y install nvtop'\n",
    "else:\n",
    "    TRAIN_BASE_IMAGE = 'python:3.10'\n",
    "    NVTOP_RUN = None\n",
    "    \n",
    "RUN_EXPORT = \"RUN export PYTHONPATH=${PYTHONPATH}:${APP_HOME}/\"\n",
    "    \n",
    "print(f\"TRAIN_BASE_IMAGE : {TRAIN_BASE_IMAGE}\")\n",
    "print(f\"NVTOP_RUN        : {NVTOP_RUN}\")\n",
    "print(f\"RUN_EXPORT       : {RUN_EXPORT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b1b1fc6-022b-4e56-b62f-673179bab7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FROM gcr.io/deeplearning-platform-release/tf2-gpu.2-13.py310\n",
      "\n",
      "ENV PYTHONUNBUFFERED True\n",
      "\n",
      "ENV APP_HOME /workspace\n",
      "\n",
      "WORKDIR $APP_HOME\n",
      "\n",
      "COPY /requirements.txt $APP_HOME/requirements.txt\n",
      "RUN pip install --upgrade pip\n",
      "RUN pip install --no-cache-dir -r $APP_HOME/requirements.txt\n",
      "RUN pip install cloudml-hypertune\n",
      "\n",
      "RUN apt update && apt -y install nvtop\n",
      "\n",
      "COPY src/per_arm_rl $APP_HOME/src/per_arm_rl\n",
      "\n",
      "RUN export PYTHONPATH=${PYTHONPATH}:${APP_HOME}/\n",
      "\n",
      "RUN pip freeze | grep wrapt\n",
      "\n",
      "# Sets up the entry point to invoke the task.\n",
      "ENTRYPOINT [\"python3\", \"-m\", \"src.per_arm_rl.perarm_task\"]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dockerfile = f'''\n",
    "FROM {TRAIN_BASE_IMAGE}\n",
    "\n",
    "ENV PYTHONUNBUFFERED True\n",
    "\n",
    "ENV APP_HOME /workspace\n",
    "\n",
    "WORKDIR $APP_HOME\n",
    "\n",
    "COPY /requirements.txt $APP_HOME/requirements.txt\n",
    "RUN pip install --upgrade pip\n",
    "RUN pip install --no-cache-dir -r $APP_HOME/requirements.txt\n",
    "RUN pip install cloudml-hypertune\n",
    "\n",
    "{NVTOP_RUN}\n",
    "\n",
    "COPY src/per_arm_rl $APP_HOME/src/per_arm_rl\n",
    "\n",
    "{RUN_EXPORT}\n",
    "\n",
    "RUN pip freeze | grep wrapt\n",
    "\n",
    "# Sets up the entry point to invoke the task.\n",
    "ENTRYPOINT [\"python3\", \"-m\", \"src.per_arm_rl.perarm_task\"]\n",
    "'''\n",
    "print(dockerfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04bd12e-c61b-4a5c-b2cb-b7843642ce0e",
   "metadata": {},
   "source": [
    "## Build image with Cloud Build\n",
    "\n",
    "Building images with Cloud Build is best practices\n",
    "* images are centrally stored and better managed for robust CI/CD\n",
    "* building images on local workbench instance can alter notebook image config (base image for notebooks vs train images are different)\n",
    "* if building locally, consider using virutal environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33d4d92a-77fc-4d3a-b730-68330cca68a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tf_vertex_agents\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb3ef36-2cfe-4199-963b-6c65bd0ec621",
   "metadata": {},
   "source": [
    "#### set `.gcloudignore`\n",
    "* to adjust this see the `gcloudignore` section at the end of `00-env-setup.ipynb` notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4e381c6-6b3c-40e1-a1d3-b959ab7185b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .gcloudignore\n"
     ]
    }
   ],
   "source": [
    "%%writefile .gcloudignore\n",
    ".gcloudignore\n",
    "WIP/*\n",
    "imgs/*\n",
    "learning/*\n",
    "*.pkl\n",
    "*.png\n",
    "*.ipynb\n",
    ".git\n",
    ".github\n",
    ".gitignore\n",
    ".DS_Store\n",
    "*.md\n",
    "*.tfrecord\n",
    ".ipynb_checkpoints/*\n",
    "*cpython-37.pyc\n",
    "**.cpython-310.pyc\n",
    "*/__pycache__/*\n",
    "src/ranking/*\n",
    "src/archive/*\n",
    "src/perarm_features/*\n",
    "04-pipelines/*\n",
    "03-ranking/*\n",
    "02-perarm-features-bandit/*\n",
    "src/pred/*\n",
    "src/serve/*\n",
    "Dockerfile_perarm_feats\n",
    "Dockerfile_perarm_feats_tpu\n",
    "Dockerfile_predict_mab_02\n",
    "vertex_env/*\n",
    "credentials.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f9a8891-faa3-4659-a36e-521bf9f186e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requirements.txt\n",
      "Dockerfile_train_my_perarm_env\n",
      "pred_instances.json\n",
      "Dockerfile_predict_mab_02e\n",
      "cloudbuild.yaml\n",
      "src/per_arm_rl/utils_config.py\n",
      "src/per_arm_rl/perarm_task.py\n",
      "src/per_arm_rl/__init__.py\n",
      "src/per_arm_rl/my_per_arm_py_env.py\n",
      "src/per_arm_rl/policy_util.py\n",
      "src/per_arm_rl/train_utils.py\n",
      "src/per_arm_rl/trainer_baseline.py\n",
      "src/per_arm_rl/data_utils.py\n",
      "src/per_arm_rl/data_config.py\n",
      "01-baseline-perarm-bandit/result.json\n"
     ]
    }
   ],
   "source": [
    "# check eligble files\n",
    "!gcloud meta list-files-for-upload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b72f42a-d45e-44da-82c1-3d55ca6c6d7d",
   "metadata": {},
   "source": [
    "### Submit container to Cloud Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e3b8e87-3e4c-410c-a554-3be3b8ed3e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOCKERNAME_01 : Dockerfile_train_my_perarm_env\n",
      "IMAGE_URI_01  : gcr.io/hybrid-vertex/train-my-perarm-env-v2\n",
      "FILE_LOCATION : .\n",
      "MACHINE_TYPE  : e2-highcpu-32\n"
     ]
    }
   ],
   "source": [
    "# image definitions for training\n",
    "MACHINE_TYPE            ='e2-highcpu-32'\n",
    "FILE_LOCATION           = \".\" # './src'\n",
    "\n",
    "print(f\"DOCKERNAME_01 : {DOCKERNAME_01}\")\n",
    "print(f\"IMAGE_URI_01  : {IMAGE_URI_01}\")\n",
    "print(f\"FILE_LOCATION : {FILE_LOCATION}\")\n",
    "print(f\"MACHINE_TYPE  : {MACHINE_TYPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d11ac85-16f7-4050-8632-cb6e4337a65a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 15 file(s) totalling 94.0 KiB before compression.\n",
      "Uploading tarball of [.] to [gs://hybrid-vertex_cloudbuild/source/1699972785.657103-a6bdaba21a2a4d858eb44defe6aca8cf.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/hybrid-vertex/locations/global/builds/50cb7b39-c1c1-46c8-928a-8242e75ac448].\n",
      "Logs are available at [ https://console.cloud.google.com/cloud-build/builds/50cb7b39-c1c1-46c8-928a-8242e75ac448?project=934903580331 ].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"50cb7b39-c1c1-46c8-928a-8242e75ac448\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://hybrid-vertex_cloudbuild/source/1699972785.657103-a6bdaba21a2a4d858eb44defe6aca8cf.tgz#1699972786059859\n",
      "Copying gs://hybrid-vertex_cloudbuild/source/1699972785.657103-a6bdaba21a2a4d858eb44defe6aca8cf.tgz#1699972786059859...\n",
      "/ [1 files][ 23.6 KiB/ 23.6 KiB]                                                \n",
      "Operation completed over 1 objects/23.6 KiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  122.4kB\n",
      "Step 1/12 : FROM gcr.io/deeplearning-platform-release/tf2-gpu.2-13.py310\n",
      "latest: Pulling from deeplearning-platform-release/tf2-gpu.2-13.py310\n",
      "6b851dcae6ca: Pulling fs layer\n",
      "4586c00479c6: Pulling fs layer\n",
      "4304fa233a80: Pulling fs layer\n",
      "afa3f70b397f: Pulling fs layer\n",
      "d963a42bc712: Pulling fs layer\n",
      "68cd1e6a2dfe: Pulling fs layer\n",
      "c4a5e6c74f13: Pulling fs layer\n",
      "afec03310895: Pulling fs layer\n",
      "44d8a5c35cf0: Pulling fs layer\n",
      "e1bab5cae66b: Pulling fs layer\n",
      "e5f5c15a6664: Pulling fs layer\n",
      "8171a8ea64b5: Pulling fs layer\n",
      "1c247d9a49f1: Pulling fs layer\n",
      "a0188afe0979: Pulling fs layer\n",
      "4f4fb700ef54: Pulling fs layer\n",
      "13eda56b8595: Pulling fs layer\n",
      "0910e2e41b78: Pulling fs layer\n",
      "fdb650ecd05f: Pulling fs layer\n",
      "af3f3505aac5: Pulling fs layer\n",
      "8643f31dbc8c: Pulling fs layer\n",
      "ab79507ae6b1: Pulling fs layer\n",
      "a9b3ebe80be7: Pulling fs layer\n",
      "e36195592140: Pulling fs layer\n",
      "9dc6bee1bcb0: Pulling fs layer\n",
      "2c5f4efecf9a: Pulling fs layer\n",
      "a2a792fc5b81: Pulling fs layer\n",
      "f248718bd1c7: Pulling fs layer\n",
      "aa835be7741f: Pulling fs layer\n",
      "95c9ea485716: Pulling fs layer\n",
      "2e0b9790ff72: Pulling fs layer\n",
      "672fc9109cbf: Pulling fs layer\n",
      "19a58815e257: Pulling fs layer\n",
      "aec883f70f16: Pulling fs layer\n",
      "cc4049f8d982: Pulling fs layer\n",
      "051225d1252b: Pulling fs layer\n",
      "aa254f6f7da1: Pulling fs layer\n",
      "db305fcd60dd: Pulling fs layer\n",
      "a83df4e85ed4: Pulling fs layer\n",
      "39da51cbcb48: Pulling fs layer\n",
      "afa3f70b397f: Waiting\n",
      "d963a42bc712: Waiting\n",
      "68cd1e6a2dfe: Waiting\n",
      "9dc6bee1bcb0: Waiting\n",
      "c4a5e6c74f13: Waiting\n",
      "2c5f4efecf9a: Waiting\n",
      "afec03310895: Waiting\n",
      "a2a792fc5b81: Waiting\n",
      "44d8a5c35cf0: Waiting\n",
      "f248718bd1c7: Waiting\n",
      "e1bab5cae66b: Waiting\n",
      "aa835be7741f: Waiting\n",
      "e5f5c15a6664: Waiting\n",
      "8171a8ea64b5: Waiting\n",
      "95c9ea485716: Waiting\n",
      "2e0b9790ff72: Waiting\n",
      "672fc9109cbf: Waiting\n",
      "1c247d9a49f1: Waiting\n",
      "19a58815e257: Waiting\n",
      "aec883f70f16: Waiting\n",
      "cc4049f8d982: Waiting\n",
      "051225d1252b: Waiting\n",
      "aa254f6f7da1: Waiting\n",
      "db305fcd60dd: Waiting\n",
      "a83df4e85ed4: Waiting\n",
      "39da51cbcb48: Waiting\n",
      "a0188afe0979: Waiting\n",
      "4f4fb700ef54: Waiting\n",
      "13eda56b8595: Waiting\n",
      "0910e2e41b78: Waiting\n",
      "fdb650ecd05f: Waiting\n",
      "af3f3505aac5: Waiting\n",
      "8643f31dbc8c: Waiting\n",
      "ab79507ae6b1: Waiting\n",
      "a9b3ebe80be7: Waiting\n",
      "e36195592140: Waiting\n",
      "4586c00479c6: Verifying Checksum\n",
      "4586c00479c6: Download complete\n",
      "afa3f70b397f: Verifying Checksum\n",
      "afa3f70b397f: Download complete\n",
      "6b851dcae6ca: Verifying Checksum\n",
      "6b851dcae6ca: Download complete\n",
      "d963a42bc712: Verifying Checksum\n",
      "d963a42bc712: Download complete\n",
      "c4a5e6c74f13: Verifying Checksum\n",
      "c4a5e6c74f13: Download complete\n",
      "afec03310895: Download complete\n",
      "4304fa233a80: Verifying Checksum\n",
      "4304fa233a80: Download complete\n",
      "44d8a5c35cf0: Verifying Checksum\n",
      "44d8a5c35cf0: Download complete\n",
      "e5f5c15a6664: Verifying Checksum\n",
      "e5f5c15a6664: Download complete\n",
      "6b851dcae6ca: Pull complete\n",
      "4586c00479c6: Pull complete\n",
      "4304fa233a80: Pull complete\n",
      "afa3f70b397f: Pull complete\n",
      "d963a42bc712: Pull complete\n",
      "68cd1e6a2dfe: Verifying Checksum\n",
      "68cd1e6a2dfe: Download complete\n",
      "1c247d9a49f1: Verifying Checksum\n",
      "1c247d9a49f1: Download complete\n",
      "a0188afe0979: Verifying Checksum\n",
      "a0188afe0979: Download complete\n",
      "8171a8ea64b5: Verifying Checksum\n",
      "8171a8ea64b5: Download complete\n",
      "4f4fb700ef54: Verifying Checksum\n",
      "4f4fb700ef54: Download complete\n",
      "0910e2e41b78: Verifying Checksum\n",
      "0910e2e41b78: Download complete\n",
      "13eda56b8595: Verifying Checksum\n",
      "13eda56b8595: Download complete\n",
      "af3f3505aac5: Verifying Checksum\n",
      "af3f3505aac5: Download complete\n",
      "fdb650ecd05f: Verifying Checksum\n",
      "fdb650ecd05f: Download complete\n",
      "ab79507ae6b1: Verifying Checksum\n",
      "ab79507ae6b1: Download complete\n",
      "8643f31dbc8c: Verifying Checksum\n",
      "8643f31dbc8c: Download complete\n",
      "a9b3ebe80be7: Verifying Checksum\n",
      "a9b3ebe80be7: Download complete\n",
      "9dc6bee1bcb0: Verifying Checksum\n",
      "9dc6bee1bcb0: Download complete\n",
      "2c5f4efecf9a: Verifying Checksum\n",
      "2c5f4efecf9a: Download complete\n",
      "a2a792fc5b81: Verifying Checksum\n",
      "a2a792fc5b81: Download complete\n",
      "f248718bd1c7: Verifying Checksum\n",
      "f248718bd1c7: Download complete\n",
      "aa835be7741f: Verifying Checksum\n",
      "aa835be7741f: Download complete\n",
      "95c9ea485716: Verifying Checksum\n",
      "95c9ea485716: Download complete\n",
      "2e0b9790ff72: Verifying Checksum\n",
      "2e0b9790ff72: Download complete\n",
      "672fc9109cbf: Verifying Checksum\n",
      "672fc9109cbf: Download complete\n",
      "19a58815e257: Verifying Checksum\n",
      "19a58815e257: Download complete\n",
      "aec883f70f16: Verifying Checksum\n",
      "aec883f70f16: Download complete\n",
      "e36195592140: Verifying Checksum\n",
      "e36195592140: Download complete\n",
      "cc4049f8d982: Verifying Checksum\n",
      "cc4049f8d982: Download complete\n",
      "aa254f6f7da1: Verifying Checksum\n",
      "aa254f6f7da1: Download complete\n",
      "e1bab5cae66b: Verifying Checksum\n",
      "e1bab5cae66b: Download complete\n",
      "a83df4e85ed4: Verifying Checksum\n",
      "a83df4e85ed4: Download complete\n",
      "39da51cbcb48: Verifying Checksum\n",
      "39da51cbcb48: Download complete\n",
      "051225d1252b: Verifying Checksum\n",
      "051225d1252b: Download complete\n",
      "db305fcd60dd: Verifying Checksum\n",
      "db305fcd60dd: Download complete\n",
      "68cd1e6a2dfe: Pull complete\n",
      "c4a5e6c74f13: Pull complete\n",
      "afec03310895: Pull complete\n",
      "44d8a5c35cf0: Pull complete\n",
      "e1bab5cae66b: Pull complete\n",
      "e5f5c15a6664: Pull complete\n",
      "8171a8ea64b5: Pull complete\n",
      "1c247d9a49f1: Pull complete\n",
      "a0188afe0979: Pull complete\n",
      "4f4fb700ef54: Pull complete\n",
      "13eda56b8595: Pull complete\n",
      "0910e2e41b78: Pull complete\n",
      "fdb650ecd05f: Pull complete\n",
      "af3f3505aac5: Pull complete\n",
      "8643f31dbc8c: Pull complete\n",
      "ab79507ae6b1: Pull complete\n",
      "a9b3ebe80be7: Pull complete\n",
      "e36195592140: Pull complete\n",
      "9dc6bee1bcb0: Pull complete\n",
      "2c5f4efecf9a: Pull complete\n",
      "a2a792fc5b81: Pull complete\n",
      "f248718bd1c7: Pull complete\n",
      "aa835be7741f: Pull complete\n",
      "95c9ea485716: Pull complete\n",
      "2e0b9790ff72: Pull complete\n",
      "672fc9109cbf: Pull complete\n",
      "19a58815e257: Pull complete\n",
      "aec883f70f16: Pull complete\n",
      "cc4049f8d982: Pull complete\n",
      "051225d1252b: Pull complete\n",
      "aa254f6f7da1: Pull complete\n",
      "db305fcd60dd: Pull complete\n",
      "a83df4e85ed4: Pull complete\n",
      "39da51cbcb48: Pull complete\n",
      "Digest: sha256:cdc09d0f02e4d104be7bb2660571b3a4522c1d8f9fe178c05a14a88955f6d73e\n",
      "Status: Downloaded newer image for gcr.io/deeplearning-platform-release/tf2-gpu.2-13.py310:latest\n",
      " ---> 81a11c671138\n",
      "Step 2/12 : ENV PYTHONUNBUFFERED True\n",
      " ---> Running in 48ae5b37aea5\n",
      "Removing intermediate container 48ae5b37aea5\n",
      " ---> 2b0c40f7b51b\n",
      "Step 3/12 : ENV APP_HOME /workspace\n",
      " ---> Running in 25c2f8835035\n",
      "Removing intermediate container 25c2f8835035\n",
      " ---> 410c87d549d8\n",
      "Step 4/12 : WORKDIR $APP_HOME\n",
      " ---> Running in 76b7ba0d11e0\n",
      "Removing intermediate container 76b7ba0d11e0\n",
      " ---> 2e0cc91cab75\n",
      "Step 5/12 : COPY /requirements.txt $APP_HOME/requirements.txt\n",
      " ---> 919646d15ab7\n",
      "Step 6/12 : RUN pip install --upgrade pip\n",
      " ---> Running in 1a473f0491f0\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.3.1)\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 1a473f0491f0\n",
      " ---> b51c4751556e\n",
      "Step 7/12 : RUN pip install --no-cache-dir -r $APP_HOME/requirements.txt\n",
      " ---> Running in 212bcaa26407\n",
      "Collecting google-cloud-aiplatform==1.33.1 (from google-cloud-aiplatform[cloud_profiler]==1.33.1->-r /workspace/requirements.txt (line 1))\n",
      "  Downloading google_cloud_aiplatform-1.33.1-py2.py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 2)) (2.13.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 3)) (1.23.5)\n",
      "Requirement already satisfied: tensorflow==2.13.0 in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 4)) (2.13.0)\n",
      "Collecting tf-agents==0.17.0 (from -r /workspace/requirements.txt (line 5))\n",
      "  Downloading tf_agents-0.17.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting tensorflow-datasets==4.9.0 (from -r /workspace/requirements.txt (line 6))\n",
      "  Downloading tensorflow_datasets-4.9.0-py3-none-any.whl (5.4 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.4/5.4 MB 98.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 7)) (2.13.0)\n",
      "Requirement already satisfied: tensorboard-plugin-profile in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 8)) (2.14.0)\n",
      "Collecting tensorboard-plugin-wit (from -r /workspace/requirements.txt (line 9))\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.3/781.3 kB 312.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tensorboard-data-server in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 10)) (0.7.2)\n",
      "Requirement already satisfied: tensorflow-io in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 11)) (0.32.0)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 12)) (1.26.18)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 13)) (10.0.1)\n",
      "Collecting wrapt==1.14.1 (from -r /workspace/requirements.txt (line 14))\n",
      "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.9/77.9 kB 242.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.33.1->google-cloud-aiplatform[cloud_profiler]==1.33.1->-r /workspace/requirements.txt (line 1)) (1.34.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.33.1->google-cloud-aiplatform[cloud_profiler]==1.33.1->-r /workspace/requirements.txt (line 1)) (1.22.3)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.33.1->google-cloud-aiplatform[cloud_profiler]==1.33.1->-r /workspace/requirements.txt (line 1)) (3.20.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.33.1->google-cloud-aiplatform[cloud_profiler]==1.33.1->-r /workspace/requirements.txt (line 1)) (23.2)\n",
      "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.33.1->google-cloud-aiplatform[cloud_profiler]==1.33.1->-r /workspace/requirements.txt (line 1)) (3.13.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.33.1->google-cloud-aiplatform[cloud_profiler]==1.33.1->-r /workspace/requirements.txt (line 1)) (1.10.4)\n",
      "Collecting shapely<2.0.0 (from google-cloud-aiplatform==1.33.1->google-cloud-aiplatform[cloud_profiler]==1.33.1->-r /workspace/requirements.txt (line 1))\n",
      "  Downloading Shapely-1.8.5.post1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 292.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (1.48.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (3.10.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (2.13.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (16.0.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (4.5.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4)) (0.32.0)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in /opt/conda/lib/python3.10/site-packages (from tf-agents==0.17.0->-r /workspace/requirements.txt (line 5)) (2.2.1)\n",
      "Collecting gin-config>=0.4.0 (from tf-agents==0.17.0->-r /workspace/requirements.txt (line 5))\n",
      "  Downloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.3/61.3 kB 208.8 MB/s eta 0:00:00\n",
      "Collecting gym<=0.23.0,>=0.17.0 (from tf-agents==0.17.0->-r /workspace/requirements.txt (line 5))\n",
      "  Downloading gym-0.23.0.tar.gz (624 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 624.4/624.4 kB 319.6 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pygame==2.1.3 (from tf-agents==0.17.0->-r /workspace/requirements.txt (line 5))\n",
      "  Downloading pygame-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.7/13.7 MB 175.6 MB/s eta 0:00:00\n",
      "Collecting tensorflow-probability~=0.20.1 (from tf-agents==0.17.0->-r /workspace/requirements.txt (line 5))\n",
      "  Downloading tensorflow_probability-0.20.1-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: array-record in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (0.5.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (8.1.7)\n",
      "Requirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (0.1.8)\n",
      "Requirement already satisfied: etils>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (1.5.2)\n",
      "Requirement already satisfied: promise in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (2.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (5.9.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (2.31.0)\n",
      "Requirement already satisfied: tensorflow-metadata in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (0.14.0)\n",
      "Requirement already satisfied: toml in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (4.66.1)\n",
      "\u001b[91mWARNING: google-cloud-aiplatform 1.33.1 does not provide the extra 'cloud-profiler'\n",
      "\u001b[0mCollecting werkzeug<2.1.0dev,>=2.0.0 (from google-cloud-aiplatform[cloud_profiler]==1.33.1->-r /workspace/requirements.txt (line 1))\n",
      "  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 289.2/289.2 kB 283.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: google-auth<3.0dev,>=2.23.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->-r /workspace/requirements.txt (line 2)) (2.23.4)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->-r /workspace/requirements.txt (line 2)) (2.3.3)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->-r /workspace/requirements.txt (line 2)) (2.6.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->-r /workspace/requirements.txt (line 2)) (1.5.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow==2.13.0->-r /workspace/requirements.txt (line 4))\n",
      "  Downloading grpcio-1.59.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r /workspace/requirements.txt (line 7)) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r /workspace/requirements.txt (line 7)) (3.5.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r /workspace/requirements.txt (line 7)) (0.41.3)\n",
      "Requirement already satisfied: gviz-api>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard-plugin-profile->-r /workspace/requirements.txt (line 8)) (1.10.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (2023.10.0)\n",
      "Requirement already satisfied: importlib_resources in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (6.1.0)\n",
      "Requirement already satisfied: zipp in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (3.17.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.33.1->google-cloud-aiplatform[cloud_profiler]==1.33.1->-r /workspace/requirements.txt (line 1)) (1.61.0)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.33.1->google-cloud-aiplatform[cloud_profiler]==1.33.1->-r /workspace/requirements.txt (line 1)) (1.48.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage->-r /workspace/requirements.txt (line 2)) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage->-r /workspace/requirements.txt (line 2)) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage->-r /workspace/requirements.txt (line 2)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->-r /workspace/requirements.txt (line 7)) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.33.1->google-cloud-aiplatform[cloud_profiler]==1.33.1->-r /workspace/requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform==1.33.1->google-cloud-aiplatform[cloud_profiler]==1.33.1->-r /workspace/requirements.txt (line 1)) (0.12.6)\n",
      "Collecting gym-notices>=0.0.4 (from gym<=0.23.0,>=0.17.0->tf-agents==0.17.0->-r /workspace/requirements.txt (line 5))\n",
      "  Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets==4.9.0->-r /workspace/requirements.txt (line 6)) (2023.7.22)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from tensorflow-probability~=0.20.1->tf-agents==0.17.0->-r /workspace/requirements.txt (line 5)) (5.1.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.23.3->google-cloud-storage->-r /workspace/requirements.txt (line 2)) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->-r /workspace/requirements.txt (line 7)) (3.2.2)\n",
      "Downloading google_cloud_aiplatform-1.33.1-py2.py3-none-any.whl (2.9 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.9/2.9 MB 300.3 MB/s eta 0:00:00\n",
      "Downloading tf_agents-0.17.0-py3-none-any.whl (1.4 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 126.1 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.59.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.3/5.3 MB 277.9 MB/s eta 0:00:00\n",
      "Downloading tensorflow_probability-0.20.1-py2.py3-none-any.whl (6.9 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.9/6.9 MB 78.4 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (pyproject.toml): started\n",
      "  Building wheel for gym (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for gym: filename=gym-0.23.0-py3-none-any.whl size=697629 sha256=9427eea08e2e9f9c9e043f7d616e2fe4a991803baafe3e5c9035fbfbd7dd31ec\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-rdkkjjya/wheels/3d/6f/b4/3991d4fae11d0ecb0754c11cc1b4e7745012850da4efaaf0b1\n",
      "Successfully built gym\n",
      "Installing collected packages: tensorboard-plugin-wit, gym-notices, gin-config, wrapt, werkzeug, tensorflow-probability, shapely, pygame, gym, grpcio, tf-agents, tensorflow-datasets, google-cloud-aiplatform\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.15.0\n",
      "    Uninstalling wrapt-1.15.0:\n",
      "      Successfully uninstalled wrapt-1.15.0\n",
      "  Attempting uninstall: werkzeug\n",
      "    Found existing installation: Werkzeug 2.1.2\n",
      "    Uninstalling Werkzeug-2.1.2:\n",
      "      Successfully uninstalled Werkzeug-2.1.2\n",
      "  Attempting uninstall: tensorflow-probability\n",
      "    Found existing installation: tensorflow-probability 0.22.1\n",
      "    Uninstalling tensorflow-probability-0.22.1:\n",
      "      Successfully uninstalled tensorflow-probability-0.22.1\n",
      "  Attempting uninstall: shapely\n",
      "    Found existing installation: shapely 2.0.2\n",
      "    Uninstalling shapely-2.0.2:\n",
      "      Successfully uninstalled shapely-2.0.2\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.48.1\n",
      "    Uninstalling grpcio-1.48.1:\n",
      "      Successfully uninstalled grpcio-1.48.1\n",
      "  Attempting uninstall: tensorflow-datasets\n",
      "    Found existing installation: tensorflow-datasets 4.9.3\n",
      "    Uninstalling tensorflow-datasets-4.9.3:\n",
      "      Successfully uninstalled tensorflow-datasets-4.9.3\n",
      "  Attempting uninstall: google-cloud-aiplatform\n",
      "    Found existing installation: google-cloud-aiplatform 1.36.0\n",
      "    Uninstalling google-cloud-aiplatform-1.36.0:\n",
      "      Successfully uninstalled google-cloud-aiplatform-1.36.0\n",
      "Successfully installed gin-config-0.5.0 google-cloud-aiplatform-1.33.1 grpcio-1.59.2 gym-0.23.0 gym-notices-0.0.8 pygame-2.1.3 shapely-1.8.5.post1 tensorboard-plugin-wit-1.8.1 tensorflow-datasets-4.9.0 tensorflow-probability-0.20.1 tf-agents-0.17.0 werkzeug-2.0.3 wrapt-1.14.1\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 212bcaa26407\n",
      " ---> d8e3c3e8442e\n",
      "Step 8/12 : RUN pip install cloudml-hypertune\n",
      " ---> Running in 08745cc92a0e\n",
      "Collecting cloudml-hypertune\n",
      "  Downloading cloudml-hypertune-0.1.0.dev6.tar.gz (3.2 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: cloudml-hypertune\n",
      "  Building wheel for cloudml-hypertune (setup.py): started\n",
      "  Building wheel for cloudml-hypertune (setup.py): finished with status 'done'\n",
      "  Created wheel for cloudml-hypertune: filename=cloudml_hypertune-0.1.0.dev6-py2.py3-none-any.whl size=3972 sha256=cf2d9ee8e709132b7b63b560ed7972e07d926828622458e1cef859af03ff2f03\n",
      "  Stored in directory: /root/.cache/pip/wheels/c6/2d/bb/9c72de7c488cd8e60172c4920c09e404c490020162205b64ba\n",
      "Successfully built cloudml-hypertune\n",
      "Installing collected packages: cloudml-hypertune\n",
      "Successfully installed cloudml-hypertune-0.1.0.dev6\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 08745cc92a0e\n",
      " ---> c54b85106978\n",
      "Step 9/12 : RUN apt update && apt -y install nvtop\n",
      " ---> Running in f3db7290973e\n",
      "\u001b[91m\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
      "\n",
      "\u001b[0mGet:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1581 B]\n",
      "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [591 kB]\n",
      "Get:3 https://packages.cloud.google.com/apt gcsfuse-focal InRelease [1301 B]\n",
      "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
      "Get:5 https://packages.cloud.google.com/apt cloud-sdk InRelease [6361 B]\n",
      "Get:6 https://packages.cloud.google.com/apt google-fast-socket InRelease [5015 B]\n",
      "Get:7 https://packages.cloud.google.com/apt gcsfuse-focal/main all Packages [750 B]\n",
      "Get:8 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [44.0 kB]\n",
      "Get:9 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1195 kB]\n",
      "Get:10 https://packages.cloud.google.com/apt gcsfuse-focal/main amd64 Packages [16.5 kB]\n",
      "Get:11 https://packages.cloud.google.com/apt cloud-sdk/main amd64 Packages [549 kB]\n",
      "Get:12 https://packages.cloud.google.com/apt google-fast-socket/main amd64 Packages [447 B]\n",
      "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1008 kB]\n",
      "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1392 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy InRelease [270 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu jammy/restricted amd64 Packages [164 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 Packages [266 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu jammy/universe amd64 Packages [17.5 MB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu jammy/main amd64 Packages [1792 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1274 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1420 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1468 kB]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [49.8 kB]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [32.6 kB]\n",
      "Get:27 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [78.3 kB]\n",
      "Fetched 29.4 MB in 5s (5714 kB/s)\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "\u001b[91mW: https://packages.cloud.google.com/apt/dists/gcsfuse-focal/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
      "W: https://packages.cloud.google.com/apt/dists/google-fast-socket/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
      "\u001b[0m12 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "\u001b[91m\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
      "\u001b[0mReading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following NEW packages will be installed:\n",
      "  nvtop\n",
      "0 upgraded, 1 newly installed, 0 to remove and 12 not upgraded.\n",
      "Need to get 43.9 kB of archives.\n",
      "After this operation, 106 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 nvtop amd64 1.2.2-1 [43.9 kB]\n",
      "\u001b[91mdebconf: unable to initialize frontend: Dialog\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\n",
      "debconf: falling back to frontend: Readline\n",
      "\u001b[0m\u001b[91mdebconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "\u001b[0m\u001b[91mdpkg-preconfigure: unable to re-open stdin: \n",
      "\u001b[0mFetched 43.9 kB in 0s (165 kB/s)\n",
      "Selecting previously unselected package nvtop.\n",
      "(Reading database ... 94405 files and directories currently installed.)\n",
      "Preparing to unpack .../nvtop_1.2.2-1_amd64.deb ...\n",
      "Unpacking nvtop (1.2.2-1) ...\n",
      "Setting up nvtop (1.2.2-1) ...\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "Removing intermediate container f3db7290973e\n",
      " ---> f6024acd1f88\n",
      "Step 10/12 : COPY src/per_arm_rl $APP_HOME/src/per_arm_rl\n",
      " ---> 915526638cda\n",
      "Step 11/12 : RUN export PYTHONPATH=${PYTHONPATH}:${APP_HOME}/\n",
      " ---> Running in d5e04ca2b99d\n",
      "Removing intermediate container d5e04ca2b99d\n",
      " ---> a9d49b2b2033\n",
      "Step 12/12 : ENTRYPOINT [\"python3\", \"-m\", \"src.per_arm_rl.perarm_task\"]\n",
      " ---> Running in f25f131f4e7c\n",
      "Removing intermediate container f25f131f4e7c\n",
      " ---> 5bda8c8364fd\n",
      "Successfully built 5bda8c8364fd\n",
      "Successfully tagged gcr.io/hybrid-vertex/train-my-perarm-env-v2:latest\n",
      "PUSH\n",
      "Pushing gcr.io/hybrid-vertex/train-my-perarm-env-v2\n",
      "The push refers to repository [gcr.io/hybrid-vertex/train-my-perarm-env-v2]\n",
      "3e36cae2a952: Preparing\n",
      "e2ab950005ac: Preparing\n",
      "3f24e0b65c48: Preparing\n",
      "dd45c2c9fddc: Preparing\n",
      "31aaa8cae2d2: Preparing\n",
      "fea241972275: Preparing\n",
      "4286eef145f8: Preparing\n",
      "47abf889a38a: Preparing\n",
      "f6a73cb151f2: Preparing\n",
      "0791d40f905f: Preparing\n",
      "6da630f71c0b: Preparing\n",
      "4ec920f180e9: Preparing\n",
      "6ec4923f8c2a: Preparing\n",
      "1fbad6590151: Preparing\n",
      "76ee6c951b57: Preparing\n",
      "4f7e69f25ebb: Preparing\n",
      "d8c39febd957: Preparing\n",
      "ef7a07da8a45: Preparing\n",
      "ebe781e89b34: Preparing\n",
      "1b899ab1b8c5: Preparing\n",
      "2c715eb2e1ce: Preparing\n",
      "e73797b88e3c: Preparing\n",
      "f1048f01adb3: Preparing\n",
      "7571be2c6600: Preparing\n",
      "b7f6cf7db999: Preparing\n",
      "b73b23e5aa4f: Preparing\n",
      "cdc327f41f9a: Preparing\n",
      "29a8646b0027: Preparing\n",
      "7d9838d71319: Preparing\n",
      "ac01bf132457: Preparing\n",
      "11d0a2148050: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "a3aa883e4b5a: Preparing\n",
      "2f1a3e7e90dc: Preparing\n",
      "0235cf47cbae: Preparing\n",
      "2971cdbb4b45: Preparing\n",
      "8374b2bc65e7: Preparing\n",
      "3b93a6feba89: Preparing\n",
      "b15400eb0fa7: Preparing\n",
      "29ecaf0c2ae0: Preparing\n",
      "41e673079fce: Preparing\n",
      "cda9215846ee: Preparing\n",
      "c5eafb4bee8f: Preparing\n",
      "81182eb0608d: Preparing\n",
      "f2baf76d88ee: Preparing\n",
      "fea241972275: Waiting\n",
      "cdd7c7392317: Preparing\n",
      "4286eef145f8: Waiting\n",
      "47abf889a38a: Waiting\n",
      "7d9838d71319: Waiting\n",
      "ac01bf132457: Waiting\n",
      "29a8646b0027: Waiting\n",
      "11d0a2148050: Waiting\n",
      "f6a73cb151f2: Waiting\n",
      "5f70bf18a086: Waiting\n",
      "41e673079fce: Waiting\n",
      "cda9215846ee: Waiting\n",
      "c5eafb4bee8f: Waiting\n",
      "a3aa883e4b5a: Waiting\n",
      "2f1a3e7e90dc: Waiting\n",
      "81182eb0608d: Waiting\n",
      "0235cf47cbae: Waiting\n",
      "2971cdbb4b45: Waiting\n",
      "f2baf76d88ee: Waiting\n",
      "8374b2bc65e7: Waiting\n",
      "cdd7c7392317: Waiting\n",
      "3b93a6feba89: Waiting\n",
      "b15400eb0fa7: Waiting\n",
      "76ee6c951b57: Waiting\n",
      "6da630f71c0b: Waiting\n",
      "4f7e69f25ebb: Waiting\n",
      "29ecaf0c2ae0: Waiting\n",
      "1b899ab1b8c5: Waiting\n",
      "2c715eb2e1ce: Waiting\n",
      "ef7a07da8a45: Waiting\n",
      "4ec920f180e9: Waiting\n",
      "ebe781e89b34: Waiting\n",
      "e73797b88e3c: Waiting\n",
      "6ec4923f8c2a: Waiting\n",
      "f1048f01adb3: Waiting\n",
      "7571be2c6600: Waiting\n",
      "b73b23e5aa4f: Waiting\n",
      "cdc327f41f9a: Waiting\n",
      "b7f6cf7db999: Waiting\n",
      "31aaa8cae2d2: Pushed\n",
      "3f24e0b65c48: Pushed\n",
      "3e36cae2a952: Pushed\n",
      "47abf889a38a: Layer already exists\n",
      "f6a73cb151f2: Layer already exists\n",
      "0791d40f905f: Layer already exists\n",
      "6da630f71c0b: Layer already exists\n",
      "4ec920f180e9: Layer already exists\n",
      "6ec4923f8c2a: Layer already exists\n",
      "1fbad6590151: Layer already exists\n",
      "fea241972275: Pushed\n",
      "76ee6c951b57: Layer already exists\n",
      "d8c39febd957: Layer already exists\n",
      "4f7e69f25ebb: Layer already exists\n",
      "ef7a07da8a45: Layer already exists\n",
      "ebe781e89b34: Layer already exists\n",
      "1b899ab1b8c5: Layer already exists\n",
      "2c715eb2e1ce: Layer already exists\n",
      "4286eef145f8: Pushed\n",
      "e73797b88e3c: Layer already exists\n",
      "f1048f01adb3: Layer already exists\n",
      "7571be2c6600: Layer already exists\n",
      "b7f6cf7db999: Layer already exists\n",
      "b73b23e5aa4f: Layer already exists\n",
      "cdc327f41f9a: Layer already exists\n",
      "29a8646b0027: Layer already exists\n",
      "7d9838d71319: Layer already exists\n",
      "ac01bf132457: Layer already exists\n",
      "11d0a2148050: Layer already exists\n",
      "5f70bf18a086: Layer already exists\n",
      "a3aa883e4b5a: Layer already exists\n",
      "2f1a3e7e90dc: Layer already exists\n",
      "0235cf47cbae: Layer already exists\n",
      "8374b2bc65e7: Layer already exists\n",
      "2971cdbb4b45: Layer already exists\n",
      "3b93a6feba89: Layer already exists\n",
      "b15400eb0fa7: Layer already exists\n",
      "29ecaf0c2ae0: Layer already exists\n",
      "41e673079fce: Layer already exists\n",
      "c5eafb4bee8f: Layer already exists\n",
      "cda9215846ee: Layer already exists\n",
      "81182eb0608d: Layer already exists\n",
      "f2baf76d88ee: Layer already exists\n",
      "cdd7c7392317: Layer already exists\n",
      "e2ab950005ac: Pushed\n",
      "dd45c2c9fddc: Pushed\n",
      "latest: digest: sha256:6aaf08be48ac16dd63edb699dffec6f5f97ab6dc56e4f238a815fee342514797 size: 9968\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                       IMAGES                                                 STATUS\n",
      "50cb7b39-c1c1-46c8-928a-8242e75ac448  2023-11-14T14:39:46+00:00  4M        gs://hybrid-vertex_cloudbuild/source/1699972785.657103-a6bdaba21a2a4d858eb44defe6aca8cf.tgz  gcr.io/hybrid-vertex/train-my-perarm-env-v2 (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "! gcloud builds submit --config ./cloudbuild.yaml \\\n",
    "    --substitutions _DOCKERNAME=$DOCKERNAME_01,_IMAGE_URI=$IMAGE_URI_01,_FILE_LOCATION=$FILE_LOCATION \\\n",
    "    --timeout=2h \\\n",
    "    --machine-type=$MACHINE_TYPE \\\n",
    "    --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629eb246-f2fc-48a0-8478-4f9c99dddd0b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## (Optional) Build Image Locally\n",
    "\n",
    "Building images with Cloud Build is best practices\n",
    "* images are centrally stored and better managed for robust CI/CD\n",
    "* building images on local workbench instance can alter notebook image config (base image for notebooks vs train images are different)\n",
    "* if building locally, consider using virutal environments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5278eb39-1dbb-48fd-b872-9cd55643a1ed",
   "metadata": {},
   "source": [
    "Provide a name for your dockerfile and make sure you are authenticated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53874306-777f-459f-9250-4a59dbc283a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gcloud auth configure-docker $REGION-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25faef9c-cb5e-425d-9ee6-7ae8003a95af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy these commands into terminal:\n",
      "\n",
      "virtualenv vertex_env\n",
      "source vertex_env/bin/activate\n"
     ]
    }
   ],
   "source": [
    "print(\"copy these commands into terminal:\\n\")\n",
    "print(f\"virtualenv vertex_env\")\n",
    "print(f\"source vertex_env/bin/activate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "027de7fe-dd2a-4be5-80c4-877f7abe4753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy these commands into terminal:\n",
      "\n",
      "export REMOTE_IMAGE_NAME=us-central1-docker.pkg.dev/hybrid-vertex/rl-movielens-rec-bandits-v2/local_docker_tfa\n",
      "export DOCKERNAME=Dockerfile_train_my_perarm_env\n",
      "docker build -t $REMOTE_IMAGE_NAME -f ./$DOCKERNAME .\n"
     ]
    }
   ],
   "source": [
    "# # set variables if running in terminal\n",
    "print(\"copy these commands into terminal:\\n\")\n",
    "print(f\"export REMOTE_IMAGE_NAME={REMOTE_IMAGE_NAME}\")\n",
    "print(f\"export DOCKERNAME={DOCKERNAME_01}\")\n",
    "print(f\"docker build -t $REMOTE_IMAGE_NAME -f ./$DOCKERNAME .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a82cbe6-0ed5-478f-a38f-e6dedc114e2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !docker build -t $REMOTE_IMAGE_NAME -f $DOCKERNAME ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6110439-f66a-4d6b-8105-17a08ce9b8da",
   "metadata": {},
   "source": [
    "### Push container to Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54a714cf-053c-4f14-b375-2a42ae2092f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy this command into terminal:\n",
      "\n",
      "docker push $REMOTE_IMAGE_NAME\n"
     ]
    }
   ],
   "source": [
    "# ### push the container to registry\n",
    "\n",
    "print(\"copy this command into terminal:\\n\")\n",
    "print(f\"docker push $REMOTE_IMAGE_NAME\")\n",
    "\n",
    "# !docker push $REMOTE_IMAGE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bc85f6-a86e-48f2-a040-89f35376d57c",
   "metadata": {},
   "source": [
    "### GPU profiling\n",
    "\n",
    "> enter these commands in the Vertex interactive terminal:\n",
    "\n",
    "```bash\n",
    "sudo apt update\n",
    "sudo apt -y install nvtop\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18df8169-e4ed-45fb-9279-85e966bc6f3e",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
