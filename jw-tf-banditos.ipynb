{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "525b561f-77f5-4736-927f-19929674b868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tf-agents --user -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53da2313-9daf-4662-8d9b-93b813d2a4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1112bb5e-0151-418f-9d17-eb17ee191788",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.bandits.agents import lin_ucb_agent\n",
    "from tf_agents.bandits.environments import stationary_stochastic_per_arm_py_environment as p_a_env\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "import tensorflow_datasets as tfds\n",
    "from pprint import pprint\n",
    "\n",
    "nest = tf.nest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dac1a89-b58b-4d4b-92ba-e70d9ed80a96",
   "metadata": {},
   "source": [
    "### movies data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03eb6ba1-8cae-41f6-b65a-31d18165fe69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[4]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'1681'], dtype=object)>,\n",
      " 'movie_title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'You So Crazy (1994)'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")\n",
    "\n",
    "for x in movies.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9c9413-3aa8-4188-b5a2-b342ef50faf2",
   "metadata": {},
   "source": [
    "### user and ratings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92dbdb4b-8f13-4455-887c-6617ebd80242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([45.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'357'], dtype=object)>,\n",
      " 'movie_title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"One Flew Over the Cuckoo's Nest (1975)\"], dtype=object)>,\n",
      " 'raw_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([46.], dtype=float32)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([879024327])>,\n",
      " 'user_gender': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'138'], dtype=object)>,\n",
      " 'user_occupation_label': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([4])>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'doctor'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>,\n",
      " 'user_zip_code': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'53211'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "\n",
    "for x in ratings.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7941678d-f920-4206-9fea-d8e3e9f15cef",
   "metadata": {},
   "source": [
    "#### Let's make this simple and load up movielens that has features\n",
    "We will only consider for this example\n",
    "1) The movie genere as an Arm feature (we will concatenate multiple genres)\n",
    "2) The user occupation and age bucket labels for the overall context features\n",
    "\n",
    "We need to load the data, get the ratings - light EDA for us to get cardnality of the dataset as well as lookups for the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a4c8c8c-6e55-4140-86e7-701308154762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(unique_movie_ids) : 1682\n",
      "unique_movie_ids      : [b'1' b'10']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique movies and users\n",
    "unique_movie_ids = ratings.map(lambda x: x[\"movie_id\"])\n",
    "unique_movie_ids = np.unique([x.numpy() for x in unique_movie_ids])\n",
    "MOVIELENS_NUM_MOVIES = len(unique_movie_ids)\n",
    "\n",
    "\n",
    "print(f\"len(unique_movie_ids) : {len(unique_movie_ids)}\")\n",
    "print(f\"unique_movie_ids      : {unique_movie_ids[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bc12022-129d-48df-8cb3-7e53dbbbfea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(unique_user_ids) : 943\n",
      "unique_user_ids      : [b'1' b'10']\n"
     ]
    }
   ],
   "source": [
    "unique_user_ids = ratings.map(lambda x: x[\"user_id\"])\n",
    "unique_user_ids = np.unique([x.numpy() for x in unique_user_ids])\n",
    "MOVIELENS_NUM_USERS = len(unique_user_ids)\n",
    "\n",
    "\n",
    "print(f\"len(unique_user_ids) : {len(unique_user_ids)}\")\n",
    "print(f\"unique_user_ids      : {unique_user_ids[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cef8a89-0e97-4d93-819e-db2d4667efa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the unnique set of user buckets and create a lookup table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "174860eb-bfeb-4b02-b4d9-1dfaddc70914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def get_dictionary_lookup_by_tf_data_key(key: str) -> Dict:\n",
    "    tensor = ratings.map(lambda x: x[key])\n",
    "    unique_elems = set()\n",
    "    for x in tensor:\n",
    "        val = x.numpy()\n",
    "        if type(val) is np.ndarray: # if multi dimesnional only grab first one\n",
    "            val = val[0]\n",
    "        unique_elems.add(val)\n",
    "    \n",
    "    #return a dictionary of keys by integer values for the feature space\n",
    "    return {val: i for i, val in enumerate(unique_elems)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8113ded-13f2-460f-a2cd-90f44307f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_age_lookup = get_dictionary_lookup_by_tf_data_key('bucketized_user_age')\n",
    "user_age_dim = len(user_age_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bed813e8-cef5-46e0-a1d5-3f6c37ea34a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: 0, 35.0: 1, 45.0: 2, 18.0: 3, 50.0: 4, 56.0: 5, 25.0: 6}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_age_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ced8d46-9e1d-4d88-9228-cb57005d064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_occ_lookup = get_dictionary_lookup_by_tf_data_key('user_occupation_text')\n",
    "user_occ_dim = len(user_occ_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "820171f0-4784-4c61-b101-d3c9ae78f7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'student': 0,\n",
       " b'salesman': 1,\n",
       " b'programmer': 2,\n",
       " b'educator': 3,\n",
       " b'homemaker': 4,\n",
       " b'writer': 5,\n",
       " b'executive': 6,\n",
       " b'artist': 7,\n",
       " b'healthcare': 8,\n",
       " b'technician': 9,\n",
       " b'doctor': 10,\n",
       " b'marketing': 11,\n",
       " b'scientist': 12,\n",
       " b'lawyer': 13,\n",
       " b'engineer': 14,\n",
       " b'entertainment': 15,\n",
       " b'administrator': 16,\n",
       " b'librarian': 17,\n",
       " b'other': 18,\n",
       " b'none': 19,\n",
       " b'retired': 20}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_occ_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca8fa3dc-1144-4fff-8a03-eacb600d58a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_gen_lookup = get_dictionary_lookup_by_tf_data_key('movie_genres')\n",
    "movie_gen_dim = len(movie_gen_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7adf6f0-6842-4777-8cfe-65953dae96f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 1,\n",
       " 2: 2,\n",
       " 3: 3,\n",
       " 4: 4,\n",
       " 5: 5,\n",
       " 6: 6,\n",
       " 7: 7,\n",
       " 8: 8,\n",
       " 9: 9,\n",
       " 10: 10,\n",
       " 12: 11,\n",
       " 13: 12,\n",
       " 14: 13,\n",
       " 15: 14,\n",
       " 16: 15,\n",
       " 17: 16,\n",
       " 18: 17,\n",
       " 19: 18}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_gen_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b571a4e9-60ef-4e06-98b3-017fec36d36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " #from https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/environments/dataset_utilities.py#L153\n",
    "    \n",
    "# def load_movielens_data(data_file, delimiter=','):\n",
    "#     \"\"\"Loads the movielens data and returns the ratings matrix.\"\"\"\n",
    "#     ratings_matrix = np.zeros([MOVIELENS_NUM_USERS, MOVIELENS_NUM_MOVIES])\n",
    "#     with tf.io.gfile.GFile(data_file, 'r') as infile:\n",
    "#     # The file is a csv with rows containing:\n",
    "#     # user id | item id | rating | timestamp\n",
    "#     reader = csv.reader(infile, delimiter=delimiter)\n",
    "#     for row in reader:\n",
    "#         user_id, item_id, rating, _ = row\n",
    "#         ratings_matrix[int(user_id) - 1, int(item_id) - 1] = float(rating)\n",
    "#     return ratings_matrix\n",
    "\n",
    "\n",
    "\n",
    "def load_movielens_data(ratings_dataset):\n",
    "    # ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "    ratings_matrix = np.zeros([MOVIELENS_NUM_USERS, MOVIELENS_NUM_MOVIES])\n",
    "    local_data = ratings_dataset.map(lambda x: {'user_id': x['user_id']\n",
    "                                                 ,'movie_id':  x['movie_id']\n",
    "                                                 ,'user_rating':  x['user_rating']\n",
    "                                                 ,'bucketized_user_age': x['bucketized_user_age']\n",
    "                                                 ,'user_occupation_text': x['user_occupation_text']\n",
    "                                                 ,'movie_genres': x['movie_genres'][0]\n",
    "                                               }\n",
    "                                                                         )\n",
    "    user_age_int = []\n",
    "    user_occ_int = []\n",
    "    mov_gen_int = []\n",
    "    for row in local_data:\n",
    "        ratings_matrix[int(row['user_id'].numpy()) - 1, int(row['movie_id'].numpy()) - 1] = float(row['user_rating'].numpy())\n",
    "        user_age_int.append(user_age_lookup[row['bucketized_user_age'].numpy()])\n",
    "        user_occ_int.append(user_occ_lookup[row['user_occupation_text'].numpy()])\n",
    "        mov_gen_int.append(movie_gen_lookup[row['movie_genres'].numpy()])\n",
    "    return ratings_matrix, np.array(user_age_int), np.array(user_occ_int), np.array(mov_gen_int)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50806cc4-f345-471f-9622-4201303c8679",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_matrix, user_age_int, user_occ_int, mov_gen_int = load_movielens_data(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21f44fc5-c9fc-4ddc-a893-89648aa0b2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.bandits.specs import utils as bandit_spec_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86a12ac-8b8a-42da-b5c3-7c6bec75413c",
   "metadata": {},
   "source": [
    "## Replicate an agent using the above data\n",
    "\n",
    "https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/environments/movielens_per_arm_py_environment.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78910d5e-e38b-4120-8808-de492353b879",
   "metadata": {},
   "source": [
    "Create an arm spec from this utility function\n",
    "https://www.tensorflow.org/agents/api_docs/python/tf_agents/specs/bandit_spec_utils/create_per_arm_observation_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce5142d9-aba2-4e53-a74e-667afa2a6452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(1,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(10, 2), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example observation spec from above\n",
    "# There are 20 user occupations and 7 age buckets. This makes our global dimension 27\n",
    "# There are 19 genres, and that will be the arm dimension for this example\n",
    "\n",
    "from tf_agents.specs.bandit_spec_utils import create_per_arm_observation_spec as create_obs_spec\n",
    "create_obs_spec(\n",
    "    global_dim = 1,\n",
    "    per_arm_dim = 2,\n",
    "    max_num_actions = 10,\n",
    "    add_num_actions_feature = False\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f12a2000-55fd-48e8-8c81-509bea9d8a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.cardinality().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b369486f-47aa-4c9c-9726-ac4f83f0fcc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Class implementation of the per-arm MovieLens Bandit environment.\"\"\"\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import random\n",
    "from typing import Optional, Text\n",
    "import gin\n",
    "import numpy as np\n",
    "\n",
    "from tf_agents.bandits.environments import bandit_py_environment\n",
    "from tf_agents.bandits.environments import dataset_utilities\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "\n",
    "GLOBAL_KEY = bandit_spec_utils.GLOBAL_FEATURE_KEY\n",
    "PER_ARM_KEY = bandit_spec_utils.PER_ARM_FEATURE_KEY\n",
    "\n",
    "\n",
    "@gin.configurable\n",
    "class MovieLensPerArmPyEnvironment(bandit_py_environment.BanditPyEnvironment):\n",
    "    \"\"\"Implements the per-arm version of the MovieLens Bandit environment.\n",
    "\n",
    "    This environment implements the MovieLens 100K dataset, available at:\n",
    "    https://www.kaggle.com/prajitdatta/movielens-100k-dataset\n",
    "\n",
    "    This dataset contains 100K ratings from 943 users on 1682 items.\n",
    "    This csv list of:\n",
    "    user id | item id | rating | timestamp.\n",
    "    This environment computes a low-rank matrix factorization (using SVD) of the\n",
    "    data matrix `A`, such that: `A ~= U * Sigma * V^T`.\n",
    "\n",
    "    The environment uses the rows of `U` as global (or user) features, and the\n",
    "    rows of `V` as per-arm (or movie) features.\n",
    "\n",
    "    The reward of recommending movie `v` to user `u` is `u * Sigma * v^T`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "               dataset = ratings,\n",
    "               rank_k: int = 2,\n",
    "               batch_size: int = 10,\n",
    "               num_actions: int = 100,\n",
    "               name: Optional[Text] = 'movielens_per_arm'):\n",
    "        \"\"\"Initializes the Per-arm MovieLens Bandit environment.\n",
    "\n",
    "        Args:\n",
    "          data_dir: (string) Directory where the data lies (in text form).\n",
    "          rank_k : (int) Which rank to use in the matrix factorization. This will\n",
    "            also be the feature dimension of both the user and the movie features.\n",
    "          batch_size: (int) Number of observations generated per call.\n",
    "          num_actions: (int) How many movies to choose from per round.\n",
    "          csv_delimiter: (string) The delimiter to use in loading the data csv file.\n",
    "          name: (string) The name of this environment instance.\n",
    "        \"\"\"\n",
    "        self._batch_size = batch_size\n",
    "        self._num_actions = num_actions\n",
    "        self.rank_k = rank_k\n",
    "\n",
    "        # Compute the matrix factorization.\n",
    "        # self._data_matrix = dataset_utilities.load_movielens_data(\n",
    "        #     data_dir, delimiter=csv_delimiter)\n",
    "\n",
    "        self._data_matrix, self._user_age_int, self._user_occ_int, self._mov_gen_int = load_movielens_data(ratings)\n",
    "        self._num_users, self._num_movies = self._data_matrix.shape\n",
    "\n",
    "        # Compute the SVD.\n",
    "        u, s, vh = np.linalg.svd(self._data_matrix, full_matrices=False)\n",
    "\n",
    "        # Keep only the largest singular values.\n",
    "        self._u_hat = u[:, :rank_k].astype(np.float32)\n",
    "        self._s_hat = s[:rank_k].astype(np.float32)\n",
    "        self._v_hat = np.transpose(vh[:rank_k]).astype(np.float32)\n",
    "\n",
    "        self._approx_ratings_matrix = np.matmul(self._u_hat * self._s_hat,\n",
    "                                                np.transpose(self._v_hat))\n",
    "\n",
    "        self._action_spec = array_spec.BoundedArraySpec(\n",
    "            shape=(),\n",
    "            dtype=np.int32,\n",
    "            minimum=0,\n",
    "            maximum=num_actions - 1,\n",
    "            name='action')\n",
    "        observation_spec = {\n",
    "            GLOBAL_KEY:\n",
    "                array_spec.ArraySpec(shape=[rank_k+2], dtype=np.float32), #creating +space for user age and occupation\n",
    "            PER_ARM_KEY:\n",
    "                array_spec.ArraySpec(\n",
    "                    shape=[num_actions, rank_k+1], dtype=np.float32), #creating +1 space for movie genre\n",
    "        }\n",
    "        self._time_step_spec = ts.time_step_spec(observation_spec)\n",
    "\n",
    "        self._current_user_indices = np.zeros(batch_size, dtype=np.int32)\n",
    "        self._previous_user_indices = np.zeros(batch_size, dtype=np.int32)\n",
    "\n",
    "        self._current_movie_indices = np.zeros([batch_size, num_actions],\n",
    "                                               dtype=np.int32)\n",
    "        self._previous_movie_indices = np.zeros([batch_size, num_actions],\n",
    "                                                dtype=np.int32)\n",
    "\n",
    "        self._observation = {\n",
    "            GLOBAL_KEY:\n",
    "                np.zeros([batch_size, rank_k+2]), #making space like above for dimensions\n",
    "            PER_ARM_KEY:\n",
    "                np.zeros([batch_size, num_actions, rank_k+1]),\n",
    "        }\n",
    "\n",
    "        super(MovieLensPerArmPyEnvironment, self).__init__(\n",
    "            observation_spec, self._action_spec, name=name)\n",
    "\n",
    "    @property\n",
    "    def batch_size(self):\n",
    "        return self._batch_size\n",
    "\n",
    "    @property\n",
    "    def batched(self):\n",
    "        return True\n",
    "\n",
    "    def _observe(self):\n",
    "        sampled_user_indices = np.random.randint(\n",
    "            self._num_users, size=self._batch_size)\n",
    "        self._previous_user_indices = self._current_user_indices\n",
    "        self._current_user_indices = sampled_user_indices\n",
    "\n",
    "        sampled_movie_indices = np.array([\n",
    "            random.sample(range(self._num_movies), self._num_actions)\n",
    "            for _ in range(self._batch_size)\n",
    "        ])\n",
    "        sampled_user_ages = self._user_age_int[sampled_user_indices]\n",
    "        sampled_user_occ = self._user_occ_int[sampled_user_indices]\n",
    "        combined_user_features = np.concatenate((self._u_hat[sampled_user_indices]\n",
    "                                                 , sampled_user_ages.reshape(-1,1)\n",
    "                                                 , sampled_user_occ.reshape(-1,1)), axis=1)\n",
    "        # current_users = combined_user_features.reshape([self._batch_size, self.rank_k+2])\n",
    "        \n",
    "        movie_index_vector = sampled_movie_indices.reshape(-1)\n",
    "        print(movie_index_vector.shape)\n",
    "        flat_genre_list = self._mov_gen_int[movie_index_vector] #shape of 1\n",
    "        flat_movie_list = self._v_hat[movie_index_vector] #shape of 2\n",
    "        combined_movie_features = np.concatenate((flat_movie_list,flat_genre_list.reshape(-1,1)), axis=1)\n",
    "        current_movies = combined_movie_features.reshape(\n",
    "            [self._batch_size, self._num_actions, self.rank_k+1])\n",
    "\n",
    "        self._previous_movie_indices = self._current_movie_indices\n",
    "        self._current_movie_indices = sampled_movie_indices\n",
    "\n",
    "        batched_observations = {\n",
    "            GLOBAL_KEY:\n",
    "                combined_user_features,\n",
    "            PER_ARM_KEY:\n",
    "                current_movies,\n",
    "        }\n",
    "        return batched_observations\n",
    "\n",
    "    def _apply_action(self, action):\n",
    "        chosen_arm_indices = self._current_movie_indices[range(self._batch_size),\n",
    "                                                         action]\n",
    "        return self._approx_ratings_matrix[self._current_user_indices,\n",
    "                                           chosen_arm_indices]\n",
    "\n",
    "    def _rewards_for_all_actions(self):\n",
    "        rewards_matrix = self._approx_ratings_matrix[\n",
    "            np.expand_dims(self._previous_user_indices, axis=-1),\n",
    "            self._previous_movie_indices]\n",
    "        return rewards_matrix\n",
    "\n",
    "    def compute_optimal_action(self):\n",
    "        return np.argmax(self._rewards_for_all_actions(), axis=-1)\n",
    "\n",
    "    def compute_optimal_reward(self):\n",
    "        return np.max(self._rewards_for_all_actions(), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d4188ae1-0859-4053-8a5f-b83c1e8a0c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MovieLensPerArmPyEnvironment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534b3fc5-d37e-4220-a081-627972436dda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "007053ce-47e6-4b16-82f5-1cdd8d51640d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-4.68955468e-03,  1.15368254e-02,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [-1.03842514e-02, -9.09375027e-03,  4.00000000e+00,\n",
       "         3.00000000e+00],\n",
       "       [-5.50003052e-02, -2.59428471e-02,  3.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [-4.29374538e-03, -2.62549985e-02,  2.00000000e+00,\n",
       "         3.00000000e+00],\n",
       "       [-2.11818181e-02, -3.80838960e-02,  4.00000000e+00,\n",
       "         1.40000000e+01],\n",
       "       [-3.31762508e-02,  2.35662591e-02,  6.00000000e+00,\n",
       "         1.80000000e+01],\n",
       "       [-5.02946274e-03, -2.92349514e-02,  3.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [-3.83273163e-03, -1.97077598e-02,  3.00000000e+00,\n",
       "         1.80000000e+01],\n",
       "       [-4.78417985e-03, -1.07728569e-02,  3.00000000e+00,\n",
       "         1.40000000e+01],\n",
       "       [-6.78159371e-02,  5.32993756e-04,  6.00000000e+00,\n",
       "         0.00000000e+00]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset().observation['global']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "79623a28-4e47-4f0e-86de-b61382b939fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation spec:  {'global': ArraySpec(shape=(4,), dtype=dtype('float32'), name=None), 'per_arm': ArraySpec(shape=(100, 3), dtype=dtype('float32'), name=None)}\n",
      "(1000,)\n",
      "\n",
      "An observation:  {'global': array([[-6.27098745e-03, -1.67641863e-02,  3.00000000e+00,\n",
      "         0.00000000e+00],\n",
      "       [-2.97608413e-03, -1.70790255e-02,  1.00000000e+00,\n",
      "         1.70000000e+01],\n",
      "       [-1.42527726e-02, -1.05242254e-02,  1.00000000e+00,\n",
      "         1.10000000e+01],\n",
      "       [-3.44458502e-03, -1.78005211e-02,  1.00000000e+00,\n",
      "         1.80000000e+01],\n",
      "       [-1.50922006e-02, -6.70611635e-02,  6.00000000e+00,\n",
      "         1.80000000e+01],\n",
      "       [-1.11539718e-02,  5.84645150e-03,  6.00000000e+00,\n",
      "         1.60000000e+01],\n",
      "       [-2.79517733e-02, -2.42402889e-02,  2.00000000e+00,\n",
      "         1.60000000e+01],\n",
      "       [-1.35534508e-02, -4.30957861e-02,  3.00000000e+00,\n",
      "         2.00000000e+00],\n",
      "       [-2.55223755e-02, -1.27906390e-02,  3.00000000e+00,\n",
      "         1.50000000e+01],\n",
      "       [-3.76718380e-02,  8.15294962e-03,  6.00000000e+00,\n",
      "         1.40000000e+01]]), 'per_arm': array([[[-1.68236755e-02, -1.40702166e-02,  4.00000000e+00],\n",
      "        [-1.19793764e-03, -2.11847574e-03,  7.00000000e+00],\n",
      "        [-1.19641088e-02, -3.45097738e-03,  0.00000000e+00],\n",
      "        ...,\n",
      "        [-1.22064266e-04, -7.42235978e-04,  0.00000000e+00],\n",
      "        [-2.24793889e-03, -2.77019967e-03,  4.00000000e+00],\n",
      "        [-3.23382020e-02, -6.03822321e-02,  0.00000000e+00]],\n",
      "\n",
      "       [[-9.52098425e-03, -6.06110087e-03,  0.00000000e+00],\n",
      "        [-1.09669827e-02, -1.16315978e-02,  0.00000000e+00],\n",
      "        [-1.18204840e-01,  3.52745652e-02,  7.00000000e+00],\n",
      "        ...,\n",
      "        [-1.64363105e-02, -9.98799596e-03,  5.00000000e+00],\n",
      "        [-7.66156614e-03, -2.15062592e-03,  4.00000000e+00],\n",
      "        [-6.07306808e-02,  6.88344985e-02,  1.50000000e+01]],\n",
      "\n",
      "       [[-4.13820567e-03,  1.12610338e-02,  2.00000000e+00],\n",
      "        [-6.99635521e-02,  1.87696721e-02,  7.00000000e+00],\n",
      "        [-4.04900126e-02,  5.66257499e-02,  0.00000000e+00],\n",
      "        ...,\n",
      "        [-3.58686229e-04,  1.38587120e-05,  0.00000000e+00],\n",
      "        [-7.54112229e-02, -7.72761703e-02,  7.00000000e+00],\n",
      "        [-9.05533205e-04,  2.44632922e-03,  4.00000000e+00]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-9.57235534e-05,  2.19103051e-04,  7.00000000e+00],\n",
      "        [-1.90379936e-02, -3.72062586e-02,  6.00000000e+00],\n",
      "        [-6.38135448e-02,  2.77147852e-02,  0.00000000e+00],\n",
      "        ...,\n",
      "        [-1.94153860e-02,  1.64054409e-02,  7.00000000e+00],\n",
      "        [-6.22018357e-04,  8.85651330e-04,  7.00000000e+00],\n",
      "        [-6.48105592e-02, -7.38782203e-03,  4.00000000e+00]],\n",
      "\n",
      "       [[-4.43708181e-04, -5.15828317e-04,  7.00000000e+00],\n",
      "        [-2.75063881e-04,  1.41952783e-04,  2.00000000e+00],\n",
      "        [-2.66395863e-02, -8.49816799e-02,  4.00000000e+00],\n",
      "        ...,\n",
      "        [-5.33709768e-04,  1.50667445e-03,  7.00000000e+00],\n",
      "        [-1.30407680e-02, -2.72822995e-02,  3.00000000e+00],\n",
      "        [-2.44210823e-03,  2.31362088e-03,  7.00000000e+00]],\n",
      "\n",
      "       [[-6.02861904e-02,  8.43269452e-02,  2.00000000e+00],\n",
      "        [-4.08615684e-03, -8.99193808e-03,  4.00000000e+00],\n",
      "        [-6.54310174e-03,  3.64946458e-03,  1.00000000e+00],\n",
      "        ...,\n",
      "        [-9.57235534e-05,  2.19103051e-04,  7.00000000e+00],\n",
      "        [-3.05079102e-05, -3.14309873e-04,  1.00000000e+01],\n",
      "        [-1.76518485e-02, -3.04364171e-02,  7.00000000e+00]]])}\n"
     ]
    }
   ],
   "source": [
    "print('observation spec: ', env.observation_spec())\n",
    "print('\\nAn observation: ', env.reset().observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4348dcce-d92e-47c1-af00-ae5181c0184d",
   "metadata": {},
   "source": [
    "### Now that the environment is created, let's optimize\n",
    "\n",
    "Taken from here\n",
    "https://github.com/tensorflow/agents/blob/5e5915b0a3650a15e82e77af6e37f41a6c744689/tf_agents/bandits/agents/examples/v2/train_eval_movielens.py#L84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ea63b13a-f613-40f3-8184-68d14e45f3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import os\n",
    "from absl import app\n",
    "from absl import flags\n",
    "\n",
    "import tensorflow as tf  # pylint: disable=g-explicit-tensorflow-version-import\n",
    "from tf_agents.bandits.agents import dropout_thompson_sampling_agent as dropout_ts_agent\n",
    "from tf_agents.bandits.agents import lin_ucb_agent\n",
    "from tf_agents.bandits.agents import linear_thompson_sampling_agent as lin_ts_agent\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent as eps_greedy_agent\n",
    "from tf_agents.bandits.agents.examples.v2 import trainer\n",
    "from tf_agents.bandits.environments import environment_utilities\n",
    "from tf_agents.bandits.environments import movielens_per_arm_py_environment\n",
    "from tf_agents.bandits.environments import movielens_py_environment\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.networks import q_network\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "TRAINING_LOOPS = 20000\n",
    "STEPS_PER_LOOP = 2\n",
    "\n",
    "RANK_K = 20\n",
    "NUM_ACTIONS = 20\n",
    "\n",
    "# LinUCB agent constants.\n",
    "\n",
    "AGENT_ALPHA = 10.0\n",
    "\n",
    "# epsilon Greedy constants.\n",
    "\n",
    "EPSILON = 0.05\n",
    "LAYERS = (50, 50, 50)\n",
    "LR = 0.005\n",
    "\n",
    "# Dropout TS constants.\n",
    "DROPOUT_RATE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f1d468cf-446a-49d0-aee1-bff3c401e493",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9d32f9df-0159-464f-bf11-c054f98ef0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MovieLensPerArmPyEnvironment(\n",
    "        rank_k=RANK_K,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_actions=NUM_ACTIONS,\n",
    ")\n",
    "environment = tf_py_environment.TFPyEnvironment(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c03aba-3f12-4375-998e-919585c2f9c1",
   "metadata": {},
   "source": [
    "### Note we will be using the reward function with this utility function\n",
    "\n",
    "```python\n",
    "@gin.configurable\n",
    "def compute_optimal_reward_with_movielens_environment(observation, environment):\n",
    "  \"\"\"Helper function for gin configurable Regret metric.\"\"\"\n",
    "  del observation\n",
    "  return tf.py_function(environment.compute_optimal_reward, [], tf.float32)\n",
    "\n",
    "@gin.configurable\n",
    "def compute_optimal_action_with_movielens_environment(observation,\n",
    "                                                      environment,\n",
    "                                                      action_dtype=tf.int32):\n",
    "  \"\"\"Helper function for gin configurable SuboptimalArms metric.\"\"\"\n",
    "  del observation\n",
    "  return tf.py_function(environment.compute_optimal_action, [], action_dtype)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "78599527-d82d-4048-a319-2dbf7e878db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_reward_fn = functools.partial(\n",
    "      environment_utilities.compute_optimal_reward_with_movielens_environment,\n",
    "      environment=environment)\n",
    "\n",
    "optimal_action_fn = functools.partial(\n",
    "  environment_utilities.compute_optimal_action_with_movielens_environment,\n",
    "  environment=environment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1d1011-8a9b-4f56-9ee7-9492b1a6f01b",
   "metadata": {},
   "source": [
    "### Below we will try different agents by selecting one of the enumerated types:\n",
    "\n",
    "```python\n",
    "flags.DEFINE_enum(\n",
    "    'agent', 'LinUCB', ['LinUCB', 'LinTS', 'epsGreedy', 'DropoutTS'],\n",
    "    'Which agent to use. Possible values: `LinUCB`, `LinTS`, `epsGreedy`,'\n",
    "    ' `DropoutTS`.')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3a6a8c07-e655-49e1-871d-ae5e567c2256",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_TYPE = 'LinUCB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "795f6e5b-e98e-4d85-9935-59deae6ba60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if AGENT_TYPE == 'LinUCB':\n",
    "    agent = lin_ucb_agent.LinearUCBAgent(\n",
    "        time_step_spec=environment.time_step_spec(),\n",
    "        action_spec=environment.action_spec(),\n",
    "        tikhonov_weight=0.001,\n",
    "        alpha=AGENT_ALPHA,\n",
    "        dtype=tf.float32,\n",
    "        accepts_per_arm_features=True)\n",
    "\n",
    "elif AGENT_TYPE == 'LinTS':\n",
    "    agent = lin_ts_agent.LinearThompsonSamplingAgent(\n",
    "        time_step_spec=environment.time_step_spec(),\n",
    "        action_spec=environment.action_spec(),\n",
    "        dtype=tf.float32,\n",
    "        accepts_per_arm_features=True)\n",
    "\n",
    "elif AGENT_TYPE == 'epsGreedy':\n",
    "    network = (\n",
    "      global_and_arm_feature_network\n",
    "      .create_feed_forward_dot_product_network(\n",
    "          environment.time_step_spec().observation,\n",
    "          global_layers=LAYERS,\n",
    "          arm_layers=LAYERS))\n",
    "\n",
    "    agent = eps_greedy_agent.NeuralEpsilonGreedyAgent(\n",
    "        time_step_spec=environment.time_step_spec(),\n",
    "        action_spec=environment.action_spec(),\n",
    "        reward_network=network,\n",
    "        optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=LR),\n",
    "        epsilon=EPSILON,\n",
    "        emit_policy_info='predicted_rewards_mean',\n",
    "        info_fields_to_inherit_from_greedy=['predicted_rewards_mean'])\n",
    "\n",
    "elif AGENT_TYPE == 'DropoutTS':\n",
    "    train_step_counter = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "    def dropout_fn():\n",
    "        return tf.math.maximum(\n",
    "          tf.math.reciprocal_no_nan(1.01 +\n",
    "                                    tf.cast(train_step_counter, tf.float32)),\n",
    "          0.0003)\n",
    "\n",
    "    agent = dropout_ts_agent.DropoutThompsonSamplingAgent(\n",
    "        time_step_spec=environment.time_step_spec(),\n",
    "        action_spec=environment.action_spec(),\n",
    "        dropout_rate=dropout_fn,\n",
    "        network_layers=LAYERS,\n",
    "        optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=LR))\n",
    "\n",
    "regret_metric = tf_bandit_metrics.RegretMetric(optimal_reward_fn)\n",
    "suboptimal_arms_metric = tf_bandit_metrics.SuboptimalArmsMetric(\n",
    "  optimal_action_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4ebbb8-bc40-42a5-bbbd-9438d3ff2e74",
   "metadata": {},
   "source": [
    "### Now train the MAB Agent\n",
    "\n",
    "Create a local checkpoint folder if you already have not\n",
    "!mkdir checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "46b033cd-dd23-4e93-a33c-347f7e3915f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "67a9c912-b2b6-44c7-909a-d431316ce0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160,)\n",
      "(160,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tensor conversion requested dtype float32 for Tensor with dtype float64: <tf.Tensor: shape=(8, 22), dtype=float64, numpy=\narray([[-2.85286382e-02, -8.30348656e-02,  3.75065953e-03,\n         2.72332150e-02,  5.02408035e-02, -4.55792844e-02,\n        -5.30029275e-02,  6.67323694e-02,  4.98623326e-02,\n        -6.48648757e-03, -4.36089113e-02, -2.25173049e-02,\n         1.53402111e-03,  4.71154377e-02, -1.16039803e-02,\n         3.48937027e-02, -3.36154997e-02,  5.44842742e-02,\n        -5.66345733e-03, -3.53569910e-02,  1.00000000e+00,\n         1.60000000e+01],\n       [-1.32478410e-02,  4.16449225e-03,  2.51094010e-02,\n         2.79174931e-02,  3.89474770e-03, -1.92512367e-02,\n        -1.16578955e-02,  3.73599993e-04, -2.27175280e-02,\n        -2.44750548e-03,  2.26559527e-02, -9.07483138e-03,\n         2.50538439e-02,  8.02389439e-03,  8.56140105e-04,\n         1.23351971e-02,  1.48605853e-02,  5.15011661e-02,\n         9.64668696e-04,  1.86574403e-02,  6.00000000e+00,\n         3.00000000e+00],\n       [-2.55665858e-03, -1.67801455e-02,  1.31196734e-02,\n        -2.41004191e-02, -2.89556943e-02,  3.32159386e-03,\n        -1.10585836e-03,  2.77119875e-03, -1.52279716e-02,\n        -1.17484562e-03, -1.29997730e-02, -4.12607240e-03,\n        -6.87728450e-03,  1.40890284e-02, -2.87873615e-02,\n        -3.48946638e-03, -3.36277648e-03,  2.85210693e-03,\n        -1.39566408e-02, -6.06396422e-03,  1.00000000e+00,\n         1.40000000e+01],\n       [-8.81190225e-03, -4.35974775e-03, -7.75873289e-03,\n        -9.46944859e-03,  1.15040103e-02, -1.08958669e-02,\n        -2.21011462e-03,  3.52963689e-03, -2.10935380e-02,\n        -7.49948341e-03, -1.77914358e-03,  3.43288071e-02,\n        -2.85508260e-02, -2.30196188e-03,  1.12295933e-02,\n         2.82370280e-02,  1.54071823e-02, -6.10279571e-03,\n        -1.52209019e-02,  9.45333019e-03,  6.00000000e+00,\n         3.00000000e+00],\n       [-4.22420911e-02, -1.09271482e-02, -5.85460439e-02,\n         3.50311585e-02, -1.50090363e-02,  6.29468122e-03,\n        -5.39392009e-02, -5.63217886e-02,  1.71908084e-02,\n         3.27809118e-02,  6.16293997e-02,  2.58915871e-03,\n        -1.40729891e-02, -5.97901195e-02, -1.48193222e-02,\n         6.35253359e-03,  3.29656564e-02,  2.31040660e-02,\n        -3.94899622e-02, -3.40745039e-02,  6.00000000e+00,\n         1.30000000e+01],\n       [-6.03723386e-03, -2.47350316e-02,  1.40131377e-02,\n        -2.03119311e-02, -1.03975004e-02, -1.96192954e-02,\n         1.38517786e-02,  7.08270702e-04, -1.20781455e-02,\n        -2.16923822e-02,  3.55492724e-04, -1.20227737e-02,\n        -5.33643458e-03, -2.38411203e-02, -2.98537761e-02,\n         1.37217995e-02,  2.03982033e-02, -3.47599350e-02,\n         2.22367961e-02,  1.65403392e-02,  6.00000000e+00,\n         1.80000000e+01],\n       [-4.70907381e-03, -1.29451100e-02,  2.07819603e-03,\n         1.10747956e-03,  3.46148089e-02, -3.44468723e-03,\n         4.87130228e-03,  1.18843513e-02,  5.42217819e-03,\n        -6.30503660e-03,  5.71571756e-03, -3.08698625e-03,\n        -4.02005669e-03,  1.43769924e-02, -1.05472619e-03,\n        -1.86135445e-03,  1.03786774e-02,  1.25164865e-03,\n        -8.69105291e-03, -2.12250892e-02,  6.00000000e+00,\n         0.00000000e+00],\n       [-3.49715166e-03, -2.26494148e-02,  1.35827623e-02,\n        -2.75515318e-02, -2.41772141e-02, -5.76983625e-03,\n        -3.94003093e-03,  7.09942193e-04, -1.94040183e-02,\n        -6.86124898e-03, -1.80153456e-02, -2.71025561e-02,\n        -7.31135067e-03, -2.39296630e-03, -6.23780899e-02,\n        -3.45613668e-03, -1.67462823e-03, -1.07506933e-02,\n         9.98086995e-04,  2.56368592e-02,  1.00000000e+00,\n         3.00000000e+00]])>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m      \u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcheckpoint\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m      \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m      \u001b[49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtraining_loops\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRAINING_LOOPS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_loop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSTEPS_PER_LOOP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m      \u001b[49m\u001b[43madditional_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mregret_metric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuboptimal_arms_metric\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/bandits/agents/examples/v2/trainer.py:268\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(root_dir, agent, environment, training_loops, steps_per_loop, async_steps_per_loop, additional_metrics, get_replay_buffer_fn, get_training_loop_fn, training_data_spec_transformation_fn, save_policy, resume_training_loops)\u001b[0m\n\u001b[1;32m    265\u001b[0m   starting_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(starting_loop, training_loops):\n\u001b[0;32m--> 268\u001b[0m   \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m   checkpoint_manager\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m    270\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m save_policy \u001b[38;5;241m&\u001b[39m (i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/bandits/agents/examples/v2/trainer.py:87\u001b[0m, in \u001b[0;36m_get_training_loop.<locals>.training_loop\u001b[0;34m(train_step, metrics)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a function that runs a single training loop and logs metrics.\"\"\"\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(async_steps_per_loop):\n\u001b[0;32m---> 87\u001b[0m   \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m   _export_metrics_and_summaries(\n\u001b[1;32m     89\u001b[0m       step\u001b[38;5;241m=\u001b[39mtrain_step \u001b[38;5;241m*\u001b[39m async_steps_per_loop \u001b[38;5;241m+\u001b[39m batch_id, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n\u001b[1;32m     90\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mbatch_size\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/drivers/dynamic_step_driver.py:182\u001b[0m, in \u001b[0;36mDynamicStepDriver.run\u001b[0;34m(self, time_step, policy_state, maximum_iterations)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, time_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, policy_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, maximum_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    166\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Takes steps in the environment using the policy while updating observers.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03m    policy_state: Tensor with final step policy state.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtime_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpolicy_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmaximum_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximum_iterations\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/utils/common.py:188\u001b[0m, in \u001b[0;36mfunction_in_tf1.<locals>.maybe_wrap.<locals>.with_check_resource_vars\u001b[0;34m(*fn_args, **fn_kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m check_tf1_allowed()\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_eager_been_enabled():\n\u001b[1;32m    186\u001b[0m   \u001b[38;5;66;03m# We're either in eager mode or in tf.function mode (no in-between); so\u001b[39;00m\n\u001b[1;32m    187\u001b[0m   \u001b[38;5;66;03m# autodep-like behavior is already expected of fn.\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m resource_variables_enabled():\n\u001b[1;32m    190\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(MISSING_RESOURCE_VARIABLES_ERROR)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/drivers/dynamic_step_driver.py:202\u001b[0m, in \u001b[0;36mDynamicStepDriver._run\u001b[0;34m(self, time_step, policy_state, maximum_iterations)\u001b[0m\n\u001b[1;32m    196\u001b[0m batch_dims \u001b[38;5;241m=\u001b[39m nest_utils\u001b[38;5;241m.\u001b[39mget_outer_shape(time_step,\n\u001b[1;32m    197\u001b[0m                                         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mtime_step_spec())\n\u001b[1;32m    198\u001b[0m counter \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mzeros(batch_dims, tf\u001b[38;5;241m.\u001b[39mint32)\n\u001b[1;32m    200\u001b[0m [_, time_step, policy_state] \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m    201\u001b[0m     tf\u001b[38;5;241m.\u001b[39mstop_gradient,\n\u001b[0;32m--> 202\u001b[0m     \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhile_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loop_condition_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loop_body_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloop_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcounter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_state\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparallel_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximum_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximum_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdriver_loop\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m time_step, policy_state\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/deprecation.py:648\u001b[0m, in \u001b[0;36mdeprecated_arg_values.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    640\u001b[0m           _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    641\u001b[0m         logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    642\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    643\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwill be removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m    647\u001b[0m             (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date), instructions)\n\u001b[0;32m--> 648\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/control_flow_ops.py:2574\u001b[0m, in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m   2368\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile_loop\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m   2369\u001b[0m \u001b[38;5;129m@deprecation\u001b[39m\u001b[38;5;241m.\u001b[39mdeprecated_arg_values(\n\u001b[1;32m   2370\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2385\u001b[0m                   maximum_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2386\u001b[0m                   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2387\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Repeat `body` while the condition `cond` is true.\u001b[39;00m\n\u001b[1;32m   2388\u001b[0m \n\u001b[1;32m   2389\u001b[0m \u001b[38;5;124;03m  Note: This op is automatically used in a `tf.function` to convert Python for-\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2572\u001b[0m \n\u001b[1;32m   2573\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2574\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwhile_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2575\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2576\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2577\u001b[0m \u001b[43m      \u001b[49m\u001b[43mloop_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloop_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2578\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshape_invariants\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape_invariants\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2579\u001b[0m \u001b[43m      \u001b[49m\u001b[43mparallel_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2580\u001b[0m \u001b[43m      \u001b[49m\u001b[43mback_prop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mback_prop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2581\u001b[0m \u001b[43m      \u001b[49m\u001b[43mswap_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswap_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2582\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2583\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmaximum_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximum_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2584\u001b[0m \u001b[43m      \u001b[49m\u001b[43mreturn_same_structure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/control_flow_ops.py:2823\u001b[0m, in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2820\u001b[0m loop_var_structure \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(type_spec\u001b[38;5;241m.\u001b[39mtype_spec_from_value,\n\u001b[1;32m   2821\u001b[0m                                         \u001b[38;5;28mlist\u001b[39m(loop_vars))\n\u001b[1;32m   2822\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cond(\u001b[38;5;241m*\u001b[39mloop_vars):\n\u001b[0;32m-> 2823\u001b[0m   loop_vars \u001b[38;5;241m=\u001b[39m \u001b[43mbody\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mloop_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2824\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m try_to_pack \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loop_vars, (\u001b[38;5;28mlist\u001b[39m, _basetuple)):\n\u001b[1;32m   2825\u001b[0m     packed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/drivers/dynamic_step_driver.py:148\u001b[0m, in \u001b[0;36mDynamicStepDriver._loop_body_fn.<locals>.loop_body\u001b[0;34m(counter, time_step, policy_state)\u001b[0m\n\u001b[1;32m    144\u001b[0m   time_step \u001b[38;5;241m=\u001b[39m time_step\u001b[38;5;241m.\u001b[39m_replace(\n\u001b[1;32m    145\u001b[0m       step_type\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfill(batch_size, ts\u001b[38;5;241m.\u001b[39mStepType\u001b[38;5;241m.\u001b[39mFIRST))\n\u001b[1;32m    147\u001b[0m traj \u001b[38;5;241m=\u001b[39m trajectory\u001b[38;5;241m.\u001b[39mfrom_transition(time_step, action_step, next_time_step)\n\u001b[0;32m--> 148\u001b[0m observer_ops \u001b[38;5;241m=\u001b[39m [observer(traj) \u001b[38;5;28;01mfor\u001b[39;00m observer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_observers]\n\u001b[1;32m    149\u001b[0m transition_observer_ops \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    150\u001b[0m     observer((time_step, action_step, next_time_step))\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m observer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transition_observers\n\u001b[1;32m    152\u001b[0m ]\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies(\n\u001b[1;32m    154\u001b[0m     [tf\u001b[38;5;241m.\u001b[39mgroup(observer_ops \u001b[38;5;241m+\u001b[39m transition_observer_ops)]):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/drivers/dynamic_step_driver.py:148\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    144\u001b[0m   time_step \u001b[38;5;241m=\u001b[39m time_step\u001b[38;5;241m.\u001b[39m_replace(\n\u001b[1;32m    145\u001b[0m       step_type\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfill(batch_size, ts\u001b[38;5;241m.\u001b[39mStepType\u001b[38;5;241m.\u001b[39mFIRST))\n\u001b[1;32m    147\u001b[0m traj \u001b[38;5;241m=\u001b[39m trajectory\u001b[38;5;241m.\u001b[39mfrom_transition(time_step, action_step, next_time_step)\n\u001b[0;32m--> 148\u001b[0m observer_ops \u001b[38;5;241m=\u001b[39m [\u001b[43mobserver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraj\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m observer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_observers]\n\u001b[1;32m    149\u001b[0m transition_observer_ops \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    150\u001b[0m     observer((time_step, action_step, next_time_step))\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m observer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transition_observers\n\u001b[1;32m    152\u001b[0m ]\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies(\n\u001b[1;32m    154\u001b[0m     [tf\u001b[38;5;241m.\u001b[39mgroup(observer_ops \u001b[38;5;241m+\u001b[39m transition_observer_ops)]):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/replay_buffers/replay_buffer.py:83\u001b[0m, in \u001b[0;36mReplayBuffer.add_batch\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m, items):\n\u001b[1;32m     73\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Adds a batch of items to the replay buffer.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03m    Adds `items` to the replay buffer.\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/replay_buffers/tf_uniform_replay_buffer.py:205\u001b[0m, in \u001b[0;36mTFUniformReplayBuffer._add_batch\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    203\u001b[0m write_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_rows_for_id(id_)\n\u001b[1;32m    204\u001b[0m write_id_op \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id_table\u001b[38;5;241m.\u001b[39mwrite(write_rows, id_)\n\u001b[0;32m--> 205\u001b[0m write_data_op \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrite_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitems\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mgroup(write_id_op, write_data_op)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/replay_buffers/table.py:128\u001b[0m, in \u001b[0;36mTable.write\u001b[0;34m(self, rows, values, slots)\u001b[0m\n\u001b[1;32m    126\u001b[0m flattened_slots \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(slots)\n\u001b[1;32m    127\u001b[0m flattened_values \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(values)\n\u001b[0;32m--> 128\u001b[0m write_ops \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    129\u001b[0m     tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mscatter_update(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slot2storage_map[slot], rows,\n\u001b[1;32m    130\u001b[0m                                 value)\u001b[38;5;241m.\u001b[39mop\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (slot, value) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flattened_slots, flattened_values)\n\u001b[1;32m    132\u001b[0m ]\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m*\u001b[39mwrite_ops)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/replay_buffers/table.py:129\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    126\u001b[0m flattened_slots \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(slots)\n\u001b[1;32m    127\u001b[0m flattened_values \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(values)\n\u001b[1;32m    128\u001b[0m write_ops \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 129\u001b[0m     \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter_update\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_slot2storage_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mslot\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mop\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (slot, value) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flattened_slots, flattened_values)\n\u001b[1;32m    132\u001b[0m ]\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m*\u001b[39mwrite_ops)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/state_ops.py:432\u001b[0m, in \u001b[0;36mscatter_update\u001b[0;34m(ref, indices, updates, use_locking, name)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ref\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39m_is_ref_dtype:\n\u001b[1;32m    429\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m gen_state_ops\u001b[38;5;241m.\u001b[39mscatter_update(ref, indices, updates,\n\u001b[1;32m    430\u001b[0m                                       use_locking\u001b[38;5;241m=\u001b[39muse_locking, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ref\u001b[38;5;241m.\u001b[39m_lazy_read(gen_resource_variable_ops\u001b[38;5;241m.\u001b[39mresource_scatter_update(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 432\u001b[0m     ref\u001b[38;5;241m.\u001b[39mhandle, indices, \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    433\u001b[0m     name\u001b[38;5;241m=\u001b[39mname))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1603\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1601\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Tensor):\n\u001b[1;32m   1602\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mis_compatible_with(value\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m-> 1603\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1604\u001b[0m         _add_error_prefix(\n\u001b[1;32m   1605\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor conversion requested dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1606\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor Tensor with dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1607\u001b[0m             name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m   1608\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[1;32m   1610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preferred_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor conversion requested dtype float32 for Tensor with dtype float64: <tf.Tensor: shape=(8, 22), dtype=float64, numpy=\narray([[-2.85286382e-02, -8.30348656e-02,  3.75065953e-03,\n         2.72332150e-02,  5.02408035e-02, -4.55792844e-02,\n        -5.30029275e-02,  6.67323694e-02,  4.98623326e-02,\n        -6.48648757e-03, -4.36089113e-02, -2.25173049e-02,\n         1.53402111e-03,  4.71154377e-02, -1.16039803e-02,\n         3.48937027e-02, -3.36154997e-02,  5.44842742e-02,\n        -5.66345733e-03, -3.53569910e-02,  1.00000000e+00,\n         1.60000000e+01],\n       [-1.32478410e-02,  4.16449225e-03,  2.51094010e-02,\n         2.79174931e-02,  3.89474770e-03, -1.92512367e-02,\n        -1.16578955e-02,  3.73599993e-04, -2.27175280e-02,\n        -2.44750548e-03,  2.26559527e-02, -9.07483138e-03,\n         2.50538439e-02,  8.02389439e-03,  8.56140105e-04,\n         1.23351971e-02,  1.48605853e-02,  5.15011661e-02,\n         9.64668696e-04,  1.86574403e-02,  6.00000000e+00,\n         3.00000000e+00],\n       [-2.55665858e-03, -1.67801455e-02,  1.31196734e-02,\n        -2.41004191e-02, -2.89556943e-02,  3.32159386e-03,\n        -1.10585836e-03,  2.77119875e-03, -1.52279716e-02,\n        -1.17484562e-03, -1.29997730e-02, -4.12607240e-03,\n        -6.87728450e-03,  1.40890284e-02, -2.87873615e-02,\n        -3.48946638e-03, -3.36277648e-03,  2.85210693e-03,\n        -1.39566408e-02, -6.06396422e-03,  1.00000000e+00,\n         1.40000000e+01],\n       [-8.81190225e-03, -4.35974775e-03, -7.75873289e-03,\n        -9.46944859e-03,  1.15040103e-02, -1.08958669e-02,\n        -2.21011462e-03,  3.52963689e-03, -2.10935380e-02,\n        -7.49948341e-03, -1.77914358e-03,  3.43288071e-02,\n        -2.85508260e-02, -2.30196188e-03,  1.12295933e-02,\n         2.82370280e-02,  1.54071823e-02, -6.10279571e-03,\n        -1.52209019e-02,  9.45333019e-03,  6.00000000e+00,\n         3.00000000e+00],\n       [-4.22420911e-02, -1.09271482e-02, -5.85460439e-02,\n         3.50311585e-02, -1.50090363e-02,  6.29468122e-03,\n        -5.39392009e-02, -5.63217886e-02,  1.71908084e-02,\n         3.27809118e-02,  6.16293997e-02,  2.58915871e-03,\n        -1.40729891e-02, -5.97901195e-02, -1.48193222e-02,\n         6.35253359e-03,  3.29656564e-02,  2.31040660e-02,\n        -3.94899622e-02, -3.40745039e-02,  6.00000000e+00,\n         1.30000000e+01],\n       [-6.03723386e-03, -2.47350316e-02,  1.40131377e-02,\n        -2.03119311e-02, -1.03975004e-02, -1.96192954e-02,\n         1.38517786e-02,  7.08270702e-04, -1.20781455e-02,\n        -2.16923822e-02,  3.55492724e-04, -1.20227737e-02,\n        -5.33643458e-03, -2.38411203e-02, -2.98537761e-02,\n         1.37217995e-02,  2.03982033e-02, -3.47599350e-02,\n         2.22367961e-02,  1.65403392e-02,  6.00000000e+00,\n         1.80000000e+01],\n       [-4.70907381e-03, -1.29451100e-02,  2.07819603e-03,\n         1.10747956e-03,  3.46148089e-02, -3.44468723e-03,\n         4.87130228e-03,  1.18843513e-02,  5.42217819e-03,\n        -6.30503660e-03,  5.71571756e-03, -3.08698625e-03,\n        -4.02005669e-03,  1.43769924e-02, -1.05472619e-03,\n        -1.86135445e-03,  1.03786774e-02,  1.25164865e-03,\n        -8.69105291e-03, -2.12250892e-02,  6.00000000e+00,\n         0.00000000e+00],\n       [-3.49715166e-03, -2.26494148e-02,  1.35827623e-02,\n        -2.75515318e-02, -2.41772141e-02, -5.76983625e-03,\n        -3.94003093e-03,  7.09942193e-04, -1.94040183e-02,\n        -6.86124898e-03, -1.80153456e-02, -2.71025561e-02,\n        -7.31135067e-03, -2.39296630e-03, -6.23780899e-02,\n        -3.45613668e-03, -1.67462823e-03, -1.07506933e-02,\n         9.98086995e-04,  2.56368592e-02,  1.00000000e+00,\n         3.00000000e+00]])>"
     ]
    }
   ],
   "source": [
    "trainer.train(\n",
    "      root_dir='checkpoint',\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      training_loops=TRAINING_LOOPS,\n",
    "      steps_per_loop=STEPS_PER_LOOP,\n",
    "      additional_metrics=[regret_metric, suboptimal_arms_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bc634a-e10b-48f3-886c-3dafdc61b733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-12.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-12:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
