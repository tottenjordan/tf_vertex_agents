{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "525b561f-77f5-4736-927f-19929674b868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tf-agents --user -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53da2313-9daf-4662-8d9b-93b813d2a4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1112bb5e-0151-418f-9d17-eb17ee191788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.bandits.agents import lin_ucb_agent\n",
    "from tf_agents.bandits.environments import stationary_stochastic_per_arm_py_environment as p_a_env\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "import tensorflow_datasets as tfds\n",
    "from pprint import pprint\n",
    "\n",
    "nest = tf.nest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dac1a89-b58b-4d4b-92ba-e70d9ed80a96",
   "metadata": {},
   "source": [
    "### movies data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03eb6ba1-8cae-41f6-b65a-31d18165fe69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[4]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'1681'], dtype=object)>,\n",
      " 'movie_title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'You So Crazy (1994)'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")\n",
    "\n",
    "for x in movies.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9c9413-3aa8-4188-b5a2-b342ef50faf2",
   "metadata": {},
   "source": [
    "### user and ratings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92dbdb4b-8f13-4455-887c-6617ebd80242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([45.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'357'], dtype=object)>,\n",
      " 'movie_title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"One Flew Over the Cuckoo's Nest (1975)\"], dtype=object)>,\n",
      " 'raw_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([46.], dtype=float32)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([879024327])>,\n",
      " 'user_gender': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'138'], dtype=object)>,\n",
      " 'user_occupation_label': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([4])>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'doctor'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>,\n",
      " 'user_zip_code': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'53211'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "\n",
    "for x in ratings.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7941678d-f920-4206-9fea-d8e3e9f15cef",
   "metadata": {},
   "source": [
    "#### Let's make this simple and load up movielens that has features\n",
    "We will only consider for this example\n",
    "1) The movie genere as an Arm feature (we will concatenate multiple genres)\n",
    "2) The user occupation and age bucket labels for the overall context features\n",
    "\n",
    "We need to load the data, get the ratings - light EDA for us to get cardnality of the dataset as well as lookups for the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a4c8c8c-6e55-4140-86e7-701308154762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(unique_movie_ids) : 1682\n",
      "unique_movie_ids      : [b'1' b'10']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique movies and users\n",
    "unique_movie_ids = ratings.map(lambda x: x[\"movie_id\"])\n",
    "unique_movie_ids = np.unique([x.numpy() for x in unique_movie_ids])\n",
    "MOVIELENS_NUM_MOVIES = len(unique_movie_ids)\n",
    "\n",
    "\n",
    "print(f\"len(unique_movie_ids) : {len(unique_movie_ids)}\")\n",
    "print(f\"unique_movie_ids      : {unique_movie_ids[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bc12022-129d-48df-8cb3-7e53dbbbfea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(unique_user_ids) : 943\n",
      "unique_user_ids      : [b'1' b'10']\n"
     ]
    }
   ],
   "source": [
    "unique_user_ids = ratings.map(lambda x: x[\"user_id\"])\n",
    "unique_user_ids = np.unique([x.numpy() for x in unique_user_ids])\n",
    "MOVIELENS_NUM_USERS = len(unique_user_ids)\n",
    "\n",
    "\n",
    "print(f\"len(unique_user_ids) : {len(unique_user_ids)}\")\n",
    "print(f\"unique_user_ids      : {unique_user_ids[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cef8a89-0e97-4d93-819e-db2d4667efa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the unnique set of user buckets and create a lookup table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "174860eb-bfeb-4b02-b4d9-1dfaddc70914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def get_dictionary_lookup_by_tf_data_key(key: str) -> Dict:\n",
    "    tensor = ratings.map(lambda x: x[key])\n",
    "    unique_elems = set()\n",
    "    for x in tensor:\n",
    "        val = x.numpy()\n",
    "        if type(val) is np.ndarray: # if multi dimesnional only grab first one\n",
    "            val = val[0]\n",
    "        unique_elems.add(val)\n",
    "    \n",
    "    #return a dictionary of keys by integer values for the feature space\n",
    "    return {val: i for i, val in enumerate(unique_elems)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8113ded-13f2-460f-a2cd-90f44307f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_age_lookup = get_dictionary_lookup_by_tf_data_key('bucketized_user_age')\n",
    "user_age_dim = len(user_age_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bed813e8-cef5-46e0-a1d5-3f6c37ea34a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: 0, 35.0: 1, 45.0: 2, 18.0: 3, 50.0: 4, 56.0: 5, 25.0: 6}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_age_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ced8d46-9e1d-4d88-9228-cb57005d064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_occ_lookup = get_dictionary_lookup_by_tf_data_key('user_occupation_text')\n",
    "user_occ_dim = len(user_occ_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "820171f0-4784-4c61-b101-d3c9ae78f7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'entertainment': 0,\n",
       " b'salesman': 1,\n",
       " b'homemaker': 2,\n",
       " b'librarian': 3,\n",
       " b'administrator': 4,\n",
       " b'other': 5,\n",
       " b'none': 6,\n",
       " b'student': 7,\n",
       " b'executive': 8,\n",
       " b'scientist': 9,\n",
       " b'artist': 10,\n",
       " b'doctor': 11,\n",
       " b'engineer': 12,\n",
       " b'educator': 13,\n",
       " b'programmer': 14,\n",
       " b'writer': 15,\n",
       " b'technician': 16,\n",
       " b'marketing': 17,\n",
       " b'healthcare': 18,\n",
       " b'lawyer': 19,\n",
       " b'retired': 20}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_occ_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca8fa3dc-1144-4fff-8a03-eacb600d58a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_gen_lookup = get_dictionary_lookup_by_tf_data_key('movie_genres')\n",
    "movie_gen_dim = len(movie_gen_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7adf6f0-6842-4777-8cfe-65953dae96f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 1,\n",
       " 2: 2,\n",
       " 3: 3,\n",
       " 4: 4,\n",
       " 5: 5,\n",
       " 6: 6,\n",
       " 7: 7,\n",
       " 8: 8,\n",
       " 9: 9,\n",
       " 10: 10,\n",
       " 12: 11,\n",
       " 13: 12,\n",
       " 14: 13,\n",
       " 15: 14,\n",
       " 16: 15,\n",
       " 17: 16,\n",
       " 18: 17,\n",
       " 19: 18}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_gen_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b571a4e9-60ef-4e06-98b3-017fec36d36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " #from https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/environments/dataset_utilities.py#L153\n",
    "    \n",
    "# def load_movielens_data(data_file, delimiter=','):\n",
    "#     \"\"\"Loads the movielens data and returns the ratings matrix.\"\"\"\n",
    "#     ratings_matrix = np.zeros([MOVIELENS_NUM_USERS, MOVIELENS_NUM_MOVIES])\n",
    "#     with tf.io.gfile.GFile(data_file, 'r') as infile:\n",
    "#     # The file is a csv with rows containing:\n",
    "#     # user id | item id | rating | timestamp\n",
    "#     reader = csv.reader(infile, delimiter=delimiter)\n",
    "#     for row in reader:\n",
    "#         user_id, item_id, rating, _ = row\n",
    "#         ratings_matrix[int(user_id) - 1, int(item_id) - 1] = float(rating)\n",
    "#     return ratings_matrix\n",
    "\n",
    "\n",
    "\n",
    "def load_movielens_data(ratings_dataset):\n",
    "    # ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "    ratings_matrix = np.zeros([MOVIELENS_NUM_USERS, MOVIELENS_NUM_MOVIES])\n",
    "    local_data = ratings_dataset.map(lambda x: {'user_id': x['user_id']\n",
    "                                                 ,'movie_id':  x['movie_id']\n",
    "                                                 ,'user_rating':  x['user_rating']\n",
    "                                                 ,'bucketized_user_age': x['bucketized_user_age']\n",
    "                                                 ,'user_occupation_text': x['user_occupation_text']\n",
    "                                                 ,'movie_genres': x['movie_genres'][0]\n",
    "                                               }\n",
    "                                                                         )\n",
    "    user_age_int = []\n",
    "    user_occ_int = []\n",
    "    mov_gen_int = []\n",
    "    for row in local_data:\n",
    "        ratings_matrix[int(row['user_id'].numpy()) - 1, int(row['movie_id'].numpy()) - 1] = float(row['user_rating'].numpy())\n",
    "        user_age_int.append(user_age_lookup[row['bucketized_user_age'].numpy()])\n",
    "        user_occ_int.append(user_occ_lookup[row['user_occupation_text'].numpy()])\n",
    "        mov_gen_int.append(movie_gen_lookup[row['movie_genres'].numpy()])\n",
    "    return ratings_matrix, np.array(user_age_int), np.array(user_occ_int), np.array(mov_gen_int)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "50806cc4-f345-471f-9622-4201303c8679",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_matrix, user_age_int, user_occ_int, mov_gen_int = load_movielens_data(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "21f44fc5-c9fc-4ddc-a893-89648aa0b2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.bandits.specs import utils as bandit_spec_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86a12ac-8b8a-42da-b5c3-7c6bec75413c",
   "metadata": {},
   "source": [
    "## Replicate an agent using the above data\n",
    "\n",
    "https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/environments/movielens_per_arm_py_environment.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78910d5e-e38b-4120-8808-de492353b879",
   "metadata": {},
   "source": [
    "Create an arm spec from this utility function\n",
    "https://www.tensorflow.org/agents/api_docs/python/tf_agents/specs/bandit_spec_utils/create_per_arm_observation_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ce5142d9-aba2-4e53-a74e-667afa2a6452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': TensorSpec(shape=(1,), dtype=tf.float32, name=None),\n",
       " 'per_arm': TensorSpec(shape=(10, 2), dtype=tf.float32, name=None)}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example observation spec from above\n",
    "# There are 20 user occupations and 7 age buckets. This makes our global dimension 27\n",
    "# There are 19 genres, and that will be the arm dimension for this example\n",
    "\n",
    "from tf_agents.specs.bandit_spec_utils import create_per_arm_observation_spec as create_obs_spec\n",
    "create_obs_spec(\n",
    "    global_dim = 1,\n",
    "    per_arm_dim = 2,\n",
    "    max_num_actions = 10,\n",
    "    add_num_actions_feature = False\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f12a2000-55fd-48e8-8c81-509bea9d8a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.cardinality().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b369486f-47aa-4c9c-9726-ac4f83f0fcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Class implementation of the per-arm MovieLens Bandit environment.\"\"\"\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import random\n",
    "from typing import Optional, Text\n",
    "import gin\n",
    "import numpy as np\n",
    "\n",
    "from tf_agents.bandits.environments import bandit_py_environment\n",
    "from tf_agents.bandits.environments import dataset_utilities\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "\n",
    "GLOBAL_KEY = bandit_spec_utils.GLOBAL_FEATURE_KEY\n",
    "PER_ARM_KEY = bandit_spec_utils.PER_ARM_FEATURE_KEY\n",
    "\n",
    "\n",
    "# @gin.configurable\n",
    "class MovieLensPerArmPyEnvironment(bandit_py_environment.BanditPyEnvironment):\n",
    "    \"\"\"Implements the per-arm version of the MovieLens Bandit environment.\n",
    "\n",
    "    This environment implements the MovieLens 100K dataset, available at:\n",
    "    https://www.kaggle.com/prajitdatta/movielens-100k-dataset\n",
    "\n",
    "    This dataset contains 100K ratings from 943 users on 1682 items.\n",
    "    This csv list of:\n",
    "    user id | item id | rating | timestamp.\n",
    "    This environment computes a low-rank matrix factorization (using SVD) of the\n",
    "    data matrix `A`, such that: `A ~= U * Sigma * V^T`.\n",
    "\n",
    "    The environment uses the rows of `U` as global (or user) features, and the\n",
    "    rows of `V` as per-arm (or movie) features.\n",
    "\n",
    "    The reward of recommending movie `v` to user `u` is `u * Sigma * v^T`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "               dataset = ratings,\n",
    "               rank_k: int = 2,\n",
    "               user_feature_dim: int = 2,\n",
    "               movie_feature_dim: int = 2,\n",
    "               batch_size: int = 10,\n",
    "               num_actions: int = 100,\n",
    "               name: Optional[Text] = 'movielens_per_arm'):\n",
    "        \"\"\"Initializes the Per-arm MovieLens Bandit environment.\n",
    "\n",
    "        Args:\n",
    "          data_dir: (string) Directory where the data lies (in text form).\n",
    "          rank_k : (int) Which rank to use in the matrix factorization. This will\n",
    "            also be the feature dimension of both the user and the movie features.\n",
    "          batch_size: (int) Number of observations generated per call.\n",
    "          num_actions: (int) How many movies to choose from per round.\n",
    "          csv_delimiter: (string) The delimiter to use in loading the data csv file.\n",
    "          name: (string) The name of this environment instance.\n",
    "        \"\"\"\n",
    "        self._batch_size = batch_size\n",
    "        self._movie_context_dim = movie_feature_dim\n",
    "        self._user_context_dim = user_feature_dim\n",
    "        self._num_actions = num_actions\n",
    "\n",
    "        # Compute the matrix factorization.\n",
    "        # self._data_matrix = dataset_utilities.load_movielens_data(\n",
    "        #     data_dir, delimiter=csv_delimiter)\n",
    "\n",
    "        self._data_matrix, self._user_age_int, self._user_occ_int, self._mov_gen_int = load_movielens_data(ratings)\n",
    "        self._num_users, self._num_movies = self._data_matrix.shape\n",
    "\n",
    "        # Compute the SVD.\n",
    "        u, s, vh = np.linalg.svd(self._data_matrix, full_matrices=False)\n",
    "\n",
    "        # Keep only the largest singular values.\n",
    "        self._u_hat = u[:, :rank_k].astype(np.float32)\n",
    "        self._s_hat = s[:rank_k].astype(np.float32)\n",
    "        self._v_hat = np.transpose(vh[:rank_k]).astype(np.float32)\n",
    "\n",
    "        self._approx_ratings_matrix = np.matmul(self._u_hat * self._s_hat,\n",
    "                                                np.transpose(self._v_hat))\n",
    "\n",
    "        self._action_spec = array_spec.BoundedArraySpec(\n",
    "            shape=(),\n",
    "            dtype=np.int32,\n",
    "            minimum=0,\n",
    "            maximum=num_actions - 1,\n",
    "            name='action')\n",
    "        observation_spec = {\n",
    "            GLOBAL_KEY:\n",
    "                array_spec.ArraySpec(shape=[user_feature_dim+2], dtype=np.float32), #creating +space for user age and occupation\n",
    "            PER_ARM_KEY:\n",
    "                array_spec.ArraySpec(\n",
    "                    shape=[num_actions, movie_feature_dim+1], dtype=np.float32), #creating +1 space for movie genre\n",
    "        }\n",
    "        self._time_step_spec = ts.time_step_spec(observation_spec)\n",
    "\n",
    "        self._current_user_indices = np.zeros(batch_size, dtype=np.int32)\n",
    "        self._previous_user_indices = np.zeros(batch_size, dtype=np.int32)\n",
    "\n",
    "        self._current_movie_indices = np.zeros([batch_size, num_actions],\n",
    "                                               dtype=np.int32)\n",
    "        self._previous_movie_indices = np.zeros([batch_size, num_actions],\n",
    "                                                dtype=np.int32)\n",
    "\n",
    "        self._observation = {\n",
    "            GLOBAL_KEY:\n",
    "                np.zeros([batch_size, user_feature_dim+2]), #making space like above for dimensions\n",
    "            PER_ARM_KEY:\n",
    "                np.zeros([batch_size, num_actions, movie_feature_dim+1]),\n",
    "        }\n",
    "\n",
    "        super(MovieLensPerArmPyEnvironment, self).__init__(\n",
    "            observation_spec, self._action_spec, name=name)\n",
    "\n",
    "    @property\n",
    "    def batch_size(self):\n",
    "        return self._batch_size\n",
    "\n",
    "    @property\n",
    "    def batched(self):\n",
    "        return True\n",
    "\n",
    "    def _observe(self):\n",
    "        sampled_user_indices = np.random.randint(\n",
    "            self._num_users, size=self._batch_size)\n",
    "        self._previous_user_indices = self._current_user_indices\n",
    "        self._current_user_indices = sampled_user_indices\n",
    "\n",
    "        sampled_movie_indices = np.array([\n",
    "            random.sample(range(self._num_movies), self._num_actions)\n",
    "            for _ in range(self._batch_size)\n",
    "        ])\n",
    "        sampled_user_ages = self._user_age_int[sampled_movie_indices]\n",
    "        sampled_user_occ = self._user_occ_int[sampled_movie_indices]\n",
    "        combined_user_features = np.concatenate((self._u_hat[sampled_user_indices],sampled_user_ages,sampled_user_occ), axis=1)\n",
    "        \n",
    "        \n",
    "        movie_index_vector = sampled_movie_indices.reshape(-1)\n",
    "        print(movie_index_vector.shape)\n",
    "        flat_genre_list = self._mov_gen_int[movie_index_vector] #shape of 1\n",
    "        flat_movie_list = self._v_hat[movie_index_vector] #shape of 2\n",
    "        combined_movie_features = np.concatenate((flat_movie_list,flat_genre_list.reshape(-1,1)), axis=1)\n",
    "        current_movies = combined_movie_features.reshape(\n",
    "            [self._batch_size, self._num_actions, self._movie_context_dim+1])\n",
    "\n",
    "        self._previous_movie_indices = self._current_movie_indices\n",
    "        self._current_movie_indices = sampled_movie_indices\n",
    "\n",
    "        batched_observations = {\n",
    "            GLOBAL_KEY:\n",
    "                combined_user_features,\n",
    "            PER_ARM_KEY:\n",
    "                current_movies,\n",
    "        }\n",
    "        return batched_observations\n",
    "\n",
    "    def _apply_action(self, action):\n",
    "        chosen_arm_indices = self._current_movie_indices[range(self._batch_size),\n",
    "                                                         action]\n",
    "        return self._approx_ratings_matrix[self._current_user_indices,\n",
    "                                           chosen_arm_indices]\n",
    "\n",
    "    def _rewards_for_all_actions(self):\n",
    "        rewards_matrix = self._approx_ratings_matrix[\n",
    "            np.expand_dims(self._previous_user_indices, axis=-1),\n",
    "            self._previous_movie_indices]\n",
    "        return rewards_matrix\n",
    "\n",
    "    def compute_optimal_action(self):\n",
    "        return np.argmax(self._rewards_for_all_actions(), axis=-1)\n",
    "\n",
    "    def compute_optimal_reward(self):\n",
    "        return np.max(self._rewards_for_all_actions(), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d4188ae1-0859-4053-8a5f-b83c1e8a0c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ml_env = MovieLensPerArmPyEnvironment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "79623a28-4e47-4f0e-86de-b61382b939fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation spec:  {'global': ArraySpec(shape=(4,), dtype=dtype('float32'), name=None), 'per_arm': ArraySpec(shape=(100, 3), dtype=dtype('float32'), name=None)}\n",
      "(1000,)\n",
      "\n",
      "An observation:  {'global': array([[-1.20043661e-02,  1.08762253e-02,  3.00000000e+00, ...,\n",
      "         1.70000000e+01,  1.50000000e+01,  7.00000000e+00],\n",
      "       [-6.29553618e-03, -2.27739313e-03,  6.00000000e+00, ...,\n",
      "         5.00000000e+00,  1.30000000e+01,  1.80000000e+01],\n",
      "       [-1.53621919e-02, -1.34565327e-02,  6.00000000e+00, ...,\n",
      "         3.00000000e+00,  7.00000000e+00,  4.00000000e+00],\n",
      "       ...,\n",
      "       [-2.99785566e-03, -1.37790823e-02,  6.00000000e+00, ...,\n",
      "         3.00000000e+00,  7.00000000e+00,  7.00000000e+00],\n",
      "       [-1.65091828e-02,  3.12202098e-03,  6.00000000e+00, ...,\n",
      "         3.00000000e+00,  1.20000000e+01,  7.00000000e+00],\n",
      "       [-1.30955558e-02, -4.20920067e-02,  3.00000000e+00, ...,\n",
      "         1.60000000e+01,  1.50000000e+01,  1.50000000e+01]]), 'per_arm': array([[[-4.80739027e-03, -1.25242826e-02,  7.00000000e+00],\n",
      "        [-1.21963059e-03, -2.37211515e-03,  4.00000000e+00],\n",
      "        [-1.10713514e-02, -2.91842152e-03,  4.00000000e+00],\n",
      "        ...,\n",
      "        [-2.28619529e-03, -7.16917450e-03,  7.00000000e+00],\n",
      "        [-3.64160584e-03, -8.28878372e-04,  7.00000000e+00],\n",
      "        [-6.06160611e-04, -6.51653449e-04,  1.00000000e+01]],\n",
      "\n",
      "       [[-3.37328599e-03,  6.53651310e-03,  1.00000000e+00],\n",
      "        [-2.83368700e-03, -1.35657238e-03,  7.00000000e+00],\n",
      "        [-3.99802998e-03,  2.10278365e-03,  7.00000000e+00],\n",
      "        ...,\n",
      "        [-1.03631231e-03,  2.90488999e-04,  0.00000000e+00],\n",
      "        [-5.53242536e-03, -2.15961672e-02,  0.00000000e+00],\n",
      "        [-2.23567616e-02,  4.70476039e-02,  7.00000000e+00]],\n",
      "\n",
      "       [[-2.27490789e-03, -1.14946079e-03,  4.00000000e+00],\n",
      "        [-2.58918963e-02, -4.71050590e-02,  4.00000000e+00],\n",
      "        [-6.24489563e-04,  8.83755158e-04,  1.00000000e+01],\n",
      "        ...,\n",
      "        [-3.32524563e-04, -1.62648247e-03,  1.30000000e+01],\n",
      "        [-2.63295486e-04,  3.56541161e-04,  0.00000000e+00],\n",
      "        [-1.58465821e-02, -8.07500817e-03,  4.00000000e+00]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-5.82814496e-03, -9.89085808e-03,  2.00000000e+00],\n",
      "        [-4.28768653e-05, -5.75652753e-04,  0.00000000e+00],\n",
      "        [-2.87594128e-04, -6.78496319e-04,  7.00000000e+00],\n",
      "        ...,\n",
      "        [-1.91840716e-02,  2.95530632e-02,  4.00000000e+00],\n",
      "        [-6.26687258e-02,  5.00649884e-02,  3.00000000e+00],\n",
      "        [-2.51711197e-02, -7.58577213e-02,  7.00000000e+00]],\n",
      "\n",
      "       [[-1.68291898e-03, -1.32073625e-03,  7.00000000e+00],\n",
      "        [-2.97586843e-02, -5.78956828e-02,  2.00000000e+00],\n",
      "        [-3.87218110e-02, -5.37931323e-02,  0.00000000e+00],\n",
      "        ...,\n",
      "        [-2.78799608e-03, -7.84436241e-03,  0.00000000e+00],\n",
      "        [-1.70573574e-02,  6.28957013e-03,  7.00000000e+00],\n",
      "        [-9.37237032e-03, -2.15580966e-02,  0.00000000e+00]],\n",
      "\n",
      "       [[-1.09452950e-02,  4.31659445e-03,  4.00000000e+00],\n",
      "        [-5.75518273e-02,  2.69607455e-02,  0.00000000e+00],\n",
      "        [-3.99636710e-03, -1.01199951e-02,  4.00000000e+00],\n",
      "        ...,\n",
      "        [-1.08983777e-01,  2.31826417e-02,  0.00000000e+00],\n",
      "        [-9.20904786e-05, -2.85553942e-05,  1.50000000e+01],\n",
      "        [-3.10505740e-02,  4.23133224e-02,  0.00000000e+00]]])}\n"
     ]
    }
   ],
   "source": [
    "print('observation spec: ', my_ml_env.observation_spec())\n",
    "print('\\nAn observation: ', my_ml_env.reset().observation)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-12.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-12:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
