{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "525b561f-77f5-4736-927f-19929674b868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tf-agents --user -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53da2313-9daf-4662-8d9b-93b813d2a4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1112bb5e-0151-418f-9d17-eb17ee191788",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.bandits.agents import lin_ucb_agent\n",
    "from tf_agents.bandits.environments import stationary_stochastic_per_arm_py_environment as p_a_env\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "import tensorflow_datasets as tfds\n",
    "from pprint import pprint\n",
    "\n",
    "nest = tf.nest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dac1a89-b58b-4d4b-92ba-e70d9ed80a96",
   "metadata": {},
   "source": [
    "### movies data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03eb6ba1-8cae-41f6-b65a-31d18165fe69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[4]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'1681'], dtype=object)>,\n",
      " 'movie_title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'You So Crazy (1994)'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")\n",
    "\n",
    "for x in movies.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9c9413-3aa8-4188-b5a2-b342ef50faf2",
   "metadata": {},
   "source": [
    "### user and ratings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92dbdb4b-8f13-4455-887c-6617ebd80242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([45.], dtype=float32)>,\n",
      " 'movie_genres': <tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[7]])>,\n",
      " 'movie_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'357'], dtype=object)>,\n",
      " 'movie_title': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"One Flew Over the Cuckoo's Nest (1975)\"], dtype=object)>,\n",
      " 'raw_user_age': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([46.], dtype=float32)>,\n",
      " 'timestamp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([879024327])>,\n",
      " 'user_gender': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>,\n",
      " 'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'138'], dtype=object)>,\n",
      " 'user_occupation_label': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([4])>,\n",
      " 'user_occupation_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'doctor'], dtype=object)>,\n",
      " 'user_rating': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>,\n",
      " 'user_zip_code': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'53211'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "\n",
    "for x in ratings.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7941678d-f920-4206-9fea-d8e3e9f15cef",
   "metadata": {},
   "source": [
    "#### Let's make this simple and load up movielens that has features\n",
    "We will only consider for this example\n",
    "1) The movie genere as an Arm feature (we will concatenate multiple genres)\n",
    "2) The user occupation and age bucket labels for the overall context features\n",
    "\n",
    "We need to load the data, get the ratings - light EDA for us to get cardnality of the dataset as well as lookups for the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a4c8c8c-6e55-4140-86e7-701308154762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(unique_movie_ids) : 1682\n",
      "unique_movie_ids      : [b'1' b'10']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique movies and users\n",
    "unique_movie_ids = ratings.map(lambda x: x[\"movie_id\"])\n",
    "unique_movie_ids = np.unique([x.numpy() for x in unique_movie_ids])\n",
    "MOVIELENS_NUM_MOVIES = len(unique_movie_ids)\n",
    "\n",
    "\n",
    "print(f\"len(unique_movie_ids) : {len(unique_movie_ids)}\")\n",
    "print(f\"unique_movie_ids      : {unique_movie_ids[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bc12022-129d-48df-8cb3-7e53dbbbfea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(unique_user_ids) : 943\n",
      "unique_user_ids      : [b'1' b'10']\n"
     ]
    }
   ],
   "source": [
    "unique_user_ids = ratings.map(lambda x: x[\"user_id\"])\n",
    "unique_user_ids = np.unique([x.numpy() for x in unique_user_ids])\n",
    "MOVIELENS_NUM_USERS = len(unique_user_ids)\n",
    "\n",
    "\n",
    "print(f\"len(unique_user_ids) : {len(unique_user_ids)}\")\n",
    "print(f\"unique_user_ids      : {unique_user_ids[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cef8a89-0e97-4d93-819e-db2d4667efa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the unnique set of user buckets and create a lookup table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "174860eb-bfeb-4b02-b4d9-1dfaddc70914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def get_dictionary_lookup_by_tf_data_key(key: str) -> Dict:\n",
    "    tensor = ratings.map(lambda x: x[key])\n",
    "    unique_elems = set()\n",
    "    for x in tensor:\n",
    "        val = x.numpy()\n",
    "        if type(val) is np.ndarray: # if multi dimesnional only grab first one\n",
    "            val = val[0]\n",
    "        unique_elems.add(val)\n",
    "    \n",
    "    #return a dictionary of keys by integer values for the feature space\n",
    "    return {val: i for i, val in enumerate(unique_elems)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8113ded-13f2-460f-a2cd-90f44307f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_age_lookup = get_dictionary_lookup_by_tf_data_key('bucketized_user_age')\n",
    "user_age_dim = len(user_age_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bed813e8-cef5-46e0-a1d5-3f6c37ea34a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: 0, 35.0: 1, 45.0: 2, 18.0: 3, 50.0: 4, 56.0: 5, 25.0: 6}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_age_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ced8d46-9e1d-4d88-9228-cb57005d064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_occ_lookup = get_dictionary_lookup_by_tf_data_key('user_occupation_text')\n",
    "user_occ_dim = len(user_occ_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "820171f0-4784-4c61-b101-d3c9ae78f7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'administrator': 0,\n",
       " b'lawyer': 1,\n",
       " b'none': 2,\n",
       " b'technician': 3,\n",
       " b'programmer': 4,\n",
       " b'artist': 5,\n",
       " b'homemaker': 6,\n",
       " b'salesman': 7,\n",
       " b'educator': 8,\n",
       " b'retired': 9,\n",
       " b'student': 10,\n",
       " b'executive': 11,\n",
       " b'writer': 12,\n",
       " b'librarian': 13,\n",
       " b'scientist': 14,\n",
       " b'marketing': 15,\n",
       " b'entertainment': 16,\n",
       " b'doctor': 17,\n",
       " b'healthcare': 18,\n",
       " b'other': 19,\n",
       " b'engineer': 20}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_occ_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca8fa3dc-1144-4fff-8a03-eacb600d58a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_gen_lookup = get_dictionary_lookup_by_tf_data_key('movie_genres')\n",
    "movie_gen_dim = len(movie_gen_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7adf6f0-6842-4777-8cfe-65953dae96f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 1,\n",
       " 2: 2,\n",
       " 3: 3,\n",
       " 4: 4,\n",
       " 5: 5,\n",
       " 6: 6,\n",
       " 7: 7,\n",
       " 8: 8,\n",
       " 9: 9,\n",
       " 10: 10,\n",
       " 12: 11,\n",
       " 13: 12,\n",
       " 14: 13,\n",
       " 15: 14,\n",
       " 16: 15,\n",
       " 17: 16,\n",
       " 18: 17,\n",
       " 19: 18}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_gen_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b571a4e9-60ef-4e06-98b3-017fec36d36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " #from https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/environments/dataset_utilities.py#L153\n",
    "    \n",
    "# def load_movielens_data(data_file, delimiter=','):\n",
    "#     \"\"\"Loads the movielens data and returns the ratings matrix.\"\"\"\n",
    "#     ratings_matrix = np.zeros([MOVIELENS_NUM_USERS, MOVIELENS_NUM_MOVIES])\n",
    "#     with tf.io.gfile.GFile(data_file, 'r') as infile:\n",
    "#     # The file is a csv with rows containing:\n",
    "#     # user id | item id | rating | timestamp\n",
    "#     reader = csv.reader(infile, delimiter=delimiter)\n",
    "#     for row in reader:\n",
    "#         user_id, item_id, rating, _ = row\n",
    "#         ratings_matrix[int(user_id) - 1, int(item_id) - 1] = float(rating)\n",
    "#     return ratings_matrix\n",
    "\n",
    "\n",
    "\n",
    "def load_movielens_data(ratings_dataset):\n",
    "    # ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "    ratings_matrix = np.zeros([MOVIELENS_NUM_USERS, MOVIELENS_NUM_MOVIES])\n",
    "    local_data = ratings_dataset.map(lambda x: {'user_id': x['user_id']\n",
    "                                                 ,'movie_id':  x['movie_id']\n",
    "                                                 ,'user_rating':  x['user_rating']\n",
    "                                                 ,'bucketized_user_age': x['bucketized_user_age']\n",
    "                                                 ,'user_occupation_text': x['user_occupation_text']\n",
    "                                                 ,'movie_genres': x['movie_genres'][0]\n",
    "                                               }\n",
    "                                                                         )\n",
    "    user_age_int = []\n",
    "    user_occ_int = []\n",
    "    mov_gen_int = []\n",
    "    for row in local_data:\n",
    "        ratings_matrix[int(row['user_id'].numpy()) - 1, int(row['movie_id'].numpy()) - 1] = float(row['user_rating'].numpy())\n",
    "        user_age_int.append(float(user_age_lookup[row['bucketized_user_age'].numpy()])+.0001)\n",
    "        user_occ_int.append(float(user_occ_lookup[row['user_occupation_text'].numpy()])+.0001)\n",
    "        mov_gen_int.append(float(movie_gen_lookup[row['movie_genres'].numpy()])+.0001) \n",
    "    return ratings_matrix, np.array(user_age_int), np.array(user_occ_int), np.array(mov_gen_int)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50806cc4-f345-471f-9622-4201303c8679",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_matrix, user_age_int, user_occ_int, mov_gen_int = load_movielens_data(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21f44fc5-c9fc-4ddc-a893-89648aa0b2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.bandits.specs import utils as bandit_spec_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78910d5e-e38b-4120-8808-de492353b879",
   "metadata": {},
   "source": [
    "Create an arm spec from this utility function\n",
    "https://www.tensorflow.org/agents/api_docs/python/tf_agents/specs/bandit_spec_utils/create_per_arm_observation_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86a12ac-8b8a-42da-b5c3-7c6bec75413c",
   "metadata": {},
   "source": [
    "## Replicate an agent using the above data\n",
    "\n",
    "https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/environments/movielens_per_arm_py_environment.py\n",
    "\n",
    "#### NOT Used but helpful to create an obs spec:\n",
    "\n",
    "```python\n",
    "# Example observation spec from above\n",
    "# There are 20 user occupations and 7 age buckets. This makes our global dimension 27\n",
    "# There are 19 genres, and that will be the arm dimension for this example\n",
    "\n",
    "from tf_agents.specs.bandit_spec_utils import create_per_arm_observation_spec as create_obs_spec\n",
    "create_obs_spec(\n",
    "    global_dim = 1,\n",
    "    per_arm_dim = 2,\n",
    "    max_num_actions = 10,\n",
    "    add_num_actions_feature = False\n",
    ") \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b369486f-47aa-4c9c-9726-ac4f83f0fcc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Class implementation of the per-arm MovieLens Bandit environment.\"\"\"\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import random\n",
    "from typing import Optional, Text\n",
    "import gin\n",
    "import numpy as np\n",
    "\n",
    "from tf_agents.bandits.environments import bandit_py_environment\n",
    "from tf_agents.bandits.environments import dataset_utilities\n",
    "from tf_agents.bandits.specs import utils as bandit_spec_utils\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "\n",
    "GLOBAL_KEY = bandit_spec_utils.GLOBAL_FEATURE_KEY\n",
    "PER_ARM_KEY = bandit_spec_utils.PER_ARM_FEATURE_KEY\n",
    "\n",
    "\n",
    "# @gin.configurable\n",
    "class MovieLensPerArmPyEnvironment(bandit_py_environment.BanditPyEnvironment):\n",
    "    \"\"\"Implements the per-arm version of the MovieLens Bandit environment.\n",
    "\n",
    "    This environment implements the MovieLens 100K dataset, available at:\n",
    "    https://www.kaggle.com/prajitdatta/movielens-100k-dataset\n",
    "\n",
    "    This dataset contains 100K ratings from 943 users on 1682 items.\n",
    "    This csv list of:\n",
    "    user id | item id | rating | timestamp.\n",
    "    This environment computes a low-rank matrix factorization (using SVD) of the\n",
    "    data matrix `A`, such that: `A ~= U * Sigma * V^T`.\n",
    "\n",
    "    The environment uses the rows of `U` as global (or user) features, and the\n",
    "    rows of `V` as per-arm (or movie) features.\n",
    "\n",
    "    The reward of recommending movie `v` to user `u` is `u * Sigma * v^T`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "               dataset = ratings,\n",
    "               rank_k: int = 2,\n",
    "               batch_size: int = 10,\n",
    "               num_actions: int = 100,\n",
    "               name: Optional[Text] = 'movielens_per_arm'):\n",
    "        \"\"\"Initializes the Per-arm MovieLens Bandit environment.\n",
    "\n",
    "        Args:\n",
    "          data_dir: (string) Directory where the data lies (in text form).\n",
    "          rank_k : (int) Which rank to use in the matrix factorization. This will\n",
    "            also be the feature dimension of both the user and the movie features.\n",
    "          batch_size: (int) Number of observations generated per call.\n",
    "          num_actions: (int) How many movies to choose from per round.\n",
    "          csv_delimiter: (string) The delimiter to use in loading the data csv file.\n",
    "          name: (string) The name of this environment instance.\n",
    "        \"\"\"\n",
    "        self._batch_size = batch_size\n",
    "        self._num_actions = num_actions\n",
    "        self.rank_k = rank_k\n",
    "\n",
    "        # Compute the matrix factorization.\n",
    "        # self._data_matrix = dataset_utilities.load_movielens_data(\n",
    "        #     data_dir, delimiter=csv_delimiter)\n",
    "\n",
    "        self._data_matrix, self._user_age_int, self._user_occ_int, self._mov_gen_int = load_movielens_data(ratings)\n",
    "        self._num_users, self._num_movies = self._data_matrix.shape\n",
    "\n",
    "        # Compute the SVD.\n",
    "        u, s, vh = np.linalg.svd(self._data_matrix, full_matrices=False)\n",
    "\n",
    "        # Keep only the largest singular values.\n",
    "        self._u_hat = u[:, :rank_k].astype(np.float32)\n",
    "        self._s_hat = s[:rank_k].astype(np.float32)\n",
    "        self._v_hat = np.transpose(vh[:rank_k]).astype(np.float32)\n",
    "\n",
    "        self._approx_ratings_matrix = np.matmul(self._u_hat * self._s_hat,\n",
    "                                                np.transpose(self._v_hat))\n",
    "\n",
    "        self._action_spec = array_spec.BoundedArraySpec(\n",
    "            shape=(),\n",
    "            dtype=np.int32,\n",
    "            minimum=0,\n",
    "            maximum=num_actions - 1,\n",
    "            name='action')\n",
    "        observation_spec = {\n",
    "            GLOBAL_KEY:\n",
    "                array_spec.ArraySpec(shape=[rank_k+2], dtype=np.float32), #creating +space for user age and occupation\n",
    "            PER_ARM_KEY:\n",
    "                array_spec.ArraySpec(\n",
    "                    shape=[num_actions, rank_k+1], dtype=np.float32), #creating +1 space for movie genre\n",
    "        }\n",
    "        self._time_step_spec = ts.time_step_spec(observation_spec)\n",
    "\n",
    "        self._current_user_indices = np.zeros(batch_size, dtype=np.int32)\n",
    "        self._previous_user_indices = np.zeros(batch_size, dtype=np.int32)\n",
    "\n",
    "        self._current_movie_indices = np.zeros([batch_size, num_actions],\n",
    "                                               dtype=np.int32)\n",
    "        self._previous_movie_indices = np.zeros([batch_size, num_actions],\n",
    "                                                dtype=np.int32)\n",
    "\n",
    "        self._observation = {\n",
    "            GLOBAL_KEY:\n",
    "                np.zeros([batch_size, rank_k+2], dtype=np.int32), #making space like above for dimensions\n",
    "            PER_ARM_KEY:\n",
    "                np.zeros([batch_size, num_actions, rank_k+1], dtype=np.int32),\n",
    "        }\n",
    "\n",
    "        super(MovieLensPerArmPyEnvironment, self).__init__(\n",
    "            observation_spec, self._action_spec, name=name)\n",
    "\n",
    "    @property\n",
    "    def batch_size(self):\n",
    "        return self._batch_size\n",
    "\n",
    "    @property\n",
    "    def batched(self):\n",
    "        return True\n",
    "\n",
    "    def _observe(self):\n",
    "        sampled_user_indices = np.random.randint(\n",
    "            self._num_users, size=self._batch_size)\n",
    "        self._previous_user_indices = self._current_user_indices\n",
    "        self._current_user_indices = sampled_user_indices\n",
    "\n",
    "        sampled_movie_indices = np.array([\n",
    "            random.sample(range(self._num_movies), self._num_actions)\n",
    "            for _ in range(self._batch_size)\n",
    "        ])\n",
    "        sampled_user_ages = self._user_age_int[sampled_user_indices]\n",
    "        sampled_user_occ = self._user_occ_int[sampled_user_indices]\n",
    "        combined_user_features = np.concatenate((self._u_hat[sampled_user_indices]\n",
    "                                                 , sampled_user_ages.reshape(-1,1)\n",
    "                                                 , sampled_user_occ.reshape(-1,1)), axis=1)\n",
    "        # current_users = combined_user_features.reshape([self._batch_size, self.rank_k+2])\n",
    "        \n",
    "        movie_index_vector = sampled_movie_indices.reshape(-1)\n",
    "        print(movie_index_vector.shape)\n",
    "        flat_genre_list = self._mov_gen_int[movie_index_vector] #shape of 1\n",
    "        flat_movie_list = self._v_hat[movie_index_vector] #shape of 2\n",
    "        combined_movie_features = np.concatenate((flat_movie_list,flat_genre_list.reshape(-1,1)), axis=1)\n",
    "        current_movies = combined_movie_features.reshape(\n",
    "            [self._batch_size, self._num_actions, self.rank_k+1])\n",
    "\n",
    "        self._previous_movie_indices = self._current_movie_indices\n",
    "        self._current_movie_indices = sampled_movie_indices\n",
    "\n",
    "        batched_observations = {\n",
    "            GLOBAL_KEY:\n",
    "                tf.convert_to_tensor(combined_user_features, dtype=tf.float32),\n",
    "            PER_ARM_KEY:\n",
    "                tf.convert_to_tensor(current_movies, dtype=tf.float32),\n",
    "        }\n",
    "        return batched_observations\n",
    "\n",
    "    def _apply_action(self, action):\n",
    "        chosen_arm_indices = self._current_movie_indices[range(self._batch_size),\n",
    "                                                         action]\n",
    "        return self._approx_ratings_matrix[self._current_user_indices,\n",
    "                                           chosen_arm_indices]\n",
    "\n",
    "    def _rewards_for_all_actions(self):\n",
    "        rewards_matrix = self._approx_ratings_matrix[\n",
    "            np.expand_dims(self._previous_user_indices, axis=-1),\n",
    "            self._previous_movie_indices]\n",
    "        return rewards_matrix\n",
    "\n",
    "    def compute_optimal_action(self):\n",
    "        return np.argmax(self._rewards_for_all_actions(), axis=-1)\n",
    "\n",
    "    def compute_optimal_reward(self):\n",
    "        return np.max(self._rewards_for_all_actions(), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4188ae1-0859-4053-8a5f-b83c1e8a0c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = MovieLensPerArmPyEnvironment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79623a28-4e47-4f0e-86de-b61382b939fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('observation spec: ', env.observation_spec())\n",
    "# print('\\nAn observation: ', env.reset().observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4348dcce-d92e-47c1-af00-ae5181c0184d",
   "metadata": {},
   "source": [
    "### Now that the environment is created, let's optimize\n",
    "\n",
    "Taken from here\n",
    "https://github.com/tensorflow/agents/blob/5e5915b0a3650a15e82e77af6e37f41a6c744689/tf_agents/bandits/agents/examples/v2/train_eval_movielens.py#L84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea63b13a-f613-40f3-8184-68d14e45f3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import os\n",
    "from absl import app\n",
    "from absl import flags\n",
    "\n",
    "import tensorflow as tf  # pylint: disable=g-explicit-tensorflow-version-import\n",
    "from tf_agents.bandits.agents import dropout_thompson_sampling_agent as dropout_ts_agent\n",
    "from tf_agents.bandits.agents import lin_ucb_agent\n",
    "from tf_agents.bandits.agents import linear_thompson_sampling_agent as lin_ts_agent\n",
    "from tf_agents.bandits.agents import neural_epsilon_greedy_agent as eps_greedy_agent\n",
    "from tf_agents.bandits.agents.examples.v2 import trainer\n",
    "from tf_agents.bandits.environments import environment_utilities\n",
    "from tf_agents.bandits.environments import movielens_per_arm_py_environment\n",
    "from tf_agents.bandits.environments import movielens_py_environment\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.bandits.networks import global_and_arm_feature_network\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.networks import q_network\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "TRAINING_LOOPS = 20000\n",
    "STEPS_PER_LOOP = 2\n",
    "\n",
    "RANK_K = 20\n",
    "NUM_ACTIONS = 20\n",
    "\n",
    "# LinUCB agent constants.\n",
    "\n",
    "AGENT_ALPHA = 10.0\n",
    "\n",
    "# epsilon Greedy constants.\n",
    "\n",
    "EPSILON = 0.05\n",
    "LAYERS = (50, 50, 50)\n",
    "LR = 0.005\n",
    "\n",
    "# Dropout TS constants.\n",
    "DROPOUT_RATE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1d468cf-446a-49d0-aee1-bff3c401e493",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d32f9df-0159-464f-bf11-c054f98ef0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MovieLensPerArmPyEnvironment(\n",
    "        rank_k=RANK_K,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_actions=NUM_ACTIONS,\n",
    ")\n",
    "environment = tf_py_environment.TFPyEnvironment(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c03aba-3f12-4375-998e-919585c2f9c1",
   "metadata": {},
   "source": [
    "### Note we will be using the reward function with this utility function\n",
    "\n",
    "```python\n",
    "@gin.configurable\n",
    "def compute_optimal_reward_with_movielens_environment(observation, environment):\n",
    "  \"\"\"Helper function for gin configurable Regret metric.\"\"\"\n",
    "  del observation\n",
    "  return tf.py_function(environment.compute_optimal_reward, [], tf.float32)\n",
    "\n",
    "@gin.configurable\n",
    "def compute_optimal_action_with_movielens_environment(observation,\n",
    "                                                      environment,\n",
    "                                                      action_dtype=tf.int32):\n",
    "  \"\"\"Helper function for gin configurable SuboptimalArms metric.\"\"\"\n",
    "  del observation\n",
    "  return tf.py_function(environment.compute_optimal_action, [], action_dtype)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78599527-d82d-4048-a319-2dbf7e878db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_reward_fn = functools.partial(\n",
    "      environment_utilities.compute_optimal_reward_with_movielens_environment,\n",
    "      environment=environment)\n",
    "\n",
    "optimal_action_fn = functools.partial(\n",
    "  environment_utilities.compute_optimal_action_with_movielens_environment,\n",
    "  environment=environment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1d1011-8a9b-4f56-9ee7-9492b1a6f01b",
   "metadata": {},
   "source": [
    "### Below we will try different agents by selecting one of the enumerated types:\n",
    "\n",
    "```python\n",
    "flags.DEFINE_enum(\n",
    "    'agent', 'LinUCB', ['LinUCB', 'LinTS', 'epsGreedy', 'DropoutTS'],\n",
    "    'Which agent to use. Possible values: `LinUCB`, `LinTS`, `epsGreedy`,'\n",
    "    ' `DropoutTS`.')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a6a8c07-e655-49e1-871d-ae5e567c2256",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_TYPE = 'LinUCB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "795f6e5b-e98e-4d85-9935-59deae6ba60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if AGENT_TYPE == 'LinUCB':\n",
    "    agent = lin_ucb_agent.LinearUCBAgent(\n",
    "        time_step_spec=environment.time_step_spec(),\n",
    "        action_spec=environment.action_spec(),\n",
    "        tikhonov_weight=0.001,\n",
    "        alpha=AGENT_ALPHA,\n",
    "        dtype=tf.float32,\n",
    "        accepts_per_arm_features=True)\n",
    "\n",
    "elif AGENT_TYPE == 'LinTS':\n",
    "    agent = lin_ts_agent.LinearThompsonSamplingAgent(\n",
    "        time_step_spec=environment.time_step_spec(),\n",
    "        action_spec=environment.action_spec(),\n",
    "        dtype=tf.float32,\n",
    "        accepts_per_arm_features=True)\n",
    "\n",
    "elif AGENT_TYPE == 'epsGreedy':\n",
    "    network = (\n",
    "      global_and_arm_feature_network\n",
    "      .create_feed_forward_dot_product_network(\n",
    "          environment.time_step_spec().observation,\n",
    "          global_layers=LAYERS,\n",
    "          arm_layers=LAYERS))\n",
    "\n",
    "    agent = eps_greedy_agent.NeuralEpsilonGreedyAgent(\n",
    "        time_step_spec=environment.time_step_spec(),\n",
    "        action_spec=environment.action_spec(),\n",
    "        reward_network=network,\n",
    "        optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=LR),\n",
    "        epsilon=EPSILON,\n",
    "        emit_policy_info='predicted_rewards_mean',\n",
    "        info_fields_to_inherit_from_greedy=['predicted_rewards_mean'])\n",
    "\n",
    "elif AGENT_TYPE == 'DropoutTS':\n",
    "    train_step_counter = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "    def dropout_fn():\n",
    "        return tf.math.maximum(\n",
    "          tf.math.reciprocal_no_nan(1.01 +\n",
    "                                    tf.cast(train_step_counter, tf.float32)),\n",
    "          0.0003)\n",
    "\n",
    "    agent = dropout_ts_agent.DropoutThompsonSamplingAgent(\n",
    "        time_step_spec=environment.time_step_spec(),\n",
    "        action_spec=environment.action_spec(),\n",
    "        dropout_rate=dropout_fn,\n",
    "        network_layers=LAYERS,\n",
    "        optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=LR))\n",
    "\n",
    "regret_metric = tf_bandit_metrics.RegretMetric(optimal_reward_fn)\n",
    "suboptimal_arms_metric = tf_bandit_metrics.SuboptimalArmsMetric(\n",
    "  optimal_action_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4ebbb8-bc40-42a5-bbbd-9438d3ff2e74",
   "metadata": {},
   "source": [
    "### Now train the MAB Agent\n",
    "\n",
    "Create a local checkpoint folder if you already have not\n",
    "!mkdir checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46b033cd-dd23-4e93-a33c-347f7e3915f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67a9c912-b2b6-44c7-909a-d431316ce0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160,)\n",
      "(160,)\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TFStepMetric._update_state at 0x7fa1fc4417e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TFStepMetric._update_state at 0x7fa1fc4417e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TFStepMetric._update_state at 0x7fa1fc443d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TFStepMetric._update_state at 0x7fa1fc443d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation/global, 0/observation/per_arm with unsupported characters which will be renamed to step_type, reward, discount, observation_global, observation_per_arm in the SavedModel.\n",
      "WARNING:absl:`0/step_type` is not a valid tf.function parameter name. Sanitizing to `arg_0_step_type`.\n",
      "WARNING:absl:`0/reward` is not a valid tf.function parameter name. Sanitizing to `arg_0_reward`.\n",
      "WARNING:absl:`0/discount` is not a valid tf.function parameter name. Sanitizing to `arg_0_discount`.\n",
      "WARNING:absl:`0/observation/global` is not a valid tf.function parameter name. Sanitizing to `arg_0_observation_global`.\n",
      "WARNING:absl:`0/observation/per_arm` is not a valid tf.function parameter name. Sanitizing to `arg_0_observation_per_arm`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint/policy_16/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:497: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: checkpoint/policy_16/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n",
      "(160,)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m      \u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcheckpoint\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m      \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m      \u001b[49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtraining_loops\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRAINING_LOOPS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_loop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSTEPS_PER_LOOP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m      \u001b[49m\u001b[43madditional_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mregret_metric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuboptimal_arms_metric\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/bandits/agents/examples/v2/trainer.py:268\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(root_dir, agent, environment, training_loops, steps_per_loop, async_steps_per_loop, additional_metrics, get_replay_buffer_fn, get_training_loop_fn, training_data_spec_transformation_fn, save_policy, resume_training_loops)\u001b[0m\n\u001b[1;32m    265\u001b[0m   starting_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(starting_loop, training_loops):\n\u001b[0;32m--> 268\u001b[0m   \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m   checkpoint_manager\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m    270\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m save_policy \u001b[38;5;241m&\u001b[39m (i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tf_agents/bandits/agents/examples/v2/trainer.py:97\u001b[0m, in \u001b[0;36m_get_training_loop.<locals>.training_loop\u001b[0;34m(train_step, metrics)\u001b[0m\n\u001b[1;32m     91\u001b[0m dataset_it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m     92\u001b[0m     replay_buffer\u001b[38;5;241m.\u001b[39mas_dataset(\n\u001b[1;32m     93\u001b[0m         sample_batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     94\u001b[0m         num_steps\u001b[38;5;241m=\u001b[39msteps,\n\u001b[1;32m     95\u001b[0m         single_deterministic_pass\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(async_steps_per_loop):\n\u001b[0;32m---> 97\u001b[0m   experience, unused_buffer_info \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_it\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m   set_expected_shape(experience, steps)\n\u001b[1;32m     99\u001b[0m   loss_info \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mtrain(experience)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:850\u001b[0m, in \u001b[0;36mOwnedIterator.get_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_next\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 850\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:780\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[0;32m--> 780\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    785\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3011\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   3010\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3011\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3012\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIteratorGetNext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_types\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3013\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3014\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3015\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(\n",
    "      root_dir='checkpoint',\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      training_loops=TRAINING_LOOPS,\n",
    "      steps_per_loop=STEPS_PER_LOOP,\n",
    "      additional_metrics=[regret_metric, suboptimal_arms_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786bbd12-9097-4c6f-ade3-82dbeca07a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-12.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-12:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
